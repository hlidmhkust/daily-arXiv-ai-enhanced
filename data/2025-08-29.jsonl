{"id": "2508.20127", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.20127", "abs": "https://arxiv.org/abs/2508.20127", "authors": ["Yihan Zhou", "Haocheng Huang", "Yue Yu", "Jianhui Shang"], "title": "A Machine Learning Approach to Volumetric Computations of Solid Pulmonary Nodules", "comment": null, "summary": "Early detection of lung cancer is crucial for effective treatment and relies\non accurate volumetric assessment of pulmonary nodules in CT scans. Traditional\nmethods, such as consolidation-to-tumor ratio (CTR) and spherical\napproximation, are limited by inconsistent estimates due to variability in\nnodule shape and density. We propose an advanced framework that combines a\nmulti-scale 3D convolutional neural network (CNN) with subtype-specific bias\ncorrection for precise volume estimation. The model was trained and evaluated\non a dataset of 364 cases from Shanghai Chest Hospital. Our approach achieved a\nmean absolute deviation of 8.0 percent compared to manual nonlinear regression,\nwith inference times under 20 seconds per scan. This method outperforms\nexisting deep learning and semi-automated pipelines, which typically have\nerrors of 25 to 30 percent and require over 60 seconds for processing. Our\nresults show a reduction in error by over 17 percentage points and a threefold\nacceleration in processing speed. These advancements offer a highly accurate,\nefficient, and scalable tool for clinical lung nodule screening and monitoring,\nwith promising potential for improving early lung cancer detection."}
{"id": "2508.20135", "categories": ["eess.IV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20135", "abs": "https://arxiv.org/abs/2508.20135", "authors": ["Andrew Yarovoi", "Christopher R. Valenta"], "title": "Data-Efficient Point Cloud Semantic Segmentation Pipeline for Unimproved Roads", "comment": "9 pages, 4 figures", "summary": "In this case study, we present a data-efficient point cloud segmentation\npipeline and training framework for robust segmentation of unimproved roads and\nseven other classes. Our method employs a two-stage training framework: first,\na projection-based convolutional neural network is pre-trained on a mixture of\npublic urban datasets and a small, curated in-domain dataset; then, a\nlightweight prediction head is fine-tuned exclusively on in-domain data. Along\nthe way, we explore the application of Point Prompt Training to batch\nnormalization layers and the effects of Manifold Mixup as a regularizer within\nour pipeline. We also explore the effects of incorporating histogram-normalized\nambients to further boost performance. Using only 50 labeled point clouds from\nour target domain, we show that our proposed training approach improves mean\nIntersection-over-Union from 33.5% to 51.8% and the overall accuracy from 85.5%\nto 90.8%, when compared to naive training on the in-domain data. Crucially, our\nresults demonstrate that pre-training across multiple datasets is key to\nimproving generalization and enabling robust segmentation under limited\nin-domain supervision. Overall, this study demonstrates a practical framework\nfor robust 3D semantic segmentation in challenging, low-data scenarios. Our\ncode is available at: https://github.com/andrewyarovoi/MD-FRNet."}
{"id": "2508.20136", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2508.20136", "abs": "https://arxiv.org/abs/2508.20136", "authors": ["Junru Lin", "Chirag Vashist", "Mikaela Angelina Uy", "Colton Stearns", "Xuan Luo", "Leonidas Guibas", "Ke Li"], "title": "Global Motion Corresponder for 3D Point-Based Scene Interpolation under Large Motion", "comment": "https://junrul.github.io/gmc/", "summary": "Existing dynamic scene interpolation methods typically assume that the motion\nbetween consecutive timesteps is small enough so that displacements can be\nlocally approximated by linear models. In practice, even slight deviations from\nthis small-motion assumption can cause conventional techniques to fail. In this\npaper, we introduce Global Motion Corresponder (GMC), a novel approach that\nrobustly handles large motion and achieves smooth transitions. GMC learns unary\npotential fields that predict SE(3) mappings into a shared canonical space,\nbalancing correspondence, spatial and semantic smoothness, and local rigidity.\nWe demonstrate that our method significantly outperforms existing baselines on\n3D scene interpolation when the two states undergo large global motions.\nFurthermore, our method enables extrapolation capabilities where other baseline\nmethods cannot."}
{"id": "2508.20139", "categories": ["eess.IV", "cs.CV", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20139", "abs": "https://arxiv.org/abs/2508.20139", "authors": ["Guoping Xu", "Jayaram K. Udupa", "Jax Luo", "Songlin Zhao", "Yajun Yu", "Scott B. Raymond", "Hao Peng", "Lipeng Ning", "Yogesh Rathi", "Wei Liu", "You Zhang"], "title": "Is the medical image segmentation problem solved? A survey of current developments and future directions", "comment": "80 pages, 38 figures", "summary": "Medical image segmentation has advanced rapidly over the past two decades,\nlargely driven by deep learning, which has enabled accurate and efficient\ndelineation of cells, tissues, organs, and pathologies across diverse imaging\nmodalities. This progress raises a fundamental question: to what extent have\ncurrent models overcome persistent challenges, and what gaps remain? In this\nwork, we provide an in-depth review of medical image segmentation, tracing its\nprogress and key developments over the past decade. We examine core principles,\nincluding multiscale analysis, attention mechanisms, and the integration of\nprior knowledge, across the encoder, bottleneck, skip connections, and decoder\ncomponents of segmentation networks. Our discussion is organized around seven\nkey dimensions: (1) the shift from supervised to semi-/unsupervised learning,\n(2) the transition from organ segmentation to lesion-focused tasks, (3)\nadvances in multi-modality integration and domain adaptation, (4) the role of\nfoundation models and transfer learning, (5) the move from deterministic to\nprobabilistic segmentation, (6) the progression from 2D to 3D and 4D\nsegmentation, and (7) the trend from model invocation to segmentation agents.\nTogether, these perspectives provide a holistic overview of the trajectory of\ndeep learning-based medical image segmentation and aim to inspire future\ninnovation. To support ongoing research, we maintain a continually updated\nrepository of relevant literature and open-source resources at\nhttps://github.com/apple1986/medicalSegReview"}
{"id": "2508.20277", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20277", "abs": "https://arxiv.org/abs/2508.20277", "authors": ["Xiaoyan Ma", "Shahryar Zehtabi", "Taejoon Kim", "Christopher G. Brinton"], "title": "Error Analysis for Over-the-Air Federated Learning under Misaligned and Time-Varying Channels", "comment": null, "summary": "This paper investigates an OFDM-based over-the-air federated learning\n(OTA-FL) system, where multiple mobile devices, e.g., unmanned aerial vehicles\n(UAVs), transmit local machine learning (ML) models to a central parameter\nserver (PS) for global model aggregation. The high mobility of local devices\nresults in imperfect channel estimation, leading to a misalignment problem,\ni.e., the model parameters transmitted from different local devices do not\narrive at the central PS simultaneously. Moreover, the mobility introduces\ntime-varying uploading channels, which further complicates the aggregation\nprocess. All these factors collectively cause distortions in the OTA-FL\ntraining process which are underexplored. To quantify these effects, we first\nderive a closed-form expression for a single-round global model update in terms\nof these channel imperfections. We then extend our analysis to capture multiple\nrounds of global updates, yielding a bound on the accumulated error in OTA-FL.\nWe validate our theoretical results via extensive numerical simulations, which\ncorroborate our derived analysis."}
{"id": "2508.20369", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20369", "abs": "https://arxiv.org/abs/2508.20369", "authors": ["Haiquan Lu", "Hongqi Min", "Yong Zeng", "Shaodan Ma"], "title": "Flexible XL-MIMO via Array Configuration Codebook: Codebook Design and Array Configuration Training", "comment": null, "summary": "XL-MIMO emerges as a promising technology to achieve unprecedented\nenhancements in spectral efficiency and spatial resolution, via\norders-of-magnitude increase in the antenna array size. However, the practical\nissues of high hardware cost and power consumption pose great challenges\ntowards the cost-effective implementation of XL-MIMO. To address such\nchallenges, this paper proposes a novel concept called array configuration\ncodebook (ACC), which enables flexible XL-MIMO cost-effectively and improves\nthe system performance compared with conventional antenna selection (AS)\nschemes with limited number of RF chains. Specifically, ACC refers to a set of\npre-designed array configuration codewords, where each codeword specifies the\npositions of activated antenna pixels. Then, flexible XL-MIMO architecture can\nbe enabled via dynamical pixel activation based on the designed ACC, without\nhaving to exhaustively try all possible combinations of the antenna pixels\nactivations. As an illustration, we give a specific codebook design,\nencompassing the classic compact array (CA), uniform sparse array (USA),\nmodular array (MoA), nested array (NA), and co-prime array (CPA), and each\ncodeword is specified by one array configuration parameter. With the designed\nACC, array configuration training is considered for multi-UE communication to\nmaximize the sum rate. To reduce the training overhead of exhaustive scanning,\na two-stage scanning scheme is proposed, including the array- and pixel-level\nscanning. For comparison, the greedy AS scheme is proposed, where the resulting\nincremental SINR expression by activating antenna pixel sequentially is derived\nin closed-form. Subsequently, array configuration training is extended to the\nwireless localization scenario. Simulation results demonstrate the\neffectiveness of codeword optimization for scenarios of multi-UE communication\nand wireless localization."}
{"id": "2508.20141", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.20141", "abs": "https://arxiv.org/abs/2508.20141", "authors": ["Ruowei Tang", "Pengfei Zhao", "Xiaoguang Li", "Ning Xu", "Yue Cheng", "Mengshi Zhang", "Zhixiang Wang", "Zhengyu Zhang", "Hongxia Yin", "Heyu Ding", "Shusheng Gong", "Yuhe Liu", "Zhenchang Wang"], "title": "UltraEar: a multicentric, large-scale database combining ultra-high-resolution computed tomography and clinical data for ear diseases", "comment": null, "summary": "Ear diseases affect billions of people worldwide, leading to substantial\nhealth and socioeconomic burdens. Computed tomography (CT) plays a pivotal role\nin accurate diagnosis, treatment planning, and outcome evaluation. The\nobjective of this study is to present the establishment and design of UltraEar\nDatabase, a large-scale, multicentric repository of isotropic 0.1 mm\nultra-high-resolution CT (U-HRCT) images and associated clinical data dedicated\nto ear diseases. UltraEar recruits patients from 11 tertiary hospitals between\nOctober 2020 and October 2035, integrating U-HRCT images, structured CT\nreports, and comprehensive clinical information, including demographics,\naudiometric profiles, surgical records, and pathological findings. A broad\nspectrum of otologic disorders is covered, such as otitis media, cholesteatoma,\nossicular chain malformation, temporal bone fracture, inner ear malformation,\ncochlear aperture stenosis, enlarged vestibular aqueduct, and sigmoid sinus\nbony deficiency. Standardized preprocessing pipelines have been developed for\ngeometric calibration, image annotation, and multi-structure segmentation. All\npersonal identifiers in DICOM headers and metadata are removed or anonymized to\nensure compliance with data privacy regulation. Data collection and curation\nare coordinated through monthly expert panel meetings, with secure storage on\nan offline cloud system. UltraEar provides an unprecedented\nultra-high-resolution reference atlas with both technical fidelity and clinical\nrelevance. This resource has significant potential to advance radiological\nresearch, enable development and validation of AI algorithms, serve as an\neducational tool for training in otologic imaging, and support\nmulti-institutional collaborative studies. UltraEar will be continuously\nupdated and expanded, ensuring long-term accessibility and usability for the\nglobal otologic research community."}
{"id": "2508.20531", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20531", "abs": "https://arxiv.org/abs/2508.20531", "authors": ["Chaoying Huang", "Wen Chen", "Qingqing Wu", "Xusheng Zhu", "Zhendong Li", "Ying Wang", "Jinhong Yuan"], "title": "Dual-IRS Aided Near-/Hybrid-Field SWIPT: Passive Beamforming and Independent Antenna Power Splitting Design", "comment": null, "summary": "This paper proposes a novel dual-intelligent reflecting surface (IRS) aided\ninterference-limited simultaneous wireless information and power transfer\n(SWIPT) system with independent power splitting (PS), where each receiving\nantenna applies different PS factors to offer an advantageous trade-off between\nthe useful information and harvested energy. We separately establish the near-\nand hybrid-field channel models for IRS-reflected links to evaluate the\nperformance gain more precisely and practically. Specifically, we formulate an\noptimization problem of maximizing the harvested power by jointly optimizing\ndual-IRS phase shifts, independent PS ratio, and receive beamforming vector in\nboth near- and hybrid-field cases. In the near-field case, the alternating\noptimization algorithm is proposed to solve the non-convex problem by applying\nthe Lagrange duality method and the difference-of-convex (DC) programming. In\nthe hybrid-field case, we first present an interesting result that the\nAP-IRS-user channel gains are invariant to the phase shifts of dual-IRS, which\nallows the optimization problem to be transformed into a convex one. Then, we\nderive the asymptotic performance of the combined channel gains in closed-form\nand analyze the characteristics of the dual-IRS. Numerical results validate our\nanalysis and indicate the performance gains of the proposed scheme that\ndual-IRS-aided SWIPT with independent PS over other benchmark schemes."}
{"id": "2508.20455", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20455", "abs": "https://arxiv.org/abs/2508.20455", "authors": ["Zhaole Wang", "Naijin Liu", "Xiao Tang", "Shuai Yuan", "Chenxi Wang", "Zhi Zhai", "Qinghe Du", "Jinxin Liu"], "title": "Secure Satellite Communications via Multiple Aerial RISs: Joint Optimization of Reflection, Association, and Deployment", "comment": "Accepted for publication in IEEE Transactions on Wireless\n  Communications", "summary": "Satellite communication is envisioned as a key enabler of future 6G networks,\nyet its wide coverage with high link attenuation poses significant challenges\nfor physical layer security. In this paper, we investigate secure multi-beam,\nmulti-group satellite communications assisted by aerial reconfigurable\nintelligent surfaces (ARISs). To maximize the sum of achievable multicast rates\namong the groups while constraining wiretap rates, we formulate a joint\noptimization problem involving transmission and reflection beamforming,\nARIS-group association, and ARIS deployment. Due to the mixed-integral and\nnon-convex nature of the formulated problem, we propose to decompose the\nproblem and employ the block coordinate descent framework that iteratively\nsolves the subproblems. Simulation results demonstrate that the proposed\nARIS-assisted multi-beam satellite system provides a notable improvement in\nsecure communication performance under various network scenarios, offering\nuseful insights into the deployment and optimization of intelligent surfaces in\nfuture secure satellite networks."}
{"id": "2508.20250", "categories": ["eess.IV", "cs.CV", "cs.MM", "68T45, 68U10", "I.4.6; I.4.8; H.5.1; I.2.10"], "pdf": "https://arxiv.org/pdf/2508.20250", "abs": "https://arxiv.org/abs/2508.20250", "authors": ["Jessica Kinnevan", "Naifa Alqahtani", "Toral Chauhan"], "title": "Efficient and Privacy-Protecting Background Removal for 2D Video Streaming using iPhone 15 Pro Max LiDAR", "comment": null, "summary": "Light Detection and Ranging (LiDAR) technology in consumer-grade mobile\ndevices can be used as a replacement for traditional background removal and\ncompositing techniques. Unlike approaches such as chroma keying and trained AI\nmodels, LiDAR's depth information is independent of subject lighting, and\nperforms equally well in low-light and well-lit environments. We integrate the\nLiDAR and color cameras on the iPhone 15 Pro Max with GPU-based image\nprocessing. We use Apple's SwiftUI and Swift frameworks for user interface and\nbackend development, and Metal Shader Language (MSL) for realtime image\nenhancement at the standard iPhone streaming frame rate of 60 frames per\nsecond. The only meaningful limitations of the technology are the streaming\nbandwidth of the depth data, which currently reduces the depth map resolution\nto 320x240, and any pre-existing limitations of the LiDAR IR laser to reflect\naccurate depth from some materials. If the LiDAR resolution on a mobile device\nlike the iPhone can be improved to match the color image resolution, LiDAR\ncould feasibly become the preeminent method of background removal for video\napplications and photography."}
{"id": "2508.20535", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20535", "abs": "https://arxiv.org/abs/2508.20535", "authors": ["Annika Stiehl", "Nicolas Weeger", "Christian Uhl", "Dominic Bechtold", "Nicole Ille", "Stefan Geißelsöder"], "title": "Towards Automated EEG-Based Detection Using Deep Convolutional Autoencoders", "comment": "\\c{opyright} 2025 IEEE. Accepted in 47th Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)\n  2025", "summary": "Epilepsy is one of the most common neurological disorders. This disease\nrequires reliable and efficient seizure detection methods.\nElectroencephalography (EEG) is the gold standard for seizure monitoring, but\nits manual analysis is a time-consuming task that requires expert knowledge. In\naddition, there are no well-defined features that allow fully automated\nanalysis. Existing deep learning-based approaches struggle to achieve high\nsensitivity while maintaining a low false alarm rate per hour (FAR/h) and lack\nconsistency in the optimal EEG input representation, whether in the time or\nfrequency domain. To address these issues, we propose a Deep Convolutional\nAutoencoder (DCAE) to extract low-dimensional latent representations that\npreserve essential EEG signal features. The ability of the model to preserve\nrelevant information was evaluated by comparing reconstruction errors based on\nboth time series and frequency-domain representations. Several autoencoders\nwith different loss functions based on time and frequency were trained and\nevaluated to determine their effectiveness in reconstructing EEG features. Our\nresults show that the DCAE model taking both time series and frequency losses\ninto account achieved the best reconstruction performance. This indicates that\nDeep Neural Networks with a single representation might not preserve the\nrelevant signal properties. This work provides insight into how deep learning\nmodels process EEG data and examines whether frequency information is captured\nwhen time series signals are used as input."}
{"id": "2508.20580", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20580", "abs": "https://arxiv.org/abs/2508.20580", "authors": ["Nicolás Alvarez Prado", "Andreas Straßhofer"], "title": "Precoded Polar Product Decoder Based on Soft-Output SCL Decoding and Maximization of Generalized Mutual Information", "comment": "5 pages, presented at ISTC 2025", "summary": "We combine two approaches to optimize the iterative decoding of product codes\nwith precoded polar component codes. On one side, we generate bitwise soft\nmessages based on the codebook probability, an approximation of an auxiliary\nquantity that considers all valid decoding paths of a successive cancellation\nlist (SCL) decoder. On the other side, we scale the soft information during\nmessage passing with offline-computed coefficients, which maximize the\ngeneralized mutual information (GMI) between the channel input and the outgoing\nmessage in each half iteration. Simulation results show significant improvement\nof the error-correcting performance compared to heuristic scaling and soft\ninformation generation based solely on the candidate list of the decoder.\nMoreover, we present an extrinsic version of the SCL decoder, which we use in a\nMonte Carlo density evolution analysis to derive decoding thresholds. The\ncomputed thresholds accurately predict the performance of the decoder."}
{"id": "2508.20600", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.20600", "abs": "https://arxiv.org/abs/2508.20600", "authors": ["Kian Anvari Hamedani", "Narges Razizadeh", "Shahabedin Nabavi", "Mohsen Ebrahimi Moghaddam"], "title": "GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac MRI Reconstruction", "comment": null, "summary": "Accelerated Cardiovascular Magnetic Resonance (CMR) image reconstruction\nremains a critical challenge due to the trade-off between scan time and image\nquality, particularly when generalizing across diverse acquisition settings. We\npropose GENRE-CMR, a generative adversarial network (GAN)-based architecture\nemploying a residual deep unrolled reconstruction framework to enhance\nreconstruction fidelity and generalization. The architecture unrolls iterative\noptimization into a cascade of convolutional subnetworks, enriched with\nresidual connections to enable progressive feature propagation from shallow to\ndeeper stages. To further improve performance, we integrate two loss functions:\n(1) an Edge-Aware Region (EAR) loss, which guides the network to focus on\nstructurally informative regions and helps prevent common reconstruction\nblurriness; and (2) a Statistical Distribution Alignment (SDA) loss, which\nregularizes the feature space across diverse data distributions via a symmetric\nKL divergence formulation. Extensive experiments confirm that GENRE-CMR\nsurpasses state-of-the-art methods on training and unseen data, achieving\n0.9552 SSIM and 38.90 dB PSNR on unseen distributions across various\nacceleration factors and sampling trajectories. Ablation studies confirm the\ncontribution of each proposed component to reconstruction quality and\ngeneralization. Our framework presents a unified and robust solution for\nhigh-quality CMR reconstruction, paving the way for clinically adaptable\ndeployment across heterogeneous acquisition protocols."}
{"id": "2508.20602", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20602", "abs": "https://arxiv.org/abs/2508.20602", "authors": ["Matthieu Correa", "Nicolas Vignais", "Isabelle A. Siegler", "Maxime Projetti"], "title": "Removing motion artifacts from mechanomyographic signals: an innovative filtering method applied to human movement analysis", "comment": null, "summary": "Mechanomyography (MMG) is a promising tool for measuring muscle activity in\nthe field but its sensitivity to motion artifacts limits its application. In\nthis study, we proposed an adaptative filtering method for MMG accelerometers\nbased on the complete ensemble empirical mode decomposition, with adaptative\nnoise and spectral fuzzy entropy, to isolate motions artefacts from the MMG\nsignal in dynamic conditions. We compared our method with the traditional\nband-pass filtering technique, demonstrating better results concerning motion\nrecomposition for deltoid and erector spinae muscles (R${}^2$ = 0.907 and\n0.842). Thus, this innovative method allows the filtering of motion artifacts\ndynamically in the 5-20 Hz bandwidth, which is not achievable with traditional\nmethod. However, the interpretation of accelerometric MMG signals from the\ntrunk and lower-limb muscles during walking or running should be approached\nwith great caution as impact-related accelerations are still present, though\ntheir exact quantity still needs to be quantified."}
{"id": "2508.20684", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20684", "abs": "https://arxiv.org/abs/2508.20684", "authors": ["Liudmila Karakchieva", "Peter Trifonov"], "title": "Polar subcodes for MIMO systems", "comment": "6 pages, 2 figures", "summary": "Polar-coded multiple-input multiple-output systems are investigated. An\nadvanced receiver implementing joint list decoding of polar codes and QR- and\nMMSE-based detectors is proposed. The approximate and exact path metrics are\nderived for joint list decoder of polar codes. A construction of polar subcodes\nfor MIMO systems with cross-antenna dynamic freezing constraints is proposed.\nThe obtained polar subcodes provide significant performance gain compared to\nLDPC-coded MIMO systems with the same rate allocation."}
{"id": "2508.21041", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.21041", "abs": "https://arxiv.org/abs/2508.21041", "authors": ["Guillaume Balezo", "Raphaël Bourgade", "Thomas Walter"], "title": "Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification in MIDOG 2025", "comment": "3 pages. Challenge report for MIDOG 2025 (Task 2: Atypical Mitotic\n  Figure Classification)", "summary": "Atypical mitotic figures (AMFs) are markers of abnormal cell division\nassociated with poor prognosis, yet their detection remains difficult due to\nlow prevalence, subtle morphology, and inter-observer variability. The MIDOG\n2025 challenge introduces a benchmark for AMF classification across multiple\ndomains. In this work, we evaluate the recently published DINOv3-H+ vision\ntransformer, pretrained on natural images, which we fine-tuned using low-rank\nadaptation (LoRA, 650k trainable parameters) and extensive augmentation.\nDespite the domain gap, DINOv3 transfers effectively to histopathology,\nachieving a balanced accuracy of 0.8871 on the preliminary test set. These\nresults highlight the robustness of DINOv3 pretraining and show that, when\ncombined with parameter-efficient fine-tuning, it provides a strong baseline\nfor atypical mitosis classification in MIDOG 2025."}
{"id": "2508.20761", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20761", "abs": "https://arxiv.org/abs/2508.20761", "authors": ["Yaniv Mazor", "Tirza Routtenberg"], "title": "Weighted Bayesian Cram$\\acute{\\text{e}}$r-Rao Bound for Mixed-Resolution Parameter Estimation", "comment": null, "summary": "Mixed-resolution architectures, combining high-resolution (analog) data with\ncoarsely quantized (e.g., 1-bit) data, are widely employed in emerging\ncommunication and radar systems to reduce hardware costs and power consumption.\nHowever, the use of coarsely quantized data introduces non-trivial tradeoffs in\nparameter estimation tasks. In this paper, we investigate the derivation of\nlower bounds for such systems. In particular, we develop the weighted Bayesian\nCramer-Rao bound (WBCRB) for the mixed-resolution setting with a general weight\nfunction. We demonstrate the special cases of: (i) the classical BCRB; (ii) the\nWBCRB that is based on the Bayesian Fisher information matrix (BFIM)-Inverse\nweighting; and (iii) the Aharon-Tabrikian tightest WBCRB with an optimal weight\nfunction. Based on the developed WBCRB, we propose a new method to approximate\nthe mean-squared-error (MSE) by partitioning the estimation problem into two\nregions: (a) where the 1-bit quantized data is informative; and (b) where it is\nsaturated. We apply region-specific WBCRB approximations in these regions to\nachieve an accurate composite MSE estimate. We derive the bounds and MSE\napproximation for the linear Gaussian orthonormal (LGO) model, which is\ncommonly used in practical signal processing applications. Our simulation\nresults demonstrate the use of the proposed bounds and approximation method in\nthe LGO model with a scalar unknown parameter. It is shown that the WBCRB\noutperforms the BCRB, where the BFIM-Inverse weighting version approaches the\noptimal WBCRB. Moreover, it is shown that the WBCRB-based MSE approximation is\ntighter and accurately predicts the non-monotonic behavior of the MSE in the\npresence of quantization errors."}
{"id": "2508.20704", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20704", "abs": "https://arxiv.org/abs/2508.20704", "authors": ["Wei Jiang", "Hans D Schotten"], "title": "Achieving Optimal Performance-Cost Trade-Off in Hierarchical Cell-Free Massive MIMO", "comment": "IEEE Globecom 2025", "summary": "Cell-free (CF) massive MIMO offers uniform service via distributed access\npoints (APs), which impose high deployment costs. A novel design called\nhierarchical cell-free (HCF) addresses this problem by replacing some APs with\na central base station, thereby lowering the costs of fronthaul network\n(wireless sites and fiber cables) while preserving performance. To identify the\noptimal uplink configuration in HCF massive MIMO, this paper provides the first\ncomprehensive analysis, benchmarking it against cellular and CF systems. We\ndevelop a unified analytical framework for spectral efficiency that supports\narbitrary combining schemes and introduce a novel hierarchical combining\napproach tailored to HCF two-tier architecture. Through analysis and evaluation\nof user fairness, system capacity, fronthaul requirements, and computational\ncomplexity, this paper identifies that HCF using centralized zero-forcing\ncombining achieves the optimal balance between performance and cost-efficiency."}
{"id": "2508.20864", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20864", "abs": "https://arxiv.org/abs/2508.20864", "authors": ["Ehsan Sadeghi", "Paul Havinga"], "title": "Breaking Barriers in Health Monitoring: Multi-Scenario Vital Sign Detection Using Mm-Wave MIMO FMCW Radar", "comment": null, "summary": "This paper explores the deployment of mm-wave Frequency Modulated Continuous\nWave (FMCW) radar for vital sign detection across multiple scenarios. We focus\non overcoming the limitations of traditional sensing methods by enhancing\nsignal processing techniques to capture subtle physiological changes\neffectively. Our study introduces novel adaptations of the Prony and MUSIC\nalgorithms tailored for real-time heart and respiration rate monitoring,\nsignificantly advancing the accuracy and reliability of non-contact vital sign\nmonitoring using radar technologies. Notably, these algorithms demonstrate a\nrobust ability to suppress noise and harmonic interference. For instance, the\nmean absolute errors (MAE) for MUSIC and Prony in heart rate detection are 1.8\nand 0.81, respectively, while for respiration rate, the MAEs are 1.01 and 0.8,\nrespectively. These results underscore the potential of FMCW radar as a\nreliable, non-invasive solution for continuous vital sign monitoring in\nhealthcare settings, particularly in clinical and emergency scenarios where\ntraditional contact-based monitoring is impractical."}
{"id": "2508.20708", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20708", "abs": "https://arxiv.org/abs/2508.20708", "authors": ["Wei Jiang", "Hans D. Schotten"], "title": "What is the Most Efficient Technique for Uplink Cell-Free Massive MIMO?", "comment": "IEEE VTC 2025-Fall", "summary": "This paper seeks to determine the most efficient uplink technique for\ncell-free massive MIMO systems. Despite offering great advances, existing works\nsuffer from fragmented methodologies and inconsistent assumptions (e.g.,\nsingle- vs. multi-antenna access points, ideal vs. spatially correlated\nchannels). To address these limitations, we: (1) establish a unified analytical\nframework compatible with centralized/distributed processing and diverse\ncombining schemes; (2) develop a universal optimization strategy for max-min\npower control; and (3) conduct a holistic study among four critical metrics:\nworst-case user spectral efficiency (fairness), system capacity, fronthaul\nsignaling, and computational complexity. Through analyses and evaluation, this\nwork ultimately identifies the optimal uplink technique for practical cell-free\ndeployments."}
{"id": "2508.20990", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.20990", "abs": "https://arxiv.org/abs/2508.20990", "authors": ["Hong-Yan Zhang", "Haoting Liu", "Rui-Jia Lin", "Yu Zhou"], "title": "A Correction for the Paper \"Symplectic geometry mode decomposition and its application to rotating machinery compound fault diagnosis\"", "comment": "13 pages, 4 figures, 2 tables", "summary": "The symplectic geometry mode decomposition (SGMD) is a powerful method for\ndecomposing time series, which is based on the diagonal averaging principle\n(DAP) inherited from the singular spectrum analysis (SSA). Although the authors\nof SGMD method generalized the form of the trajectory matrix in SSA, the DAP is\nnot updated simultaneously. In this work, we pointed out the limitations of the\nSGMD method and fixed the bugs with the pulling back theorem for computing the\ngiven component of time series from the corresponding component of trajectory\nmatrix."}
{"id": "2508.20806", "categories": ["cs.IT", "cs.CE", "cs.SY", "eess.SY", "math.DS", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20806", "abs": "https://arxiv.org/abs/2508.20806", "authors": ["Moriba Jah", "Van Haslett"], "title": "The Epistemic Support-Point Filter (ESPF): A Bounded Possibilistic Framework for Ordinal State Estimation", "comment": null, "summary": "Traditional state estimation methods rely on probabilistic assumptions that\noften collapse epistemic uncertainty into scalar beliefs, risking\noverconfidence in sparse or adversarial sensing environments. We introduce the\nEpistemic Support-Point Filter (ESPF), a novel non-Bayesian filtering framework\nfully grounded in possibility theory and epistemic humility. ESPF redefines the\nevolution of belief over state space using compatibility-weighted support\nupdates, surprisalaware pruning, and adaptive dispersion via sparse grid\nquadrature. Unlike conventional filters, ESPF does not seek a posterior\ndistribution, but rather maintains a structured region of plausibility or\nnon-rejection, updated using ordinal logic rather than integration. For\nmulti-model inference, we employ the Choquet integral to fuse competing\nhypotheses based on a dynamic epistemic capacity function, generalizing\nclassical winner-take-all strategies. The result is an inference engine capable\nof dynamically contracting or expanding belief support in direct response to\ninformation structure, without requiring prior statistical calibration. This\nwork presents a foundational shift in how inference, evidence, and ignorance\nare reconciled, supporting robust estimation where priors are unavailable,\nmisleading, or epistemically unjustified."}
{"id": "2508.20704", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20704", "abs": "https://arxiv.org/abs/2508.20704", "authors": ["Wei Jiang", "Hans D Schotten"], "title": "Achieving Optimal Performance-Cost Trade-Off in Hierarchical Cell-Free Massive MIMO", "comment": "IEEE Globecom 2025", "summary": "Cell-free (CF) massive MIMO offers uniform service via distributed access\npoints (APs), which impose high deployment costs. A novel design called\nhierarchical cell-free (HCF) addresses this problem by replacing some APs with\na central base station, thereby lowering the costs of fronthaul network\n(wireless sites and fiber cables) while preserving performance. To identify the\noptimal uplink configuration in HCF massive MIMO, this paper provides the first\ncomprehensive analysis, benchmarking it against cellular and CF systems. We\ndevelop a unified analytical framework for spectral efficiency that supports\narbitrary combining schemes and introduce a novel hierarchical combining\napproach tailored to HCF two-tier architecture. Through analysis and evaluation\nof user fairness, system capacity, fronthaul requirements, and computational\ncomplexity, this paper identifies that HCF using centralized zero-forcing\ncombining achieves the optimal balance between performance and cost-efficiency."}
{"id": "2508.20940", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20940", "abs": "https://arxiv.org/abs/2508.20940", "authors": ["Giuseppe Del Prete", "Antonio Roccolano", "Ferdinando Zullo"], "title": "On the non-existence of perfect codes in the sum-rank metric", "comment": null, "summary": "We study perfect codes in the sum-rank metric, a generalization of both the\nHamming and rank metrics relevant in multishot network coding and space-time\ncoding. A perfect code attains equality in the sphere-packing bound,\ncorresponding to a partition of the ambient space into disjoint metric balls.\nWhile perfect codes in the Hamming and rank metrics are completely classified,\nthe existence of nontrivial perfect codes in the sum-rank metric remains\nlargely open. In this paper, we investigate linear perfect codes in the\nsum-rank metric. We analyze the geometry of balls and derive bounds on their\nvolumes, showing how the sphere-packing bound applies. For two-block spaces, we\ndetermine explicit parameter constraints for the existence of perfect codes.\nFor multiple-block spaces, we establish non-existence results for various\nranges of minimum distance, divisibility conditions, and code dimensions. We\nfurther provide computational evidence based on congruence conditions imposed\nby the volume of metric balls."}
{"id": "2508.20708", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20708", "abs": "https://arxiv.org/abs/2508.20708", "authors": ["Wei Jiang", "Hans D. Schotten"], "title": "What is the Most Efficient Technique for Uplink Cell-Free Massive MIMO?", "comment": "IEEE VTC 2025-Fall", "summary": "This paper seeks to determine the most efficient uplink technique for\ncell-free massive MIMO systems. Despite offering great advances, existing works\nsuffer from fragmented methodologies and inconsistent assumptions (e.g.,\nsingle- vs. multi-antenna access points, ideal vs. spatially correlated\nchannels). To address these limitations, we: (1) establish a unified analytical\nframework compatible with centralized/distributed processing and diverse\ncombining schemes; (2) develop a universal optimization strategy for max-min\npower control; and (3) conduct a holistic study among four critical metrics:\nworst-case user spectral efficiency (fairness), system capacity, fronthaul\nsignaling, and computational complexity. Through analyses and evaluation, this\nwork ultimately identifies the optimal uplink technique for practical cell-free\ndeployments."}
{"id": "2508.20980", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20980", "abs": "https://arxiv.org/abs/2508.20980", "authors": ["Siyao Li", "Mingzhe Chen", "Shuangyang Li", "Giuseppe Caire"], "title": "On Secrecy Capacity of Binary Beampointing Channels with Block Memory and Feedback", "comment": "7 pages, 2 figures, accepted by 61st Allerton Conference on\n  Communication, Control, and Computing", "summary": "This paper investigates the secrecy capacity of the binary beampointing (BBP)\nchannel with block memory and feedback, a simplified yet insightful model for\nmillimeter-wave (mmWave) systems with beamformed transmissions and backscatter\nfeedback. We consider a system where a legitimate receiver and a passive\neavesdropper experience independent and uniformly distributed angular\ndirections over transmission blocks, with the base station receiving noiseless,\nunit-delayed feedback from both, under the per-symbol input cost constraints.\nWe establish a closed-form upper bound on the secrecy capacity, which is based\non the main channel between the base station and the legitimate receiver.\nMoreover, we propose a joint communication and adaptive sensing (JCAS) scheme\nand derive its achievable secrecy rate. Simulation results show that the gap\nbetween the inner and outer bounds narrows as the number of block length\nincreases. This reveals the efficiency of this JCAS scheme, which strategically\nleverages feedback to balance the demands of sensing the legitimate user and\npreventing information leakage to the eavesdropper."}
{"id": "2508.20997", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.20997", "abs": "https://arxiv.org/abs/2508.20997", "authors": ["Siyao Li", "Shuangyang Li", "Giuseppe Caire"], "title": "On the Sensing Capacity of Gaussian \"Beam-Pointing\" Channels with Block Memory and Feedback", "comment": "6 pages, accepted by 2025 IEEE International Symposium on Information\n  Theory (ISIT 2025)", "summary": "Driven by the demands of high-frequency wireless communications in 5G and 6G\nsystems (e.g., mmWave, sub-THz), we explore a state-dependent {\\em Gaussian\nbeam-pointing} (GBP) channel. In this model, the channel state defines an\nunknown angle of departure (AoD), which remains constant within each coherence\nblock of $Q$ time slots but changes independently across blocks. The\ntransmitter receives strictly causal feedback which may originate from a radar\ndetection system or explicit feedback from the receiver at the end of each slot\nand estimates the AoD at the end of each block. To enhance transmission\nefficiency, we propose a joint communication and sensing scheme. While the\ncommunication capacity of the GBP channel has been previously analyzed by the\nauthors, this work focuses on sensing capacity, characterized by the mutual\ninformation between the channel state and the feedback conditioned on the\ntransmitted signal. We derive an upper bound using dynamic programming and\npropose an achievable inner bound on the sensing capacity, both formulated as\noptimization problems. For the special case of $Q=1$, the proposed transmission\nscheme achieves the optimal sensing rate and highlights the inherent trade-off\nbetween sensing and communication performance."}
