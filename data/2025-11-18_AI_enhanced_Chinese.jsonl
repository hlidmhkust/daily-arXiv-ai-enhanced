{"id": "2511.12108", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.12108", "abs": "https://arxiv.org/abs/2511.12108", "authors": ["Qianfan Wang", "Jifan Liang", "Peihong Yuan", "Ken R. Duffy", "Muriel M\u00e9dard", "Xiao Ma"], "title": "Guessing Decoding of Short Blocklength Codes", "comment": null, "summary": "Future beyond-5G and 6G systems demand ultra-reliable, low-latency communication with short blocklengths, motivating the development of universal decoding algorithms. Guessing decoding, which infers the noise or codeword candidate in order of decreasing (exact or approximate) likelihood, offers a universal framework applicable to short codes. In this paper, we present a unified treatment of two prominent recent families of guessing decoding: guessing random additive noise decoding (GRAND) and guessing codeword decoding (GCD). For each, we (i) present algorithmic implementations and ordering strategies; (ii) prove maximum-likelihood (ML) optimality under appropriate stopping criteria; (iii) derive saddle-point approximations for the average number of queries; and (iv) validate theoretical predictions with simulations. We further analyze the performance degradation due to limited search budgets relative to ML performance, compare key metrics (worst-case and average complexity, hardware considerations), and highlight how advances in one approach transfer naturally to the other. Our results clarify the operating regimes where GRAND and GCD demonstrate superior performance. This work provides both theoretical insights and practical guidelines for deploying universal guessing decoders in next-generation short-blocklength communications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u4e24\u79cd\u4e3b\u8981\u7684\u731c\u6d4b\u89e3\u7801\u65b9\u6cd5\uff08GRAND\u548cGCD\uff09\u8fdb\u884c\u4e86\u7edf\u4e00\u5206\u6790\uff0c\u5305\u62ec\u7b97\u6cd5\u5b9e\u73b0\u3001ML\u6700\u4f18\u6027\u8bc1\u660e\u3001\u590d\u6742\u5ea6\u5206\u6790\u548c\u6027\u80fd\u6bd4\u8f83\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u77ed\u7801\u901a\u4fe1\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u8df5\u5efa\u8bae\u3002", "motivation": "\u672a\u67655G\u548c6G\u7cfb\u7edf\u9700\u8981\u8d85\u53ef\u9760\u3001\u4f4e\u5ef6\u8fdf\u7684\u77ed\u7801\u901a\u4fe1\uff0c\u8fd9\u63a8\u52a8\u4e86\u901a\u7528\u89e3\u7801\u7b97\u6cd5\u7684\u53d1\u5c55\u3002\u731c\u6d4b\u89e3\u7801\u4e3a\u77ed\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u6846\u67b6\u3002", "method": "\u5bf9GRAND\u548cGCD\u4e24\u79cd\u731c\u6d4b\u89e3\u7801\u65b9\u6cd5\u8fdb\u884c\u7edf\u4e00\u5904\u7406\uff0c\u5305\u62ec\u7b97\u6cd5\u5b9e\u73b0\u3001\u6392\u5e8f\u7b56\u7565\u3001ML\u6700\u4f18\u6027\u8bc1\u660e\u3001\u978d\u70b9\u8fd1\u4f3c\u590d\u6742\u5ea6\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u79cd\u65b9\u6cd5\u5728\u9002\u5f53\u505c\u6b62\u51c6\u5219\u4e0b\u7684ML\u6700\u4f18\u6027\uff0c\u5206\u6790\u4e86\u6709\u9650\u641c\u7d22\u9884\u7b97\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u6bd4\u8f83\u4e86\u5173\u952e\u6307\u6807\uff08\u6700\u574f\u60c5\u51b5\u548c\u5e73\u5747\u590d\u6742\u5ea6\u3001\u786c\u4ef6\u8003\u8651\uff09\uff0c\u5e76\u9610\u660e\u4e86\u5404\u81ea\u7684\u4f18\u52bf\u5de5\u4f5c\u533a\u95f4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u4e0b\u4e00\u4ee3\u77ed\u7801\u901a\u4fe1\u4e2d\u90e8\u7f72\u901a\u7528\u731c\u6d4b\u89e3\u7801\u5668\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u8df5\u6307\u5357\uff0c\u5c55\u793a\u4e86GRAND\u548cGCD\u5728\u4e0d\u540c\u5de5\u4f5c\u533a\u95f4\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.12279", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.12279", "abs": "https://arxiv.org/abs/2511.12279", "authors": ["Shubhransh Singhvi", "Saransh Chopra", "K. V. Rashmi"], "title": "Tight Lower Bounds on the Bandwidth Cost of MDS Convertible Codes in the Split Regime", "comment": null, "summary": "Recent advances in erasure coding for distributed storage systems have demonstrated that adapting redundancy to varying disk failure rates can lead to substantial storage savings. Such adaptation requires code conversion, wherein data encoded under an initial $[k^I + r^I, k^I]$ code is transformed into data encoded under a final $[k^F + r^F, k^F]$ code - an operation that can be resource-intensive. Convertible codes are a class of codes designed to facilitate this transformation efficiently while preserving desirable properties such as the MDS property. In this work, we investigate the fundamental limits on the bandwidth cost of conversion (total amount of data transferred between the storage nodes during conversion) for systematic MDS convertible codes. Specifically, we study the subclass of conversions known as the split regime (a single initial codeword is converted into multiple final codewords).\n  In this setting, prior to this work, the best known lower bounds on the bandwidth cost of conversion for all parameters were derived by Maturana and Rashmi under certain uniformity assumptions on the number of symbols downloaded from each node. Further, these bounds were shown to be tight for the parameter regime where $r^F \\geq k^F$ or $r^I \\leq r^F$. In this work, we derive lower bounds on the bandwidth cost of systematic MDS convertible codes for all parameters in the split regime without the uniformity assumption. Moreover, our bounds are tight for the broader parameter regime where $r^F \\geq k^F$ or $r^I \\leq k^F$. Subsequently, our bounds also partially resolve the conjecture proposed by Maturana and Rashmi. We employ a novel information-theoretic framework, which assumes only that the initial and final codes are systematic and does not rely on any linearity assumptions or the aforementioned uniformity assumptions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u4e2d\u53ef\u8f6c\u6362\u7801\u5728\u62c6\u5206\u673a\u5236\u4e0b\u7684\u5e26\u5bbd\u6210\u672c\u57fa\u672c\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u4e0b\u754c\uff0c\u5e76\u5728\u66f4\u5e7f\u6cdb\u7684\u53c2\u6570\u8303\u56f4\u5185\u5b9e\u73b0\u4e86\u7d27\u81f4\u6027\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u4e2d\u64e6\u9664\u7f16\u7801\u7684\u53d1\u5c55\uff0c\u6839\u636e\u78c1\u76d8\u6545\u969c\u7387\u8c03\u6574\u5197\u4f59\u5ea6\u53ef\u4ee5\u663e\u8457\u8282\u7701\u5b58\u50a8\u7a7a\u95f4\u3002\u8fd9\u79cd\u8c03\u6574\u9700\u8981\u4ee3\u7801\u8f6c\u6362\uff0c\u800c\u73b0\u6709\u8f6c\u6362\u65b9\u6cd5\u53ef\u80fd\u8d44\u6e90\u5bc6\u96c6\u3002\u53ef\u8f6c\u6362\u7801\u65e8\u5728\u9ad8\u6548\u5b9e\u73b0\u8fd9\u79cd\u8f6c\u6362\u540c\u65f6\u4fdd\u6301MDS\u5c5e\u6027\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u4ec5\u5047\u8bbe\u521d\u59cb\u548c\u6700\u7ec8\u4ee3\u7801\u662f\u7cfb\u7edf\u6027\u7684\uff0c\u4e0d\u4f9d\u8d56\u7ebf\u6027\u5047\u8bbe\u6216\u5747\u5300\u6027\u5047\u8bbe\u3002\u7814\u7a76\u62c6\u5206\u673a\u5236\u4e0b\u7684\u7cfb\u7edfMDS\u53ef\u8f6c\u6362\u7801\u5e26\u5bbd\u6210\u672c\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86\u62c6\u5206\u673a\u5236\u4e0b\u6240\u6709\u53c2\u6570\u7684\u7cfb\u7edfMDS\u53ef\u8f6c\u6362\u7801\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\uff0c\u8fd9\u4e9b\u4e0b\u754c\u5728\u66f4\u5e7f\u6cdb\u7684\u53c2\u6570\u8303\u56f4\uff08r^F \u2265 k^F \u6216 r^I \u2264 k^F\uff09\u5185\u662f\u7d27\u81f4\u7684\uff0c\u90e8\u5206\u89e3\u51b3\u4e86Maturana\u548cRashmi\u63d0\u51fa\u7684\u731c\u60f3\u3002", "conclusion": "\u63d0\u51fa\u7684\u4fe1\u606f\u8bba\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u5747\u5300\u6027\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u7d27\u81f4\u7684\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u7ed3\u679c\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u53ef\u8f6c\u6362\u7801\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.12430", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.12430", "abs": "https://arxiv.org/abs/2511.12430", "authors": ["Qi Wang", "Xiaoming Chen", "Qiao Qi", "Zhaolin Wang", "Yuanwei Liu"], "title": "Integration of Navigation and Remote Sensing in LEO Satellite Constellations", "comment": "IEEE Transactions on Communications, 2025", "summary": "Low earth orbit (LEO) satellite constellations are becoming a cornerstone of next-generation satellite networks, enabling worldwide high-precision navigation and high-quality remote sensing. This paper proposes a novel dual-function LEO satellite constellation frame structure that effectively integrating navigation and remote sensing. Then, the Cramer-Rao bound (CRB)-based positioning, velocity measurement, and timing (PVT) error and the signal-to-ambiguity-interference-noise ratio (SAINR) are derived as performance metrics for navigation and remote sensing, respectively. Based on it, a joint beamforming design is proposed by minimizing the average weighted PVT error for navigation user equipments (UEs) while ensuring SAINR requirement for remote sensing. Simulation results validate the proposed multi-satellite cooperative beamforming design, demonstrating its effectiveness as an integrated solution for next-generation multi-function LEO satellite constellations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u53cc\u529f\u80fdLEO\u536b\u661f\u661f\u5ea7\u5e27\u7ed3\u6784\uff0c\u6709\u6548\u6574\u5408\u5bfc\u822a\u548c\u9065\u611f\u529f\u80fd\uff0c\u57fa\u4e8eCRB\u63a8\u5bfcPVT\u8bef\u5dee\u548cSAINR\u4f5c\u4e3a\u6027\u80fd\u6307\u6807\uff0c\u5e76\u8bbe\u8ba1\u8054\u5408\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u661f\u5ea7\u6b63\u6210\u4e3a\u4e0b\u4e00\u4ee3\u536b\u661f\u7f51\u7edc\u7684\u6838\u5fc3\uff0c\u9700\u8981\u5b9e\u73b0\u5168\u7403\u9ad8\u7cbe\u5ea6\u5bfc\u822a\u548c\u9ad8\u8d28\u91cf\u9065\u611f\u7684\u591a\u529f\u80fd\u96c6\u6210\u3002", "method": "\u63d0\u51fa\u53cc\u529f\u80fdLEO\u536b\u661f\u661f\u5ea7\u5e27\u7ed3\u6784\uff0c\u63a8\u5bfc\u57fa\u4e8eCRB\u7684PVT\u8bef\u5dee\u548cSAINR\u6027\u80fd\u6307\u6807\uff0c\u8bbe\u8ba1\u6700\u5c0f\u5316\u5bfc\u822a\u7528\u6237\u5e73\u5747\u52a0\u6743PVT\u8bef\u5dee\u540c\u65f6\u4fdd\u8bc1\u9065\u611fSAINR\u8981\u6c42\u7684\u8054\u5408\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u591a\u536b\u661f\u534f\u4f5c\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u591a\u529f\u80fdLEO\u536b\u661f\u661f\u5ea7\u96c6\u6210\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e0b\u4e00\u4ee3\u591a\u529f\u80fdLEO\u536b\u661f\u661f\u5ea7\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u96c6\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u5bfc\u822a\u548c\u9065\u611f\u529f\u80fd\u7684\u534f\u540c\u4f18\u5316\u3002"}}
{"id": "2511.12469", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.12469", "abs": "https://arxiv.org/abs/2511.12469", "authors": ["Xuehui Dong", "Miyu Feng", "Chen Shao", "Bokai Lai", "Jianan Zhang", "Rujing Xiong", "Kai Wan", "Tiebin Mi", "Robert Caiming Qiu"], "title": "Metasurface-Enabled Superheterodyne Transmitter With Decoupled Harmonic-Free Signal Generation and Precoding", "comment": null, "summary": "The evolution of programmable metasurfaces (PM) from passive beamforming to active information transmission marks a paradigm shift for next-generation wireless systems. However, this transition is hindered by fundamental limitations in conventional metasurface transmitter architectures, including restricted modulation orders, symbol-level spatial inconsistency, and significant harmonic interference. These issues stem from the intrinsic coupling between baseband signal processing and radio-frequency beamforming in monolithic designs reliant on simplistic switching mechanisms. This paper proposes a novel metasurface-enabled superheterodyne architecture (MSA) that fundamentally decouples these functionalities. The MSA introduces a dual-stage up-conversion process, comprising a digital up-conversion module for in-phase/quadrature modulation and baseband-to-intermediate frequency conversion, a precoder module for precoding, and a custom-designed magnitude-phase-decoupled metasurface that acts as a reconfigurable reflective mixer array. This decoupling of harmonic-free waveform generation from spatial precoding overcomes the critical drawbacks of existing approaches. Experimental results from a 5.8 GHz proof-of-concept prototype system validate the MSA's superior performance. The system generates spatially isotropic constellations for arbitrary-order QAM modulations, ensures consistent time-frequency signatures for applications like Doppler-spoofing, and achieves data rates up to 20 Mbps within a linear operating region that minimizes nonlinear distortion. The capability of employing spatial diversity and multi-stream interference cancellation has been demonstrated for the first time in a PM-based transmitter.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8d85\u5916\u5dee\u67b6\u6784\u7684\u53ef\u7f16\u7a0b\u8d85\u8868\u9762\u53d1\u5c04\u673a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u67b6\u6784\u4e2d\u8c03\u5236\u9636\u6570\u53d7\u9650\u3001\u7a7a\u95f4\u4e0d\u4e00\u81f4\u548c\u8c10\u6ce2\u5e72\u6270\u7b49\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8c10\u6ce2\u81ea\u7531\u6ce2\u5f62\u751f\u6210\u4e0e\u7a7a\u95f4\u9884\u7f16\u7801\u7684\u89e3\u8026\u3002", "motivation": "\u4f20\u7edf\u53ef\u7f16\u7a0b\u8d85\u8868\u9762\u53d1\u5c04\u673a\u67b6\u6784\u5b58\u5728\u57fa\u672c\u9650\u5236\uff1a\u8c03\u5236\u9636\u6570\u53d7\u9650\u3001\u7b26\u53f7\u7ea7\u7a7a\u95f4\u4e0d\u4e00\u81f4\u6027\u548c\u663e\u8457\u8c10\u6ce2\u5e72\u6270\uff0c\u8fd9\u4e9b\u95ee\u9898\u6e90\u4e8e\u57fa\u5e26\u4fe1\u53f7\u5904\u7406\u4e0e\u5c04\u9891\u6ce2\u675f\u6210\u5f62\u7684\u5185\u5728\u8026\u5408\u3002", "method": "\u91c7\u7528\u8d85\u5916\u5dee\u67b6\u6784\uff0c\u5305\u542b\u6570\u5b57\u4e0a\u53d8\u9891\u6a21\u5757\u8fdb\u884cI/Q\u8c03\u5236\u548c\u57fa\u5e26\u5230\u4e2d\u9891\u8f6c\u6362\u3001\u9884\u7f16\u7801\u6a21\u5757\u4ee5\u53ca\u5b9a\u5236\u7684\u5e45\u5ea6-\u76f8\u4f4d\u89e3\u8026\u8d85\u8868\u9762\u4f5c\u4e3a\u53ef\u91cd\u6784\u53cd\u5c04\u6df7\u9891\u5668\u9635\u5217\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\uff1a\u751f\u6210\u4efb\u610f\u9636QAM\u8c03\u5236\u7684\u7a7a\u95f4\u5404\u5411\u540c\u6027\u661f\u5ea7\u56fe\uff0c\u786e\u4fdd\u591a\u666e\u52d2\u6b3a\u9a97\u7b49\u5e94\u7528\u7684\u4e00\u81f4\u65f6\u9891\u7279\u5f81\uff0c\u5728\u7ebf\u6027\u5de5\u4f5c\u533a\u57df\u5185\u5b9e\u73b0\u9ad8\u8fbe20 Mbps\u7684\u6570\u636e\u901f\u7387\uff0c\u5e76\u9996\u6b21\u5728PM\u53d1\u5c04\u673a\u4e2d\u5c55\u793a\u4e86\u7a7a\u95f4\u591a\u6837\u6027\u548c\u591a\u6d41\u5e72\u6270\u6d88\u9664\u80fd\u529b\u3002", "conclusion": "MSA\u67b6\u6784\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7f3a\u70b9\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u53ef\u7f16\u7a0b\u8d85\u8868\u9762\u53d1\u5c04\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.11644", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.11644", "abs": "https://arxiv.org/abs/2511.11644", "authors": ["Jiantang Huang"], "title": "Slow - Motion Video Synthesis for Basketball Using Frame Interpolation", "comment": "3 pages, 4 figures", "summary": "Basketball broadcast footage is traditionally captured at 30-60 fps, limiting viewers' ability to appreciate rapid plays such as dunks and crossovers. We present a real-time slow-motion synthesis system that produces high-quality basketball-specific interpolated frames by fine-tuning the recent Real-Time Intermediate Flow Estimation (RIFE) network on the SportsSloMo dataset. Our pipeline isolates the basketball subset of SportsSloMo, extracts training triplets, and fine-tunes RIFE with human-aware random cropping. We compare the resulting model against Super SloMo and the baseline RIFE model using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity (SSIM) on held-out clips. The fine-tuned RIFE attains a mean PSNR of 34.3 dB and SSIM of 0.949, outperforming Super SloMo by 2.1 dB and the baseline RIFE by 1.3 dB. A lightweight Gradio interface demonstrates end-to-end 4x slow-motion generation on a single RTX 4070 Ti Super at approximately 30 fps. These results indicate that task-specific adaptation is crucial for sports slow-motion, and that RIFE provides an attractive accuracy-speed trade-off for consumer applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b9e\u65f6\u6162\u52a8\u4f5c\u5408\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03RIFE\u7f51\u7edc\u5728\u7bee\u7403\u89c6\u9891\u4e0a\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u76844\u500d\u6162\u52a8\u4f5c\u751f\u6210\uff0c\u5728PSNR\u548cSSIM\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7bee\u7403\u8f6c\u64ad\u5e27\u7387\u6709\u9650\uff0830-60fps\uff09\uff0c\u65e0\u6cd5\u5145\u5206\u5c55\u793a\u5feb\u901f\u52a8\u4f5c\u5982\u6263\u7bee\u548c\u53d8\u5411\uff0c\u9700\u8981\u66f4\u597d\u7684\u6162\u52a8\u4f5c\u5408\u6210\u6280\u672f\u3002", "method": "\u5728SportsSloMo\u6570\u636e\u96c6\u7684\u7bee\u7403\u5b50\u96c6\u4e0a\u5fae\u8c03RIFE\u7f51\u7edc\uff0c\u91c7\u7528\u4eba\u7c7b\u611f\u77e5\u7684\u968f\u673a\u88c1\u526a\u7b56\u7565\uff0c\u6784\u5efa\u7aef\u5230\u7aef\u7684\u6162\u52a8\u4f5c\u751f\u6210\u7cfb\u7edf\u3002", "result": "\u5fae\u8c03\u540e\u7684RIFE\u6a21\u578b\u8fbe\u5230\u5e73\u5747PSNR 34.3 dB\u548cSSIM 0.949\uff0c\u5206\u522b\u6bd4Super SloMo\u9ad82.1 dB\uff0c\u6bd4\u57fa\u7ebfRIFE\u9ad81.3 dB\uff0c\u5728RTX 4070 Ti Super\u4e0a\u5b9e\u73b0\u7ea630 fps\u7684\u5b9e\u65f6\u5904\u7406\u3002", "conclusion": "\u4efb\u52a1\u7279\u5b9a\u7684\u9002\u5e94\u5bf9\u4f53\u80b2\u6162\u52a8\u4f5c\u81f3\u5173\u91cd\u8981\uff0cRIFE\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e4b\u95f4\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6743\u8861\uff0c\u9002\u5408\u6d88\u8d39\u7ea7\u5e94\u7528\u3002"}}
{"id": "2511.11844", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.11844", "abs": "https://arxiv.org/abs/2511.11844", "authors": ["Olaoluwa A. Adegboye", "Kufre M. Udofia", "Akaninyene Obot"], "title": "Inverted C-Shaped Slots Loaded Exponential Tapered Triple Band Notched Ultra Wideband (UWB) Antenna", "comment": null, "summary": "This research presents a simple strategy for designing an exponentially tapered, triple-notched ultrawideband antenna. The antenna's microstrip line feed and radiating patch are matched using an exponential tapered transformer. This method inserts antenna notch elements, by cutting two inverted C-shaped slots in the radiating patch; frequency rejection can be achieved for WI-MAX and wireless LAN. The X-band is rejected by etching a U-shaped slot in the feedline. When embedding the notch elements, cross-coupling was minimized. The desired antenna was designed, simulated, and measured. The measured results and graphs show that our proposed design is reliable. This band notched antenna rejects 3.5 GHz (Wi-MAX band, 3.3 to 3.7 GHz), 5.5 GHz (WLAN 2 band, 5.15 to 5.825 GHz), and 7.5 GHz (for satellite downlink X - band-7.25 GHz to 7.75 GHz). The proposed antenna meets UWB design requirements.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6307\u6570\u9525\u5f62\u4e09\u9677\u6ce2\u8d85\u5bbd\u5e26\u5929\u7ebf\u8bbe\u8ba1\u7b56\u7565\uff0c\u901a\u8fc7\u5728\u8f90\u5c04\u8d34\u7247\u4e0a\u5207\u5272\u4e24\u4e2a\u5012C\u5f62\u69fd\u548c\u5728\u9988\u7ebf\u4e0a\u8680\u523bU\u5f62\u69fd\uff0c\u5b9e\u73b0\u5bf9Wi-MAX\u3001WLAN\u548cX\u6ce2\u6bb5\u4e09\u4e2a\u9891\u6bb5\u7684\u9891\u7387\u6291\u5236\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u6291\u5236\u7279\u5b9a\u5e72\u6270\u9891\u6bb5\u7684\u8d85\u5bbd\u5e26\u5929\u7ebf\uff0c\u89e3\u51b3Wi-MAX\u3001WLAN\u548cX\u6ce2\u6bb5\u7b49\u9891\u6bb5\u5bf9\u8d85\u5bbd\u5e26\u7cfb\u7edf\u7684\u5e72\u6270\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6307\u6570\u9525\u5f62\u53d8\u6362\u5668\u5339\u914d\u5fae\u5e26\u7ebf\u9988\u7535\u548c\u8f90\u5c04\u8d34\u7247\uff0c\u5728\u8f90\u5c04\u8d34\u7247\u4e0a\u5207\u5272\u4e24\u4e2a\u5012C\u5f62\u69fd\u6291\u5236Wi-MAX\u548cWLAN\u9891\u6bb5\uff0c\u5728\u9988\u7ebf\u4e0a\u8680\u523bU\u5f62\u69fd\u6291\u5236X\u6ce2\u6bb5\uff0c\u5e76\u6700\u5c0f\u5316\u4ea4\u53c9\u8026\u5408\u6548\u5e94\u3002", "result": "\u5929\u7ebf\u6210\u529f\u6291\u5236\u4e863.5GHz(Wi-MAX)\u30015.5GHz(WLAN)\u548c7.5GHz(X\u6ce2\u6bb5)\u4e09\u4e2a\u9891\u6bb5\uff0c\u6d4b\u91cf\u7ed3\u679c\u548c\u56fe\u8868\u663e\u793a\u8bbe\u8ba1\u53ef\u9760\uff0c\u6ee1\u8db3\u8d85\u5bbd\u5e26\u8bbe\u8ba1\u8981\u6c42\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6307\u6570\u9525\u5f62\u4e09\u9677\u6ce2\u8d85\u5bbd\u5e26\u5929\u7ebf\u8bbe\u8ba1\u7b56\u7565\u6709\u6548\u53ef\u884c\uff0c\u80fd\u591f\u540c\u65f6\u6291\u5236\u591a\u4e2a\u5e72\u6270\u9891\u6bb5\uff0c\u4e3a\u8d85\u5bbd\u5e26\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6297\u5e72\u6270\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12718", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.12718", "abs": "https://arxiv.org/abs/2511.12718", "authors": ["Yaniv Fogel", "Meir Feder"], "title": "Leave-One-Out Learning with Log-Loss", "comment": null, "summary": "We study batch learning with log-loss in the individual setting, where the outcome sequence is deterministic. Because empirical statistics are not directly applicable in this regime, obtaining regret guarantees for batch learning has long posed a fundamental challenge. We propose a natural criterion based on leave-one-out regret and analyze its minimax value for several hypothesis classes. For the multinomial simplex over $m$ symbols, we show that the minimax regret is $\\frac{m-1}{N} + o\\!\\left(\\frac{1}{N}\\right)$, and compare it to the stochastic realizable case where it is $\\frac{m-1}{2N} + o\\!\\left(\\frac{1}{N}\\right)$. More generally, we prove that every hypothesis class of VC dimension $d$ is learnable in the individual batch-learning problem, with regret at most $\\frac{d\\log(N)}{N} + o\\!\\left(\\frac{\\log(N)}{N}\\right)$, and we establish matching lower bounds for certain classes. We further derive additional upper bounds that depend on structural properties of the hypothesis class. These results establish, for the first time, that universal batch learning with log-loss is possible in the individual setting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4e2a\u4f53\u786e\u5b9a\u6027\u8bbe\u7f6e\u4e0b\u7684\u6279\u91cf\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7559\u4e00\u6cd5\u9057\u61be\u7684\u81ea\u7136\u51c6\u5219\uff0c\u5e76\u5206\u6790\u4e86\u591a\u4e2a\u5047\u8bbe\u7c7b\u7684\u6700\u5c0f\u6700\u5927\u9057\u61be\u503c\u3002", "motivation": "\u5728\u4e2a\u4f53\u8bbe\u7f6e\u4e2d\uff0c\u7531\u4e8e\u7ed3\u679c\u5e8f\u5217\u662f\u786e\u5b9a\u6027\u7684\uff0c\u7ecf\u9a8c\u7edf\u8ba1\u91cf\u4e0d\u76f4\u63a5\u9002\u7528\uff0c\u56e0\u6b64\u6279\u91cf\u5b66\u4e60\u7684\u9057\u61be\u4fdd\u8bc1\u4e00\u76f4\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u7559\u4e00\u6cd5\u9057\u61be\u7684\u51c6\u5219\uff0c\u5206\u6790\u4e86\u591a\u7c7b\u5047\u8bbe\u7c7b\u7684\u6700\u5c0f\u6700\u5927\u9057\u61be\u503c\uff0c\u5305\u62ec\u591a\u9879\u5355\u7eaf\u5f62\u548cVC\u7ef4\u5047\u8bbe\u7c7b\u3002", "result": "\u5bf9\u4e8em\u4e2a\u7b26\u53f7\u7684\u591a\u9879\u5355\u7eaf\u5f62\uff0c\u6700\u5c0f\u6700\u5927\u9057\u61be\u4e3a(m-1)/N + o(1/N)\uff1b\u5bf9\u4e8eVC\u7ef4\u4e3ad\u7684\u5047\u8bbe\u7c7b\uff0c\u9057\u61be\u4e0a\u754c\u4e3ad log(N)/N + o(log(N)/N)\uff0c\u5e76\u5efa\u7acb\u4e86\u5339\u914d\u4e0b\u754c\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u9996\u6b21\u8bc1\u660e\u5728\u4e2a\u4f53\u8bbe\u7f6e\u4e0b\uff0c\u4f7f\u7528\u5bf9\u6570\u635f\u5931\u7684\u901a\u7528\u6279\u91cf\u5b66\u4e60\u662f\u53ef\u80fd\u7684\u3002"}}
{"id": "2511.11766", "categories": ["eess.IV", "cs.MM", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.11766", "abs": "https://arxiv.org/abs/2511.11766", "authors": ["V. Asiryan", "V. Volchkov", "N. Papulovskaya"], "title": "Weyl-Heisenberg Transform Capabilities in JPEG Compression Standard", "comment": null, "summary": "This paper is devoted to the development and research of a new compression technology based on Weyl-Heisenberg bases (WH-technology) for modifying the JPEG compression standard and improving its characteristics. For this purpose, the paper analyzes the main stages of the JPEG compression algorithm, notes its key features and problems that limit further enhancement of its efficiency. To overcome these limitations, it is proposed to use the real version of the two-dimensional discrete orthogonal Weyl-Heisenberg transform (DWHT) instead of the discrete cosine transform (DCT) at the stage of transformation coding. This transformation, unlike DCT, initially has a block structure and is built on the basis of the Weyl-Heisenberg optimal signal basis, the functions of which are orthogonal and well localized both in the frequency and time domains. This feature of DWHT allows for more efficient decorrelation and compression of element values in each block of the image after transformation coding. As a result, it is possible to obtain more efficient selection and screening of insignificant elements at the subsequent stages of quantization and information coding. Based on DWHT, a new version of the JPEG compression algorithm was developed, and convenient criteria for evaluating the compression efficiency and metrics of quality losses were proposed. The results of an experimental study are presented, confirming the higher compression efficiency of the proposed algorithm in comparison with the JPEG compression standard.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eWeyl-Heisenberg\u57fa\u7684\u65b0\u538b\u7f29\u6280\u672f\u6765\u6539\u8fdbJPEG\u6807\u51c6\uff0c\u7528\u4e8c\u7ef4\u79bb\u6563\u6b63\u4ea4Weyl-Heisenberg\u53d8\u6362(DWHT)\u66ff\u4ee3DCT\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u56fe\u50cf\u538b\u7f29\u3002", "motivation": "JPEG\u538b\u7f29\u7b97\u6cd5\u5b58\u5728\u6548\u7387\u63d0\u5347\u7684\u9650\u5236\uff0c\u9700\u8981\u514b\u670dDCT\u5728\u53d8\u6362\u7f16\u7801\u9636\u6bb5\u7684\u5c40\u9650\u6027\u3002", "method": "\u5728\u53d8\u6362\u7f16\u7801\u9636\u6bb5\u4f7f\u7528\u4e8c\u7ef4\u79bb\u6563\u6b63\u4ea4Weyl-Heisenberg\u53d8\u6362(DWHT)\u66ff\u4ee3\u79bb\u6563\u4f59\u5f26\u53d8\u6362(DCT)\uff0c\u5229\u7528\u5176\u5757\u7ed3\u6784\u548c\u65f6\u9891\u57df\u826f\u597d\u5c40\u90e8\u5316\u7684\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u7814\u7a76\u8bc1\u5b9e\u63d0\u51fa\u7684\u7b97\u6cd5\u6bd4JPEG\u6807\u51c6\u5177\u6709\u66f4\u9ad8\u7684\u538b\u7f29\u6548\u7387\u3002", "conclusion": "\u57fa\u4e8eDWHT\u7684JPEG\u6539\u8fdb\u7b97\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u8fdb\u884c\u53bb\u76f8\u5173\u548c\u538b\u7f29\uff0c\u5728\u91cf\u5316\u7f16\u7801\u9636\u6bb5\u80fd\u66f4\u9ad8\u6548\u5730\u7b5b\u9009\u4e0d\u663e\u8457\u5143\u7d20\u3002"}}
{"id": "2511.11947", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11947", "abs": "https://arxiv.org/abs/2511.11947", "authors": ["Tri Nhu Do"], "title": "AI-Open-RAN for Non-Terrestrial Networks", "comment": null, "summary": "In this paper, we propose the concept of AIO-RAN-NTN, a unified all-in-one Radio Access Network (RAN) for Non-Terrestrial Networks (NTNs), built on an open architecture that leverages open interfaces and artificial intelligence (AI)-based functionalities. This approach advances interoperability, flexibility, and intelligence in next-generation telecommunications. First, we provide a concise overview of the state-of-the-art architectures for Open-RAN and AI-RAN, highlighting key network functions and infrastructure elements. Next, we introduce our integrated AIO-RAN-NTN blueprint, emphasizing how internal and air interfaces from AIO-RAN and the 3rd Generation Partnership Project (3GPP) can be applied to emerging environments such as NTNs. To examine the impact of mobility on AIO-RAN, we implement a testbed transmission using the OpenAirInterface platform for a standalone (SA) New Radio (NR) 5G system. We then train an AI model on realistic data to forecast key performance indicators (KPIs). Our experiments demonstrate that the AIO-based SA architecture is sensitive to mobility, even at low speeds, but this limitation can be mitigated through AI-driven KPI forecasting.", "AI": {"tldr": "\u63d0\u51fa\u4e86AIO-RAN-NTN\u6982\u5ff5\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f00\u653e\u67b6\u6784\u548c\u4eba\u5de5\u667a\u80fd\u7684\u7edf\u4e00\u975e\u5730\u9762\u7f51\u7edc\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\uff0c\u901a\u8fc7AI\u9a71\u52a8\u7684KPI\u9884\u6d4b\u6765\u7f13\u89e3\u79fb\u52a8\u6027\u5f71\u54cd\u3002", "motivation": "\u63a8\u52a8\u4e0b\u4e00\u4ee3\u7535\u4fe1\u7f51\u7edc\u7684\u4e92\u64cd\u4f5c\u6027\u3001\u7075\u6d3b\u6027\u548c\u667a\u80fd\u5316\uff0c\u7279\u522b\u662f\u5728\u975e\u5730\u9762\u7f51\u7edc\u73af\u5883\u4e2d\u3002", "method": "\u5f00\u53d1\u4e86\u96c6\u6210AIO-RAN-NTN\u84dd\u56fe\uff0c\u4f7f\u7528OpenAirInterface\u5e73\u53f0\u5b9e\u73b05G\u72ec\u7acb\u7ec4\u7f51\u7cfb\u7edf\u6d4b\u8bd5\u5e8a\uff0c\u5e76\u8bad\u7ec3AI\u6a21\u578b\u9884\u6d4b\u5173\u952e\u6027\u80fd\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8eAIO\u7684\u72ec\u7acb\u67b6\u6784\u5bf9\u79fb\u52a8\u6027\u654f\u611f\uff0c\u5373\u4f7f\u4f4e\u901f\u79fb\u52a8\u4e5f\u4f1a\u53d7\u5f71\u54cd\uff0c\u4f46\u901a\u8fc7AI\u9a71\u52a8\u7684KPI\u9884\u6d4b\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u9650\u5236\u3002", "conclusion": "AIO-RAN-NTN\u67b6\u6784\u80fd\u591f\u6709\u6548\u63d0\u5347\u975e\u5730\u9762\u7f51\u7edc\u7684\u6027\u80fd\uff0cAI\u6280\u672f\u662f\u89e3\u51b3\u79fb\u52a8\u6027\u95ee\u9898\u7684\u5173\u952e\u624b\u6bb5\u3002"}}
{"id": "2511.12803", "categories": ["cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.12803", "abs": "https://arxiv.org/abs/2511.12803", "authors": ["Yu-Han Huang", "Venugopal V. Veeravalli"], "title": "Finite-Horizon Quickest Change Detection Balancing Latency with False Alarm Probability", "comment": "27 pages, 1 figure, submitted to Sequential Analysis", "summary": "A finite-horizon variant of the quickest change detection (QCD) problem that is of relevance to learning in non-stationary environments is studied. The metric characterizing false alarms is the probability of a false alarm occurring before the horizon ends. The metric that characterizes the delay is \\emph{latency}, which is the smallest value such that the probability that detection delay exceeds this value is upper bounded to a predetermined latency level. The objective is to minimize the latency (at a given latency level), while maintaining a low false alarm probability. Under the pre-specified latency and false alarm levels, a universal lower bound on the latency, which any change detection procedure needs to satisfy, is derived. Change detectors are then developed, which are order-optimal in terms of the horizon. The case where the pre- and post-change distributions are known is considered first, and then the results are generalized to the non-parametric case when they are unknown except that they are sub-Gaussian with different means. Simulations are provided to validate the theoretical results.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u7684\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\uff0c\u9488\u5bf9\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u5e94\u7528\u3002\u5728\u7ed9\u5b9a\u8bef\u62a5\u6982\u7387\u548c\u5ef6\u8fdf\u6c34\u5e73\u7ea6\u675f\u4e0b\uff0c\u63a8\u5bfc\u4e86\u5ef6\u8fdf\u7684\u901a\u7528\u4e0b\u754c\uff0c\u5e76\u5f00\u53d1\u4e86\u5728\u65f6\u95f4\u8303\u56f4\u4e0a\u8fbe\u5230\u9636\u6570\u6700\u4f18\u7684\u68c0\u6d4b\u5668\u3002", "motivation": "\u7814\u7a76\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u7684\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b66\u4e60\u7b97\u6cd5\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u9700\u8981\u5728\u6709\u9650\u65f6\u95f4\u5185\u5feb\u901f\u51c6\u786e\u5730\u68c0\u6d4b\u5206\u5e03\u53d8\u5316\u3002", "method": "\u9996\u5148\u8003\u8651\u5df2\u77e5\u53d8\u5316\u524d\u540e\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u7136\u540e\u63a8\u5e7f\u5230\u975e\u53c2\u6570\u60c5\u51b5\uff08\u4ec5\u77e5\u5206\u5e03\u4e3a\u4e9a\u9ad8\u65af\u4e14\u5747\u503c\u4e0d\u540c\uff09\u3002\u63a8\u5bfc\u4e86\u5ef6\u8fdf\u7684\u901a\u7528\u4e0b\u754c\uff0c\u5e76\u5f00\u53d1\u4e86\u5728\u65f6\u95f4\u8303\u56f4\u4e0a\u9636\u6570\u6700\u4f18\u7684\u68c0\u6d4b\u5668\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u6240\u63d0\u51fa\u7684\u68c0\u6d4b\u5668\u5728\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u8fbe\u5230\u9636\u6570\u6700\u4f18\u6027\u80fd\uff0c\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u7684\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u68c0\u6d4b\u5668\uff0c\u5728\u7ed9\u5b9a\u8bef\u62a5\u548c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u5e94\u7528\u3002"}}
{"id": "2511.11937", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11937", "abs": "https://arxiv.org/abs/2511.11937", "authors": ["Omar Abdelrazik", "Mohamed Elsayed", "Noorul Wahab", "Nasir Rajpoot", "Adam Shephard"], "title": "A Deep Learning Framework for Thyroid Nodule Segmentation and Malignancy Classification from Ultrasound Images", "comment": "5 pages, 2 figures, 2 tables", "summary": "Ultrasound-based risk stratification of thyroid nodules is a critical clinical task, but it suffers from high inter-observer variability. While many deep learning (DL) models function as \"black boxes,\" we propose a fully automated, two-stage framework for interpretable malignancy prediction. Our method achieves interpretability by forcing the model to focus only on clinically relevant regions. First, a TransUNet model automatically segments the thyroid nodule. The resulting mask is then used to create a region of interest around the nodule, and this localised image is fed directly into a ResNet-18 classifier. We evaluated our framework using 5-fold cross-validation on a clinical dataset of 349 images, where it achieved a high F1-score of 0.852 for predicting malignancy. To validate its performance, we compared it against a strong baseline using a Random Forest classifier with hand-crafted morphological features, which achieved an F1-score of 0.829. The superior performance of our DL framework suggests that the implicit visual features learned from the localised nodule are more predictive than explicit shape features alone. This is the first fully automated end-to-end pipeline for both detecting thyroid nodules on ultrasound images and predicting their malignancy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u7532\u72b6\u817a\u7ed3\u8282\u8d85\u58f0\u56fe\u50cf\u7684\u53ef\u89e3\u91ca\u6076\u6027\u9884\u6d4b\uff0c\u901a\u8fc7\u5f3a\u5236\u6a21\u578b\u4ec5\u5173\u6ce8\u4e34\u5e8a\u76f8\u5173\u533a\u57df\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7532\u72b6\u817a\u7ed3\u8282\u8d85\u58f0\u98ce\u9669\u5206\u5c42\u5b58\u5728\u9ad8\u89c2\u5bdf\u8005\u95f4\u53d8\u5f02\u6027\uff0c\u800c\u8bb8\u591a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u662f\"\u9ed1\u7bb1\"\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528TransUNet\u81ea\u52a8\u5206\u5272\u7532\u72b6\u817a\u7ed3\u8282\uff0c\u7136\u540e\u7528\u5206\u5272\u63a9\u7801\u521b\u5efa\u611f\u5174\u8da3\u533a\u57df\uff0c\u5c06\u5c40\u90e8\u5316\u56fe\u50cf\u8f93\u5165ResNet-18\u5206\u7c7b\u5668\u8fdb\u884c\u6076\u6027\u9884\u6d4b\u3002", "result": "\u5728349\u5f20\u4e34\u5e8a\u56fe\u50cf\u4e0a\u901a\u8fc75\u6298\u4ea4\u53c9\u9a8c\u8bc1\u83b7\u5f970.852\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u4f7f\u7528\u624b\u5de5\u5f62\u6001\u7279\u5f81\u7684\u968f\u673a\u68ee\u6797\u57fa\u7ebf\uff08F1=0.829\uff09\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u65e2\u80fd\u68c0\u6d4b\u7532\u72b6\u817a\u7ed3\u8282\u53c8\u80fd\u9884\u6d4b\u6076\u6027\uff0c\u5b66\u4e60\u5230\u7684\u9690\u5f0f\u89c6\u89c9\u7279\u5f81\u6bd4\u663e\u5f0f\u5f62\u72b6\u7279\u5f81\u66f4\u5177\u9884\u6d4b\u6027\u3002"}}
{"id": "2511.11951", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11951", "abs": "https://arxiv.org/abs/2511.11951", "authors": ["Nghia Thinh Nguyen", "Tri Nhu Do"], "title": "Temporal Micro-Doppler Spectrogram-based ViT Multiclass Target Classification", "comment": null, "summary": "In this paper, we propose a new Temporal MDS-Vision Transformer (T-MDS-ViT) for multiclass target classification using millimeter-wave FMCW radar micro-Doppler spectrograms. Specifically, we design a transformer-based architecture that processes stacked range-velocity-angle (RVA) spatiotemporal tensors via patch embeddings and cross-axis attention mechanisms to explicitly model the sequential nature of MDS data across multiple frames. The T-MDS-ViT exploits mobility-aware constraints in its attention layer correspondences to maintain separability under target overlaps and partial occlusions. Next, we apply an explainable mechanism to examine how the attention layers focus on characteristic high-energy regions of the MDS representations and their effect on class-specific kinematic features. We also demonstrate that our proposed framework is superior to existing CNN-based methods in terms of classification accuracy while achieving better data efficiency and real-time deployability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684T-MDS-ViT\u6a21\u578b\uff0c\u7528\u4e8e\u6beb\u7c73\u6ce2FMCW\u96f7\u8fbe\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u7684\u591a\u76ee\u6807\u5206\u7c7b\uff0c\u901a\u8fc7\u8de8\u8f74\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u65f6\u7a7a\u5f20\u91cf\uff0c\u5728\u5206\u7c7b\u51c6\u786e\u7387\u548c\u5b9e\u65f6\u90e8\u7f72\u65b9\u9762\u4f18\u4e8e\u73b0\u6709CNN\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\u5728\u5904\u7406\u96f7\u8fbe\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u663e\u5f0f\u5efa\u6a21MDS\u6570\u636e\u65f6\u5e8f\u7279\u6027\u5e76\u5904\u7406\u76ee\u6807\u91cd\u53e0\u548c\u90e8\u5206\u906e\u6321\u7684\u67b6\u6784\u3002", "method": "\u8bbe\u8ba1Transformer\u67b6\u6784\u5904\u7406\u5806\u53e0\u7684RVA\u65f6\u7a7a\u5f20\u91cf\uff0c\u4f7f\u7528\u8865\u4e01\u5d4c\u5165\u548c\u8de8\u8f74\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u6ce8\u610f\u529b\u5c42\u4e2d\u5229\u7528\u79fb\u52a8\u611f\u77e5\u7ea6\u675f\u4fdd\u6301\u76ee\u6807\u53ef\u5206\u6027\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709CNN\u65b9\u6cd5\uff0c\u540c\u65f6\u5177\u6709\u66f4\u597d\u7684\u6570\u636e\u6548\u7387\u548c\u5b9e\u65f6\u90e8\u7f72\u80fd\u529b\u3002", "conclusion": "T-MDS-ViT\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u5efa\u6a21MDS\u6570\u636e\u7684\u65f6\u7a7a\u7279\u6027\uff0c\u4e3a\u96f7\u8fbe\u76ee\u6807\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.13347", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.13347", "abs": "https://arxiv.org/abs/2511.13347", "authors": ["Shuo Zheng", "Shuowen Zhang"], "title": "Joint Transmit Beamforming and Reflection Optimization for Beyond Diagonal RIS Aided Multi-Cell MIMO Communication", "comment": "submitted for possible publication", "summary": "The sixth-generation (6G) wireless networks will rely on ultra-dense multi-cell deployment to meet the high rate and connectivity demands. However, frequency reuse leads to severe inter-cell interference, particularly for cell-edge users, which limits the communication performance. To overcome this challenge, we investigate a beyond diagonal reconfigurable intelligent surface (BD-RIS) aided multi-cell multi-user downlink MIMO communication system, where a BD-RIS is deployed to enhance desired signals and suppress both intra-cell and inter-cell interference.We formulate the joint optimization problem of the transmit beamforming matrices at the BSs and the BD-RIS reflection matrix to maximize the weighted sum rate of all users, subject to the challenging unitary constraint of the BD-RIS reflection matrix and transmit power constraints at the BSs. To tackle this non-convex and difficult problem, we apply the weighted minimum mean squared error (WMMSE) method to transform the problem into an equivalent tractable form, and propose an efficient alternating optimization (AO) based algorithm to iteratively update the transmit beamforming and BD-RIS reflection using Lagrange duality theory and manifold optimization. Numerical results demonstrate the superiority of the proposed design over various benchmark schemes, and provide useful practical insights on the BD-RIS deployment strategy for multi-cell systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86BD-RIS\u8f85\u52a9\u7684\u591a\u5c0f\u533a\u591a\u7528\u6237MIMO\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u57fa\u7ad9\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u548cBD-RIS\u53cd\u5c04\u77e9\u9635\u6765\u6700\u5927\u5316\u52a0\u6743\u548c\u901f\u7387\uff0c\u6709\u6548\u6291\u5236\u5c0f\u533a\u95f4\u5e72\u6270\u3002", "motivation": "6G\u7f51\u7edc\u91c7\u7528\u8d85\u5bc6\u96c6\u591a\u5c0f\u533a\u90e8\u7f72\uff0c\u4f46\u9891\u7387\u590d\u7528\u5bfc\u81f4\u4e25\u91cd\u7684\u5c0f\u533a\u95f4\u5e72\u6270\uff0c\u7279\u522b\u662f\u5bf9\u5c0f\u533a\u8fb9\u7f18\u7528\u6237\u3002\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u589e\u5f3a\u671f\u671b\u4fe1\u53f7\u5e76\u6291\u5236\u5e72\u6270\u3002", "method": "\u4f7f\u7528WMMSE\u65b9\u6cd5\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u7b49\u4ef7\u53ef\u5904\u7406\u5f62\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316\u7684\u7b97\u6cd5\uff0c\u7ed3\u5408\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u7406\u8bba\u548c\u6d41\u5f62\u4f18\u5316\u8fed\u4ee3\u66f4\u65b0\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u548cBD-RIS\u53cd\u5c04\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u8bbe\u8ba1\u4f18\u4e8e\u591a\u79cd\u57fa\u51c6\u65b9\u6848\uff0c\u5e76\u4e3a\u591a\u5c0f\u533a\u7cfb\u7edf\u4e2dBD-RIS\u90e8\u7f72\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "conclusion": "BD-RIS\u80fd\u6709\u6548\u63d0\u5347\u591a\u5c0f\u533a\u7cfb\u7edf\u7684\u901a\u4fe1\u6027\u80fd\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u6291\u5236\u5e72\u6270\u548c\u63d0\u5347\u548c\u901f\u7387\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2511.11963", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.11963", "abs": "https://arxiv.org/abs/2511.11963", "authors": ["Nikola Janju\u0161evi\u0107", "Amirhossein Khalilian-Gourtani", "Yao Wang", "Li Feng"], "title": "Noisy MRI Reconstruction via MAP Estimation with an Implicit Deep-Denoiser Prior", "comment": "4 figures, conference paper", "summary": "Accelerating magnetic resonance imaging (MRI) remains challenging, particularly under realistic acquisition noise. While diffusion models have recently shown promise for reconstructing undersampled MRI data, many approaches lack an explicit link to the underlying MRI physics, and their parameters are sensitive to measurement noise, limiting their reliability in practice. We introduce Implicit-MAP (ImMAP), a diffusion-based reconstruction framework that integrates the acquisition noise model directly into a maximum a posteriori (MAP) formulation. Specifically, we build on the stochastic ascent method of Kadkhodaie et al. and generalize it to handle MRI encoding operators and realistic measurement noise. Across both simulated and real noisy datasets, ImMAP consistently outperforms state-of-the-art deep learning (LPDSNet) and diffusion-based (DDS) methods. By clarifying the practical behavior and limitations of diffusion models under realistic noise conditions, ImMAP establishes a more reliable and interpretable", "AI": {"tldr": "ImMAP\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684MRI\u91cd\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u91c7\u96c6\u566a\u58f0\u6a21\u578b\u76f4\u63a5\u6574\u5408\u5230\u6700\u5927\u540e\u9a8c\u6982\u7387(MAP)\u516c\u5f0f\u4e2d\uff0c\u5728\u771f\u5b9e\u566a\u58f0\u6761\u4ef6\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728MRI\u91cd\u5efa\u4e2d\u7f3a\u4e4f\u4e0eMRI\u7269\u7406\u7684\u660e\u786e\u8054\u7cfb\uff0c\u4e14\u53c2\u6570\u5bf9\u6d4b\u91cf\u566a\u58f0\u654f\u611f\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002", "method": "\u57fa\u4e8eKadkhodaie\u7b49\u4eba\u7684\u968f\u673a\u4e0a\u5347\u65b9\u6cd5\uff0c\u5c06\u5176\u63a8\u5e7f\u5230\u5904\u7406MRI\u7f16\u7801\u7b97\u5b50\u548c\u771f\u5b9e\u6d4b\u91cf\u566a\u58f0\uff0c\u6784\u5efa\u4e86\u96c6\u6210\u566a\u58f0\u6a21\u578b\u7684MAP\u516c\u5f0f\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u566a\u58f0\u6570\u636e\u96c6\u4e0a\uff0cImMAP\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u548c\u6269\u6563\u57fa\u65b9\u6cd5(LPDSNet\u548cDDS)\u3002", "conclusion": "\u901a\u8fc7\u9610\u660e\u6269\u6563\u6a21\u578b\u5728\u771f\u5b9e\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u5b9e\u9645\u884c\u4e3a\u548c\u5c40\u9650\u6027\uff0cImMAP\u5efa\u7acb\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684MRI\u91cd\u5efa\u6846\u67b6\u3002"}}
{"id": "2511.11980", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.11980", "abs": "https://arxiv.org/abs/2511.11980", "authors": ["Yuan Guo", "Wen Chen", "Xudong Bai", "Chong He", "Qiong Wu"], "title": "Resource Allocation for Transmissive RIS Transceiver Enabled SWIPT Systems", "comment": null, "summary": "A novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) framework is proposed. The sum-rate of the information decoding (ID) users is maximized by optimizing the TRIS transceiver's beamforming, subject to the energy harvesting (EH) users' quality-of-harvest and the per-antenna power constraints. To solve this non-convex problem, we develop an efficient optimization algorithm. First, the original problem is reformulated as a semi-definite programming (SDP) problem. The resulting SDP problem is then addressed using successive convex approximation (SCA) combined with a penalty-based method. Numerical results demonstrate the effectiveness of the algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u900f\u5c04\u5f0f\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(TRIS)\u6536\u53d1\u5668\u8d4b\u80fd\u7684SWIPT\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316TRIS\u6536\u53d1\u5668\u7684\u6ce2\u675f\u6210\u5f62\u6765\u6700\u5927\u5316\u4fe1\u606f\u89e3\u7801\u7528\u6237\u7684\u901f\u7387\u548c\uff0c\u540c\u65f6\u6ee1\u8db3\u80fd\u91cf\u6536\u96c6\u7528\u6237\u7684\u6536\u83b7\u8d28\u91cf\u548c\u6bcf\u5929\u7ebf\u529f\u7387\u7ea6\u675f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edfSWIPT\u7cfb\u7edf\u4e2d\u4fe1\u606f\u4f20\u8f93\u548c\u80fd\u91cf\u6536\u96c6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5229\u7528TRIS\u6280\u672f\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u540c\u65f6\u65e0\u7ebf\u4fe1\u606f\u548c\u80fd\u91cf\u4f20\u8f93\u3002", "method": "\u5c06\u539f\u59cb\u975e\u51f8\u95ee\u9898\u91cd\u6784\u4e3a\u534a\u5b9a\u89c4\u5212\u95ee\u9898\uff0c\u7136\u540e\u4f7f\u7528\u9010\u6b21\u51f8\u903c\u8fd1\u4e0e\u57fa\u4e8e\u60e9\u7f5a\u7684\u65b9\u6cd5\u76f8\u7ed3\u5408\u7684\u9ad8\u6548\u4f18\u5316\u7b97\u6cd5\u8fdb\u884c\u6c42\u89e3\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "TRIS\u6536\u53d1\u5668\u8d4b\u80fd\u7684SWIPT\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u4fe1\u606f\u89e3\u7801\u7528\u6237\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6ee1\u8db3\u80fd\u91cf\u6536\u96c6\u7528\u6237\u7684\u9700\u6c42\u3002"}}
{"id": "2511.13482", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.13482", "abs": "https://arxiv.org/abs/2511.13482", "authors": ["Shenrui Lin", "Shuowen Zhang"], "title": "On the Capacity of Pixel Antenna based MIMO Communication", "comment": "submitted for possible publication", "summary": "Pixel antenna is a promising technology to enhance the wireless communication data rate by adaptively reconfiguring each antenna's radiation pattern via a so-called antenna coding technique which controls the states of switches connected to multiple pixel ports. This paper studies a multiple-input multiple-output (MIMO) system where both the transmitter and the receiver are equipped with multiple pixel antennas. We aim to characterize the fundamental capacity limit of this MIMO system by jointly optimizing the transmit covariance matrix and the antenna coders at both the transmitter and the receiver. This problem is a mixed-integer non-linear program (MINLP) which is non-convex and particularly challenging to solve due to the binary-valued optimization variables corresponding to the antenna coders. We first propose an exhaustive search based method to obtain the optimal solution to this problem, which corresponds to the fundamental capacity limit. Then, we propose a branch-and-bound based iterative algorithm aiming to find a high-quality suboptimal solution with lower complexity than exhaustive search as the number of pixel ports becomes large. Finally, we devise an alternating optimization (AO) based algorithm with polynomial complexity. Numerical results show that our proposed algorithms achieve a flexible trade-off between performance and complexity. Moreover, equipping the transceivers with pixel antennas can enhance the achievable rate of MIMO communications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u914d\u5907\u50cf\u7d20\u5929\u7ebf\u7684MIMO\u7cfb\u7edf\u5bb9\u91cf\u6781\u9650\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u534f\u65b9\u5dee\u77e9\u9635\u548c\u6536\u53d1\u4e24\u7aef\u7684\u5929\u7ebf\u7f16\u7801\u5668\u6765\u6700\u5927\u5316\u7cfb\u7edf\u5bb9\u91cf\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u50cf\u7d20\u5929\u7ebf\u6280\u672f\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u6784\u5929\u7ebf\u8f90\u5c04\u6a21\u5f0f\u6765\u63d0\u9ad8\u65e0\u7ebf\u901a\u4fe1\u6570\u636e\u901f\u7387\uff0c\u4f46\u5728MIMO\u7cfb\u7edf\u4e2d\u8054\u5408\u4f18\u5316\u53d1\u5c04\u534f\u65b9\u5dee\u548c\u5929\u7ebf\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u6765\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u7b97\u6cd5\uff1a1\uff09\u7a77\u4e3e\u641c\u7d22\u6cd5\u83b7\u5f97\u6700\u4f18\u89e3\uff1b2\uff09\u5206\u652f\u5b9a\u754c\u8fed\u4ee3\u7b97\u6cd5\u5728\u590d\u6742\u5ea6\u8f83\u4f4e\u65f6\u83b7\u5f97\u9ad8\u8d28\u91cf\u6b21\u4f18\u89e3\uff1b3\uff09\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u5177\u6709\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5728\u6027\u80fd\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u4e86\u7075\u6d3b\u6743\u8861\uff0c\u914d\u5907\u50cf\u7d20\u5929\u7ebf\u53ef\u4ee5\u589e\u5f3aMIMO\u901a\u4fe1\u7684\u53ef\u5b9e\u73b0\u901f\u7387\u3002", "conclusion": "\u50cf\u7d20\u5929\u7ebf\u6280\u672f\u80fd\u591f\u6709\u6548\u63d0\u5347MIMO\u7cfb\u7edf\u6027\u80fd\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3a\u89e3\u51b3\u8fd9\u7c7b\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12126", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.12126", "abs": "https://arxiv.org/abs/2511.12126", "authors": ["Bingze Dai", "Xi Zhang", "Wei-Ning Lee"], "title": "Volumetric Ultrasound via 3D Null Subtraction Imaging with Circular and Spiral Apertures", "comment": "10 pages,12 figures", "summary": "Volumetric ultrasound imaging faces a fundamental trade-off among image quality, frame rate, and hardware complexity. This study introduces three-dimensional Null Subtraction Imaging (3D NSI), a nonlinear beamforming framework that addresses this trade-off by combining computationally efficient null-subtraction process with multiplexing-aware sparse aperture designs on matrix arrays. We evaluate three apodization configurations: a fully addressed circular aperture and two Fermat's spiral sparse apertures. To overcome channel-sharing constraints common in matrix arrays multiplexed with low-channel-count ultrasound systems, we propose a spiral \"no-reuse\" apodization that enforces non-overlapping element sets across transmit-receive events. This design resolves multiplexing conflicts and enables up to a 16-fold increase in acquisition volume rate using only 240 active elements on a 1024-element probe. In computer simulations and tissue-mimicking phantom experiments, 3D NSI achieved an average improvement of 36% in azimuthal and elevational resolutions, along with an approximately 20% higher contrast ratio, compared to the conventional Delay-and-Sum (DAS) beamformer under matched transmit/receive configurations. When implemented with the spiral no-reuse aperture, the 3D NSI framework achieved over 1000 volumes per second with a computational load less than three times that of DAS, making it a practical solution for real-time 4D imaging.", "AI": {"tldr": "\u4e09\u7ef4\u96f6\u51cf\u6210\u50cf\uff083D NSI\uff09\u662f\u4e00\u79cd\u975e\u7ebf\u6027\u6ce2\u675f\u6210\u5f62\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u8ba1\u7b97\u9ad8\u6548\u7684\u96f6\u51cf\u8fc7\u7a0b\u4e0e\u77e9\u9635\u9635\u5217\u4e0a\u7684\u590d\u7528\u611f\u77e5\u7a00\u758f\u5b54\u5f84\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u4f53\u79ef\u8d85\u58f0\u6210\u50cf\u5728\u56fe\u50cf\u8d28\u91cf\u3001\u5e27\u7387\u548c\u786c\u4ef6\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4f53\u79ef\u8d85\u58f0\u6210\u50cf\u5728\u56fe\u50cf\u8d28\u91cf\u3001\u5e27\u7387\u548c\u786c\u4ef6\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u77e9\u9635\u9635\u5217\u4e0e\u4f4e\u901a\u9053\u6570\u8d85\u58f0\u7cfb\u7edf\u590d\u7528\u65f6\u9762\u4e34\u7684\u901a\u9053\u5171\u4eab\u7ea6\u675f\u3002", "method": "\u63d0\u51fa3D NSI\u6846\u67b6\uff0c\u7ed3\u5408\u96f6\u51cf\u8fc7\u7a0b\u548c\u590d\u7528\u611f\u77e5\u7a00\u758f\u5b54\u5f84\u8bbe\u8ba1\u3002\u8bc4\u4f30\u4e09\u79cd\u5b54\u5f84\u914d\u7f6e\uff1a\u5168\u5bfb\u5740\u5706\u5f62\u5b54\u5f84\u548c\u4e24\u79cd\u8d39\u9a6c\u87ba\u65cb\u7a00\u758f\u5b54\u5f84\u3002\u7279\u522b\u63d0\u51fa\u87ba\u65cb\"\u65e0\u590d\u7528\"\u5b54\u5f84\u8bbe\u8ba1\uff0c\u5728\u53d1\u5c04-\u63a5\u6536\u4e8b\u4ef6\u95f4\u5f3a\u5236\u975e\u91cd\u53e0\u5143\u4ef6\u96c6\u4ee5\u89e3\u51b3\u590d\u7528\u51b2\u7a81\u3002", "result": "\u5728\u8ba1\u7b97\u673a\u6a21\u62df\u548c\u7ec4\u7ec7\u6a21\u62df\u4f53\u6a21\u5b9e\u9a8c\u4e2d\uff0c3D NSI\u76f8\u6bd4\u4f20\u7edf\u5ef6\u8fdf\u6c42\u548c\u6ce2\u675f\u6210\u5f62\u5668\uff0c\u5728\u5339\u914d\u7684\u53d1\u5c04/\u63a5\u6536\u914d\u7f6e\u4e0b\uff0c\u65b9\u4f4d\u89d2\u548c\u4ef0\u89d2\u5206\u8fa8\u7387\u5e73\u5747\u63d0\u9ad836%\uff0c\u5bf9\u6bd4\u5ea6\u6bd4\u63d0\u9ad8\u7ea620%\u3002\u4f7f\u7528\u87ba\u65cb\u65e0\u590d\u7528\u5b54\u5f84\u65f6\uff0c3D NSI\u6846\u67b6\u5b9e\u73b0\u4e86\u6bcf\u79d2\u8d85\u8fc71000\u4e2a\u4f53\u79ef\u7684\u91c7\u96c6\u901f\u7387\uff0c\u8ba1\u7b97\u8d1f\u8f7d\u4e0d\u5230DAS\u7684\u4e09\u500d\u3002", "conclusion": "3D NSI\u6846\u67b6\u4e3a\u5b9e\u65f64D\u6210\u50cf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4ec5\u4f7f\u7528240\u4e2a\u6d3b\u52a8\u5143\u4ef6\uff08\u57281024\u5143\u4ef6\u63a2\u5934\u4e0a\uff09\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u8fbe16\u500d\u7684\u91c7\u96c6\u4f53\u79ef\u7387\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u5408\u7406\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2511.11985", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.11985", "abs": "https://arxiv.org/abs/2511.11985", "authors": ["Yuan Guo", "Wen Chen", "Yanze Zhu", "Zhendong Li", "Qiong Wu", "Kunlun Wang"], "title": "Beamforming for Transmissive RIS Transmitter Enabled Simultaneous Wireless Information and Power Transfer Systems", "comment": null, "summary": "This paper investigates a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) system with multiple information decoding (ID) and energy harvesting (EH) users. Under the considered system model, we formulate an optimization problem that maximizes the sum-rate of all ID users via the design of the TRIS transceiver's active beamforming. The design is constrained by per-antenna power limits at the TRIS transceiver and by the minimum harvested energy demand of all EH users. Due to the non-convexity of the objective function and the energy harvesting constraint, the sum-rate problem is difficult to tackle. To solve this challenging optimization problem, by leveraging the weighted minimum mean squared error (WMMSE) framework and the majorization-minimization (MM) method, we propose a second-order cone programming (SOCP)-based algorithm. Per-element power constraints introduce a large number of constraints, making the problem considerably more difficult. By applying the alternating direction method of multipliers (ADMM) method, we successfully develop an analytical, computationally efficient, and highly parallelizable algorithm to address this challenge. Numerical results are provided to validate the convergence and effectiveness of the proposed algorithms. Furthermore, the low-complexity algorithm significantly reduces computational complexity without performance degradation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u65b0\u578b\u900f\u5c04\u5f0f\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(TRIS)\u6536\u53d1\u5668\u8d4b\u80fd\u7684SWIPT\u7cfb\u7edf\uff0c\u901a\u8fc7WMMSE\u548cMM\u65b9\u6cd5\u5f00\u53d1\u4e86SOCP\u7b97\u6cd5\uff0c\u5e76\u4f7f\u7528ADMM\u65b9\u6cd5\u5904\u7406\u529f\u7387\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5e76\u884c\u8ba1\u7b97\u3002", "motivation": "\u5728\u5177\u6709\u591a\u4e2a\u4fe1\u606f\u89e3\u7801\u548c\u80fd\u91cf\u6536\u96c6\u7528\u6237\u7684SWIPT\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u975e\u51f8\u76ee\u6807\u51fd\u6570\u548c\u80fd\u91cf\u6536\u96c6\u7ea6\u675f\uff0c\u7279\u522b\u662f\u5b58\u5728\u5927\u91cf\u5355\u5143\u529f\u7387\u7ea6\u675f\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002", "method": "\u91c7\u7528WMMSE\u6846\u67b6\u548cMM\u65b9\u6cd5\u63d0\u51faSOCP\u7b97\u6cd5\uff0c\u5e76\u5e94\u7528ADMM\u65b9\u6cd5\u5904\u7406\u5355\u5143\u529f\u7387\u7ea6\u675f\uff0c\u5f00\u53d1\u4e86\u8ba1\u7b97\u9ad8\u6548\u4e14\u9ad8\u5ea6\u5e76\u884c\u7684\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6536\u655b\u6027\u548c\u6709\u6548\u6027\uff0c\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86TRIS\u6536\u53d1\u5668\u8d4b\u80fd\u7684SWIPT\u7cfb\u7edf\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.13601", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.13601", "abs": "https://arxiv.org/abs/2511.13601", "authors": ["Kai Wang"], "title": "A Deterministic Dimension Property of Twisted Goppa Codes", "comment": "This is the first version (v1) of an original research article. 7 pages, containing 1 primary data table", "summary": "This paper presents a large-scale computational study on the dimensional properties of twisted Goppa codes. Through the systematic analysis of over 50,000 parameter sets, we uncover a remarkable deterministic regularity: the actual dimension k of a twisted Goppa code is uniquely determined by a set of macro-parameters (q,m,t,b,u). Specifically, when the order of the finite field q, the extension degree m, the degree t of the Goppa polynomial, the translation parameter b of the automorphism, and the order u of the transformation are fixed, the dimension k of the generated code remains constant.", "AI": {"tldr": "\u5bf9\u626d\u66f2Goppa\u7801\u7684\u7ef4\u5ea6\u7279\u6027\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8ba1\u7b97\u7814\u7a76\uff0c\u53d1\u73b0\u5f53\u6709\u9650\u57df\u9636\u6570q\u3001\u6269\u5c55\u5ea6m\u3001Goppa\u591a\u9879\u5f0f\u6b21\u6570t\u3001\u81ea\u540c\u6784\u5e73\u79fb\u53c2\u6570b\u548c\u53d8\u6362\u9636\u6570u\u56fa\u5b9a\u65f6\uff0c\u7801\u7684\u7ef4\u5ea6k\u662f\u786e\u5b9a\u4e0d\u53d8\u7684\u3002", "motivation": "\u7814\u7a76\u626d\u66f2Goppa\u7801\u7684\u7ef4\u5ea6\u7279\u6027\uff0c\u63a2\u7d22\u5176\u53c2\u6570\u4e0e\u7ef4\u5ea6\u4e4b\u95f4\u7684\u786e\u5b9a\u6027\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8d85\u8fc750,000\u4e2a\u53c2\u6570\u96c6\u8fdb\u884c\u5927\u89c4\u6a21\u8ba1\u7b97\u7814\u7a76\uff0c\u7cfb\u7edf\u6027\u5730\u8003\u5bdf\u626d\u66f2Goppa\u7801\u7684\u7ef4\u5ea6\u7279\u6027\u3002", "result": "\u53d1\u73b0\u626d\u66f2Goppa\u7801\u7684\u7ef4\u5ea6k\u7531\u4e00\u7ec4\u5b8f\u89c2\u53c2\u6570(q,m,t,b,u)\u552f\u4e00\u786e\u5b9a\uff0c\u5f53\u8fd9\u4e9b\u53c2\u6570\u56fa\u5b9a\u65f6\uff0c\u751f\u6210\u7684\u7801\u7684\u7ef4\u5ea6\u4fdd\u6301\u6052\u5b9a\u3002", "conclusion": "\u626d\u66f2Goppa\u7801\u7684\u7ef4\u5ea6\u5177\u6709\u786e\u5b9a\u6027\u89c4\u5f8b\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u5b8f\u89c2\u53c2\u6570(q,m,t,b,u)\uff0c\u8fd9\u4e3a\u7801\u7684\u8bbe\u8ba1\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.12212", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12212", "abs": "https://arxiv.org/abs/2511.12212", "authors": ["Petr Boriskov", "Kirill Rudkovskii", "Andrei Velichko"], "title": "Recursive Threshold Median Filter and Autoencoder for Salt-and-Pepper Denoising: SSIM analysis of Images and Entropy Maps", "comment": "14 pages, 13 figures, 4 tables", "summary": "This paper studies the removal of salt-and-pepper noise from images using median filter (MF) and simple three-layer autoencoder (AE) within recursive threshold algorithm. The performance of denoising is assessed with two metrics: the standard Structural Similarity Index SSIMImg of restored and clean images and a newly applied metric SSIMMap - the SSIM of entropy maps of these images computed via 2D Sample Entropy in sliding windows. We shown that SSIMMap is more sensitive to blur and local intensity transitions and complements SSIMImg. Experiments on low- and high-resolution grayscales images demonstrate that recursive threshold MF robustly restores images even under strong noise (50-60 %), whereas simple AE is only capable of restoring images with low levels of noise (<30 %). We propose two scalable schemes: (i) 2MF, which uses two MFs with different window sizes and a final thresholding step, effective for highlighting sharp local details at low resolution; and (ii) MFs-AE, which aggregates features from multiple MFs via an AE and is beneficial for restoring the overall scene structure at higher resolution. Owing to its simplicity and computational efficiency, MF remains preferable for deployment on resource-constrained platforms (edge/IoT), whereas AE underperforms without prior denoising. The results also validate the practical value of SSIMMap for objective blur assessment and denoising parameter tuning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u4e2d\u503c\u6ee4\u6ce2\u5668\u548c\u7b80\u5355\u4e09\u5c42\u81ea\u7f16\u7801\u5668\u5728\u9012\u5f52\u9608\u503c\u7b97\u6cd5\u4e2d\u53bb\u9664\u56fe\u50cf\u6912\u76d0\u566a\u58f0\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u53ef\u6269\u5c55\u65b9\u6848\u5e76\u9a8c\u8bc1\u4e86\u65b0\u7684SSIMMap\u8bc4\u4f30\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u56fe\u50cf\u53bb\u566a\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6912\u76d0\u566a\u58f0\u7684\u53bb\u9664\uff0c\u5e76\u5f00\u53d1\u66f4\u654f\u611f\u7684\u8bc4\u4f30\u6307\u6807\u6765\u8865\u5145\u4f20\u7edf\u7684SSIMImg\u6307\u6807\u3002", "method": "\u4f7f\u7528\u4e2d\u503c\u6ee4\u6ce2\u5668\u548c\u7b80\u5355\u4e09\u5c42\u81ea\u7f16\u7801\u5668\u7ed3\u5408\u9012\u5f52\u9608\u503c\u7b97\u6cd5\uff0c\u63d0\u51fa\u4e862MF\u548cMFs-AE\u4e24\u79cd\u53ef\u6269\u5c55\u65b9\u6848\u3002", "result": "\u9012\u5f52\u9608\u503c\u4e2d\u503c\u6ee4\u6ce2\u5668\u5728\u5f3a\u566a\u58f0\uff0850-60%\uff09\u4e0b\u4ecd\u80fd\u7a33\u5065\u6062\u590d\u56fe\u50cf\uff0c\u800c\u7b80\u5355\u81ea\u7f16\u7801\u5668\u4ec5\u9002\u7528\u4e8e\u4f4e\u566a\u58f0\u6c34\u5e73\uff08<30%\uff09\u3002SSIMMap\u6307\u6807\u5bf9\u6a21\u7cca\u548c\u5c40\u90e8\u5f3a\u5ea6\u53d8\u5316\u66f4\u654f\u611f\u3002", "conclusion": "\u4e2d\u503c\u6ee4\u6ce2\u5668\u56e0\u5176\u7b80\u5355\u6027\u548c\u8ba1\u7b97\u6548\u7387\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u66f4\u9002\u7528\uff0c\u800c\u81ea\u7f16\u7801\u5668\u5728\u6ca1\u6709\u9884\u53bb\u566a\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002SSIMMap\u5728\u5ba2\u89c2\u6a21\u7cca\u8bc4\u4f30\u548c\u53bb\u566a\u53c2\u6570\u8c03\u4f18\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.12045", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12045", "abs": "https://arxiv.org/abs/2511.12045", "authors": ["Paloma Sette", "Maria Werneck", "William Barbosa", "Ana Loubacker"], "title": "MUSTEM: A Dual-Modality System for Vibrotactile and Visual Translation of Music as an Assistive Technology", "comment": null, "summary": "The emotional and structural experience of music remains a significant accessibility challenge for the deaf and hard of hearing community. This paper introduces MUSTEM (Multisensorial Emotional Translation), a novel system designed to translate music into a rich, coherent, and scientifically-grounded sensory experience. We present a dual-modality approach addressing this challenge through two interconnected components. First, a low-cost, portable hardware prototype that performs real-time audio analysis, mapping distinct frequency bands (sub-bass, bass, mid-range, treble) to a four-channel vibrotactile system, allowing users to feel the music's rhythmic and foundational structure. Second, to overcome the processing limitations of embedded hardware, we developed a high-fidelity software simulation that demonstrates the full potential of the visual translation. This assistive dashboard decodes musical components - such as rhythm, harmony, and frequency spectrum - into an intuitive and educational visual interface. MUSTEM offers a comprehensive framework for sensory substitution, presenting a viable and accessible pathway for the deaf community to experience music not just as vibration, but as a structured, substantiated and emotionally resonant visual and tactile language. Preliminary feedback from seven deaf users suggests the system's spatial vibrotactile mapping is perceptible and engaging. All source code and hardware designs are released as open-source. Video demonstrations and open-source code are available on the project's official channel.", "AI": {"tldr": "MUSTEM\u7cfb\u7edf\u901a\u8fc7\u632f\u52a8\u89e6\u89c9\u548c\u89c6\u89c9\u754c\u9762\u5c06\u97f3\u4e50\u8f6c\u5316\u4e3a\u591a\u611f\u5b98\u4f53\u9a8c\uff0c\u5e2e\u52a9\u804b\u4eba\u548c\u542c\u529b\u969c\u788d\u8005\u611f\u53d7\u97f3\u4e50\u7684\u60c5\u611f\u548c\u7ed3\u6784\u3002", "motivation": "\u89e3\u51b3\u804b\u4eba\u548c\u542c\u529b\u969c\u788d\u7fa4\u4f53\u5728\u97f3\u4e50\u60c5\u611f\u548c\u7ed3\u6784\u4f53\u9a8c\u65b9\u9762\u7684\u53ef\u8bbf\u95ee\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u53cc\u6a21\u6001\u65b9\u6cd5\uff1a1) \u4f4e\u6210\u672c\u4fbf\u643a\u786c\u4ef6\u539f\u578b\uff0c\u5b9e\u65f6\u5206\u6790\u97f3\u9891\u5e76\u5c06\u4e0d\u540c\u9891\u6bb5\u6620\u5c04\u5230\u56db\u901a\u9053\u632f\u52a8\u89e6\u89c9\u7cfb\u7edf\uff1b2) \u9ad8\u4fdd\u771f\u8f6f\u4ef6\u6a21\u62df\uff0c\u5c06\u97f3\u4e50\u5143\u7d20\u89e3\u7801\u4e3a\u76f4\u89c2\u7684\u89c6\u89c9\u754c\u9762\u3002", "result": "\u521d\u6b65\u53cd\u9988\u663e\u793a7\u540d\u804b\u4eba\u7528\u6237\u8ba4\u4e3a\u7cfb\u7edf\u7684\u7a7a\u95f4\u632f\u52a8\u89e6\u89c9\u6620\u5c04\u53ef\u611f\u77e5\u4e14\u5f15\u4eba\u5165\u80dc\u3002\u6240\u6709\u6e90\u4ee3\u7801\u548c\u786c\u4ef6\u8bbe\u8ba1\u5df2\u5f00\u6e90\u3002", "conclusion": "MUSTEM\u4e3a\u611f\u5b98\u66ff\u4ee3\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\uff0c\u4e3a\u804b\u4eba\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u9014\u5f84\uff0c\u8ba9\u4ed6\u4eec\u4e0d\u4ec5\u80fd\u611f\u53d7\u632f\u52a8\uff0c\u8fd8\u80fd\u4f53\u9a8c\u7ed3\u6784\u5316\u548c\u60c5\u611f\u5171\u9e23\u7684\u89c6\u89c9\u89e6\u89c9\u8bed\u8a00\u3002"}}
{"id": "2511.12248", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12248", "abs": "https://arxiv.org/abs/2511.12248", "authors": ["Kerem Basim", "Mehmet Ozan Unal", "Metin Ertas", "Isa Yildirim"], "title": "Deep Unfolded BM3D: Unrolling Non-local Collaborative Filtering into a Trainable Neural Network", "comment": null, "summary": "Block-Matching and 3D Filtering (BM3D) exploits non-local self-similarity priors for denoising but relies on fixed parameters. Deep models such as U-Net are more flexible but often lack interpretability and fail to generalize across noise regimes. In this study, we propose Deep Unfolded BM3D (DU-BM3D), a hybrid framework that unrolls BM3D into a trainable architecture by replacing its fixed collaborative filtering with a learnable U-Net denoiser. This preserves BM3D's non-local structural prior while enabling end-to-end optimization. We evaluate DU-BM3D on low-dose CT (LDCT) denoising and show that it outperforms classic BM3D and standalone U-Net across simulated LDCT at different noise levels, yielding higher PSNR and SSIM, especially in high-noise conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86DU-BM3D\uff0c\u4e00\u79cd\u5c06\u4f20\u7edfBM3D\u7b97\u6cd5\u5c55\u5f00\u4e3a\u53ef\u8bad\u7ec3\u67b6\u6784\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u53ef\u5b66\u4e60\u7684U-Net\u53bb\u566a\u5668\u66ff\u4ee3\u56fa\u5b9a\u534f\u4f5c\u6ee4\u6ce2\uff0c\u5728\u4f4e\u5242\u91cfCT\u53bb\u566a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfBM3D\u548c\u72ec\u7acbU-Net\u3002", "motivation": "BM3D\u5229\u7528\u975e\u5c40\u90e8\u81ea\u76f8\u4f3c\u6027\u5148\u9a8c\u8fdb\u884c\u53bb\u566a\u4f46\u4f9d\u8d56\u56fa\u5b9a\u53c2\u6570\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5982U-Net\u66f4\u7075\u6d3b\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u96be\u4ee5\u8de8\u566a\u58f0\u57df\u6cdb\u5316\u3002", "method": "\u5c06BM3D\u5c55\u5f00\u4e3a\u53ef\u8bad\u7ec3\u67b6\u6784\uff0c\u7528\u53ef\u5b66\u4e60\u7684U-Net\u53bb\u566a\u5668\u66ff\u4ee3\u5176\u56fa\u5b9a\u7684\u534f\u4f5c\u6ee4\u6ce2\uff0c\u4fdd\u7559BM3D\u7684\u975e\u5c40\u90e8\u7ed3\u6784\u5148\u9a8c\u540c\u65f6\u652f\u6301\u7aef\u5230\u7aef\u4f18\u5316\u3002", "result": "\u5728\u4f4e\u5242\u91cfCT\u53bb\u566a\u4efb\u52a1\u4e2d\uff0cDU-BM3D\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u5747\u4f18\u4e8e\u7ecf\u5178BM3D\u548c\u72ec\u7acbU-Net\uff0c\u5c24\u5176\u5728\u5f3a\u566a\u58f0\u6761\u4ef6\u4e0b\u83b7\u5f97\u66f4\u9ad8\u7684PSNR\u548cSSIM\u3002", "conclusion": "DU-BM3D\u6210\u529f\u7ed3\u5408\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u7075\u6d3b\u6027\uff0c\u5728\u533b\u5b66\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.12051", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12051", "abs": "https://arxiv.org/abs/2511.12051", "authors": ["Scott Staniewicz", "Sara Mirzaee", "Heresh Fattahi", "Talib Oliver-Cabrera", "Emre Havazli", "Geoffrey Gunter", "Se-Yeon Jeon", "Mary Grace Bato", "Jinwoo Kim", "Simran S. Sangha", "Bruce Chapman", "Alexander L. Handwerger", "Marin Govorcin", "Piyush Agram", "David Bekaert"], "title": "Near-Real-Time InSAR Phase Estimation for Large-Scale Surface Displacement Monitoring", "comment": "14 pages, 11 figures, plus supplementary material", "summary": "Operational near-real-time monitoring of Earth's surface deformation using Interferometric Synthetic Aperture Radar (InSAR) requires processing algorithms that efficiently incorporate new acquisitions without reprocessing historical archives. We present sequential phase linking approach using compressed single-look-complex images (SLCs) capable of producing surface displacement estimates within hours of the time of a new acquisition. Our key algorithmic contribution is a mini-stack reference scheme that maintains phase consistency across processing batches without adjusting or re-estimating previous time steps, enabling straightforward operational deployment. We introduce online methods for persistent and distributed scatterer identification that adapt to temporal changes in surface properties through incremental amplitude statistics updates. The processing chain incorporates multiple complementary metrics for pixel quality that are reliable for small SLC stack sizes, and an L1-norm network inversion to limit propagation of unwrapping errors across the time series. We use our algorithm to produce OPERA Surface Displacement from Sentinel-1 product, the first continental-scale surface displacement product over North America. Validation against GPS measurements and InSAR residual analysis demonstrates millimeter-level agreement in velocity estimates in varying environmental conditions. We demonstrate our algorithm's capabilities with a successful recovery of meter-scale co-eruptive displacement at Kilauea volcano during the 2018 eruption, as well as detection of subtle uplift at Three Sisters volcano, Oregon- a challenging environment for C-band InSAR due to dense vegetation and seasonal snow. We have made all software available as open source libraries, providing a significant advancement to the open scientific community's ability to process large InSAR data sets in a cloud environment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8fd1\u5b9e\u65f6InSAR\u5730\u8868\u5f62\u53d8\u76d1\u6d4b\u7684\u5e8f\u5217\u76f8\u4f4d\u8fde\u63a5\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u65b0\u6570\u636e\u91c7\u96c6\u540e\u51e0\u5c0f\u65f6\u5185\u751f\u6210\u4f4d\u79fb\u4f30\u8ba1\uff0c\u65e0\u9700\u91cd\u65b0\u5904\u7406\u5386\u53f2\u6570\u636e\u3002", "motivation": "\u5b9e\u73b0\u8fd1\u5b9e\u65f6\u7684InSAR\u5730\u8868\u5f62\u53d8\u76d1\u6d4b\u9700\u8981\u80fd\u591f\u9ad8\u6548\u6574\u5408\u65b0\u91c7\u96c6\u6570\u636e\u800c\u65e0\u9700\u91cd\u65b0\u5904\u7406\u5386\u53f2\u6863\u6848\u7684\u5904\u7406\u7b97\u6cd5\u3002", "method": "\u4f7f\u7528\u538b\u7f29\u5355\u89c6\u590d\u56fe\u50cf(SLCs)\u7684\u5e8f\u5217\u76f8\u4f4d\u8fde\u63a5\u65b9\u6cd5\uff0c\u91c7\u7528\u8ff7\u4f60\u5806\u6808\u53c2\u8003\u65b9\u6848\u4fdd\u6301\u8de8\u5904\u7406\u6279\u6b21\u7684\u76f8\u4f4d\u4e00\u81f4\u6027\uff0c\u5305\u542b\u5728\u7ebf\u6301\u4e45\u548c\u5206\u5e03\u5f0f\u6563\u5c04\u4f53\u8bc6\u522b\u65b9\u6cd5\uff0c\u4ee5\u53caL1\u8303\u6570\u7f51\u7edc\u53cd\u6f14\u9650\u5236\u89e3\u7f20\u8bef\u5dee\u4f20\u64ad\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8eOPERA\u5730\u8868\u4f4d\u79fb\u4ea7\u54c1\uff0c\u9a8c\u8bc1\u663e\u793a\u4e0eGPS\u6d4b\u91cf\u548cInSAR\u6b8b\u5dee\u5206\u6790\u5728\u6beb\u7c73\u7ea7\u901f\u5ea6\u4f30\u8ba1\u4e0a\u4e00\u81f4\uff0c\u6210\u529f\u6062\u590d\u4e86\u57fa\u62c9\u97e6\u5384\u706b\u5c712018\u5e74\u55b7\u53d1\u671f\u95f4\u7684\u7c73\u7ea7\u540c\u55b7\u53d1\u4f4d\u79fb\uff0c\u5e76\u5728\u4e09\u59d0\u59b9\u706b\u5c71\u68c0\u6d4b\u5230\u5fae\u5f31\u62ac\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f00\u653e\u79d1\u5b66\u754c\u5728\u4e91\u73af\u5883\u4e2d\u5904\u7406\u5927\u578bInSAR\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u6240\u6709\u8f6f\u4ef6\u5df2\u4f5c\u4e3a\u5f00\u6e90\u5e93\u63d0\u4f9b\u3002"}}
{"id": "2511.12268", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12268", "abs": "https://arxiv.org/abs/2511.12268", "authors": ["Rupam Mukherjee", "Rajkumar Daniel", "Soujanya Hazra", "Shirin Dasgupta", "Subhamoy Mandal"], "title": "Multimodal RGB-HSI Feature Fusion with Patient-Aware Incremental Heuristic Meta-Learning for Oral Lesion Classification", "comment": "4 pages, 1 figure, 2 tables", "summary": "Early detection of oral cancer and potentially malignant disorders is challenging in low-resource settings due to limited annotated data. We present a unified four-class oral lesion classifier that integrates deep RGB embeddings, hyperspectral reconstruction, handcrafted spectral-textural descriptors, and demographic metadata. A pathologist-verified subset of oral cavity images was curated and processed using a fine-tuned ConvNeXt-v2 encoder, followed by RGB-to-HSI reconstruction into 31-band hyperspectral cubes. Haemoglobin-sensitive indices, texture features, and spectral-shape measures were extracted and fused with deep and clinical features. Multiple machine-learning models were assessed with patient-wise validation. We further introduce an incremental heuristic meta-learner (IHML) that combines calibrated base classifiers through probabilistic stacking and patient-level posterior smoothing. On an unseen patient split, the proposed framework achieved a macro F1 of 66.23% and an accuracy of 64.56%. Results demonstrate that hyperspectral reconstruction and uncertainty-aware meta-learning substantially improve robustness for real-world oral lesion screening.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u56db\u7c7b\u53e3\u8154\u75c5\u53d8\u5206\u7c7b\u5668\uff0c\u7ed3\u5408\u6df1\u5ea6RGB\u5d4c\u5165\u3001\u9ad8\u5149\u8c31\u91cd\u5efa\u3001\u624b\u5de5\u5149\u8c31\u7eb9\u7406\u63cf\u8ff0\u7b26\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u5143\u6570\u636e\uff0c\u7528\u4e8e\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u53e3\u8154\u764c\u65e9\u671f\u68c0\u6d4b\u3002", "motivation": "\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\uff0c\u7531\u4e8e\u6807\u6ce8\u6570\u636e\u6709\u9650\uff0c\u53e3\u8154\u764c\u548c\u6f5c\u5728\u6076\u6027\u75c5\u53d8\u7684\u65e9\u671f\u68c0\u6d4b\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u4f7f\u7528\u5fae\u8c03\u7684ConvNeXt-v2\u7f16\u7801\u5668\u5904\u7406\u53e3\u8154\u56fe\u50cf\uff0c\u8fdb\u884cRGB\u5230HSI\u91cd\u5efa\u751f\u621031\u6ce2\u6bb5\u9ad8\u5149\u8c31\u7acb\u65b9\u4f53\uff0c\u63d0\u53d6\u8840\u7ea2\u86cb\u767d\u654f\u611f\u6307\u6570\u3001\u7eb9\u7406\u7279\u5f81\u548c\u5149\u8c31\u5f62\u72b6\u5ea6\u91cf\uff0c\u4e0e\u6df1\u5ea6\u548c\u4e34\u5e8a\u7279\u5f81\u878d\u5408\uff0c\u5e76\u5f15\u5165\u589e\u91cf\u542f\u53d1\u5f0f\u5143\u5b66\u4e60\u5668\uff08IHML\uff09\u901a\u8fc7\u6982\u7387\u5806\u53e0\u548c\u60a3\u8005\u7ea7\u540e\u9a8c\u5e73\u6ed1\u7ed3\u5408\u6821\u51c6\u7684\u57fa\u7840\u5206\u7c7b\u5668\u3002", "result": "\u5728\u672a\u89c1\u8fc7\u7684\u60a3\u8005\u5206\u5272\u4e0a\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e8666.23%\u7684\u5b8f\u89c2F1\u5206\u6570\u548c64.56%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u9ad8\u5149\u8c31\u91cd\u5efa\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5143\u5b66\u4e60\u663e\u8457\u63d0\u9ad8\u4e86\u771f\u5b9e\u4e16\u754c\u53e3\u8154\u75c5\u53d8\u7b5b\u67e5\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.12073", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12073", "abs": "https://arxiv.org/abs/2511.12073", "authors": ["Woojae Jeong", "Wenhui Cui", "Kleanthis Avramidis", "Takfarinas Medani", "Shrikanth Narayanan", "Richard Leahy"], "title": "Informed Bootstrap Augmentation Improves EEG Decoding", "comment": null, "summary": "Electroencephalography (EEG) offers detailed access to neural dynamics but remains constrained by noise and trial-by-trial variability, limiting decoding performance in data-restricted or complex paradigms. Data augmentation is often employed to enhance feature representations, yet conventional uniform averaging overlooks differences in trial informativeness and can degrade representational quality. We introduce a weighted bootstrapping approach that prioritizes more reliable trials to generate higher-quality augmented samples. In a Sentence Evaluation paradigm, weights were computed from relative ERP differences and applied during probabilistic sampling and averaging. Across conditions, weighted bootstrapping improved decoding accuracy relative to unweighted (from 68.35% to 71.25% at best), demonstrating that emphasizing reliable trials strengthens representational quality. The results demonstrate that reliability-based augmentation yields more robust and discriminative EEG representations. The code is publicly available at https://github.com/lyricists/NeuroBootstrap.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u9760\u6027\u7684\u52a0\u6743\u81ea\u4e3e\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5148\u9009\u62e9\u4fe1\u606f\u91cf\u66f4\u5927\u7684\u8bd5\u9a8c\u6837\u672c\u6765\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684EEG\u6570\u636e\u589e\u5f3a\u6837\u672c\uff0c\u5728\u53e5\u5b50\u8bc4\u4f30\u8303\u5f0f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u89e3\u7801\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfEEG\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u91c7\u7528\u5747\u5300\u5e73\u5747\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u8bd5\u9a8c\u6837\u672c\u7684\u4fe1\u606f\u4ef7\u503c\u5dee\u5f02\uff0c\u53ef\u80fd\u5bfc\u81f4\u8868\u5f81\u8d28\u91cf\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8bc6\u522b\u5e76\u4f18\u5148\u4f7f\u7528\u66f4\u53ef\u9760\u8bd5\u9a8c\u7684\u65b9\u6cd5\u6765\u6539\u5584\u7279\u5f81\u8868\u793a\u3002", "method": "\u5f00\u53d1\u4e86\u52a0\u6743\u81ea\u4e3e\u65b9\u6cd5\uff0c\u57fa\u4e8e\u76f8\u5bf9ERP\u5dee\u5f02\u8ba1\u7b97\u8bd5\u9a8c\u6743\u91cd\uff0c\u5728\u6982\u7387\u91c7\u6837\u548c\u5e73\u5747\u8fc7\u7a0b\u4e2d\u4f18\u5148\u9009\u62e9\u66f4\u53ef\u9760\u7684\u8bd5\u9a8c\u6765\u751f\u6210\u589e\u5f3a\u6837\u672c\u3002", "result": "\u5728\u53e5\u5b50\u8bc4\u4f30\u8303\u5f0f\u4e2d\uff0c\u52a0\u6743\u81ea\u4e3e\u65b9\u6cd5\u76f8\u6bd4\u672a\u52a0\u6743\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u89e3\u7801\u51c6\u786e\u7387\uff08\u4ece68.35%\u63d0\u5347\u81f371.25%\uff09\uff0c\u8868\u660e\u5f3a\u8c03\u53ef\u9760\u8bd5\u9a8c\u80fd\u591f\u589e\u5f3a\u8868\u5f81\u8d28\u91cf\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u9760\u6027\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u66f4\u9c81\u68d2\u548c\u66f4\u5177\u533a\u5206\u5ea6\u7684EEG\u8868\u5f81\uff0c\u4e3a\u6570\u636e\u53d7\u9650\u6216\u590d\u6742\u8303\u5f0f\u4e0b\u7684\u795e\u7ecf\u89e3\u7801\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12269", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12269", "abs": "https://arxiv.org/abs/2511.12269", "authors": ["Rupam Mukherjee", "Rajkumar Daniel", "Soujanya Hazra", "Shirin Dasgupta", "Subhamoy Mandal"], "title": "RAA-MIL: A Novel Framework for Classification of Oral Cytology", "comment": "Under Review at IEEE ISBI 2026", "summary": "Cytology is a valuable tool for early detection of oral squamous cell carcinoma (OSCC). However, manual examination of cytology whole slide images (WSIs) is slow, subjective, and depends heavily on expert pathologists. To address this, we introduce the first weakly supervised deep learning framework for patient-level diagnosis of oral cytology whole slide images, leveraging the newly released Oral Cytology Dataset [1], which provides annotated cytology WSIs from ten medical centres across India. Each patient case is represented as a bag of cytology patches and assigned a diagnosis label (Healthy, Benign, Oral Potentially Malignant Disorders (OPMD), OSCC) by an in-house expert pathologist. These patient-level weak labels form a new extension to the dataset. We evaluate a baseline multiple-instance learning (MIL) model and a proposed Region-Affinity Attention MIL (RAA-MIL) that models spatial relationships between regions within each slide. The RAA-MIL achieves an average accuracy of 72.7%, weighted F1-score of 0.69 on an unseen test set, outperforming the baseline. This study establishes the first patient-level weakly supervised benchmark for oral cytology and moves toward reliable AI-assisted digital pathology.", "AI": {"tldr": "\u9996\u4e2a\u5f31\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u53e3\u8154\u7ec6\u80de\u5b66\u5168\u73bb\u7247\u56fe\u50cf\u7684\u75c5\u4eba\u7ea7\u522b\u8bca\u65ad\uff0c\u901a\u8fc7\u591a\u5b9e\u4f8b\u5b66\u4e60\u548c\u533a\u57df\u4eb2\u548c\u529b\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347\u8bca\u65ad\u6027\u80fd", "motivation": "\u624b\u52a8\u68c0\u67e5\u53e3\u8154\u7ec6\u80de\u5b66\u5168\u73bb\u7247\u56fe\u50cf\u901f\u5ea6\u6162\u3001\u4e3b\u89c2\u6027\u5f3a\u4e14\u4f9d\u8d56\u4e13\u5bb6\u75c5\u7406\u5b66\u5bb6\uff0c\u9700\u8981AI\u8f85\u52a9\u7684\u81ea\u52a8\u5316\u8bca\u65ad\u65b9\u6cd5", "method": "\u63d0\u51fa\u533a\u57df\u4eb2\u548c\u529b\u6ce8\u610f\u529b\u591a\u5b9e\u4f8b\u5b66\u4e60(RAA-MIL)\u6846\u67b6\uff0c\u5efa\u6a21\u73bb\u7247\u5185\u533a\u57df\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u4f7f\u7528\u75c5\u4eba\u7ea7\u522b\u7684\u5f31\u6807\u7b7e\u8fdb\u884c\u8bad\u7ec3", "result": "RAA-MIL\u5728\u672a\u89c1\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523072.7%\u7684\u5e73\u5747\u51c6\u786e\u7387\u548c0.69\u7684\u52a0\u6743F1\u5206\u6570\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u9996\u4e2a\u53e3\u8154\u7ec6\u80de\u5b66\u75c5\u4eba\u7ea7\u522b\u5f31\u76d1\u7763\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u53ef\u9760\u7684AI\u8f85\u52a9\u6570\u5b57\u75c5\u7406\u5b66\u53d1\u5c55"}}
{"id": "2511.12102", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12102", "abs": "https://arxiv.org/abs/2511.12102", "authors": ["Abhisha Garg", "Akash Kumar", "Suraj Srivastava", "Nimish Yadav", "Aditya K. Jagannatham", "Lajos Hanzo"], "title": "Bayesian Learning Aided Simultaneous Sparse Estimation of Dual-Wideband THz Channels in Multi-User Hybrid MIMO Systems", "comment": null, "summary": "This work conceives the Bayesian Group-Sparse Regression (BGSR) for the estimation of a spatial and frequency wideband, i.e., a dual wideband channel in Multi-User (MU) THz hybrid MIMO scenarios. We develop a practical dual wideband THz channel model that incorporates absorption losses, reflection losses, diffused ray modeling and angles of arrival/departure (AoAs/AoDs) using a Gaussian Mixture Model (GMM). Furthermore, a low-resolution analog-to-digital converter (ADC) is employed at each RF chain, which is crucial for wideband THz massive MIMO systems to reduce power consumption and hardware complexity, given the high sampling rates and large number of antennas involved. The quantized MU THz MIMO model is linearized using the popular Bussgang decomposition followed by BGSR based channel learning framework that results in sparsity across different subcarriers, where each subcarrier has its unique dictionary matrix. Next, the Bayesian Cram\u00e9r Rao Bound (BCRB) is devised for bounding the normalized mean square error (NMSE) performance. Extensive simulations were performed to assess the performance improvements achieved by the proposed BGSR method compared to other sparse estimation techniques. The metrics considered for quantifying the performance improvements include the NMSE and bit error rate (BER).", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u7fa4\u7a00\u758f\u56de\u5f52\u65b9\u6cd5\u7528\u4e8e\u592a\u8d6b\u5179\u6df7\u5408MIMO\u7cfb\u7edf\u4e2d\u7684\u53cc\u5bbd\u5e26\u4fe1\u9053\u4f30\u8ba1\uff0c\u7ed3\u5408\u4f4e\u5206\u8fa8\u7387ADC\u548c\u8d1d\u53f6\u65af\u514b\u62c9\u7f8e\u7f57\u754c\u5206\u6790\u6027\u80fd\u3002", "motivation": "\u592a\u8d6b\u5179\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u9700\u8981\u5904\u7406\u9ad8\u91c7\u6837\u7387\u548c\u5927\u91cf\u5929\u7ebf\u5e26\u6765\u7684\u529f\u8017\u4e0e\u786c\u4ef6\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u540c\u65f6\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u7a7a\u95f4\u548c\u9891\u7387\u53cc\u5bbd\u5e26\u4fe1\u9053\u3002", "method": "\u5f00\u53d1\u5b9e\u7528\u7684\u53cc\u5bbd\u5e26\u592a\u8d6b\u5179\u4fe1\u9053\u6a21\u578b\uff0c\u91c7\u7528\u4f4e\u5206\u8fa8\u7387ADC\uff0c\u4f7f\u7528Bussgang\u5206\u89e3\u7ebf\u6027\u5316\u91cf\u5316\u6a21\u578b\uff0c\u63d0\u51fa\u8d1d\u53f6\u65af\u7fa4\u7a00\u758f\u56de\u5f52\u6846\u67b6\u8fdb\u884c\u4fe1\u9053\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u4eff\u771f\u9a8c\u8bc1\uff0c\u6240\u63d0BGSR\u65b9\u6cd5\u5728\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u548c\u8bef\u7801\u7387\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed6\u7a00\u758f\u4f30\u8ba1\u6280\u672f\u3002", "conclusion": "BGSR\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u592a\u8d6b\u5179\u53cc\u5bbd\u5e26MIMO\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u5728\u6027\u80fd\u63d0\u5347\u548c\u590d\u6742\u5ea6\u63a7\u5236\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.12373", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12373", "abs": "https://arxiv.org/abs/2511.12373", "authors": ["Fan Li", "Arun Iyengar", "Lanyu Xu"], "title": "MTMed3D: A Multi-Task Transformer-Based Model for 3D Medical Imaging", "comment": null, "summary": "In the field of medical imaging, AI-assisted techniques such as object detection, segmentation, and classification are widely employed to alleviate the workload of physicians and doctors. However, single-task models are predominantly used, overlooking the shared information across tasks. This oversight leads to inefficiencies in real-life applications. In this work, we propose MTMed3D, a novel end-to-end Multi-task Transformer-based model to address the limitations of single-task models by jointly performing 3D detection, segmentation, and classification in medical imaging. Our model uses a Transformer as the shared encoder to generate multi-scale features, followed by CNN-based task-specific decoders. The proposed framework was evaluated on the BraTS 2018 and 2019 datasets, achieving promising results across all three tasks, especially in detection, where our method achieves better results than prior works. Additionally, we compare our multi-task model with equivalent single-task variants trained separately. Our multi-task model significantly reduces computational costs and achieves faster inference speed while maintaining comparable performance to the single-task models, highlighting its efficiency advantage. To the best of our knowledge, this is the first work to leverage Transformers for multi-task learning that simultaneously covers detection, segmentation, and classification tasks in 3D medical imaging, presenting its potential to enhance diagnostic processes. The code is available at https://github.com/fanlimua/MTMed3D.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86MTMed3D\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6a21\u578b\uff0c\u57283D\u533b\u5b66\u5f71\u50cf\u4e2d\u540c\u65f6\u6267\u884c\u68c0\u6d4b\u3001\u5206\u5272\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u5e76\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u533b\u5b66\u5f71\u50cfAI\u4e3b\u8981\u4f7f\u7528\u5355\u4efb\u52a1\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u4efb\u52a1\u95f4\u7684\u5171\u4eab\u4fe1\u606f\uff0c\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u6548\u7387\u4f4e\u4e0b\u3002\u591a\u4efb\u52a1\u5b66\u4e60\u53ef\u4ee5\u5145\u5206\u5229\u7528\u4efb\u52a1\u95f4\u7684\u76f8\u5173\u6027\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u4f7f\u7528Transformer\u4f5c\u4e3a\u5171\u4eab\u7f16\u7801\u5668\u751f\u6210\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u7136\u540e\u4f7f\u7528\u57fa\u4e8eCNN\u7684\u4efb\u52a1\u7279\u5b9a\u89e3\u7801\u5668\u3002\u5728BraTS 2018\u548c2019\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5355\u4efb\u52a1\u6a21\u578b\u53d8\u4f53\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u90fd\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\u3002\u591a\u4efb\u52a1\u6a21\u578b\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u63a8\u7406\u901f\u5ea6\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5355\u4efb\u52a1\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u57283D\u533b\u5b66\u5f71\u50cf\u4e2d\u5229\u7528Transformer\u540c\u65f6\u5904\u7406\u68c0\u6d4b\u3001\u5206\u5272\u548c\u5206\u7c7b\u4efb\u52a1\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u5de5\u4f5c\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u5347\u8bca\u65ad\u6d41\u7a0b\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.12137", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12137", "abs": "https://arxiv.org/abs/2511.12137", "authors": ["Zheng Wang", "Yifu Li", "Yuchao Mei", "Xinyu Sui", "Qingbin Li", "Xu Luo", "Rui Wang", "Dongxin Ni", "Jian Pang"], "title": "A 24-GHz CMOS Transformer-Based Three-Tline Series Doherty Power Amplifier Achieving 39% PAE", "comment": "This paper has been accepted by ICTA2025", "summary": "This paper presents a transformer-based three- transmission-line (Tline) series Doherty power amplifier (PA) implemented in 65-nm CMOS, targeting broadband K/Ka-band applications. By integrating an impedance-scaling network into the output matching structure, the design enables effective load modulation and reduced impedance transformation ratio (ITR) at power back-off when employing stacked cascode transistors. The PA demonstrates a -3-dB small-signal gain bandwidth from 22 to 32.5 GHz, a saturated output power (Psat) of 21.6 dBm, and a peak power-added efficiency (PAE) of 39%. At 6dB back-off, the PAE remains above 24%, validating its suitability for high- efficiency mm-wave phased-array transmitters in next-generation wireless systems.", "AI": {"tldr": "\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u4e09\u4f20\u8f93\u7ebf\u7ea7\u8054Doherty\u529f\u7387\u653e\u5927\u5668\uff0c\u91c7\u752865nm CMOS\u5de5\u827a\uff0c\u9488\u5bf9\u5bbd\u5e26K/Ka\u6ce2\u6bb5\u5e94\u7528\uff0c\u901a\u8fc7\u963b\u6297\u7f29\u653e\u7f51\u7edc\u5b9e\u73b0\u6709\u6548\u8d1f\u8f7d\u8c03\u5236\u548c\u964d\u4f4e\u963b\u6297\u53d8\u6362\u6bd4\u3002", "motivation": "\u9488\u5bf9\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u6beb\u7c73\u6ce2\u76f8\u63a7\u9635\u53d1\u5c04\u673a\u5bf9\u9ad8\u6548\u7387\u5bbd\u5e26\u529f\u7387\u653e\u5927\u5668\u7684\u9700\u6c42\uff0c\u5f00\u53d1\u9002\u7528\u4e8eK/Ka\u6ce2\u6bb5\u7684Doherty\u529f\u7387\u653e\u5927\u5668\u3002", "method": "\u91c7\u7528\u53d8\u538b\u5668\u57fa\u4e09\u4f20\u8f93\u7ebf\u7ea7\u8054\u7ed3\u6784\uff0c\u5728\u8f93\u51fa\u5339\u914d\u7ed3\u6784\u4e2d\u96c6\u6210\u963b\u6297\u7f29\u653e\u7f51\u7edc\uff0c\u4f7f\u7528\u5806\u53e0\u5171\u6e90\u5171\u6805\u6676\u4f53\u7ba1\uff0c\u5b9e\u73b0\u8d1f\u8f7d\u8c03\u5236\u548c\u964d\u4f4e\u529f\u7387\u56de\u9000\u65f6\u7684\u963b\u6297\u53d8\u6362\u6bd4\u3002", "result": "\u5c0f\u4fe1\u53f7\u589e\u76ca\u5e26\u5bbd22-32.5GHz\uff0c\u9971\u548c\u8f93\u51fa\u529f\u738721.6dBm\uff0c\u5cf0\u503c\u529f\u7387\u9644\u52a0\u6548\u738739%\uff0c6dB\u56de\u9000\u65f6\u6548\u7387\u4ecd\u9ad8\u4e8e24%\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u9a8c\u8bc1\u4e86\u5176\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u6beb\u7c73\u6ce2\u76f8\u63a7\u9635\u53d1\u5c04\u673a\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5b9e\u73b0\u4e86\u5bbd\u5e26\u9ad8\u6548\u7387\u6027\u80fd\u3002"}}
{"id": "2511.12396", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12396", "abs": "https://arxiv.org/abs/2511.12396", "authors": ["Jiacheng Wang", "Hao Li", "Xing Yao", "Ahmad Toubasi", "Taegan Vinarsky", "Caroline Gheen", "Joy Derwenskus", "Chaoyang Jin", "Richard Dortch", "Junzhong Xu", "Francesca Bagnato", "Ipek Oguz"], "title": "DEMIST: \\underline{DE}coupled \\underline{M}ulti-stream latent d\\underline{I}ffusion for Quantitative Myelin Map \\underline{S}yn\\underline{T}hesis", "comment": null, "summary": "Quantitative magnetization transfer (qMT) imaging provides myelin-sensitive biomarkers, such as the pool size ratio (PSR), which is valuable for multiple sclerosis (MS) assessment. However, qMT requires specialized 20-30 minute scans. We propose DEMIST to synthesize PSR maps from standard T1w and FLAIR images using a 3D latent diffusion model with three complementary conditioning mechanisms. Our approach has two stages: first, we train separate autoencoders for PSR and anatomical images to learn aligned latent representations. Second, we train a conditional diffusion model in this latent space on top of a frozen diffusion foundation backbone. Conditioning is decoupled into: (i) \\textbf{semantic} tokens via cross-attention, (ii) \\textbf{spatial} per-scale residual hints via a 3D ControlNet branch, and (iii) \\textbf{adaptive} LoRA-modulated attention. We include edge-aware loss terms to preserve lesion boundaries and alignment losses to maintain quantitative consistency, while keeping the number of trainable parameters low and retaining the inductive bias of the pretrained model. We evaluate on 163 scans from 99 subjects using 5-fold cross-validation. Our method outperforms VAE, GAN and diffusion baselines on multiple metrics, producing sharper boundaries and better quantitative agreement with ground truth. Our code is publicly available at https://github.com/MedICL-VU/MS-Synthesis-3DcLDM.", "AI": {"tldr": "DEMIST\u65b9\u6cd5\u4f7f\u75283D\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4ece\u6807\u51c6T1w\u548cFLAIR\u56fe\u50cf\u5408\u6210\u5b9a\u91cf\u78c1\u5316\u8f6c\u79fb\u6210\u50cf\u7684PSR\u56fe\uff0c\u901a\u8fc7\u4e09\u79cd\u4e92\u8865\u6761\u4ef6\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u5408\u6210\u3002", "motivation": "\u4f20\u7edfqMT\u6210\u50cf\u9700\u898120-30\u5206\u949f\u7684\u4e13\u4e1a\u626b\u63cf\uff0c\u8017\u65f6\u8f83\u957f\u3002\u7814\u7a76\u65e8\u5728\u4ece\u5e38\u89c4MRI\u5e8f\u5217\u5feb\u901f\u5408\u6210PSR\u56fe\uff0c\u7528\u4e8e\u591a\u53d1\u6027\u786c\u5316\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u5148\u8bad\u7ec3PSR\u548c\u89e3\u5256\u56fe\u50cf\u7684\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u5bf9\u9f50\u6f5c\u5728\u8868\u793a\uff0c\u7136\u540e\u5728\u6f5c\u5728\u7a7a\u95f4\u8bad\u7ec3\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u5305\u542b\u8bed\u4e49\u6807\u8bb0\u3001\u7a7a\u95f4\u6b8b\u5dee\u63d0\u793a\u548c\u81ea\u9002\u5e94LoRA\u8c03\u5236\u4e09\u79cd\u6761\u4ef6\u673a\u5236\u3002", "result": "\u5728163\u4e2a\u626b\u63cf\u76845\u6298\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\uff0c\u65b9\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8eVAE\u3001GAN\u548c\u6269\u6563\u57fa\u7ebf\uff0c\u4ea7\u751f\u66f4\u6e05\u6670\u7684\u8fb9\u754c\u548c\u66f4\u597d\u7684\u5b9a\u91cf\u4e00\u81f4\u6027\u3002", "conclusion": "DEMIST\u80fd\u591f\u4ece\u6807\u51c6MRI\u5e8f\u5217\u9ad8\u6548\u5408\u6210\u9ad8\u8d28\u91cf\u7684PSR\u56fe\uff0c\u4e3a\u591a\u53d1\u6027\u786c\u5316\u8bc4\u4f30\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.12297", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12297", "abs": "https://arxiv.org/abs/2511.12297", "authors": ["Angqi Liu", "Filippo Moro", "Sebastian Billaudelle", "Melika Payvand"], "title": "A Linear Implementation of an Analog Resonate-and-Fire Neuron", "comment": null, "summary": "Oscillatory dynamics have recently proven highly effective in machine learning (ML), particularly through State-Space-Models (SSM) that leverage structured linear recurrences for long-range temporal processing. Resonate-and-Fire neurons capture such oscillatory behavior in a spiking framework, offering strong expressivity with sparse event-based communication. While early analog RAF circuits employed nonlinear coupling and suffered from process sensitivity, modern ML practice favors linear recurrence. In this work, we introduce a resonate-and-fire (RAF) neuron, built in 22nm Fully-Depleted Silicon-on-Insulator technology, that aligns with SSM principles while retaining the efficiency of spike-based communication. We analyze its dynamics, linearity, and resilience to Process, Voltage, and Temperature variations, and evaluate its power, performance, and area trade-offs. We map the characteristics of our circuit into a system-level simulation where our RAF neuron is utilized in a keyword-spotting task, showing that its non-idealities do not hinder performance. Our results establish RAF neurons as robust, energy-efficient computational primitives for neuromorphic hardware.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e22nm FD-SOI\u6280\u672f\u7684\u5171\u632f\u653e\u7535\u795e\u7ecf\u5143\uff0c\u8be5\u795e\u7ecf\u5143\u7b26\u5408\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u539f\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u57fa\u4e8e\u8109\u51b2\u901a\u4fe1\u7684\u6548\u7387\uff0c\u5728\u5173\u952e\u8bcd\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u5c06\u632f\u8361\u52a8\u529b\u5b66\u4e0e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u5229\u7528\u5171\u632f\u653e\u7535\u795e\u7ecf\u5143\u7684\u7a00\u758f\u4e8b\u4ef6\u901a\u4fe1\u4f18\u52bf\uff0c\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u8ba1\u7b97\u539f\u8bed\u3002", "method": "\u572822nm FD-SOI\u6280\u672f\u4e2d\u6784\u5efa\u5171\u632f\u653e\u7535\u795e\u7ecf\u5143\uff0c\u5206\u6790\u5176\u52a8\u529b\u5b66\u7279\u6027\u3001\u7ebf\u6027\u5ea6\u4ee5\u53ca\u5bf9PVT\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u8bc4\u4f30\u5176\u529f\u8017\u3001\u6027\u80fd\u548c\u9762\u79ef\u6743\u8861\u3002", "result": "\u7535\u8def\u7279\u6027\u88ab\u6620\u5c04\u5230\u7cfb\u7edf\u7ea7\u4eff\u771f\u4e2d\uff0c\u5728\u5173\u952e\u8bcd\u8bc6\u522b\u4efb\u52a1\u4e2d\u663e\u793a\u5176\u975e\u7406\u60f3\u6027\u4e0d\u4f1a\u5f71\u54cd\u6027\u80fd\uff0cRAF\u795e\u7ecf\u5143\u88ab\u8bc1\u660e\u662f\u7a33\u5065\u4e14\u8282\u80fd\u7684\u8ba1\u7b97\u539f\u8bed\u3002", "conclusion": "RAF\u795e\u7ecf\u5143\u4f5c\u4e3a\u7a33\u5065\u3001\u8282\u80fd\u7684\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u8ba1\u7b97\u539f\u8bed\u5177\u6709\u826f\u597d\u524d\u666f\uff0c\u5176\u975e\u7406\u60f3\u6027\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6027\u80fd\u3002"}}
{"id": "2511.12451", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12451", "abs": "https://arxiv.org/abs/2511.12451", "authors": ["Abdullah Al Bashit", "Prakash Nepal", "Lee Makowski"], "title": "A Multicollinearity-Aware Signal-Processing Framework for Cross-$\u03b2$ Identification via X-ray Scattering of Alzheimer's Tissue", "comment": "19 pages, 4 figures, journal paper under review", "summary": "X-ray scattering measurements of in situ human brain tissue encode structural signatures of pathological cross-$\u03b2$ inclusions, yet systematic exploitation of these data for automated detection remains challenging due to substrate contamination, strong inter-feature correlations, and limited sample sizes. This work develops a three-stage classification framework for identifying cross-$\u03b2$ structural inclusions-a hallmark of Alzheimer's disease-in X-ray scattering profiles of post-mortem human brain. Stage 1 employs a Bayes-optimal classifier to separate mica substrate from tissue regions on the basis of their distinct scattering signatures. Stage 2 introduces a multicollinearityaware, class-conditional correlation pruning scheme with formal guarantees on the induced Bayes risk and approximation error, thereby reducing redundancy while retaining class-discriminative information. Stage 3 trains a compact neural network on the pruned feature set to detect the presence or absence of cross-$\u03b2$ fibrillar ordering. The top-performing model, optimized with a composite loss combining Focal and Dice objectives, attains a test F1-score of 84.30% using 11 of 211 candidate features and 174 trainable parameters. The overall framework yields an interpretable, theory-grounded strategy for data-limited classification problems involving correlated, high-dimensional experimental measurements, exemplified here by X-ray scattering profiles of neurodegenerative tissue.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u5728X\u5c04\u7ebf\u6563\u5c04\u6570\u636e\u4e2d\u68c0\u6d4b\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u4ea4\u53c9\u03b2\u7ed3\u6784\u5305\u6db5\u4f53\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u5206\u7c7b\u3001\u76f8\u5173\u6027\u526a\u679d\u548c\u7d27\u51d1\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u9ad8\u6548\u5206\u7c7b\u3002", "motivation": "X\u5c04\u7ebf\u6563\u5c04\u6d4b\u91cf\u4e2d\u7684\u4eba\u8111\u7ec4\u7ec7\u6570\u636e\u5305\u542b\u75c5\u7406\u4ea4\u53c9\u03b2\u5305\u6db5\u4f53\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u4f46\u7531\u4e8e\u57fa\u5e95\u6c61\u67d3\u3001\u5f3a\u7279\u5f81\u76f8\u5173\u6027\u548c\u6709\u9650\u6837\u672c\u91cf\uff0c\u81ea\u52a8\u5316\u68c0\u6d4b\u9762\u4e34\u6311\u6218\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) \u8d1d\u53f6\u65af\u6700\u4f18\u5206\u7c7b\u5668\u5206\u79bb\u57fa\u5e95\u548c\u7ec4\u7ec7\u533a\u57df\uff1b2) \u591a\u5171\u7ebf\u6027\u611f\u77e5\u7684\u76f8\u5173\u6027\u526a\u679d\u65b9\u6848\uff1b3) \u5728\u526a\u679d\u7279\u5f81\u96c6\u4e0a\u8bad\u7ec3\u7d27\u51d1\u795e\u7ecf\u7f51\u7edc\u68c0\u6d4b\u4ea4\u53c9\u03b2\u7ea4\u7ef4\u6709\u5e8f\u6027\u3002", "result": "\u6700\u4f73\u6a21\u578b\u4f7f\u752811\u4e2a\u5019\u9009\u7279\u5f81\u4e2d\u768411\u4e2a\u548c174\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523084.30%\u7684F1\u5206\u6570\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6570\u636e\u6709\u9650\u3001\u6d89\u53ca\u76f8\u5173\u9ad8\u7ef4\u5b9e\u9a8c\u6d4b\u91cf\u7684\u5206\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u7406\u8bba\u57fa\u7840\u7b56\u7565\uff0c\u7279\u522b\u9002\u7528\u4e8e\u795e\u7ecf\u9000\u884c\u6027\u7ec4\u7ec7X\u5c04\u7ebf\u6563\u5c04\u5206\u6790\u3002"}}
{"id": "2511.12308", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12308", "abs": "https://arxiv.org/abs/2511.12308", "authors": ["Jiajun Zhu", "Yanqun Tang", "Cong Yi", "Haoran Yin", "Yuanhan Ni", "Fan Liu", "Zhiqiang Wei", "Huseyin Arslan"], "title": "ISAC with Affine Frequency Division Multiplexing: An FMCW-Based Signal Processing Perspective", "comment": "Submitted to IEEE for possible publication", "summary": "This paper investigates the sensing potential of affine frequency division multiplexing (AFDM) in high-mobility integrated sensing and communication (ISAC) from the perspective of radar waveforms. We introduce an innovative parameter selection criterion that establishes a precise mathematical equivalence between AFDM subcarriers and Nyquist-sampled frequency-modulated continuous-wave (FMCW). This connection not only provides a clear physical insight into AFDM's sensing mechanism but also enables a direct mapping from the DAFT index to delay-Doppler (DD) parameters of wireless channels. Building on this, we develop a novel input-output model in a DD-parameterized DAFT (DD-DAFT) domain for AFDM, which explicitly reveals the inherent DD coupling effect arising from the chirp-channel interaction. Subsequently, we design two matched-filtering sensing algorithms. The first is performed in the time-frequency domain with low complexity, while the second is operated in the DD-DAFT domain to precisely resolve the DD coupling. Simulations show that our algorithms achieve effective pilot-free sensing and demonstrate a fundamental trade-off between sensing performance, communication overhead, and computational complexity. The proposed AFDM outperforms classical AFDM and other variants in most scenarios.", "AI": {"tldr": "\u672c\u6587\u4ece\u96f7\u8fbe\u6ce2\u5f62\u89d2\u5ea6\u7814\u7a76AFDM\u5728\u9ad8\u79fb\u52a8\u6027ISAC\u4e2d\u7684\u611f\u77e5\u6f5c\u529b\uff0c\u63d0\u51fa\u53c2\u6570\u9009\u62e9\u51c6\u5219\u5efa\u7acbAFDM\u5b50\u8f7d\u6ce2\u4e0eFMCW\u7684\u6570\u5b66\u7b49\u4ef7\u6027\uff0c\u5f00\u53d1DD-DAFT\u57df\u8f93\u5165\u8f93\u51fa\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e24\u79cd\u5339\u914d\u6ee4\u6ce2\u611f\u77e5\u7b97\u6cd5\uff0c\u5b9e\u73b0\u65e0\u5bfc\u9891\u611f\u77e5\u5e76\u5c55\u793a\u6027\u80fd\u6743\u8861\u3002", "motivation": "\u7814\u7a76AFDM\u5728\u9ad8\u79fb\u52a8\u6027\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u4e2d\u7684\u611f\u77e5\u80fd\u529b\uff0c\u4ece\u96f7\u8fbe\u6ce2\u5f62\u89d2\u5ea6\u63a2\u7d22\u5176\u7269\u7406\u673a\u5236\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u901f\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u53c2\u6570\u9009\u62e9\u51c6\u5219\u5efa\u7acbAFDM\u5b50\u8f7d\u6ce2\u4e0eFMCW\u7684\u6570\u5b66\u7b49\u4ef7\u6027\uff1b\u5f00\u53d1DD-DAFT\u57df\u8f93\u5165\u8f93\u51fa\u6a21\u578b\u63ed\u793a\u5541\u557e-\u4fe1\u9053\u4ea4\u4e92\u4ea7\u751f\u7684DD\u8026\u5408\u6548\u5e94\uff1b\u8bbe\u8ba1\u65f6\u9891\u57df\u548cDD-DAFT\u57df\u4e24\u79cd\u5339\u914d\u6ee4\u6ce2\u611f\u77e5\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u663e\u793a\u7b97\u6cd5\u5b9e\u73b0\u6709\u6548\u65e0\u5bfc\u9891\u611f\u77e5\uff0c\u5728\u591a\u6570\u573a\u666f\u4e0b\u4f18\u4e8e\u7ecf\u5178AFDM\u548c\u5176\u4ed6\u53d8\u4f53\uff0c\u63ed\u793a\u4e86\u611f\u77e5\u6027\u80fd\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "AFDM\u5728\u9ad8\u79fb\u52a8\u6027ISAC\u4e2d\u5177\u6709\u4f18\u8d8a\u7684\u611f\u77e5\u6f5c\u529b\uff0c\u6240\u63d0\u65b9\u6cd5\u4e3a\u7406\u89e3AFDM\u611f\u77e5\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.12689", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.12689", "abs": "https://arxiv.org/abs/2511.12689", "authors": ["Harshana Weligampola", "Yuanrui Chen", "Abhiram Gnanasambandam", "Weiheng Tang", "Dilshan Godaliyadda", "Hamid R. Sheikh", "Qi Guo", "Stanley H. Chan"], "title": "Diffusion Algorithm for Metalens Optical Aberration Correction", "comment": "5 pages, 4 figures", "summary": "Metalenses offer a path toward creating ultra-thin optical systems, but they inherently suffer from severe, spatially varying optical aberrations, especially chromatic aberration, which makes image reconstruction a significant challenge. This paper presents a novel algorithmic solution to this problem, designed to reconstruct a sharp, full-color image from two inputs: a sharp, bandpass-filtered grayscale ``structure image'' and a heavily distorted ``color cue'' image, both captured by the metalens system. Our method utilizes a dual-branch diffusion model, built upon a pre-trained Stable Diffusion XL framework, to fuse information from the two inputs. We demonstrate through quantitative and qualitative comparisons that our approach significantly outperforms existing deblurring and pansharpening methods, effectively restoring high-frequency details while accurately colorizing the image.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53cc\u5206\u652f\u6269\u6563\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u4ece\u91d1\u5c5e\u900f\u955c\u7cfb\u7edf\u6355\u83b7\u7684\u9510\u5229\u7070\u5ea6\u7ed3\u6784\u56fe\u50cf\u548c\u5931\u771f\u7684\u989c\u8272\u7ebf\u7d22\u56fe\u50cf\u4e2d\u91cd\u5efa\u6e05\u6670\u7684\u5168\u5f69\u56fe\u50cf\u3002", "motivation": "\u91d1\u5c5e\u900f\u955c\u867d\u7136\u80fd\u5b9e\u73b0\u8d85\u8584\u5149\u5b66\u7cfb\u7edf\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u7684\u5149\u5b66\u50cf\u5dee\uff08\u7279\u522b\u662f\u8272\u5dee\uff09\uff0c\u4f7f\u5f97\u56fe\u50cf\u91cd\u5efa\u6210\u4e3a\u91cd\u5927\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684Stable Diffusion XL\u6846\u67b6\u6784\u5efa\u53cc\u5206\u652f\u6269\u6563\u6a21\u578b\uff0c\u878d\u5408\u7ed3\u6784\u56fe\u50cf\u548c\u989c\u8272\u7ebf\u7d22\u56fe\u50cf\u7684\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u5b9a\u91cf\u548c\u5b9a\u6027\u6bd4\u8f83\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u53bb\u6a21\u7cca\u548c\u5168\u8272\u9510\u5316\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u6062\u590d\u9ad8\u9891\u7ec6\u8282\u5e76\u51c6\u786e\u7740\u8272\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u91d1\u5c5e\u900f\u955c\u7cfb\u7edf\u7684\u8272\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u5168\u5f69\u56fe\u50cf\u91cd\u5efa\u3002"}}
{"id": "2511.12348", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12348", "abs": "https://arxiv.org/abs/2511.12348", "authors": ["Mostafa Nozari", "Israel Leyva-Mayorga", "Fabio Saggese", "Gilberto Berardinelli"], "title": "Toward ISAC-empowered subnetworks: Cooperative localization and iterative node selection", "comment": null, "summary": "This paper tackles the sensing-communication trade-off in integrated sensing and communication (ISAC)-empowered subnetworks for mono-static target localization. We propose a low-complexity iterative node selection algorithm that exploits the spatial diversity of subnetwork deployments and dynamically refines the set of sensing subnetworks to maximize localization accuracy under tight resource constraints. Simulation results show that our method achieves sub-7 cm accuracy in additive white Gaussian noise (AWGN) channels within only three iterations, yielding over 97% improvement compared to the best-performing benchmark under the same sensing budget. We further demonstrate that increasing spatial diversity through additional antennas and subnetworks enhances sensing robustness, especially in fading channels. Finally, we quantify the sensing-communication trade-off, showing that reducing sensing iterations and the number of sensing subnetworks improves throughput at the cost of reduced localization precision.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u8fed\u4ee3\u8282\u70b9\u9009\u62e9\u7b97\u6cd5\uff0c\u7528\u4e8eISAC\u5b50\u7f51\u7edc\u4e2d\u7684\u5355\u7ad9\u76ee\u6807\u5b9a\u4f4d\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u6700\u5927\u5316\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u5b50\u7f51\u7edc\u4e2d\u611f\u77e5\u4e0e\u901a\u4fe1\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5355\u7ad9\u76ee\u6807\u5b9a\u4f4d\u573a\u666f\u4e0b\u3002", "method": "\u5229\u7528\u5b50\u7f51\u7edc\u90e8\u7f72\u7684\u7a7a\u95f4\u591a\u6837\u6027\uff0c\u52a8\u6001\u4f18\u5316\u611f\u77e5\u5b50\u7f51\u7edc\u96c6\u5408\uff0c\u91c7\u7528\u4f4e\u590d\u6742\u5ea6\u8fed\u4ee3\u8282\u70b9\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u5728AWGN\u4fe1\u9053\u4e2d\u4ec5\u97003\u6b21\u8fed\u4ee3\u5373\u53ef\u5b9e\u73b0\u4e9a7\u5398\u7c73\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u6700\u4f73\u57fa\u51c6\u65b9\u6cd5\u5728\u76f8\u540c\u611f\u77e5\u9884\u7b97\u4e0b\u63d0\u534797%\u4ee5\u4e0a\u3002\u589e\u52a0\u7a7a\u95f4\u591a\u6837\u6027\u53ef\u589e\u5f3a\u611f\u77e5\u9c81\u68d2\u6027\u3002", "conclusion": "\u51cf\u5c11\u611f\u77e5\u8fed\u4ee3\u6b21\u6570\u548c\u611f\u77e5\u5b50\u7f51\u7edc\u6570\u91cf\u53ef\u63d0\u9ad8\u541e\u5410\u91cf\uff0c\u4f46\u4f1a\u964d\u4f4e\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u91cf\u5316\u4e86\u611f\u77e5-\u901a\u4fe1\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2511.12730", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12730", "abs": "https://arxiv.org/abs/2511.12730", "authors": ["Emilien Valat", "Ozan \u00d6ktem"], "title": "Improving the Generalisation of Learned Reconstruction Frameworks", "comment": "11 pages, 8 figures", "summary": "Ensuring proper generalization is a critical challenge in applying data-driven methods for solving inverse problems in imaging, as neural networks reconstructing an image must perform well across varied datasets and acquisition geometries. In X-ray Computed Tomography (CT), convolutional neural networks (CNNs) are widely used to filter the projection data but are ill-suited for this task as they apply grid-based convolutions to the sinogram, which inherently lies on a line manifold, not a regular grid. The CNNs, unaware of the geometry, are implicitly tied to it and require an excessive amount of parameters as they must infer the relations between measurements from the data rather than from prior information.\n  The contribution of this paper is twofold. First, we introduce a graph data structure to represent CT acquisition geometries and tomographic data, providing a detailed explanation of the graph's structure for circular, cone-beam geometries. Second, we propose GLM, a hybrid neural network architecture that leverages both graph and grid convolutions to process tomographic data.\n  We demonstrate that GLM outperforms CNNs when performance is quantified in terms of structural similarity and peak signal-to-noise ratio, despite the fact that GLM uses only a fraction of the trainable parameters. Compared to CNNs, GLM also requires significantly less training time and memory, and its memory requirements scale better. Crucially, GLM demonstrates robust generalization to unseen variations in the acquisition geometry, like when training only on fully sampled CT data and then testing on sparse-view CT data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eCT\u6210\u50cf\u7684\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784GLM\uff0c\u901a\u8fc7\u56fe\u6570\u636e\u7ed3\u6784\u8868\u793aCT\u91c7\u96c6\u51e0\u4f55\u548c\u5c42\u6790\u6570\u636e\uff0c\u7ed3\u5408\u56fe\u5377\u79ef\u548c\u7f51\u683c\u5377\u79ef\u5904\u7406\u5c42\u6790\u6570\u636e\uff0c\u76f8\u6bd4\u4f20\u7edfCNN\u5728\u6027\u80fd\u3001\u53c2\u6570\u6548\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfCNN\u5728CT\u6210\u50cf\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u5c06\u57fa\u4e8e\u7f51\u683c\u7684\u5377\u79ef\u5e94\u7528\u4e8e\u6b63\u5f26\u56fe\u6570\u636e\uff0c\u800c\u6b63\u5f26\u56fe\u672c\u8d28\u4e0a\u4f4d\u4e8e\u7ebf\u6d41\u5f62\u4e0a\u800c\u975e\u89c4\u5219\u7f51\u683c\u3002CNN\u4e0d\u4e86\u89e3\u51e0\u4f55\u7ed3\u6784\uff0c\u9700\u8981\u4ece\u6570\u636e\u4e2d\u63a8\u65ad\u6d4b\u91cf\u5173\u7cfb\uff0c\u5bfc\u81f4\u53c2\u6570\u8fc7\u591a\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u5f15\u5165\u56fe\u6570\u636e\u7ed3\u6784\u8868\u793aCT\u91c7\u96c6\u51e0\u4f55\u548c\u5c42\u6790\u6570\u636e\uff0c\u63d0\u51faGLM\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u56fe\u5377\u79ef\u548c\u7f51\u683c\u5377\u79ef\u5904\u7406\u5c42\u6790\u6570\u636e\u3002", "result": "GLM\u5728\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u5cf0\u503c\u4fe1\u566a\u6bd4\u65b9\u9762\u4f18\u4e8eCNN\uff0c\u4ec5\u4f7f\u7528\u4e00\u5c0f\u90e8\u5206\u53ef\u8bad\u7ec3\u53c2\u6570\u3002\u76f8\u6bd4CNN\uff0cGLM\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u9700\u6c42\u663e\u8457\u51cf\u5c11\uff0c\u5185\u5b58\u9700\u6c42\u6269\u5c55\u6027\u66f4\u597d\u3002GLM\u5bf9\u91c7\u96c6\u51e0\u4f55\u7684\u672a\u89c1\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GLM\u67b6\u6784\u901a\u8fc7\u7ed3\u5408\u56fe\u5377\u79ef\u548c\u7f51\u683c\u5377\u79ef\uff0c\u6709\u6548\u89e3\u51b3\u4e86CT\u6210\u50cf\u4e2d\u4f20\u7edfCNN\u7684\u51e0\u4f55\u611f\u77e5\u4e0d\u8db3\u95ee\u9898\uff0c\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2511.12470", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12470", "abs": "https://arxiv.org/abs/2511.12470", "authors": ["Zijun Wang", "Anjali Omer", "Jacob Chakareski", "Nicholas Mastronarde", "Rui Zhang"], "title": "Cross-Layer Design for Near-Field mmWave Beam Management and Scheduling under Delay-Sensitive Traffic", "comment": "Workshop paper submitted to the AI4NextG Workshop at NeurIPS 2025", "summary": "Next-generation wireless networks will rely on mmWave/sub-THz spectrum and extremely large antenna arrays (ELAAs). This will push their operation into the near field where far-field beam management degrades and beam training becomes more costly and must be done more frequently. Because ELAA training and data transmission consume energy and training trades off with service time, we pose a cross-layer control problem that couples PHY-layer beam management with MAC-layer service under delay-sensitive traffic. The controller decides when to retrain and how aggressively to train (pilot count and sparsity) while allocating transmit power, explicitly balancing pilot overhead, data-phase rate, and energy to reduce the queueing delay of MAC-layer frames/packets to be transmitted. We model the problem as a partially observable Markov decision process and solve it with deep reinforcement learning. In simulations with a realistic near-field channel and varying mobility and traffic load, the learned policy outperforms strong 5G-NR--style baselines at a comparable energy: it achieves 85.5% higher throughput than DFT sweeping and reduces the overflow rate by 78%. These results indicate a practical path to overhead-aware, traffic-adaptive near-field beam management with implications for emerging low-latency, high-rate next-generation applications such as digital twin, spatial computing, and immersive communication.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u5c42\u63a7\u5236\u65b9\u6cd5\uff0c\u5c06\u7269\u7406\u5c42\u6ce2\u675f\u7ba1\u7406\u4e0eMAC\u5c42\u670d\u52a1\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8fd1\u573a\u6ce2\u675f\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u4fdd\u8bc1\u670d\u52a1\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4f7f\u7528\u6beb\u7c73\u6ce2/\u592a\u8d6b\u5179\u9891\u8c31\u548c\u8d85\u5927\u5929\u7ebf\u9635\u5217\uff0c\u4f7f\u7cfb\u7edf\u5de5\u4f5c\u5728\u8fd1\u573a\u533a\u57df\uff0c\u4f20\u7edf\u8fdc\u573a\u6ce2\u675f\u7ba1\u7406\u6027\u80fd\u4e0b\u964d\uff0c\u6ce2\u675f\u8bad\u7ec3\u6210\u672c\u589e\u52a0\u4e14\u9700\u8981\u66f4\u9891\u7e41\u6267\u884c\uff0c\u9700\u8981\u5e73\u8861\u8bad\u7ec3\u5f00\u9500\u4e0e\u6570\u636e\u4f20\u8f93\u6548\u7387\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6c42\u89e3\uff0c\u63a7\u5236\u5668\u51b3\u7b56\u4f55\u65f6\u91cd\u65b0\u8bad\u7ec3\u3001\u8bad\u7ec3\u5f3a\u5ea6\uff08\u5bfc\u9891\u6570\u91cf\u548c\u7a00\u758f\u5ea6\uff09\u4ee5\u53ca\u53d1\u5c04\u529f\u7387\u5206\u914d\u3002", "result": "\u5728\u771f\u5b9e\u8fd1\u573a\u4fe1\u9053\u548c\u4e0d\u540c\u79fb\u52a8\u6027\u3001\u6d41\u91cf\u8d1f\u8f7d\u7684\u4eff\u771f\u4e2d\uff0c\u5b66\u4e60\u7b56\u7565\u6bd45G-NR\u98ce\u683c\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\uff1a\u541e\u5410\u91cf\u6bd4DFT\u626b\u63cf\u9ad885.5%\uff0c\u6ea2\u51fa\u7387\u964d\u4f4e78%\uff0c\u80fd\u8017\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f00\u9500\u611f\u77e5\u3001\u6d41\u91cf\u81ea\u9002\u5e94\u7684\u8fd1\u573a\u6ce2\u675f\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5bf9\u6570\u5b57\u5b6a\u751f\u3001\u7a7a\u95f4\u8ba1\u7b97\u548c\u6c89\u6d78\u5f0f\u901a\u4fe1\u7b49\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u901f\u7387\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.12853", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12853", "abs": "https://arxiv.org/abs/2511.12853", "authors": ["Min Gu Kwak", "Yeonju Lee", "Hairong Wang", "Jing Li"], "title": "BrainNormalizer: Anatomy-Informed Pseudo-Healthy Brain Reconstruction from Tumor MRI via Edge-Guided ControlNet", "comment": null, "summary": "Brain tumors are among the most clinically significant neurological diseases and remain a major cause of morbidity and mortality due to their aggressive growth and structural heterogeneity. As tumors expand, they induce substantial anatomical deformation that disrupts both local tissue organization and global brain architecture, complicating diagnosis, treatment planning, and surgical navigation. Yet a subject-specific reference of how the brain would appear without tumor-induced changes is fundamentally unobtainable in clinical practice. We present BrainNormalizer, an anatomy-informed diffusion framework that reconstructs pseudo-healthy MRIs directly from tumorous scans by conditioning the generative process on boundary cues extracted from the subject's own anatomy. This boundary-guided conditioning enables anatomically plausible pseudo-healthy reconstruction without requiring paired non-tumorous and tumorous scans. BrainNormalizer employs a two-stage training strategy. The pretrained diffusion model is first adapted through inpainting-based fine-tuning on tumorous and non-tumorous scans. Next, an edge-map-guided ControlNet branch is trained to inject fine-grained anatomical contours into the frozen decoder while preserving learned priors. During inference, a deliberate misalignment strategy pairs tumorous inputs with non-tumorous prompts and mirrored contralateral edge maps, leveraging hemispheric correspondence to guide reconstruction. On the BraTS2020 dataset, BrainNormalizer achieves strong quantitative performance and qualitatively produces anatomically plausible reconstructions in tumor-affected regions while retaining overall structural coherence. BrainNormalizer provides clinically reliable anatomical references for treatment planning and supports new research directions in counterfactual modeling and tumor-induced deformation analysis.", "AI": {"tldr": "BrainNormalizer\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u80bf\u7624MRI\u76f4\u63a5\u91cd\u5efa\u4f2a\u5065\u5eb7MRI\uff0c\u4e3a\u4e34\u5e8a\u6cbb\u7597\u89c4\u5212\u63d0\u4f9b\u89e3\u5256\u5b66\u53c2\u8003\u3002", "motivation": "\u8111\u80bf\u7624\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u89e3\u5256\u53d8\u5f62\uff0c\u4f46\u4e34\u5e8a\u4e0a\u65e0\u6cd5\u83b7\u5f97\u65e0\u80bf\u7624\u7684\u4e2a\u4f53\u7279\u5f02\u6027\u53c2\u8003\u56fe\u50cf\uff0c\u8fd9\u7ed9\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u5e26\u6765\u56f0\u96be\u3002", "method": "\u91c7\u7528\u8fb9\u754c\u5f15\u5bfc\u7684\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u9996\u5148\u8fdb\u884c\u57fa\u4e8e\u4fee\u590d\u7684\u5fae\u8c03\uff0c\u7136\u540e\u8bad\u7ec3\u8fb9\u7f18\u56fe\u5f15\u5bfc\u7684ControlNet\u5206\u652f\uff0c\u5728\u63a8\u7406\u65f6\u5229\u7528\u955c\u50cf\u5bf9\u4fa7\u8fb9\u7f18\u56fe\u548c\u9519\u4f4d\u7b56\u7565\u3002", "result": "\u5728BraTS2020\u6570\u636e\u96c6\u4e0a\uff0cBrainNormalizer\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u5b9a\u91cf\u6027\u80fd\uff0c\u5e76\u5728\u80bf\u7624\u533a\u57df\u4ea7\u751f\u89e3\u5256\u5b66\u4e0a\u5408\u7406\u7684\u91cd\u5efa\uff0c\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7ed3\u6784\u4e00\u81f4\u6027\u3002", "conclusion": "BrainNormalizer\u4e3a\u6cbb\u7597\u89c4\u5212\u63d0\u4f9b\u4e34\u5e8a\u53ef\u9760\u7684\u89e3\u5256\u53c2\u8003\uff0c\u5e76\u652f\u6301\u53cd\u4e8b\u5b9e\u5efa\u6a21\u548c\u80bf\u7624\u8bf1\u5bfc\u53d8\u5f62\u5206\u6790\u7684\u65b0\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.12478", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12478", "abs": "https://arxiv.org/abs/2511.12478", "authors": ["Mahdi Pirayesh Shirazi Nejad", "David Hicks", "Matt Valentine", "Ki H. Chon"], "title": "Lightweight Deep Autoencoder for ECG Denoising with Morphology Preservation and Near Real-Time Hardware Deployment", "comment": null, "summary": "Electrocardiogram (ECG) signals are often degraded by various noise sources such as baseline wander, motion artifacts, and electromyographic interference, posing a major challenge in clinical settings. This paper presents a lightweight deep learning-based denoising framework, forming a compact autoencoder architecture. The model was trained under severe noise conditions (-5 dB signal-to-noise ratio (SNR)) using a rigorously partitioned dataset to ensure no data leakage and robust generalization. Extensive evaluations were conducted across seven noise configurations and three SNR levels (-5 dB, 0 dB, and +5 dB), showing consistent denoising performance with minimal morphological distortion, critical for maintaining diagnostic integrity. In particular, tests on clinically vital rhythms such as ventricular tachycardia (VT) and ventricular fibrillation (VF) confirm that the proposed model effectively suppresses noise without altering arrhythmic features essential for diagnosis. Visual and quantitative assessments, including SNR improvement, RMSE, and correlation metrics, validate the model's efficacy in preserving waveform fidelity. To demonstrate real-world applicability, the model was deployed on a Raspberry Pi 4 using TensorFlow Lite with float16 precision. Inference latency was measured at just 1.41 seconds per 14-second ECG segment, indicating feasibility for near-real-time use in edge devices. Overall, this study introduces a lightweight, hardware-validated, and morphologically reliable ECG denoising solution suitable for integration into portable or wearable healthcare systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u53bb\u566a\u6846\u67b6\uff0c\u91c7\u7528\u7d27\u51d1\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5728-5 dB\u5f3a\u566a\u58f0\u6761\u4ef6\u4e0b\u8bad\u7ec3\uff0c\u5728\u591a\u79cd\u566a\u58f0\u914d\u7f6e\u548cSNR\u6c34\u5e73\u4e0b\u5747\u8868\u73b0\u7a33\u5b9a\uff0c\u80fd\u6709\u6548\u6291\u5236\u566a\u58f0\u540c\u65f6\u4fdd\u6301\u5fc3\u7535\u56fe\u5f62\u6001\u5b8c\u6574\u6027\uff0c\u5e76\u5728\u6811\u8393\u6d3e4\u4e0a\u9a8c\u8bc1\u4e86\u8fb9\u7f18\u90e8\u7f72\u53ef\u884c\u6027\u3002", "motivation": "\u5fc3\u7535\u56fe\u4fe1\u53f7\u5e38\u53d7\u57fa\u7ebf\u6f02\u79fb\u3001\u8fd0\u52a8\u4f2a\u5f71\u548c\u808c\u7535\u5e72\u6270\u7b49\u591a\u79cd\u566a\u58f0\u6c61\u67d3\uff0c\u4e25\u91cd\u5f71\u54cd\u4e34\u5e8a\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u4e14\u80fd\u4fdd\u6301\u6ce2\u5f62\u5f62\u6001\u7684\u53bb\u566a\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u7d27\u51d1\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5728-5 dB\u5f3a\u566a\u58f0\u6761\u4ef6\u4e0b\u8bad\u7ec3\uff0c\u4f7f\u7528\u4e25\u683c\u5212\u5206\u7684\u6570\u636e\u96c6\u9632\u6b62\u6570\u636e\u6cc4\u6f0f\uff0c\u5728\u4e03\u79cd\u566a\u58f0\u914d\u7f6e\u548c\u4e09\u4e2aSNR\u6c34\u5e73(-5 dB\u30010 dB\u3001+5 dB)\u4e0b\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5728\u6240\u6709\u6d4b\u8bd5\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u4e00\u81f4\u7684\u53bb\u566a\u6027\u80fd\uff0c\u5bf9\u5fc3\u5ba4\u5fc3\u52a8\u8fc7\u901f\u548c\u5fc3\u5ba4\u98a4\u52a8\u7b49\u5173\u952e\u5fc3\u5f8b\u80fd\u6709\u6548\u6291\u5236\u566a\u58f0\u800c\u4e0d\u6539\u53d8\u8bca\u65ad\u5fc5\u9700\u7684\u8282\u5f8b\u7279\u5f81\uff0c\u5728\u6811\u8393\u6d3e4\u4e0a\u63a8\u7406\u5ef6\u8fdf\u4ec5\u4e3a1.41\u79d2/14\u79d2ECG\u6bb5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u786c\u4ef6\u9a8c\u8bc1\u4e14\u5f62\u6001\u53ef\u9760\u7684ECG\u53bb\u566a\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u96c6\u6210\u5230\u4fbf\u643a\u5f0f\u6216\u53ef\u7a7f\u6234\u533b\u7597\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2511.12931", "categories": ["eess.IV", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2511.12931", "abs": "https://arxiv.org/abs/2511.12931", "authors": ["Zain Shabeeb", "Daniel Saeedi", "Darin Tsui", "Vida Jamali", "Amirali Aghazadeh"], "title": "cryoSENSE: Compressive Sensing Enables High-throughput Microscopy with Sparse and Generative Priors on the Protein Cryo-EM Image Manifold", "comment": null, "summary": "Cryo-electron microscopy (cryo-EM) enables the atomic-resolution visualization of biomolecules; however, modern direct detectors generate data volumes that far exceed the available storage and transfer bandwidth, thereby constraining practical throughput. We introduce cryoSENSE, the computational realization of a hardware-software co-designed framework for compressive cryo-EM sensing and acquisition. We show that cryo-EM images of proteins lie on low-dimensional manifolds that can be independently represented using sparse priors in predefined bases and generative priors captured by a denoising diffusion model. cryoSENSE leverages these low-dimensional manifolds to enable faithful image reconstruction from spatial and Fourier-domain undersampled measurements while preserving downstream structural resolution. In experiments, cryoSENSE increases acquisition throughput by up to 2.5$\\times$ while retaining the original 3D resolution, offering controllable trade-offs between the number of masked measurements and the level of downsampling. Sparse priors favor faithful reconstruction from Fourier-domain measurements and moderate compression, whereas generative diffusion priors achieve accurate recovery from pixel-domain measurements and more severe undersampling. Project website: https://cryosense.github.io.", "AI": {"tldr": "cryoSENSE\u662f\u4e00\u4e2a\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u538b\u7f29\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u51b7\u51bb\u7535\u955c\u56fe\u50cf\u7684\u4f4e\u7ef4\u6d41\u5f62\u7279\u6027\uff0c\u5728\u7a7a\u95f4\u57df\u548c\u5085\u91cc\u53f6\u57df\u8fdb\u884c\u6b20\u91c7\u6837\uff0c\u5b9e\u73b0\u9ad8\u8fbe2.5\u500d\u7684\u91c7\u96c6\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb3D\u5206\u8fa8\u7387\u3002", "motivation": "\u73b0\u4ee3\u76f4\u63a5\u63a2\u6d4b\u5668\u4ea7\u751f\u7684\u51b7\u51bb\u7535\u955c\u6570\u636e\u91cf\u8fdc\u8d85\u5b58\u50a8\u548c\u4f20\u8f93\u5e26\u5bbd\u9650\u5236\uff0c\u5236\u7ea6\u4e86\u5b9e\u9645\u91c7\u96c6\u6548\u7387\u3002\u9700\u8981\u5f00\u53d1\u538b\u7f29\u611f\u77e5\u65b9\u6cd5\u6765\u51cf\u5c11\u6570\u636e\u91cf\u540c\u65f6\u4fdd\u6301\u7ed3\u6784\u5206\u8fa8\u7387\u3002", "method": "\u5229\u7528\u86cb\u767d\u8d28\u51b7\u51bb\u7535\u955c\u56fe\u50cf\u7684\u4f4e\u7ef4\u6d41\u5f62\u7279\u6027\uff0c\u5728\u9884\u5b9a\u4e49\u57fa\u4e0a\u4f7f\u7528\u7a00\u758f\u5148\u9a8c\u548c\u901a\u8fc7\u53bb\u566a\u6269\u6563\u6a21\u578b\u6355\u83b7\u7684\u751f\u6210\u5148\u9a8c\uff0c\u4ece\u7a7a\u95f4\u57df\u548c\u5085\u91cc\u53f6\u57df\u7684\u6b20\u91c7\u6837\u6d4b\u91cf\u4e2d\u91cd\u5efa\u56fe\u50cf\u3002", "result": "cryoSENSE\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.5\u500d\u7684\u91c7\u96c6\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb3D\u5206\u8fa8\u7387\u3002\u7a00\u758f\u5148\u9a8c\u5728\u5085\u91cc\u53f6\u57df\u6d4b\u91cf\u548c\u4e2d\u7b49\u538b\u7f29\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u800c\u751f\u6210\u6269\u6563\u5148\u9a8c\u5728\u50cf\u7d20\u57df\u6d4b\u91cf\u548c\u66f4\u4e25\u91cd\u6b20\u91c7\u6837\u4e0b\u5b9e\u73b0\u51c6\u786e\u6062\u590d\u3002", "conclusion": "cryoSENSE\u901a\u8fc7\u538b\u7f29\u611f\u77e5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u51b7\u51bb\u7535\u955c\u6570\u636e\u5b58\u50a8\u548c\u4f20\u8f93\u74f6\u9888\uff0c\u4e3a\u9ad8\u5206\u8fa8\u7387\u7ed3\u6784\u751f\u7269\u5b66\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9ad8\u901a\u91cf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12508", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12508", "abs": "https://arxiv.org/abs/2511.12508", "authors": ["Yanhao Wang", "Lei Wang", "Jie Wang", "Yimin Liu"], "title": "Robust Radar HRRP Recognition under Non-uniform Jamming Based on Complex-valued Frequency Attention Network", "comment": null, "summary": "Complex electromagnetic environments, often containing multiple jammers with different jamming patterns, produce non-uniform jamming power across the frequency spectrum. This spectral non-uniformity directly induces severe distortion in the target's HRRP, consequently compromising the performance and reliability of conventional HRRP-based target recognition methods. This paper proposes a novel, end-to-end trained network for robust radar target recognition. The core of our model is a CFA module that operates directly on the complex spectrum of the received echo. The CFA module learns to generate an adaptive frequency-domain filter, assigning lower weights to bands corrupted by strong jamming while preserving critical target information in cleaner bands. The filtered spectrum is then fed into a classifier backbone for recognition. Experimental results on simulated HRRP data with various jamming combinations demonstrate our method's superiority. Notably, under severe jamming conditions, our model achieves a recognition accuracy nearly 9% higher than traditional model-based approaches, all while introducing negligible computational overhead. This highlights its exceptional performance and robustness in challenging jamming environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u96f7\u8fbe\u76ee\u6807\u8bc6\u522b\u7f51\u7edc\uff0c\u901a\u8fc7CFA\u6a21\u5757\u5728\u590d\u6570\u9891\u8c31\u4e0a\u751f\u6210\u81ea\u9002\u5e94\u6ee4\u6ce2\u5668\uff0c\u6291\u5236\u5f3a\u5e72\u6270\u9891\u6bb5\u5e76\u4fdd\u7559\u76ee\u6807\u4fe1\u606f\uff0c\u5728\u4e25\u91cd\u5e72\u6270\u73af\u5883\u4e0b\u6bd4\u4f20\u7edf\u65b9\u6cd5\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u9ad8\u8fd19%\u3002", "motivation": "\u590d\u6742\u7535\u78c1\u73af\u5883\u4e2d\u591a\u79cd\u5e72\u6270\u6e90\u5bfc\u81f4\u9891\u8c31\u529f\u7387\u4e0d\u5747\u5300\uff0c\u4e25\u91cd\u626d\u66f2\u76ee\u6807\u9ad8\u5206\u8fa8\u7387\u8ddd\u79bb\u50cf(HRRP)\uff0c\u5f71\u54cd\u4f20\u7edfHRRP\u76ee\u6807\u8bc6\u522b\u65b9\u6cd5\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "method": "\u8bbe\u8ba1CFA\u6a21\u5757\u76f4\u63a5\u5728\u63a5\u6536\u56de\u6ce2\u7684\u590d\u6570\u9891\u8c31\u4e0a\u64cd\u4f5c\uff0c\u5b66\u4e60\u751f\u6210\u81ea\u9002\u5e94\u9891\u57df\u6ee4\u6ce2\u5668\uff0c\u5bf9\u5f3a\u5e72\u6270\u9891\u6bb5\u8d4b\u4e88\u8f83\u4f4e\u6743\u91cd\uff0c\u540c\u65f6\u4fdd\u7559\u5e72\u51c0\u9891\u6bb5\u4e2d\u7684\u5173\u952e\u76ee\u6807\u4fe1\u606f\uff0c\u6ee4\u6ce2\u540e\u7684\u9891\u8c31\u9001\u5165\u5206\u7c7b\u5668\u8fdb\u884c\u8bc6\u522b\u3002", "result": "\u5728\u5305\u542b\u591a\u79cd\u5e72\u6270\u7ec4\u5408\u7684\u6a21\u62dfHRRP\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e25\u91cd\u5e72\u6270\u6761\u4ef6\u4e0b\u6bd4\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u9ad8\u8fd19%\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6311\u6218\u6027\u5e72\u6270\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u590d\u6742\u7535\u78c1\u73af\u5883\u4e0b\u7684\u96f7\u8fbe\u76ee\u6807\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12961", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12961", "abs": "https://arxiv.org/abs/2511.12961", "authors": ["Pritam P. Karmokar", "William J. Beksi"], "title": "Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation", "comment": "13 pages, 9 figures, and 3 tables", "summary": "Event cameras, by virtue of their working principle, directly encode motion within a scene. Many learning-based and model-based methods exist that estimate event-based optical flow, however the temporally dense yet spatially sparse nature of events poses significant challenges. To address these issues, contrast maximization (CM) is a prominent model-based optimization methodology that estimates the motion trajectories of events within an event volume by optimally warping them. Since its introduction, the CM framework has undergone a series of refinements by the computer vision community. Nonetheless, it remains a highly non-convex optimization problem. In this paper, we introduce a novel biologically-inspired hybrid CM method for event-based optical flow estimation that couples visual and inertial motion cues. Concretely, we propose the use of orientation maps, derived from camera 3D velocities, as priors to guide the CM process. The orientation maps provide directional guidance and constrain the space of estimated motion trajectories. We show that this orientation-guided formulation leads to improved robustness and convergence in event-based optical flow estimation. The evaluation of our approach on the MVSEC, DSEC, and ECD datasets yields superior accuracy scores over the state of the art.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6bd4\u5ea6\u6700\u5927\u5316\u7684\u751f\u7269\u542f\u53d1\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u60ef\u6027\u8fd0\u52a8\u7ebf\u7d22\u6765\u4f30\u8ba1\u4e8b\u4ef6\u76f8\u673a\u7684\u5149\u6d41\uff0c\u901a\u8fc7\u65b9\u5411\u56fe\u5f15\u5bfc\u4f18\u5316\u8fc7\u7a0b\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u6536\u655b\u6027\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u76f4\u63a5\u7f16\u7801\u573a\u666f\u4e2d\u7684\u8fd0\u52a8\uff0c\u4f46\u4e8b\u4ef6\u6570\u636e\u5728\u65f6\u95f4\u4e0a\u5bc6\u96c6\u800c\u7a7a\u95f4\u4e0a\u7a00\u758f\u7684\u7279\u6027\u7ed9\u5149\u6d41\u4f30\u8ba1\u5e26\u6765\u6311\u6218\u3002\u5bf9\u6bd4\u5ea6\u6700\u5927\u5316\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u4ecd\u662f\u4e00\u4e2a\u9ad8\u5ea6\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u5bf9\u6bd4\u5ea6\u6700\u5927\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u4ece\u76f8\u673a3D\u901f\u5ea6\u5bfc\u51fa\u7684\u65b9\u5411\u56fe\u4f5c\u4e3a\u5148\u9a8c\u6765\u5f15\u5bfc\u5bf9\u6bd4\u5ea6\u6700\u5927\u5316\u8fc7\u7a0b\uff0c\u4e3a\u8fd0\u52a8\u8f68\u8ff9\u4f30\u8ba1\u63d0\u4f9b\u65b9\u5411\u6307\u5bfc\u548c\u7ea6\u675f\u3002", "result": "\u5728MVSEC\u3001DSEC\u548cECD\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u65b9\u5411\u56fe\u5f15\u5bfc\u7684\u5bf9\u6bd4\u5ea6\u6700\u5927\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u4ef6\u76f8\u673a\u5149\u6d41\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\u548c\u6536\u655b\u6027\uff0c\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u7cbe\u5ea6\u8868\u73b0\u3002"}}
{"id": "2511.12540", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12540", "abs": "https://arxiv.org/abs/2511.12540", "authors": ["Dimitris Antoniadis", "Timothy G. Constandinou"], "title": "A mixed-signal analogue front-end for brain-implantable neural interfaces using a digital fixed-point IIR filter and bulk offset cancellation", "comment": "4 pages plus 1 references IEEE conference style", "summary": "Advances in miniaturised implantable neural electronics have paved the way for therapeutic brain-computer interfaces with clinical potential for movement disorders, epilepsy, and broader neurological applications. This paper presents a mixed-signal analogue front end (AFE) designed to record both extracellular action potentials (EAPs) and local field potentials (LFPs). The feedforward path integrates a low-noise amplifier (LNA) and a successive-approximation-register (SAR) analogue-to-digital converter (ADC), while the feedback path employs a fixed-point infinite-impulse-response (IIR) Chebyshev Type II low-pass filter to suppress sub-mHz components via bulk-voltage control of the LNA input differential pair using two R-2R pseudo-resistor digital-to-analogue converters (DACs). The proposed AFE achieves up to 41.42dB gain, consumes 2.178uA per channel, occupies 0.198mm2 per channel, and supports neural signal monitoring from 0.1Hz to 10kHz with 3.59uVrms input-referred integrated noise.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u4fe1\u53f7\u6a21\u62df\u524d\u7aef\uff0c\u7528\u4e8e\u540c\u65f6\u8bb0\u5f55\u7ec6\u80de\u5916\u52a8\u4f5c\u7535\u4f4d\u548c\u5c40\u90e8\u573a\u7535\u4f4d\uff0c\u96c6\u6210\u4e86\u4f4e\u566a\u58f0\u653e\u5927\u5668\u3001SAR ADC\u548c\u53cd\u9988\u8def\u5f84\u7684IIR\u6ee4\u6ce2\u5668\uff0c\u5b9e\u73b0\u4e86\u4f4e\u529f\u8017\u3001\u5c0f\u9762\u79ef\u7684\u9ad8\u6027\u80fd\u795e\u7ecf\u4fe1\u53f7\u76d1\u6d4b\u3002", "motivation": "\u968f\u7740\u5fae\u578b\u690d\u5165\u5f0f\u795e\u7ecf\u7535\u5b50\u8bbe\u5907\u7684\u53d1\u5c55\uff0c\u8111\u673a\u63a5\u53e3\u5728\u8fd0\u52a8\u969c\u788d\u3001\u766b\u75eb\u7b49\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u7684\u6cbb\u7597\u4e2d\u5c55\u73b0\u51fa\u4e34\u5e8a\u6f5c\u529b\uff0c\u9700\u8981\u80fd\u591f\u540c\u65f6\u8bb0\u5f55\u4e0d\u540c\u7c7b\u578b\u795e\u7ecf\u4fe1\u53f7\u7684\u9ad8\u6027\u80fd\u6a21\u62df\u524d\u7aef\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4fe1\u53f7\u8bbe\u8ba1\uff0c\u524d\u5411\u8def\u5f84\u5305\u542b\u4f4e\u566a\u58f0\u653e\u5927\u5668\u548c\u9010\u6b21\u903c\u8fd1\u5bc4\u5b58\u5668ADC\uff0c\u53cd\u9988\u8def\u5f84\u4f7f\u7528\u56fa\u5b9a\u70b9\u65e0\u9650\u8109\u51b2\u54cd\u5e94\u5207\u6bd4\u96ea\u592bII\u578b\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7R-2R\u4f2a\u7535\u963bDAC\u63a7\u5236LNA\u8f93\u5165\u5dee\u5206\u5bf9\u6765\u6291\u5236\u4e9a\u6beb\u8d6b\u5179\u5206\u91cf\u3002", "result": "\u8be5\u6a21\u62df\u524d\u7aef\u5b9e\u73b0\u4e8641.42dB\u589e\u76ca\uff0c\u6bcf\u901a\u9053\u529f\u80172.178\u03bcA\uff0c\u9762\u79ef0.198mm\u00b2\uff0c\u652f\u63010.1Hz\u81f310kHz\u7684\u795e\u7ecf\u4fe1\u53f7\u76d1\u6d4b\uff0c\u8f93\u5165\u53c2\u8003\u79ef\u5206\u566a\u58f0\u4e3a3.59\u03bcVrms\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u62df\u524d\u7aef\u8bbe\u8ba1\u5728\u529f\u8017\u3001\u9762\u79ef\u548c\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u690d\u5165\u5f0f\u8111\u673a\u63a5\u53e3\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.13310", "categories": ["eess.IV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.13310", "abs": "https://arxiv.org/abs/2511.13310", "authors": ["Marijn Borghouts", "Ruisheng Su"], "title": "PyPeT: A Python Perfusion Tool for Automated Quantitative Brain CT and MR Perfusion Analysis", "comment": null, "summary": "Computed tomography perfusion (CTP) and magnetic resonance perfusion (MRP) are widely used in acute ischemic stroke assessment and other cerebrovascular conditions to generate quantitative maps of cerebral hemodynamics. While commercial perfusion analysis software exists, it is often costly, closed source, and lacks customizability. This work introduces PyPeT, an openly available Python Perfusion Tool for head CTP and MRP processing. PyPeT is capable of producing cerebral blood flow (CBF), cerebral blood volume (CBV), mean transit time (MTT), time-to-peak (TTP), and time-to-maximum (Tmax) maps from raw four-dimensional perfusion data. PyPeT aims to make perfusion research as accessible and customizable as possible. This is achieved through a unified framework in which both CTP and MRP data can be processed, with a strong focus on modularity, low computational burden, and significant inline documentation. PyPeT's outputs can be validated through an extensive debug mode in which every step of the process is visualized. Additional validation was performed via visual and quantitative comparison with reference perfusion maps generated by three FDA-approved commercial perfusion tools and a research tool. These comparisons show a mean SSIM around 0.8 for all comparisons, indicating a good and stable correlation with FDA-approved tools. The code for PyPeT is openly available at our GitHub https://github.com/Marijn311/CT-and-MR-Perfusion-Tool", "AI": {"tldr": "PyPeT\u662f\u4e00\u4e2a\u5f00\u6e90\u7684Python\u8111\u704c\u6ce8\u5904\u7406\u5de5\u5177\uff0c\u7528\u4e8eCT\u548cMR\u704c\u6ce8\u6570\u636e\u7684\u5206\u6790\uff0c\u80fd\u591f\u751f\u6210\u591a\u79cd\u8111\u8840\u6d41\u52a8\u529b\u5b66\u53c2\u6570\u56fe\uff0c\u5e76\u4e0eFDA\u6279\u51c6\u7684\u5546\u4e1a\u8f6f\u4ef6\u5177\u6709\u826f\u597d\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5546\u4e1a\u704c\u6ce8\u5206\u6790\u8f6f\u4ef6\u6210\u672c\u9ad8\u3001\u95ed\u6e90\u4e14\u7f3a\u4e4f\u53ef\u5b9a\u5236\u6027\uff0c\u9650\u5236\u4e86\u704c\u6ce8\u7814\u7a76\u7684\u53ef\u53ca\u6027\u548c\u7075\u6d3b\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684Python\u6846\u67b6\uff0c\u652f\u6301CT\u548cMR\u704c\u6ce8\u6570\u636e\u5904\u7406\uff0c\u5f3a\u8c03\u6a21\u5757\u5316\u3001\u4f4e\u8ba1\u7b97\u8d1f\u62c5\u548c\u8be6\u7ec6\u7684\u5185\u8054\u6587\u6863\uff0c\u5305\u542b\u5e7f\u6cdb\u7684\u8c03\u8bd5\u6a21\u5f0f\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u4e0e\u4e09\u79cdFDA\u6279\u51c6\u7684\u5546\u4e1a\u704c\u6ce8\u5de5\u5177\u548c\u7814\u7a76\u5de5\u5177\u8fdb\u884c\u89c6\u89c9\u548c\u5b9a\u91cf\u6bd4\u8f83\uff0c\u663e\u793a\u5e73\u5747SSIM\u7ea6\u4e3a0.8\uff0c\u8868\u660e\u4e0eFDA\u6279\u51c6\u5de5\u5177\u6709\u826f\u597d\u7684\u7a33\u5b9a\u76f8\u5173\u6027\u3002", "conclusion": "PyPeT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u8bbf\u95ee\u3001\u53ef\u5b9a\u5236\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u704c\u6ce8\u7814\u7a76\u66f4\u52a0\u6c11\u4e3b\u5316\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u4e0a\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2511.12733", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12733", "abs": "https://arxiv.org/abs/2511.12733", "authors": ["Ahmed Hussain", "Ahmed Sultan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil"], "title": "Near Field Tapering with Slepian Window: Balancing the Range Angle Sidelobe Trade off", "comment": null, "summary": "Near-field beamforming enables target discrimination in both range (axial) and angle (lateral) dimensions. Elevated sidelobes along either dimension, however, increase susceptibility to interference and degrade detection performance. Conventional amplitude tapering techniques, designed for far-field scenarios, cannot simultaneously suppress axial and lateral sidelobes in near-field. In this letter, we propose a Slepian-based amplitude tapering approach that maximizes mainlobe energy concentration, achieving significant sidelobe reduction in both dimensions. Numerical results show that the proposed taper improves peak sidelobe suppression by approximately 24 dB in the lateral domain and 10 dB in the axial domain compared to a conventional uniform window.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSlepian\u7684\u5e45\u5ea6\u9525\u524a\u65b9\u6cd5\uff0c\u7528\u4e8e\u8fd1\u573a\u6ce2\u675f\u6210\u5f62\uff0c\u80fd\u540c\u65f6\u6291\u5236\u8f74\u5411\u548c\u6a2a\u5411\u65c1\u74e3\uff0c\u76f8\u6bd4\u4f20\u7edf\u5747\u5300\u7a97\u53e3\u5728\u6a2a\u5411\u548c\u8f74\u5411\u5206\u522b\u5b9e\u73b0\u4e86\u7ea624dB\u548c10dB\u7684\u5cf0\u503c\u65c1\u74e3\u6291\u5236\u63d0\u5347\u3002", "motivation": "\u8fd1\u573a\u6ce2\u675f\u6210\u5f62\u80fd\u5728\u8ddd\u79bb\uff08\u8f74\u5411\uff09\u548c\u89d2\u5ea6\uff08\u6a2a\u5411\uff09\u7ef4\u5ea6\u5b9e\u73b0\u76ee\u6807\u8bc6\u522b\uff0c\u4f46\u4efb\u4e00\u7ef4\u5ea6\u7684\u8fc7\u9ad8\u65c1\u74e3\u4f1a\u589e\u52a0\u5e72\u6270\u654f\u611f\u6027\u5e76\u964d\u4f4e\u68c0\u6d4b\u6027\u80fd\u3002\u4f20\u7edf\u7684\u5e45\u5ea6\u9525\u524a\u6280\u672f\u8bbe\u8ba1\u7528\u4e8e\u8fdc\u573a\u573a\u666f\uff0c\u65e0\u6cd5\u540c\u65f6\u6291\u5236\u8fd1\u573a\u4e2d\u7684\u8f74\u5411\u548c\u6a2a\u5411\u65c1\u74e3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eSlepian\u7684\u5e45\u5ea6\u9525\u524a\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4e3b\u74e3\u80fd\u91cf\u96c6\u4e2d\u5ea6\u6765\u5b9e\u73b0\u4e24\u4e2a\u7ef4\u5ea6\u7684\u663e\u8457\u65c1\u74e3\u6291\u5236\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u5747\u5300\u7a97\u53e3\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u9525\u524a\u65b9\u6cd5\u5728\u6a2a\u5411\u57df\u6539\u5584\u4e86\u7ea624dB\u7684\u5cf0\u503c\u65c1\u74e3\u6291\u5236\uff0c\u5728\u8f74\u5411\u57df\u6539\u5584\u4e86\u7ea610dB\u7684\u5cf0\u503c\u65c1\u74e3\u6291\u5236\u3002", "conclusion": "Slepian-based\u5e45\u5ea6\u9525\u524a\u65b9\u6cd5\u80fd\u6709\u6548\u540c\u65f6\u6291\u5236\u8fd1\u573a\u6ce2\u675f\u6210\u5f62\u4e2d\u7684\u8f74\u5411\u548c\u6a2a\u5411\u65c1\u74e3\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.13628", "categories": ["eess.IV", "eess.SP", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.13628", "abs": "https://arxiv.org/abs/2511.13628", "authors": ["Alexander Mertens", "Diego Martinez", "Amgad Louka", "Ying Yang", "Chad Harris", "Ian Connell"], "title": "Smooth Total variation Regularization for Interference Detection and Elimination (STRIDE) for MRI", "comment": null, "summary": "MRI is increasingly desired to function near electronic devices that emit potentially dynamic electromagnetic interference (EMI). To accommodate for this, we propose the STRIDE method, which improves on previous external-sensor-based EMI removal methods by exploiting inherent MR image smoothness in its total variation. STRIDE measures data from both EMI detectors and primary MR imaging coils, transforms this data into the image domain, and for each column of the resulting image array, combines and subtracts data from the EMI detectors in a way that optimizes for total-variation smoothness. Performance was tested on phantom and in-vivo datasets with a 0.5T scanner. STRIDE resulted in visually better EMI removal, higher temporal SNR, larger EMI removal percentage, and lower RMSE than standard implementations. STRIDE is a robust technique that leverages inherent MR image properties to provide improved EMI removal performance over standard algorithms, particularly for time-varying noise sources.", "AI": {"tldr": "STRIDE\u65b9\u6cd5\u901a\u8fc7\u5229\u7528MRI\u56fe\u50cf\u7684\u603b\u53d8\u5206\u5e73\u6ed1\u6027\u6765\u6539\u8fdb\u5916\u90e8\u4f20\u611f\u5668\u7535\u78c1\u5e72\u6270\u53bb\u9664\uff0c\u57280.5T\u626b\u63cf\u4eea\u4e0a\u6d4b\u8bd5\u663e\u793a\u6bd4\u6807\u51c6\u65b9\u6cd5\u66f4\u597d\u7684EMI\u53bb\u9664\u6548\u679c\u3002", "motivation": "MRI\u9700\u8981\u80fd\u591f\u5728\u53d1\u5c04\u52a8\u6001\u7535\u78c1\u5e72\u6270\u7684\u7535\u5b50\u8bbe\u5907\u9644\u8fd1\u5de5\u4f5c\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u73b0\u6709\u7684\u5916\u90e8\u4f20\u611f\u5668EMI\u53bb\u9664\u65b9\u6cd5\u3002", "method": "STRIDE\u65b9\u6cd5\u540c\u65f6\u6d4b\u91cfEMI\u68c0\u6d4b\u5668\u548c\u4e3b\u8981MR\u6210\u50cf\u7ebf\u5708\u7684\u6570\u636e\uff0c\u5c06\u6570\u636e\u8f6c\u6362\u5230\u56fe\u50cf\u57df\uff0c\u5bf9\u6bcf\u4e2a\u56fe\u50cf\u9635\u5217\u5217\u7ed3\u5408\u5e76\u51cf\u53bbEMI\u68c0\u6d4b\u5668\u6570\u636e\uff0c\u4ee5\u4f18\u5316\u603b\u53d8\u5206\u5e73\u6ed1\u6027\u3002", "result": "\u5728\u4f53\u6a21\u548c\u4f53\u5185\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u663e\u793a\uff0cSTRIDE\u5728\u89c6\u89c9EMI\u53bb\u9664\u3001\u65f6\u95f4\u4fe1\u566a\u6bd4\u3001EMI\u53bb\u9664\u767e\u5206\u6bd4\u548cRMSE\u65b9\u9762\u5747\u4f18\u4e8e\u6807\u51c6\u5b9e\u73b0\u3002", "conclusion": "STRIDE\u662f\u4e00\u79cd\u9c81\u68d2\u6280\u672f\uff0c\u5229\u7528\u56fa\u6709\u7684MR\u56fe\u50cf\u7279\u6027\u63d0\u4f9b\u6bd4\u6807\u51c6\u7b97\u6cd5\u66f4\u597d\u7684EMI\u53bb\u9664\u6027\u80fd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u65f6\u53d8\u566a\u58f0\u6e90\u3002"}}
{"id": "2511.12750", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.12750", "abs": "https://arxiv.org/abs/2511.12750", "authors": ["Ahmed Hussain", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil"], "title": "Uniform Circular Arrays in Near-Field: Omnidirectional Coverage with Limited Capacity", "comment": null, "summary": "Recent studies suggest that uniform circular arrays (UCAs) can extend the angular coverage of the radiative near field region. This work investigates whether such enhanced angular coverage translates into improved spatial multiplexing performance when compared to uniform linear arrays (ULAs). To more accurately delineate the effective near field region, we introduce the effective beamfocusing Rayleigh distance (EBRD), an angle dependent metric that bounds the spatial region where beamfocusing remains effective. Closed form expressions for both beamdepth and EBRD are derived for UCAs. Our analysis shows that, under a fixed antenna element count, ULAs achieve narrower beamdepth and a longer EBRD than UCAs. Conversely, under a fixed aperture length, UCAs provide slightly narrower beamdepth and a marginally longer EBRD. Simulation results further confirm that ULAs achieve higher sum rate under the fixed element constraint, while UCAs offer marginal performance gain under the fixed aperture constraint.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5747\u5300\u5706\u5f62\u9635\u5217(UCA)\u4e0e\u5747\u5300\u7ebf\u6027\u9635\u5217(ULA)\u5728\u7a7a\u95f4\u590d\u7528\u6027\u80fd\u65b9\u9762\u7684\u6bd4\u8f83\uff0c\u5f15\u5165\u4e86\u6709\u6548\u6ce2\u675f\u805a\u7126\u745e\u5229\u8ddd\u79bb(EBRD)\u6765\u66f4\u51c6\u786e\u754c\u5b9a\u8fd1\u573a\u533a\u57df\u3002", "motivation": "\u8fd1\u671f\u7814\u7a76\u8868\u660eUCA\u53ef\u4ee5\u6269\u5c55\u8f90\u5c04\u8fd1\u573a\u533a\u57df\u7684\u89d2\u8986\u76d6\u8303\u56f4\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7a76\u8fd9\u79cd\u589e\u5f3a\u7684\u89d2\u8986\u76d6\u662f\u5426\u80fd\u8f6c\u5316\u4e3a\u6bd4ULA\u66f4\u597d\u7684\u7a7a\u95f4\u590d\u7528\u6027\u80fd\u3002", "method": "\u5f15\u5165\u4e86\u89d2\u5ea6\u76f8\u5173\u7684\u6709\u6548\u6ce2\u675f\u805a\u7126\u745e\u5229\u8ddd\u79bb(EBRD)\u6307\u6807\uff0c\u63a8\u5bfc\u4e86UCA\u7684\u6ce2\u675f\u6df1\u5ea6\u548cEBRD\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u6bd4\u8f83\u4e24\u79cd\u9635\u5217\u7684\u6027\u80fd\u3002", "result": "\u5728\u56fa\u5b9a\u5929\u7ebf\u5143\u7d20\u6570\u91cf\u4e0b\uff0cULA\u5b9e\u73b0\u66f4\u7a84\u7684\u6ce2\u675f\u6df1\u5ea6\u548c\u66f4\u957f\u7684EBRD\uff1b\u5728\u56fa\u5b9a\u5b54\u5f84\u957f\u5ea6\u4e0b\uff0cUCA\u63d0\u4f9b\u7a0d\u7a84\u7684\u6ce2\u675f\u6df1\u5ea6\u548c\u7565\u957f\u7684EBRD\u3002ULA\u5728\u56fa\u5b9a\u5143\u7d20\u7ea6\u675f\u4e0b\u83b7\u5f97\u66f4\u9ad8\u548c\u901f\u7387\uff0cUCA\u5728\u56fa\u5b9a\u5b54\u5f84\u7ea6\u675f\u4e0b\u4ec5\u6709\u8fb9\u9645\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "UCA\u5728\u6269\u5c55\u89d2\u8986\u76d6\u65b9\u9762\u7684\u4f18\u52bf\u5e76\u4e0d\u80fd\u76f4\u63a5\u8f6c\u5316\u4e3a\u663e\u8457\u7684\u7a7a\u95f4\u590d\u7528\u6027\u80fd\u63d0\u5347\uff0c\u9635\u5217\u9009\u62e9\u5e94\u6839\u636e\u5177\u4f53\u7ea6\u675f\u6761\u4ef6\u51b3\u5b9a\u3002"}}
{"id": "2511.13104", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.13104", "abs": "https://arxiv.org/abs/2511.13104", "authors": ["Reiner Thom\u00e4", "Michael D\u00f6bereiner", "Reza Faramarzahangari", "Jonas Gedschold. Marc Francisco Colaco Miranda", "Saw James Myint", "Steffen Schieler", "Christian Schneider", "Sebastian Semper", "Carsten Smeenk", "Gerd Sommerkorn", "Zhixiang Zhao"], "title": "Distributed Multisensor ISAC", "comment": null, "summary": "Integrated Sensing and Communications (ISAC) will become a service in future mobile communication networks. It enables the detection and recognition of passive objects and environments using radar-like sensing. The ultimate advantage is the reuse of the mobile network and radio access resources for scene illumination, sensing, data transportation, computation, and fusion. It enables building a distributed, ubiquitous sensing network that can be adapted for a variety of radio sensing tasks and services.\n  In this article, we develop the principles of multi-sensor ISAC (MS-ISAC). MS-ISAC corresponds to multi-user MIMO communication, which in radar terminology is known as distributed MIMO radar. \\ First, we develop basic architectural principles for MS-ISAC and link them to example use cases. We then propose a generic MS-ISAC architecture. After a brief reference to multipath propagation and multistatic target reflectivity issues, we outline multilink access, coordination, precoding and link adaptation schemes for MS-ISAC. Moreover, we review model-based estimation and tracking of delay~/~Doppler from sparse OFDMA~/~TDMA frames. We emphasize Cooperative Passive Coherent Location (CPCL) for bistatic correlation and synchronization. Finally, issues of multisensor node synchronization and distributed data fusion are addressed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u4f20\u611f\u5668\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(MS-ISAC)\u7684\u57fa\u672c\u539f\u7406\uff0c\u5c06\u5176\u4e0e\u5206\u5e03\u5f0fMIMO\u96f7\u8fbe\u76f8\u5173\u8054\uff0c\u5e76\u5f00\u53d1\u4e86\u67b6\u6784\u539f\u5219\u3001\u534f\u8c03\u65b9\u6848\u548c\u5206\u5e03\u5f0f\u6570\u636e\u878d\u5408\u65b9\u6cd5\u3002", "motivation": "\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u5c06\u6210\u4e3a\u672a\u6765\u79fb\u52a8\u901a\u4fe1\u7f51\u7edc\u7684\u670d\u52a1\uff0c\u901a\u8fc7\u91cd\u7528\u79fb\u52a8\u7f51\u7edc\u548c\u65e0\u7ebf\u63a5\u5165\u8d44\u6e90\u5b9e\u73b0\u88ab\u52a8\u5bf9\u8c61\u548c\u73af\u5883\u7684\u68c0\u6d4b\u8bc6\u522b\uff0c\u6784\u5efa\u5206\u5e03\u5f0f\u3001\u65e0\u5904\u4e0d\u5728\u7684\u611f\u77e5\u7f51\u7edc\u3002", "method": "\u5f00\u53d1MS-ISAC\u67b6\u6784\u539f\u5219\uff0c\u63d0\u51fa\u591a\u94fe\u8def\u63a5\u5165\u3001\u534f\u8c03\u3001\u9884\u7f16\u7801\u548c\u94fe\u8def\u9002\u914d\u65b9\u6848\uff0c\u4f7f\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u5ef6\u8fdf/\u591a\u666e\u52d2\u4f30\u8ba1\u4e0e\u8ddf\u8e2a\uff0c\u91c7\u7528\u534f\u4f5c\u88ab\u52a8\u76f8\u5e72\u5b9a\u4f4d(CPCL)\u8fdb\u884c\u53cc\u7ad9\u76f8\u5173\u548c\u540c\u6b65\u3002", "result": "\u5efa\u7acb\u4e86MS-ISAC\u7684\u57fa\u672c\u6846\u67b6\uff0c\u5c06\u591a\u7528\u6237MIMO\u901a\u4fe1\u4e0e\u5206\u5e03\u5f0fMIMO\u96f7\u8fbe\u6982\u5ff5\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u591a\u4f20\u611f\u5668\u8282\u70b9\u540c\u6b65\u548c\u5206\u5e03\u5f0f\u6570\u636e\u878d\u5408\u95ee\u9898\u3002", "conclusion": "MS-ISAC\u4e3a\u5b9e\u73b0\u5206\u5e03\u5f0f\u3001\u81ea\u9002\u5e94\u7684\u65e0\u7ebf\u611f\u77e5\u4efb\u52a1\u548c\u670d\u52a1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6280\u672f\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u4e2d\u7684\u96c6\u6210\u611f\u77e5\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.13171", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.13171", "abs": "https://arxiv.org/abs/2511.13171", "authors": ["Niccol\u00f2 Paglierani", "Francesco Linsalata", "Vineeth Teeda", "Davide Scazzoli", "Maurizio Magarini"], "title": "Autonomous Sensing UAV for Accurate Multi-User Identification and Localization in Cellular Networks", "comment": null, "summary": "This paper presents an autonomous sensing frame- work for identifying and localizing multiple users in Fifth Generation (5G) networks using an Unmanned Aerial Vehicle (UAV) that is not part of the serving access network. Unlike conventional aerial serving nodes, the proposed UAV operates passively and is dedicated solely to sensing. It captures Uplink (UL) Sounding Reference Signals (SRS), and requires virtually no coordination with the network infrastructure. A complete signal processing chain is proposed and developed, encompassing synchronization, user identification, and localization, all executed onboard UAV during flight. The system autonomously plans and adapts its mission workflow to estimate multiple user positions within a single deployment, integrating flight control with real-time sensing. Extensive simulations and a full-scale low- altitude experimental campaign validate the approach, showing localization errors below 3 m in rural field tests and below 8 m in urban simulation scenarios, while reliably identifying each user. The results confirm the feasibility of infrastructure-independent sensing UAVs as a core element of the emerging Low Altitude Economy (LAE), supporting situational awareness and rapid deployment in emergency or connectivity-limited environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u65e0\u4eba\u673a\u57285G\u7f51\u7edc\u4e2d\u88ab\u52a8\u611f\u77e5\u5e76\u5b9a\u4f4d\u591a\u4e2a\u7528\u6237\u7684\u81ea\u4e3b\u6846\u67b6\uff0c\u65e0\u9700\u4e0e\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u534f\u8c03\uff0c\u901a\u8fc7\u6355\u83b7\u4e0a\u884c\u94fe\u8def\u53c2\u8003\u4fe1\u53f7\u5b9e\u73b0\u7528\u6237\u8bc6\u522b\u548c\u5b9a\u4f4d\u3002", "motivation": "\u4f20\u7edf\u7a7a\u4e2d\u670d\u52a1\u8282\u70b9\u9700\u8981\u4e0e\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u534f\u8c03\uff0c\u800c\u8be5\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u72ec\u7acb\u4e8e\u57fa\u7840\u8bbe\u65bd\u7684\u88ab\u52a8\u611f\u77e5\u65e0\u4eba\u673a\uff0c\u652f\u6301\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u7684\u6001\u52bf\u611f\u77e5\u548c\u7d27\u6025\u90e8\u7f72\u3002", "method": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u4fe1\u53f7\u5904\u7406\u94fe\uff0c\u5305\u62ec\u540c\u6b65\u3001\u7528\u6237\u8bc6\u522b\u548c\u5b9a\u4f4d\uff0c\u6240\u6709\u5904\u7406\u90fd\u5728\u65e0\u4eba\u673a\u4e0a\u5b9e\u65f6\u6267\u884c\uff0c\u5e76\u81ea\u4e3b\u89c4\u5212\u548c\u8c03\u6574\u4efb\u52a1\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5728\u519c\u6751\u5b9e\u5730\u6d4b\u8bd5\u4e2d\u5b9a\u4f4d\u8bef\u5dee\u4f4e\u4e8e3\u7c73\uff0c\u5728\u57ce\u5e02\u6a21\u62df\u573a\u666f\u4e2d\u4f4e\u4e8e8\u7c73\uff0c\u540c\u65f6\u53ef\u9760\u8bc6\u522b\u6bcf\u4e2a\u7528\u6237\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u72ec\u7acb\u4e8e\u57fa\u7840\u8bbe\u65bd\u7684\u611f\u77e5\u65e0\u4eba\u673a\u4f5c\u4e3a\u65b0\u5174\u4f4e\u7a7a\u7ecf\u6d4e\u6838\u5fc3\u5143\u7d20\u7684\u53ef\u884c\u6027\uff0c\u652f\u6301\u7d27\u6025\u6216\u8fde\u63a5\u53d7\u9650\u73af\u5883\u4e2d\u7684\u6001\u52bf\u611f\u77e5\u548c\u5feb\u901f\u90e8\u7f72\u3002"}}
{"id": "2511.13272", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.13272", "abs": "https://arxiv.org/abs/2511.13272", "authors": ["Zeyang Sun", "Xidong Mu", "Shuai Han", "Sai Xu", "Michail Matthaiou"], "title": "Pinching-Antenna-Enabled Cognitive Radio Networks", "comment": "13 pages, 7 figures", "summary": "This paper investigates a pinching-antenna (PA)-enabled cognitive radio network, where both the primary transmitter (PT) and secondary transmitter (ST) are equipped with a single waveguide and multiple PAs to facilitate simultaneous spectrum sharing. Under a general Ricean fading channel model, a closed-form analytical expression for the average spectral efficiency (SE) achieved by PAs is first derived. Based on this, a sum-SE maximization problem is formulated to jointly optimize the primary and secondary pinching beamforming, subject to system constraints on the transmission power budgets, minimum antenna separation requirements, and feasible PA deployment regions. To address this non-convex problem, a three-stage optimization algorithm is developed to sequentially optimize both the PT and ST pinching beamforming, and the ST power control. For the PT and ST pinching beamforming optimization, the coarse positions of PA are first determined at the waveguide-level. Then, wavelength-level refinements achieve constructive signal combination at the intended user and destructive superposition at the unintended user. For the ST power control, a closed-form solution is derived. Simulation results demonstrate that i) PAs can achieve significant SE improvements over conventional fixed-position antennas; ii) the proposed pinching beamforming design achieves effective interference suppression and superior performance for both even and odd numbers of PAs; and iii) the developed three-stage optimization algorithm enables nearly orthogonal transmission between the primary and secondary networks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5939\u6301\u5929\u7ebf\u7684\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\uff0c\u901a\u8fc7\u4f18\u5316\u5939\u6301\u6ce2\u675f\u6210\u5f62\u548c\u529f\u7387\u63a7\u5236\u5b9e\u73b0\u4e3b\u6b21\u7f51\u7edc\u9891\u8c31\u5171\u4eab\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u5728\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\u4e2d\u9891\u8c31\u6548\u7387\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u5929\u7ebf\u6280\u672f\u6765\u6539\u5584\u4e3b\u6b21\u7f51\u7edc\u95f4\u7684\u9891\u8c31\u5171\u4eab\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u4f18\u5316\u7b97\u6cd5\uff1a\u9996\u5148\u5728\u6ce2\u5bfc\u7ea7\u786e\u5b9aPA\u7c97\u4f4d\u7f6e\uff0c\u7136\u540e\u8fdb\u884c\u6ce2\u957f\u7ea7\u7cbe\u5316\u5b9e\u73b0\u4fe1\u53f7\u5efa\u8bbe\u6027\u7ec4\u5408\uff0c\u6700\u540e\u63a8\u5bfc\u95ed\u5f0f\u529f\u7387\u63a7\u5236\u89e3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff1aPA\u76f8\u6bd4\u4f20\u7edf\u5929\u7ebf\u663e\u8457\u63d0\u5347\u9891\u8c31\u6548\u7387\uff1b\u5939\u6301\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u6709\u6548\u6291\u5236\u5e72\u6270\uff1b\u4e09\u9636\u6bb5\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u4e3b\u6b21\u7f51\u7edc\u8fd1\u4e4e\u6b63\u4ea4\u4f20\u8f93\u3002", "conclusion": "\u5939\u6301\u5929\u7ebf\u6280\u672f\u7ed3\u5408\u63d0\u51fa\u7684\u4f18\u5316\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\u7684\u9891\u8c31\u6548\u7387\u548c\u5e72\u6270\u7ba1\u7406\u80fd\u529b\u3002"}}
{"id": "2511.13336", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.13336", "abs": "https://arxiv.org/abs/2511.13336", "authors": ["Maolin Li", "Feng Shu", "Minghao Chen", "Cunhua Pan", "Fuhui Zhou", "Yongpeng Wu", "Liang Yang"], "title": "Sensing-enabled Secure Rotatable Array System Enhanced by Multi-Layer Transmitting RIS", "comment": null, "summary": "Programmable metasurfaces and adjustable antennas are promising technologies. The security of a rotatable array system is investigated in this paper. A dual-base-station (BS) architecture is adopted, in which the BSs collaboratively perform integrated sensing of the eavesdropper (the target) and communication tasks. To address the security challenge when the sensing target is located on the main communication link, the problem of maximizing the secrecy rate (SR) under sensing signal-to-interference-plus-noise ratio requirements and discrete constraints is formulated. This problem involves the joint optimization of the array pose, the antenna distribution on the array surface, the multi-layer transmitting RIS phase matrices, and the beamforming matrices, which is non-convex. To solve this challenge, an two-stage online algorithm based on the generalized Rayleigh quotient and an offline algorithm based on the Multi-Agent Deep Deterministic Policy Gradient are proposed. Simulation results validate the effectiveness of the proposed algorithms. Compared to conventional schemes without array pose adjustment, the proposed approach achieves approximately 22\\% improvement in SR. Furthermore, array rotation provides higher performance gains than position changes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u65cb\u8f6c\u9635\u5217\u7cfb\u7edf\u7684\u5b89\u5168\u901a\u4fe1\u65b9\u6848\uff0c\u91c7\u7528\u53cc\u57fa\u7ad9\u67b6\u6784\u534f\u540c\u6267\u884c\u7a83\u542c\u8005\u611f\u77e5\u548c\u901a\u4fe1\u4efb\u52a1\uff0c\u901a\u8fc7\u4f18\u5316\u9635\u5217\u59ff\u6001\u3001\u5929\u7ebf\u5206\u5e03\u3001RIS\u76f8\u4f4d\u77e9\u9635\u548c\u6ce2\u675f\u6210\u5f62\u77e9\u9635\u6765\u6700\u5927\u5316\u4fdd\u5bc6\u7387\u3002", "motivation": "\u53ef\u7f16\u7a0b\u8d85\u8868\u9762\u548c\u53ef\u8c03\u5929\u7ebf\u662f\u524d\u666f\u6280\u672f\uff0c\u4f46\u4f20\u7edf\u65b9\u6848\u5728\u611f\u77e5\u76ee\u6807\u4f4d\u4e8e\u4e3b\u901a\u4fe1\u94fe\u8def\u4e0a\u65f6\u5b58\u5728\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528\u53cc\u57fa\u7ad9\u67b6\u6784\uff0c\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49\u745e\u5229\u5546\u7684\u4e24\u9636\u6bb5\u5728\u7ebf\u7b97\u6cd5\u548c\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7684\u79bb\u7ebf\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u9635\u5217\u59ff\u6001\u3001\u5929\u7ebf\u5206\u5e03\u3001\u591a\u5c42\u53d1\u5c04RIS\u76f8\u4f4d\u77e9\u9635\u548c\u6ce2\u675f\u6210\u5f62\u77e9\u9635\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65e0\u9635\u5217\u59ff\u6001\u8c03\u6574\u65b9\u6848\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7ea622%\u7684\u4fdd\u5bc6\u7387\u63d0\u5347\uff0c\u4e14\u9635\u5217\u65cb\u8f6c\u6bd4\u4f4d\u7f6e\u53d8\u5316\u63d0\u4f9b\u66f4\u9ad8\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u53ef\u65cb\u8f6c\u9635\u5217\u7cfb\u7edf\u80fd\u6709\u6548\u63d0\u5347\u901a\u4fe1\u5b89\u5168\u6027\uff0c\u9635\u5217\u59ff\u6001\u4f18\u5316\u5bf9\u6027\u80fd\u63d0\u5347\u81f3\u5173\u91cd\u8981\uff0c\u6240\u63d0\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002"}}
