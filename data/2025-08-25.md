<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 6]
- [eess.IV](#eess.IV) [Total: 8]
- [eess.SP](#eess.SP) [Total: 5]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network](https://arxiv.org/abs/2508.15821)
*Bibo Wu,Fang Fang,Ming Zeng,Xianbin Wang*

Main category: cs.IT

TL;DR: 提出混合传统和可调天线网络(HCPAN)来优化NOMA联邦学习系统的通信效率，通过模糊逻辑客户端分类和深度强化学习算法联合优化天线部署和资源分配，显著减少总时间并提升FL性能


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中常见的"拖后腿"问题，通过动态建立强视距链路来提高通信效率

Method: 提出混合传统和可调天线网络框架，采用模糊逻辑客户端分类方案，然后基于深度强化学习算法联合优化可调天线部署和资源分配

Result: 仿真结果验证了所提方案通过优化可调天线部署能够有效提升联邦学习性能

Conclusion: 该混合网络架构和优化算法能够显著改善NOMA联邦学习系统的通信效率，有效缓解拖后腿问题

Abstract: Leveraging pinching antennas in wireless network enabled federated learning
(FL) can effectively mitigate the common "straggler" issue in FL by dynamically
establishing strong line-of-sight (LoS) links on demand. This letter proposes a
hybrid conventional and pinching antenna network (HCPAN) to significantly
improve communication efficiency in the non-orthogonal multiple access
(NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client
classification scheme is first proposed to effectively balance clients' data
contributions and communication conditions. Given this classification, we
formulate a total time minimization problem to jointly optimize pinching
antenna placement and resource allocation. Due to the complexity of variable
coupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm
is developed to effectively address this problem. Simulation results validate
the superiority of the proposed scheme in enhancing FL performance via the
optimized deployment of pinching antenna.

</details>


### [2] [Tri-Hybrid Beamforming for Radiation-Center Reconfigurable Antenna Array: Spectral Efficiency and Energy Efficiency](https://arxiv.org/abs/2508.15924)
*Yinchen Li,Chenhao Qi,Shiwen Mao,Octavia A. Dobre*

Main category: cs.IT

TL;DR: 基于辐射中心可重配天线数组的三混合波束成型架构，包含数字、模拟和电磁波束成型，通过三循环交替优化算法实现频谱效率和能量效率最大化。


<details>
  <summary>Details</summary>
Motivation: 为了提升大型MIMO系统的频谱效率和能量效率，减少硬件复杂度和功耗，需要一种新的波束成型架构和优化算法。

Method: 提出三混合波束成型架构，包含数字、模拟和电磁波束成型。使用三循环交替优化算法，内循环和中循环用于数字和模拟波束成型优化，外循环用于辐射中心选择。对于能量效率优化，提出双二次变换分数规划算法和拉格朗日双变换分数规划算法。

Result: 模拟结果表明该方法在提升频谱效率和能量效率方面具有很大潜力。拉格朗日双变换算法在只有轻微性能损失的情况下显著降低了计算复杂度。

Conclusion: 基于辐射中心可重配天线数组的三混合波束成型架构是一种有效的解决方案，能够同时提高系统性能和能量效率，为大型MIMO系统提供了新的设计思路。

Abstract: In this paper, we propose a tri-hybrid beamforming (THBF) architecture based
on the radiation-center (RC) reconfigurable antenna array (RCRAA), including
the digital beamforming, analog beamforming, and electromagnetic (EM)
beamforming, where the EM beamformer design is modeled as RC selection. Aiming
at spectral efficiency (SE) maximization subject to the hardware and power
consumption constraints, we propose a tri-loop alternating optimization (TLAO)
scheme for the THBF design, where the digital and analog beamformers are
optimized based on the penalty dual decomposition in the inner and middle
loops, and the RC selection is determined through the coordinate descent method
in the outer loop. Aiming at energy-efficiency (EE) maximization, we develop a
dual quadratic transform-based fractional programming (DQTFP) scheme, where the
TLAO scheme is readily used for the THBF design. To reduce the computational
complexity, we propose the Lagrange dual transform-based fractional programming
(LDTFP) scheme, where each iteration has a closed-form solution. Simulation
results demonstrate the great potential of the RCRAA in improving both SE and
EE. Compared to the DQTFP scheme, the LDTFP scheme significantly reduces the
computational complexity with only minor performance loss.

</details>


### [3] [Multi-User SLNR-Based Precoding With Gold Nanoparticles in Vehicular VLC Systems](https://arxiv.org/abs/2508.16075)
*Geonho Han,Hyuckjin Choi,Hyesang Cho,Jeong Hyeon Han,Ki Tae Nam,Junil Choi*

Main category: cs.IT

TL;DR: 本文提出利用金纳米粒子(GNPs)的光学特性和SLNR预编码技术来解决车载可见光通信中LED相关性高的问题，通过优化RGB比例和预编码器设计，显著提高了多用户环境下的总速率和保密速率。


<details>
  <summary>Details</summary>
Motivation: 车载可见光通信(VVLC)系统中，由于车头灯中LED间距小导致信道高度相关，难以通过空间复用提高数据速率，需要解决LED相关性问题和多用户支持挑战。

Method: 利用金纳米粒子(GNPs)的手性光学特性降低LED间相关性；采用SLNR预编码支持多用户；通过广义瑞利商和连续凸逼近优化RGB光源比例和预编码器设计。

Result: 仿真结果表明，基于SLNR的预编码器与优化RGB比例显著提高了多用户车载环境的总速率和窃听场景的保密速率。

Conclusion: LED间的去相关和RGB比例优化对提升VVLC性能至关重要，提出的SLNR预编码方法有效解决了车载可见光通信的关键挑战。

Abstract: Visible spectrum is an emerging frontier in wireless communications for
enhancing connectivity and safety in vehicular environments. The vehicular
visible light communication (VVLC) system is a key feature in leveraging
existing infrastructures, but it still has several critical challenges.
Especially, VVLC channels are highly correlated due to the small gap between
light emitting diodes (LEDs) in each headlight, making it difficult to increase
data rates by spatial multiplexing. In this paper, we exploit recently
synthesized gold nanoparticles (GNPs) to reduce the correlation between LEDs,
i.e., the chiroptical properties of GNPs for differential absorption depending
on the azimuth angle of incident light are used to mitigate the LED
correlation. In addition, we adopt a signal-to-leakage-plus-noise ratio
(SLNR)-based precoder to support multiple users. The ratio of RGB light sources
in each LED also needs to be optimized to maximize the sum SLNR satisfying a
white light constraint for illumination since the GNPs can vary the color of
transmitted light by the differential absorption across wavelength. The
nonconvex optimization problems for precoders and RGB ratios can be solved by
the generalized Rayleigh quotient with the approximated shot noise and
successive convex approximation (SCA). The simulation results show that the
SLNR-based precoder with the optimized RGB ratios significantly improves the
sum rate in a multi-user vehicular environment and the secrecy rate in a
wiretapping scenario. The proposed SLNR-based precoding verifies that the
decorrelation between LEDs and the RGB ratio optimization are essential to
enhance the VVLC performance.

</details>


### [4] [Implicit and Explicit Formulas of the Joint RDF for a Tuple of Multivariate Gaussian Sources with Individual Square-Error Distortions](https://arxiv.org/abs/2508.16301)
*Evagoras Stylianou,Charalambos D. Charalambous,Themistoklis Charalambous*

Main category: cs.IT

TL;DR: 本文分析了相关多元高斯源的联合率失真函数，提出了闭式解和对称失真情况下的显式表达式


<details>
  <summary>Details</summary>
Motivation: 研究相关多元高斯源在个体平方误差失真下的联合率失真函数，以改进对该问题的理解和闭式解的发展

Method: 利用Hotelling的典型变量形式，推导出涉及非线性方程组的闭式联合RDF表征，并对对称失真情况使用两个注水变量进行显式表达

Result: 获得了相关多元高斯源联合RDF的闭式解，特别在对称失真情况下得到了简洁的显式表达式

Conclusion: 该研究显著提高了对多元高斯源联合率失真函数的理解，并推动了闭式解的发展

Abstract: This paper analyzes the joint Rate Distortion Function (RDF) of correlated
multivariate Gaussian sources with individual square-error distortions.
Leveraging Hotelling's canonical variable form, presented is a closed-form
characterization of the joint RDF, that involves {a system of nonlinear
equations. Furthermore, for the special case of symmetric distortions (i.e.,
equal distortions), the joint RDF is explicitly expressed in terms of} two
water-filling variables. The results greatly improve our understanding and
advance the development of closed-form solutions of the joint RDF for
multivariate Gaussian sources with individual square-error distortions.

</details>


### [5] [Agentic AI Empowered Multi-UAV Trajectory Optimization in Low-Altitude Economy Networks](https://arxiv.org/abs/2508.16379)
*Feibo Jiang,Li Dong,Xitao Pan,Kezhi Wang,Cunhua Pan*

Main category: cs.IT

TL;DR: 提出ARMAIT框架，结合Agentic RAG和MAIT混合神经网络，用于多无人机轨迹优化，通过T-GRPO方法实现统一策略优化


<details>
  <summary>Details</summary>
Motivation: 解决多无人机轨迹优化问题，需要能够自主理解高级任务需求并有效处理不同系统规模的复杂优化任务

Method: 基于LLM构建Agentic RAG系统，集成无人机知识库；设计MAIT混合架构结合注意力机制和Mamba的高效时序建模；提出T-GRPO方法进行统一策略梯度优化

Result: 大量实验验证了ARMAIT框架的可行性和有效性

Conclusion: 该框架为多无人机轨迹优化提供了创新的解决方案，结合了Agentic AI、RAG和先进的神经网络架构

Abstract: This paper proposes a novel Agentic Retrieval-augmented generation with
Mamba-Attention Integrated Transformer (ARMAIT) framework for multi-Unmanned
Aerial Vehicle (UAV) trajectory optimization. The framework is built upon Large
Language Models (LLMs), incorporating Retrieval-Augmented Generation (RAG)
empowered by Agentic AI and integrated with a UAV-specific knowledge base.
Through the Agentic RAG, the LLM autonomously interprets high-level task
requirements and identifies the key components necessary for trajectory
optimization, including model inputs and outputs, network architecture, reward
functions, and task constraints. To support efficient modeling across different
system scales, we introduce the Mamba-Attention Integrated Transformer (MAIT),
a hybrid neural architecture that combines the long-range dependency modeling
capability of attention mechanisms with the efficient temporal dynamic
representation of Mamba. Furthermore, a Trajectory-Group Relative Policy
Optimization (T-GRPO) method is proposed to achieve unified policy gradient
optimization in both discrete and continuous trajectory spaces for MAIT
training. Extensive experimental results validate the feasibility and
effectiveness of the proposed ARMAIT framework.

</details>


### [6] [Enhanced Successive Cancellation List Decoder for Long Polar Codes Targeting 6G Air Interface](https://arxiv.org/abs/2508.16498)
*Jiajie Li,Sihui Shen,Warren J. Gross*

Main category: cs.IT

TL;DR: 提出了扰动增强和偏置增强的SCL解码器算法，通过降低内存使用和计算复杂度来实现长极化码的高效解码，在6G通信中达到性能与资源消耗的平衡。


<details>
  <summary>Details</summary>
Motivation: 6G通信标准对信道编码提出新的能效和面积成本要求，需要解决长极化码（如8K比特）在连续取消列表解码中的内存使用和计算复杂度挑战。

Method: 提出扰动增强(PE)SCL解码器、偏置增强(BE)SCL解码器、广义分区SCL(GPSCL)解码器，并结合输入分布感知(IDA)解码技术来优化内存和计算效率。

Result: BE GPSCL解码器相比传统SCL解码器内存使用减少67%，计算复杂度降低5.4倍，解码性能损失仅0.05dB，达到与更大列表尺寸解码器相当的性能。

Conclusion: 所提出的算法技术能够有效实现长极化码在下一代通信标准中的部署，在保持解码性能的同时显著降低了资源消耗。

Abstract: The 6th generation communication standard's air interface requires innovation
in channel coding to fulfill anticipated energy and area cost reduction
requirements. In this paper, we propose algorithmic techniques to enable the
implementation of long polar codes (e.g., length 8K bits) in next-generation
communications standards by addressing key challenges in memory usage and
computational complexity presented by successive decoding list (SCL) polar
decoding. Perturbation-enhanced (PE) successive cancelation list (SCL) decoders
with a list size of $L$ reach the decoding performance of the SCL decoder with
a list size of $2L$. The proposed bias-enhanced (BE) SCL decoders, which
simplifies the PE SCL decoder based on insights gained by an ablation study,
returns similar decoding performance to PE SCL decoders. Also, proposed BE
generalized partitioned SCL (GPSCL) decoders with a list size of $8$ have a
$67\%$ reduction in the memory usage and similar decoding performance compared
to SCL decoders with a list size of $16$. Furthermore, input-distribution-aware
(IDA) decoding is applied to BE GPSCL decoders. Up to $5.4\times$ reduction in
the computational complexity is achieved compared to SCL decoders with a list
size of $16$. The degraded decoding performance is at most $0.05\text{ dB}$
compared to BE GPSCL decoders without IDA decoding.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [7] [Robust Residual Finite Scalar Quantization for Neural Compression](https://arxiv.org/abs/2508.15860)
*Xiaoxu Zhu*

Main category: eess.IV

TL;DR: 提出了RFSQ框架解决FSQ在残差量化中的信号衰减问题，通过可学习缩放因子和可逆LayerNorm两种条件化策略，显著提升了多阶段残差量化的效果。


<details>
  <summary>Details</summary>
Motivation: FSQ在残差量化框架中存在残差幅度衰减问题，后续FSQ层接收的信号逐渐变弱，限制了其有效性。

Method: 提出了Robust Residual Finite Scalar Quantization (RFSQ)框架，包含两种新颖的条件化策略：可学习缩放因子和可逆层归一化。

Result: 在ImageNet上的实验显示，RFSQ变体显著优于VQ-EMA、FSQ和LFQ等基线方法，感知损失改善达45%，L1重建误差减少28.7%。

Conclusion: RFSQ在保持FSQ简单性的同时，成为神经压缩中更优越的量化方法，其中LayerNorm策略在不同配置下表现最一致。

Abstract: Finite Scalar Quantization (FSQ) has emerged as a promising alternative to
Vector Quantization (VQ) in neural compression, offering simplified training
and improved stability. However, naive application of FSQ in residual
quantization frameworks suffers from the \textbf{residual magnitude decay
problem}, where subsequent FSQ layers receive progressively weaker signals,
severely limiting their effectiveness. We propose \textbf{Robust Residual
Finite Scalar Quantization (RFSQ)}, a general framework that addresses this
fundamental limitation through two novel conditioning strategies: learnable
scaling factors and invertible layer normalization. Our approach maintains the
simplicity of FSQ while enabling effective multi-stage residual quantization.
Comprehensive experiments on ImageNet demonstrate that RFSQ variants
significantly outperform strong baselines including VQ-EMA, FSQ, and LFQ,
achieving up to 45\% improvement in perceptual loss and 28.7\% reduction in L1
reconstruction error. The proposed LayerNorm strategy shows the most consistent
improvements across different configurations, establishing RFSQ as a superior
quantization method for neural compression.

</details>


### [8] [Turbo Spin Echo Imaging at 7T with Bilateral Orthogonality Generative Acquisitions Method for Homogeneous T_1, T_2 and Proton Density Contrasts](https://arxiv.org/abs/2508.15867)
*Celik Boga,Anke Henning*

Main category: eess.IV

TL;DR: 通过将BOGA方法适配于7T平行发射系统的TSE成像，成功获得了均匀的T1、T2和质子密度加权图像，免除了发射/收集场不均匀效应。


<details>
  <summary>Details</summary>
Motivation: 解决7T碳核磁共振成像中由于发射和收集场不均匀导致的图像异质性问题，提高T1、T2和PD对比度的均匀性。

Method: 采用并行发射系统，获取具有互补性RF模式和扫描参数的多个TSE图像作为BOGA方法的输入，通过不同子集数据处理每种对比度，并测试两种TSE因子的效果。

Result: 获得了均匀的T1、T2和质子密度加权图像，免除了发射/收集场不均匀效应，同时解决了TSE扫描的混合对比度问题，且不受TSE因子影响。

Conclusion: BOGA方法在TSE成像中成功实现了均匀的T1、T2和PD对比度，无需预先数据收集即可消除不均匀效应，在7T碳核磁共振中具有重要应用价值。

Abstract: Purpose: Bilateral Orthogonality Generative Acquisitions (BOGA) method, which
was initially implemented for T_2^* contrast via gradient echo acquisitions, is
adapted for TSE imaging at 7T using parallel transmission (pTx) system for
obtaining homogeneous T_1, T_2 and proton density weighted images. Theory and
Methods: Multiple TSE images with complimentary RF modes and scan parameters
are acquired as input images for the BOGA method where RF modes have
complimentary transmit and receive field inhomogeneity patterns and scan
parameters have varying echo and repetition times. With the application of the
BOGA method using different subsets of the data acquisitions for each contrast,
homogeneous T_1, T_2 and proton density contrast in the final images obtained.
Furthermore, to demonstrate the effect of the TSE factor, two TSE factors are
used individually. Normalized intensity profiles and signal to noise ratio maps
are utilized for the comparison of the CP mode images and the TSE factors
respectively.
  Results: Homogeneous T_1, T_2 and proton density weighted images are obtained
with the TSE implementation of the BOGA method without the transmit and receive
field inhomogeneity effects. Furthermore, mixed contrast effects of the TSE
acquisition are simultaneously resolved independently of the TSE factor.
  Conclusion: TSE application of BOGA method results in homogeneous T_1, T_2
and proton density contrasts at 7T, as the inhomogeneity effects are removed
from the final contrast without any prior data acquisitions.

</details>


### [9] [Beyond Imaging: Vision Transformer Digital Twin Surrogates for 3D+T Biological Tissue Dynamics](https://arxiv.org/abs/2508.15883)
*Kaan Berke Ugurlar,Joaquín de Navascués,Michael Taynnan Barros*

Main category: eess.IV

TL;DR: VT-DTSN是一个基于Vision Transformer的深度学习框架，用于从3D+T生物组织成像数据中预测组织动态变化，通过多视图融合和复合损失函数实现高保真重建。


<details>
  <summary>Details</summary>
Motivation: 理解活体组织的动态组织和稳态维持需要高分辨率、时间分辨的成像技术，以及能够从复杂数据集中提取可解释、预测性见解的方法。

Method: 利用DINO预训练的Vision Transformers，采用多视图融合策略，通过复合损失函数（像素级精度、感知结构和特征空间对齐）训练模型。

Result: 模型在果蝇中肠的3D+T成像数据上表现出鲁棒性和一致性，实现了低错误率和高结构相似性，同时保持高效的推理性能。

Conclusion: VT-DTSN为跨时间点重建和组织动态研究提供了一个可行的高保真替代模型，能够补充生物研究中时间分辨成像研究的计算探索。

Abstract: Understanding the dynamic organization and homeostasis of living tissues
requires high-resolution, time-resolved imaging coupled with methods capable of
extracting interpretable, predictive insights from complex datasets. Here, we
present the Vision Transformer Digital Twin Surrogate Network (VT-DTSN), a deep
learning framework for predictive modeling of 3D+T imaging data from biological
tissue. By leveraging Vision Transformers pretrained with DINO
(Self-Distillation with NO Labels) and employing a multi-view fusion strategy,
VT-DTSN learns to reconstruct high-fidelity, time-resolved dynamics of a
Drosophila midgut while preserving morphological and feature-level integrity
across imaging depths. The model is trained with a composite loss prioritizing
pixel-level accuracy, perceptual structure, and feature-space alignment,
ensuring biologically meaningful outputs suitable for in silico experimentation
and hypothesis testing. Evaluation across layers and biological replicates
demonstrates VT-DTSN's robustness and consistency, achieving low error rates
and high structural similarity while maintaining efficient inference through
model optimization. This work establishes VT-DTSN as a feasible, high-fidelity
surrogate for cross-timepoint reconstruction and for studying tissue dynamics,
enabling computational exploration of cellular behaviors and homeostasis to
complement time-resolved imaging studies in biological research.

</details>


### [10] [Structure-Preserving Medical Image Generation from a Latent Graph Representation](https://arxiv.org/abs/2508.15920)
*Kevin Arias,Edwin Vargas,Kumar Vijay Mishra,Antonio Ortega,Henry Arguello*

Main category: eess.IV

TL;DR: 提出了一种利用潜在图表示(LGR)来保持医学图像结构相似性的生成模型，通过图卷积网络重建X射线图像，在分类和分割任务上分别提升3%和2%的性能


<details>
  <summary>Details</summary>
Motivation: 医学影像数据稀缺且获取成本高，传统生成模型忽略医学图像的高度结构化特性，无法有效保持解剖限制和结构相似性

Method: 设计端到端模型学习潜在图表示(LGR)捕获X射线图像内在结构，使用图卷积网络(GCN)从LGR重建图像，采用对抗训练学习LGR分布

Result: 数值实验表明该方法在分类和分割任务上分别提升3%和2%的性能

Conclusion: 通过学习潜在图表示，提出的生成模型能够生成保持结构特征的合成医学图像，有效解决数据稀缺问题并提升下游任务性能

Abstract: Supervised learning techniques have proven their efficacy in many
applications with abundant data. However, applying these methods to medical
imaging is challenging due to the scarcity of data, given the high acquisition
costs and intricate data characteristics of those images, thereby limiting the
full potential of deep neural networks. To address the lack of data,
augmentation techniques leverage geometry, color, and the synthesis ability of
generative models (GMs). Despite previous efforts, gaps in the generation
process limit the impact of data augmentation to improve understanding of
medical images, e.g., the highly structured nature of some domains, such as
X-ray images, is ignored. Current GMs rely solely on the network's capacity to
blindly synthesize augmentations that preserve semantic relationships of chest
X-ray images, such as anatomical restrictions, representative structures, or
structural similarities consistent across datasets. In this paper, we introduce
a novel GM that leverages the structural resemblance of medical images by
learning a latent graph representation (LGR). We design an end-to-end model to
learn (i) a LGR that captures the intrinsic structure of X-ray images and (ii)
a graph convolutional network (GCN) that reconstructs the X-ray image from the
LGR. We employ adversarial training to guide the generator and discriminator
models in learning the distribution of the learned LGR. Using the learned GCN,
our approach generates structure-preserving synthetic images by mapping
generated LGRs to X-ray. Additionally, we evaluate the learned graph
representation for other tasks, such as X-ray image classification and
segmentation. Numerical experiments demonstrate the efficacy of our approach,
increasing performance up to $3\%$ and $2\%$ for classification and
segmentation, respectively.

</details>


### [11] [Decoding MGMT Methylation: A Step Towards Precision Medicine in Glioblastoma](https://arxiv.org/abs/2508.16424)
*Hafeez Ur Rehman,Sumaiya Fazal,Moutaz Alazab,Ali Baydoun*

Main category: eess.IV

TL;DR: CAMP框架使用自适应稀疏惩罚的卷积自编码器，通过合成MRI切片和预测MGMT甲基化状态，在胶质母细胞瘤治疗预测中取得了97%的准确率。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤是高度恶性的脑肿瘤，MGMT基因甲基化状态是预测治疗效果的关键生物标志物，但现有非侵入性成像技术难以准确预测，因为肿瘤具有复杂异质性、对比度不均和增强模式不规则等特点。

Method: 提出CAMP框架，分为两个阶段：1）使用定制自编码器生成合成MRI切片，有效捕捉和保留不同MRI模态下的精细组织和肿瘤结构；2）使用带有自适应稀疏惩罚的卷积神经网络预测MGMT甲基化状态，该惩罚能动态调整以适应数据变化。

Result: 在基准数据集上验证，CAMP达到了0.97的准确率、0.98的特异性和0.97的敏感性，显著优于现有方法，在MRI图像合成方面表现出色，能保留脑组织、脂肪和个体肿瘤结构。

Conclusion: CAMP框架有潜力改善MRI数据解读，为胶质母细胞瘤患者提供更个性化的治疗策略，展示了自适应稀疏惩罚在医学图像分析中的有效性。

Abstract: Glioblastomas, constituting over 50% of malignant brain tumors, are highly
aggressive brain tumors that pose substantial treatment challenges due to their
rapid progression and resistance to standard therapies. The methylation status
of the O-6-Methylguanine-DNA Methyltransferase (MGMT) gene is a critical
biomarker for predicting patient response to treatment, particularly with the
alkylating agent temozolomide. However, accurately predicting MGMT methylation
status using non-invasive imaging techniques remains challenging due to the
complex and heterogeneous nature of glioblastomas, that includes, uneven
contrast, variability within lesions, and irregular enhancement patterns. This
study introduces the Convolutional Autoencoders for MGMT Methylation Status
Prediction (CAMP) framework, which is based on adaptive sparse penalties to
enhance predictive accuracy. The CAMP framework operates in two phases: first,
generating synthetic MRI slices through a tailored autoencoder that effectively
captures and preserves intricate tissue and tumor structures across different
MRI modalities; second, predicting MGMT methylation status using a
convolutional neural network enhanced by adaptive sparse penalties. The
adaptive sparse penalty dynamically adjusts to variations in the data, such as
contrast differences and tumor locations in MR images. Our method excels in MRI
image synthesis, preserving brain tissue, fat, and individual tumor structures
across all MRI modalities. Validated on benchmark datasets, CAMP achieved an
accuracy of 0.97, specificity of 0.98, and sensitivity of 0.97, significantly
outperforming existing methods. These results demonstrate the potential of the
CAMP framework to improve the interpretation of MRI data and contribute to more
personalized treatment strategies for glioblastoma patients.

</details>


### [12] [Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization](https://arxiv.org/abs/2508.16479)
*Yupei Zhang,Xiaofei Wang,Anran Liu,Lequan Yu,Chao Li*

Main category: eess.IV

TL;DR: 提出解耦多模态框架解决组织病理学与转录组多模态学习中的异质性、多尺度整合和配对数据依赖问题，通过四个创新策略提升癌症诊断和预后性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法面临多模态异质性、多尺度整合不足和对配对数据的依赖等挑战，限制了临床适用性

Method: 提出解耦多模态框架：1)解耦多模态融合模块分解WSI和转录组为肿瘤和微环境子空间；2)跨放大倍数基因表达一致性策略；3)子空间知识蒸馏实现仅WSI推理；4)信息token聚合模块

Result: 在癌症诊断、预后和生存预测的广泛实验中，该方法在多个设置下优于最先进方法

Conclusion: 该解耦多模态框架有效解决了多模态学习的关键挑战，提高了临床适用性和推理效率

Abstract: Histopathology remains the gold standard for cancer diagnosis and prognosis.
With the advent of transcriptome profiling, multi-modal learning combining
transcriptomics with histology offers more comprehensive information. However,
existing multi-modal approaches are challenged by intrinsic multi-modal
heterogeneity, insufficient multi-scale integration, and reliance on paired
data, restricting clinical applicability. To address these challenges, we
propose a disentangled multi-modal framework with four contributions: 1) To
mitigate multi-modal heterogeneity, we decompose WSIs and transcriptomes into
tumor and microenvironment subspaces using a disentangled multi-modal fusion
module, and introduce a confidence-guided gradient coordination strategy to
balance subspace optimization. 2) To enhance multi-scale integration, we
propose an inter-magnification gene-expression consistency strategy that aligns
transcriptomic signals across WSI magnifications. 3) To reduce dependency on
paired data, we propose a subspace knowledge distillation strategy enabling
transcriptome-agnostic inference through a WSI-only student model. 4) To
improve inference efficiency, we propose an informative token aggregation
module that suppresses WSI redundancy while preserving subspace semantics.
Extensive experiments on cancer diagnosis, prognosis, and survival prediction
demonstrate our superiority over state-of-the-art methods across multiple
settings. Code is available at
https://github.com/helenypzhang/Disentangled-Multimodal-Learning.

</details>


### [13] [Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.16557)
*Tainyi Zhang,Zheng-Peng Duan,Peng-Tao Jiang,Bo Li,Ming-Ming Cheng,Chun-Le Guo,Chongyi Li*

Main category: eess.IV

TL;DR: 提出TADSR方法，通过时间感知机制在单步超分中充分利用SD模型不同时间步的生成先验，实现性能提升和可控的保真度-真实性权衡


<details>
  <summary>Details</summary>
Motivation: 现有基于VSD的Real-ISR方法使用固定时间步，难以充分利用SD模型在不同噪声注入时间步下的不同生成先验，导致性能次优

Method: 提出时间感知VAE编码器将图像投影到基于时间步的潜在特征，以及时间感知VSD损失来桥接师生模型的时间步，实现更好的生成先验对齐

Result: 实验结果表明该方法在单步超分中实现了最先进性能，并能通过改变时间步条件自然实现保真度和真实性的可控权衡

Conclusion: TADSR通过时间感知机制有效利用了SD模型在不同时间步的生成能力，在Real-ISR任务中取得了优异性能并提供了可控性

Abstract: Diffusion-based real-world image super-resolution (Real-ISR) methods have
demonstrated impressive performance. To achieve efficient Real-ISR, many works
employ Variational Score Distillation (VSD) to distill pre-trained
stable-diffusion (SD) model for one-step SR with a fixed timestep. However, due
to the different noise injection timesteps, the SD will perform different
generative priors. Therefore, a fixed timestep is difficult for these methods
to fully leverage the generative priors in SD, leading to suboptimal
performance. To address this, we propose a Time-Aware one-step Diffusion
Network for Real-ISR (TADSR). We first introduce a Time-Aware VAE Encoder,
which projects the same image into different latent features based on
timesteps. Through joint dynamic variation of timesteps and latent features,
the student model can better align with the input pattern distribution of the
pre-trained SD, thereby enabling more effective utilization of SD's generative
capabilities. To better activate the generative prior of SD at different
timesteps, we propose a Time-Aware VSD loss that bridges the timesteps of the
student model and those of the teacher model, thereby producing more consistent
generative prior guidance conditioned on timesteps. Additionally, though
utilizing the generative prior in SD at different timesteps, our method can
naturally achieve controllable trade-offs between fidelity and realism by
changing the timestep condition. Experimental results demonstrate that our
method achieves both state-of-the-art performance and controllable SR results
with only a single step.

</details>


### [14] [A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer](https://arxiv.org/abs/2508.16569)
*Yuhui Tao,Zhongwei Zhao,Zilong Wang,Xufang Luo,Feng Chen,Kang Wang,Chuanfu Wu,Xue Zhang,Shaoting Zhang,Jiaxi Yao,Xingwei Jin,Xinyang Jiang,Yifan Yang,Dongsheng Li,Lili Qiu,Zhiqiang Shao,Jianming Guo,Nengwang Yu,Shuo Wang,Ying Xiong*

Main category: eess.IV

TL;DR: RenalCLIP是一个基于视觉-语言基础模型的肾脏肿块诊断系统，通过两阶段预训练策略在CT扫描上实现卓越性能，在10个临床任务中表现优于现有模型，特别是在复发预测任务上提升20%，且具有出色的数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决肾脏肿块非侵入性评估的挑战，避免良性或惰性肿瘤的过度治疗，提高诊断准确性和预后分层精度。

Method: 开发RenalCLIP视觉-语言基础模型，采用两阶段预训练策略：首先用领域特定知识增强图像和文本编码器，然后通过对比学习目标对齐，使用27,866个CT扫描和8,809名患者的数据进行训练和验证。

Result: 在10个临床任务中表现优异，复发预测C-index达0.726（提升20%），仅需20%训练数据即可达到基线模型100%数据的性能，在报告生成、图像-文本检索和零样本诊断任务中表现卓越。

Conclusion: RenalCLIP提供了一个强大的工具，能够提高诊断准确性、优化预后分层，并为肾癌患者提供个性化管理方案，具有重要的临床转化潜力。

Abstract: The non-invasive assessment of increasingly incidentally discovered renal
masses is a critical challenge in urologic oncology, where diagnostic
uncertainty frequently leads to the overtreatment of benign or indolent tumors.
In this study, we developed and validated RenalCLIP using a dataset of 27,866
CT scans from 8,809 patients across nine Chinese medical centers and the public
TCIA cohort, a visual-language foundation model for characterization, diagnosis
and prognosis of renal mass. The model was developed via a two-stage
pre-training strategy that first enhances the image and text encoders with
domain-specific knowledge before aligning them through a contrastive learning
objective, to create robust representations for superior generalization and
diagnostic precision. RenalCLIP achieved better performance and superior
generalizability across 10 core tasks spanning the full clinical workflow of
kidney cancer, including anatomical assessment, diagnostic classification, and
survival prediction, compared with other state-of-the-art general-purpose CT
foundation models. Especially, for complicated task like recurrence-free
survival prediction in the TCIA cohort, RenalCLIP achieved a C-index of 0.726,
representing a substantial improvement of approximately 20% over the leading
baselines. Furthermore, RenalCLIP's pre-training imparted remarkable data
efficiency; in the diagnostic classification task, it only needs 20% training
data to achieve the peak performance of all baseline models even after they
were fully fine-tuned on 100% of the data. Additionally, it achieved superior
performance in report generation, image-text retrieval and zero-shot diagnosis
tasks. Our findings establish that RenalCLIP provides a robust tool with the
potential to enhance diagnostic accuracy, refine prognostic stratification, and
personalize the management of patients with kidney cancer.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [15] [Secure ISAC Systems Empowered by Compound Reconfigurable Antenna Arrays](https://arxiv.org/abs/2508.16055)
*Mengzhen Liu,Ming Li,Rang Liu,Qian Liu*

Main category: eess.SP

TL;DR: 本文提出了一种基于复合可重配天线数组的新题安全ISAC框架，通过联合设计电磁域和基带域预编码器，解决传统方案在空间分辨率和安全性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 在ISAC系统中，双功能信号会在雷达感知过程中暴露通信信息，尤其当感知目标本身是侦听者时。传统基带域安全方案受限于不足的空间分辨率和空间相关频道的负面影响。

Method: 提出使用复合可重配天线数组，在电磁域实现辐射图案和偏振状态的同时可重配性。建立包含虚拟角域、空间域和去偏振效应的通道模型，并形成一个混合整数非线性规划问题来联合设计EM域和BB域预编码器。使用分数规划、主要化-最小化、二阶梯形规划和罚法方法的迭代分解算法来解决这个复杂优化问题。

Result: 模拟结果显示，提出的CRA数组架构与联合EM-BB域设计在安全ISAC系统中实现了显著性能提升。与传统放射形成相比，雷达感知收益最高提升12dB，同时保持了稳健的通信安全性。

Conclusion: 通过联合利用电磁域中的额外自由度，本文提出的方案为安全ISAC系统设计带来了重大改进，有效克服了传统基带域方案的限制。

Abstract: In integrated sensing and communication (ISAC) systems, the use of
dual-functional signals inherently exposes confidential communication
information during radar sensing, particularly when the sensing target itself
acts as an eavesdropper. Conventional physical-layer security solutions rely on
directional beamforming or artificial noise injection implemented via signal
processing in the baseband (BB) domain. However, these BB-domain approaches are
constrained by insufficient spatial resolution and the adverse effects of
spatially correlated channels. To overcome these limitations, this paper
proposes a novel secure ISAC framework empowered by compound reconfigurable
antenna (CRA) arrays, which offer simultaneous reconfigurability of radiation
patterns and polarization states in the electromagnetic (EM) domain.
Specifically, we develop a comprehensive channel model incorporating virtual
angular domain, spatial domain, and depolarization effects, and formulate a
mixed-integer nonlinear programming (MINLP) problem to jointly design EM-domain
and BB-domain precoders and combiners. To efficiently solve this complex
optimization problem, we propose an iterative decomposition-based algorithm
leveraging fractional programming (FP), majorization-minimization (MM),
second-order cone programming (SOCP), and penalty methods. Extensive simulation
results demonstrate that the CRA array architecture with proposed joint EM-and
BB-domain design achieves significant performance improvements in secure ISAC
systems. In particular, radar sensing gains of up to 12dB are observed over
conventional beamforming, while robust communication security is maintained.
These results highlight the considerable benefits attainable by jointly
leveraging additional degrees of freedom (DoFs) in the EM domain for secure
ISAC system design.

</details>


### [16] [FM OFDM Unifying High Mobility Communications and Sensing](https://arxiv.org/abs/2508.16107)
*Amir Bouziane,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本文研究了用于6G集成感知与通信的FM-OFDM波形，该波形具有恒定包络特性，在高移动性双色散信道条件下提供优越的感知性能。


<details>
  <summary>Details</summary>
Motivation: 6G系统需要同时支持高速数据传输和精确环境感知，但传统OFDM的高峰均功率比(PAPR)在高频段带来挑战，需要寻找更适合的波形设计方案。

Method: 提出频率调制正交频分复用(FM OFDM)波形，推导其在时变多径信道中的输入输出关系，分析载波间干扰、多普勒效应和有效信道增益。

Result: 与CP OFDM和CE OFDM相比，FM-OFDM在高信噪比和高移动性条件下展现出更优越的距离和速度估计精度。

Conclusion: FM-OFDM适合作为6G高频段集成感知与通信应用的统一波形解决方案。

Abstract: Integrated Sensing and Communication (ISAC) is foundational to future sixth
generation (6G) systems, demanding waveform co-design that supports both high
throughput data transmission and accurate environmental perception. While
Orthogonal Frequency Division Multiplexing (OFDM) offers flexibility and
backward compatibility, its high Peak to Average Power Ratio (PAPR) poses
significant challenges at higher frequency bands. To address this, we
investigate Frequency Modulated Orthogonal Frequency Division Multiplexing (FM
OFDM) a constant envelope waveform that facilitates robust joint sensing and
communication under highly mobile, doubly dispersive channel conditions. We
derive a comprehensive input output relationship for FM OFDM in time varying
multipath channels, including analytical expressions for Inter Carrier
Interference (ICI), Doppler effects, and effective channel gains. Extensive
simulations comparing FM OFDM with conventional Cyclic Prefix Orthogonal
Frequency Division Multiplexing (CP OFDM) and Constant Envelope Orthogonal
Frequency Division Multiplexing (CE OFDM) demonstrate superior range and
velocity estimation accuracy of FM-OFDM, particularly at high Signal to Noise
Ratios (SNRs) and under high mobility, highlighting its suitability as a
unified waveform for high frequency ISAC applications in 6G.

</details>


### [17] [A Scalable Hybrid Track-Before-Detect Tracking System: Application to Coastal Maritime Radar Surveillance](https://arxiv.org/abs/2508.16169)
*Lukas Herrmann,Ángel F. García-Fernández,Edmund F. Brekke,Egil Eide*

Main category: eess.SP

TL;DR: 提出了一种结合检测前跟踪(TBD)和检测跟踪的混合框架，用于海岸雷达监视中的多目标跟踪，解决了TBD方法计算复杂和可扩展性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管TBD方法在理论上有优势，但由于计算复杂性和有限的可扩展性，在实际多目标跟踪应用中很少使用。需要一种能够在资源受限条件下处理复杂海上环境的可扩展解决方案。

Method: 使用IE-PHPMHT TBD模块与常规PMBM点跟踪器相结合的混合框架。处理原始雷达数据包括地杂波抑制、单元检测和基于聚类的特征提取。高阈值检测用于跟踪强目标，低阈值检测用于TBD模块的自适应新生，实现弱目标或模糊目标的早期起始和持续跟踪。

Result: 使用挪威特隆赫姆峡湾的真实X波段雷达数据进行验证，该方法在资源约束下的大范围观测区域中展示了鲁棒的多目标跟踪性能。

Conclusion: 该方法适用于复杂海上环境中的操作部署，支持海岸监视和自主性需求，展示了在实际应用中的可行性。

Abstract: Despite their theoretical advantages, track-before-detect (TBD) methods
remain largely absent from real-world multi-target tracking applications due to
their computational complexity and limited scalability. This paper presents a
scalable hybrid tracking framework that combines a TBD multi-target tracking
algorithm with a detection-based multi-target tracking algorithm for coastal
radar surveillance. In particular, the approach uses an integrated existence
Poisson histogram-probabilistic multi-hypothesis tracking (IE-PHPMHT)-based TBD
module with a conventional Poisson multi-Bernoulli Mixture (PMBM) point
tracker. The system processes raw radar data through land clutter suppression,
cell-wise detection, and clustering-based feature extraction. High-threshold
detections are used to track strong targets via the point tracker, while
low-threshold detections are employed for adaptive birth in the TBD module,
enabling early initiation and sustained tracking of weak or ambiguous targets.
Validated using real X-band radar data from the Trondheim Fjord, Norway, the
approach demonstrates robust multi-target tracking performance in a full-scale
application with a large observation area under resource constraints,
highlighting its suitability for operational deployment in complex maritime
environments needed for coastal surveillance and to support autonomy.

</details>


### [18] [Hybrid Precoding Revisited: Low-Dimensional Subspace Perspective for MU-MIMO Systems](https://arxiv.org/abs/2508.16218)
*Mintaek Oh,Jinseok Choi*

Main category: eess.SP

TL;DR: 提出了一种基于低维子空间特性的低复杂度混合预编码框架，用于多用户MIMO系统，包括动态子阵列天线分区和统计CSIT利用方法


<details>
  <summary>Details</summary>
Motivation: 多用户MIMO系统中传统混合预编码方法复杂度高，需要开发低复杂度且性能优越的预编码方案

Method: 利用低维子空间特性识别无约束最优RF预编码器，通过降复杂度预编码方法优化混合预编码器，扩展包括动态子阵列天线分区和基于信道协方差的统计CSIT利用

Result: 仿真验证所提算法在显著降低复杂度的同时，相比现有方法实现了更优越的性能

Conclusion: 该低复杂度混合预编码框架为多用户MIMO系统提供了有效的解决方案，在性能和复杂度之间取得了良好平衡

Abstract: This letter presents a low-complexity hybrid precoding framework for
multiuser multiple-input multiple-output (MIMO) systems by leveraging a
low-dimensional subspace property. Under the low-dimensional subspace
perspective, we first identify an unconstrained optimal radio-frequency (RF)
precoder. We then optimize a hybrid precoder via a reduced-complexity precoding
method. We further extend the proposed framework to (i) a dynamic-subarray
antenna partitioning algorithm that adaptively allocates subsets of antennas
associated with RF chains, and (ii) a channel covariance-based approach to
exploit statistical channel state information at a transmitter (CSIT), ensuring
robustness with partial CSIT. Simulations validate that our proposed algorithms
achieve superior performance while significantly reducing complexity compared
to existing methods.

</details>


### [19] [Parameter-Free Logit Distillation via Sorting Mechanism](https://arxiv.org/abs/2508.16544)
*Stephen Ekaputra Limantoro*

Main category: eess.SP

TL;DR: 提出一种基于排序机制的logit处理方法，通过修正教师模型的错误预测并重新排序分布来改进知识蒸馏效果


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法通常直接使用教师模型的原始分布，忽略了错误预测的潜在影响，这与通过交叉熵损失进行硬标签学习的动机相矛盾，可能导致某些样本的知识蒸馏效果不佳

Method: 提出一种新颖的logit处理方案，通过排序机制实现两个目标：(1)基于标签修正教师模型的错误预测；(2)按照优先级排名自然重新排序分布。该方法可作为即插即用的预处理模块应用于现有的基于logit的知识蒸馏方法

Result: 在CIFAR-100和ImageNet数据集上的大量实验证明了该方法的有效性

Conclusion: 所提出的排序方法是一种易于使用的预处理技术，能够有效提升现有知识蒸馏方法的性能

Abstract: Knowledge distillation (KD) aims to distill the knowledge from the teacher
(larger) to the student (smaller) model via soft-label for the efficient neural
network. In general, the performance of a model is determined by accuracy,
which is measured with labels. However, existing KD approaches usually use the
teacher with its original distribution, neglecting the potential of incorrect
prediction. This may contradict the motivation of hard-label learning through
cross-entropy loss, which may lead to sub-optimal knowledge distillation on
certain samples. To address this issue, we propose a novel logit processing
scheme via a sorting mechanism. Specifically, our method has a two-fold goal:
(1) fixing the incorrect prediction of the teacher based on the labels and (2)
reordering the distribution in a natural way according to priority rank at
once. As an easy-to-use, plug-and-play pre-processing, our sort method can be
effectively applied to existing logit-based KD methods. Extensive experiments
on the CIFAR-100 and ImageNet datasets demonstrate the effectiveness of our
method.

</details>
