<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [cs.IT](#cs.IT) [Total: 5]
- [eess.IV](#eess.IV) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Closed-form Expression of the Gaussian Noise Model Supporting O-Band Transmission](https://arxiv.org/abs/2510.11867)
*Zelin Gan,Henrique Buglia,Romulo Aparecido,Mindaugas Jarmolovičius,Eric Sillekens,Jiaqian Yang,Ronit Sohanpal,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 提出了一种用于O波段低色散传输系统中非线性干扰估计的闭式模型，该模型结合了四波混频效率项以及多跨距中自相位调制和交叉相位调制的相干贡献，相比传统高斯噪声模型更准确。


<details>
  <summary>Details</summary>
Motivation: 传统闭式高斯噪声模型在低色散O波段传输系统中存在局限性，需要开发更准确的非线性干扰估计模型来支持系统优化。

Method: 通过结合四波混频效率项以及自相位调制和交叉相位调制的相干贡献，扩展了闭式模型，并在41-161个信道、96 GBaud符号率、最高16.1 THz带宽、80-800 km传输距离条件下进行了验证。

Result: 与分步傅里叶方法和数值积分相比，非线性干扰信噪比的平均绝对误差低于0.22 dB，验证了模型的准确性。

Conclusion: 所提出的闭式模型为O波段相干传输系统优化提供了高效且准确的工具。

Abstract: We present a novel closed-form model for nonlinear interference (NLI)
estimation in low-dispersion O-band transmission systems. The formulation
incorporates the four-wave mixing (FWM) efficiency term as well as the coherent
contributions of self- and cross-phase modulation (SPM/XPM) across multiple
identical spans. This extension enables accurate evaluation of the NLI in
scenarios where conventional closed-form Gaussian Noise (GN) models are
limited. The proposed model is validated against split-step Fourier method
(SSFM) simulations and numerical integration across 41-161 channels, with a 96
GBaud symbol rate, bandwidths of up to 16.1 THz, and transmission distances
from 80 to 800 km. Results show a mean absolute error of the NLI
signal-to-noise ratio (SNR) below 0.22 dB. The proposed closed-form model
offers an efficient and accurate tool for system optimisation in O-band
coherent transmission.

</details>


### [2] [Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems](https://arxiv.org/abs/2510.11891)
*Haoran He*

Main category: eess.SP

TL;DR: 提出一种基于深度神经网络的机器学习方法用于大规模MIMO系统信道估计，相比传统LS和MMSE方法在NMSE和BER性能上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决5G及未来网络中由导频污染和高移动性导致的信道估计不准确问题，提高系统可靠性。

Method: 使用多层感知器DNN架构，包含3个隐藏层(256,128,64神经元)，ReLU激活函数，Adam优化器和MSE损失函数，从导频信号学习预测信道矩阵。

Result: 在COST 2100数据集上验证，DNN方法在中等SNR下比LS和MMSE方法NMSE性能提升3-5dB，在高移动性场景下表现稳健，计算复杂度为2.3 GFlOPs，推理时间1.8ms。

Conclusion: 该工作推动了机器学习在无线通信中的集成，为下一代网络提供了高效的资源分配和频谱效率提升方案。

Abstract: This paper proposes a machine learning-assisted channel estimation approach
for massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE
methods. In 5G and beyond, accurate channel estimation mitigates pilot
contamination and high mobility issues that harm system reliability. The
proposed DNN architecture includes multi-layer perceptrons with ReLU
activation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam
optimizer (learning rate 1e-4) and MSE loss function. It learns from pilot
signals to predict channel matrices, achieving lower NMSE and BER across
different SNR levels. Simulations use the COST 2100 public standard dataset (a
well-recognized MIMO channel dataset for 5G, not synthetic datasets) with
10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show
the DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust
performance in high-mobility scenarios. The study evaluates metrics like NMSE
vs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations,
and computational complexity. The DNN has 2.3 GFlOPs computational complexity,
15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying
deployment feasibility. This work advances ML integration in wireless
communications, facilitating efficient resource allocation and improved
spectral efficiency in next-generation networks. Future work may use more
real-world datasets and hybrid architectures for better generalization.

</details>


### [3] [Beyond-Diagonal RIS Architecture Design and Optimization under Physics-Consistent Models](https://arxiv.org/abs/2510.12366)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文研究了基于物理一致模型的对角线外可重构智能表面（BD-RIS）架构设计与优化，提出了多种优化算法，并评估了电磁效应对系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有BD-RIS研究大多依赖简化的信道模型，忽略了实际电磁效应如互耦和阻抗失配。本文旨在解决这一研究空白，在物理一致模型下研究BD-RIS的架构设计与优化。

Method: 基于多端口网络理论构建物理一致模型，开发了多种优化方法：针对SISO系统的闭式解、针对单流MIMO系统的SDR全局最优算法、针对多用户MIMO系统的ADMM高效算法。

Result: 研究发现带状连接RIS与全连接RIS具有相同的信道整形能力，扩展了传统信道模型下的现有结果。通过仿真评估了各种电磁效应和近似方法对系统性能的影响。

Conclusion: 在物理一致模型下，BD-RIS架构设计与优化能够有效考虑实际电磁效应，提出的优化算法在不同系统配置下均表现良好，为实际部署提供了理论支持。

Abstract: Reconfigurable intelligent surface (RIS) is a promising technology for future
wireless communication systems. Conventional RIS is constrained to a diagonal
scattering matrix, which limits its flexibility. Recently, beyond-diagonal RIS
(BD-RIS) has been proposed as a more general RIS architecture class that allows
inter-element connections and shows great potential for performance
improvement. Despite extensive progress on BD-RIS, most existing studies rely
on simplified channel models that ignore practical electromagnetic (EM) effects
such as mutual coupling and impedance mismatching. To address this gap, this
paper investigates the architecture design and optimization of BD-RIS under the
general physics-consistent model derived with multiport network theory in
recent literature. Building on a compact reformulation of this model, we show
that band-connected RIS achieves the same channel-shaping capability as
fully-connected RIS, which extends existing results obtained for conventional
channel models. We then develop optimization methods under the general
physics-consistent model; specifically, we derive closed-form solutions for
single-input single-output (SISO) systems, propose a globally optimal
semidefinite relaxation (SDR)-based algorithm for single-stream multi-input
multi-output (MIMO) systems, and design an efficient alternating direction
method of multipliers (ADMM)-based algorithm for multiuser MIMO systems. Using
the proposed algorithms, we conduct comprehensive simulations to evaluate the
impact of various EM effects and approximations, including mutual coupling
among RIS antennas and the commonly adopted unilateral approximation, on system
performance.

</details>


### [4] [Using STAR-IRS to Secure Indoor Communications Through Symbol-Level Random Phase Modulation](https://arxiv.org/abs/2510.11925)
*Yanan Du,Zeyang Sun,Yilan Zhang,Sai Xu,Beiyuan Liu*

Main category: eess.SP

TL;DR: 提出基于STAR-IRS的安全室内通信方案，使用GNN优化保密率，并通过FPGA加速器降低计算延迟


<details>
  <summary>Details</summary>
Motivation: 保护室内用户与发射器之间的保密通信，防止室外窃听者窃听信息

Method: 部署STAR-IRS在墙壁或窗户上，将电磁波动态分为反射和透射两部分：反射信号增强目标用户接收，透射信号通过符号级随机相位调制降低窃听者信号质量；使用GNN求解保密率最大化问题，并设计FPGA加速器

Result: 仿真显示该方案在保密性能上优于传统方案和仅反射方案；GNN方法在求解优化问题时优于MRT、ZF和MMSE基准技术；FPGA加速器实现了低推理延迟

Conclusion: STAR-IRS结合GNN优化和FPGA加速是有效的安全室内通信解决方案，能显著提升保密性能并降低计算延迟

Abstract: This paper proposes a secure indoor communication scheme based on
simultaneous transmitting and reflecting intelligent reflecting surface
(STAR-IRS). Specifically, a transmitter (Alice) sends confidential information
to its intended user (Bob) indoors, while several eavesdroppers (Eves) lurk
outside. To safeguard the transmission from eavesdropping, the STAR-IRS is
deployed on walls or windows. Upon impinging on the STAR-IRS, the incoming
electromagnetic wave is dynamically partitioned into two components, enabling
both transmission through and reflection from the surface. The reflected signal
is controlled to enhance reception at Bob, while the transmitted signal is
modulated with symbol-level random phase shifts to degrade the signal quality
at Eves. Based on such a setting, the secrecy rate maximization problem is
formulated. To solve it, a graph neural network (GNN)-based scheme is
developed. Furthermore, a field-programmable gate array (FPGA)-based GNN
accelerator is designed to reduce computational latency. Simulation results
demonstrate that the proposed strategy outperforms both the conventional scheme
and the reflection-only scheme in terms of secrecy performance. Moreover, the
GNN-based approach achieves superior results compared to benchmark techniques
such as maximum ratio transmission (MRT), zero forcing (ZF), and minimum mean
square error (MMSE) in solving the optimization problem. Finally, experimental
evaluations confirm that the FPGA-based accelerator enables low inference
latency.

</details>


### [5] [62.6 GHz ScAlN Solidly Mounted Acoustic Resonators](https://arxiv.org/abs/2510.11994)
*Yinan Wang,Byeongjin Kim,Nishanth Ravi,Kapil Saha,Supratik Dasgupta,Vakhtang Chulukhadze,Eugene Kwon,Lezli Matto,Pietro Simeoni,Omar Barrera,Ian Anderson,Tzu-Hsuan Hsu,Jue Hou,Matteo Rinaldi,Mark S. Goorsky,Ruochen Lu*

Main category: eess.SP

TL;DR: 该论文展示了创纪录的62.6 GHz固态安装声学谐振器，采用67.6 nm钪铝氮化物压电层和40 nm铂底电极，在声学布拉格反射器上实现第三阶厚度伸缩体声波模式。


<details>
  <summary>Details</summary>
Motivation: 开发用于下一代射频前端的毫米波SMR器件，为滤波器和谐振器提供高性能解决方案。

Method: 使用67.6 nm Sc0.3Al0.7N压电层和40 nm Pt底电极，在8.5对交替SiO2/Ta2O5层构成的声学布拉格反射器上设计第三阶厚度伸缩体声波模式。

Result: 制造的SMR在63 GHz处提取的压电耦合系数为0.8%，最大Bode品质因子为51，是目前报道的最高工作频率SMR。

Conclusion: 这些结果为毫米波SMR器件在下一代射频前端中的应用建立了可行途径。

Abstract: We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator
(SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N)
piezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode,
positioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2
nm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and
piezoelectric stack above are designed to confine a third-order
thickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently
transducing with thickness-field excitation. The fabricated SMR exhibits an
extracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode
quality factor (Q) of 51 at 63 GHz, representing the highest operating
frequency reported for an SMR to date. These results establish a pathway toward
mmWave SMR devices for filters and resonators in next-generation RF front ends.

</details>


### [6] [A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation](https://arxiv.org/abs/2510.12179)
*Abdullahi Mohammad,Bdah Eya,Bassant Selim*

Main category: eess.SP

TL;DR: 提出基于CNN-LSTM架构的多任务学习框架，结合注意力机制，用于联合估计脉冲噪声参数，通过统一加权损失函数实现多参数同时学习。


<details>
  <summary>Details</summary>
Motivation: 脉冲噪声严重影响无线通信系统可靠性，需要准确估计其统计参数以实现有效抑制。

Method: 使用CNN-LSTM架构的多任务学习框架，集成注意力机制，采用统一加权损失函数在共享表示空间中同时学习多个参数。

Result: 实验表明该框架实现稳定收敛、更快训练和增强的可扩展性，与单任务学习模型相比具有更好的复杂度-性能权衡和显著内存节省。

Conclusion: 多任务学习方法在无线系统实时脉冲噪声参数估计中表现出有效性。

Abstract: Impulsive noise poses a significant challenge to the reliability of wireless
communication systems, necessitating accurate estimation of its statistical
parameters for effective mitigation. This paper introduces a multitask learning
(MTL) framework based on a CNN-LSTM architecture enhanced with an attention
mechanism for the joint estimation of impulsive noise parameters. The proposed
model leverages a unified weighted-loss function to enable simultaneous
learning of multiple parameters within a shared representation space, improving
learning efficiency and generalization across related tasks. Experimental
results show that the proposed MTL framework achieves stable convergence,
faster training, and enhanced scalability with modest computational overhead.
Benchmarking against conventional single-task learning (STL) models confirms
its favorable complexity-performance trade-off and significant memory savings,
indicating the effectiveness of the MTL approach for real-time impulsive noise
parameter estimation in wireless systems.

</details>


### [7] [Probabilistic Constellation Shaping for OFDM ISAC Signals Under Temporal-Frequency Filtering](https://arxiv.org/abs/2510.12204)
*Zhen Du,Jingjing Xu,Yifeng Xiong,Jie Wang,Musa Furkan Keskin,Henk Wymeersch,Fan Liu,Shi Jin*

Main category: eess.SP

TL;DR: 提出了一种统一的概率星座整形框架，用于在6G集成感知与通信系统中平衡通信速率和感知性能，通过优化通信速率同时约束感知CSI的均方误差、功率和概率分布来实现灵活的感知与通信权衡。


<details>
  <summary>Details</summary>
Motivation: 在6G集成感知与通信系统中，使用OFDM通信信号进行感知虽然成本效益高，但有限字母调制（如QAM）引入的随机性会显著降低匹配和不匹配滤波方案的感知性能，需要在保持通信能力的同时提升感知性能。

Method: 提出了统一的概率星座整形框架，通过最大化通信速率同时约束感知信道状态信息的均方误差、功率和概率分布，优化感知能力。该方法兼容匹配和不匹配滤波方案，并分析了不同感知度量之间的内在关系。

Result: 仿真和现场测量验证了所提出的PCS方法在实现灵活感知与通信权衡方面的有效性，以及在真实6G无线传输场景中增强性能的可信度。

Conclusion: 该概率星座整形框架为6G集成感知与通信系统提供了一种有效的解决方案，能够在保持通信能力的同时显著提升感知性能，并通过实际验证证明了其在现实场景中的实用性。

Abstract: Integrated sensing and communications (ISAC) is considered an innovative
technology in sixth-generation (6G) wireless networks, where utilizing
orthogonal frequency division multiplexing (OFDM) communication signals for
sensing provides a cost-effective solution for implementing ISAC. However, the
sensing performance of matched and mismatched filtering schemes can be
significantly deteriorated due to the signaling randomness induced by
finite-alphabet modulations with nonconstant modulus, such as quadrature
amplitude modulation (QAM) constellations. Therefore, improving sensing
performance without significantly compromising communication capability (i.e.,
maintaining randomness), remains a challenging task. To that end, we propose a
unified probabilistic constellation shaping (PCS) framework that is compatible
with both matched and mismatched filtering schemes, by maximizing the
communication rate while imposing constraints on mean square error (MSE) of
sensing channel state information (CSI), power, and probability distribution.
Specifically, the MSE of sensing CSI is leveraged to optimize sensing
capability, which is illustrated to be a more comprehensive metric compared to
the output SNR after filtering (SNRout) and integrated sidelobes ratio (ISLR).
Additionally, the internal relationships among these three sensing metrics are
explicitly analyzed. Finally, both simulations and field measurements validate
the efficiency of proposed PCS approach in achieving a flexible S&C trade-off,
as well as its credibility in enhancing 6G wireless transmission in real-world
scenarios.

</details>


### [8] [Wireless Channel Modeling for Machine Learning -- A Critical View on Standardized Channel Models](https://arxiv.org/abs/2510.12279)
*Benedikt Böck,Amar Kasibovic,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 论文指出3GPP TDL和CDL等标准化链路级信道模型在评估基于机器学习的物理层方法时存在局限性，会导致分布偏移和近高斯特性，使得ML模型无法超越经典方法。采用场景级视角可以解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有标准化链路级信道模型在评估ML物理层方法时存在限制性假设，导致分布偏移和近高斯特性，使得ML模型表现不佳，需要寻找更好的评估框架。

Method: 通过分析链路级信道模型的局限性，论证线性方法在信道压缩、估计和建模中的最优性，并提出采用场景级视角作为解决方案。

Result: 研究表明在链路级信道模型下，ML模型无法超越经典线性方法，而场景级视角能够解锁ML的相对增益。

Conclusion: 链路级信道模型不适合评估ML模型，应采用场景级视角来充分发挥ML在物理层应用中的潜力。

Abstract: Standardized (link-level) channel models such as the 3GPP TDL and CDL models
are frequently used to evaluate machine learning (ML)-based physical-layer
methods. However, in this work, we argue that a link-level perspective
incorporates limiting assumptions, causing unwanted distributional shifts or
necessitating impractical online training. An additional drawback is that this
perspective leads to (near-)Gaussian channel characteristics. Thus, ML-based
models, trained on link-level channel data, do not outperform classical
approaches for a variety of physical-layer applications. Particularly, we
demonstrate the optimality of simple linear methods for channel compression,
estimation, and modeling, revealing the unsuitability of link-level channel
models for evaluating ML models. On the upside, adopting a scenario-level
perspective offers a solution to this problem and unlocks the relative gains
enabled by ML.

</details>


### [9] [A New Method of Constructing Hadamard Matrices, Circulant Hadamard Matrices, CZCS, GCS, CCC, and CZCSS](https://arxiv.org/abs/2510.12315)
*Piyush Priyanshu,Sudhan Majhi,Subhabrata Paul*

Main category: eess.SP

TL;DR: 本文提出了一种使用线性算子和广义布尔函数构造所有8个4阶循环Hadamard矩阵的新方法，并利用这些矩阵递归构造了覆盖所有长度的二进制交叉Z互补集(CZCS)、Golay互补集(GCS)以及Hadamard矩阵。


<details>
  <summary>Details</summary>
Motivation: 之前缺乏覆盖所有长度的二进制CZCS构造方法，且需要更灵活的GCS构造方案。本文旨在解决这些问题，并为Hadamard猜想的研究提供新方向。

Method: 使用线性算子和广义布尔函数构造循环Hadamard矩阵，然后递归构造CZCS、GCS和Hadamard矩阵。还提出了基于循环矩阵的低复杂度替代构造方法。

Result: 成功构造了所有8个4阶循环Hadamard矩阵，实现了覆盖所有长度的二进制CZCS（首次实现）、具有灵活群大小的GCS，以及参数为(2N,2N,2N)-CCC的二进制完全互补码和(2^{n+2},2^{n+2},2^{n+2},2^{n+1})-CZCSS的最优交叉Z互补序列集。

Conclusion: 所有提出的构造方法都是新颖的，参数优于现有技术。建立了Hadamard矩阵与GCS之间的关系，为Hadamard猜想的研究开辟了新方向。

Abstract: A Hadamard matrix $H$ is a square matrix of order $n$ with entries $\pm 1$,
such that $HH^\top=nI_{n}$, where $I_n$ is an identity matrix of order $n$. A
circulant Hadamard matrix $H$ is a Hadamard matrix that has rows of entries in
cyclic order. There exist only $8$ circulant Hadamard matrices of order 4, and
here, we provide a novel construction of all such $8$ circulant Hadamard
matrices using a linear operator and generalized Boolean function (GBF). The
constructed circulant Hadamard matrices are used recursively to construct a
binary cross Z-complementary set (CZCS) of all lengths with an even phase, a
binary Golay complementary set (GCS) of all lengths, and Hadamard matrices of
order $2^{n+2}$, where $n\geq1$. The construction of a binary CZCS covering all
lengths was not available before. We also propose an alternative,
lower-complexity construction of binary GCSs of all lengths and Hadamard
matrices of order $2^{a+1}10^b26^c$ using circulant matrices, where $ a,b,c
\geq 0$. The proposed binary GCS covers all lengths with a flexible flock size.
The constructions of GCS are further extended to form binary complete
complementary code (CCC) of the parameter $(2N,2N,2N)-CCC$ where
$N=2^a10^b26^c, a,b,c \geq 0$. The constructed binary CCC provides a flexible
flock size. The construction of CZCS is further extended to form a binary
optimal cross-Z complementary sequence set (CZCSS) of the parameter $(2^{n+2},
2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$, where $n\geq1$. Finally, we provide a
relation between Hadamard matrices and GCS, which enables the study of the
Hadamard conjecture in a new direction. We also provided a few properties of
circulant matrices over aperiodic cross-correlation (ACCF) and aperiodic
auto-correlation (AACF), which are used to prove the theorems. All proposed
constructions are novel, and their parameters are compared with the existing
state-of-the-art.

</details>


### [10] [HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation](https://arxiv.org/abs/2510.12515)
*Zhige Chen,Chengxuan Qin,Wenlong You,Rui Liu,Congying Chu,Rui Yang,Kay Chen Tan,Jibin Wu*

Main category: eess.SP

TL;DR: HEAR是首个专门支持异构EEG设备的EEG基础模型，通过可学习的基于坐标的空间嵌入将不同电极布局和数量的设备映射到统一表示空间，使用空间引导transformer捕获时空依赖关系。


<details>
  <summary>Details</summary>
Motivation: EEG设备异构性阻碍了大规模EEG基础模型的广泛应用和进一步发展，需要解决不同电极布局和电极数量带来的挑战。

Method: 使用可学习的基于坐标的空间嵌入统一不同电极布局，采用空间引导transformer处理时空依赖关系，构建包含8,782小时数据的大规模EEG数据集。

Result: HEAR在支持异构EEG设备和跨认知任务、跨被试泛化方面显著优于现有EEG基础模型。

Conclusion: HEAR成功解决了EEG设备异构性问题，为EEG基础模型的广泛应用和进一步发展提供了有效解决方案。

Abstract: Electroencephalography (EEG) is an essential technique for neuroscience
research and brain-computer interface (BCI) applications. Recently, large-scale
EEG foundation models have been developed, exhibiting robust generalization
capabilities across diverse tasks and subjects. However, the heterogeneity of
EEG devices not only hinders the widespread adoption of these models but also
poses significant challenges to their further scaling and development. In this
paper, we introduce HEAR, the first EEG foundation model explicitly designed to
support heterogeneous EEG devices, accommodating varying electrode layouts and
electrode counts. HEAR employs a learnable, coordinate-based spatial embedding
to map electrodes with diverse layouts and varying counts into a unified
representational space. This unified spatial representation is then processed
by a novel spatially-guided transformer, which effectively captures
spatiotemporal dependencies across electrodes. To support the development of
HEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data
collected from over 150 distinct electrode layouts with up to 1,132 electrodes.
Experimental results demonstrate that HEAR substantially outperforms existing
EEG foundation models in supporting heterogeneous EEG devices and generalizing
across diverse cognitive tasks and subjects.

</details>


### [11] [A Unified Framework for Adaptive Waveform Processing in Next Generation Wireless Networks](https://arxiv.org/abs/2510.12648)
*Abdelali Arous,Hamza Haif,Arman Farhang,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本文提出了一个通用的自适应变换域框架，通过DFT矩阵的前后处理实现不同域间的动态转换，以应对复杂传播环境和下一代应用需求。


<details>
  <summary>Details</summary>
Motivation: 传统的时频域在复杂传播环境和下一代应用中面临挑战，而延迟-多普勒域和啁啾域等新型多路复用域提供了额外的自由度来建模和利用无线信道特性。

Method: 提出基于离散傅里叶变换(DFT)矩阵前后处理的广义自适应变换域框架，支持根据信道条件和系统需求在不同域间动态切换。

Result: 建立了跨域波形处理框架，能够适应不同信道条件，并在多种场景中展示了其适用性。

Conclusion: 跨域波形处理框架为解决复杂无线环境挑战提供了有效方法，未来需要进一步研究其实际应用和面临的挑战。

Abstract: The emergence of alternative multiplexing domains to the time-frequency
domains, e.g., the delay-Doppler and chirp domains, offers a promising approach
for addressing the challenges posed by complex propagation environments and
next-generation applications. Unlike the time and frequency domains, these
domains offer unique channel representations which provide additional degrees
of freedom (DoF) for modeling, characterizing, and exploiting wireless channel
features. This article provides a comprehensive analysis of channel
characteristics, including delay, Doppler shifts, and channel coefficients
across various domains, with an emphasis on their inter-domain relationships,
shared characteristics, and domain-specific distinctions. We further evaluate
the comparative advantages of each domain under specific channel conditions.
Building on this analysis, we propose a generalized and adaptive transform
domain framework that leverages the pre- and post-processing of the discrete
Fourier transform (DFT) matrix, to enable dynamic transitions between various
domains in response to the channel conditions and system requirements. Finally,
several representative use cases are presented to demonstrate the applicability
of the proposed cross-domain waveform processing framework in diverse
scenarios, along with future directions and challenges.

</details>


### [12] [Moment-based Posterior Sampling for Multi-reference Alignment](https://arxiv.org/abs/2510.12651)
*Axel Janson,Joakim Andén*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯方法和扩散模型的多参考对齐方法，通过使用样本功率谱作为条件，显著减少了所需样本数量，同时提供准确的后验采样和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现有频率方法虽然能在低信噪比下准确恢复信号，但需要大量样本。本文旨在开发一种能够减少所需样本数量的方法。

Method: 使用扩散模型作为数据驱动的即插即用先验，以样本功率谱（平移不变统计量）为条件，实现后验采样和不确定性量化。

Result: 仿真实验表明，与期望最大化、双谱反演等最先进方法相比，该方法显著减少了所需样本数量。

Conclusion: 该方法为其他轨道恢复问题（如冷冻电镜）提供了一个有前景的框架。

Abstract: We propose a Bayesian approach to the problem of multi-reference alignment --
the recovery of signals from noisy, randomly shifted observations. While
existing frequentist methods accurately recover the signal at arbitrarily low
signal-to-noise ratios, they require a large number of samples to do so. In
contrast, our proposed method leverages diffusion models as data-driven
plug-and-play priors, conditioning these on the sample power spectrum (a
shift-invariant statistic) enabling both accurate posterior sampling and
uncertainty quantification. The use of an appropriate prior significantly
reduces the required number of samples, as illustrated in simulation
experiments with comparisons to state-of-the-art methods such as
expectation--maximization and bispectrum inversion. These findings establish
our approach as a promising framework for other orbit recovery problems, such
as cryogenic electron microscopy (cryo-EM).

</details>


### [13] [Enhanced Angle-Range Cluster Parameter Estimation in Full-Duplex ISAC Systems](https://arxiv.org/abs/2510.12711)
*Muhammad Talha,Besma Smida,David González G*

Main category: eess.SP

TL;DR: 提出了一种用于角度和距离域分布目标的集成感知与通信框架，包括截断MUSIC扩展算法和基于DFT的距离估计算法，以及动态发射波束成形方案。


<details>
  <summary>Details</summary>
Motivation: 研究在角度和距离域均有分布的目标的集成感知与通信问题，需要准确估计目标密度函数参数并同时服务多个下行用户。

Method: 使用射线簇建模目标，提出截断MUSIC扩展算法估计密度函数参数，基于DFT的算法估计距离和范围扩展，开发动态发射波束成形算法。

Result: 仿真结果表明，在低高信噪比和宽角度扩展情况下，所提算法优于基线方案。

Conclusion: 提出的集成感知与通信框架能有效估计分布目标参数并同时服务多个用户，在各种场景下均表现出优越性能。

Abstract: This work studies an integrated sensing and communication (ISAC) framework
for targets that are spread both in the angle and range domains. We model each
target using a cluster of rays parameterized by a specific density function,
and propose a truncated Multiple Signal Classification (MUSIC) spread (TMS)
algorithm to accurately estimate the parameters of the density function. Unlike
the conventional MUSIC spread (CMS), TMS restricts the signal subspace rank
based on the eigen decomposition of the received-signal autocorrelation. We
also propose a discrete Fourier transform (DFT) based algorithm for estimating
the distance and range spread of each target. Leveraging these estimates, we
then develop a dynamic transmit beamforming algorithm that successfully
illuminates multiple targets while also serving multiple downlink (DL) users.
Simulation results demonstrate the superiority of our proposed algorithms over
baseline schemes in both low and high signal-to-noise ratio (SNR) regimes as
well as under a wide angular spread regime.

</details>


### [14] [Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective](https://arxiv.org/abs/2510.12763)
*Saurabh Sihag,Gonzalo Mateos,Alejandro Ribeiro*

Main category: eess.SP

TL;DR: 本文介绍了基于图信号处理的大脑年龄差距预测模型，特别是协方差神经网络，用于解决传统神经退行性变评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统MRI评估神经退行性变的方法缺乏统计复杂性，无法充分捕捉空间相关性和异质性。大脑年龄差距作为数据驱动的生物标志物具有潜力，但现有模型存在方法不透明和泛化性差的问题。

Method: 提出基于图信号处理的框架，重点介绍图神经网络和协方差神经网络，利用结构MRI衍生的解剖协方差矩阵进行大脑年龄预测。

Result: 协方差神经网络提供了强大的理论基础和操作可解释性，能够稳健地估计大脑年龄差距预测。

Conclusion: 通过整合图信号处理、机器学习和网络神经科学的视角，为可靠且可解释的大脑年龄差距预测模型指明了前进方向，并概述了个性化医疗的未来研究方向。

Abstract: Neurodegeneration, characterized by the progressive loss of neuronal
structure or function, is commonly assessed in clinical practice through
reductions in cortical thickness or brain volume, as visualized by structural
MRI. While informative, these conventional approaches lack the statistical
sophistication required to fully capture the spatially correlated and
heterogeneous nature of neurodegeneration, which manifests both in healthy
aging and in neurological disorders. To address these limitations, brain age
gap has emerged as a promising data-driven biomarker of brain health. The brain
age gap prediction (BAGP) models estimate the difference between a person's
predicted brain age from neuroimaging data and their chronological age. The
resulting brain age gap serves as a compact biomarker of brain health, with
recent studies demonstrating its predictive utility for disease progression and
severity. However, practical adoption of BAGP models is hindered by their
methodological obscurities and limited generalizability across diverse clinical
populations. This tutorial article provides an overview of BAGP and introduces
a principled framework for this application based on recent advancements in
graph signal processing (GSP). In particular, we focus on graph neural networks
(GNNs) and introduce the coVariance neural network (VNN), which leverages the
anatomical covariance matrices derived from structural MRI. VNNs offer strong
theoretical grounding and operational interpretability, enabling robust
estimation of brain age gap predictions. By integrating perspectives from GSP,
machine learning, and network neuroscience, this work clarifies the path
forward for reliable and interpretable BAGP models and outlines future research
directions in personalized medicine.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [15] [Approximate Proximal Operators for Analog Compressed Sensing Using PN-junction Diode](https://arxiv.org/abs/2510.12065)
*Soma Furusawa,Taisei Kato,Ryo Hayakawa,Kazunori Hayashi*

Main category: cs.IT

TL;DR: 该论文提出使用PN结二极管的正向电压-电流特性实现ℓ₁和MCP正则化函数的近似近端算子，用于模拟压缩感知。通过计算机仿真验证了在考虑模拟器件噪声的情况下，使用这些近似近端算子的稀疏重建性能。


<details>
  <summary>Details</summary>
Motivation: 为了实现模拟压缩感知，需要找到ℓ₁和MCP正则化函数的近似近端算子的实际实现方法。

Method: 利用PN结二极管的正向电压-电流特性设计电子模拟电路，实现ℓ₁和MCP正则化函数的近似近端算子，并将其应用于近端梯度法的压缩感知中。

Result: 通过计算机仿真表明，使用提出的近似近端算子的算法具有良好的稀疏重建性能，即使在考虑模拟器件引入的加性噪声的情况下。

Conclusion: 提出的基于PN结二极管特性的近似近端算子实现方法是有效的，可用于模拟压缩感知系统。

Abstract: In order to realize analog compressed sensing, the paper considers
approximate proximal operators of the $\ell_1$ and minimax concave penalty
(MCP) regularization functions. Specifically, we propose to realize the
approximate functions by an electric analog circuit using forward
voltage-current (V-I) characteristics of the PN-junction diodes. To confirm the
validity of the proposed approach, we employ the proposed approximate proximal
operators for the $\ell_1$ and MCP regularization functions in compressed
sensing with the proximal gradient method. The sparse reconstruction
performance of the algorithms using the proposed approximate proximal operators
is demonstrated via computer simulations taking into account the impact of
additive noise introduced by analog devices.

</details>


### [16] [FedLoDrop: Federated LoRA with Dropout for Generalized LLM Fine-tuning](https://arxiv.org/abs/2510.12078)
*Sijing Xie,Dingzhu Wen,Changsheng You,Qimei Chen,Mehdi Bennis,Kaibin Huang*

Main category: cs.IT

TL;DR: 提出了FedLoDrop框架，在联邦LoRA中对可训练矩阵的行列应用dropout，通过优化dropout率和资源分配来最小化泛化误差上界，解决过拟合问题并降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 为了在降低训练成本的同时增强大语言模型的泛化能力，需要解决联邦学习中过拟合和有限网络资源的问题。

Method: 提出FedLoDrop框架，对联邦LoRA的可训练矩阵行列应用dropout；建立泛化误差界和收敛性分析；通过分支定界法和惩罚性逐次凸近似算法优化dropout率和资源分配。

Result: 数值结果表明该方法能有效缓解过拟合并提高泛化能力，同时降低通信成本。

Conclusion: FedLoDrop通过dropout和资源联合优化，在保证性能的同时降低了训练成本和通信开销，为边缘网络部署提供了有效解决方案。

Abstract: Fine-tuning (FT) large language models (LLMs) is crucial for adapting
general-purpose models to specific tasks, enhancing accuracy and relevance with
minimal resources. To further enhance generalization ability while reducing
training costs, this paper proposes Federated LoRA with Dropout (FedLoDrop), a
new framework that applies dropout to the rows and columns of the trainable
matrix in Federated LoRA. A generalization error bound and convergence analysis
under sparsity regularization are obtained, which elucidate the fundamental
trade-off between underfitting and overfitting. The error bound reveals that a
higher dropout rate increases model sparsity, thereby lowering the upper bound
of pointwise hypothesis stability (PHS). While this reduces the gap between
empirical and generalization errors, it also incurs a higher empirical error,
which, together with the gap, determines the overall generalization error. On
the other hand, though dropout reduces communication costs, deploying FedLoDrop
at the network edge still faces challenges due to limited network resources. To
address this issue, an optimization problem is formulated to minimize the upper
bound of the generalization error, by jointly optimizing the dropout rate and
resource allocation subject to the latency and per-device energy consumption
constraints. To solve this problem, a branch-and-bound (B\&B)-based method is
proposed to obtain its globally optimal solution. Moreover, to reduce the high
computational complexity of the B\&B-based method, a penalized successive
convex approximation (P-SCA)-based algorithm is proposed to efficiently obtain
its high-quality suboptimal solution. Finally, numerical results demonstrate
the effectiveness of the proposed approach in mitigating overfitting and
improving the generalization capability.

</details>


### [17] [Hybrid centralized-distributed precoding in fronthaul-constrained CF-mMIMO systems](https://arxiv.org/abs/2510.12406)
*Zahra Mobini,Hien Quoc Ngo,Ardavan Rahimian,Anvar Tukmanov,David Townend,Michail Matthaiou,Simon L. Cotton*

Main category: cs.IT

TL;DR: 提出了一种混合集中-分布式预编码策略，用于前传受限的无蜂窝大规模MIMO系统，通过动态用户分组和功率控制来最大化总频谱效率。


<details>
  <summary>Details</summary>
Motivation: 解决前传容量受限的无蜂窝大规模MIMO系统中频谱效率与前传需求之间的权衡问题，需要一种能够适应不同系统配置的灵活预编码方案。

Method: 将用户分为两组：一组采用集中式预编码，另一组采用分布式预编码。通过优化用户分组和功率控制来最大化总频谱效率，同时满足前传容量和接入点功率约束。

Result: 数值结果表明，所提出的混合方案在各种系统配置下均优于完全集中式和完全分布式方法，表现出更好的性能和适应性。

Conclusion: 混合集中-分布式预编码策略为前传受限的无蜂窝大规模MIMO系统提供了一种高效灵活的解决方案，能够平衡频谱效率和前传需求。

Abstract: We investigate a fronthaul-limited cell-free massive multiple-input
multiple-output (CF-mMIMO) system and propose a hybrid centralized-distributed
precoding strategy that dynamically adapts to varying fronthaul and spectral
efficiency (SE) requirements. The proposed approach divides users into two
groups: one served by centralized precoding and the other by distributed
precoding. We formulate a novel optimization problem for user grouping and
power control aimed at maximizing the sum SE, subject to fronthaul and
per-access point (AP) power constraints. To tackle the problem, we transform it
into a tractable form and propose efficient solution algorithms. Numerical
results confirm the hybrid scheme's versatility and superior performance,
consistently outperforming fully centralized and distributed approaches across
diverse system configurations.

</details>


### [18] [Phase Transitions of the Additive Uniform Noise Channel with Peak Amplitude and Cost Constraint](https://arxiv.org/abs/2510.12427)
*Jonas Stapmanns,Catarina Dias,Luke Eilers,Tobias Kühn,Jean-Pascal Pfister*

Main category: cs.IT

TL;DR: 该论文研究了在加性均匀噪声信道下，量化在什么条件下是最优的。通过分析容量实现输入分布与噪声水平、平均成本约束和成本函数曲率的关系，发现当成本函数为凹函数时，最优输入分布是离散的；当成本函数为凸函数且成本约束有效时，最优输入分布支撑整个区间。


<details>
  <summary>Details</summary>
Motivation: 探究在加性均匀噪声信道中，量化成为最优编码策略的具体条件，这对于理解信道容量实现机制具有重要意义。

Method: 在峰值幅度和成本约束下，分析加性均匀噪声信道的容量实现输入分布，考虑噪声水平、平均成本约束和成本函数曲率的影响。

Result: 当成本函数为凹函数时，容量实现输入分布是离散的；当成本函数为凸函数且成本约束有效时，容量实现输入分布支撑整个区间。对于离散最优输入分布的情况，推导出了信道容量的解析表达式。

Conclusion: 量化最优性取决于成本函数的曲率特性：凹成本函数导致离散最优输入分布，凸成本函数导致连续最优输入分布，这为信道编码设计提供了理论指导。

Abstract: Under which condition is quantization optimal? We address this question in
the context of the additive uniform noise channel under peak amplitude and cost
constraints. We compute analytically the capacity-achieving input distribution
as a function of the noise level, the average cost constraint, and the
curvature of the cost function. We find that when the cost function is concave,
the capacity-achieving input distribution is discrete, whereas when the cost
function is convex and the cost constraint is active, the support of the
capacity-achieving input distribution spans the entire interval. For the cases
of a discrete capacity-achieving input distribution, we derive the analytical
expressions for the capacity of the channel.

</details>


### [19] [CoNet-Rx: Collaborative Neural Networks for OFDM Receivers](https://arxiv.org/abs/2510.12739)
*Mohanad Obeed,Ming Jian*

Main category: cs.IT

TL;DR: 提出协作网络(CoNet)用于OFDM接收机，通过多个小型子网络从不同角度处理信号特征，相比传统ResNet在相同复杂度下显著降低误码率和推理延迟


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的OFDM接收机模型通常从计算机视觉领域改编，不适合无线通信场景，存在计算资源需求高、内存占用大、推理延迟显著等问题，且缩小网络规模会导致性能明显下降

Method: 设计协作网络架构，使用多个小型ResNet或CNN子网络同时处理信号的不同特征（如信道相关性和干扰模式），通过元素级乘法等交互操作融合子网络输出

Result: 仿真结果显示CoNet在相同网络规模和计算复杂度下，相比传统ResNet架构显著降低了误码率(BER)和推理延迟

Conclusion: CoNet为资源受限环境下的OFDM接收机提供了一种高效解决方案，在保持高性能的同时降低了计算需求

Abstract: Deep learning (DL) based methods for orthogonal frequency division
multiplexing (OFDM) radio receivers demonstrated higher signal detection
performance compared to the traditional receivers. However, the existing
DL-based models, usually adapted from computer vision, aren't well suited for
wireless communications. These models require high computational resources and
memory, and have significant inference delays, limiting their use in
resource-constrained settings. Additionally, reducing network size to ease
resource demands often leads to notable performance degradation. This paper
introduces collaborative networks (CoNet), a novel neural network (NN)
architecture designed for OFDM receivers. CoNet uses multiple small ResNet or
CNN subnetworks to simultaneously process signal features from different
perspectives like capturing channel correlations and interference patterns.
These subnetworks fuse their outputs through interaction operations (e.g.,
element-wise multiplication), significantly enhancing detection performance.
Simulation results show CoNet significantly outperforms traditional
architectures like residual networks (ResNets) in bit error rate (BER) and
reduces inference delay when both nets have the same size and the same
computational complexity.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [20] [Normalization-equivariant Diffusion Models: Learning Posterior Samplers From Noisy And Partial Measurements](https://arxiv.org/abs/2510.11964)
*Brett Levac,Jon Tamir,Marcelo Pereyra,Julian Tachella*

Main category: eess.IV

TL;DR: 提出了首个仅使用单操作器噪声测量数据训练扩散模型进行图像恢复的方法，通过尺度等变性理论实现从噪声数据中学习，无需干净图像或互补采集过程。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型依赖干净图像训练，但在实际场景中获取无噪声数据困难或不现实，且现有方法需要温和噪声或额外无噪声数据，限制了实际应用。

Method: 发现扩散模型具有弱尺度等变性，据此开发了去噪分数匹配策略，可泛化到比训练数据更低噪声水平；结合等变成像框架处理不完整和噪声数据。

Result: 在图像去噪、去马赛克和修复任务上进行了广泛实验验证，与现有技术相比表现出有效性。

Conclusion: 该方法首次实现了仅使用单操作器噪声测量数据训练扩散模型进行图像恢复，突破了现有方法对干净数据或互补采集过程的依赖。

Abstract: Diffusion models (DMs) have rapidly emerged as a powerful framework for image
generation and restoration. However, existing DMs are primarily trained in a
supervised manner by using a large corpus of clean images. This reliance on
clean data poses fundamental challenges in many real-world scenarios, where
acquiring noise-free data is hard or infeasible, and only noisy and potentially
incomplete measurements are available. While some methods can train DMs using
noisy data, they are generally effective only when the amount of noise is very
mild or when some additional noise-free data is available. In addition,
existing methods for training DMs from incomplete measurements require access
to multiple complementary acquisition processes, an assumption that poses a
significant practical limitation. Here we introduce the first approach for
learning DMs for image restoration using only noisy measurement data from a
single operator. As a first key contribution, we show that DMs, and more
broadly minimum mean squared error denoisers, exhibit a weak form of scale
equivariance linking rescaling in signal amplitude to changes in noise
intensity. We then leverage this theoretical insight to develop a denoising
score-matching strategy that generalizes robustly to noise levels lower than
those present in the training data, thereby enabling the learning of DMs from
noisy measurements. To further address the challenges of incomplete and noisy
data, we integrate our method with equivariant imaging, a complementary
self-supervised learning framework that exploits the inherent invariants of
imaging problems, to train DMs for image restoration from single-operator
measurements that are both incomplete and noisy. We validate the effectiveness
of our approach through extensive experiments on image denoising, demosaicing,
and inpainting, along with comparisons with the state of the art.

</details>


### [21] [LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications](https://arxiv.org/abs/2510.12379)
*Vibhoothi Vibhoothi,François Pitié,Anil Kokaram*

Main category: eess.IV

TL;DR: 提出轻量级神经网络LiteVPNet，用于预测NVENC AV1编码器的量化参数，以实现指定的VMAF质量分数，满足电影制作中精确质量控制和能效需求。


<details>
  <summary>Details</summary>
Motivation: 电影制作生态系统中的视频工作流程（如现场虚拟制作）需要精确的质量控制和能效，现有转码方法在质量控制或计算开销方面存在不足。

Method: 使用轻量级神经网络LiteVPNet，结合低复杂度特征（包括比特流特性、视频复杂度测量和基于CLIP的语义嵌入）来预测量化参数。

Result: LiteVPNet在广泛的质量目标范围内实现平均VMAF误差低于1.2分，87%的测试语料VMAF误差在2分以内，优于现有方法的约61%。

Conclusion: LiteVPNet在各种质量区域的表现突出了其在增强高价值内容传输和流媒体方面的适用性，实现更节能、高质量的媒体体验。

Abstract: In the last decade, video workflows in the cinema production ecosystem have
presented new use cases for video streaming technology. These new workflows,
e.g. in On-set Virtual Production, present the challenge of requiring precise
quality control and energy efficiency. Existing approaches to transcoding often
fall short of these requirements, either due to a lack of quality control or
computational overhead. To fill this gap, we present a lightweight neural
network (LiteVPNet) for accurately predicting Quantisation Parameters for NVENC
AV1 encoders that achieve a specified VMAF score. We use low-complexity
features, including bitstream characteristics, video complexity measures, and
CLIP-based semantic embeddings. Our results demonstrate that LiteVPNet achieves
mean VMAF errors below 1.2 points across a wide range of quality targets.
Notably, LiteVPNet achieves VMAF errors within 2 points for over 87% of our
test corpus, c.f. approx 61% with state-of-the-art methods. LiteVPNet's
performance across various quality regions highlights its applicability for
enhancing high-value content transport and streaming for more energy-efficient,
high-quality media experiences.

</details>


### [22] [An Empirical Study of Reducing AV1 Decoder Complexity and Energy Consumption via Encoder Parameter Tuning](https://arxiv.org/abs/2510.12380)
*Vibhoothi Vibhoothi,Julien Zouein,Shanker Shreejith,Jean-Baptiste Kempf,Anil Kokaram*

Main category: eess.IV

TL;DR: 本文系统分析了AV1编码器中禁用不同编码工具和调整参数对解码复杂度、能耗和压缩效率的影响，发现特定配置可显著降低解码复杂度且对感知质量影响很小。


<details>
  <summary>Details</summary>
Motivation: AV1等先进视频编解码器的高解码复杂度阻碍了其在电池受限设备上的广泛应用，需要找到降低解码能耗的方法。

Method: 使用libaom-av1和SVT-AV1两个AV1编码器，系统性地禁用各种编码工具并调整编码参数，利用RAPL和Intel SoC Watch等系统级能耗测量工具量化解码复杂度、能耗和压缩效率之间的权衡。

Result: 对于libaom-av1，禁用CDEF环路滤波器可使解码周期平均减少10%；对于SVT-AV1，使用内置的fast-decode=2预设可实现更显著的24%解码周期减少。

Conclusion: 研究结果为内容提供商提供了降低AV1视频流媒体能耗的策略，特定编码器配置可大幅降低解码复杂度且对感知质量影响很小。

Abstract: The widespread adoption of advanced video codecs such as AV1 is often
hindered by their high decoding complexity, posing a challenge for
battery-constrained devices. While encoders can be configured to produce
bitstreams that are decoder-friendly, estimating the decoding complexity and
energy overhead for a given video is non-trivial. In this study, we
systematically analyse the impact of disabling various coding tools and
adjusting coding parameters in two AV1 encoders, libaom-av1 and SVT-AV1. Using
system-level energy measurement tools like RAPL (Running Average Power Limit),
Intel SoC Watch (integrated with VTune profiler), we quantify the resulting
trade-offs between decoding complexity, energy consumption, and compression
efficiency for decoding a bitstream. Our results demonstrate that specific
encoder configurations can substantially reduce decoding complexity with
minimal perceptual quality degradation. For libaom-av1, disabling CDEF, an
in-loop filter gives us a mean reduction in decoding cycles by 10%. For
SVT-AV1, using the in-built, fast-decode=2 preset achieves a more substantial
24% reduction in decoding cycles. These findings provide strategies for content
providers to lower the energy footprint of AV1 video streaming.

</details>


### [23] [MH-LVC: Multi-Hypothesis Temporal Prediction for Learned Conditional Residual Video Coding](https://arxiv.org/abs/2510.12479)
*Huu-Tai Phung,Zong-Lin Gao,Yi-Chen Yao,Kuan-Wei Ho,Yi-Hsin Chen,Yu-Hsiang Lin,Alessandro Gnutti,Wen-Hsiao Peng*

Main category: eess.IV

TL;DR: MH-LVC提出了一种多假设时间预测方案，使用长短时参考帧进行条件残差视频编码，解决了传统方法内存访问过多的问题。


<details>
  <summary>Details</summary>
Motivation: 现有条件视频编码方法需要存储大量隐式上下文信息，导致内存访问过多，限制了实际应用。

Method: 采用多假设时间预测，限制同时使用的参考帧数量为2个，通过解码帧缓冲区管理灵活利用长短时参考帧。

Result: 在低延迟B配置下，PSNR-RGB性能优于VTM-17.0，与DCVC-FM等先进学习编解码器性能相当，但需要更少的解码帧缓冲区和相似的解码时间。

Conclusion: MH-LVC在保持高性能的同时有效减少了内存需求，为学习视频编解码器的实际部署提供了可行方案。

Abstract: This work, termed MH-LVC, presents a multi-hypothesis temporal prediction
scheme that employs long- and short-term reference frames in a conditional
residual video coding framework. Recent temporal context mining approaches to
conditional video coding offer superior coding performance. However, the need
to store and access a large amount of implicit contextual information extracted
from past decoded frames in decoding a video frame poses a challenge due to
excessive memory access. Our MH-LVC overcomes this issue by storing multiple
long- and short-term reference frames but limiting the number of reference
frames used at a time for temporal prediction to two. Our decoded frame buffer
management allows the encoder to flexibly utilize the long-term key frames to
mitigate temporal cascading errors and the short-term reference frames to
minimize prediction errors. Moreover, our buffering scheme enables the temporal
prediction structure to be adapted to individual input videos. While this
flexibility is common in traditional video codecs, it has not been fully
explored for learned video codecs. Extensive experiments show that the proposed
method outperforms VTM-17.0 under the low-delay B configuration in terms of
PSNR-RGB across commonly used test datasets, and performs comparably to the
state-of-the-art learned codecs (e.g.~DCVC-FM) while requiring less decoded
frame buffer and similar decoding time.

</details>


### [24] [A High-Level Feature Model to Predict the Encoding Energy of a Hardware Video Encoder](https://arxiv.org/abs/2510.12754)
*Diwakara Reddy,Christian Herglotz,André Kaup*

Main category: eess.IV

TL;DR: 提出使用高斯过程回归的高层特征模型来预测硬件视频编码器的编码能耗，在仅使用P帧和单个关键帧的评估中，平均绝对百分比误差约为9%。


<details>
  <summary>Details</summary>
Motivation: 随着电池供电设备的实时视频直播和用户生成内容普及，需要实时视频编码，而硬件编码器适合此类任务，但需要预测其编码能耗。

Method: 使用高斯过程回归构建高层特征模型来预测硬件视频编码器的编码能量，并通过消融研究验证空间分辨率是关键特征。

Result: 在仅使用P帧和单个关键帧的限制评估设置中，模型预测编码能量的平均绝对百分比误差约为9%，空间分辨率被证明是编码能量预测的关键特征。

Conclusion: 该模型可用于在实际编码前估算不同空间分辨率、编码标准和编解码器预设下视频编码所需的能量，具有实用价值。

Abstract: In today's society, live video streaming and user generated content streamed
from battery powered devices are ubiquitous. Live streaming requires real-time
video encoding, and hardware video encoders are well suited for such an
encoding task. In this paper, we introduce a high-level feature model using
Gaussian process regression that can predict the encoding energy of a hardware
video encoder. In an evaluation setup restricted to only P-frames and a single
keyframe, the model can predict the encoding energy with a mean absolute
percentage error of approximately 9%. Further, we demonstrate with an ablation
study that spatial resolution is a key high-level feature for encoding energy
prediction of a hardware encoder. A practical application of our model is that
it can be used to perform a prior estimation of the energy required to encode a
video at various spatial resolutions, with different coding standards and codec
presets.

</details>
