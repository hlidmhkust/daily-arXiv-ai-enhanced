<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 13]
- [eess.SP](#eess.SP) [Total: 9]
- [cs.IT](#cs.IT) [Total: 6]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Clinically-aligned Multi-modal Chest X-ray Classification](https://arxiv.org/abs/2511.09581)
*Phillip Sloan,Edwin Simpson,Majid Mirmehdi*

Main category: eess.IV

TL;DR: CaMCheX是一个多模态Transformer框架，将多视图胸部X光研究与结构化临床数据对齐，以改进胸部X光分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有胸部X光分类方法主要依赖单视图图像级输入，忽略了临床实践中可用的结构化临床信息和多图像研究，无法充分反映临床医生的诊断决策过程。

Method: 使用视图特定的ConvNeXt编码器处理正面和侧面胸部X光片，通过Transformer融合模块将图像特征与临床指征、病史和生命体征等临床数据融合。

Result: 在MIMIC-CXR和CXR-LT基准测试中均超越了现有最先进方法。

Conclusion: 基于临床的多模态对齐对于推进胸部X光分类具有重要价值，能够生成更符合临床推理的情境感知表示。

Abstract: Radiology is essential to modern healthcare, yet rising demand and staffing shortages continue to pose major challenges. Recent advances in artificial intelligence have the potential to support radiologists and help address these challenges. Given its widespread use and clinical importance, chest X-ray classification is well suited to augment radiologists' workflows. However, most existing approaches rely solely on single-view, image-level inputs, ignoring the structured clinical information and multi-image studies available at the time of reporting. In this work, we introduce CaMCheX, a multimodal transformer-based framework that aligns multi-view chest X-ray studies with structured clinical data to better reflect how clinicians make diagnostic decisions. Our architecture employs view-specific ConvNeXt encoders for frontal and lateral chest radiographs, whose features are fused with clinical indications, history, and vital signs using a transformer fusion module. This design enables the model to generate context-aware representations that mirror reasoning in clinical practice. Our results exceed the state of the art for both the original MIMIC-CXR dataset and the more recent CXR-LT benchmarks, highlighting the value of clinically grounded multimodal alignment for advancing chest X-ray classification.

</details>


### [2] [Diffusion-Based Quality Control of Medical Image Segmentations across Organs](https://arxiv.org/abs/2511.09588)
*Vincenzo Marcianò,Hava Chaptoukaev,Virginia Fernandez,M. Jorge Cardoso,Sébastien Ourselin,Michela Antonelli,Maria A. Zuluaga*

Main category: eess.IV

TL;DR: 提出了一种基于扩散生成范式的通用质量控制框架nnQC，通过团队专家架构和指纹适应技术，能够自适应处理不同器官的医学图像分割质量评估问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割的深度学习方法容易产生幻觉导致解剖学上不合理的分割结果，而现有的质量控制方法都是器官特定的，缺乏通用性和可用性。

Method: 采用扩散生成范式，提出团队专家架构，其中两个专家分别编码3D空间意识和解剖信息，通过加权条件模块动态组合这些信息来生成伪地面实况，并集成指纹适应技术确保跨器官适应性。

Result: 在7个器官的12个公开数据集上评估，nnQC在所有实验中始终优于最先进方法，即使在分割掩码严重退化或完全缺失的情况下也表现良好。

Conclusion: nnQC是一个多功能且有效的质量控制框架，能够适应不同器官、数据集和成像模态，解决了医学图像分割质量控制的通用性问题。

Abstract: Medical image segmentation using deep learning (DL) has enabled the development of automated analysis pipelines for large-scale population studies. However, state-of-the-art DL methods are prone to hallucinations, which can result in anatomically implausible segmentations. With manual correction impractical at scale, automated quality control (QC) techniques have to address the challenge. While promising, existing QC methods are organ-specific, limiting their generalizability and usability beyond their original intended task. To overcome this limitation, we propose no-new Quality Control (nnQC), a robust QC framework based on a diffusion-generative paradigm that self-adapts to any input organ dataset. Central to nnQC is a novel Team of Experts (ToE) architecture, where two specialized experts independently encode 3D spatial awareness, represented by the relative spatial position of an axial slice, and anatomical information derived from visual features from the original image. A weighted conditional module dynamically combines the pair of independent embeddings, or opinions to condition the sampling mechanism within a diffusion process, enabling the generation of a spatially aware pseudo-ground truth for predicting QC scores. Within its framework, nnQC integrates fingerprint adaptation to ensure adaptability across organs, datasets, and imaging modalities. We evaluated nnQC on seven organs using twelve publicly available datasets. Our results demonstrate that nnQC consistently outperforms state-of-the-art methods across all experiments, including cases where segmentation masks are highly degraded or completely missing, confirming its versatility and effectiveness across different organs.

</details>


### [3] [Segment Any Tumour: An Uncertainty-Aware Vision Foundation Model for Whole-Body Analysis](https://arxiv.org/abs/2511.09592)
*Himashi Peiris,Sizhe Wang,Gary Egan,Mehrtash Harandi,Meng Law,Zhaolin Chen*

Main category: eess.IV

TL;DR: SAT3D是一个轻量级3D体积基础模型，专门用于医学影像中的肿瘤分割，通过不确定性感知训练和对抗学习解决医学影像中组织异质性、伪影和低对比度边界等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础模型（如Segment Anything Model）直接应用于医学影像存在挑战，主要由于组织异质性、成像伪影和低对比度边界，特别是在肿瘤和癌症原发灶区域，导致在模糊或重叠病变区域的分割效果不佳。

Method: SAT3D集成了移位窗口视觉变换器进行分层体积表示，采用不确定性感知训练流程，将不确定性估计作为提示来指导低对比度区域的可靠边界预测，并通过对抗学习增强模型在模糊病理区域的性能。

Result: 在11个公开数据集（3,884个训练病例和694个分布内评估病例）上，SAT3D相比三个最新视觉基础模型和nnUNet表现出更强的泛化性和鲁棒性。模型在17,075个3D体积-掩模对上进行训练，涵盖多种模态和癌症原发灶。

Conclusion: SAT3D在挑战性和分布外场景下显著提高了分割准确性，展示了其作为医学图像分析可扩展基础模型的潜力，并开发了3D Slicer插件支持交互式、提示驱动的分割和可视化。

Abstract: Prompt-driven vision foundation models, such as the Segment Anything Model, have recently demonstrated remarkable adaptability in computer vision. However, their direct application to medical imaging remains challenging due to heterogeneous tissue structures, imaging artefacts, and low-contrast boundaries, particularly in tumours and cancer primaries leading to suboptimal segmentation in ambiguous or overlapping lesion regions. Here, we present Segment Any Tumour 3D (SAT3D), a lightweight volumetric foundation model designed to enable robust and generalisable tumour segmentation across diverse medical imaging modalities. SAT3D integrates a shifted-window vision transformer for hierarchical volumetric representation with an uncertainty-aware training pipeline that explicitly incorporates uncertainty estimates as prompts to guide reliable boundary prediction in low-contrast regions. Adversarial learning further enhances model performance for the ambiguous pathological regions. We benchmark SAT3D against three recent vision foundation models and nnUNet across 11 publicly available datasets, encompassing 3,884 tumour and cancer cases for training and 694 cases for in-distribution evaluation. Trained on 17,075 3D volume-mask pairs across multiple modalities and cancer primaries, SAT3D demonstrates strong generalisation and robustness. To facilitate practical use and clinical translation, we developed a 3D Slicer plugin that enables interactive, prompt-driven segmentation and visualisation using the trained SAT3D model. Extensive experiments highlight its effectiveness in improving segmentation accuracy under challenging and out-of-distribution scenarios, underscoring its potential as a scalable foundation model for medical image analysis.

</details>


### [4] [SuperRivolution: Fine-Scale Rivers from Coarse Temporal Satellite Imagery](https://arxiv.org/abs/2511.09597)
*Rangel Daroya,Subhransu Maji*

Main category: eess.IV

TL;DR: SuperRivolution框架利用低分辨率卫星图像时间序列提升河流分割精度，显著缩小与高分辨率模型的差距。


<details>
  <summary>Details</summary>
Motivation: 高分辨率卫星图像稀少且昂贵，而低分辨率图像更易获取但精度不足，需要开发方法从低分辨率时间序列中提取精细河流信息。

Method: 提出SuperRivolution框架，使用9,810张低分辨率时间序列图像与高分辨率标签配对的数据集，探索了单图像模型集成、图像超分辨率和端到端时序模型等多种策略。

Result: 河流分割F1分数从60.9%提升至80.5%，接近高分辨率模型的94.1%；河流宽度估计任务也有类似改进。

Conclusion: 公开可用的低分辨率卫星档案在精细尺度河流监测方面具有巨大潜力。

Abstract: Satellite missions provide valuable optical data for monitoring rivers at diverse spatial and temporal scales. However, accessibility remains a challenge: high-resolution imagery is ideal for fine-grained monitoring but is typically scarce and expensive compared to low-resolution imagery. To address this gap, we introduce SuperRivolution, a framework that improves river segmentation resolution by leveraging information from time series of low-resolution satellite images. We contribute a new benchmark dataset of 9,810 low-resolution temporal images paired with high-resolution labels from an existing river monitoring dataset. Using this benchmark, we investigate multiple strategies for river segmentation, including ensembling single-image models, applying image super-resolution, and developing end-to-end models trained on temporal sequences. SuperRivolution significantly outperforms single-image methods and baseline temporal approaches, narrowing the gap with supervised high-resolution models. For example, the F1 score for river segmentation improves from 60.9% to 80.5%, while the state-of-the-art model operating on high-resolution images achieves 94.1%. Similar improvements are also observed in river width estimation tasks. Our results highlight the potential of publicly available low-resolution satellite archives for fine-scale river monitoring.

</details>


### [5] [Bridging the Data Gap: Spatially Conditioned Diffusion Model for Anomaly Generation in Photovoltaic Electroluminescence Images](https://arxiv.org/abs/2511.09604)
*Shiva Hanifi,Sasan Jafarnejad,Marc Köntges,Andrej Wentnagel,Andreas Kokkas,Raphael Frank*

Main category: eess.IV

TL;DR: PV-DDPM是一个空间条件去噪扩散概率模型，用于生成光伏电池的异常电致发光图像，支持四种电池类型和多种缺陷类型的同时生成。


<details>
  <summary>Details</summary>
Motivation: 光伏模块的可靠异常检测对维持太阳能效率至关重要，但缺乏大规模、多样化和平衡的数据集限制了计算机视觉模型的发展。

Method: 使用空间条件去噪扩散概率模型(PV-DDPM)，通过二元掩码控制结构特征和缺陷位置，生成单缺陷和多缺陷场景的异常电致发光图像。

Result: 生成的图像在所有类别中实现了FID 4.10和KID 0.0023±0.0007的定量评估结果。使用E-SCDD数据集训练AA-CLIP模型，相比SCDD数据集，像素级AUC和平均精度分别提高了1.70和8.34个百分点。

Conclusion: PV-DDPM是首个联合建模多种光伏电池类型并支持同时生成多种异常类型的框架，E-SCDD数据集显著提升了异常检测模型的性能。

Abstract: Reliable anomaly detection in photovoltaic (PV) modules is critical for maintaining solar energy efficiency. However, developing robust computer vision models for PV inspection is constrained by the scarcity of large-scale, diverse, and balanced datasets. This study introduces PV-DDPM, a spatially conditioned denoising diffusion probabilistic model that generates anomalous electroluminescence (EL) images across four PV cell types: multi-crystalline silicon (multi-c-Si), mono-crystalline silicon (mono-c-Si), half-cut multi-c-Si, and interdigitated back contact (IBC) with dogbone interconnect. PV-DDPM enables controlled synthesis of single-defect and multi-defect scenarios by conditioning on binary masks representing structural features and defect positions. To the best of our knowledge, this is the first framework that jointly models multiple PV cell types while supporting simultaneous generation of diverse anomaly types. We also introduce E-SCDD, an enhanced version of the SCDD dataset, comprising 1,000 pixel-wise annotated EL images spanning 30 semantic classes, and 1,768 unlabeled synthetic samples. Quantitative evaluation shows our generated images achieve a Fréchet Inception Distance (FID) of 4.10 and Kernel Inception Distance (KID) of 0.0023 $\pm$ 0.0007 across all categories. Training the vision--language anomaly detection model AA-CLIP on E-SCDD, compared to the SCDD dataset, improves pixel-level AUC and average precision by 1.70 and 8.34 points, respectively.

</details>


### [6] [TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks](https://arxiv.org/abs/2511.09605)
*Johannes Kiechle,Stefan M. Fischer,Daniel M. Lang,Cosmin I. Bercea,Matthew J. Nyflot,Lina Felsner,Julia A. Schnabel,Jan C. Peeken*

Main category: eess.IV

TL;DR: 提出TomoGraphView框架，通过全方向体积切片和球形图特征聚合解决3D医学图像分类中传统切片方法空间信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 3D医学图像分类面临复杂空间关系和长程依赖的挑战，现有基于2D基础模型的方法在体积切片时无法充分捕捉目标结构的空间范围，且切片聚合策略缺乏空间连贯性。

Method: 结合全方向体积切片和球形图特征聚合，通过多方向切片捕捉更全面的空间信息，并使用图结构保持切片间的空间关系。

Result: 开发了开源代码库和用户友好的全方向切片工具，为3D医学图像分析提供了新的解决方案。

Conclusion: TomoGraphView框架有效解决了传统切片方法的局限性，为3D医学图像分析提供了更全面的空间特征提取能力。

Abstract: The growing number of medical tomography examinations has necessitated the development of automated methods capable of extracting comprehensive imaging features to facilitate downstream tasks such as tumor characterization, while assisting physicians in managing their growing workload. However, 3D medical image classification remains a challenging task due to the complex spatial relationships and long-range dependencies inherent in volumetric data. Training models from scratch suffers from low data regimes, and the absence of 3D large-scale multimodal datasets has limited the development of 3D medical imaging foundation models. Recent studies, however, have highlighted the potential of 2D vision foundation models, originally trained on natural images, as powerful feature extractors for medical image analysis. Despite these advances, existing approaches that apply 2D models to 3D volumes via slice-based decomposition remain suboptimal. Conventional volume slicing strategies, which rely on canonical planes such as axial, sagittal, or coronal, may inadequately capture the spatial extent of target structures when these are misaligned with standardized viewing planes. Furthermore, existing slice-wise aggregation strategies rarely account for preserving the volumetric structure, resulting in a loss of spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer.

</details>


### [7] [TempRetinex: Retinex-based Unsupervised Enhancement for Low-light Video Under Diverse Lighting Conditions](https://arxiv.org/abs/2511.09609)
*Yini Li,Nantheera Anantrasirichai*

Main category: eess.IV

TL;DR: TempRetinex是一个基于Retinex的无监督视频增强框架，通过利用帧间相关性、自适应亮度调整、多尺度时间一致性损失和自集成机制，在低光视频增强中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 视频包含丰富的时序信息，为低光增强提供了比单张图像更多的互补线索。现有无监督方法在不同光照条件下的泛化能力较差，需要更好的方法来处理多样化的光照场景和保持时间一致性。

Method: 1) 自适应亮度调整预处理对齐不同曝光下的光照分布；2) 多尺度时间一致性损失确保连续帧间的多尺度相似性；3) 遮挡感知掩码技术处理复杂运动；4) 反向推理策略优化未收敛帧；5) 自集成机制提升不同纹理的降噪效果。

Result: 在感知质量和时间一致性方面达到最先进性能，相比先前方法PSNR提升高达29.7%。

Conclusion: TempRetinex通过有效利用时序信息和创新的预处理及损失设计，显著提升了无监督视频低光增强的性能和鲁棒性。

Abstract: Videos inherently contain rich temporal information that provides complementary cues for low-light enhancement beyond what can be achieved with single images. We propose TempRetinex, a novel unsupervised Retinex-based framework that effectively exploits inter-frame correlations for video enhancement. To address the poor generalization of existing unsupervised methods under varying illumination, we introduce adaptive brightness adjustment (ABA) preprocessing that explicitly aligns lighting distributions across exposures. This significantly improves model robustness to diverse lighting scenarios and eases training optimization, leading to better denoising performance. For enhanced temporal coherence, we propose a multi-scale temporal consistency-aware loss to enforce multiscale similarity between consecutive frames, and an occlusion-aware masking technique to handle complex motions. We further incorporate a reverse inference strategy to refine unconverged frames and a self-ensemble (SE) mechanism to boost the denoising across diverse textures. Experiments demonstrate that TempRetinex achieves state-of-the-art performance in both perceptual quality and temporal consistency, achieving up to a 29.7% PSNR gain over prior methods.

</details>


### [8] [A Fourier-Based Global Denoising Model for Smart Artifacts Removing of Microscopy Images](https://arxiv.org/abs/2511.09734)
*Huanhuan Zhao,Connor Vernachio,Laxmi Bhurtel,Wooin Yang,Ruben Millan-Solsona,Spenser R. Brown,Marti Checa,Komal Sharma Agrawal,Adam M. Guss,Liam Collins,Wonhee Ko,Arpan Biswas*

Main category: eess.IV

TL;DR: 提出了一种全局去噪模型(GDM)，通过双通道输入和FFT损失函数，在去除显微镜图像伪影的同时保留弱但重要的物理特征。


<details>
  <summary>Details</summary>
Motivation: 现有去噪模型通常将弱信号视为噪声而增强强信号，这在显微镜图像中会擦除重要的物理信息。显微镜参数调优耗时且困难，低质量图像会导致分析错误。

Method: 1) 设计双成像输入通道，包含非配对和特定目标预处理图像，用户可定义通道间权衡；2) 集成基于像素和快速傅里叶变换(FFT)的损失函数训练U-net模型。

Result: 与无FFT去噪模型相比，GDM在STM生成的Cu和Si材料图像、AFM生成的Pantoea sp.YR343生物膜图像和SEM生成的塑料降解图像上表现更好。

Conclusion: 该工作流可扩展到改善其他显微镜图像质量，为实验人员提供设计灵活性，可根据领域专家偏好智能调整。

Abstract: Microscopy such as Scanning Tunneling Microscopy (STM), Atomic Force Microscopy (AFM) and Scanning Electron Microscopy (SEM) are essential tools in material imaging at micro- and nanoscale resolutions to extract physical knowledge and materials structure-property relationships. However, tuning microscopy controls (e.g. scanning speed, current setpoint, tip bias etc.) to obtain a high-quality of images is a non-trivial and time-consuming effort. On the other hand, with sub-standard images, the key features are not accurately discovered due to noise and artifacts, leading to erroneous analysis. Existing denoising models mostly build on generalizing the weak signals as noises while the strong signals are enhanced as key features, which is not always the case in microscopy images, thus can completely erase a significant amount of hidden physical information. To address these limitations, we propose a global denoising model (GDM) to smartly remove artifacts of microscopy images while preserving weaker but physically important features. The proposed model is developed based on 1) first designing a two-imaging input channel of non-pair and goal specific pre-processed images with user-defined trade-off information between two channels and 2) then integrating a loss function of pixel- and fast Fourier-transformed (FFT) based on training the U-net model. We compared the proposed GDM with the non-FFT denoising model over STM-generated images of Copper(Cu) and Silicon(Si) materials, AFM-generated Pantoea sp.YR343 bio-film images and SEM-generated plastic degradation images. We believe this proposed workflow can be extended to improve other microscopy image quality and will benefit the experimentalists with the proposed design flexibility to smartly tune via domain-experts preferences.

</details>


### [9] [Electromagnetic Quantitative Inversion for Translationally Moving Targets via Phase Correlation Registration of Back-Projection Images](https://arxiv.org/abs/2511.09898)
*Yitao Lin,Dahai Dai,Shilong Sun,Yuchen Wu,Bo Pang*

Main category: eess.IV

TL;DR: 提出了一种基于相位相关配准的反投影图像电磁定量反演方案，用于平移运动目标，结合TDM-MIMO雷达架构和相对运动补偿，实现了加速收敛和更高重建精度的RMC-CC-CSI算法。


<details>
  <summary>Details</summary>
Motivation: 传统电磁反演方法在处理运动目标时面临挑战，需要解决目标相对定位和运动补偿问题以提高重建质量。

Method: 采用TDM-MIMO雷达架构，通过相位相关配准实现高精度相对定位，应用相对运动补偿对多周期MIMO数据进行迭代反演，并将CC-CSI算法整合到迭代优化步骤中。

Result: 数值和实验结果表明，RMC-CC-CSI相比传统CC-CSI在静止目标情况下具有加速收敛、增强重建保真度和改善噪声免疫能力，尽管计算成本有所增加。

Conclusion: 该方案为运动目标电磁定量反演提供了有效框架，RMC-CC-CSI算法在性能上优于传统方法，具有实际应用价值。

Abstract: An novel electromagnetic quantitative inversion scheme for translationally moving targets via phase correlation registration of back-projection (BP) images is proposed. Based on a time division multiplexing multiple-input multiple-output (TDM-MIMO) radar architecture, the scheme first achieves high-precision relative positioning of the target, then applies relative motion compensation to perform iterative inversion on multi-cycle MIMO measurement data, thereby reconstructing the target's electromagnetic parameters. As a general framework compatible with other mainstream inversion algorithms, we exemplify our approach by incorporating the classical cross-correlated contrast source inversion (CC-CSI) into iterative optimization step of the scheme, resulting in a new algorithm termed RMC-CC-CSI. Numerical and experimental results demonstrate that RMC-CC-CSI offers accelerated convergence, enhanced reconstruction fidelity, and improved noise immunity over conventional CC-CSI for stationary targets despite increased computational cost.

</details>


### [10] [Learning phase diversity for solving ill-posed inverse problems in imaging](https://arxiv.org/abs/2511.09952)
*Jasleen Birdi,Tamal Majumder,Debanjan Halder,Muskan Kularia,Kedar Khare*

Main category: eess.IV

TL;DR: 本文提出了一种基于物理信息的数据增强方法，通过训练网络生成相位多样性的伪数据，结合真实数据提升光学成像逆问题重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决光学成像逆问题中传统深度学习方法虽然速度快但未改变问题本质，而多测量数据需要复杂硬件设置的矛盾。

Method: 利用相位多样性测量的局部相关性，训练网络从真实数据生成相位多样性伪数据，结合真实数据进行重建。

Result: 在非相干和相干光学成像中验证了该方法能提供高质量逆问题解，使用更简单的重建算法即可获得良好结果。

Conclusion: 该方法为构建更精简的高保真计算成像系统开辟了新途径，可广泛应用于各种光学成像应用。

Abstract: Inverse problems in imaging are typically ill-posed and are usually solved by employing regularized optimization techniques. The usage of appropriate constraints can restrict the solution space, thus making it feasible for a reconstruction algorithm to find a meaningful solution. In recent years, deep network based ideas aimed at learning the end-to-end mapping between the raw measurements and the target image have gained popularity. In the learning approach, the functional relationship between the measured raw data and the solution image are learned by training a deep network with prior examples. While this approach allows one to significantly increase the real-time operational speed, it does not change the nature of the underlying ill-posed inverse problem. It is well-known that availability of diverse non-redundant data via additional measurements can generically improve the robustness of the reconstruction algorithms. The multiple data measurements, however, typically demand additional hardware and complex system setups that are not desirable. In this work, we note that in both incoherent and coherent optical imaging, the irradiance patterns corresponding to two phase diverse measurements associated with the same test object have implicit local correlation which may be learned. A physics informed data augmentation scheme is then described where a trained network is used for generating a phase diverse pseudo-data based on a ground truth data frame. The true data along with the augmented pesudo-data are observed to provide high quality inverse solutions with simpler reconstruction algorithms. We validate this approach for both incoherent and coherent optical imaging (or phase retrieval) configurations with vortex phase as a diversity mechanism. Our results may open new avenues for leaner high-fidelity computational imaging systems across a broad range of applications.

</details>


### [11] [Efficient Automated Diagnosis of Retinopathy of Prematurity by Customize CNN Models](https://arxiv.org/abs/2511.10023)
*Farzan Saeedi,Sanaz Keshvari,Nasser Shoeibi*

Main category: eess.IV

TL;DR: 本研究使用定制化CNN模型进行早产儿视网膜病变诊断，相比预训练模型获得更高准确率和F1分数，并通过投票系统进一步提升性能，同时降低了计算负担。


<details>
  <summary>Details</summary>
Motivation: 改进ROP诊断的精确性和效率，解决深度神经网络计算成本高的问题，开发适用于临床环境的诊断辅助工具。

Method: 采用定制化CNN模型架构，结合数据集整理、预处理策略，并实施投票系统来提升模型性能。

Result: 定制CNN模型在准确率和F1分数上优于预训练模型，计算负担显著降低，模型可在专用软硬件配置中部署。

Conclusion: 深度学习模型能有效提升ROP诊断的精确度和效率，为临床诊断提供了有价值的辅助工具。

Abstract: This paper encompasses an in-depth examination of Retinopathy of Prematurity (ROP) diagnosis, employing advanced deep learning methodologies. Our focus centers on refining and evaluating CNN-based approaches for precise and efficient ROP detection. We navigate the complexities of dataset curation, preprocessing strategies, and model architecture, aligning with research objectives encompassing model effectiveness, computational cost analysis, and time complexity assessment. Results underscore the supremacy of tailored CNN models over pre-trained counterparts, evident in heightened accuracy and F1-scores. Implementation of a voting system further enhances performance. Additionally, our study reveals the potential of the proposed customized CNN model to alleviate computational burdens associated with deep neural networks. Furthermore, we showcase the feasibility of deploying these models within dedicated software and hardware configurations, highlighting their utility as valuable diagnostic aids in clinical settings. In summary, our discourse significantly contributes to ROP diagnosis, unveiling the efficacy of deep learning models in enhancing diagnostic precision and efficiency.

</details>


### [12] [Equivariant Denoisers for Plug and Play Image Restoration](https://arxiv.org/abs/2511.10340)
*Marien Renaud,Eliot Guez,Arthur Leclaire,Nicolas Papadakis*

Main category: eess.IV

TL;DR: 提出了两个基于等变去噪器和随机优化的统一框架：等变正则化去噪(ERED)和等变即插即用(EPnP)，用于图像恢复任务。


<details>
  <summary>Details</summary>
Motivation: 现有深度架构无法有效表示不变图像分布，而图像分布对某些变换（如旋转、翻转）具有不变性，这限制了图像恢复方法的性能。

Method: 利用等变去噪器和随机优化构建ERED和EPnP框架，通过包含等变性质来改进图像先验建模。

Result: 分析了所提算法的收敛性，并讨论了其实际优势。

Conclusion: 提出的等变框架能够更好地建模图像先验，为图像恢复任务提供更有效的解决方案。

Abstract: One key ingredient of image restoration is to define a realistic prior on clean images to complete the missing information in the observation. State-of-the-art restoration methods rely on a neural network to encode this prior. Typical image distributions are invariant to some set of transformations, such as rotations or flips. However, most deep architectures are not designed to represent an invariant image distribution. Recent works have proposed to overcome this difficulty by including equivariance properties within a Plug-and-Play paradigm. In this work, we propose two unified frameworks named Equivariant Regularization by Denoising (ERED) and Equivariant Plug-and-Play (EPnP) based on equivariant denoisers and stochastic optimization. We analyze the convergence of the proposed algorithms and discuss their practical benefit.

</details>


### [13] [Domain Adaptation for Camera-Specific Image Characteristics using Shallow Discriminators](https://arxiv.org/abs/2511.10424)
*Maximiliane Gruber,Jürgen Seiler,André Kaup*

Main category: eess.IV

TL;DR: 本文提出浅层判别器架构来改进像素级域适应方法，通过更小的感受野尺寸更准确地学习未知图像畸变，在实例分割任务中显著提升性能并大幅降低网络复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决学习型感知算法中训练数据与应用阶段图像特征不匹配导致的域差距问题，改进现有无配对学习的原始到畸变映射方法的局限性。

Method: 使用浅层判别器架构，减小感受野尺寸以更准确地学习局部畸变特征，在低网络复杂度下实现像素级域适应。

Result: 在实例分割的域适应设置中，相比现有方法平均精度提升最高达0.15（单个畸变）和0.16（相机特定特征），参数量减少20倍但性能不受影响。

Conclusion: 提出的浅层判别器方法在保持性能的同时显著提高了域适应效率，证明了小感受野在准确学习局部畸变特征方面的优势。

Abstract: Each image acquisition setup leads to its own camera-specific image characteristics degrading the image quality. In learning-based perception algorithms, characteristics occurring during the application phase, but absent in the training data, lead to a domain gap impeding the performance. Previously, pixel-level domain adaptation through unpaired learning of the pristine-to-distorted mapping function has been proposed. In this work, we propose shallow discriminator architectures to address limitations of these approaches. We show that a smaller receptive field size improves learning of unknown image distortions by more accurately reproducing local distortion characteristics at a low network complexity. In a domain adaptation setup for instance segmentation, we achieve mean average precision increases over previous methods of up to 0.15 for individual distortions and up to 0.16 for camera-specific image characteristics in a simplified camera model. In terms of number of parameters, our approach matches the complexity of one state of the art method while reducing complexity by a factor of 20 compared to another, demonstrating superior efficiency without compromising performance.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [14] [Investigation of Feature Selection and Pooling Methods for Environmental Sound Classification](https://arxiv.org/abs/2511.09802)
*Parinaz Binandeh Dehaghani,Danilo Pena,A. Pedro Aguiar*

Main category: eess.SP

TL;DR: 本文研究了维度缩减和池化方法对轻量级CNN环境声音分类的影响，评估了SSRP及其变体，发现SSRP-T在ESC-50数据集上达到80.69%准确率，显著优于基线CNN和PCA方法。


<details>
  <summary>Details</summary>
Motivation: 在资源受限场景下，需要平衡环境声音分类任务的准确性和计算成本，探索高效的维度缩减和池化方法。

Method: 评估稀疏显著区域池化(SSRP)及其变体SSRP-B和SSRP-T，在不同超参数设置下与主成分分析(PCA)进行比较。

Result: 在ESC-50数据集上，SSRP-T达到80.69%准确率，显著优于基线CNN(66.75%)和PCA模型(37.60%)。

Conclusion: 精心调优的稀疏池化策略为环境声音分类任务提供了鲁棒、高效且高性能的解决方案，特别适用于资源受限场景。

Abstract: This paper explores the impact of dimensionality reduction and pooling methods for Environmental Sound Classification (ESC) using lightweight CNNs. We evaluate Sparse Salient Region Pooling (SSRP) and its variants, SSRP-Basic (SSRP-B) and SSRP-Top-K (SSRP-T), under various hyperparameter settings and compare them with Principal Component Analysis (PCA). Experiments on the ESC-50 dataset demonstrate that SSRP-T achieves up to 80.69 % accuracy, significantly outperforming both the baseline CNN (66.75 %) and the PCA-reduced model (37.60 %). Our findings confirm that a well-tuned sparse pooling strategy provides a robust, efficient, and high-performing solution for ESC tasks, particularly in resource-constrained scenarios where balancing accuracy and computational cost is crucial.

</details>


### [15] [Massive MIMO-OFDM Channel Acquisition with Multi-group Adjustable Phase Shift Pilots](https://arxiv.org/abs/2511.09826)
*Yu Zhao,Li You,Jinke Tang,Mengyu Qian,Bin Jiang,Xiang-Gen Xia,Xiqi Gao*

Main category: eess.SP

TL;DR: 提出了多组可调相移导频(MAPSPs)方法，通过多组基本序列生成导频，在角度-时延域利用信道稀疏性，显著降低大规模MIMO-OFDM系统的信道估计开销并提高频谱效率。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO-OFDM系统面临高信道获取开销的挑战，而可调相移导频(APSPs)虽然能利用信道稀疏性降低开销，但仍有改进空间。

Method: 将传统空间-频域信道模型转换为角度-时延域稀疏信道矩阵；通过多组基本序列生成MAPSPs；分析导频干扰对MMSE估计的影响机制；提出基于Zadoff-Chu序列的实现方案，包括接收信号预处理和导频调度方法。

Result: 仿真结果表明，MAPSP方法相比APSP实现了更低的估计均方误差(MSE)，并在移动场景中显著提高了频谱效率。

Conclusion: MAPSP方法通过多组导频设计和相位调度，有效降低了大规模MIMO-OFDM系统的信道估计开销，提升了系统性能。

Abstract: Massive multiple-input multiple-output - orthogonal frequency division multiplexing (MIMO-OFDM) systems face the challenge of high channel acquisition overhead while providing significant spectral efficiency (SE). Adjustable phase shift pilots (APSPs) are an effective technique to acquire channels with low overhead by exploiting channel sparsity. In this paper, we extend it to multiple groups and propose multi-group adjustable phase shift pilots (MAPSPs) to improve SE further. We first introduce a massive MIMO-OFDM system model and transform the conventional channel model in the space-frequency domain to the angle-delay domain, obtaining a sparse channel matrix. Then, we propose a method of generating MAPSPs through multiple basic sequences and investigate channel estimation processes. By analyzing the components of pilot interference, we elucidate the underlying mechanism by which interference affects MMSE estimation. Building upon this foundation, we demonstrate the benefit of phase scheduling in MAPSP channel estimation and establish the optimal design condition tailored for scheduling. Furthermore, we propose an implementation scheme based on Zadoff-Chu sequences that includes received signal pre-processing and pilot scheduling methods to mitigate pilot interference. Simulation results indicate that the MAPSP method achieves a lower mean square error (MSE) of estimation than APSP and significantly enhances SE in mobility scenarios.

</details>


### [16] [ASSENT: Learning-Based Association Optimization for Distributed Cell-Free ISAC](https://arxiv.org/abs/2511.09992)
*Mehdi Zafari,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 提出ASSENT框架，使用图神经网络解决分布式无蜂窝ISAC系统中的AP聚类、用户/目标调度和AP模式选择问题，在有限前传容量下实现近最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC解决方案主要依赖集中式处理和完整信道状态信息，缺乏在分布式部署和前传限制下可扩展的联合AP聚类和用户/目标调度方法。

Method: 将问题建模为混合整数线性规划，然后提出ASSENT图神经网络框架，通过训练学习关联和模式选择策略，直接从轻量级链路统计中做出决策。

Result: 仿真显示ASSENT实现近最优效用，准确学习底层关联关系，单次前向传播推理相比基于优化的方法显著降低决策延迟。

Conclusion: ASSENT为无蜂窝ISAC系统提供实时可扩展的解决方案，开源实现促进可复现和可扩展研究。

Abstract: Integrated Sensing and Communication (ISAC) is a key emerging 6G technology. Despite progress, ISAC still lacks scalable methods for joint AP clustering and user/target scheduling in distributed deployments under fronthaul limits. Moreover, existing ISAC solutions largely rely on centralized processing and full channel state information, limiting scalability. This paper addresses joint access point (AP) clustering, user and target scheduling, and AP mode selection in distributed cell-free ISAC systems operating with constrained fronthaul capacity. We formulate the problem as a mixed-integer linear program (MILP) that jointly captures interference coupling, RF-chain limits, and sensing requirements, providing optimal but computationally demanding solutions. To enable real-time and scalable operation, we propose ASSENT (ASSociation and ENTity selection), a graph neural network (GNN) framework trained on MILP solutions to efficiently learn association and mode-selection policies directly from lightweight link statistics. Simulations show that ASSENT achieves near-optimal utility while accurately learning the underlying associations. Additionally, its single forward pass inference reduces decision latency compared to optimization-based methods. An open-source Python/PyTorch implementation with full datasets is provided to facilitate reproducible and extensible research in cell-free ISAC.

</details>


### [17] [Rotatable IRS Aided Wireless Communication](https://arxiv.org/abs/2511.10006)
*Qiaoyan Peng,Qingqing Wu,Guangji Chen,Wen Chen,Shaodan Ma,Shanpu Shen,Rui Zhang*

Main category: eess.SP

TL;DR: 本文研究了可旋转智能反射面(IRS)的联合优化，通过动态调整IRS的旋转角度来最大化目标区域内所有位置的最小期望信噪比(SNR)。


<details>
  <summary>Details</summary>
Motivation: 可旋转IRS引入了新的空间自由度，无需实时改变元件位置即可调整方向。为了充分发挥可旋转IRS在无线通信中的潜力，需要优化其旋转角度以增强区域覆盖性能。

Method: 提出了角度相关的信道模型，准确描述IRS元件的接收和反射特性。针对单目标位置情况，开发了基于粒子群优化(PSO)的算法；针对区域覆盖增强情况，采用带零点检测的双循环PSO迭代算法。

Result: 数值结果表明，所提出的可旋转IRS设计在不同系统设置下相比各种基准方案实现了显著的SNR改进。

Conclusion: 可旋转IRS通过优化旋转角度能够有效提升无线通信系统的区域覆盖性能，所提出的算法和模型为实际应用提供了理论基础和实用方法。

Abstract: Rotatable intelligent reflecting surface (IRS) introduces a new spatial degree of freedom (DoF) by dynamically adjusting orientations without the need of changing its elements' positions in real time. To unleash the full potential of rotatable IRSs for wireless communications, this paper investigates the joint optimization of IRS rotation angles to maximize the minimum expected signal-to-noise ratio (SNR) over all locations within a given target area. We first propose an angle-dependent channel model that accurately characterizes the reception and reflection of each IRS element. Different from the conventional cosine-law assumption, the proposed model captures the practical electromagnetic characteristics of the IRS, including the effective reception area and reflection efficiency. For the single target location case, a particle swarm optimization (PSO)-based algorithm is developed to solve the SNR maximization problem, and a closed-form expression for a near-optimal solution is derived to provide useful insights. For the general area coverage enhancement case, the optimal rotation is obtained through a two-loop PSO-based iterative algorithm with null-point detection. In this algorithm, the outer loop updates the global rotation angles to maximize the minimum SNR over the target area, whereas the inner loop evaluates the SNR distribution within the area to identify the location corresponding to the minimum SNR through null-point detection. Numerical results demonstrate significant SNR improvement achieved by the proposed rotatable IRS design over various benchmark schemes under different system setups.

</details>


### [18] [Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement](https://arxiv.org/abs/2511.10073)
*Yuhao Ren,Yiting Liu,Yanfei Zhou,Zhiyu Zheng,Li Shang,Fan Yang,Zhiang Wang*

Main category: eess.SP

TL;DR: 提出了一种轻量级的协同优化框架，通过面积提示细化初始化和宏调度布局程序，在VLSI全局布局中平衡了计算效率和布局质量。


<details>
  <summary>Details</summary>
Motivation: 现有的布局初始化方法存在权衡：面积感知初始器计算昂贵，而基于点的快速初始器忽略单元面积，影响收敛性和解质量。

Method: 1. 面积提示细化初始器：通过虚拟节点和负权重边将启发式单元面积信息整合到有符号图信号中；2. 宏调度布局程序：逐步恢复面积约束，实现从细化初始器到完整面积感知目标的平滑过渡。

Result: 在12个测试案例中，11个案例的HPWL相比基于点初始器有改善，最高减少2.2%，运行速度比最先进的面积感知初始器快约100倍。

Conclusion: 该框架有效弥合了初始化差距，在保持计算效率的同时显著提升了布局质量。

Abstract: Global placement is a critical step with high computational complexity in VLSI physical design. Modern analytical placers formulate the placement problem as a nonlinear optimization, where initialization strongly affects both convergence behavior and final placement quality. However, existing initialization methods exhibit a trade-off: area-aware initializers account for cell areas but are computationally expensive and can dominate total runtime, while fast point-based initializers ignore cell area, leading to a modeling gap that impairs convergence and solution quality. We propose a lightweight co-optimization framework that bridges this initialization gap through two strategies. First, an area-hint refinement initializer incorporates heuristic cell area information into a signed graph signal by augmenting the netlist graph with virtual nodes and negative-weight edges, yielding an area-aware and spectrally smooth placement initialization. Second, a macro-schedule placement procedure progressively restores area constraints, enabling a smooth transition from the refined initializer to the full area-aware objective and producing high-quality placement results. We evaluate the framework on macro-heavy ISPD2005 academic benchmarks and two real-world industrial designs across two technology nodes (12 cases in total). Experimental results show that our method consistently improves half-perimeter wirelength (HPWL) over point-based initializers in 11 out of 12 cases, achieving up to 2.2% HPWL reduction, while running approximately 100 times faster than the state-of-the-art area-aware initializer.

</details>


### [19] [NOMA-Enabled Dual-IRS Relay Network Integrated with Ambient Backscatter Communication](https://arxiv.org/abs/2511.10178)
*Chandrima Thakur,Priyanka Ghosh,Rashmita Badhai,Sumit Kundu*

Main category: eess.SP

TL;DR: 本文分析了支持NOMA的双智能反射面中继网络与环境反向散射通信的集成系统，包含源节点、能量受限中继、两个NOMA用户和BS节点，使用时间切换中继协议同时进行能量收集和信息转发。


<details>
  <summary>Details</summary>
Motivation: 为未来物联网应用设计可靠且节能的NOMA-IRS辅助BS网络，解决能量受限中继的通信问题，并利用IRS增强链路性能。

Method: 采用时间切换中继协议，部署两个IRS增强链路，推导了中断概率和吞吐量的闭式表达式，并通过蒙特卡洛仿真验证分析结果。

Result: 数值结果揭示了主链路和BS辅助链路之间的关键权衡关系，系统性能受功率分配因子、反射效率、IRS元素数量和传输速率等参数影响。

Conclusion: 所提出的框架为设计未来物联网应用的可靠节能NOMA-IRS辅助BS网络提供了有用见解。

Abstract: This paper analyzes a NOMA-enabled dual-Intelligent Reflecting Surface (IRS) relay network integrated with Ambient Backscatter (BS) communication. The system comprises a source, an energy-constrained relay with energy harvesting (EH) and BS capabilities, two NOMA users, and a BS node. The relay adopts a time-switching relaying (TSR) protocol to harvest energy and forward information ,while simultaneously enabling BS-based communication. Two IRS are deployed to enhance the S to R and R to (D1, D2) links under blockage conditions. Closed-form expressions for the Outage Probability (OP) and Throughput of both the main communication links and the BS-assisted secondary links are derived. Furthermore, throughput is analyzed under varying system parameters, including power allocation factors, reflection efficiency, IRS elements, and transmission rate. Monte Carlo simulations validate the analytical results. numerical findings reveal critical trade-offs between the main and RS links. The proposed framework provides useful insights for designing reliable and energy-efficient NOMA-IRS-aided BS networks for future IoT applications.

</details>


### [20] [High Order Delta-Sigma Modulation with Positive Integer Coefficients](https://arxiv.org/abs/2511.10205)
*Martin J. W. Schubert*

Main category: eess.SP

TL;DR: 提出了用于级联Delta-Sigma调制器结构的二项式整数参数，该结构具有分布式反馈和分布式前馈输入以及多比特输出


<details>
  <summary>Details</summary>
Motivation: 实现高阶Delta-Sigma调制器设计，同时简化系数选择过程

Method: 使用二项式整数参数配置级联Delta-Sigma调制器结构，该结构包含分布式反馈、分布式前馈输入和多比特输出

Result: 证明了使用这些系数可以实现高阶调制器，并讨论了系数的精度要求

Conclusion: 二项式整数参数为级联Delta-Sigma调制器设计提供了有效的解决方案，能够实现高阶性能

Abstract: This document proposes binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback and distributed feedforward input and multi-bit output. It is demonstrated that high orders can be achieved with these coefficients. Accuracy requirements concerning the coefficients are discussed.

</details>


### [21] [Semantic Communication with Hopfield Memories](https://arxiv.org/abs/2511.10302)
*Karim Nasreddine,Christo Kurisummoottil Thomas,Walid Saad*

Main category: eess.SP

TL;DR: 提出了一种基于现代Hopfield网络的内存增强语义通信框架，通过软注意力检索机制动态调整语义原型权重，在数据动态变化时实现稳定的匹配决策，显著减少传输比特数。


<details>
  <summary>Details</summary>
Motivation: 传统联合源信道编码使用静态语义表示，无法适应动态变化的源分布。现有基于变分自编码器的硬量化方法在数据动态变化时频繁更新内存，导致带宽使用效率低下。

Method: 使用现代Hopfield网络在发射器和接收器之间维护共享语义概念内存，采用软注意力检索机制平滑调整存储的语义原型权重，并联合优化编码器、解码器和内存检索机制。

Result: 在多样化视频场景的广泛仿真中，所提出的基于MHN的方法平均实现了约14%的比特减少，在渐进内容变化场景中最高可达70%的比特减少。

Conclusion: 软检索相比硬量化在有限语义漂移下减少了不必要的传输，理论分析建立了基本的率-失真-重用权衡关系。

Abstract: Traditional joint source-channel coding employs static learned semantic representations that cannot dynamically adapt to evolving source distributions. Shared semantic memories between transmitter and receiver can potentially enable bandwidth savings by reusing previously transmitted concepts as context to reconstruct data, but require effective mechanisms to determine when current content is similar enough to stored patterns. However, existing hard quantization approaches based on variational autoencoders are limited by frequent memory updates even under small changes in data dynamics, which leads to inefficient usage of bandwidth.To address this challenge, in this paper, a memory-augmented semantic communication framework is proposed where both transmitter and receiver maintain a shared memory of semantic concepts using modern Hopfield networks (MHNs). The proposed framework employs soft attention-based retrieval that smoothly adjusts stored semantic prototype weights as data evolves that enables stable matching decisions under gradual data dynamics. A joint optimization of encoder, decoder, and memory retrieval
  mechanism is performed with the objective of maximizing a reasoning capacity metric that quantifies semantic efficiency as the product of memory reuse rate and compression ratio. Theoretical analysis establishes the fundamental rate-distortion-reuse tradeoff and proves that soft retrieval reduces unnecessary transmissions compared to hard quantization under bounded semantic drift. Extensive simulations over diverse video scenarios demonstrate that the proposed MHN-based approach achieves substantial bit reductions around 14% on average and up to 70% in scenarios with gradual content changes compared to baseline.

</details>


### [22] [Evaluation of Grid-based Uncertainty Propagation for Collaborative Self-Calibration in Indoor Positioning Systems](https://arxiv.org/abs/2511.10526)
*Andrea Jung,Paul Schwarzbach,Oliver Michler*

Main category: eess.SP

TL;DR: 本文提出了一种基于离散贝叶斯方法的协作式UWB网络自校准算法，通过概率状态估计降低了对测量可用性的要求，在静态室内环境中实现了亚米级定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于无线电的定位系统需要精确测量位置的固定参考点（锚点），部署耗时且成本高昂，因此需要开发自动化的网络初始化方法以减少对基础设施的依赖。

Method: 扩展了基于网格不确定性传播的离散贝叶斯方法，通过概率状态估计进行协作式自校准，在12个节点的静态室内UWB网络中进行了真实数据验证。

Result: 在视距条件下平均测距误差为0.28米，混合传播场景下总体测距误差为1.11米，实现了亚米级定位精度，算法对测量噪声和部分连接场景具有鲁棒性。

Conclusion: 该方法为室内定位应用提供了自动化的UWB网络初始化方案，相比手动锚点校准程序显著降低了基础设施依赖性。

Abstract: Radio-based localization systems conventionally require stationary reference points (e.g. anchors) with precisely surveyed positions, making deployment time-consuming and costly. This paper presents an empirical evaluation of collaborative self-calibration for Ultra-Wideband (UWB) networks, extending a discrete Bayesian approach based on grid-based uncertainty propagation. The enhanced algorithm reduces measurement availability requirements while maintaining positioning accuracy through probabilistic state estimation. We validate the approach using real-world data from controlled indoor UWB network experiments with 12 nodes in a static environment. Experimental evaluation demonstrates 0.28~m mean ranging error under line-of-sight conditions and 1.11~m overall ranging error across mixed propagation scenarios, achieving sub-meter positioning accuracy. Results demonstrate the algorithm's robustness to measurement noise and partial connectivity scenarios typical in industrial deployments. The findings contribute to automated UWB network initialization for indoor positioning applications, reducing infrastructure dependency compared to manual anchor calibration procedures.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [A Universal Block Error Rate Bound for Fluid Antenna Systems](https://arxiv.org/abs/2511.09929)
*Zhentian Zhang,David Morales-Jimenez,Hao Jiang,Christos Masouros*

Main category: cs.IT

TL;DR: 本文研究了有限块长流体天线系统(FBL-FAS)，提出了一个通用的块错误率(BLER)边界作为性能基准，该边界在有无统计模型的情况下都可计算，具有简单性、准确性和普适性。


<details>
  <summary>Details</summary>
Motivation: 当前研究很少探讨有限块长约束对流体天线系统设计的影响，缺乏统一的性能度量标准和分析模型。

Method: 推导了一个通用的BLER边界，该边界可在有统计模型和无统计模型的情况下计算，支持模型感知和模型无关的系统场景。

Result: 当统计模型已知时，从所提BLER边界推导的分析结果与实证发现高度一致，验证了边界的准确性。

Conclusion: 所提出的BLER边界为各种FAS架构提供了一个通用且实用的性能基准，具有显著简单性、准确性和普适性。

Abstract: Fluid antenna systems (FASs) offer genuine simplicity for communication network design by eliminating expensive hardware overhead and reducing the complexity of access protocol architectures. Through the discovery of significant spatial diversity within a compact antenna space, FASs enable the implementation of reconfigurable-antenna-based architectures. However, current state-of-the-art studies rarely investigate the impact of finite blocklength constraints on FAS-based designs, leaving a gap in both analytical modeling and the establishment of a solid, universally applicable performance metric for finite blocklength fluid antenna systems (FBL-FAS). In this work, we focus on the study of FBL-FAS and, more importantly, derive a block error rate (BLER) bound that serves as a general and practical performance benchmark across various FAS architectures. The proposed BLER bound is computable both with and without an explicit statistical model, meaning that the BLER performance can be characterized analytically or empirically under model-aware or model-free system scenarios. Moreover, when the statistical model is known, the analytical results derived from the proposed BLER bound exhibit strong alignment with the empirical findings, demonstrating the remarkable simplicity, accuracy, and universality of the proposed BLER bound.

</details>


### [24] [Implicit Semantic Communication Based on Bayesian Reconstruction Framework](https://arxiv.org/abs/2511.10052)
*Yiwei Liao,Shurui Tu,Yujie Zhou,Dongzi Jin,Yong Xiao,Yingyu Li*

Main category: cs.IT

TL;DR: 提出了一种基于贝叶斯超图推理的语义通信框架，能够从发送端基于成对关系的显式语义中恢复接收端的高阶超边隐含语义信息。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信大多基于成对关系图表示语义，无法捕捉对某些语义源至关重要的高阶交互关系。

Method: 使用贝叶斯超图推理方法，在接收端基于发送端传输的成对关系显式语义直接恢复涉及高阶超边的隐含语义信息。

Result: 在真实数据集上的实验表明，所提出的SBRF方法基于成对关系显式语义能够实现高达90%的高阶超边恢复准确率。

Conclusion: 该框架成功解决了语义通信中高阶语义信息恢复的问题，为语义通信系统提供了更强大的语义表达能力。

Abstract: Semantic communication is a novel communication paradigm that focuses on the transportation and delivery of the \emph{meaning} of messages. Recent results have verified that a graphical structure provides the most expressive and structurally faithful formalism for representing the relational semantics in most information sources. However, most existing works represent the semantics based on pairwise relation-based graphs, which cannot capture the higher-order interactions that are essential for some semantic sources. This paper proposes a novel Bayesian hypergraph inference-based semantic communication framework that can directly recover implicit semantic information involving high-order hyperedges at the receiver based on the pairwise relation-based explicit semantics sent by the transmitter. Experimental results based on real-world datasets demonstrated that the proposed SBRF achieves up to 90\% recovery accuracy of the high-order hyperedges based on the pairwise relation-based explicit semantics.

</details>


### [25] [Generalized Spectral Bound for Quasi-Twisted Codes](https://arxiv.org/abs/2511.10066)
*Buket Özkaya*

Main category: cs.IT

TL;DR: 本文提出了一种改进的准扭转码谱界方法，相比Jensen界和Ezerman界能提供更紧的最小距离下界。


<details>
  <summary>Details</summary>
Motivation: 现有准扭转码的谱界方法性能不如Jensen界，而近期准循环码的改进谱界方法在许多情况下优于Jensen界，因此希望将这种方法推广到准扭转码。

Method: 采用近期准循环码改进谱界的方法，将其推广到准扭转码的情况。

Result: 新的广义谱界相比Jensen界和Ezerman界能提供更紧的最小距离下界。

Conclusion: 推广的谱界方法在准扭转码中表现优于现有的Jensen界和Ezerman界。

Abstract: Semenov and Trifonov [22] developed a spectral theory for quasi-cyclic codes and formulated a BCH-like minimum distance bound. Their approach was generalized by Zeh and Ling [24], by using the HT bound. The first spectral bound for quasi-twisted codes appeared in [7], which generalizes Semenov-Trifonov and Zeh-Ling bounds, but its overall performance was observed to be worse than the Jensen bound. More recently, an improved spectral bound for quasi-cyclic codes was proposed in [15], which outperforms the Jensen bound in many cases. In this paper, we adopt this approach to quasi-twisted case and we show that this new generalized spectral bound provides tighter lower bounds on the minimum distance compared to the Jensen and Ezerman et. al. bounds.

</details>


### [26] [Sequential Adversarial Hypothesis Testing](https://arxiv.org/abs/2511.10181)
*Eeshan Modak,Mayank Bakshi,Bikash Kumar Dey,Vinod M. Prabhakaran*

Main category: cs.IT

TL;DR: 本文研究了顺序设置下的对抗性二元假设检验问题，其中每个假设对应一个封闭的凸分布集合，对手根据过去观测选择分布生成观测数据。


<details>
  <summary>Details</summary>
Motivation: 在顺序设置中，检测器使用的观测数量是可变的，这种额外的自由度可以提高测试的渐近性能。研究在观测数量约束和错误概率约束下的性能极限。

Method: 通过分析每个假设对应的封闭凸分布集合，考虑对手能够访问过去观测并选择分布的情况，研究顺序检测器的性能。

Result: 刻画了可实现的错误指数对的闭包，并分析了在观测数量约束和错误概率约束下的性能。

Conclusion: 顺序设置下的对抗性二元假设检验问题具有更好的渐近性能，研究结果为该问题提供了理论分析框架和性能界限。

Abstract: We study the adversarial binary hypothesis testing problem in the sequential setting. Associated with each hypothesis is a closed, convex set of distributions. Given the hypothesis, each observation is generated according to a distribution chosen (from the set associated with the hypothesis) by an adversary who has access to past observations. In the sequential setting, the number of observations the detector uses to arrive at a decision is variable; this extra freedom improves the asymptotic performance of the test. We characterize the closure of the set of achievable pairs of error exponents. We also study the problem under constraints on the number of observations used and the probability of error incurred.

</details>


### [27] [Causal Model-Based Reinforcement Learning for Sample-Efficient IoT Channel Access](https://arxiv.org/abs/2511.10291)
*Aswin Arun,Christo Kurisummoottil Thomas,Rimalpudi Sarvendranath,Walid Saad*

Main category: cs.IT

TL;DR: 提出了一种基于因果模型的多智能体强化学习框架，通过结构因果模型和注意力网络显式表示网络变量间的因果关系，显著提高了样本效率并提供了可解释的调度决策。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在无线物联网应用中面临样本效率低的问题，而传统基于模型的方法依赖黑盒模型，缺乏可解释性和推理能力。

Method: 使用结构因果模型和注意力推理网络显式表示网络变量间的因果关系，开发可解释的因果模型捕获MAC控制消息、传输动作和信道观测之间的关系，通过数据增强生成合成数据，使用近端策略优化进行策略优化。

Result: 分析结果表明因果MBRL相比黑盒方法具有指数级样本复杂度优势，平均减少58%的环境交互，收敛速度更快，并能通过注意力因果归因提供可解释的调度决策。

Conclusion: 因果MBRL结合了样本效率和可解释性，为资源受限的无线系统提供了一种实用的方法。

Abstract: Despite the advantages of multi-agent reinforcement learning (MARL) for wireless use case such as medium access control (MAC), their real-world deployment in Internet of Things (IoT) is hindered by their sample inefficiency. To alleviate this challenge, one can leverage model-based reinforcement learning (MBRL) solutions, however, conventional MBRL approaches rely on black-box models that are not interpretable and cannot reason. In contrast, in this paper, a novel causal model-based MARL framework is developed by leveraging tools from causal learn- ing. In particular, the proposed model can explicitly represent causal dependencies between network variables using structural causal models (SCMs) and attention-based inference networks. Interpretable causal models are then developed to capture how MAC control messages influence observations, how transmission actions determine outcomes, and how channel observations affect rewards. Data augmentation techniques are then used to generate synthetic rollouts using the learned causal model for policy optimization via proximal policy optimization (PPO). Analytical results demonstrate exponential sample complexity gains of causal MBRL over black-box approaches. Extensive simulations demonstrate that, on average, the proposed approach can reduce environment interactions by 58%, and yield faster convergence compared to model-free baselines. The proposed approach inherently is also shown to provide interpretable scheduling decisions via attention-based causal attribution, revealing which network conditions drive the policy. The resulting combination of sample efficiency and interpretability establishes causal MBRL as a practical approach for resource-constrained wireless systems.

</details>


### [28] [Reconfigurable Airspace: Synergizing Movable Antenna and Intelligent Surface for Low-Altitude ISAC Networks](https://arxiv.org/abs/2511.10310)
*Honghao Wang,Qingqing Wu,Yifan Jiang,Ziyuan Zheng,Ziheng Zhang,Yanze Zhu,Ying Gao,Wen Chen,Guanghai Liu,Abbas Jamalipour*

Main category: cs.IT

TL;DR: 提出了一种利用可移动天线(MAs)和智能反射面(IRSs)作为双重使能器的框架，以解决低空无人机网络在6G集成感知与通信系统中的挑战，包括高移动性、复杂传播环境以及感知与通信功能之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 低空无人机网络是未来6G集成感知与通信系统的关键组成部分，但其部署面临无人机高移动性、复杂传播环境以及感知与通信功能之间固有权衡的挑战。

Method: 利用可移动天线通过主动收发器重构和智能反射面通过被动信道重构的协同工作，显著提升系统性能。分析了两种核心无人机部署场景：作为ISAC用户和作为空中网络节点。

Result: 仿真结果验证了MA-IRS使能的ISAC架构具有巨大潜力，能够实现高精度跟踪、空中安全、鲁棒设计和复杂耦合资源优化。

Conclusion: 识别并分析了每个场景下的关键技术挑战和研究机会，为先进低空ISAC网络的未来设计指明了清晰方向。

Abstract: Low-altitude unmanned aerial vehicle (UAV) networks are integral to future 6G integrated sensing and communication (ISAC) systems. However, their deployment is hindered by challenges stemming from high mobility of UAVs, complex propagation environments, and the inherent trade-offs between coexisting sensing and communication functions. This article proposes a novel framework that leverages movable antennas (MAs) and intelligent reflecting surfaces (IRSs) as dual enablers to overcome these limitations. MAs, through active transceiver reconfiguration, and IRSs, via passive channel reconstruction, can work in synergy to significantly enhance system performance. Our analysis first elaborates on the fundamental gains offered by MAs and IRSs, and provides simulation results that validate the immense potential of the MA-IRS-enabled ISAC architecture. Two core UAV deployment scenarios are then investigated: (i) UAVs as ISAC users, where we focus on achieving high-precision tracking and aerial safety, and (ii) UAVs as aerial network nodes, where we address robust design and complex coupled resource optimization. Finally, key technical challenges and research opportunities are identified and analyzed for each scenario, charting a clear course for the future design of advanced low-altitude ISAC networks.

</details>
