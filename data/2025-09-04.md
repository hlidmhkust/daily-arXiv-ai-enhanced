<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 4]
- [eess.IV](#eess.IV) [Total: 23]
- [eess.SP](#eess.SP) [Total: 14]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [On a class of twisted elliptic curve codes](https://arxiv.org/abs/2509.03034)
*Xiaofeng Liu,Jun Zhang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 本文研究了带扭曲的椭圆曲线码(TECCs)，特别关注单扭曲情况，给出了奇偶校验矩阵的显式表达式，建立了自对偶性的充要条件，确定了最小距离，并提供了MDS、AMDS、自对偶和MDS自对偶TECCs的实例。


<details>
  <summary>Details</summary>
Motivation: 受扭曲广义Reed-Solomon(TGRS)码研究的启发，本文首次系统研究扭曲椭圆曲线码(TECCs)，旨在扩展编码理论在椭圆曲线上的应用。

Method: 通过计算Weil微分显式给出TECCs的奇偶校验矩阵，建立自对偶性的充要条件，确定最小距离，并构造具体实例。

Result: 成功构建了TECCs的理论框架，给出了自对偶性的完整判据，确定了最小距离，提供了多种类型TECCs的实例，并证明了TECCs与ECCs/GRS码的非等价性。

Conclusion: TECCs为编码理论提供了新的研究方向，具有重要的理论价值和潜在应用前景，特别是在构造MDS自对偶码方面展现出独特优势。

Abstract: Motivated by the studies of twisted generalized Reed-Solomon (TGRS) codes, we
initiate the study of twisted elliptic curve codes (TECCs) in this paper. In
particular, we study a class of TECCs with one twist. The parity-check matrices
of the TECCs are explicitly given by computing the Weil differentials. Then the
sufficient and necessary conditions of self-duality are presented. The minimum
distances of the TECCs are also determined. Moreover, examples of MDS, AMDS,
self-dual and MDS self-dual TECCs are given. Finally, we calculate the
dimensions of the Schur squares of TECCs and show the non-equivalence between
TECCs and ECCs/GRS codes.

</details>


### [2] [Successive Cancellation Decoding For General Monotone Chain Polar Codes](https://arxiv.org/abs/2509.03128)
*Zichang Ren,Chunhang Zheng,Dou Li,Yuping Zhao*

Main category: cs.IT

TL;DR: 提出了单调链极化码的通用SC解码框架，支持多终端、非二进制和任意单调链解码，时间复杂度在O(NlogN)到O(N²)之间，并引入了常数时间分叉策略实现高效列表解码。


<details>
  <summary>Details</summary>
Motivation: 单调链极化码在分布式无损编码中具有灵活性，但现有SC解码方案面临挑战，需要通用的解码解决方案来处理任意终端数、非二进制字母表和任意单调链。

Method: 将SC解码任务制定为极化变换上的推理子任务序列，提出基于概率传播原理的计算图框架，并引入常数时间解码器分叉策略。

Result: 数值结果显示所提方案相比经典lazy-copy方案具有优越性能，时间效率高且不依赖O(N)空间技术。

Conclusion: 提出的计算图框架和分叉策略为单调链极化码提供了有效的通用SC解码解决方案，解决了现有方法的局限性。

Abstract: Monotone chain polar codes generalize classical polar codes to multivariate
settings, offering a flexible approach for achieving the entire admissible rate
region in the distributed lossless coding problem. However, this flexibility
also introduces significant challenges for existing successive cancellation
(SC) based decoding schemes. Motivated by the need for a general SC decoding
solution, we present a comprehensive decoding strategy for monotone chain polar
codes that can handle arbitrary numbers of terminals, non-binary alphabets, and
decoding along arbitrary monotone chains. Specifically, we formulate the SC
decoding task as a series of inference subtasks over the polar transform and
propose a computational graph framework based on probability propagation
principles. This approach highlights the impact of variable switching during
decoding and shows that time complexity varies between $O(N\log{N})$ and
$O(N^2)$, depending on the specific chain structure. Moreover, we demonstrate
that the widely used $O(N)$ space optimization is not universally applicable to
monotone chain polar codes, which prompts us to introduce a constant-time
decoder forking strategy based on the proposed logical computation graphs. This
strategy enables time-efficient list decoding without relying on $O(N)$-space
techniques. Numerical results verify the superior performance of the proposed
scheme compared with the classical lazy-copy scheme.

</details>


### [3] [New Bounds for Linear Codes with Applications](https://arxiv.org/abs/2509.03337)
*Liren Lin,Guanghui Zhang,Bocong Chen,Hongwei Liu*

Main category: cs.IT

TL;DR: 该论文在传统线性码边界理论基础上，通过引入非零码字权重w的附加假设，结合残差码技术和经典边界方法，推导出了连接参数n、k、d、q和w的显式不等式，获得了比传统边界更严格的限制条件。


<details>
  <summary>Details</summary>
Motivation: 传统线性码边界理论仅基于参数n、k、d和q，忽略了码字权重信息。该研究旨在利用码中包含特定权重码字的附加信息，获得更精确的边界限制。

Method: 结合残差码技术和经典边界方法（如Singleton边界和Griesmer边界），推导出连接码长n、维度k、最小距离d、域大小q和码字权重w的显式不等式。

Result: 获得了比传统边界更严格的权重限制，特别是在接近最小距离或码长的权重范围内。数值比较显示这些w感知边界显著扩大了已知的排除权重范围。

Conclusion: 通过引入码字权重信息，该研究提供了对线性码结构更精细的限制，特别是在MDS码权重约束、一般线性码数值限制和权重分布排除范围方面具有重要应用价值。

Abstract: Bounds on linear codes play a central role in coding theory, as they capture
the fundamental trade-off between error-correction capability (minimum
distance) and information rate (dimension relative to length). Classical
results characterize this trade-off solely in terms of the parameters $n$, $k$,
$d$ and $q$. In this work we derive new bounds under the additional assumption
that the code contains a nonzero codeword of weight $w$.By combining
residual-code techniques with classical results such as the Singleton and
Griesmer bounds,we obtain explicit inequalities linking $n$, $k$, $d$, $q$ and
$w$. These bounds impose sharper restrictions on admissible codeword weights,
particularly those close to the minimum distance or to the code length.
Applications include refined constraints on the weights of MDS codes, numerical
restrictions on general linear codes, and excluded weight ranges in the weight
distribution. Numerical comparisons across standard parameter sets demonstrate
that these $w$-aware bounds strictly enlarge known excluded weight ranges and
sharpen structural limitations on linear codes.

</details>


### [4] [PoolPy: Flexible Group Testing Design for Large-Scale Screening](https://arxiv.org/abs/2509.03481)
*Lorenzo Talamanca,Julian Trouillon*

Main category: cs.IT

TL;DR: PoolPy是一个统一的群体检测框架，提供10种不同方法的优化策略选择，通过web界面计算超过10,000种设计方案，帮助用户根据时间、成本或样本稀释等约束条件选择最优群体检测方法。


<details>
  <summary>Details</summary>
Motivation: 在大规模筛查活动中，群体检测相比单个样本检测可以大幅减少检测次数，但由于方法多样性和性能差异，以及缺乏易用工具，选择和实施合适的群体检测方法仍然具有挑战性。

Method: 开发PoolPy统一框架，集成10种群体检测方法，根据用户定义的时间、成本或样本稀释等约束条件，计算和比较超过10,000种群体检测设计方案。

Result: 识别了关键权衡因素（如最小化检测次数或组大小），确定了不同方法在特定应用场景中的适用性，发现没有单一方法在所有情况下都是最优的。

Conclusion: 群体检测方法的选择需要根据具体案例进行，PoolPy框架提供了清晰的指导，帮助用户根据实际约束条件选择最适合的群体检测策略。

Abstract: In large screening campaigns, group testing can greatly reduce the number of
tests needed when compared to testing each sample individually. However,
choosing and applying an appropriate group testing method remains challenging
due to the wide variety in design and performance across methods, and the lack
of accessible tools. Here, we present PoolPy, a unified framework for designing
and selecting optimal group testing strategies across ten different methods
according to user-defined constraints, such as time, cost or sample dilution.
By computing over 10,000 group testing designs made available through a web
interface, we identified key trade-offs, such as minimizing test number or
group size, that define applicability to specific use cases. Overall, we show
that no single method is universally optimal, and provide clear indications for
method choice on a case-by-case basis.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [5] [Pan-Cancer mitotic figures detection and domain generalization: MIDOG 2025 Challenge](https://arxiv.org/abs/2509.02585)
*Zhuoyan Shen,Esther Bär,Maria Hawkins,Konstantin Bräutigam,Charles-Antoine Collins-Fekete*

Main category: eess.IV

TL;DR: 本文介绍了MIDOG 2025挑战赛的提交方案，专注于病理组织学中的有丝分裂检测，通过发布新数据集和采用最新训练方法取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 解决癌症预后评估中关键的有丝分裂检测任务，遵循"Bitter Lesson"原则，强调数据规模而非算法新颖性。

Method: 公开发布两个新数据集（常规和非常规有丝分裂），采用最新的训练方法，包括数据增强和优化技术。

Result: Track-1 F1分数达到0.8407，Track-2非常规有丝分裂细胞分类的平衡准确率达到0.9107。

Conclusion: 通过大规模数据和现代训练方法的结合，在有丝分裂检测任务上取得了显著性能提升，验证了数据规模的重要性。

Abstract: This report details our submission to the Mitotic Domain Generalization
(MIDOG) 2025 challenge, which addresses the critical task of mitotic figure
detection in histopathology for cancer prognostication. Following the "Bitter
Lesson"\cite{sutton2019bitterlesson} principle that emphasizes data scale over
algorithmic novelty, we have publicly released two new datasets to bolster
training data for both conventional \cite{Shen2024framework} and atypical
mitoses \cite{shen_2025_16780587}. Besides, we implement up-to-date training
methodologies for both track and reach a Track-1 F1-Score of 0.8407 on our test
set, as well as a Track-2 balanced accuracy of 0.9107 for atypical mitotic cell
classification.

</details>


### [6] [MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and Atypical Subtyping](https://arxiv.org/abs/2509.02586)
*Esha Sadia Nasir,Jiaqi Lv,Mostafa Jahanifer,Shan E Ahmed Raza*

Main category: eess.IV

TL;DR: MitoDetect++是一个用于MIDOG 2025挑战赛的深度学习管道，通过U-Net架构进行有丝分裂检测，使用Vision Transformer进行非典型有丝分裂分类，在验证域上达到0.892的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 自动检测和分类有丝分裂图像，特别是区分非典型和正常有丝分裂，是计算病理学中的关键挑战，需要开发统一的深度学习解决方案。

Method: 采用U-Net编码器-解码器架构（EfficientNetV2-L骨干网络）进行检测，使用Virchow2视觉变换器（LoRA微调）进行分类，结合注意力模块、强数据增强、焦点损失和分层交叉验证。

Result: 在验证域上实现了0.892的平衡准确率，显示出良好的临床适用性和跨任务可扩展性。

Conclusion: MitoDetect++提供了一个有效的统一框架，能够同时处理有丝分裂检测和非典型分类任务，具有强大的泛化能力和临床实用性。

Abstract: Automated detection and classification of mitotic figures especially
distinguishing atypical from normal remain critical challenges in computational
pathology. We present MitoDetect++, a unified deep learning pipeline designed
for the MIDOG 2025 challenge, addressing both mitosis detection and atypical
mitosis classification. For detection (Track 1), we employ a U-Net-based
encoder-decoder architecture with EfficientNetV2-L as the backbone, enhanced
with attention modules, and trained via combined segmentation losses. For
classification (Track 2), we leverage the Virchow2 vision transformer,
fine-tuned efficiently using Low-Rank Adaptation (LoRA) to minimize resource
consumption. To improve generalization and mitigate domain shifts, we integrate
strong augmentations, focal loss, and group-aware stratified 5-fold
cross-validation. At inference, we deploy test-time augmentation (TTA) to boost
robustness. Our method achieves a balanced accuracy of 0.892 across validation
domains, highlighting its clinical applicability and scalability across tasks.

</details>


### [7] [Sequential Hard Mining: a data-centric approach for Mitosis Detection](https://arxiv.org/abs/2509.02588)
*Maxime W. Lafarge,Viktor H. Koelzer*

Main category: eess.IV

TL;DR: 该论文采用受劳加技术启发的高效样本采样方法，以更有效地利用大量有标注的有丝分裂图象数据集训练深度学习模型，并为MIDOG 2025挑战赛提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着组织学图像中有丝分裂图标注数据集的不断增长，如何最优地利用这些大量数据来训练深度学习模型成为了新的挑战。

Method: 基于之前提出的方法，采用受劳加技术启发的高效样本采样方法，对训练数据进行优化选择。

Result: 为MIDOG 2025挑战赛的两个赛道提供了借鉴劳加技术的解决方案。

Conclusion: 通过高效的数据采样策略，可以更有效地利用大规模标注数据来提升深度学习模型在有丝分裂图识别任务中的性能。

Abstract: With a continuously growing availability of annotated datasets of mitotic
figures in histology images, finding the best way to optimally use with this
unprecedented amount of data to optimally train deep learning models has become
a new challenge. Here, we build upon previously proposed approaches with a
focus on efficient sampling of training data inspired by boosting techniques
and present our candidate solutions for the two tracks of the MIDOG 2025
challenge.

</details>


### [8] [Normal and Atypical Mitosis Image Classifier using Efficient Vision Transformer](https://arxiv.org/abs/2509.02589)
*Xuan Qi,Dominic Labella,Thomas Sanford,Maxwell Lee*

Main category: eess.IV

TL;DR: 使用EfficientViT-L2混合架构在MIDOG 2025挑战中实现非典型与正常有丝分裂分类，在13,938个癌细胞核数据集上获得0.859平衡准确率和0.942 ROC AUC


<details>
  <summary>Details</summary>
Motivation: 解决癌症病理图像中非典型有丝分裂与正常有丝分裂的自动分类问题，这对于癌症诊断和分级至关重要

Method: 采用EfficientViT-L2混合CNN-ViT架构，使用留一癌症类型交叉验证和5折集成，通过染色解卷积进行图像增强

Result: 在初步评估阶段获得平衡准确率0.859、ROC AUC 0.942和原始准确率0.85，表现出竞争性且均衡的性能

Conclusion: EfficientViT-L2架构在非典型有丝分裂分类任务中表现出色，具有良好的领域泛化能力和平衡的性能指标

Abstract: We tackle atypical versus normal mitosis classification in the MIDOG 2025
challenge using EfficientViT-L2, a hybrid CNN--ViT architecture optimized for
accuracy and efficiency. A unified dataset of 13,938 nuclei from seven cancer
types (MIDOG++ and AMi-Br) was used, with atypical mitoses comprising ~15. To
assess domain generalization, we applied leave-one-cancer-type-out
cross-validation with 5-fold ensembles, using stain-deconvolution for image
augmentation. For challenge submissions, we trained an ensemble with the same
5-fold split but on all cancer types. In the preliminary evaluation phase, this
model achieved balanced accuracy of 0.859, ROC AUC of 0.942, and raw accuracy
of 0.85, demonstrating competitive and well-balanced performance across
metrics.

</details>


### [9] [Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification](https://arxiv.org/abs/2509.02591)
*Mieko Ochi,Bae Yuan*

Main category: eess.IV

TL;DR: 利用病理基础模型通过效率微调和集成学习，精准区分有线分裂的典型和非典型变体，提高肝肿瘤预测准确性


<details>
  <summary>Details</summary>
Motivation: 有线分裂的非典型变体数量与肿瘤恶性程度密切相关，但却是生物检验师识别的难点，需要精准区分来支撑患者预后评估和资源分配

Method: 基于大规模组织病理数据预训练的病理基础模型，采用低秩适配进行参数效率微调，训练中使用鱼眼变换强调有线分裂，并通过傅里叶域适配利用ImageNet目标图像，最后集成多个模型整合补充性形态见解

Result: 在预评阶段数据集上达到了高平衡准确度

Conclusion: 通过基础模型的效率微调和多模型集成策略，可以有效提高有线分裂变体分类的准确性，为肝肿瘤预后评估提供可靠差异化指标

Abstract: Mitotic figures are classified into typical and atypical variants, with
atypical counts correlating strongly with tumor aggressiveness. Accurate
differentiation is therefore essential for patient prognostication and resource
allocation, yet remains challenging even for expert pathologists. Here, we
leveraged Pathology Foundation Models (PFMs) pre-trained on large
histopathology datasets and applied parameter-efficient fine-tuning via
low-rank adaptation. During training, we employ a fisheye transform to
emphasize mitoses and Fourier Domain Adaptation using ImageNet target images.
Finally, we ensembled multiple PFMs to integrate complementary morphological
insights, achieving a high balanced accuracy on the Preliminary Evaluation
Phase dataset.

</details>


### [10] [Robust Pan-Cancer Mitotic Figure Detection with YOLOv12](https://arxiv.org/abs/2509.02593)
*Raphaël Bourgade,Guillaume Balezo,Thomas Walter*

Main category: eess.IV

TL;DR: 基于YOLOv12的有杰图识别方法，在MIDOG 2025挑战赛中获得0.801的F1分数，不依赖外部数据


<details>
  <summary>Details</summary>
Motivation: 有杰图是肿瘤质预后的关键组织学标志，但识别存在显著的观察者间差异，需要发展稳健的自动检测算法

Method: 采用YOLOv12物体检测架构开发有杰图检测方法

Result: 在MIDOG 2025挑战赛预测试验集上获得F1分数0.801

Conclusion: 该方法在不使用外部数据的情况下展现了良好的有杰图检测性能，为解决观察者间差异问题提供了有效方案

Abstract: Mitotic figures represent a key histoprognostic feature in tumor pathology,
providing crucial insights into tumor aggressiveness and proliferation.
However, their identification remains challenging, subject to significant
inter-observer variability, even among experienced pathologists. To address
this issue, the MItosis DOmain Generalization (MIDOG) 2025 challenge marks the
third edition of an international competition aiming to develop robust mitosis
detection algorithms. In this paper, we present a mitotic figures detection
approach based on the YOLOv12 object detection architecture, achieving a
$F_1$-score of 0.801 on the preliminary test set of the MIDOG 2025 challenge,
without relying on external data.

</details>


### [11] [ConvNeXt with Histopathology-Specific Augmentations for Mitotic Figure Classification](https://arxiv.org/abs/2509.02595)
*Hana Feki,Alice Blondel,Thomas Walter*

Main category: eess.IV

TL;DR: 基于轻量级ConvNeXt架构的解决方案，通过多数据集训练和病理学特异性数据增强，在MIDOG 2025挑战赛中实现了0.8961的平衡准确率，证明广泛领域暴露和针对性增强策略对构建准确且可泛化的有丝分裂图像分类器至关重要。


<details>
  <summary>Details</summary>
Motivation: 准确分类有丝分裂图像对计算病理学至关重要，但区分非典型有丝分裂图像(AMFs)和正常有丝分裂图像(NMFs)存在挑战，包括形态差异细微、类内变异大、领域偏移、标注有限和严重类别不平衡等问题。

Method: 使用轻量级ConvNeXt架构，在多个数据集(AMi-Br, AtNorM-Br, AtNorM-MD, OMG-Octo)上进行训练以最大化领域覆盖；采用病理学特异性数据增强管道(包括弹性和染色特异性变换)和平衡采样来缓解类别不平衡；使用分组5折交叉验证策略进行可靠评估。

Result: 在初步排行榜上，模型达到了0.8961的平衡准确率，排名靠前。

Conclusion: 广泛领域暴露结合针对性增强策略是构建准确且可泛化的有丝分裂图像分类器的关键。

Abstract: Accurate mitotic figure classification is crucial in computational pathology,
as mitotic activity informs cancer grading and patient prognosis.
Distinguishing atypical mitotic figures (AMFs), which indicate higher tumor
aggressiveness, from normal mitotic figures (NMFs) remains challenging due to
subtle morphological differences and high intra-class variability. This task is
further complicated by domain shifts, including variations in organ, tissue
type, and scanner, as well as limited annotations and severe class imbalance.
To address these challenges in Track 2 of the MIDOG 2025 Challenge, we propose
a solution based on the lightweight ConvNeXt architecture, trained on all
available datasets (AMi-Br, AtNorM-Br, AtNorM-MD, and OMG-Octo) to maximize
domain coverage. Robustness is enhanced through a histopathology-specific
augmentation pipeline, including elastic and stain-specific transformations,
and balanced sampling to mitigate class imbalance. A grouped 5-fold
cross-validation strategy ensures reliable evaluation. On the preliminary
leaderboard, our model achieved a balanced accuracy of 0.8961, ranking among
the top entries. These results highlight that broad domain exposure combined
with targeted augmentation strategies is key to building accurate and
generalizable mitotic figure classifiers.

</details>


### [12] [Solutions for Mitotic Figure Detection and Atypical Classification in MIDOG 2025](https://arxiv.org/abs/2509.02597)
*Shuting Xu,Runtong Liu,Zhixuan Chen,Junlin Hou,Hao Chen*

Main category: eess.IV

TL;DR: 本文提出了一种用于有丝分裂图像分析的两阶段检测-分类框架和集成分类方法，在MIDOG 2025挑战赛的两个任务中表现出色


<details>
  <summary>Details</summary>
Motivation: 深度学习在计算病理学有丝分裂图像分析中取得了显著进展，但需要解决有丝分裂检测和非典型有丝分裂分类的域泛化问题

Method: 对于有丝分裂检测任务采用两阶段框架：先定位候选有丝分裂图像，再用专用分类模块精炼预测；对于非典型有丝分裂分类任务采用集成策略，整合多个先进深度学习架构的预测

Result: 大量实验证明所提方法在两个任务中均有效

Conclusion: 提出的两阶段检测-分类框架和集成分类方法能够有效提升有丝分裂图像分析的准确性和鲁棒性

Abstract: Deep learning has driven significant advances in mitotic figure analysis
within computational pathology. In this paper, we present our approach to the
Mitosis Domain Generalization (MIDOG) 2025 Challenge, which consists of two
distinct tasks, i.e., mitotic figure detection and atypical mitosis
classification. For the mitotic figure detection task, we propose a two-stage
detection-classification framework that first localizes candidate mitotic
figures and subsequently refines the predictions using a dedicated
classification module. For the atypical mitosis classification task, we employ
an ensemble strategy that integrates predictions from multiple state-of-the-art
deep learning architectures to improve robustness and accuracy. Extensive
experiments demonstrate the effectiveness of our proposed methods across both
tasks.

</details>


### [13] [MIDOG 2025: Mitotic Figure Detection with Attention-Guided False Positive Correction](https://arxiv.org/abs/2509.02598)
*Andrew Broad,Jason Keighley,Lucy Godson,Alex Wright*

Main category: eess.IV

TL;DR: 通过在FCOS检测器基础上增添FAL-CNN分类器和融合网络，提出了一种降低偶然检测错误率的有细胞检测方法


<details>
  <summary>Details</summary>
Motivation: 减少FCOS物体检测器的偶然检测错误率，提高检测准确性和网络的普适性

Method: 在FCOS检测器基础上，增添FAL-CNN模型用于异常有细胞分类，通过融合网络生成检测框调整

Result: 在预测评估数据集上达到了F1分数0.655的有细胞检测结果

Conclusion: 该复合模型能够有效提高有细胞检测的准确性和可靠性

Abstract: We present a novel approach which extends the existing Fully Convolutional
One-Stage Object Detector (FCOS) for mitotic figure detection. Our composite
model adds a Feedback Attention Ladder CNN (FAL-CNN) model for classification
of normal versus abnormal mitotic figures, feeding into a fusion network that
is trained to generate adjustments to bounding boxes predicted by FCOS. Our
network aims to reduce the false positive rate of the FCOS object detector, to
improve the accuracy of object detection and enhance the generalisability of
the network. Our model achieved an F1 score of 0.655 for mitosis detection on
the preliminary evaluation dataset.

</details>


### [14] [RF-DETR for Robust Mitotic Figure Detection: A MIDOG 2025 Track 1 Approach](https://arxiv.org/abs/2509.02599)
*Piotr Giedziun,Jan Sołtysik,Mateusz Górczany,Norbert Ropiak,Marcin Przymus,Piotr Krajewski,Jarosław Kwiecień,Artur Bartczak,Izabela Wasiak,Mateusz Maniewski*

Main category: eess.IV

TL;DR: 本文提出了一种基于RF-DETR的单阶段检测方法，通过硬负样本挖掘技术在MIDOG 2025挑战赛中实现了跨域的有程分裂图检测，在预测测试集上获得0.789的F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决组织学图像中由于扫描仪、染色协议和组织类型差异导致的显著域假移问题，提高有程分裂图检测的稳健性和通用性。

Method: 使用RF-DETR（Roboflow Detection Transformer）梯形检测器，结合硬负样本挖掘技术，在MIDOG++数据集上进行训练。原计划采用两阶段方案（高回收率检测+分类精炼），但围于时间限制改为单阶段检测管线。

Result: 在预测测试集上获得F1分数0.789（回收率0.839，精确率0.746），证明了方法在未见域上具有良好的通用性。

Conclusion: 训练数据的平衡性和硬负样本挖掘技术对于解决有程分裂图检测中的域假移挑战具有重要意义，单阶段检测方案在时间紧张情况下仍能获得良好性能。

Abstract: Mitotic figure detection in histopathology images remains challenging due to
significant domain shifts across different scanners, staining protocols, and
tissue types. This paper presents our approach for the MIDOG 2025 challenge
Track 1, focusing on robust mitotic figure detection across diverse
histological contexts. While we initially planned a two-stage approach
combining high-recall detection with subsequent classification refinement, time
constraints led us to focus on optimizing a single-stage detection pipeline. We
employed RF-DETR (Roboflow Detection Transformer) with hard negative mining,
trained on MIDOG++ dataset. On the preliminary test set, our method achieved an
F1 score of 0.789 with a recall of 0.839 and precision of 0.746, demonstrating
effective generalization across unseen domains. The proposed solution offers
insights into the importance of training data balance and hard negative mining
for addressing domain shift challenges in mitotic figure detection.

</details>


### [15] [Team Westwood Solution for MIDOG 2025 Challenge](https://arxiv.org/abs/2509.02600)
*Tengyou Xu,Haochen Yang,Xiang 'Anthony' Chen,Hongyan Gu,Mohammad Haeri*

Main category: eess.IV

TL;DR: 团队Westwood在MIDOG 2025挑战赛中提出的有丝分裂检测和非典型有丝分裂分类解决方案，使用nnUNetV2进行初始候选检测，结合多个CNN模型和随机森林分类器进行集成预测


<details>
  <summary>Details</summary>
Motivation: 解决有丝分裂检测和非典型有丝分裂分类的领域泛化问题，提高病理图像分析的准确性和鲁棒性

Method: 有丝分裂检测：nnUNetV2进行初始候选筛查 + EfficientNet-b3/b5/V2-s三个CNN + 随机森林分类器集成；非典型有丝分裂分类：EfficientNet-b3/b5 + InceptionV3三个CNN + 随机森林分类器集成

Result: 在初步测试集上，有丝分裂检测F1得分0.7450，非典型有丝分裂分类平衡准确率0.8722

Conclusion: 提出的集成学习方法在MIDOG 2025挑战赛中表现出色，证明了多模型集成在医学图像分析任务中的有效性

Abstract: This abstract presents our solution (Team Westwood) for mitosis detection and
atypical mitosis classification in the MItosis DOmain Generalization (MIDOG)
2025 challenge. For mitosis detection, we trained an nnUNetV2 for initial
mitosis candidate screening with high sensitivity, followed by a random forest
classifier ensembling predictions of three convolutional neural networks
(CNNs): EfficientNet-b3, EfficientNet-b5, and EfficientNetV2-s. For the
atypical mitosis classification, we trained another random forest classifier
ensembling the predictions of three CNNs: EfficientNet-b3, EfficientNet-b5, and
InceptionV3. On the preliminary test set, our solution achieved an F1 score of
0.7450 for track 1 mitosis detection, and a balanced accuracy of 0.8722 for
track 2 atypical mitosis classification.

</details>


### [16] [Foundation Model-Driven Classification of Atypical Mitotic Figures with Domain-Aware Training Strategies](https://arxiv.org/abs/2509.02601)
*Piotr Giedziun,Jan Sołtysik,Mateusz Górczany,Norbert Ropiak,Marcin Przymus,Piotr Krajewski,Jarosław Kwiecień,Artur Bartczak,Izabela Wasiak,Mateusz Maniewski*

Main category: eess.IV

TL;DR: 基于H-optimus-0病理基础模型，采用LoRA微调和MixUp增强等方法解决正常与异常有丝分裂图像的二分类问题


<details>
  <summary>Details</summary>
Motivation: 解决MIDOG 2025挑战赛第二赛道中正常有丝分裂图像(NMFs)与异常有丝分裂图像(AMFs)的复杂二分类问题

Method: 使用H-optimus-0病理基础模型，结合LoRA低秩适应微调、MixUp数据增强、基于多专家共识的软标签、难负样本挖掘、自适应焦点损失、度量学习和域适应技术

Result: 在初步评估阶段取得了合理的性能表现

Conclusion: 该方法展示了基础模型在这一复杂分类任务中的应用前景和挑战

Abstract: We present a solution for the MIDOG 2025 Challenge Track~2, addressing binary
classification of normal mitotic figures (NMFs) versus atypical mitotic figures
(AMFs). The approach leverages pathology-specific foundation model H-optimus-0,
selected based on recent cross-domain generalization benchmarks and our
empirical testing, with Low-Rank Adaptation (LoRA) fine-tuning and MixUp
augmentation. Implementation includes soft labels based on multi-expert
consensus, hard negative mining, and adaptive focal loss, metric learning and
domain adaptation. The method demonstrates both the promise and challenges of
applying foundation models to this complex classification task, achieving
reasonable performance in the preliminary evaluation phase.

</details>


### [17] [Masked Autoencoder Pretraining and BiXLSTM ResNet Architecture for PET/CT Tumor Segmentation](https://arxiv.org/abs/2509.02602)
*Moona Mazher,Steven A Niederer,Abdul Qayyum*

Main category: eess.IV

TL;DR: 基于MAE自监督预训练和双向XLSTM结构的两阶段深度学习框架，通过PET/CT多模态融合实现了更准确的全身病变分割


<details>
  <summary>Details</summary>
Motivation: 解决全身PET/CT病变分割中手工流程劳动密集、观察者间变异性高的问题，以及现有自动化方法在模态特异性、时间点隔离和专家知识整合不足等限制

Method: 两阶段框架：第一阶段使用Masked Autoencoder(MAE)在无标注PET/CT和纵向CT扫描上进行自监督预训练；第二阶段使用双向XLSTM结构增强ResNet块和卷积解码器对预训练编码器进行微调

Result: 在AutoPET Task 1数据集上，自监督预训练显著提升了分割精度，Dice分数从0.543提升到0.582

Conclusion: 结合自监督学习与多模态融合的方法具有强大潜力，能够实现稳健且可推广的PET/CT病变分割

Abstract: The accurate segmentation of lesions in whole-body PET/CT imaging is
es-sential for tumor characterization, treatment planning, and response
assess-ment, yet current manual workflows are labor-intensive and prone to
inter-observer variability. Automated deep learning methods have shown promise
but often remain limited by modality specificity, isolated time points, or
in-sufficient integration of expert knowledge. To address these challenges, we
present a two-stage lesion segmentation framework developed for the fourth
AutoPET Challenge. In the first stage, a Masked Autoencoder (MAE) is em-ployed
for self-supervised pretraining on unlabeled PET/CT and longitudinal CT scans,
enabling the extraction of robust modality-specific representations without
manual annotations. In the second stage, the pretrained encoder is fine-tuned
with a bidirectional XLSTM architecture augmented with ResNet blocks and a
convolutional decoder. By jointly leveraging anatomical (CT) and functional
(PET) information as complementary input channels, the model achieves improved
temporal and spatial feature integration. Evalua-tion on the AutoPET Task 1
dataset demonstrates that self-supervised pre-training significantly enhances
segmentation accuracy, achieving a Dice score of 0.582 compared to 0.543
without pretraining. These findings high-light the potential of combining
self-supervised learning with multimodal fu-sion for robust and generalizable
PET/CT lesion segmentation. Code will be available at
https://github.com/RespectKnowledge/AutoPet_2025_BxLSTM_UNET_Segmentation

</details>


### [18] [Towards Digital Twins for Optimal Radioembolization](https://arxiv.org/abs/2509.02607)
*Nisanth Kumar Panneerselvam,Guneet Mummaneni,Emilie Roncali*

Main category: eess.IV

TL;DR: 这篇论文提出了一种基于计算流体力学和物理信息机器学习的动态数字双胎框架，用于优化干脾电射塞治疗的个人化计划。


<details>
  <summary>Details</summary>
Motivation: 干脾电射塞治疗面临复杂的肚动脉解剖结构、变化的血流和微球运输不确定性等挑战，需要一种能够最大化治疗效果并最小化健康组织损伤的个人化解决方案。

Method: 采用高保真度计算流体力学(CFD)和物理信息机器学习方法(PINNs、PI-GANs、PI-DMs等)相结合的方案。CFD进行微球运输计算，而AI模型通过将控制方程集成到神经网络训练中，实现网格免需的高效仿真。

Result: 该框架能够在保持物理保真度的同时大大提高计算效率，支持快速金石多种流动场景的采样，为实时决策提供支持。

Conclusion: CFD与物理信息AI方法的结合构成了动态数字双胎的基础，有望优化干脾电射塞治疗的个人化计划，最终改善临床结果。

Abstract: Radioembolization is a localized liver cancer treatment that delivers
radioactive microspheres (30 micron) to tumors via a catheter inserted in the
hepatic arterial tree. The goal is to maximize therapeutic efficacy while
minimizing damage to healthy liver tissue. However, optimization is challenging
due to complex hepatic artery anatomy, variable blood flow, and uncertainty in
microsphere transport. The creation of dynamic, patient-specific digital twins
may provide a transformative solution to these challenges. This work outlines a
framework for a liver radioembolization digital twin using high-fidelity
computational fluid dynamics (CFD) and/or recent physics-informed machine
learning approaches. The CFD approach involves microsphere transport
calculations in the hepatic arterial tree with individual patient data, which
enables personalized treatment planning. Although accurate, traditional CFD is
computationally expensive and limits clinical applicability.
  To accelerate simulations, physics-informed neural networks (PINNs) and their
generative extensions play an increasingly important role. PINNs integrate
governing equations, such as the Navier-Stokes equations, directly into the
neural network training process, enabling mesh-free, data-efficient
approximation of blood flow and microsphere transport. Physics-informed
generative adversarial networks (PI-GANs), diffusion models (PI-DMs), and
transformer-based architectures further enable uncertainty-aware, temporally
resolved predictions with reduced computational cost. These AI surrogates not
only maintain physical fidelity but also support rapid sampling of diverse flow
scenarios, facilitating real-time decision support.
  Together, CFD and physics-informed AI methods form the foundation of dynamic,
patient-specific digital twin to optimize radioembolization planning and
ultimately improve clinical outcomes.

</details>


### [19] [Is Synthetic Image Augmentation Useful for Imbalanced Classification Problems? Case-Study on the MIDOG2025 Atypical Cell Detection Competition](https://arxiv.org/abs/2509.02612)
*Leire Benito-Del-Valle,Pedro A. Moreno-Sánchez,Itziar Egusquiza,Itsaso Vitoria,Artzai Picón,Cristina López-Saratxaga,Adrian Galdran*

Main category: eess.IV

TL;DR: MIDOG 2025挑战赛新增非典型有丝分裂分类任务，研究比较了ImageNet预训练的ConvNeXt和病理学自监督ViT模型，两者在AUROC约95%表现优异，合成数据平衡效果有限。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学图像中正常与非典型有丝分裂细胞的分类问题，这是一个临床相关但高度不平衡的跨域挑战。

Method: 使用ConvNeXt-Small（ImageNet预训练）和Lunit ViT（病理学自监督预训练）两种骨干网络，通过五折交叉验证比较性能，并尝试合成数据平衡类别。

Result: 两种模型均达到约95%的平均AUROC，ConvNeXt峰值略高但Lunit更稳定。在隐藏测试集上ConvNeXt达到95.4% AUROC，合成平衡未带来一致改进。

Conclusion: ImageNet和领域预训练骨干网络都适用于非典型有丝分裂分类，领域预训练提供鲁棒性而ImageNet预训练能达到更高峰值，简单的合成平衡方法效益有限。

Abstract: The MIDOG 2025 challenge extends prior work on mitotic figure detection by
introducing a new Track 2 on atypical mitosis classification. This task aims to
distinguish normal from atypical mitotic figures in histopathology images, a
clinically relevant but highly imbalanced and cross-domain problem. We
investigated two complementary backbones: (i) ConvNeXt-Small, pretrained on
ImageNet, and (ii) a histopathology-specific ViT from Lunit trained via
self-supervision. To address the strong prevalence imbalance (9408 normal vs.
1741 atypical), we synthesized additional atypical examples to approximate
class balance and compared models trained with real-only vs. real+synthetic
data. Using five-fold cross-validation, both backbones reached strong
performance (mean AUROC approximately 95 percent), with ConvNeXt achieving
slightly higher peaks while Lunit exhibited greater fold-to-fold stability.
Synthetic balancing, however, did not lead to consistent improvements. On the
organizers' preliminary hidden test set, explicitly designed as an
out-of-distribution debug subset, ConvNeXt attained the highest AUROC (95.4
percent), whereas Lunit remained competitive on balanced accuracy. These
findings suggest that both ImageNet and domain-pretrained backbones are viable
for atypical mitosis classification, with domain-pretraining conferring
robustness and ImageNet pretraining reaching higher peaks, while naive
synthetic balancing has limited benefit. Full hidden test set results will be
reported upon challenge completion.

</details>


### [20] [A Two-Stage Strategy for Mitosis Detection Using Improved YOLO11x Proposals and ConvNeXt Classification](https://arxiv.org/abs/2509.02627)
*Jie Xiao,Mengye Lyu,Shaojun Liu*

Main category: eess.IV

TL;DR: 通过两步框架（YOLO11x收集分裂倒体候选 + ConvNeXt-Tiny分类器过滤）提高全片图谱分裂检测的F1分数，在复杂病理环境中减少假阻性和假阻性


<details>
  <summary>Details</summary>
Motivation: 全片图谱分裂检测遇到非肝肿、炎症、坏死区域等复杂环境导致假阻性和假阻性增多，影响F1分数

Method: 1. 改进YOLO11x（集成EMA注意力和LSConv）使用低信心阈值生成大量分裂倒体候选，保证检出率
2. ConvNeXt-Tiny分类器过滤假阻性，提高精确度

Result: 在MIDOG++、MITOS_WSI_CCMCT和MITOS_WSI_CMC数据集上达到0.882的F1分数，比单步YOLO11x基线提高0.035，精确度从0.762提升到0.839，检出率保持相似

Conclusion: 两步框架通过先收集后过滤的策略，有效平衡了检测的检出率和精确度，在复杂病理环境中显著提升了分裂倒体检测性能

Abstract: MIDOG 2025 Track 1 requires mitosis detection in whole-slide images (WSIs)
containing non-tumor, inflamed, and necrotic regions. Due to the complicated
and heterogeneous context, as well as possible artifacts, there are often false
positives and false negatives, thus degrading the detection F1-score. To
address this problem, we propose a two-stage framework. Firstly, an improved
YOLO11x, integrated with EMA attention and LSConv, is employed to generate
mitosis candidates. We use a low confidence threshold to generate as many
proposals as possible, ensuring the detection recall. Then, a ConvNeXt-Tiny
classifier is employed to filter out the false positives, ensuring the
detection precision. Consequently, the proposed two-stage framework can
generate a high detection F1-score. Evaluated on a fused dataset comprising
MIDOG++, MITOS_WSI_CCMCT, and MITOS_WSI_CMC, our framework achieves an F1-score
of 0.882, which is 0.035 higher than the single-stage YOLO11x baseline. This
performance gain is produced by a significant precision improvement, from 0.762
to 0.839, and a comparable recall. The code is available at
https://github.com/xxiao0304/MIDOG-2025-Track-1-of-SZTU.

</details>


### [21] [Challenges and Lessons from MIDOG 2025: A Two-Stage Approach to Domain-Robust Mitotic Figure Detection](https://arxiv.org/abs/2509.02630)
*Euiseop Song,Jaeyoung Park,Jaewoo Park*

Main category: eess.IV

TL;DR: 本文介绍了参与MIDOG 2025挑战赛的两阶段有丝分裂检测方法，使用Faster R-CNN进行候选检测和集成分类器进行假阳性抑制，获得了高召回率但低精度的结果


<details>
  <summary>Details</summary>
Motivation: 解决计算病理学中有丝分裂图形检测面临的领域变异性和形态复杂性挑战，开发跨不同组织领域的鲁棒检测方法

Method: 两阶段管道：Faster R-CNN用于候选检测，DenseNet-121、EfficientNet-v2、InceptionResNet-v2三种分类器集成进行假阳性减少

Result: 最佳提交获得F1-score 0.2237（召回率0.9528，精确率0.1267），高召回率显示有效检测但极低精确率揭示跨领域区分真伪有丝分裂的根本挑战

Conclusion: 后续优化尝试适得其反，突显了组织病理学领域泛化的复杂性，强调了有效假阳性抑制策略的重要性

Abstract: Mitotic figure detection remains a challenging task in computational
pathology due to domain variability and morphological complexity. This paper
describes our participation in the MIDOG 2025 challenge, focusing on robust
mitotic figure detection across diverse tissue domains. We developed a
two-stage pipeline combining Faster R-CNN for candidate detection with an
ensemble of three classifiers (DenseNet-121, EfficientNet-v2,
InceptionResNet-v2) for false positive reduction. Our best submission achieved
F1-score 0.2237 (Recall: 0.9528, Precision: 0.1267) using a Faster R-CNN
trained solely on MIDOG++ dataset. While our high recall demonstrates effective
mitotic figure detection, the critically low precision (12.67%) reveals
fundamental challenges in distinguishing true mitoses from morphologically
similar imposters across diverse domains. Analysis of six submission variants
showed that subsequent optimization attempts were counterproductive,
highlighting the omplexity of domain generalization in histopathology. This
work provides valuable insights into the practical challenges of developing
robust mitotic figure detection algorithms and emphasizes the importance of
effective false positive suppression strategies.

</details>


### [22] [A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection](https://arxiv.org/abs/2509.02637)
*Yasemin Topuz,M. Taha Gökcan,Serdar Yıldız,Songül Varlı*

Main category: eess.IV

TL;DR: SDF-YOLO是一个轻量级且具有领域鲁棒性的检测框架，专门用于小且罕见的目标如核分裂象检测，在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 核分裂象检测是计算病理学的关键任务，但扫描仪、组织类型和染色方案的差异导致的领域变异性对自动化检测方法的鲁棒性构成重大挑战。

Method: 基于YOLOv11构建，采用任务特定修改：单检测头与核分裂象尺度对齐、坐标注意力增强位置敏感性、改进的跨通道特征混合。

Result: 在MIDOG2025挑战赛测试集上获得AP 0.799，精确率0.758，召回率0.775，F1分数0.766，FROC-AUC 5.793，表现出竞争性准确性和计算效率。

Conclusion: SDF-YOLO提供了一个可靠且高效的框架，能够在不同领域中实现鲁棒的核分裂象检测。

Abstract: Mitotic figure detection is a crucial task in computational pathology, as
mitotic activity serves as a strong prognostic marker for tumor aggressiveness.
However, domain variability that arises from differences in scanners, tissue
types, and staining protocols poses a major challenge to the robustness of
automated detection methods. In this study, we introduce SDF-YOLO (Single
Detect Focused YOLO), a lightweight yet domain-robust detection framework
designed specifically for small, rare targets such as mitotic figures. The
model builds on YOLOv11 with task-specific modifications, including a single
detection head aligned with mitotic figure scale, coordinate attention to
enhance positional sensitivity, and improved cross-channel feature mixing.
Experiments were conducted on three datasets that span human and canine tumors:
MIDOG ++, canine cutaneous mast cell tumor (CCMCT), and canine mammary
carcinoma (CMC). When submitted to the preliminary test set for the MIDOG2025
challenge, SDF-YOLO achieved an average precision (AP) of 0.799, with a
precision of 0.758, a recall of 0.775, an F1 score of 0.766, and an FROC-AUC of
5.793, demonstrating both competitive accuracy and computational efficiency.
These results indicate that SDF-YOLO provides a reliable and efficient
framework for robust mitotic figure detection across diverse domains.

</details>


### [23] [Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge](https://arxiv.org/abs/2509.02640)
*Biwen Meng,Xi Long,Jingxin Liu*

Main category: eess.IV

TL;DR: 通过视觉提示调整(VPT)咄染色标准化测试时增强(TTA)等技术，基于UNI2-h病理基础模型的方法在MIDOG2025挑战赛中实现了高准确率的非典型有丝切裂检测


<details>
  <summary>Details</summary>
Motivation: 非典型有丝切裂(AMFs)作为异常细胞分裂的临床指标具有重要价值，但因形态媒糊性咄扫描仪变异性导致检测困难

Method: 研究了三种UNI2-h病理基础模型的适配方案：LoRA基准线、视觉提示调整(VPT)、以及VPT结合Vahadane咄Macenko染色标准化的测试时增强(TTA)

Result: 最终提交在预测排行榜上获得0.8837的平衡准确率咄0.9513的ROC-AUC，排名前10团队

Conclusion: 提示基适配结合染色标准化TTA提供了一种有效的策略，可在多样化成像条件下实现高性能的非典型有丝切裂分类

Abstract: Atypical mitotic figures (AMFs) are clinically relevant indicators of
abnormal cell division, yet their reliable detection remains challenging due to
morphological ambiguity and scanner variability. In this work, we investigated
three variants of adapting the pathology foundation model UNI2-h for the
MIDOG2025 Track 2 challenge. Starting from a LoRA-based baseline, we found that
visual prompt tuning (VPT) substantially improved generalization, and that
further integrating test-time augmentation (TTA) with Vahadane and Macenko
stain normalization provided the best robustness. Our final submission achieved
a balanced accuracy of 0.8837 and an ROC-AUC of 0.9513 on the preliminary
leaderboard, ranking within the top 10 teams. These results demonstrate that
prompt-based adaptation combined with stain-normalization TTA offers an
effective strategy for atypical mitosis classification under diverse imaging
conditions.

</details>


### [24] [Ensemble YOLO Framework for Multi-Domain Mitotic Figure Detection in Histopathology Images](https://arxiv.org/abs/2509.02957)
*Navya Sri Kelam,Akash Parekh,Saikiran Bonthu,Nitin Singhal*

Main category: eess.IV

TL;DR: YOLOv5和YOLOv8在病理图像有丝分裂检测中的性能比较，通过集成策略提升检测效果


<details>
  <summary>Details</summary>
Motivation: 解决全玻片病理图像中有丝分裂细胞检测的挑战，包括稀缺性、形态异质性和染色变异问题，利用MIDOG竞赛基准推动通用深度学习模型发展

Method: 使用YOLOv5和YOLOv8两种单阶段检测器，在MIDOG++、CMC和CCMCT数据集上训练，采用染色不变性颜色扰动和纹理保持增强技术提升鲁棒性，最后集成两种模型

Result: 内部验证中YOLOv5精度更高，YOLOv8召回率更好，集成模型在不显著降低精度的情况下提高了灵敏度

Conclusion: 基于现代目标检测器的集成策略能有效提升数字病理学中有丝分裂自动检测的性能

Abstract: Accurate detection of mitotic figures in whole slide histopathological images
remains a challenging task due to their scarcity, morphological heterogeneity,
and the variability introduced by tissue preparation and staining protocols.
The MIDOG competition series provides standardized benchmarks for evaluating
detection approaches across diverse domains, thus motivating the development of
generalizable deep learning models. In this work, we investigate the
performance of two modern one-stage detectors, YOLOv5 and YOLOv8, trained on
MIDOG++, CMC, and CCMCT datasets. To enhance robustness, training incorporated
stain-invariant color perturbations and texture preserving augmentations. In
internal validation, YOLOv5 achieved superior precision, while YOLOv8 provided
improved recall, reflecting architectural trade-offs between anchor-based and
anchor-free detection. To capitalize on these complementary strengths, we
employed an ensemble of the two models, which improved sensitivity without a
major reduction in precision. These findings highlight the effectiveness of
ensemble strategies built upon contemporary object detectors to advance
automated mitosis detection in digital pathology.

</details>


### [25] [Deep Self-knowledge Distillation: A hierarchical supervised learning for coronary artery segmentation](https://arxiv.org/abs/2509.03173)
*Mingfeng Lin*

Main category: eess.IV

TL;DR: 本文提出深度自我知识萌荘方法，通过层次输出监督和双重损失函数，显著提升了冠状动脉分割的性能和模型演进能力。


<details>
  <summary>Details</summary>
Motivation: 现有的冠状动脉分割方法在性能和普适性方面存在不足，而当前的知识萌荘方法没有充分利用模型的层次知识，导致信息浪费和模型性能提升不足。

Method: 提出深度自我知识萌荘方法，结合深度分布损失和像素级自我知识萌荘损失，通过层次学习策略优化学生模型的分割性能。方法结合了松弛约束的概率分布向量和严格约束的像素级监督。

Result: 在XCAD和DCA1数据集上的实验表明，该方法在dice系数、准确率、敏感性和IoU指标上都超过了其他比较模型。

Conclusion: 深度自我知识萌荘方法通过层次知识利用和双重监督机制，有效提升了冠状动脉分割的性能和模型演进能力，为医学图像分割任务提供了新的解决方案。

Abstract: Coronary artery disease is a leading cause of mortality, underscoring the
critical importance of precise diagnosis through X-ray angiography. Manual
coronary artery segmentation from these images is time-consuming and
inefficient, prompting the development of automated models. However, existing
methods, whether rule-based or deep learning models, struggle with issues like
poor performance and limited generalizability. Moreover, current knowledge
distillation methods applied in this field have not fully exploited the
hierarchical knowledge of the model, leading to certain information waste and
insufficient enhancement of the model's performance capabilities for
segmentation tasks. To address these issues, this paper introduces Deep
Self-knowledge Distillation, a novel approach for coronary artery segmentation
that leverages hierarchical outputs for supervision. By combining Deep
Distribution Loss and Pixel-wise Self-knowledge Distillation Loss, our method
enhances the student model's segmentation performance through a hierarchical
learning strategy, effectively transferring knowledge from the teacher model.
Our method combines a loosely constrained probabilistic distribution vector
with tightly constrained pixel-wise supervision, providing dual regularization
for the segmentation model while also enhancing its generalization and
robustness. Extensive experiments on XCAD and DCA1 datasets demonstrate that
our approach outperforms the dice coefficient, accuracy, sensitivity and IoU
compared to other models in comparative evaluations.

</details>


### [26] [Prompt-Guided Patch UNet-VAE with Adversarial Supervision for Adrenal Gland Segmentation in Computed Tomography Medical Images](https://arxiv.org/abs/2509.03188)
*Hania Ghouse,Muzammil Behzad*

Main category: eess.IV

TL;DR: 这篇论文提出了一种统一框架，通过结合变分重建、监督分割和对抗性补丁反馈来解决CT形态小而不规则腹部器官的分割挑战。


<details>
  <summary>Details</summary>
Motivation: 解决腹部小器官分割中的类不平衡、空间上下文信息较少和标注数据有限等问题。

Method: 使用VAE-UNet基础架来联合重建输入补丁和生成分割掩码，结合了变分重建、监督分割、对抗性补丁反馈、VGG感知重建损失和PatchGAN辨别器。

Result: 在BTCV数据集上进行的完整实验显示，该方法提高了分割准确性，尤其是在边界敏感区域，同时保持了强大的重建质量。

Conclusion: 混合生成-辨别训练方案对小器官分割有效，为在数据稀缺情况下平衡真实性、多样性和解剖一致性提供了新的见解。

Abstract: Segmentation of small and irregularly shaped abdominal organs, such as the
adrenal glands in CT imaging, remains a persistent challenge due to severe
class imbalance, poor spatial context, and limited annotated data. In this
work, we propose a unified framework that combines variational reconstruction,
supervised segmentation, and adversarial patch-based feedback to address these
limitations in a principled and scalable manner. Our architecture is built upon
a VAE-UNet backbone that jointly reconstructs input patches and generates
voxel-level segmentation masks, allowing the model to learn disentangled
representations of anatomical structure and appearance. We introduce a
patch-based training pipeline that selectively injects synthetic patches
generated from the learned latent space, and systematically study the effects
of varying synthetic-to-real patch ratios during training. To further enhance
output fidelity, the framework incorporates perceptual reconstruction loss
using VGG features, as well as a PatchGAN-style discriminator for adversarial
supervision over spatial realism. Comprehensive experiments on the BTCV dataset
demonstrate that our approach improves segmentation accuracy, particularly in
boundary-sensitive regions, while maintaining strong reconstruction quality.
Our findings highlight the effectiveness of hybrid generative-discriminative
training regimes for small-organ segmentation and provide new insights into
balancing realism, diversity, and anatomical consistency in data-scarce
scenarios.

</details>


### [27] [Generalist versus Specialist Vision Foundation Models for Ocular Disease and Oculomics](https://arxiv.org/abs/2509.03421)
*Yukun Zhou,Paul Nderitu,Jocelyn Hui Lin Goh,Justin Engelmann,Siegfried K. Wagner,Anran Ran,Hongyang Jiang,Lie Ju,Ke Zou,Sahana Srinivasan,Hyunmin Kim,Takahiro Ninomiya,Zheyuan Wang,Gabriel Dawei Yang,Eden Ruffell,Dominic Williamson,Rui Santos,Gabor Mark Somfai,Carol Y. Cheung,Tien Yin Wong,Daniel C. Alexander,Yih Chung Tham,Pearse A. Keane*

Main category: eess.IV

TL;DR: 通过系统性评估发现，尺寸更大的通用基础模型在视网膜图像应用中显示强大适应性，但专业的RETFound-DINOv2模型仍在眼部疾病检测和眼科学任务中表现更优，具有更强的普适性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 研究通用基础模型如DINOv2和DINOv3的出现引发了问题：领域特定预训练是否仍必需？如果是，专业模型与通用模型之间的差距有多大？

Method: 系统性评估DINOv2和DINOv3在视网膜图像应用中的适应性，与专业模型RETFound-MAE和RETFound-DINOv2进行比较，使用精调和线性探针两种适应策略，评估眼部疾病检测和系统性疾病预测任务。

Result: 尺寸更大的通用模型在多样任务中显示强大适应性，但RETFound-DINOv2在眼部疾病检测和眼科学任务中持续超过通用基础模型，表现出更强的普适性和数据效率。

Conclusion: 专业视网膜基础模型仍是临床应用的最佳选择，但与通用基础模型的差距正在缩小，持续的数据和模型扩大可以带来领域相关收益，使得通用模型成为未来医学基础模型的强大基础。

Abstract: Medical foundation models, pre-trained with large-scale clinical data,
demonstrate strong performance in diverse clinically relevant applications.
RETFound, trained on nearly one million retinal images, exemplifies this
approach in applications with retinal images. However, the emergence of
increasingly powerful and multifold larger generalist foundation models such as
DINOv2 and DINOv3 raises the question of whether domain-specific pre-training
remains essential, and if so, what gap persists. To investigate this, we
systematically evaluated the adaptability of DINOv2 and DINOv3 in retinal image
applications, compared to two specialist RETFound models, RETFound-MAE and
RETFound-DINOv2. We assessed performance on ocular disease detection and
systemic disease prediction using two adaptation strategies: fine-tuning and
linear probing. Data efficiency and adaptation efficiency were further analysed
to characterise trade-offs between predictive performance and computational
cost. Our results show that although scaling generalist models yields strong
adaptability across diverse tasks, RETFound-DINOv2 consistently outperforms
these generalist foundation models in ocular-disease detection and oculomics
tasks, demonstrating stronger generalisability and data efficiency. These
findings suggest that specialist retinal foundation models remain the most
effective choice for clinical applications, while the narrowing gap with
generalist foundation models suggests that continued data and model scaling can
deliver domain-relevant gains and position them as strong foundations for
future medical foundation models.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [28] [EEG-MSAF: An Interpretable Microstate Framework uncovers Default-Mode Decoherence in Early Neurodegeneration](https://arxiv.org/abs/2509.02568)
*Mohammad Mehedi Hasan,Pedro G. Lind,Hernando Ombao,Anis Yazidi,Rabindra Khadka*

Main category: eess.SP

TL;DR: EEG-MSAF是一个端到端的EEG微状态分析框架，通过机器学习分类和SHAP特征解释，在痴呆症早期诊断中达到89-95%的准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 痴呆症是全球性健康挑战，需要早期准确诊断。传统EEG方法难以捕捉脑电活动的瞬时复杂性，因此需要开发新的分析框架来识别痴呆相关生物标志物。

Method: EEG-MSAF包含三个阶段：1)自动微状态特征提取；2)机器学习分类；3)SHAP特征排序识别关键生物标志物。使用SVM等分类器在两个EEG数据集上进行评估。

Result: 在CAUEEG数据集上达到89%±0.01准确率，比CEEDNET基线提升19.3%；在Thessaloniki数据集上达到95%±0.01准确率，与EEGConvNeXt相当。SHAP分析识别出微状态C和F作为关键生物标志物。

Conclusion: EEG-MSAF结合了准确性、泛化性和可解释性，推进了基于EEG的痴呆症诊断，并揭示了跨认知谱系的脑动力学特征，微状态F作为新的默认模式模式是MCI和DEM的早期关键生物标志物。

Abstract: Dementia (DEM) is a growing global health challenge, underscoring the need
for early and accurate diagnosis. Electroencephalography (EEG) provides a
non-invasive window into brain activity, but conventional methods struggle to
capture its transient complexity. We present the \textbf{EEG Microstate
Analysis Framework (EEG-MSAF)}, an end-to-end pipeline that leverages EEG
microstates discrete, quasi-stable topographies to identify DEM-related
biomarkers and distinguish DEM, mild cognitive impairment (MCI), and normal
cognition (NC). EEG-MSAF comprises three stages: (1) automated microstate
feature extraction, (2) classification with machine learning (ML), and (3)
feature ranking using Shapley Additive Explanations (SHAP) to highlight key
biomarkers. We evaluate on two EEG datasets: the public Chung-Ang University
EEG (CAUEEG) dataset and a clinical cohort from Thessaloniki Hospital. Our
framework demonstrates strong performance and generalizability. On CAUEEG,
EEG-MSAF-SVM achieves \textbf{89\% $\pm$ 0.01 accuracy}, surpassing the deep
learning baseline CEEDNET by \textbf{19.3\%}. On the Thessaloniki dataset, it
reaches \textbf{95\% $\pm$ 0.01 accuracy}, comparable to EEGConvNeXt. SHAP
analysis identifies mean correlation and occurrence as the most informative
metrics: disruption of microstate C (salience/attention network) dominates DEM
prediction, while microstate F, a novel default-mode pattern, emerges as a key
early biomarker for both MCI and DEM. By combining accuracy, generalizability,
and interpretability, EEG-MSAF advances EEG-based dementia diagnosis and sheds
light on brain dynamics across the cognitive spectrum.

</details>


### [29] [Recall Gabor Communication Theory and Joint Time-Frequency Analysis](https://arxiv.org/abs/2509.02724)
*Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 本文回顾Gabor通信理论、Gabor变换和展开，及其与联合时频分析的联系


<details>
  <summary>Details</summary>
Motivation: 重新审视Gabor的通信理论基础理论，探讨其时频分析方法在现代信号处理中的应用价值

Method: 采用理论回顾和分析的方法，系统梳理Gabor通信理论、Gabor变换和展开的数学框架

Result: 建立了Gabor理论与联合时频分析之间的明确联系，为现代时频信号处理提供了理论基础

Conclusion: Gabor的理论框架为时频分析奠定了重要基础，其变换和展开方法在联合时频分析中具有持续的应用价值

Abstract: In this article, we first briefly recall Gabor's communication theory and
then Gabor transform and expansion, and also its connection with joint time
frequency analysis.

</details>


### [30] [minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels](https://arxiv.org/abs/2509.02797)
*Sagnik Bhattacharya,Abhiram Rao Gorle,John M. Cioffi*

Main category: eess.SP

TL;DR: minPIC框架：首个实现高斯干扰信道SIC可达速率区域帕累托边界的算法，通过双变量引导排序和凸优化解决6G无蜂窝网络中功率、子载波和解码顺序的联合优化问题


<details>
  <summary>Details</summary>
Motivation: 6G无蜂窝网络需要处理空间嵌套的多址接入和广播信道，现有OMA、NOMA和RSMA方案依赖固定启发式方法进行干扰管理，导致速率次优、功率效率低下和可扩展性问题

Method: 提出minPIC框架，引入双变量引导排序准则识别全局最优SIC顺序，然后通过带有辅助对数行列式约束的凸优化进行求解，采用二分搜索高效实现

Result: minPIC能够实现高斯干扰信道SIC可达速率区域的帕累托边界，有望满足沉浸式XR等6G应用的高速率、低功耗要求

Conclusion: minPIC是首个算法实现高斯干扰信道SIC可达速率区域帕累托边界的方法，为无蜂窝网络的可扩展干扰管理开辟了新途径

Abstract: 6G envisions massive cell-free networks with spatially nested multiple access
(MAC) and broadcast (BC) channels without centralized coordination. This makes
optimal resource allocation across power, subcarriers, and decoding orders
crucial for interference channels (ICs), where neither transmitters nor
receivers can cooperate. Current orthogonal multiple access (OMA) methods, as
well as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed
heuristics for interference management, leading to suboptimal rates, power
inefficiency, and scalability issues. This paper proposes a novel minPIC
framework for optimal power, subcarrier, and decoding order allocation in
general multi-user ICs. Unlike existing methods, minPIC eliminates heuristic
SIC order assumptions. Despite the convexity of the IC capacity region, fixing
an SIC order induces non-convexity in resource allocation, traditionally
requiring heuristic approximations. We instead introduce a dual-variable-guided
sorting criterion to identify globally optimal SIC orders, followed by convex
optimization with auxiliary log-det constraints, efficiently solved via binary
search. We also demonstrate that minPIC could potentially meet the stringent
high-rate, low-power targets of immersive XR and other 6G applications. To the
best of our knowledge, minPIC is the first algorithmic realisation of the
Pareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the
door to scalable interference management in cell-free networks.

</details>


### [31] [Protecting Legacy Wireless Systems Against Interference: Precoding and Codebook Approaches Using Massive MIMO and Region Constraints](https://arxiv.org/abs/2509.02819)
*Sameer Mathad,Taejoon Kim,David J. Love*

Main category: eess.SP

TL;DR: 这篇论文提出了一种基于通信理论的方案，通过在大规模MIMO系统中加入区域约束来保护传统用户免受干扰，而不是采用地理排除区方案。


<details>
  <summary>Details</summary>
Motivation: 随着高速无线通信需求的增长，需要利用传统系统段段的邻近频段，但这会对关键基础设施网络中的传统用户造成干扰。现有的地理排除区方案存在限制，需要更好的保护方案。

Method: 在大规模MIMO系统设计中添加接收功率约束（区域约束），对单用户和多用户系统进行容量分析和总速率分析，提出了一种预编码设计方法。

Result: 该方法能够在利用新频段资源的同时，有效保护传统用户免受干扰影响。

Conclusion: 通过通信理论基础的区域约束方案，可以更有效地解决新旧系统共存时的干扰问题，为高速无线通信的发展提供了可行的技术路径。

Abstract: The ever-increasing demand for high-speed wireless communication has
generated significant interest in utilizing frequency bands that are adjacent
to those occupied by legacy wireless systems. Since the legacy wireless systems
were designed based on often decades-old assumptions about wireless
interference, utilizing these new bands will result in interference with the
existing legacy users. Many of these legacy wireless devices are used by
critical infrastructure networks upon which society depends. There is an urgent
need to develop schemes that can protect legacy users from such interference.
For many applications, legacy users are located within
geographically-constrained regions. Several studies have proposed mitigating
interference through the implementation of exclusion zones near these
geographically-constrained regions. In contrast to solutions based on
geographic exclusion zones, this paper presents a communication theory-based
solution. By leveraging knowledge of these geographically-constrained regions,
we aim to reduce the interference impact on legacy users. We achieve this by
incorporating received power constraints, termed as region constraints, in our
massive multiple-input multiple-output (MIMO) system design. We perform a
capacity analysis of single-user massive MIMO and a sum-rate analysis of the
multi-user massive MIMO system with transmit power and region constraints. We
present a precoding design method that allows for the utilization of new
frequency bands while protecting legacy users.

</details>


### [32] [Spatially Adaptive SWIPT with Pinching Antenna under Probabilistic LoS Blockage](https://arxiv.org/abs/2509.03038)
*Ruihong Jiang,Ruichen Zhang,Yanqing Xu,Huimin Hu,Yang Lu,Dusit Niyato*

Main category: eess.SP

TL;DR: 这篇论文研究了在概率性视线阻塞环境下，使用可重配制拉抓天线的力量分割垂直SWIPT系统，通过关联优化天线位置和力量分割比来最大化平均信噪比。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中实现稳健的同时无线信息与能量传输，应对概率性视线阻塞带来的挑战，通过机械可重配制性提升系统的续航能力。

Method: 构建使用可重配制拉抓天线的PS-SWIPT系统模型，形成关于天线位置和力量分割比的联合优化问题，并求解出闭形最优解。

Result: 能量收集要求对最优天线位置及其可行域产生确定性影响，需将天线部署在近用户处以最大化平均通道增益；空间适配与动态力量分割结合可在概率性LoS阻塞下实现稳健的SWIPT性能。

Conclusion: 机械可重配制性主要通过确保动态环境中的能量可行性来提升系统的续航能力，为应对概率性视线阻塞提供了有效解决方案。

Abstract: This paper considers a power-splitting (PS)-based simultaneous wireless
information and power transfer (SWIPT) system employing a reconfigurable
pinching antenna (PA) under probabilistic line-of-sight (LoS) blockage. We
formulate a joint optimization of the PA position and the PS ratio to maximize
the average signal-to-noise ratio (SNR) at a user, subject to its average
energy harvesting (EH) and PA placement limits. We derive a closed-form optimal
solution. Results demonstrate that the EH requirement has a deterministic
impact on the optimal PA position as well as its feasible region, requiring
deployment of the PA as close to the user as possible to maximize average
channel gain. This spatial adaptation, combined with dynamic PS, enables robust
SWIPT performance in the presence of probabilistic LoS blockage, revealing that
mechanical reconfigurability primarily enhances sustainability by ensuring
energy feasibility in dynamic environments.

</details>


### [33] [S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG](https://arxiv.org/abs/2509.03066)
*Huaicheng Zhang,Ruoxin Wang,Chenlian Zhou,Jiguang Shi,Yue Ge,Zhoutong Li,Sheng Chang,Hao Wang,Jin He,Qijun Huang*

Main category: eess.SP

TL;DR: S2M2ECG是一个基于状态空间模型(SSM)的心电图分析架构，采用三级融合机制处理多导联ECG信号，在性能、计算复杂度和特征融合之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 多导联心电图信号分析面临性能、计算复杂度和多源特征融合的平衡挑战，传统深度学习方法难以同时满足这些需求。状态空间模型(SSM)的高效计算特性和线性复杂度使其特别适合ECG这类低维数据。

Method: 提出S2M2ECG架构，包含三级融合机制：1)时空双向SSM与分段标记化的低层信号融合；2)导联内双向扫描的时间信息融合；3)跨导联特征交互的空间信息融合。采用多分支设计和导联融合模块，实现各导联独立分析的同时确保无缝集成。

Result: S2M2ECG在节律、形态和临床场景中均表现出优越性能，其轻量级架构参数数量几乎是最少的，非常适合高效推理和便捷部署。

Conclusion: S2M2ECG在性能、计算复杂度和ECG特异性特征之间取得了优异平衡，为心血管疾病诊断中的高性能轻量级计算提供了有前景的替代方案。

Abstract: As one of the most effective methods for cardiovascular disease (CVD)
diagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic
multi-sensor information fusion challenge that has been continuously researched
in deep learning domains. Despite the numerous algorithms proposed with
different DL architectures, maintaining a balance among performance,
computational complexity, and multi-source ECG feature fusion remains
challenging. Recently, state space models (SSMs), particularly Mamba, have
demonstrated remarkable effectiveness across various fields. Their inherent
design for high-efficiency computation and linear complexity makes them
particularly suitable for low-dimensional data like ECGs. This work proposes
S2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1)
Spatio-temporal bi-directional SSMs with segment tokenization for low-level
signal fusion, (2) Intra-lead temporal information fusion with bi-directional
scanning to enhance recognition accuracy in both forward and backward
directions, (3) Cross-lead feature interaction modules for spatial information
fusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in
ECG signals, a multi-branch design and lead fusion modules are incorporated,
enabling individual analysis of each lead while ensuring seamless integration
with others. Experimental results reveal that S2M2ECG achieves superior
performance in the rhythmic, morphological, and clinical scenarios. Moreover,
its lightweight architecture ensures it has nearly the fewest parameters among
existing models, making it highly suitable for efficient inference and
convenient deployment. Collectively, S2M2ECG offers a promising alternative
that strikes an excellent balance among performance, computational complexity,
and ECG-specific characteristics, paving the way for high-performance,
lightweight computations in CVD diagnosis.

</details>


### [34] [Credible Uncertainty Quantification under Noise and System Model Mismatch](https://arxiv.org/abs/2509.03311)
*Penggao Yan,Li-Ta Hsu*

Main category: eess.SP

TL;DR: 提出一个统一的多指标评估框架来评估状态估计器的可信度，结合传统指标和适当评分规则，能够高精度诊断模型缺陷


<details>
  <summary>Details</summary>
Motivation: 状态估计器提供的自评估不确定性指标（如协方差矩阵）可能由于噪声或系统模型不匹配等建模违规而具有误导性，需要可靠的可信度评估方法

Method: 构建紧凑的可信度组合，结合归一化估计误差平方(NEES)、不可信指数(NCI)等传统指标与负对数似然(NLL)和能量评分(ES)等适当评分规则，提出基于能量距离的位置检验来检测系统模型误设，利用NLL和ES的不对称敏感性区分乐观协方差缩放和系统偏差

Result: 在六个不同可信度场景的蒙特卡洛模拟中，该方法实现了高分类准确率(80-100%)，显著优于单一指标基线方法

Conclusion: 该框架提供了一个实用工具，能够将可信度指标的模式转化为对模型缺陷的可操作诊断

Abstract: State estimators often provide self-assessed uncertainty metrics, such as
covariance matrices, whose reliability is critical for downstream tasks.
However, these self-assessments can be misleading due to underlying modeling
violations like noise or system model mismatch. This letter addresses the
problem of estimator credibility by introducing a unified, multi-metric
evaluation framework. We construct a compact credibility portfolio that
synergistically combines traditional metrics like the Normalized Estimation
Error Squared (NEES) and the Noncredibility Index (NCI) with proper scoring
rules, namely the Negative Log-Likelihood (NLL) and the Energy Score (ES). Our
key contributions are a novel energy distance-based location test to robustly
detect system model misspecification and a method that leverages the asymmetric
sensitivities of NLL and ES to distinguish optimism covariance scaling from
system bias. Monte Carlo simulations across six distinct credibility scenarios
demonstrate that our proposed method achieves high classification accuracy
(80-100%), drastically outperforming single-metric baselines which consistently
fail to provide a complete and correct diagnosis. This framework provides a
practical tool for turning patterns of credibility indicators into actionable
diagnoses of model deficiencies.

</details>


### [35] [YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform](https://arxiv.org/abs/2509.03070)
*Po-Heng Chou,Wei-Lung Mao,Ru-Ping Lin*

Main category: eess.SP

TL;DR: 基于YOLO的时频谱图轴承故障诊断框架，通过连续小波变换将振动信号转换为时频谱图，利用YOLOv9/v10/v11模型进行故障分类，在多个数据集上实现了高精度和可视化故障位置。


<details>
  <summary>Details</summary>
Motivation: 解决旋转机械轴承故障诊断中的转捡故障特征捕捉困难和模型通用性问题，提供可视化故障位置的实用解决方案。

Method: 使用Morlet小波将一维振动信号转换为时频谱图，然后采用YOLOv9、v10、v11模型进行故障分类检测。

Result: 在CWRU、PU、IMS三个数据集上达到高精度：YOLOv11分别获得99.4%、97.8%、99.5%的mAP分数，显著超越基准MCNN-LSTM模型。

Conclusion: CWT-YOLO流水线为旋转机械状态监控提供了高精度、高通用性和可视化故障位置的实用解决方案。

Abstract: This letter proposes a YOLO-based framework for spatial bearing fault
diagnosis using time-frequency spectrograms derived from continuous wavelet
transform (CWT). One-dimensional vibration signals are first transformed into
time-frequency spectrograms using Morlet wavelets to capture transient fault
signatures. These spectrograms are then processed by YOLOv9, v10, and v11
models to classify fault types. Evaluated on three benchmark datasets,
including Case Western Reserve University (CWRU), Paderborn University (PU),
and Intelligent Maintenance System (IMS), the proposed CWT--YOLO pipeline
achieves significantly higher accuracy and generalizability than the baseline
MCNN--LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%
(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism
enables direct visualization of fault locations in spectrograms, offering a
practical solution for condition monitoring in rotating machinery.

</details>


### [36] [Baseband Model, Cutoff Rate Bounds and Constellation Shaping for Mixed Gaussian-Impulsive Noise](https://arxiv.org/abs/2509.03333)
*Tianfu Qi,Jun Wang*

Main category: eess.SP

TL;DR: 本文针对混合噪声（高斯白噪声+脉冲噪声）下的通信系统性能优化问题，通过理论分析截止率来优化发送星座图设计。


<details>
  <summary>Details</summary>
Motivation: 混合噪声在多种通信场景中出现，会严重降低系统性能，需要找到有效的优化方法来提升通信速率。

Method: 首先推导混合噪声的基带表示，然后通过分段线性近似得到截止率的闭式上下界，最后利用投影梯度法优化星座图的几何和概率分布。

Result: 数值结果表明所提出的截止率边界紧密且具有预期的渐近行为，优化后的星座方案相比基线实现了显著的速率提升。

Conclusion: 基于截止率分析的星座优化方法能有效提升混合噪声环境下的通信性能，所提出的边界方法具有理论价值和实用意义。

Abstract: Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN),
appears in numerous communication scenarios and can severely degrade system
performance. In this paper, we address this issue by optimizing the transmitted
constellation under mixed noise based on a theoretical analysis of the cutoff
rate (CR). First, starting from the passband model of the mixed noise, we
derive its corresponding baseband representation. Due to the complexity of the
CR, an exact analytic expression is generally intractable. Therefore, the
baseband noise model is employed to obtain closed-form lower and upper bounds
of the CR. A piecewise linear approximation is applied to derive efficient
bounds by exploiting the algebraic properties of the integral terms. These
bounds are then used as criteria to optimize the transmitted constellation
points in both geometric and probabilistic distributions. The projected
gradient method is employed to solve the optimization problem, and the
convergence and properties of the solutions are analyzed. Numerical results
demonstrate that the proposed CR bounds are tight and exhibit the expected
asymptotic behavior. Furthermore, the optimized constellation scheme achieves a
significant rate improvement compared to baselines.

</details>


### [37] [Self-supervised Radio Representation Learning: Can we Learn Multiple Tasks?](https://arxiv.org/abs/2509.03077)
*Ogechukwu Kanu,Ashkan Eshaghbeigi,Hatem Abou-Zeid*

Main category: eess.SP

TL;DR: 提出基于动量对比的自监督学习方案，用于无线电信号表示学习，在AoA估计和AMC分类任务中超越监督学习基线


<details>
  <summary>Details</summary>
Motivation: 解决6G AI发展中数据标注成本高的问题，利用自监督学习从大量无标签数据中学习鲁棒表示

Method: 使用动量对比的对比学习方法，通过精心设计的数据增强和多样化数据提取不变性潜在表示

Result: 学习到的表示即使在冻结编码器权重时也有效，微调后性能进一步提升，超越监督基线

Conclusion: 自监督学习可减少对标注数据的依赖并提升模型泛化能力，为6G AI基础模型铺平道路

Abstract: Artificial intelligence (AI) is anticipated to play a pivotal role in 6G.
However, a key challenge in developing AI-powered solutions is the extensive
data collection and labeling efforts required to train supervised deep learning
models. To overcome this, self-supervised learning (SSL) approaches have
recently demonstrated remarkable success across various domains by leveraging
large volumes of unlabeled data to achieve near-supervised performance. In this
paper, we propose an effective SSL scheme for radio signal representation
learning using momentum contrast. By applying contrastive learning, our method
extracts robust, transferable representations from a large real-world dataset.
We assess the generalizability of these learned representations across two
wireless communications tasks: angle of arrival (AoA) estimation and automatic
modulation classification (AMC). Our results show that carefully designed
augmentations and diverse data enable contrastive learning to produce
high-quality, invariant latent representations. These representations are
effective even with frozen encoder weights, and fine-tuning further enhances
performance, surpassing supervised baselines. To the best of our knowledge,
this is the first work to propose and demonstrate the effectiveness of
self-supervised learning for radio signals across multiple tasks. Our findings
highlight the potential of self-supervised learning to transform AI for
wireless communications by reducing dependence on labeled data and improving
model generalization - paving the way for scalable foundational 6G AI models
and solutions.

</details>


### [38] [Handwriting Imagery EEG Classification based on Convolutional Neural Networks](https://arxiv.org/abs/2509.03111)
*Hao Yang,Guang Ouyang*

Main category: eess.SP

TL;DR: 通过深度神经网络解码头皮电脑电位图像手写想象的非侵入性EEG信号，识别26个英文字母，最高准确率达20%，为脑-文本BCI研究提供基准线


<details>
  <summary>Details</summary>
Motivation: 手写想象作为脑-机接口的有前景范式，非侵入性EEG记录比侵入性方法更实用可行，需要探索其在文本输出方面的解码极限

Method: 使用5名参与者想象手写26个英文字母，记录头皮EEG信号，进行字母间EEG相似性分析，然后训练四种卷积神经网络模型进行分类

Result: EEG数据显示出明显的字母特异模式，CNN分类器在随机水平3.85%的基础上达到约20%的最高准确率，显示了将非侵入性脑信号转换为文本输出的潜力

Conclusion: 这是首次尝试解码手写想象相关的非侵入性EEG，虽然准确率不足以支撑可用的脑-文本BCI，但模型表现为未来研究确立了基准线，展示了该方向的研究潜力

Abstract: Handwriting imagery has emerged as a promising paradigm for brain-computer
interfaces (BCIs) aimed at translating brain activity into text output.
Compared with invasively recorded electroencephalography (EEG), non-invasive
recording offers a more practical and feasible approach to capturing brain
signals for BCI. This study explores the limit of decoding non-invasive EEG
associated with handwriting imagery into English letters using deep neural
networks. To this end, five participants were instructed to imagine writing the
26 English letters with their EEG being recorded from the scalp. A measurement
of EEG similarity across letters was conducted to investigate letter-specific
patterns in the dataset. Subsequently, four convolutional neural network (CNN)
models were trained for EEG classification. Descriptively, the EEG data clearly
exhibited letter-specific patterns serving as a proof-of-concept for
EEG-to-text translation. Under the chance level of accuracy at 3.85%, the CNN
classifiers trained on each participant reached the highest limit of around
20%. This study marks the first attempt to decode non-invasive EEG associated
with handwriting imagery. Although the achieved accuracy is not sufficient for
a usable brain-to-text BCI, the model's performance is noteworthy in revealing
the potential for translating non-invasively recorded brain signals into text
outputs and establishing a baseline for future research.

</details>


### [39] [Deep Learning for High Speed Optical Coherence Elastography with a Fiber Scanning Endoscope](https://arxiv.org/abs/2509.03193)
*Maximilian Neidhardt,Sarah Latus,Tim Eixmann,Gereon Hüttmann,Alexander Schlaefer*

Main category: eess.SP

TL;DR: 开发了一种基于深度学习的小型化光纤扫描内镜系统，能够在微估手术中实时评估细胶细胶缩硬度，提高了精确度和速度。


<details>
  <summary>Details</summary>
Motivation: 现有的图像基于细胶缩硬度评估方法在微估手术中不适用，需要一种能够在介入性操作中实现快速、局部化硬度测量的方法。

Method: 设计了小型化光纤扫描内镜，采用锥形扫描模式（5.05 kHz），并使用空间-时间深度学习网络处理复杂波场图像序列，在模拟不同弹性的幻影样品上进行端到端训练。

Result: 在2D扫描中，新方法的平均绝对误差为6.31±5.76 kPa，显著低于传统相位跟踪方法的11.33±12.78 kPa。在3D扫描中，误差降低到4.48±3.63 kPa，而传统2D方法为19.75±21.82 kPa。还在猪组织中证明了可行性。

Conclusion: 该研究提出的深度学习处理流水线和小型化内镜系统能够在微估手术中实现实时、准确的细胶缩硬度评估，为临床应用提供了有前晨的技术支持。

Abstract: Tissue stiffness is related to soft tissue pathologies and can be assessed
through palpation or via clinical imaging systems, e.g., ultrasound or magnetic
resonance imaging. Typically, the image based approaches are not suitable
during interventions, particularly for minimally invasive surgery. To this end,
we present a miniaturized fiber scanning endoscope for fast and localized
elastography. Moreover, we propose a deep learning based signal processing
pipeline to account for the intricate data and the need for real-time
estimates. Our elasticity estimation approach is based on imaging complex and
diffuse wave fields that encompass multiple wave frequencies and propagate in
various directions. We optimize the probe design to enable different scan
patterns. To maximize temporal sampling while maintaining three-dimensional
information we define a scan pattern in a conical shape with a temporal
frequency of 5.05 kHz. To efficiently process the image sequences of complex
wave fields we consider a spatio-temporal deep learning network. We train the
network in an end-to-end fashion on measurements from phantoms representing
multiple elasticities. The network is used to obtain localized and robust
elasticity estimates, allowing to create elasticity maps in real-time. For 2D
scanning, our approach results in a mean absolute error of 6.31+-5.76 kPa
compared to 11.33+-12.78 kPa for conventional phase tracking. For scanning
without estimating the wave direction, the novel 3D method reduces the error to
4.48+-3.63 kPa compared to 19.75+-21.82 kPa for the conventional 2D method.
Finally, we demonstrate feasibility of elasticity estimates in ex-vivo porcine
tissue.

</details>


### [40] [Crosstalk-Resilient Beamforming for Movable Antenna Enabled Integrated Sensing and Communication](https://arxiv.org/abs/2509.03273)
*Zeyuan Zhang,Yue Xiu,Zheng Dong,Jiacheng Yin,Maurice J. Khabbaz,Chadi Assi,Ning Wei*

Main category: eess.SP

TL;DR: 这篇论文研究了在天线交象影响下的可移动天线集成感知通信系统，通过深度强化学习策略优化聚焦和天线位置设计，提出了一种能够提升系统性能的交象弹性算法。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线系统中的天线交象问题在可移动天线场景下需要重新建模，以优化集成感知通信系统的性能。

Method: 使用深度强化学习方法，采用Twin Delayed Deep Deterministic Policy Gradient (TD3)算法训练灵活聚焦继电器，平衡探索与奖励最大化。

Result: 数值结果显示，所提出的交象弹性算法在集成感知通信性能上超过了其他基准方案。

Conclusion: 该研究为可移动天线系统提供了一种有效的交象影响减缓方案，显著提升了集成感知通信的整体性能。

Abstract: This paper investigates a movable antenna (MA) enabled integrated sensing and
communication (ISAC) system under the influence of antenna crosstalk. First, it
generalizes the antenna crosstalk model from the conventional fixed-position
antenna (FPA) system to the MA scenario. Then, a Cramer-Rao bound (CRB)
minimization problem driven by joint beamforming and antenna position design is
presented. Specifically, to address this highly non-convex flexible beamforming
problem, we deploy a deep reinforcement learning (DRL) approach to train a
flexible beamforming agent. To ensure stability during training, a Twin Delayed
Deep Deterministic Policy Gradient (TD3) algorithm is adopted to balance
exploration with reward maximization for efficient and reliable learning.
Numerical results demonstrate that the proposed crosstalk-resilient (CR)
algorithm enhances the overall ISAC performance compared to other benchmark
schemes.

</details>


### [41] [Efficient DoA Estimation with Hybrid Linear and Rectangular Arrays Using Compact DFT Codebook](https://arxiv.org/abs/2509.03488)
*Miguel Rivas-Costa,Carlos Mosquera*

Main category: eess.SP

TL;DR: 提出了一种使用Butler矩阵的混合模拟数字架构，通过利用波束成形信号的柯西类位移结构，实现了接近CRLB下界的近最优DoA估计精度


<details>
  <summary>Details</summary>
Motivation: 混合模拟数字架构在大规模天线阵列中具有成本效益，但由于有限的数字维度和受限的波束成形设计，准确的波达方向估计仍然具有挑战性

Method: 采用Butler矩阵在均匀线性阵列上合成DFT波束，利用波束成形信号的柯西类位移结构，提出二阶统计量估计算法

Result: 在仿真中实现了接近克拉美-罗下界(CRLB)的近最优精度，优于现有最先进方法

Conclusion: 所提出的HAD架构和估计算法能够有效解决大规模天线阵列中的DoA估计挑战，达到接近理论最优的性能

Abstract: Hybrid Analog and Digital (HAD) architectures provide a cost-effective
alternative for large-scale antenna arrays, but accurate Direction-of-Arrival
(DoA) estimation remains challenging due to limited digital dimensionality and
constrained beamforming design. In this work, we propose a HAD architecture
that employs Butler matrices to synthesize DFT beams over a uniform linear
array. By exploiting the Cauchy-like displacement structure of the beamformed
signal, we introduce a second-order statistics estimation algorithm that
achieves near-optimal accuracy, approaching the Cram\'er-Rao Lower Bound (CRLB)
and outperforming state-of-the-art methods in simulation.

</details>
