{"id": "2511.09929", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.09929", "abs": "https://arxiv.org/abs/2511.09929", "authors": ["Zhentian Zhang", "David Morales-Jimenez", "Hao Jiang", "Christos Masouros"], "title": "A Universal Block Error Rate Bound for Fluid Antenna Systems", "comment": null, "summary": "Fluid antenna systems (FASs) offer genuine simplicity for communication network design by eliminating expensive hardware overhead and reducing the complexity of access protocol architectures. Through the discovery of significant spatial diversity within a compact antenna space, FASs enable the implementation of reconfigurable-antenna-based architectures. However, current state-of-the-art studies rarely investigate the impact of finite blocklength constraints on FAS-based designs, leaving a gap in both analytical modeling and the establishment of a solid, universally applicable performance metric for finite blocklength fluid antenna systems (FBL-FAS). In this work, we focus on the study of FBL-FAS and, more importantly, derive a block error rate (BLER) bound that serves as a general and practical performance benchmark across various FAS architectures. The proposed BLER bound is computable both with and without an explicit statistical model, meaning that the BLER performance can be characterized analytically or empirically under model-aware or model-free system scenarios. Moreover, when the statistical model is known, the analytical results derived from the proposed BLER bound exhibit strong alignment with the empirical findings, demonstrating the remarkable simplicity, accuracy, and universality of the proposed BLER bound.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6709\u9650\u5757\u957f\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf(FBL-FAS)\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u5757\u9519\u8bef\u7387(BLER)\u8fb9\u754c\u4f5c\u4e3a\u6027\u80fd\u57fa\u51c6\uff0c\u8be5\u8fb9\u754c\u5728\u6709\u65e0\u7edf\u8ba1\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u90fd\u53ef\u8ba1\u7b97\uff0c\u5177\u6709\u7b80\u5355\u6027\u3001\u51c6\u786e\u6027\u548c\u666e\u9002\u6027\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5f88\u5c11\u63a2\u8ba8\u6709\u9650\u5757\u957f\u7ea6\u675f\u5bf9\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5f71\u54cd\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6027\u80fd\u5ea6\u91cf\u6807\u51c6\u548c\u5206\u6790\u6a21\u578b\u3002", "method": "\u63a8\u5bfc\u4e86\u4e00\u4e2a\u901a\u7528\u7684BLER\u8fb9\u754c\uff0c\u8be5\u8fb9\u754c\u53ef\u5728\u6709\u7edf\u8ba1\u6a21\u578b\u548c\u65e0\u7edf\u8ba1\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\uff0c\u652f\u6301\u6a21\u578b\u611f\u77e5\u548c\u6a21\u578b\u65e0\u5173\u7684\u7cfb\u7edf\u573a\u666f\u3002", "result": "\u5f53\u7edf\u8ba1\u6a21\u578b\u5df2\u77e5\u65f6\uff0c\u4ece\u6240\u63d0BLER\u8fb9\u754c\u63a8\u5bfc\u7684\u5206\u6790\u7ed3\u679c\u4e0e\u5b9e\u8bc1\u53d1\u73b0\u9ad8\u5ea6\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u8fb9\u754c\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684BLER\u8fb9\u754c\u4e3a\u5404\u79cdFAS\u67b6\u6784\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u5b9e\u7528\u7684\u6027\u80fd\u57fa\u51c6\uff0c\u5177\u6709\u663e\u8457\u7b80\u5355\u6027\u3001\u51c6\u786e\u6027\u548c\u666e\u9002\u6027\u3002"}}
{"id": "2511.10052", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.10052", "abs": "https://arxiv.org/abs/2511.10052", "authors": ["Yiwei Liao", "Shurui Tu", "Yujie Zhou", "Dongzi Jin", "Yong Xiao", "Yingyu Li"], "title": "Implicit Semantic Communication Based on Bayesian Reconstruction Framework", "comment": null, "summary": "Semantic communication is a novel communication paradigm that focuses on the transportation and delivery of the \\emph{meaning} of messages. Recent results have verified that a graphical structure provides the most expressive and structurally faithful formalism for representing the relational semantics in most information sources. However, most existing works represent the semantics based on pairwise relation-based graphs, which cannot capture the higher-order interactions that are essential for some semantic sources. This paper proposes a novel Bayesian hypergraph inference-based semantic communication framework that can directly recover implicit semantic information involving high-order hyperedges at the receiver based on the pairwise relation-based explicit semantics sent by the transmitter. Experimental results based on real-world datasets demonstrated that the proposed SBRF achieves up to 90\\% recovery accuracy of the high-order hyperedges based on the pairwise relation-based explicit semantics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u8d85\u56fe\u63a8\u7406\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u53d1\u9001\u7aef\u57fa\u4e8e\u6210\u5bf9\u5173\u7cfb\u7684\u663e\u5f0f\u8bed\u4e49\u4e2d\u6062\u590d\u63a5\u6536\u7aef\u7684\u9ad8\u9636\u8d85\u8fb9\u9690\u542b\u8bed\u4e49\u4fe1\u606f\u3002", "motivation": "\u73b0\u6709\u8bed\u4e49\u901a\u4fe1\u5927\u591a\u57fa\u4e8e\u6210\u5bf9\u5173\u7cfb\u56fe\u8868\u793a\u8bed\u4e49\uff0c\u65e0\u6cd5\u6355\u6349\u5bf9\u67d0\u4e9b\u8bed\u4e49\u6e90\u81f3\u5173\u91cd\u8981\u7684\u9ad8\u9636\u4ea4\u4e92\u5173\u7cfb\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u8d85\u56fe\u63a8\u7406\u65b9\u6cd5\uff0c\u5728\u63a5\u6536\u7aef\u57fa\u4e8e\u53d1\u9001\u7aef\u4f20\u8f93\u7684\u6210\u5bf9\u5173\u7cfb\u663e\u5f0f\u8bed\u4e49\u76f4\u63a5\u6062\u590d\u6d89\u53ca\u9ad8\u9636\u8d85\u8fb9\u7684\u9690\u542b\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684SBRF\u65b9\u6cd5\u57fa\u4e8e\u6210\u5bf9\u5173\u7cfb\u663e\u5f0f\u8bed\u4e49\u80fd\u591f\u5b9e\u73b0\u9ad8\u8fbe90%\u7684\u9ad8\u9636\u8d85\u8fb9\u6062\u590d\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u8bed\u4e49\u901a\u4fe1\u4e2d\u9ad8\u9636\u8bed\u4e49\u4fe1\u606f\u6062\u590d\u7684\u95ee\u9898\uff0c\u4e3a\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2511.10066", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.10066", "abs": "https://arxiv.org/abs/2511.10066", "authors": ["Buket \u00d6zkaya"], "title": "Generalized Spectral Bound for Quasi-Twisted Codes", "comment": null, "summary": "Semenov and Trifonov [22] developed a spectral theory for quasi-cyclic codes and formulated a BCH-like minimum distance bound. Their approach was generalized by Zeh and Ling [24], by using the HT bound. The first spectral bound for quasi-twisted codes appeared in [7], which generalizes Semenov-Trifonov and Zeh-Ling bounds, but its overall performance was observed to be worse than the Jensen bound. More recently, an improved spectral bound for quasi-cyclic codes was proposed in [15], which outperforms the Jensen bound in many cases. In this paper, we adopt this approach to quasi-twisted case and we show that this new generalized spectral bound provides tighter lower bounds on the minimum distance compared to the Jensen and Ezerman et. al. bounds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u51c6\u626d\u8f6c\u7801\u8c31\u754c\u65b9\u6cd5\uff0c\u76f8\u6bd4Jensen\u754c\u548cEzerman\u754c\u80fd\u63d0\u4f9b\u66f4\u7d27\u7684\u6700\u5c0f\u8ddd\u79bb\u4e0b\u754c\u3002", "motivation": "\u73b0\u6709\u51c6\u626d\u8f6c\u7801\u7684\u8c31\u754c\u65b9\u6cd5\u6027\u80fd\u4e0d\u5982Jensen\u754c\uff0c\u800c\u8fd1\u671f\u51c6\u5faa\u73af\u7801\u7684\u6539\u8fdb\u8c31\u754c\u65b9\u6cd5\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u4f18\u4e8eJensen\u754c\uff0c\u56e0\u6b64\u5e0c\u671b\u5c06\u8fd9\u79cd\u65b9\u6cd5\u63a8\u5e7f\u5230\u51c6\u626d\u8f6c\u7801\u3002", "method": "\u91c7\u7528\u8fd1\u671f\u51c6\u5faa\u73af\u7801\u6539\u8fdb\u8c31\u754c\u7684\u65b9\u6cd5\uff0c\u5c06\u5176\u63a8\u5e7f\u5230\u51c6\u626d\u8f6c\u7801\u7684\u60c5\u51b5\u3002", "result": "\u65b0\u7684\u5e7f\u4e49\u8c31\u754c\u76f8\u6bd4Jensen\u754c\u548cEzerman\u754c\u80fd\u63d0\u4f9b\u66f4\u7d27\u7684\u6700\u5c0f\u8ddd\u79bb\u4e0b\u754c\u3002", "conclusion": "\u63a8\u5e7f\u7684\u8c31\u754c\u65b9\u6cd5\u5728\u51c6\u626d\u8f6c\u7801\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684Jensen\u754c\u548cEzerman\u754c\u3002"}}
{"id": "2511.10181", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.10181", "abs": "https://arxiv.org/abs/2511.10181", "authors": ["Eeshan Modak", "Mayank Bakshi", "Bikash Kumar Dey", "Vinod M. Prabhakaran"], "title": "Sequential Adversarial Hypothesis Testing", "comment": "Shorter version of this work was published at ISIT 2024", "summary": "We study the adversarial binary hypothesis testing problem in the sequential setting. Associated with each hypothesis is a closed, convex set of distributions. Given the hypothesis, each observation is generated according to a distribution chosen (from the set associated with the hypothesis) by an adversary who has access to past observations. In the sequential setting, the number of observations the detector uses to arrive at a decision is variable; this extra freedom improves the asymptotic performance of the test. We characterize the closure of the set of achievable pairs of error exponents. We also study the problem under constraints on the number of observations used and the probability of error incurred.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u987a\u5e8f\u8bbe\u7f6e\u4e0b\u7684\u5bf9\u6297\u6027\u4e8c\u5143\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5047\u8bbe\u5bf9\u5e94\u4e00\u4e2a\u5c01\u95ed\u7684\u51f8\u5206\u5e03\u96c6\u5408\uff0c\u5bf9\u624b\u6839\u636e\u8fc7\u53bb\u89c2\u6d4b\u9009\u62e9\u5206\u5e03\u751f\u6210\u89c2\u6d4b\u6570\u636e\u3002", "motivation": "\u5728\u987a\u5e8f\u8bbe\u7f6e\u4e2d\uff0c\u68c0\u6d4b\u5668\u4f7f\u7528\u7684\u89c2\u6d4b\u6570\u91cf\u662f\u53ef\u53d8\u7684\uff0c\u8fd9\u79cd\u989d\u5916\u7684\u81ea\u7531\u5ea6\u53ef\u4ee5\u63d0\u9ad8\u6d4b\u8bd5\u7684\u6e10\u8fd1\u6027\u80fd\u3002\u7814\u7a76\u5728\u89c2\u6d4b\u6570\u91cf\u7ea6\u675f\u548c\u9519\u8bef\u6982\u7387\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u6781\u9650\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6bcf\u4e2a\u5047\u8bbe\u5bf9\u5e94\u7684\u5c01\u95ed\u51f8\u5206\u5e03\u96c6\u5408\uff0c\u8003\u8651\u5bf9\u624b\u80fd\u591f\u8bbf\u95ee\u8fc7\u53bb\u89c2\u6d4b\u5e76\u9009\u62e9\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u7814\u7a76\u987a\u5e8f\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u3002", "result": "\u523b\u753b\u4e86\u53ef\u5b9e\u73b0\u7684\u9519\u8bef\u6307\u6570\u5bf9\u7684\u95ed\u5305\uff0c\u5e76\u5206\u6790\u4e86\u5728\u89c2\u6d4b\u6570\u91cf\u7ea6\u675f\u548c\u9519\u8bef\u6982\u7387\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u3002", "conclusion": "\u987a\u5e8f\u8bbe\u7f6e\u4e0b\u7684\u5bf9\u6297\u6027\u4e8c\u5143\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\u5177\u6709\u66f4\u597d\u7684\u6e10\u8fd1\u6027\u80fd\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u8be5\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\u548c\u6027\u80fd\u754c\u9650\u3002"}}
{"id": "2511.09802", "categories": ["eess.SP", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.09802", "abs": "https://arxiv.org/abs/2511.09802", "authors": ["Parinaz Binandeh Dehaghani", "Danilo Pena", "A. Pedro Aguiar"], "title": "Investigation of Feature Selection and Pooling Methods for Environmental Sound Classification", "comment": "6 pages, 7 figures (including subfigures)", "summary": "This paper explores the impact of dimensionality reduction and pooling methods for Environmental Sound Classification (ESC) using lightweight CNNs. We evaluate Sparse Salient Region Pooling (SSRP) and its variants, SSRP-Basic (SSRP-B) and SSRP-Top-K (SSRP-T), under various hyperparameter settings and compare them with Principal Component Analysis (PCA). Experiments on the ESC-50 dataset demonstrate that SSRP-T achieves up to 80.69 % accuracy, significantly outperforming both the baseline CNN (66.75 %) and the PCA-reduced model (37.60 %). Our findings confirm that a well-tuned sparse pooling strategy provides a robust, efficient, and high-performing solution for ESC tasks, particularly in resource-constrained scenarios where balancing accuracy and computational cost is crucial.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7ef4\u5ea6\u7f29\u51cf\u548c\u6c60\u5316\u65b9\u6cd5\u5bf9\u8f7b\u91cf\u7ea7CNN\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u4e86SSRP\u53ca\u5176\u53d8\u4f53\uff0c\u53d1\u73b0SSRP-T\u5728ESC-50\u6570\u636e\u96c6\u4e0a\u8fbe\u523080.69%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfCNN\u548cPCA\u65b9\u6cd5\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\uff0c\u9700\u8981\u5e73\u8861\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u63a2\u7d22\u9ad8\u6548\u7684\u7ef4\u5ea6\u7f29\u51cf\u548c\u6c60\u5316\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30\u7a00\u758f\u663e\u8457\u533a\u57df\u6c60\u5316(SSRP)\u53ca\u5176\u53d8\u4f53SSRP-B\u548cSSRP-T\uff0c\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u4e0e\u4e3b\u6210\u5206\u5206\u6790(PCA)\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728ESC-50\u6570\u636e\u96c6\u4e0a\uff0cSSRP-T\u8fbe\u523080.69%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfCNN(66.75%)\u548cPCA\u6a21\u578b(37.60%)\u3002", "conclusion": "\u7cbe\u5fc3\u8c03\u4f18\u7684\u7a00\u758f\u6c60\u5316\u7b56\u7565\u4e3a\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u9ad8\u6548\u4e14\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2511.09581", "categories": ["eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.09581", "abs": "https://arxiv.org/abs/2511.09581", "authors": ["Phillip Sloan", "Edwin Simpson", "Majid Mirmehdi"], "title": "Clinically-aligned Multi-modal Chest X-ray Classification", "comment": "9 Pages, 2 Figures, 3 Tables & 2 Supplementary Tables in Appendix. Accepted to ML4H 2025 (Proceedings)", "summary": "Radiology is essential to modern healthcare, yet rising demand and staffing shortages continue to pose major challenges. Recent advances in artificial intelligence have the potential to support radiologists and help address these challenges. Given its widespread use and clinical importance, chest X-ray classification is well suited to augment radiologists' workflows. However, most existing approaches rely solely on single-view, image-level inputs, ignoring the structured clinical information and multi-image studies available at the time of reporting. In this work, we introduce CaMCheX, a multimodal transformer-based framework that aligns multi-view chest X-ray studies with structured clinical data to better reflect how clinicians make diagnostic decisions. Our architecture employs view-specific ConvNeXt encoders for frontal and lateral chest radiographs, whose features are fused with clinical indications, history, and vital signs using a transformer fusion module. This design enables the model to generate context-aware representations that mirror reasoning in clinical practice. Our results exceed the state of the art for both the original MIMIC-CXR dataset and the more recent CXR-LT benchmarks, highlighting the value of clinically grounded multimodal alignment for advancing chest X-ray classification.", "AI": {"tldr": "CaMCheX\u662f\u4e00\u4e2a\u591a\u6a21\u6001Transformer\u6846\u67b6\uff0c\u5c06\u591a\u89c6\u56fe\u80f8\u90e8X\u5149\u7814\u7a76\u4e0e\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\u5bf9\u9f50\uff0c\u4ee5\u6539\u8fdb\u80f8\u90e8X\u5149\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u80f8\u90e8X\u5149\u5206\u7c7b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5355\u89c6\u56fe\u56fe\u50cf\u7ea7\u8f93\u5165\uff0c\u5ffd\u7565\u4e86\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u53ef\u7528\u7684\u7ed3\u6784\u5316\u4e34\u5e8a\u4fe1\u606f\u548c\u591a\u56fe\u50cf\u7814\u7a76\uff0c\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u4e34\u5e8a\u533b\u751f\u7684\u8bca\u65ad\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u89c6\u56fe\u7279\u5b9a\u7684ConvNeXt\u7f16\u7801\u5668\u5904\u7406\u6b63\u9762\u548c\u4fa7\u9762\u80f8\u90e8X\u5149\u7247\uff0c\u901a\u8fc7Transformer\u878d\u5408\u6a21\u5757\u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u4e34\u5e8a\u6307\u5f81\u3001\u75c5\u53f2\u548c\u751f\u547d\u4f53\u5f81\u7b49\u4e34\u5e8a\u6570\u636e\u878d\u5408\u3002", "result": "\u5728MIMIC-CXR\u548cCXR-LT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u4e34\u5e8a\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u5bf9\u4e8e\u63a8\u8fdb\u80f8\u90e8X\u5149\u5206\u7c7b\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u751f\u6210\u66f4\u7b26\u5408\u4e34\u5e8a\u63a8\u7406\u7684\u60c5\u5883\u611f\u77e5\u8868\u793a\u3002"}}
{"id": "2511.10291", "categories": ["cs.IT", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.10291", "abs": "https://arxiv.org/abs/2511.10291", "authors": ["Aswin Arun", "Christo Kurisummoottil Thomas", "Rimalpudi Sarvendranath", "Walid Saad"], "title": "Causal Model-Based Reinforcement Learning for Sample-Efficient IoT Channel Access", "comment": null, "summary": "Despite the advantages of multi-agent reinforcement learning (MARL) for wireless use case such as medium access control (MAC), their real-world deployment in Internet of Things (IoT) is hindered by their sample inefficiency. To alleviate this challenge, one can leverage model-based reinforcement learning (MBRL) solutions, however, conventional MBRL approaches rely on black-box models that are not interpretable and cannot reason. In contrast, in this paper, a novel causal model-based MARL framework is developed by leveraging tools from causal learn- ing. In particular, the proposed model can explicitly represent causal dependencies between network variables using structural causal models (SCMs) and attention-based inference networks. Interpretable causal models are then developed to capture how MAC control messages influence observations, how transmission actions determine outcomes, and how channel observations affect rewards. Data augmentation techniques are then used to generate synthetic rollouts using the learned causal model for policy optimization via proximal policy optimization (PPO). Analytical results demonstrate exponential sample complexity gains of causal MBRL over black-box approaches. Extensive simulations demonstrate that, on average, the proposed approach can reduce environment interactions by 58%, and yield faster convergence compared to model-free baselines. The proposed approach inherently is also shown to provide interpretable scheduling decisions via attention-based causal attribution, revealing which network conditions drive the policy. The resulting combination of sample efficiency and interpretability establishes causal MBRL as a practical approach for resource-constrained wireless systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u6ce8\u610f\u529b\u7f51\u7edc\u663e\u5f0f\u8868\u793a\u7f51\u7edc\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8c03\u5ea6\u51b3\u7b56\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u65e0\u7ebf\u7269\u8054\u7f51\u5e94\u7528\u4e2d\u9762\u4e34\u6837\u672c\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u4f9d\u8d56\u9ed1\u76d2\u6a21\u578b\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u6ce8\u610f\u529b\u63a8\u7406\u7f51\u7edc\u663e\u5f0f\u8868\u793a\u7f51\u7edc\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u6a21\u578b\u6355\u83b7MAC\u63a7\u5236\u6d88\u606f\u3001\u4f20\u8f93\u52a8\u4f5c\u548c\u4fe1\u9053\u89c2\u6d4b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u8fdb\u884c\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5206\u6790\u7ed3\u679c\u8868\u660e\u56e0\u679cMBRL\u76f8\u6bd4\u9ed1\u76d2\u65b9\u6cd5\u5177\u6709\u6307\u6570\u7ea7\u6837\u672c\u590d\u6742\u5ea6\u4f18\u52bf\uff0c\u5e73\u5747\u51cf\u5c1158%\u7684\u73af\u5883\u4ea4\u4e92\uff0c\u6536\u655b\u901f\u5ea6\u66f4\u5feb\uff0c\u5e76\u80fd\u901a\u8fc7\u6ce8\u610f\u529b\u56e0\u679c\u5f52\u56e0\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8c03\u5ea6\u51b3\u7b56\u3002", "conclusion": "\u56e0\u679cMBRL\u7ed3\u5408\u4e86\u6837\u672c\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u65e0\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.09826", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.09826", "abs": "https://arxiv.org/abs/2511.09826", "authors": ["Yu Zhao", "Li You", "Jinke Tang", "Mengyu Qian", "Bin Jiang", "Xiang-Gen Xia", "Xiqi Gao"], "title": "Massive MIMO-OFDM Channel Acquisition with Multi-group Adjustable Phase Shift Pilots", "comment": "to appear on IEEE Transactions on Communications", "summary": "Massive multiple-input multiple-output - orthogonal frequency division multiplexing (MIMO-OFDM) systems face the challenge of high channel acquisition overhead while providing significant spectral efficiency (SE). Adjustable phase shift pilots (APSPs) are an effective technique to acquire channels with low overhead by exploiting channel sparsity. In this paper, we extend it to multiple groups and propose multi-group adjustable phase shift pilots (MAPSPs) to improve SE further. We first introduce a massive MIMO-OFDM system model and transform the conventional channel model in the space-frequency domain to the angle-delay domain, obtaining a sparse channel matrix. Then, we propose a method of generating MAPSPs through multiple basic sequences and investigate channel estimation processes. By analyzing the components of pilot interference, we elucidate the underlying mechanism by which interference affects MMSE estimation. Building upon this foundation, we demonstrate the benefit of phase scheduling in MAPSP channel estimation and establish the optimal design condition tailored for scheduling. Furthermore, we propose an implementation scheme based on Zadoff-Chu sequences that includes received signal pre-processing and pilot scheduling methods to mitigate pilot interference. Simulation results indicate that the MAPSP method achieves a lower mean square error (MSE) of estimation than APSP and significantly enhances SE in mobility scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u7ec4\u53ef\u8c03\u76f8\u79fb\u5bfc\u9891(MAPSPs)\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7ec4\u57fa\u672c\u5e8f\u5217\u751f\u6210\u5bfc\u9891\uff0c\u5728\u89d2\u5ea6-\u65f6\u5ef6\u57df\u5229\u7528\u4fe1\u9053\u7a00\u758f\u6027\uff0c\u663e\u8457\u964d\u4f4e\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u5f00\u9500\u5e76\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u9762\u4e34\u9ad8\u4fe1\u9053\u83b7\u53d6\u5f00\u9500\u7684\u6311\u6218\uff0c\u800c\u53ef\u8c03\u76f8\u79fb\u5bfc\u9891(APSPs)\u867d\u7136\u80fd\u5229\u7528\u4fe1\u9053\u7a00\u758f\u6027\u964d\u4f4e\u5f00\u9500\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u5c06\u4f20\u7edf\u7a7a\u95f4-\u9891\u57df\u4fe1\u9053\u6a21\u578b\u8f6c\u6362\u4e3a\u89d2\u5ea6-\u65f6\u5ef6\u57df\u7a00\u758f\u4fe1\u9053\u77e9\u9635\uff1b\u901a\u8fc7\u591a\u7ec4\u57fa\u672c\u5e8f\u5217\u751f\u6210MAPSPs\uff1b\u5206\u6790\u5bfc\u9891\u5e72\u6270\u5bf9MMSE\u4f30\u8ba1\u7684\u5f71\u54cd\u673a\u5236\uff1b\u63d0\u51fa\u57fa\u4e8eZadoff-Chu\u5e8f\u5217\u7684\u5b9e\u73b0\u65b9\u6848\uff0c\u5305\u62ec\u63a5\u6536\u4fe1\u53f7\u9884\u5904\u7406\u548c\u5bfc\u9891\u8c03\u5ea6\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cMAPSP\u65b9\u6cd5\u76f8\u6bd4APSP\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u4f30\u8ba1\u5747\u65b9\u8bef\u5dee(MSE)\uff0c\u5e76\u5728\u79fb\u52a8\u573a\u666f\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u9891\u8c31\u6548\u7387\u3002", "conclusion": "MAPSP\u65b9\u6cd5\u901a\u8fc7\u591a\u7ec4\u5bfc\u9891\u8bbe\u8ba1\u548c\u76f8\u4f4d\u8c03\u5ea6\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u5f00\u9500\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.09588", "categories": ["eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.09588", "abs": "https://arxiv.org/abs/2511.09588", "authors": ["Vincenzo Marcian\u00f2", "Hava Chaptoukaev", "Virginia Fernandez", "M. Jorge Cardoso", "S\u00e9bastien Ourselin", "Michela Antonelli", "Maria A. Zuluaga"], "title": "Diffusion-Based Quality Control of Medical Image Segmentations across Organs", "comment": null, "summary": "Medical image segmentation using deep learning (DL) has enabled the development of automated analysis pipelines for large-scale population studies. However, state-of-the-art DL methods are prone to hallucinations, which can result in anatomically implausible segmentations. With manual correction impractical at scale, automated quality control (QC) techniques have to address the challenge. While promising, existing QC methods are organ-specific, limiting their generalizability and usability beyond their original intended task. To overcome this limitation, we propose no-new Quality Control (nnQC), a robust QC framework based on a diffusion-generative paradigm that self-adapts to any input organ dataset. Central to nnQC is a novel Team of Experts (ToE) architecture, where two specialized experts independently encode 3D spatial awareness, represented by the relative spatial position of an axial slice, and anatomical information derived from visual features from the original image. A weighted conditional module dynamically combines the pair of independent embeddings, or opinions to condition the sampling mechanism within a diffusion process, enabling the generation of a spatially aware pseudo-ground truth for predicting QC scores. Within its framework, nnQC integrates fingerprint adaptation to ensure adaptability across organs, datasets, and imaging modalities. We evaluated nnQC on seven organs using twelve publicly available datasets. Our results demonstrate that nnQC consistently outperforms state-of-the-art methods across all experiments, including cases where segmentation masks are highly degraded or completely missing, confirming its versatility and effectiveness across different organs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u751f\u6210\u8303\u5f0f\u7684\u901a\u7528\u8d28\u91cf\u63a7\u5236\u6846\u67b6nnQC\uff0c\u901a\u8fc7\u56e2\u961f\u4e13\u5bb6\u67b6\u6784\u548c\u6307\u7eb9\u9002\u5e94\u6280\u672f\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u5904\u7406\u4e0d\u540c\u5668\u5b98\u7684\u533b\u5b66\u56fe\u50cf\u5206\u5272\u8d28\u91cf\u8bc4\u4f30\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u56fe\u50cf\u5206\u5272\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u5bfc\u81f4\u89e3\u5256\u5b66\u4e0a\u4e0d\u5408\u7406\u7684\u5206\u5272\u7ed3\u679c\uff0c\u800c\u73b0\u6709\u7684\u8d28\u91cf\u63a7\u5236\u65b9\u6cd5\u90fd\u662f\u5668\u5b98\u7279\u5b9a\u7684\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u53ef\u7528\u6027\u3002", "method": "\u91c7\u7528\u6269\u6563\u751f\u6210\u8303\u5f0f\uff0c\u63d0\u51fa\u56e2\u961f\u4e13\u5bb6\u67b6\u6784\uff0c\u5176\u4e2d\u4e24\u4e2a\u4e13\u5bb6\u5206\u522b\u7f16\u78013D\u7a7a\u95f4\u610f\u8bc6\u548c\u89e3\u5256\u4fe1\u606f\uff0c\u901a\u8fc7\u52a0\u6743\u6761\u4ef6\u6a21\u5757\u52a8\u6001\u7ec4\u5408\u8fd9\u4e9b\u4fe1\u606f\u6765\u751f\u6210\u4f2a\u5730\u9762\u5b9e\u51b5\uff0c\u5e76\u96c6\u6210\u6307\u7eb9\u9002\u5e94\u6280\u672f\u786e\u4fdd\u8de8\u5668\u5b98\u9002\u5e94\u6027\u3002", "result": "\u57287\u4e2a\u5668\u5b98\u768412\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cnnQC\u5728\u6240\u6709\u5b9e\u9a8c\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u5206\u5272\u63a9\u7801\u4e25\u91cd\u9000\u5316\u6216\u5b8c\u5168\u7f3a\u5931\u7684\u60c5\u51b5\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "nnQC\u662f\u4e00\u4e2a\u591a\u529f\u80fd\u4e14\u6709\u6548\u7684\u8d28\u91cf\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u5668\u5b98\u3001\u6570\u636e\u96c6\u548c\u6210\u50cf\u6a21\u6001\uff0c\u89e3\u51b3\u4e86\u533b\u5b66\u56fe\u50cf\u5206\u5272\u8d28\u91cf\u63a7\u5236\u7684\u901a\u7528\u6027\u95ee\u9898\u3002"}}
{"id": "2511.10310", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10310", "abs": "https://arxiv.org/abs/2511.10310", "authors": ["Honghao Wang", "Qingqing Wu", "Yifan Jiang", "Ziyuan Zheng", "Ziheng Zhang", "Yanze Zhu", "Ying Gao", "Wen Chen", "Guanghai Liu", "Abbas Jamalipour"], "title": "Reconfigurable Airspace: Synergizing Movable Antenna and Intelligent Surface for Low-Altitude ISAC Networks", "comment": null, "summary": "Low-altitude unmanned aerial vehicle (UAV) networks are integral to future 6G integrated sensing and communication (ISAC) systems. However, their deployment is hindered by challenges stemming from high mobility of UAVs, complex propagation environments, and the inherent trade-offs between coexisting sensing and communication functions. This article proposes a novel framework that leverages movable antennas (MAs) and intelligent reflecting surfaces (IRSs) as dual enablers to overcome these limitations. MAs, through active transceiver reconfiguration, and IRSs, via passive channel reconstruction, can work in synergy to significantly enhance system performance. Our analysis first elaborates on the fundamental gains offered by MAs and IRSs, and provides simulation results that validate the immense potential of the MA-IRS-enabled ISAC architecture. Two core UAV deployment scenarios are then investigated: (i) UAVs as ISAC users, where we focus on achieving high-precision tracking and aerial safety, and (ii) UAVs as aerial network nodes, where we address robust design and complex coupled resource optimization. Finally, key technical challenges and research opportunities are identified and analyzed for each scenario, charting a clear course for the future design of advanced low-altitude ISAC networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u53ef\u79fb\u52a8\u5929\u7ebf(MAs)\u548c\u667a\u80fd\u53cd\u5c04\u9762(IRSs)\u4f5c\u4e3a\u53cc\u91cd\u4f7f\u80fd\u5668\u7684\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u4f4e\u7a7a\u65e0\u4eba\u673a\u7f51\u7edc\u57286G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u6311\u6218\uff0c\u5305\u62ec\u9ad8\u79fb\u52a8\u6027\u3001\u590d\u6742\u4f20\u64ad\u73af\u5883\u4ee5\u53ca\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u4f4e\u7a7a\u65e0\u4eba\u673a\u7f51\u7edc\u662f\u672a\u67656G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5176\u90e8\u7f72\u9762\u4e34\u65e0\u4eba\u673a\u9ad8\u79fb\u52a8\u6027\u3001\u590d\u6742\u4f20\u64ad\u73af\u5883\u4ee5\u53ca\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\u4e4b\u95f4\u56fa\u6709\u6743\u8861\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u53ef\u79fb\u52a8\u5929\u7ebf\u901a\u8fc7\u4e3b\u52a8\u6536\u53d1\u5668\u91cd\u6784\u548c\u667a\u80fd\u53cd\u5c04\u9762\u901a\u8fc7\u88ab\u52a8\u4fe1\u9053\u91cd\u6784\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002\u5206\u6790\u4e86\u4e24\u79cd\u6838\u5fc3\u65e0\u4eba\u673a\u90e8\u7f72\u573a\u666f\uff1a\u4f5c\u4e3aISAC\u7528\u6237\u548c\u4f5c\u4e3a\u7a7a\u4e2d\u7f51\u7edc\u8282\u70b9\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86MA-IRS\u4f7f\u80fd\u7684ISAC\u67b6\u6784\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8ddf\u8e2a\u3001\u7a7a\u4e2d\u5b89\u5168\u3001\u9c81\u68d2\u8bbe\u8ba1\u548c\u590d\u6742\u8026\u5408\u8d44\u6e90\u4f18\u5316\u3002", "conclusion": "\u8bc6\u522b\u5e76\u5206\u6790\u4e86\u6bcf\u4e2a\u573a\u666f\u4e0b\u7684\u5173\u952e\u6280\u672f\u6311\u6218\u548c\u7814\u7a76\u673a\u4f1a\uff0c\u4e3a\u5148\u8fdb\u4f4e\u7a7aISAC\u7f51\u7edc\u7684\u672a\u6765\u8bbe\u8ba1\u6307\u660e\u4e86\u6e05\u6670\u65b9\u5411\u3002"}}
{"id": "2511.09992", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09992", "abs": "https://arxiv.org/abs/2511.09992", "authors": ["Mehdi Zafari", "A. Lee Swindlehurst"], "title": "ASSENT: Learning-Based Association Optimization for Distributed Cell-Free ISAC", "comment": "Preprint. 6 pages, 2 figures, 2 tables. Under review. Code and datasets: https://github.com/LS-Wireless/ASSENT-CellFree-ISAC", "summary": "Integrated Sensing and Communication (ISAC) is a key emerging 6G technology. Despite progress, ISAC still lacks scalable methods for joint AP clustering and user/target scheduling in distributed deployments under fronthaul limits. Moreover, existing ISAC solutions largely rely on centralized processing and full channel state information, limiting scalability. This paper addresses joint access point (AP) clustering, user and target scheduling, and AP mode selection in distributed cell-free ISAC systems operating with constrained fronthaul capacity. We formulate the problem as a mixed-integer linear program (MILP) that jointly captures interference coupling, RF-chain limits, and sensing requirements, providing optimal but computationally demanding solutions. To enable real-time and scalable operation, we propose ASSENT (ASSociation and ENTity selection), a graph neural network (GNN) framework trained on MILP solutions to efficiently learn association and mode-selection policies directly from lightweight link statistics. Simulations show that ASSENT achieves near-optimal utility while accurately learning the underlying associations. Additionally, its single forward pass inference reduces decision latency compared to optimization-based methods. An open-source Python/PyTorch implementation with full datasets is provided to facilitate reproducible and extensible research in cell-free ISAC.", "AI": {"tldr": "\u63d0\u51faASSENT\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u5206\u5e03\u5f0f\u65e0\u8702\u7a9dISAC\u7cfb\u7edf\u4e2d\u7684AP\u805a\u7c7b\u3001\u7528\u6237/\u76ee\u6807\u8c03\u5ea6\u548cAP\u6a21\u5f0f\u9009\u62e9\u95ee\u9898\uff0c\u5728\u6709\u9650\u524d\u4f20\u5bb9\u91cf\u4e0b\u5b9e\u73b0\u8fd1\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709ISAC\u89e3\u51b3\u65b9\u6848\u4e3b\u8981\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u5904\u7406\u548c\u5b8c\u6574\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u7f3a\u4e4f\u5728\u5206\u5e03\u5f0f\u90e8\u7f72\u548c\u524d\u4f20\u9650\u5236\u4e0b\u53ef\u6269\u5c55\u7684\u8054\u5408AP\u805a\u7c7b\u548c\u7528\u6237/\u76ee\u6807\u8c03\u5ea6\u65b9\u6cd5\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u7136\u540e\u63d0\u51faASSENT\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u5b66\u4e60\u5173\u8054\u548c\u6a21\u5f0f\u9009\u62e9\u7b56\u7565\uff0c\u76f4\u63a5\u4ece\u8f7b\u91cf\u7ea7\u94fe\u8def\u7edf\u8ba1\u4e2d\u505a\u51fa\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u663e\u793aASSENT\u5b9e\u73b0\u8fd1\u6700\u4f18\u6548\u7528\uff0c\u51c6\u786e\u5b66\u4e60\u5e95\u5c42\u5173\u8054\u5173\u7cfb\uff0c\u5355\u6b21\u524d\u5411\u4f20\u64ad\u63a8\u7406\u76f8\u6bd4\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u51b3\u7b56\u5ef6\u8fdf\u3002", "conclusion": "ASSENT\u4e3a\u65e0\u8702\u7a9dISAC\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u65f6\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u6e90\u5b9e\u73b0\u4fc3\u8fdb\u53ef\u590d\u73b0\u548c\u53ef\u6269\u5c55\u7814\u7a76\u3002"}}
{"id": "2511.09592", "categories": ["eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.09592", "abs": "https://arxiv.org/abs/2511.09592", "authors": ["Himashi Peiris", "Sizhe Wang", "Gary Egan", "Mehrtash Harandi", "Meng Law", "Zhaolin Chen"], "title": "Segment Any Tumour: An Uncertainty-Aware Vision Foundation Model for Whole-Body Analysis", "comment": null, "summary": "Prompt-driven vision foundation models, such as the Segment Anything Model, have recently demonstrated remarkable adaptability in computer vision. However, their direct application to medical imaging remains challenging due to heterogeneous tissue structures, imaging artefacts, and low-contrast boundaries, particularly in tumours and cancer primaries leading to suboptimal segmentation in ambiguous or overlapping lesion regions. Here, we present Segment Any Tumour 3D (SAT3D), a lightweight volumetric foundation model designed to enable robust and generalisable tumour segmentation across diverse medical imaging modalities. SAT3D integrates a shifted-window vision transformer for hierarchical volumetric representation with an uncertainty-aware training pipeline that explicitly incorporates uncertainty estimates as prompts to guide reliable boundary prediction in low-contrast regions. Adversarial learning further enhances model performance for the ambiguous pathological regions. We benchmark SAT3D against three recent vision foundation models and nnUNet across 11 publicly available datasets, encompassing 3,884 tumour and cancer cases for training and 694 cases for in-distribution evaluation. Trained on 17,075 3D volume-mask pairs across multiple modalities and cancer primaries, SAT3D demonstrates strong generalisation and robustness. To facilitate practical use and clinical translation, we developed a 3D Slicer plugin that enables interactive, prompt-driven segmentation and visualisation using the trained SAT3D model. Extensive experiments highlight its effectiveness in improving segmentation accuracy under challenging and out-of-distribution scenarios, underscoring its potential as a scalable foundation model for medical image analysis.", "AI": {"tldr": "SAT3D\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea73D\u4f53\u79ef\u57fa\u7840\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u533b\u5b66\u5f71\u50cf\u4e2d\u7684\u80bf\u7624\u5206\u5272\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bad\u7ec3\u548c\u5bf9\u6297\u5b66\u4e60\u89e3\u51b3\u533b\u5b66\u5f71\u50cf\u4e2d\u7ec4\u7ec7\u5f02\u8d28\u6027\u3001\u4f2a\u5f71\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u8fb9\u754c\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08\u5982Segment Anything Model\uff09\u76f4\u63a5\u5e94\u7528\u4e8e\u533b\u5b66\u5f71\u50cf\u5b58\u5728\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u7ec4\u7ec7\u5f02\u8d28\u6027\u3001\u6210\u50cf\u4f2a\u5f71\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u8fb9\u754c\uff0c\u7279\u522b\u662f\u5728\u80bf\u7624\u548c\u764c\u75c7\u539f\u53d1\u7076\u533a\u57df\uff0c\u5bfc\u81f4\u5728\u6a21\u7cca\u6216\u91cd\u53e0\u75c5\u53d8\u533a\u57df\u7684\u5206\u5272\u6548\u679c\u4e0d\u4f73\u3002", "method": "SAT3D\u96c6\u6210\u4e86\u79fb\u4f4d\u7a97\u53e3\u89c6\u89c9\u53d8\u6362\u5668\u8fdb\u884c\u5206\u5c42\u4f53\u79ef\u8868\u793a\uff0c\u91c7\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4f5c\u4e3a\u63d0\u793a\u6765\u6307\u5bfc\u4f4e\u5bf9\u6bd4\u5ea6\u533a\u57df\u7684\u53ef\u9760\u8fb9\u754c\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u5b66\u4e60\u589e\u5f3a\u6a21\u578b\u5728\u6a21\u7cca\u75c5\u7406\u533a\u57df\u7684\u6027\u80fd\u3002", "result": "\u572811\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff083,884\u4e2a\u8bad\u7ec3\u75c5\u4f8b\u548c694\u4e2a\u5206\u5e03\u5185\u8bc4\u4f30\u75c5\u4f8b\uff09\u4e0a\uff0cSAT3D\u76f8\u6bd4\u4e09\u4e2a\u6700\u65b0\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u548cnnUNet\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002\u6a21\u578b\u572817,075\u4e2a3D\u4f53\u79ef-\u63a9\u6a21\u5bf9\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u764c\u75c7\u539f\u53d1\u7076\u3002", "conclusion": "SAT3D\u5728\u6311\u6218\u6027\u548c\u5206\u5e03\u5916\u573a\u666f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5272\u51c6\u786e\u6027\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u6790\u53ef\u6269\u5c55\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u5e76\u5f00\u53d1\u4e863D Slicer\u63d2\u4ef6\u652f\u6301\u4ea4\u4e92\u5f0f\u3001\u63d0\u793a\u9a71\u52a8\u7684\u5206\u5272\u548c\u53ef\u89c6\u5316\u3002"}}
{"id": "2511.10006", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10006", "abs": "https://arxiv.org/abs/2511.10006", "authors": ["Qiaoyan Peng", "Qingqing Wu", "Guangji Chen", "Wen Chen", "Shaodan Ma", "Shanpu Shen", "Rui Zhang"], "title": "Rotatable IRS Aided Wireless Communication", "comment": null, "summary": "Rotatable intelligent reflecting surface (IRS) introduces a new spatial degree of freedom (DoF) by dynamically adjusting orientations without the need of changing its elements' positions in real time. To unleash the full potential of rotatable IRSs for wireless communications, this paper investigates the joint optimization of IRS rotation angles to maximize the minimum expected signal-to-noise ratio (SNR) over all locations within a given target area. We first propose an angle-dependent channel model that accurately characterizes the reception and reflection of each IRS element. Different from the conventional cosine-law assumption, the proposed model captures the practical electromagnetic characteristics of the IRS, including the effective reception area and reflection efficiency. For the single target location case, a particle swarm optimization (PSO)-based algorithm is developed to solve the SNR maximization problem, and a closed-form expression for a near-optimal solution is derived to provide useful insights. For the general area coverage enhancement case, the optimal rotation is obtained through a two-loop PSO-based iterative algorithm with null-point detection. In this algorithm, the outer loop updates the global rotation angles to maximize the minimum SNR over the target area, whereas the inner loop evaluates the SNR distribution within the area to identify the location corresponding to the minimum SNR through null-point detection. Numerical results demonstrate significant SNR improvement achieved by the proposed rotatable IRS design over various benchmark schemes under different system setups.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53ef\u65cb\u8f6c\u667a\u80fd\u53cd\u5c04\u9762(IRS)\u7684\u8054\u5408\u4f18\u5316\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574IRS\u7684\u65cb\u8f6c\u89d2\u5ea6\u6765\u6700\u5927\u5316\u76ee\u6807\u533a\u57df\u5185\u6240\u6709\u4f4d\u7f6e\u7684\u6700\u5c0f\u671f\u671b\u4fe1\u566a\u6bd4(SNR)\u3002", "motivation": "\u53ef\u65cb\u8f6cIRS\u5f15\u5165\u4e86\u65b0\u7684\u7a7a\u95f4\u81ea\u7531\u5ea6\uff0c\u65e0\u9700\u5b9e\u65f6\u6539\u53d8\u5143\u4ef6\u4f4d\u7f6e\u5373\u53ef\u8c03\u6574\u65b9\u5411\u3002\u4e3a\u4e86\u5145\u5206\u53d1\u6325\u53ef\u65cb\u8f6cIRS\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u6f5c\u529b\uff0c\u9700\u8981\u4f18\u5316\u5176\u65cb\u8f6c\u89d2\u5ea6\u4ee5\u589e\u5f3a\u533a\u57df\u8986\u76d6\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u89d2\u5ea6\u76f8\u5173\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u51c6\u786e\u63cf\u8ff0IRS\u5143\u4ef6\u7684\u63a5\u6536\u548c\u53cd\u5c04\u7279\u6027\u3002\u9488\u5bf9\u5355\u76ee\u6807\u4f4d\u7f6e\u60c5\u51b5\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316(PSO)\u7684\u7b97\u6cd5\uff1b\u9488\u5bf9\u533a\u57df\u8986\u76d6\u589e\u5f3a\u60c5\u51b5\uff0c\u91c7\u7528\u5e26\u96f6\u70b9\u68c0\u6d4b\u7684\u53cc\u5faa\u73afPSO\u8fed\u4ee3\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u53ef\u65cb\u8f6cIRS\u8bbe\u8ba1\u5728\u4e0d\u540c\u7cfb\u7edf\u8bbe\u7f6e\u4e0b\u76f8\u6bd4\u5404\u79cd\u57fa\u51c6\u65b9\u6848\u5b9e\u73b0\u4e86\u663e\u8457\u7684SNR\u6539\u8fdb\u3002", "conclusion": "\u53ef\u65cb\u8f6cIRS\u901a\u8fc7\u4f18\u5316\u65cb\u8f6c\u89d2\u5ea6\u80fd\u591f\u6709\u6548\u63d0\u5347\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u533a\u57df\u8986\u76d6\u6027\u80fd\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u6a21\u578b\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2511.09597", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.09597", "abs": "https://arxiv.org/abs/2511.09597", "authors": ["Rangel Daroya", "Subhransu Maji"], "title": "SuperRivolution: Fine-Scale Rivers from Coarse Temporal Satellite Imagery", "comment": null, "summary": "Satellite missions provide valuable optical data for monitoring rivers at diverse spatial and temporal scales. However, accessibility remains a challenge: high-resolution imagery is ideal for fine-grained monitoring but is typically scarce and expensive compared to low-resolution imagery. To address this gap, we introduce SuperRivolution, a framework that improves river segmentation resolution by leveraging information from time series of low-resolution satellite images. We contribute a new benchmark dataset of 9,810 low-resolution temporal images paired with high-resolution labels from an existing river monitoring dataset. Using this benchmark, we investigate multiple strategies for river segmentation, including ensembling single-image models, applying image super-resolution, and developing end-to-end models trained on temporal sequences. SuperRivolution significantly outperforms single-image methods and baseline temporal approaches, narrowing the gap with supervised high-resolution models. For example, the F1 score for river segmentation improves from 60.9% to 80.5%, while the state-of-the-art model operating on high-resolution images achieves 94.1%. Similar improvements are also observed in river width estimation tasks. Our results highlight the potential of publicly available low-resolution satellite archives for fine-scale river monitoring.", "AI": {"tldr": "SuperRivolution\u6846\u67b6\u5229\u7528\u4f4e\u5206\u8fa8\u7387\u536b\u661f\u56fe\u50cf\u65f6\u95f4\u5e8f\u5217\u63d0\u5347\u6cb3\u6d41\u5206\u5272\u7cbe\u5ea6\uff0c\u663e\u8457\u7f29\u5c0f\u4e0e\u9ad8\u5206\u8fa8\u7387\u6a21\u578b\u7684\u5dee\u8ddd\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u536b\u661f\u56fe\u50cf\u7a00\u5c11\u4e14\u6602\u8d35\uff0c\u800c\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\u66f4\u6613\u83b7\u53d6\u4f46\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u65b9\u6cd5\u4ece\u4f4e\u5206\u8fa8\u7387\u65f6\u95f4\u5e8f\u5217\u4e2d\u63d0\u53d6\u7cbe\u7ec6\u6cb3\u6d41\u4fe1\u606f\u3002", "method": "\u63d0\u51faSuperRivolution\u6846\u67b6\uff0c\u4f7f\u75289,810\u5f20\u4f4e\u5206\u8fa8\u7387\u65f6\u95f4\u5e8f\u5217\u56fe\u50cf\u4e0e\u9ad8\u5206\u8fa8\u7387\u6807\u7b7e\u914d\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u4e86\u5355\u56fe\u50cf\u6a21\u578b\u96c6\u6210\u3001\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u548c\u7aef\u5230\u7aef\u65f6\u5e8f\u6a21\u578b\u7b49\u591a\u79cd\u7b56\u7565\u3002", "result": "\u6cb3\u6d41\u5206\u5272F1\u5206\u6570\u4ece60.9%\u63d0\u5347\u81f380.5%\uff0c\u63a5\u8fd1\u9ad8\u5206\u8fa8\u7387\u6a21\u578b\u768494.1%\uff1b\u6cb3\u6d41\u5bbd\u5ea6\u4f30\u8ba1\u4efb\u52a1\u4e5f\u6709\u7c7b\u4f3c\u6539\u8fdb\u3002", "conclusion": "\u516c\u5f00\u53ef\u7528\u7684\u4f4e\u5206\u8fa8\u7387\u536b\u661f\u6863\u6848\u5728\u7cbe\u7ec6\u5c3a\u5ea6\u6cb3\u6d41\u76d1\u6d4b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.10073", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10073", "abs": "https://arxiv.org/abs/2511.10073", "authors": ["Yuhao Ren", "Yiting Liu", "Yanfei Zhou", "Zhiyu Zheng", "Li Shang", "Fan Yang", "Zhiang Wang"], "title": "Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement", "comment": null, "summary": "Global placement is a critical step with high computational complexity in VLSI physical design. Modern analytical placers formulate the placement problem as a nonlinear optimization, where initialization strongly affects both convergence behavior and final placement quality. However, existing initialization methods exhibit a trade-off: area-aware initializers account for cell areas but are computationally expensive and can dominate total runtime, while fast point-based initializers ignore cell area, leading to a modeling gap that impairs convergence and solution quality. We propose a lightweight co-optimization framework that bridges this initialization gap through two strategies. First, an area-hint refinement initializer incorporates heuristic cell area information into a signed graph signal by augmenting the netlist graph with virtual nodes and negative-weight edges, yielding an area-aware and spectrally smooth placement initialization. Second, a macro-schedule placement procedure progressively restores area constraints, enabling a smooth transition from the refined initializer to the full area-aware objective and producing high-quality placement results. We evaluate the framework on macro-heavy ISPD2005 academic benchmarks and two real-world industrial designs across two technology nodes (12 cases in total). Experimental results show that our method consistently improves half-perimeter wirelength (HPWL) over point-based initializers in 11 out of 12 cases, achieving up to 2.2% HPWL reduction, while running approximately 100 times faster than the state-of-the-art area-aware initializer.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u534f\u540c\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u9762\u79ef\u63d0\u793a\u7ec6\u5316\u521d\u59cb\u5316\u548c\u5b8f\u8c03\u5ea6\u5e03\u5c40\u7a0b\u5e8f\uff0c\u5728VLSI\u5168\u5c40\u5e03\u5c40\u4e2d\u5e73\u8861\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u5e03\u5c40\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u5e03\u5c40\u521d\u59cb\u5316\u65b9\u6cd5\u5b58\u5728\u6743\u8861\uff1a\u9762\u79ef\u611f\u77e5\u521d\u59cb\u5668\u8ba1\u7b97\u6602\u8d35\uff0c\u800c\u57fa\u4e8e\u70b9\u7684\u5feb\u901f\u521d\u59cb\u5668\u5ffd\u7565\u5355\u5143\u9762\u79ef\uff0c\u5f71\u54cd\u6536\u655b\u6027\u548c\u89e3\u8d28\u91cf\u3002", "method": "1. \u9762\u79ef\u63d0\u793a\u7ec6\u5316\u521d\u59cb\u5668\uff1a\u901a\u8fc7\u865a\u62df\u8282\u70b9\u548c\u8d1f\u6743\u91cd\u8fb9\u5c06\u542f\u53d1\u5f0f\u5355\u5143\u9762\u79ef\u4fe1\u606f\u6574\u5408\u5230\u6709\u7b26\u53f7\u56fe\u4fe1\u53f7\u4e2d\uff1b2. \u5b8f\u8c03\u5ea6\u5e03\u5c40\u7a0b\u5e8f\uff1a\u9010\u6b65\u6062\u590d\u9762\u79ef\u7ea6\u675f\uff0c\u5b9e\u73b0\u4ece\u7ec6\u5316\u521d\u59cb\u5668\u5230\u5b8c\u6574\u9762\u79ef\u611f\u77e5\u76ee\u6807\u7684\u5e73\u6ed1\u8fc7\u6e21\u3002", "result": "\u572812\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c11\u4e2a\u6848\u4f8b\u7684HPWL\u76f8\u6bd4\u57fa\u4e8e\u70b9\u521d\u59cb\u5668\u6709\u6539\u5584\uff0c\u6700\u9ad8\u51cf\u5c112.2%\uff0c\u8fd0\u884c\u901f\u5ea6\u6bd4\u6700\u5148\u8fdb\u7684\u9762\u79ef\u611f\u77e5\u521d\u59cb\u5668\u5feb\u7ea6100\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u5f25\u5408\u4e86\u521d\u59cb\u5316\u5dee\u8ddd\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5e03\u5c40\u8d28\u91cf\u3002"}}
{"id": "2511.09604", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.09604", "abs": "https://arxiv.org/abs/2511.09604", "authors": ["Shiva Hanifi", "Sasan Jafarnejad", "Marc K\u00f6ntges", "Andrej Wentnagel", "Andreas Kokkas", "Raphael Frank"], "title": "Bridging the Data Gap: Spatially Conditioned Diffusion Model for Anomaly Generation in Photovoltaic Electroluminescence Images", "comment": "8 pages, 4 figures", "summary": "Reliable anomaly detection in photovoltaic (PV) modules is critical for maintaining solar energy efficiency. However, developing robust computer vision models for PV inspection is constrained by the scarcity of large-scale, diverse, and balanced datasets. This study introduces PV-DDPM, a spatially conditioned denoising diffusion probabilistic model that generates anomalous electroluminescence (EL) images across four PV cell types: multi-crystalline silicon (multi-c-Si), mono-crystalline silicon (mono-c-Si), half-cut multi-c-Si, and interdigitated back contact (IBC) with dogbone interconnect. PV-DDPM enables controlled synthesis of single-defect and multi-defect scenarios by conditioning on binary masks representing structural features and defect positions. To the best of our knowledge, this is the first framework that jointly models multiple PV cell types while supporting simultaneous generation of diverse anomaly types. We also introduce E-SCDD, an enhanced version of the SCDD dataset, comprising 1,000 pixel-wise annotated EL images spanning 30 semantic classes, and 1,768 unlabeled synthetic samples. Quantitative evaluation shows our generated images achieve a Fr\u00e9chet Inception Distance (FID) of 4.10 and Kernel Inception Distance (KID) of 0.0023 $\\pm$ 0.0007 across all categories. Training the vision--language anomaly detection model AA-CLIP on E-SCDD, compared to the SCDD dataset, improves pixel-level AUC and average precision by 1.70 and 8.34 points, respectively.", "AI": {"tldr": "PV-DDPM\u662f\u4e00\u4e2a\u7a7a\u95f4\u6761\u4ef6\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u5149\u4f0f\u7535\u6c60\u7684\u5f02\u5e38\u7535\u81f4\u53d1\u5149\u56fe\u50cf\uff0c\u652f\u6301\u56db\u79cd\u7535\u6c60\u7c7b\u578b\u548c\u591a\u79cd\u7f3a\u9677\u7c7b\u578b\u7684\u540c\u65f6\u751f\u6210\u3002", "motivation": "\u5149\u4f0f\u6a21\u5757\u7684\u53ef\u9760\u5f02\u5e38\u68c0\u6d4b\u5bf9\u7ef4\u6301\u592a\u9633\u80fd\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u548c\u5e73\u8861\u7684\u6570\u636e\u96c6\u9650\u5236\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u4f7f\u7528\u7a7a\u95f4\u6761\u4ef6\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(PV-DDPM)\uff0c\u901a\u8fc7\u4e8c\u5143\u63a9\u7801\u63a7\u5236\u7ed3\u6784\u7279\u5f81\u548c\u7f3a\u9677\u4f4d\u7f6e\uff0c\u751f\u6210\u5355\u7f3a\u9677\u548c\u591a\u7f3a\u9677\u573a\u666f\u7684\u5f02\u5e38\u7535\u81f4\u53d1\u5149\u56fe\u50cf\u3002", "result": "\u751f\u6210\u7684\u56fe\u50cf\u5728\u6240\u6709\u7c7b\u522b\u4e2d\u5b9e\u73b0\u4e86FID 4.10\u548cKID 0.0023\u00b10.0007\u7684\u5b9a\u91cf\u8bc4\u4f30\u7ed3\u679c\u3002\u4f7f\u7528E-SCDD\u6570\u636e\u96c6\u8bad\u7ec3AA-CLIP\u6a21\u578b\uff0c\u76f8\u6bd4SCDD\u6570\u636e\u96c6\uff0c\u50cf\u7d20\u7ea7AUC\u548c\u5e73\u5747\u7cbe\u5ea6\u5206\u522b\u63d0\u9ad8\u4e861.70\u548c8.34\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "PV-DDPM\u662f\u9996\u4e2a\u8054\u5408\u5efa\u6a21\u591a\u79cd\u5149\u4f0f\u7535\u6c60\u7c7b\u578b\u5e76\u652f\u6301\u540c\u65f6\u751f\u6210\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\u7684\u6846\u67b6\uff0cE-SCDD\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347\u4e86\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.10178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10178", "abs": "https://arxiv.org/abs/2511.10178", "authors": ["Chandrima Thakur", "Priyanka Ghosh", "Rashmita Badhai", "Sumit Kundu"], "title": "NOMA-Enabled Dual-IRS Relay Network Integrated with Ambient Backscatter Communication", "comment": null, "summary": "This paper analyzes a NOMA-enabled dual-Intelligent Reflecting Surface (IRS) relay network integrated with Ambient Backscatter (BS) communication. The system comprises a source, an energy-constrained relay with energy harvesting (EH) and BS capabilities, two NOMA users, and a BS node. The relay adopts a time-switching relaying (TSR) protocol to harvest energy and forward information ,while simultaneously enabling BS-based communication. Two IRS are deployed to enhance the S to R and R to (D1, D2) links under blockage conditions. Closed-form expressions for the Outage Probability (OP) and Throughput of both the main communication links and the BS-assisted secondary links are derived. Furthermore, throughput is analyzed under varying system parameters, including power allocation factors, reflection efficiency, IRS elements, and transmission rate. Monte Carlo simulations validate the analytical results. numerical findings reveal critical trade-offs between the main and RS links. The proposed framework provides useful insights for designing reliable and energy-efficient NOMA-IRS-aided BS networks for future IoT applications.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u652f\u6301NOMA\u7684\u53cc\u667a\u80fd\u53cd\u5c04\u9762\u4e2d\u7ee7\u7f51\u7edc\u4e0e\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u7684\u96c6\u6210\u7cfb\u7edf\uff0c\u5305\u542b\u6e90\u8282\u70b9\u3001\u80fd\u91cf\u53d7\u9650\u4e2d\u7ee7\u3001\u4e24\u4e2aNOMA\u7528\u6237\u548cBS\u8282\u70b9\uff0c\u4f7f\u7528\u65f6\u95f4\u5207\u6362\u4e2d\u7ee7\u534f\u8bae\u540c\u65f6\u8fdb\u884c\u80fd\u91cf\u6536\u96c6\u548c\u4fe1\u606f\u8f6c\u53d1\u3002", "motivation": "\u4e3a\u672a\u6765\u7269\u8054\u7f51\u5e94\u7528\u8bbe\u8ba1\u53ef\u9760\u4e14\u8282\u80fd\u7684NOMA-IRS\u8f85\u52a9BS\u7f51\u7edc\uff0c\u89e3\u51b3\u80fd\u91cf\u53d7\u9650\u4e2d\u7ee7\u7684\u901a\u4fe1\u95ee\u9898\uff0c\u5e76\u5229\u7528IRS\u589e\u5f3a\u94fe\u8def\u6027\u80fd\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u5207\u6362\u4e2d\u7ee7\u534f\u8bae\uff0c\u90e8\u7f72\u4e24\u4e2aIRS\u589e\u5f3a\u94fe\u8def\uff0c\u63a8\u5bfc\u4e86\u4e2d\u65ad\u6982\u7387\u548c\u541e\u5410\u91cf\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1\u5206\u6790\u7ed3\u679c\u3002", "result": "\u6570\u503c\u7ed3\u679c\u63ed\u793a\u4e86\u4e3b\u94fe\u8def\u548cBS\u8f85\u52a9\u94fe\u8def\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u5173\u7cfb\uff0c\u7cfb\u7edf\u6027\u80fd\u53d7\u529f\u7387\u5206\u914d\u56e0\u5b50\u3001\u53cd\u5c04\u6548\u7387\u3001IRS\u5143\u7d20\u6570\u91cf\u548c\u4f20\u8f93\u901f\u7387\u7b49\u53c2\u6570\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u8bbe\u8ba1\u672a\u6765\u7269\u8054\u7f51\u5e94\u7528\u7684\u53ef\u9760\u8282\u80fdNOMA-IRS\u8f85\u52a9BS\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u7528\u89c1\u89e3\u3002"}}
{"id": "2511.09605", "categories": ["eess.IV", "cs.AI", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.09605", "abs": "https://arxiv.org/abs/2511.09605", "authors": ["Johannes Kiechle", "Stefan M. Fischer", "Daniel M. Lang", "Cosmin I. Bercea", "Matthew J. Nyflot", "Lina Felsner", "Julia A. Schnabel", "Jan C. Peeken"], "title": "TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks", "comment": "Preprint submitted to Medical Image Analysis (MedIA)", "summary": "The growing number of medical tomography examinations has necessitated the development of automated methods capable of extracting comprehensive imaging features to facilitate downstream tasks such as tumor characterization, while assisting physicians in managing their growing workload. However, 3D medical image classification remains a challenging task due to the complex spatial relationships and long-range dependencies inherent in volumetric data. Training models from scratch suffers from low data regimes, and the absence of 3D large-scale multimodal datasets has limited the development of 3D medical imaging foundation models. Recent studies, however, have highlighted the potential of 2D vision foundation models, originally trained on natural images, as powerful feature extractors for medical image analysis. Despite these advances, existing approaches that apply 2D models to 3D volumes via slice-based decomposition remain suboptimal. Conventional volume slicing strategies, which rely on canonical planes such as axial, sagittal, or coronal, may inadequately capture the spatial extent of target structures when these are misaligned with standardized viewing planes. Furthermore, existing slice-wise aggregation strategies rarely account for preserving the volumetric structure, resulting in a loss of spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer.", "AI": {"tldr": "\u63d0\u51faTomoGraphView\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u65b9\u5411\u4f53\u79ef\u5207\u7247\u548c\u7403\u5f62\u56fe\u7279\u5f81\u805a\u5408\u89e3\u51b33D\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u4e2d\u4f20\u7edf\u5207\u7247\u65b9\u6cd5\u7a7a\u95f4\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\u3002", "motivation": "3D\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u9762\u4e34\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u548c\u957f\u7a0b\u4f9d\u8d56\u7684\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e2D\u57fa\u7840\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u4f53\u79ef\u5207\u7247\u65f6\u65e0\u6cd5\u5145\u5206\u6355\u6349\u76ee\u6807\u7ed3\u6784\u7684\u7a7a\u95f4\u8303\u56f4\uff0c\u4e14\u5207\u7247\u805a\u5408\u7b56\u7565\u7f3a\u4e4f\u7a7a\u95f4\u8fde\u8d2f\u6027\u3002", "method": "\u7ed3\u5408\u5168\u65b9\u5411\u4f53\u79ef\u5207\u7247\u548c\u7403\u5f62\u56fe\u7279\u5f81\u805a\u5408\uff0c\u901a\u8fc7\u591a\u65b9\u5411\u5207\u7247\u6355\u6349\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u4fe1\u606f\uff0c\u5e76\u4f7f\u7528\u56fe\u7ed3\u6784\u4fdd\u6301\u5207\u7247\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\u3002", "result": "\u5f00\u53d1\u4e86\u5f00\u6e90\u4ee3\u7801\u5e93\u548c\u7528\u6237\u53cb\u597d\u7684\u5168\u65b9\u5411\u5207\u7247\u5de5\u5177\uff0c\u4e3a3D\u533b\u5b66\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "TomoGraphView\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5207\u7247\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a3D\u533b\u5b66\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002"}}
{"id": "2511.10205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10205", "abs": "https://arxiv.org/abs/2511.10205", "authors": ["Martin J. W. Schubert"], "title": "High Order Delta-Sigma Modulation with Positive Integer Coefficients", "comment": "4 pages, 11 figures. This paper was rejected by the 2025 IEEE SiPS Workshop, mainly because the idea was not sufficiently developed, e.g. regarding stability limits. Presumably for this reason, the German Federal Office for Economic Affairs and Export Control that monitors issues of signal processing, has approved the publication", "summary": "This document proposes binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback and distributed feedforward input and multi-bit output. It is demonstrated that high orders can be achieved with these coefficients. Accuracy requirements concerning the coefficients are discussed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7528\u4e8e\u7ea7\u8054Delta-Sigma\u8c03\u5236\u5668\u7ed3\u6784\u7684\u4e8c\u9879\u5f0f\u6574\u6570\u53c2\u6570\uff0c\u8be5\u7ed3\u6784\u5177\u6709\u5206\u5e03\u5f0f\u53cd\u9988\u548c\u5206\u5e03\u5f0f\u524d\u9988\u8f93\u5165\u4ee5\u53ca\u591a\u6bd4\u7279\u8f93\u51fa", "motivation": "\u5b9e\u73b0\u9ad8\u9636Delta-Sigma\u8c03\u5236\u5668\u8bbe\u8ba1\uff0c\u540c\u65f6\u7b80\u5316\u7cfb\u6570\u9009\u62e9\u8fc7\u7a0b", "method": "\u4f7f\u7528\u4e8c\u9879\u5f0f\u6574\u6570\u53c2\u6570\u914d\u7f6e\u7ea7\u8054Delta-Sigma\u8c03\u5236\u5668\u7ed3\u6784\uff0c\u8be5\u7ed3\u6784\u5305\u542b\u5206\u5e03\u5f0f\u53cd\u9988\u3001\u5206\u5e03\u5f0f\u524d\u9988\u8f93\u5165\u548c\u591a\u6bd4\u7279\u8f93\u51fa", "result": "\u8bc1\u660e\u4e86\u4f7f\u7528\u8fd9\u4e9b\u7cfb\u6570\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u9636\u8c03\u5236\u5668\uff0c\u5e76\u8ba8\u8bba\u4e86\u7cfb\u6570\u7684\u7cbe\u5ea6\u8981\u6c42", "conclusion": "\u4e8c\u9879\u5f0f\u6574\u6570\u53c2\u6570\u4e3a\u7ea7\u8054Delta-Sigma\u8c03\u5236\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u9636\u6027\u80fd"}}
{"id": "2511.09609", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.09609", "abs": "https://arxiv.org/abs/2511.09609", "authors": ["Yini Li", "Nantheera Anantrasirichai"], "title": "TempRetinex: Retinex-based Unsupervised Enhancement for Low-light Video Under Diverse Lighting Conditions", "comment": null, "summary": "Videos inherently contain rich temporal information that provides complementary cues for low-light enhancement beyond what can be achieved with single images. We propose TempRetinex, a novel unsupervised Retinex-based framework that effectively exploits inter-frame correlations for video enhancement. To address the poor generalization of existing unsupervised methods under varying illumination, we introduce adaptive brightness adjustment (ABA) preprocessing that explicitly aligns lighting distributions across exposures. This significantly improves model robustness to diverse lighting scenarios and eases training optimization, leading to better denoising performance. For enhanced temporal coherence, we propose a multi-scale temporal consistency-aware loss to enforce multiscale similarity between consecutive frames, and an occlusion-aware masking technique to handle complex motions. We further incorporate a reverse inference strategy to refine unconverged frames and a self-ensemble (SE) mechanism to boost the denoising across diverse textures. Experiments demonstrate that TempRetinex achieves state-of-the-art performance in both perceptual quality and temporal consistency, achieving up to a 29.7% PSNR gain over prior methods.", "AI": {"tldr": "TempRetinex\u662f\u4e00\u4e2a\u57fa\u4e8eRetinex\u7684\u65e0\u76d1\u7763\u89c6\u9891\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u5e27\u95f4\u76f8\u5173\u6027\u3001\u81ea\u9002\u5e94\u4eae\u5ea6\u8c03\u6574\u3001\u591a\u5c3a\u5ea6\u65f6\u95f4\u4e00\u81f4\u6027\u635f\u5931\u548c\u81ea\u96c6\u6210\u673a\u5236\uff0c\u5728\u4f4e\u5149\u89c6\u9891\u589e\u5f3a\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89c6\u9891\u5305\u542b\u4e30\u5bcc\u7684\u65f6\u5e8f\u4fe1\u606f\uff0c\u4e3a\u4f4e\u5149\u589e\u5f3a\u63d0\u4f9b\u4e86\u6bd4\u5355\u5f20\u56fe\u50cf\u66f4\u591a\u7684\u4e92\u8865\u7ebf\u7d22\u3002\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\u5728\u4e0d\u540c\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u5904\u7406\u591a\u6837\u5316\u7684\u5149\u7167\u573a\u666f\u548c\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "method": "1) \u81ea\u9002\u5e94\u4eae\u5ea6\u8c03\u6574\u9884\u5904\u7406\u5bf9\u9f50\u4e0d\u540c\u66dd\u5149\u4e0b\u7684\u5149\u7167\u5206\u5e03\uff1b2) \u591a\u5c3a\u5ea6\u65f6\u95f4\u4e00\u81f4\u6027\u635f\u5931\u786e\u4fdd\u8fde\u7eed\u5e27\u95f4\u7684\u591a\u5c3a\u5ea6\u76f8\u4f3c\u6027\uff1b3) \u906e\u6321\u611f\u77e5\u63a9\u7801\u6280\u672f\u5904\u7406\u590d\u6742\u8fd0\u52a8\uff1b4) \u53cd\u5411\u63a8\u7406\u7b56\u7565\u4f18\u5316\u672a\u6536\u655b\u5e27\uff1b5) \u81ea\u96c6\u6210\u673a\u5236\u63d0\u5347\u4e0d\u540c\u7eb9\u7406\u7684\u964d\u566a\u6548\u679c\u3002", "result": "\u5728\u611f\u77e5\u8d28\u91cf\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5PSNR\u63d0\u5347\u9ad8\u8fbe29.7%\u3002", "conclusion": "TempRetinex\u901a\u8fc7\u6709\u6548\u5229\u7528\u65f6\u5e8f\u4fe1\u606f\u548c\u521b\u65b0\u7684\u9884\u5904\u7406\u53ca\u635f\u5931\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u76d1\u7763\u89c6\u9891\u4f4e\u5149\u589e\u5f3a\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.10302", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10302", "abs": "https://arxiv.org/abs/2511.10302", "authors": ["Karim Nasreddine", "Christo Kurisummoottil Thomas", "Walid Saad"], "title": "Semantic Communication with Hopfield Memories", "comment": "6 pages", "summary": "Traditional joint source-channel coding employs static learned semantic representations that cannot dynamically adapt to evolving source distributions. Shared semantic memories between transmitter and receiver can potentially enable bandwidth savings by reusing previously transmitted concepts as context to reconstruct data, but require effective mechanisms to determine when current content is similar enough to stored patterns. However, existing hard quantization approaches based on variational autoencoders are limited by frequent memory updates even under small changes in data dynamics, which leads to inefficient usage of bandwidth.To address this challenge, in this paper, a memory-augmented semantic communication framework is proposed where both transmitter and receiver maintain a shared memory of semantic concepts using modern Hopfield networks (MHNs). The proposed framework employs soft attention-based retrieval that smoothly adjusts stored semantic prototype weights as data evolves that enables stable matching decisions under gradual data dynamics. A joint optimization of encoder, decoder, and memory retrieval\n  mechanism is performed with the objective of maximizing a reasoning capacity metric that quantifies semantic efficiency as the product of memory reuse rate and compression ratio. Theoretical analysis establishes the fundamental rate-distortion-reuse tradeoff and proves that soft retrieval reduces unnecessary transmissions compared to hard quantization under bounded semantic drift. Extensive simulations over diverse video scenarios demonstrate that the proposed MHN-based approach achieves substantial bit reductions around 14% on average and up to 70% in scenarios with gradual content changes compared to baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73b0\u4ee3Hopfield\u7f51\u7edc\u7684\u5185\u5b58\u589e\u5f3a\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u8f6f\u6ce8\u610f\u529b\u68c0\u7d22\u673a\u5236\u52a8\u6001\u8c03\u6574\u8bed\u4e49\u539f\u578b\u6743\u91cd\uff0c\u5728\u6570\u636e\u52a8\u6001\u53d8\u5316\u65f6\u5b9e\u73b0\u7a33\u5b9a\u7684\u5339\u914d\u51b3\u7b56\uff0c\u663e\u8457\u51cf\u5c11\u4f20\u8f93\u6bd4\u7279\u6570\u3002", "motivation": "\u4f20\u7edf\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u4f7f\u7528\u9759\u6001\u8bed\u4e49\u8868\u793a\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u6e90\u5206\u5e03\u3002\u73b0\u6709\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u786c\u91cf\u5316\u65b9\u6cd5\u5728\u6570\u636e\u52a8\u6001\u53d8\u5316\u65f6\u9891\u7e41\u66f4\u65b0\u5185\u5b58\uff0c\u5bfc\u81f4\u5e26\u5bbd\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528\u73b0\u4ee3Hopfield\u7f51\u7edc\u5728\u53d1\u5c04\u5668\u548c\u63a5\u6536\u5668\u4e4b\u95f4\u7ef4\u62a4\u5171\u4eab\u8bed\u4e49\u6982\u5ff5\u5185\u5b58\uff0c\u91c7\u7528\u8f6f\u6ce8\u610f\u529b\u68c0\u7d22\u673a\u5236\u5e73\u6ed1\u8c03\u6574\u5b58\u50a8\u7684\u8bed\u4e49\u539f\u578b\u6743\u91cd\uff0c\u5e76\u8054\u5408\u4f18\u5316\u7f16\u7801\u5668\u3001\u89e3\u7801\u5668\u548c\u5185\u5b58\u68c0\u7d22\u673a\u5236\u3002", "result": "\u5728\u591a\u6837\u5316\u89c6\u9891\u573a\u666f\u7684\u5e7f\u6cdb\u4eff\u771f\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8eMHN\u7684\u65b9\u6cd5\u5e73\u5747\u5b9e\u73b0\u4e86\u7ea614%\u7684\u6bd4\u7279\u51cf\u5c11\uff0c\u5728\u6e10\u8fdb\u5185\u5bb9\u53d8\u5316\u573a\u666f\u4e2d\u6700\u9ad8\u53ef\u8fbe70%\u7684\u6bd4\u7279\u51cf\u5c11\u3002", "conclusion": "\u8f6f\u68c0\u7d22\u76f8\u6bd4\u786c\u91cf\u5316\u5728\u6709\u9650\u8bed\u4e49\u6f02\u79fb\u4e0b\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u4f20\u8f93\uff0c\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u57fa\u672c\u7684\u7387-\u5931\u771f-\u91cd\u7528\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2511.09734", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09734", "abs": "https://arxiv.org/abs/2511.09734", "authors": ["Huanhuan Zhao", "Connor Vernachio", "Laxmi Bhurtel", "Wooin Yang", "Ruben Millan-Solsona", "Spenser R. Brown", "Marti Checa", "Komal Sharma Agrawal", "Adam M. Guss", "Liam Collins", "Wonhee Ko", "Arpan Biswas"], "title": "A Fourier-Based Global Denoising Model for Smart Artifacts Removing of Microscopy Images", "comment": "21 pages, 9 figures", "summary": "Microscopy such as Scanning Tunneling Microscopy (STM), Atomic Force Microscopy (AFM) and Scanning Electron Microscopy (SEM) are essential tools in material imaging at micro- and nanoscale resolutions to extract physical knowledge and materials structure-property relationships. However, tuning microscopy controls (e.g. scanning speed, current setpoint, tip bias etc.) to obtain a high-quality of images is a non-trivial and time-consuming effort. On the other hand, with sub-standard images, the key features are not accurately discovered due to noise and artifacts, leading to erroneous analysis. Existing denoising models mostly build on generalizing the weak signals as noises while the strong signals are enhanced as key features, which is not always the case in microscopy images, thus can completely erase a significant amount of hidden physical information. To address these limitations, we propose a global denoising model (GDM) to smartly remove artifacts of microscopy images while preserving weaker but physically important features. The proposed model is developed based on 1) first designing a two-imaging input channel of non-pair and goal specific pre-processed images with user-defined trade-off information between two channels and 2) then integrating a loss function of pixel- and fast Fourier-transformed (FFT) based on training the U-net model. We compared the proposed GDM with the non-FFT denoising model over STM-generated images of Copper(Cu) and Silicon(Si) materials, AFM-generated Pantoea sp.YR343 bio-film images and SEM-generated plastic degradation images. We believe this proposed workflow can be extended to improve other microscopy image quality and will benefit the experimentalists with the proposed design flexibility to smartly tune via domain-experts preferences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u5c40\u53bb\u566a\u6a21\u578b(GDM)\uff0c\u901a\u8fc7\u53cc\u901a\u9053\u8f93\u5165\u548cFFT\u635f\u5931\u51fd\u6570\uff0c\u5728\u53bb\u9664\u663e\u5fae\u955c\u56fe\u50cf\u4f2a\u5f71\u7684\u540c\u65f6\u4fdd\u7559\u5f31\u4f46\u91cd\u8981\u7684\u7269\u7406\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u53bb\u566a\u6a21\u578b\u901a\u5e38\u5c06\u5f31\u4fe1\u53f7\u89c6\u4e3a\u566a\u58f0\u800c\u589e\u5f3a\u5f3a\u4fe1\u53f7\uff0c\u8fd9\u5728\u663e\u5fae\u955c\u56fe\u50cf\u4e2d\u4f1a\u64e6\u9664\u91cd\u8981\u7684\u7269\u7406\u4fe1\u606f\u3002\u663e\u5fae\u955c\u53c2\u6570\u8c03\u4f18\u8017\u65f6\u4e14\u56f0\u96be\uff0c\u4f4e\u8d28\u91cf\u56fe\u50cf\u4f1a\u5bfc\u81f4\u5206\u6790\u9519\u8bef\u3002", "method": "1) \u8bbe\u8ba1\u53cc\u6210\u50cf\u8f93\u5165\u901a\u9053\uff0c\u5305\u542b\u975e\u914d\u5bf9\u548c\u7279\u5b9a\u76ee\u6807\u9884\u5904\u7406\u56fe\u50cf\uff0c\u7528\u6237\u53ef\u5b9a\u4e49\u901a\u9053\u95f4\u6743\u8861\uff1b2) \u96c6\u6210\u57fa\u4e8e\u50cf\u7d20\u548c\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362(FFT)\u7684\u635f\u5931\u51fd\u6570\u8bad\u7ec3U-net\u6a21\u578b\u3002", "result": "\u4e0e\u65e0FFT\u53bb\u566a\u6a21\u578b\u76f8\u6bd4\uff0cGDM\u5728STM\u751f\u6210\u7684Cu\u548cSi\u6750\u6599\u56fe\u50cf\u3001AFM\u751f\u6210\u7684Pantoea sp.YR343\u751f\u7269\u819c\u56fe\u50cf\u548cSEM\u751f\u6210\u7684\u5851\u6599\u964d\u89e3\u56fe\u50cf\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u53ef\u6269\u5c55\u5230\u6539\u5584\u5176\u4ed6\u663e\u5fae\u955c\u56fe\u50cf\u8d28\u91cf\uff0c\u4e3a\u5b9e\u9a8c\u4eba\u5458\u63d0\u4f9b\u8bbe\u8ba1\u7075\u6d3b\u6027\uff0c\u53ef\u6839\u636e\u9886\u57df\u4e13\u5bb6\u504f\u597d\u667a\u80fd\u8c03\u6574\u3002"}}
{"id": "2511.10526", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10526", "abs": "https://arxiv.org/abs/2511.10526", "authors": ["Andrea Jung", "Paul Schwarzbach", "Oliver Michler"], "title": "Evaluation of Grid-based Uncertainty Propagation for Collaborative Self-Calibration in Indoor Positioning Systems", "comment": null, "summary": "Radio-based localization systems conventionally require stationary reference points (e.g. anchors) with precisely surveyed positions, making deployment time-consuming and costly. This paper presents an empirical evaluation of collaborative self-calibration for Ultra-Wideband (UWB) networks, extending a discrete Bayesian approach based on grid-based uncertainty propagation. The enhanced algorithm reduces measurement availability requirements while maintaining positioning accuracy through probabilistic state estimation. We validate the approach using real-world data from controlled indoor UWB network experiments with 12 nodes in a static environment. Experimental evaluation demonstrates 0.28~m mean ranging error under line-of-sight conditions and 1.11~m overall ranging error across mixed propagation scenarios, achieving sub-meter positioning accuracy. Results demonstrate the algorithm's robustness to measurement noise and partial connectivity scenarios typical in industrial deployments. The findings contribute to automated UWB network initialization for indoor positioning applications, reducing infrastructure dependency compared to manual anchor calibration procedures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u6563\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u534f\u4f5c\u5f0fUWB\u7f51\u7edc\u81ea\u6821\u51c6\u7b97\u6cd5\uff0c\u901a\u8fc7\u6982\u7387\u72b6\u6001\u4f30\u8ba1\u964d\u4f4e\u4e86\u5bf9\u6d4b\u91cf\u53ef\u7528\u6027\u7684\u8981\u6c42\uff0c\u5728\u9759\u6001\u5ba4\u5185\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u4e9a\u7c73\u7ea7\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u65e0\u7ebf\u7535\u7684\u5b9a\u4f4d\u7cfb\u7edf\u9700\u8981\u7cbe\u786e\u6d4b\u91cf\u4f4d\u7f6e\u7684\u56fa\u5b9a\u53c2\u8003\u70b9\uff08\u951a\u70b9\uff09\uff0c\u90e8\u7f72\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u81ea\u52a8\u5316\u7684\u7f51\u7edc\u521d\u59cb\u5316\u65b9\u6cd5\u4ee5\u51cf\u5c11\u5bf9\u57fa\u7840\u8bbe\u65bd\u7684\u4f9d\u8d56\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u4e8e\u7f51\u683c\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u7684\u79bb\u6563\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u901a\u8fc7\u6982\u7387\u72b6\u6001\u4f30\u8ba1\u8fdb\u884c\u534f\u4f5c\u5f0f\u81ea\u6821\u51c6\uff0c\u572812\u4e2a\u8282\u70b9\u7684\u9759\u6001\u5ba4\u5185UWB\u7f51\u7edc\u4e2d\u8fdb\u884c\u4e86\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u3002", "result": "\u5728\u89c6\u8ddd\u6761\u4ef6\u4e0b\u5e73\u5747\u6d4b\u8ddd\u8bef\u5dee\u4e3a0.28\u7c73\uff0c\u6df7\u5408\u4f20\u64ad\u573a\u666f\u4e0b\u603b\u4f53\u6d4b\u8ddd\u8bef\u5dee\u4e3a1.11\u7c73\uff0c\u5b9e\u73b0\u4e86\u4e9a\u7c73\u7ea7\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u7b97\u6cd5\u5bf9\u6d4b\u91cf\u566a\u58f0\u548c\u90e8\u5206\u8fde\u63a5\u573a\u666f\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5ba4\u5185\u5b9a\u4f4d\u5e94\u7528\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7684UWB\u7f51\u7edc\u521d\u59cb\u5316\u65b9\u6848\uff0c\u76f8\u6bd4\u624b\u52a8\u951a\u70b9\u6821\u51c6\u7a0b\u5e8f\u663e\u8457\u964d\u4f4e\u4e86\u57fa\u7840\u8bbe\u65bd\u4f9d\u8d56\u6027\u3002"}}
{"id": "2511.09898", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.09898", "abs": "https://arxiv.org/abs/2511.09898", "authors": ["Yitao Lin", "Dahai Dai", "Shilong Sun", "Yuchen Wu", "Bo Pang"], "title": "Electromagnetic Quantitative Inversion for Translationally Moving Targets via Phase Correlation Registration of Back-Projection Images", "comment": null, "summary": "An novel electromagnetic quantitative inversion scheme for translationally moving targets via phase correlation registration of back-projection (BP) images is proposed. Based on a time division multiplexing multiple-input multiple-output (TDM-MIMO) radar architecture, the scheme first achieves high-precision relative positioning of the target, then applies relative motion compensation to perform iterative inversion on multi-cycle MIMO measurement data, thereby reconstructing the target's electromagnetic parameters. As a general framework compatible with other mainstream inversion algorithms, we exemplify our approach by incorporating the classical cross-correlated contrast source inversion (CC-CSI) into iterative optimization step of the scheme, resulting in a new algorithm termed RMC-CC-CSI. Numerical and experimental results demonstrate that RMC-CC-CSI offers accelerated convergence, enhanced reconstruction fidelity, and improved noise immunity over conventional CC-CSI for stationary targets despite increased computational cost.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f4d\u76f8\u5173\u914d\u51c6\u7684\u53cd\u6295\u5f71\u56fe\u50cf\u7535\u78c1\u5b9a\u91cf\u53cd\u6f14\u65b9\u6848\uff0c\u7528\u4e8e\u5e73\u79fb\u8fd0\u52a8\u76ee\u6807\uff0c\u7ed3\u5408TDM-MIMO\u96f7\u8fbe\u67b6\u6784\u548c\u76f8\u5bf9\u8fd0\u52a8\u8865\u507f\uff0c\u5b9e\u73b0\u4e86\u52a0\u901f\u6536\u655b\u548c\u66f4\u9ad8\u91cd\u5efa\u7cbe\u5ea6\u7684RMC-CC-CSI\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7535\u78c1\u53cd\u6f14\u65b9\u6cd5\u5728\u5904\u7406\u8fd0\u52a8\u76ee\u6807\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u76ee\u6807\u76f8\u5bf9\u5b9a\u4f4d\u548c\u8fd0\u52a8\u8865\u507f\u95ee\u9898\u4ee5\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002", "method": "\u91c7\u7528TDM-MIMO\u96f7\u8fbe\u67b6\u6784\uff0c\u901a\u8fc7\u76f8\u4f4d\u76f8\u5173\u914d\u51c6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u76f8\u5bf9\u5b9a\u4f4d\uff0c\u5e94\u7528\u76f8\u5bf9\u8fd0\u52a8\u8865\u507f\u5bf9\u591a\u5468\u671fMIMO\u6570\u636e\u8fdb\u884c\u8fed\u4ee3\u53cd\u6f14\uff0c\u5e76\u5c06CC-CSI\u7b97\u6cd5\u6574\u5408\u5230\u8fed\u4ee3\u4f18\u5316\u6b65\u9aa4\u4e2d\u3002", "result": "\u6570\u503c\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRMC-CC-CSI\u76f8\u6bd4\u4f20\u7edfCC-CSI\u5728\u9759\u6b62\u76ee\u6807\u60c5\u51b5\u4e0b\u5177\u6709\u52a0\u901f\u6536\u655b\u3001\u589e\u5f3a\u91cd\u5efa\u4fdd\u771f\u5ea6\u548c\u6539\u5584\u566a\u58f0\u514d\u75ab\u80fd\u529b\uff0c\u5c3d\u7ba1\u8ba1\u7b97\u6210\u672c\u6709\u6240\u589e\u52a0\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u8fd0\u52a8\u76ee\u6807\u7535\u78c1\u5b9a\u91cf\u53cd\u6f14\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0cRMC-CC-CSI\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.09952", "categories": ["eess.IV", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.09952", "abs": "https://arxiv.org/abs/2511.09952", "authors": ["Jasleen Birdi", "Tamal Majumder", "Debanjan Halder", "Muskan Kularia", "Kedar Khare"], "title": "Learning phase diversity for solving ill-posed inverse problems in imaging", "comment": null, "summary": "Inverse problems in imaging are typically ill-posed and are usually solved by employing regularized optimization techniques. The usage of appropriate constraints can restrict the solution space, thus making it feasible for a reconstruction algorithm to find a meaningful solution. In recent years, deep network based ideas aimed at learning the end-to-end mapping between the raw measurements and the target image have gained popularity. In the learning approach, the functional relationship between the measured raw data and the solution image are learned by training a deep network with prior examples. While this approach allows one to significantly increase the real-time operational speed, it does not change the nature of the underlying ill-posed inverse problem. It is well-known that availability of diverse non-redundant data via additional measurements can generically improve the robustness of the reconstruction algorithms. The multiple data measurements, however, typically demand additional hardware and complex system setups that are not desirable. In this work, we note that in both incoherent and coherent optical imaging, the irradiance patterns corresponding to two phase diverse measurements associated with the same test object have implicit local correlation which may be learned. A physics informed data augmentation scheme is then described where a trained network is used for generating a phase diverse pseudo-data based on a ground truth data frame. The true data along with the augmented pesudo-data are observed to provide high quality inverse solutions with simpler reconstruction algorithms. We validate this approach for both incoherent and coherent optical imaging (or phase retrieval) configurations with vortex phase as a diversity mechanism. Our results may open new avenues for leaner high-fidelity computational imaging systems across a broad range of applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u7f51\u7edc\u751f\u6210\u76f8\u4f4d\u591a\u6837\u6027\u7684\u4f2a\u6570\u636e\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u63d0\u5347\u5149\u5b66\u6210\u50cf\u9006\u95ee\u9898\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u5149\u5b66\u6210\u50cf\u9006\u95ee\u9898\u4e2d\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u901f\u5ea6\u5feb\u4f46\u672a\u6539\u53d8\u95ee\u9898\u672c\u8d28\uff0c\u800c\u591a\u6d4b\u91cf\u6570\u636e\u9700\u8981\u590d\u6742\u786c\u4ef6\u8bbe\u7f6e\u7684\u77db\u76fe\u3002", "method": "\u5229\u7528\u76f8\u4f4d\u591a\u6837\u6027\u6d4b\u91cf\u7684\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u8bad\u7ec3\u7f51\u7edc\u4ece\u771f\u5b9e\u6570\u636e\u751f\u6210\u76f8\u4f4d\u591a\u6837\u6027\u4f2a\u6570\u636e\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u91cd\u5efa\u3002", "result": "\u5728\u975e\u76f8\u5e72\u548c\u76f8\u5e72\u5149\u5b66\u6210\u50cf\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u9006\u95ee\u9898\u89e3\uff0c\u4f7f\u7528\u66f4\u7b80\u5355\u7684\u91cd\u5efa\u7b97\u6cd5\u5373\u53ef\u83b7\u5f97\u826f\u597d\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u66f4\u7cbe\u7b80\u7684\u9ad8\u4fdd\u771f\u8ba1\u7b97\u6210\u50cf\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u79cd\u5149\u5b66\u6210\u50cf\u5e94\u7528\u3002"}}
{"id": "2511.10023", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.10023", "abs": "https://arxiv.org/abs/2511.10023", "authors": ["Farzan Saeedi", "Sanaz Keshvari", "Nasser Shoeibi"], "title": "Efficient Automated Diagnosis of Retinopathy of Prematurity by Customize CNN Models", "comment": null, "summary": "This paper encompasses an in-depth examination of Retinopathy of Prematurity (ROP) diagnosis, employing advanced deep learning methodologies. Our focus centers on refining and evaluating CNN-based approaches for precise and efficient ROP detection. We navigate the complexities of dataset curation, preprocessing strategies, and model architecture, aligning with research objectives encompassing model effectiveness, computational cost analysis, and time complexity assessment. Results underscore the supremacy of tailored CNN models over pre-trained counterparts, evident in heightened accuracy and F1-scores. Implementation of a voting system further enhances performance. Additionally, our study reveals the potential of the proposed customized CNN model to alleviate computational burdens associated with deep neural networks. Furthermore, we showcase the feasibility of deploying these models within dedicated software and hardware configurations, highlighting their utility as valuable diagnostic aids in clinical settings. In summary, our discourse significantly contributes to ROP diagnosis, unveiling the efficacy of deep learning models in enhancing diagnostic precision and efficiency.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5b9a\u5236\u5316CNN\u6a21\u578b\u8fdb\u884c\u65e9\u4ea7\u513f\u89c6\u7f51\u819c\u75c5\u53d8\u8bca\u65ad\uff0c\u76f8\u6bd4\u9884\u8bad\u7ec3\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u5e76\u901a\u8fc7\u6295\u7968\u7cfb\u7edf\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u6539\u8fdbROP\u8bca\u65ad\u7684\u7cbe\u786e\u6027\u548c\u6548\u7387\uff0c\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u9002\u7528\u4e8e\u4e34\u5e8a\u73af\u5883\u7684\u8bca\u65ad\u8f85\u52a9\u5de5\u5177\u3002", "method": "\u91c7\u7528\u5b9a\u5236\u5316CNN\u6a21\u578b\u67b6\u6784\uff0c\u7ed3\u5408\u6570\u636e\u96c6\u6574\u7406\u3001\u9884\u5904\u7406\u7b56\u7565\uff0c\u5e76\u5b9e\u65bd\u6295\u7968\u7cfb\u7edf\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9a\u5236CNN\u6a21\u578b\u5728\u51c6\u786e\u7387\u548cF1\u5206\u6570\u4e0a\u4f18\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u8ba1\u7b97\u8d1f\u62c5\u663e\u8457\u964d\u4f4e\uff0c\u6a21\u578b\u53ef\u5728\u4e13\u7528\u8f6f\u786c\u4ef6\u914d\u7f6e\u4e2d\u90e8\u7f72\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347ROP\u8bca\u65ad\u7684\u7cbe\u786e\u5ea6\u548c\u6548\u7387\uff0c\u4e3a\u4e34\u5e8a\u8bca\u65ad\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2511.10340", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.10340", "abs": "https://arxiv.org/abs/2511.10340", "authors": ["Marien Renaud", "Eliot Guez", "Arthur Leclaire", "Nicolas Papadakis"], "title": "Equivariant Denoisers for Plug and Play Image Restoration", "comment": "arXiv admin note: substantial text overlap with arXiv:2412.05343", "summary": "One key ingredient of image restoration is to define a realistic prior on clean images to complete the missing information in the observation. State-of-the-art restoration methods rely on a neural network to encode this prior. Typical image distributions are invariant to some set of transformations, such as rotations or flips. However, most deep architectures are not designed to represent an invariant image distribution. Recent works have proposed to overcome this difficulty by including equivariance properties within a Plug-and-Play paradigm. In this work, we propose two unified frameworks named Equivariant Regularization by Denoising (ERED) and Equivariant Plug-and-Play (EPnP) based on equivariant denoisers and stochastic optimization. We analyze the convergence of the proposed algorithms and discuss their practical benefit.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u57fa\u4e8e\u7b49\u53d8\u53bb\u566a\u5668\u548c\u968f\u673a\u4f18\u5316\u7684\u7edf\u4e00\u6846\u67b6\uff1a\u7b49\u53d8\u6b63\u5219\u5316\u53bb\u566a(ERED)\u548c\u7b49\u53d8\u5373\u63d2\u5373\u7528(EPnP)\uff0c\u7528\u4e8e\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u67b6\u6784\u65e0\u6cd5\u6709\u6548\u8868\u793a\u4e0d\u53d8\u56fe\u50cf\u5206\u5e03\uff0c\u800c\u56fe\u50cf\u5206\u5e03\u5bf9\u67d0\u4e9b\u53d8\u6362\uff08\u5982\u65cb\u8f6c\u3001\u7ffb\u8f6c\uff09\u5177\u6709\u4e0d\u53d8\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u56fe\u50cf\u6062\u590d\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u5229\u7528\u7b49\u53d8\u53bb\u566a\u5668\u548c\u968f\u673a\u4f18\u5316\u6784\u5efaERED\u548cEPnP\u6846\u67b6\uff0c\u901a\u8fc7\u5305\u542b\u7b49\u53d8\u6027\u8d28\u6765\u6539\u8fdb\u56fe\u50cf\u5148\u9a8c\u5efa\u6a21\u3002", "result": "\u5206\u6790\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5b9e\u9645\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b49\u53d8\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u5efa\u6a21\u56fe\u50cf\u5148\u9a8c\uff0c\u4e3a\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.10424", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.10424", "abs": "https://arxiv.org/abs/2511.10424", "authors": ["Maximiliane Gruber", "J\u00fcrgen Seiler", "Andr\u00e9 Kaup"], "title": "Domain Adaptation for Camera-Specific Image Characteristics using Shallow Discriminators", "comment": "5 pages, 7 figures, accepted for International Conference on Visual Communications and Image Processing (VCIP) 2025", "summary": "Each image acquisition setup leads to its own camera-specific image characteristics degrading the image quality. In learning-based perception algorithms, characteristics occurring during the application phase, but absent in the training data, lead to a domain gap impeding the performance. Previously, pixel-level domain adaptation through unpaired learning of the pristine-to-distorted mapping function has been proposed. In this work, we propose shallow discriminator architectures to address limitations of these approaches. We show that a smaller receptive field size improves learning of unknown image distortions by more accurately reproducing local distortion characteristics at a low network complexity. In a domain adaptation setup for instance segmentation, we achieve mean average precision increases over previous methods of up to 0.15 for individual distortions and up to 0.16 for camera-specific image characteristics in a simplified camera model. In terms of number of parameters, our approach matches the complexity of one state of the art method while reducing complexity by a factor of 20 compared to another, demonstrating superior efficiency without compromising performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6d45\u5c42\u5224\u522b\u5668\u67b6\u6784\u6765\u6539\u8fdb\u50cf\u7d20\u7ea7\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u66f4\u5c0f\u7684\u611f\u53d7\u91ce\u5c3a\u5bf8\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u672a\u77e5\u56fe\u50cf\u7578\u53d8\uff0c\u5728\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u5927\u5e45\u964d\u4f4e\u7f51\u7edc\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5b66\u4e60\u578b\u611f\u77e5\u7b97\u6cd5\u4e2d\u8bad\u7ec3\u6570\u636e\u4e0e\u5e94\u7528\u9636\u6bb5\u56fe\u50cf\u7279\u5f81\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u57df\u5dee\u8ddd\u95ee\u9898\uff0c\u6539\u8fdb\u73b0\u6709\u65e0\u914d\u5bf9\u5b66\u4e60\u7684\u539f\u59cb\u5230\u7578\u53d8\u6620\u5c04\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u6d45\u5c42\u5224\u522b\u5668\u67b6\u6784\uff0c\u51cf\u5c0f\u611f\u53d7\u91ce\u5c3a\u5bf8\u4ee5\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u5c40\u90e8\u7578\u53d8\u7279\u5f81\uff0c\u5728\u4f4e\u7f51\u7edc\u590d\u6742\u5ea6\u4e0b\u5b9e\u73b0\u50cf\u7d20\u7ea7\u57df\u9002\u5e94\u3002", "result": "\u5728\u5b9e\u4f8b\u5206\u5272\u7684\u57df\u9002\u5e94\u8bbe\u7f6e\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u7cbe\u5ea6\u63d0\u5347\u6700\u9ad8\u8fbe0.15\uff08\u5355\u4e2a\u7578\u53d8\uff09\u548c0.16\uff08\u76f8\u673a\u7279\u5b9a\u7279\u5f81\uff09\uff0c\u53c2\u6570\u91cf\u51cf\u5c1120\u500d\u4f46\u6027\u80fd\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6d45\u5c42\u5224\u522b\u5668\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u57df\u9002\u5e94\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u5c0f\u611f\u53d7\u91ce\u5728\u51c6\u786e\u5b66\u4e60\u5c40\u90e8\u7578\u53d8\u7279\u5f81\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
