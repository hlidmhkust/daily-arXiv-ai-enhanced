<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 24]
- [cs.IT](#cs.IT) [Total: 14]
- [eess.SP](#eess.SP) [Total: 24]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Diagnostic Accuracy of Open-Source Vision-Language Models on Diverse Medical Imaging Tasks](https://arxiv.org/abs/2508.01016)
*Gustav Müller-Franzes,Debora Jutz,Jakob Nikolas Kather,Christiane Kuhl,Sven Nebelung,Daniel Truhn*

Main category: eess.IV

TL;DR: 该研究评估了五种VLMs在MedFMC数据集上的表现，Qwen2.5在多项任务中表现最佳，但所有模型在复杂任务（如视网膜眼底检查）中表现不佳。多模态输入和链式思维提示未能提升准确性。


<details>
  <summary>Details</summary>
Motivation: 评估开源VLMs在医学图像诊断中的性能，为临床应用的潜力提供依据。

Method: 使用MedFMC数据集，比较五种VLMs在三种实验设置（仅视觉输入、多模态输入、链式思维推理）下的诊断准确性。

Result: Qwen2.5在胸部X光和内窥镜图像中表现最佳，但在复杂任务中表现有限。多模态输入和链式思维提示未显著提升准确性。

Conclusion: 开源VLMs在医学诊断中具有潜力，但在复杂任务中需进一步优化和领域适配。

Abstract: This retrospective study evaluated five VLMs (Qwen2.5, Phi-4, Gemma3,
Llama3.2, and Mistral3.1) using the MedFMC dataset. This dataset includes
22,349 images from 7,461 patients encompassing chest radiography (19 disease
multi-label classifications), colon pathology (tumor detection), endoscopy
(colorectal lesion identification), neonatal jaundice assessment (skin
color-based treatment necessity), and retinal fundoscopy (5-point diabetic
retinopathy grading). Diagnostic accuracy was compared in three experimental
settings: visual input only, multimodal input, and chain-of-thought reasoning.
Model accuracy was assessed against ground truth labels, with statistical
comparisons using bootstrapped confidence intervals (p<.05). Qwen2.5 achieved
the highest accuracy for chest radiographs (90.4%) and endoscopy images
(84.2%), significantly outperforming the other models (p<.001). In colon
pathology, Qwen2.5 (69.0%) and Phi-4 (69.6%) performed comparably (p=.41), both
significantly exceeding other VLMs (p<.001). Similarly, for neonatal jaundice
assessment, Qwen2.5 (58.3%) and Phi-4 (58.1%) showed comparable leading
accuracies (p=.93) significantly exceeding their counterparts (p<.001). All
models struggled with retinal fundoscopy; Qwen2.5 and Gemma3 achieved the
highest, albeit modest, accuracies at 18.6% (comparable, p=.99), significantly
better than other tested models (p<.001). Unexpectedly, multimodal input
reduced accuracy for some models and modalities, and chain-of-thought reasoning
prompts also failed to improve accuracy. The open-source VLMs demonstrated
promising diagnostic capabilities, particularly in chest radiograph
interpretation. However, performance in complex domains such as retinal
fundoscopy was limited, underscoring the need for further development and
domain-specific adaptation before widespread clinical application.

</details>


### [2] [CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis](https://arxiv.org/abs/2508.01292)
*Alec Sargood,Lemuel Puglisi,James H. Cole,Neil P. Oxtoby,Daniele Ravì,Daniel C. Alexander*

Main category: eess.IV

TL;DR: 该论文提出了一种基于扩散的潜在生成框架CoCoLIT，用于从结构MRI合成淀粉样PET扫描，以低成本进行大规模阿尔茨海默病筛查。


<details>
  <summary>Details</summary>
Motivation: 虽然MRI不直接检测淀粉样病理，但可能包含与淀粉样沉积相关的信息，通过高级建模可以揭示这些信息。

Method: CoCoLIT结合了加权图像空间损失（WISL）、潜在平均稳定化（LAS）分析和ControlNet条件化，用于MRI到PET的转换。

Result: 在公开数据集上，CoCoLIT在图像和淀粉样相关指标上显著优于现有方法，淀粉样阳性分类性能提升显著。

Conclusion: CoCoLIT为低成本、大规模的AD筛查提供了有效工具，代码和模型已开源。

Abstract: Synthesizing amyloid PET scans from the more widely available and accessible
structural MRI modality offers a promising, cost-effective approach for
large-scale Alzheimer's Disease (AD) screening. This is motivated by evidence
that, while MRI does not directly detect amyloid pathology, it may nonetheless
encode information correlated with amyloid deposition that can be uncovered
through advanced modeling. However, the high dimensionality and structural
complexity of 3D neuroimaging data pose significant challenges for existing
MRI-to-PET translation methods. Modeling the cross-modality relationship in a
lower-dimensional latent space can simplify the learning task and enable more
effective translation. As such, we present CoCoLIT (ControlNet-Conditioned
Latent Image Translation), a diffusion-based latent generative framework that
incorporates three main innovations: (1) a novel Weighted Image Space Loss
(WISL) that improves latent representation learning and synthesis quality; (2)
a theoretical and empirical analysis of Latent Average Stabilization (LAS), an
existing technique used in similar generative models to enhance inference
consistency; and (3) the introduction of ControlNet-based conditioning for
MRI-to-PET translation. We evaluate CoCoLIT's performance on publicly available
datasets and find that our model significantly outperforms state-of-the-art
methods on both image-based and amyloid-related metrics. Notably, in
amyloid-positivity classification, CoCoLIT outperforms the second-best method
with improvements of +10.5% on the internal dataset and +23.7% on the external
dataset. The code and models of our approach are available at
https://github.com/brAIn-science/CoCoLIT.

</details>


### [3] [SWAN: Synergistic Wavelet-Attention Network for Infrared Small Target Detection](https://arxiv.org/abs/2508.01322)
*Yuxin Jing,Jufeng Zhao,Tianpei Zhang,Yiming Zhu*

Main category: eess.IV

TL;DR: 提出了一种名为SWAN的新框架，通过结合小波变换和注意力机制，从空间和频率域检测红外小目标，显著提升了复杂背景下的检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测在民用和军事应用中至关重要，但现有方法依赖传统卷积操作，难以区分小目标的频率域特征与复杂背景杂波。

Method: 提出了SWAN框架，包括Haar小波卷积（HWConv）进行跨域融合、移位空间注意力（SSA）建模长程依赖，以及残差双通道注意力（RDCA）抑制背景干扰。

Result: 在基准数据集上的实验表明，SWAN优于现有方法，显著提升了检测精度和鲁棒性。

Conclusion: SWAN通过多域融合和注意力机制，有效解决了复杂背景下红外小目标检测的挑战。

Abstract: Infrared small target detection (IRSTD) is thus critical in both civilian and
military applications. This study addresses the challenge of precisely IRSTD in
complex backgrounds. Recent methods focus fundamental reliance on conventional
convolution operations, which primarily capture local spatial patterns and
struggle to distinguish the unique frequency-domain characteristics of small
targets from intricate background clutter. To overcome these limitations, we
proposed the Synergistic Wavelet-Attention Network (SWAN), a novel framework
designed to perceive targets from both spatial and frequency domains. SWAN
leverages a Haar Wavelet Convolution (HWConv) for a deep, cross-domain fusion
of the frequency energy and spatial details of small target. Furthermore, a
Shifted Spatial Attention (SSA) mechanism efficiently models long-range spatial
dependencies with linear computational complexity, enhancing contextual
awareness. Finally, a Residual Dual-Channel Attention (RDCA) module adaptively
calibrates channel-wise feature responses to suppress background interference
while amplifying target-pertinent signals. Extensive experiments on benchmark
datasets demonstrate that SWAN surpasses existing state-of-the-art methods,
showing significant improvements in detection accuracy and robustness,
particularly in complex challenging scenarios.

</details>


### [4] [Classification of Brain Tumors using Hybrid Deep Learning Models](https://arxiv.org/abs/2508.01350)
*Neerav Nemchand Gala*

Main category: eess.IV

TL;DR: 研究通过迁移学习优化CNN在医学图像分类中的性能，比较EfficientNetV2、EfficientNet和ResNet50，发现EfficientNetV2表现最佳但训练时间更长。


<details>
  <summary>Details</summary>
Motivation: 传统CNN需要大量计算资源和训练数据，研究旨在通过迁移学习减少样本需求。

Method: 使用EfficientNetV2、EfficientNet和ResNet50对脑瘤（胶质瘤、脑膜瘤、垂体瘤）进行分类。

Result: EfficientNetV2表现最优，但训练时间增加。

Conclusion: EfficientNetV2在分类任务中表现优异，但需权衡性能与计算成本。

Abstract: The use of Convolutional Neural Networks (CNNs) has greatly improved the
interpretation of medical images. However, conventional CNNs typically demand
extensive computational resources and large training datasets. To address these
limitations, this study applied transfer learning to achieve strong
classification performance using fewer training samples. Specifically, the
study compared EfficientNetV2 with its predecessor, EfficientNet, and with
ResNet50 in classifying brain tumors into three types: glioma, meningioma, and
pituitary tumors. Results showed that EfficientNetV2 delivered superior
performance compared to the other models. However, this improvement came at the
cost of increased training time, likely due to the model's greater complexity.

</details>


### [5] [Predicting EGFR Mutation in LUAD from Histopathological Whole-Slide Images Using Pretrained Foundation Model and Transfer Learning: An Indian Cohort Study](https://arxiv.org/abs/2508.01352)
*Sagar Singh Gwal,Rajan,Suyash Devgan,Shraddhanjali Satapathy,Abhishek Goyal,Nuruddin Mohammad Iqbal,Vivaan Jain,Prabhat Singh Mallik,Deepali Jain,Ishaan Gupta*

Main category: eess.IV

TL;DR: 该研究提出了一种基于视觉变换器（ViT）和注意力多实例学习（ABMIL）的深度学习框架，用于从H&E染色全切片图像（WSI）预测EGFR突变状态，并在印度和TCGA数据集上验证了其高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: EGFR突变在肺腺癌（LUAD）中占比高，且可通过特定酪氨酸激酶抑制剂（TKI）治疗。预测EGFR突变状态有助于临床决策，尤其是在东南亚人群中突变率显著高于高加索人群。

Method: 采用基于ViT的病理基础模型和ABMIL架构的深度学习框架，利用印度队列（170 WSI）训练，并在内部测试集（30 WSI）和TCGA外部测试集（86 WSI）上评估。

Result: 模型在内部和外部测试集上的AUC分别为0.933和0.965，表现优于先前研究，且适用于小数据集训练。

Conclusion: 该框架证明了利用常规病理切片准确预测EGFR突变状态的可行性，特别适用于资源有限的环境。

Abstract: Lung adenocarcinoma (LUAD) is a subtype of non-small cell lung cancer
(NSCLC). LUAD with mutation in the EGFR gene accounts for approximately 46% of
LUAD cases. Patients carrying EGFR mutations can be treated with specific
tyrosine kinase inhibitors (TKIs). Hence, predicting EGFR mutation status can
help in clinical decision making. H&E-stained whole slide imaging (WSI) is a
routinely performed screening procedure for cancer staging and subtyping,
especially affecting the Southeast Asian populations with significantly higher
incidence of the mutation when compared to Caucasians (39-64% vs 7-22%). Recent
progress in AI models has shown promising results in cancer detection and
classification. In this study, we propose a deep learning (DL) framework built
on vision transformers (ViT) based pathology foundation model and
attention-based multiple instance learning (ABMIL) architecture to predict EGFR
mutation status from H&E WSI. The developed pipeline was trained using data
from an Indian cohort (170 WSI) and evaluated across two independent datasets:
Internal test (30 WSI from Indian cohort) set, and an external test set from
TCGA (86 WSI). The model shows consistent performance across both datasets,
with AUCs of 0.933 (+/-0.010), and 0.965 (+/-0.015) for the internal and
external test sets respectively. This proposed framework can be efficiently
trained on small datasets, achieving superior performance as compared to
several prior studies irrespective of training domain. The current study
demonstrates the feasibility of accurately predicting EGFR mutation status
using routine pathology slides, particularly in resource-limited settings using
foundation models and attention-based multiple instance learning.

</details>


### [6] [Viscosity Stabilized Plug-and-Play Reconstruction](https://arxiv.org/abs/2508.01441)
*Arghya Sinha,Trishit Mukherjee,Kunal N. Chaudhury*

Main category: eess.IV

TL;DR: 提出了一种数据驱动的稳定机制，用于解决PnP方法中迭代过程不稳定的问题，通过自适应平均不稳定操作符与收缩IR操作符，有效抑制振荡和发散。


<details>
  <summary>Details</summary>
Motivation: PnP方法在模型基图像重建中使用预训练的降噪器，但黑盒网络可能导致迭代过程不稳定，视觉质量和PSNR在后期迭代中下降。

Method: 提出一种数据驱动的稳定机制，通过自适应平均不稳定PnP操作符与收缩IR操作符，实现粘度正则化，抑制后期迭代中的振荡。

Result: 验证了该稳定机制在不同近端算法、降噪架构和成像任务中的有效性。

Conclusion: 该方法简单有效，能够在不限制降噪器的情况下提升PnP的稳定性。

Abstract: The plug-and-play (PnP) method uses a deep denoiser within a proximal
algorithm for model-based image reconstruction (IR). Unlike end-to-end IR, PnP
allows the same pretrained denoiser to be used across different imaging tasks,
without the need for retraining. However, black-box networks can make the
iterative process in PnP unstable. A common issue observed across architectures
like CNNs, diffusion models, and transformers is that the visual quality and
PSNR often improve initially but then degrade in later iterations. Previous
attempts to ensure stability usually impose restrictive constraints on the
denoiser. However, standard denoisers, which are freely trained for single-step
noise removal, need not satisfy such constraints. We propose a simple
data-driven stabilization mechanism that adaptively averages the potentially
unstable PnP operator with a contractive IR operator. This acts as a form of
viscosity regularization, where the contractive component progressively dampens
updates in later iterations, helping to suppress oscillations and prevent
divergence. We validate the effectiveness of our stabilization mechanism across
different proximal algorithms, denoising architectures, and imaging tasks.

</details>


### [7] [CGCCE-Net:Change-Guided Cross Correlation Enhancement Network for Remote Sensing Building Change Detection](https://arxiv.org/abs/2508.01549)
*ChengMing Wang*

Main category: eess.IV

TL;DR: 提出了一种名为CGCCE-Net的网络，用于解决建筑物变化检测（BCD）中特殊颜色问题，通过多尺度特征提取和语义信息交互，显著提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决建筑物变化检测任务中特殊颜色导致的检测困难问题。

Method: 设计了CGRR分支用于多尺度特征提取，GCCM模块用于双时相图像语义信息交互，SCEM模块用于语义特征增强，以及CFD模块用于信息融合和图像重建。

Result: 在三个公开数据集上，CGCCE-Net优于主流BCD方法，表现突出。

Conclusion: CGCCE-Net通过多模块协同工作，有效提升了建筑物变化检测的精度和鲁棒性。

Abstract: Change detection encompasses a variety of task types, and the goal of
building change detection (BCD) tasks is to accurately locate buildings and
distinguish changed building areas. In recent years, various deep
learning-based BCD methods have achieved significant success in detecting
difference regions by using different change information enhancement
techniques, effectively improving the precision of BCD tasks. To address the
issue of BCD with special colors, we propose the change-guided cross
correlation enhancement network (CGCCE-Net). We design the change-guided
residual refinement (CGRR) Branch, which focuses on extending shallow texture
features to multiple scale features obtained from PVT, enabling early attention
and acquisition of special colors. Then, channel spatial attention is used in
the deep features to achieve independent information enhancement. Additionally,
we construct the global cross correlation module (GCCM) to facilitate semantic
information interaction between bi-temporal images, establishing building and
target recognition relationships between different images. Further semantic
feature enhancement is achieved through the semantic cognitive enhancement
module (SCEM), and finally, the cross fusion decoder (CFD) is used for change
information fusion and image reconstruction. Extensive experiments on three
public datasets demonstrate that our CGCCE-Net outperforms mainstream BCD
methods with outstanding performance.

</details>


### [8] [MGCR-Net:Multimodal Graph-Conditioned Vision-Language Reconstruction Network for Remote Sensing Change Detection](https://arxiv.org/abs/2508.01555)
*Chengming Wang,Guodong Fan,Jinjiang Li,Min Gan,C. L. Philip Chen*

Main category: eess.IV

TL;DR: 提出了一种多模态图条件视觉语言重建网络（MGCR-Net），用于遥感变化检测（RSCD），通过多模态大语言模型（MLLM）优化策略生成文本数据，结合视觉和文本特征，实现高性能变化检测。


<details>
  <summary>Details</summary>
Motivation: 传统变化检测方法在多模态数据探索和应用中存在局限性，需要进一步挖掘多模态数据的语义交互能力。

Method: 设计MLLM优化策略生成文本数据，通过双编码器提取视觉和文本特征，引入多模态图条件视觉语言重建机制（SGCM），结合图注意力实现跨维度交互，最终使用语言视觉变换器（LViT）深度融合特征。

Result: 在四个公开数据集上，MGCR-Net优于主流变化检测方法。

Conclusion: MGCR-Net通过多模态数据的语义交互和特征融合，显著提升了遥感变化检测的性能。

Abstract: With the advancement of remote sensing satellite technology and the rapid
progress of deep learning, remote sensing change detection (RSCD) has become a
key technique for regional monitoring. Traditional change detection (CD)
methods and deep learning-based approaches have made significant contributions
to change analysis and detection, however, many outstanding methods still face
limitations in the exploration and application of multimodal data. To address
this, we propose the multimodal graph-conditioned vision-language
reconstruction network (MGCR-Net) to further explore the semantic interaction
capabilities of multimodal data. Multimodal large language models (MLLM) have
attracted widespread attention for their outstanding performance in computer
vision, particularly due to their powerful visual-language understanding and
dialogic interaction capabilities. Specifically, we design a MLLM-based
optimization strategy to generate multimodal textual data from the original CD
images, which serve as textual input to MGCR. Visual and textual features are
extracted through a dual encoder framework. For the first time in the RSCD
task, we introduce a multimodal graph-conditioned vision-language
reconstruction mechanism, which is integrated with graph attention to construct
a semantic graph-conditioned reconstruction module (SGCM), this module
generates vision-language (VL) tokens through graph-based conditions and
enables cross-dimensional interaction between visual and textual features via
multihead attention. The reconstructed VL features are then deeply fused using
the language vision transformer (LViT), achieving fine-grained feature
alignment and high-level semantic interaction. Experimental results on four
public datasets demonstrate that MGCR achieves superior performance compared to
mainstream CD methods. Our code is available on
https://github.com/cn-xvkong/MGCR

</details>


### [9] [Deeply Supervised Multi-Task Autoencoder for Biological Brain Age estimation using three dimensional T$_1$-weighted magnetic resonance imaging](https://arxiv.org/abs/2508.01565)
*Mehreen Kanwal,Yunsik Son*

Main category: eess.IV

TL;DR: 提出了一种深度监督多任务自编码器（DSMT-AE）框架，用于从3D MRI中准确预测大脑年龄，并通过多任务学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决3D模型优化中的梯度消失问题，并利用性别分类等辅助任务提升大脑年龄预测的准确性和泛化能力。

Method: 采用深度监督和多任务学习，同时优化大脑年龄预测、性别分类和图像重建任务。

Result: 在OpenBHB数据集上实现了最先进的性能，并在不同年龄和性别子组中表现出鲁棒性。

Conclusion: DSMT-AE框架通过多任务学习和深度监督显著提升了大脑年龄预测的准确性和鲁棒性。

Abstract: Accurate estimation of biological brain age from three dimensional (3D)
T$_1$-weighted magnetic resonance imaging (MRI) is a critical imaging biomarker
for identifying accelerated aging associated with neurodegenerative diseases.
Effective brain age prediction necessitates training 3D models to leverage
comprehensive insights from volumetric MRI scans, thereby fully capturing
spatial anatomical context. However, optimizing deep 3D models remains
challenging due to problems such as vanishing gradients. Furthermore, brain
structural patterns differ significantly between sexes, which impacts aging
trajectories and vulnerability to neurodegenerative diseases, thereby making
sex classification crucial for enhancing the accuracy and generalizability of
predictive models. To address these challenges, we propose a Deeply Supervised
Multitask Autoencoder (DSMT-AE) framework for brain age estimation. DSMT-AE
employs deep supervision, which involves applying supervisory signals at
intermediate layers during training, to stabilize model optimization, and
multitask learning to enhance feature representation. Specifically, our
framework simultaneously optimizes brain age prediction alongside auxiliary
tasks of sex classification and image reconstruction, thus effectively
capturing anatomical and demographic variability to improve prediction
accuracy. We extensively evaluate DSMT-AE on the Open Brain Health Benchmark
(OpenBHB) dataset, the largest multisite neuroimaging cohort combining ten
publicly available datasets. The results demonstrate that DSMT-AE achieves
state-of-the-art performance and robustness across age and sex subgroups.
Additionally, our ablation study confirms that each proposed component
substantially contributes to the improved predictive accuracy and robustness of
the overall architecture.

</details>


### [10] [Tractography-Guided Dual-Label Collaborative Learning for Multi-Modal Cranial Nerves Parcellation](https://arxiv.org/abs/2508.01577)
*Lei Xie,Junxiong Huang,Yuanjing Feng,Qingrun Zeng*

Main category: eess.IV

TL;DR: 提出了一种基于纤维追踪和专家标注的双标签协作学习网络（DCLNet），用于多模态颅神经分割，通过模态自适应编码模块（MEM）优化信息融合，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合方法对扩散MRI信息利用不足，导致分割性能较低。

Method: 提出DCLNet，结合纤维追踪生成的粗标签和专家标注的精确标签进行协作学习，并引入MEM模块实现结构MRI和扩散MRI的软信息交换。

Result: 在HCP数据集上的实验表明，DCLNet性能优于单标签网络。

Conclusion: 双标签策略能有效解决颅神经分割任务中的固有模糊性问题。

Abstract: The parcellation of Cranial Nerves (CNs) serves as a crucial quantitative
methodology for evaluating the morphological characteristics and anatomical
pathways of specific CNs. Multi-modal CNs parcellation networks have achieved
promising segmentation performance, which combine structural Magnetic Resonance
Imaging (MRI) and diffusion MRI. However, insufficient exploration of diffusion
MRI information has led to low performance of existing multi-modal fusion. In
this work, we propose a tractography-guided Dual-label Collaborative Learning
Network (DCLNet) for multi-modal CNs parcellation. The key contribution of our
DCLNet is the introduction of coarse labels of CNs obtained from fiber
tractography through CN atlas, and collaborative learning with precise labels
annotated by experts. Meanwhile, we introduce a Modality-adaptive Encoder
Module (MEM) to achieve soft information swapping between structural MRI and
diffusion MRI. Extensive experiments conducted on the publicly available Human
Connectome Project (HCP) dataset demonstrate performance improvements compared
to single-label network. This systematic validation underscores the
effectiveness of dual-label strategies in addressing inherent ambiguities in
CNs parcellation tasks.

</details>


### [11] [Measuring and Predicting Where and When Pathologists Focus their Visual Attention while Grading Whole Slide Images of Cancer](https://arxiv.org/abs/2508.01668)
*Souradeep Chakraborty,Ruoyu Xue,Rajarsi Gupta,Oksana Yaskiv,Constantin Friedman,Natallia Sheuka,Dana Perez,Paul Friedman,Won-Tak Choi,Waqas Mahmud,Beatrice Knudsen,Gregory Zelinsky,Joel Saltz,Dimitris Samaras*

Main category: eess.IV

TL;DR: 开发了一种预测病理学家注意力轨迹的方法，通过两阶段模型预测其在全切片图像（WSI）中的动态注意力分配。


<details>
  <summary>Details</summary>
Motivation: 预测专家病理学家的注意力轨迹，可为病理学培训提供决策支持系统，帮助学员学习如何分配注意力。

Method: 使用基于Transformer的两阶段模型：第一阶段预测静态注意力热图，第二阶段通过自回归方式预测动态扫描路径。

Result: 模型在预测注意力扫描路径方面优于随机和基线模型。

Conclusion: 该模型工具可帮助病理学学员像专家一样在全切片图像阅读中分配注意力。

Abstract: The ability to predict the attention of expert pathologists could lead to
decision support systems for better pathology training. We developed methods to
predict the spatio-temporal (where and when) movements of pathologists'
attention as they grade whole slide images (WSIs) of prostate cancer. We
characterize a pathologist's attention trajectory by their x, y, and m
(magnification) movements of a viewport as they navigate WSIs using a digital
microscope. This information was obtained from 43 pathologists across 123 WSIs,
and we consider the task of predicting the pathologist attention scanpaths
constructed from the viewport centers. We introduce a fixation extraction
algorithm that simplifies an attention trajectory by extracting fixations in
the pathologist's viewing while preserving semantic information, and we use
these pre-processed data to train and test a two-stage model to predict the
dynamic (scanpath) allocation of attention during WSI reading via intermediate
attention heatmap prediction. In the first stage, a transformer-based
sub-network predicts the attention heatmaps (static attention) across different
magnifications. In the second stage, we predict the attention scanpath by
sequentially modeling the next fixation points in an autoregressive manner
using a transformer-based approach, starting at the WSI center and leveraging
multi-magnification feature representations from the first stage. Experimental
results show that our scanpath prediction model outperforms chance and baseline
models. Tools developed from this model could assist pathology trainees in
learning to allocate their attention during WSI reading like an expert.

</details>


### [12] [LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation](https://arxiv.org/abs/2508.01772)
*Cristian Minoccheri,Matthew Hodgman,Haoyuan Ma,Rameez Merchant,Emily Wittrup,Craig Williamson,Kayvan Najarian*

Main category: eess.IV

TL;DR: 该研究提出了一种基于LoRA的改进方法（CP-LoRA和DoRA变体），用于动脉瘤性蛛网膜下腔出血（SAH）的医学图像分割，显著优于传统Unet微调方法。


<details>
  <summary>Details</summary>
Motivation: 动脉瘤性蛛网膜下腔出血（SAH）是一种高死亡率的神经系统急症，现有方法在有限数据集上表现不佳，而迁移学习和参数高效方法在医学图像领域尚未充分探索。

Method: 采用预训练的Unet架构，基于124名创伤性脑损伤患者的CT扫描数据，并在30名SAH患者数据上进行微调。提出了基于张量CP分解的CP-LoRA方法和DoRA变体，并与现有LoRA方法及标准微调策略进行比较。

Result: LoRA方法在SAH分割任务中表现优于传统Unet微调，CP-LoRA在参数更少的情况下性能相当，且高秩参数化效果更佳。

Conclusion: 研究表明，不同血肿类型间的迁移学习可行，且LoRA方法在SAH分割中显著优于传统方法。

Abstract: Aneurysmal subarachnoid hemorrhage (SAH) is a life-threatening neurological
emergency with mortality rates exceeding 30%. Transfer learning from related
hematoma types represents a potentially valuable but underexplored approach.
Although Unet architectures remain the gold standard for medical image
segmentation due to their effectiveness on limited datasets, Low-Rank
Adaptation (LoRA) methods for parameter-efficient transfer learning have been
rarely applied to convolutional neural networks in medical imaging contexts. We
implemented a Unet architecture pre-trained on computed tomography scans from
124 traumatic brain injury patients across multiple institutions, then
fine-tuned on 30 aneurysmal SAH patients from the University of Michigan Health
System using 3-fold cross-validation. We developed a novel CP-LoRA method based
on tensor CP-decomposition and introduced DoRA variants (DoRA-C, convDoRA,
CP-DoRA) that decompose weight matrices into magnitude and directional
components. We compared these approaches against existing LoRA methods (LoRA-C,
convLoRA) and standard fine-tuning strategies across different modules on a
multi-view Unet model. LoRA-based methods consistently outperformed standard
Unet fine-tuning. Performance varied by hemorrhage volume, with all methods
showing improved accuracy for larger volumes. CP-LoRA achieved comparable
performance to existing methods while using significantly fewer parameters.
Over-parameterization with higher ranks consistently yielded better performance
than strictly low-rank adaptations. This study demonstrates that transfer
learning between hematoma types is feasible and that LoRA-based methods
significantly outperform conventional Unet fine-tuning for aneurysmal SAH
segmentation.

</details>


### [13] [Joint Lossless Compression and Steganography for Medical Images via Large Language Models](https://arxiv.org/abs/2508.01782)
*Pengcheng Zheng,Xiaorong Pu,Kecheng Chen,Jiaxin Huang,Meng Yang,Bai Feng,Yazhou Ren,Jianan Jiang*

Main category: eess.IV

TL;DR: 提出了一种结合无损压缩和隐写术的新框架，用于医学图像，优化了压缩性能与效率的平衡，并确保安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的压缩方法在医学图像上性能与效率不平衡，且忽视压缩过程的安全性。

Method: 采用比特平面切片技术，将图像分为全局和局部模态，设计双路径无损压缩，并在局部路径中嵌入隐写算法，结合A-LoRA微调策略。

Result: 实验表明，该方法在压缩比、效率和安全性上表现优越。

Conclusion: 该方法为医学图像提供了高效、安全的无损压缩解决方案，代码将开源。

Abstract: Recently, large language models (LLMs) have driven promis ing progress in
lossless image compression. However, di rectly adopting existing paradigms for
medical images suf fers from an unsatisfactory trade-off between compression
  performance and efficiency. Moreover, existing LLM-based
  compressors often overlook the security of the compres sion process, which is
critical in modern medical scenarios.
  To this end, we propose a novel joint lossless compression
  and steganography framework. Inspired by bit plane slicing
  (BPS), we find it feasible to securely embed privacy messages
  into medical images in an invisible manner. Based on this in sight, an
adaptive modalities decomposition strategy is first
  devised to partition the entire image into two segments, pro viding global
and local modalities for subsequent dual-path
  lossless compression. During this dual-path stage, we inno vatively propose a
segmented message steganography algo rithm within the local modality path to
ensure the security of
  the compression process. Coupled with the proposed anatom ical priors-based
low-rank adaptation (A-LoRA) fine-tuning
  strategy, extensive experimental results demonstrate the su periority of our
proposed method in terms of compression ra tios, efficiency, and security. The
source code will be made
  publicly available.

</details>


### [14] [Conditional Residual Coding with Explicit-Implicit Temporal Buffering for Learned Video Compression](https://arxiv.org/abs/2508.01818)
*Yi-Hsin Chen,Kuan-Wei Ho,Martin Benjak,Jörn Ostermann,Wen-Hsiao Peng*

Main category: eess.IV

TL;DR: 提出了一种混合显隐式时间缓冲方案，用于条件残差视频编码，结合显式和隐式时间信息以提高性能并减少内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有条件编码方法依赖隐式时间信息，虽性能优越但内存需求大，需探索更高效的缓冲策略。

Method: 采用混合缓冲策略，结合一帧显式时间参考和少量隐式特征，优化条件残差编码。

Result: 混合方案性能优于单一显式或隐式方法，且缓冲大小降至等效两帧，性能损失可忽略。

Conclusion: 混合缓冲策略高效平衡性能与内存，实验揭示了两种时间参考对编码性能的影响。

Abstract: This work proposes a hybrid, explicit-implicit temporal buffering scheme for
conditional residual video coding. Recent conditional coding methods propagate
implicit temporal information for inter-frame coding, demonstrating superior
coding performance to those relying exclusively on previously decoded frames
(i.e. the explicit temporal information). However, these methods require
substantial memory to store a large number of implicit features. This work
presents a hybrid buffering strategy. For inter-frame coding, it buffers one
previously decoded frame as the explicit temporal reference and a small number
of learned features as implicit temporal reference. Our hybrid buffering scheme
for conditional residual coding outperforms the single use of explicit or
implicit information. Moreover, it allows the total buffer size to be reduced
to the equivalent of two video frames with a negligible performance drop on 2K
video sequences. The ablation experiment further sheds light on how these two
types of temporal references impact the coding performance.

</details>


### [15] [M$^3$AD: Multi-task Multi-gate Mixture of Experts for Alzheimer's Disease Diagnosis with Conversion Pattern Modeling](https://arxiv.org/abs/2508.01819)
*Yufeng Jiang,Hexiao Ding,Hongzhao Chen,Jing Lan,Xinzhi Teng,Gerald W. Y. Cheng,Zongxi Li,Haoran Xie,Jung Sun Yoo,Jing Cai*

Main category: eess.IV

TL;DR: 该研究提出了一种名为M$^3$AD的多任务多门混合专家框架，用于联合处理阿尔茨海默病（AD）的诊断分类和认知过渡建模，通过结构MRI实现了更高的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法将AD的复杂连续过程简化为离散分类任务，忽略了认知过渡的动态性。本研究旨在通过多任务学习框架更全面地建模AD的进展。

Method: 研究结合了开源T1加权sMRI预处理流程、统一学习框架（包含人口统计学先验）和多门混合专家架构，采用两阶段训练协议（SimMIM预训练和多任务微调）。

Result: 在六个数据集上的评估显示，三分类（NC-MCI-AD）准确率达95.13%，二分类（NC-AD）达99.15%，认知过渡预测准确率达97.76%，均优于现有方法。

Conclusion: M$^3$AD框架在仅使用结构MRI的情况下，显著提升了AD诊断和认知过渡预测的性能，为早期干预提供了实用解决方案。

Abstract: Alzheimer's disease (AD) progression follows a complex continuum from normal
cognition (NC) through mild cognitive impairment (MCI) to dementia, yet most
deep learning approaches oversimplify this into discrete classification tasks.
This study introduces M$^3$AD, a novel multi-task multi-gate mixture of experts
framework that jointly addresses diagnostic classification and cognitive
transition modeling using structural MRI. We incorporate three key innovations:
(1) an open-source T1-weighted sMRI preprocessing pipeline, (2) a unified
learning framework capturing NC-MCI-AD transition patterns with demographic
priors (age, gender, brain volume) for improved generalization, and (3) a
customized multi-gate mixture of experts architecture enabling effective
multi-task learning with structural MRI alone. The framework employs
specialized expert networks for diagnosis-specific pathological patterns while
shared experts model common structural features across the cognitive continuum.
A two-stage training protocol combines SimMIM pretraining with multi-task
fine-tuning for joint optimization. Comprehensive evaluation across six
datasets comprising 12,037 T1-weighted sMRI scans demonstrates superior
performance: 95.13% accuracy for three-class NC-MCI-AD classification and
99.15% for binary NC-AD classification, representing improvements of 4.69% and
0.55% over state-of-the-art approaches. The multi-task formulation
simultaneously achieves 97.76% accuracy in predicting cognitive transition. Our
framework outperforms existing methods using fewer modalities and offers a
clinically practical solution for early intervention. Code:
https://github.com/csyfjiang/M3AD.

</details>


### [16] [Large Kernel MedNeXt for Breast Tumor Segmentation and Self-Normalizing Network for pCR Classification in Magnetic Resonance Images](https://arxiv.org/abs/2508.01831)
*Toufiq Musah*

Main category: eess.IV

TL;DR: 该论文提出了一种基于大核MedNeXt架构的两阶段训练策略，用于DCE-MRI中的乳腺肿瘤分割和pCR分类，取得了较好的分割和分类性能。


<details>
  <summary>Details</summary>
Motivation: 准确的乳腺肿瘤分割对pCR评估等下游任务至关重要，但现有方法在性能上仍有提升空间。

Method: 采用大核MedNeXt架构和UpKern算法，通过两阶段训练策略扩展感受野，并结合自归一化网络（SNN）进行pCR分类。

Result: 分割任务中Dice得分为0.67，NormHD为0.24；pCR分类的平均平衡准确率为57%，部分子组达75%。

Conclusion: 结合大感受野和放射组学分类具有优势，未来可通过高级集成和临床变量整合进一步提升性能。

Abstract: Accurate breast tumor segmentation in dynamic contrast-enhanced magnetic
resonance imaging (DCE-MRI) is important for downstream tasks such as
pathological complete response (pCR) assessment. In this work, we address both
segmentation and pCR classification using the large-scale MAMA-MIA DCE-MRI
dataset. We employ a large-kernel MedNeXt architecture with a two-stage
training strategy that expands the receptive field from 3x3x3 to 5x5x5 kernels
using the UpKern algorithm. This approach allows stable transfer of learned
features to larger kernels, improving segmentation performance on the unseen
validation set. An ensemble of large-kernel models achieved a Dice score of
0.67 and a normalized Hausdorff Distance (NormHD) of 0.24. For pCR
classification, we trained a self-normalizing network (SNN) on radiomic
features extracted from the predicted segmentations and first post-contrast
DCE-MRI, reaching an average balanced accuracy of 57\%, and up to 75\% in some
subgroups. Our findings highlight the benefits of combining larger receptive
fields and radiomics-driven classification while motivating future work on
advanced ensembling and the integration of clinical variables to further
improve performance and generalization. Code:
https://github.com/toufiqmusah/caladan-mama-mia.git

</details>


### [17] [Less is More: AMBER-AFNO -- a New Benchmark for Lightweight 3D Medical Image Segmentation](https://arxiv.org/abs/2508.01941)
*Andrea Dosi,Semanto Mondal,Rajib Chandra Ghosh,Massimo Brescia,Giuseppe Longo*

Main category: eess.IV

TL;DR: 将遥感领域的AMBER模型迁移到医疗领域，用于3D医学数据分割，通过AFNO替代多头自注意力机制，显著降低模型复杂度，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何将遥感领域的先进模型迁移到医疗领域，以提升3D医学数据分割的效率和性能。

Method: 使用AMBER架构，以AFNO替代多头自注意力机制，通过频域混合捕捉全局上下文，减少模型参数和计算复杂度。

Result: 在ACDC和Synapse数据集上，AMBER-AFNO在DSC和HD指标上表现优异，参数减少80%，训练和推理效率显著提升。

Conclusion: AMBER-AFNO在3D医学数据分割任务中实现了高效且高性能的解决方案，为模型轻量化提供了新思路。

Abstract: This work presents the results of a methodological transfer from remote
sensing to healthcare, adapting AMBER -- a transformer-based model originally
designed for multiband images, such as hyperspectral data -- to the task of 3D
medical datacube segmentation. In this study, we use the AMBER architecture
with Adaptive Fourier Neural Operators (AFNO) in place of the multi-head
self-attention mechanism. While existing models rely on various forms of
attention to capture global context, AMBER-AFNO achieves this through
frequency-domain mixing, enabling a drastic reduction in model complexity. This
design reduces the number of trainable parameters by over 80% compared to
UNETR++, while maintaining a FLOPs count comparable to other state-of-the-art
architectures. Model performance is evaluated on two benchmark 3D medical
datasets -- ACDC and Synapse -- using standard metrics such as Dice Similarity
Coefficient (DSC) and Hausdorff Distance (HD), demonstrating that AMBER-AFNO
achieves competitive or superior accuracy with significant gains in training
efficiency, inference speed, and memory usage.

</details>


### [18] [HyTIP: Hybrid Temporal Information Propagation for Masked Conditional Residual Video Coding](https://arxiv.org/abs/2508.02072)
*Yi-Hsin Chen,Yi-Chen Yao,Kuan-Wei Ho,Chun-Hung Wu,Huu-Tai Phung,Martin Benjak,Jörn Ostermann,Wen-Hsiao Peng*

Main category: eess.IV

TL;DR: HyTIP是一种结合输出递归和隐式特征传播的混合视频编码框架，解决了现有方法的局限性，性能优于单独使用任一方法，且缓冲需求更小。


<details>
  <summary>Details</summary>
Motivation: 现有基于RNN的视频编码方法存在输出递归的双重约束或隐式特征传播的大缓冲需求问题，HyTIP旨在结合两者优势。

Method: HyTIP采用混合缓冲策略，结合显式解码帧和少量隐式潜在特征，提升编码性能。

Result: HyTIP在PSNR-RGB和MS-SSIM-RGB上优于VTM 17.0 (Low-delay B)，且缓冲需求更小。

Conclusion: HyTIP通过混合机制实现了高性能视频编码，同时减少了缓冲需求，优于现有方法。

Abstract: Most frame-based learned video codecs can be interpreted as recurrent neural
networks (RNNs) propagating reference information along the temporal dimension.
This work revisits the limitations of the current approaches from an RNN
perspective. The output-recurrence methods, which propagate decoded frames, are
intuitive but impose dual constraints on the output decoded frames, leading to
suboptimal rate-distortion performance. In contrast, the hidden-to-hidden
connection approaches, which propagate latent features within the RNN, offer
greater flexibility but require large buffer sizes. To address these issues, we
propose HyTIP, a learned video coding framework that combines both mechanisms.
Our hybrid buffering strategy uses explicit decoded frames and a small number
of implicit latent features to achieve competitive coding performance.
Experimental results show that our HyTIP outperforms the sole use of either
output-recurrence or hidden-to-hidden approaches. Furthermore, it achieves
comparable performance to state-of-the-art methods but with a much smaller
buffer size, and outperforms VTM 17.0 (Low-delay B) in terms of PSNR-RGB and
MS-SSIM-RGB. The source code of HyTIP is available at
https://github.com/NYCU-MAPL/HyTIP.

</details>


### [19] [REACT-KD: Region-Aware Cross-modal Topological Knowledge Distillation for Interpretable Medical Image Classification](https://arxiv.org/abs/2508.02104)
*Hongzhao Chen,Hexiao Ding,Yufeng Jiang,Jing Lan,Ka Chun Li,Gerald W. Y. Cheng,Sam Ng,Chi Lai Ho,Jing Cai,Liang-ting Lin,Jung Sun Yoo*

Main category: eess.IV

TL;DR: REACT-KD是一种区域感知跨模态拓扑知识蒸馏框架，用于从临床影像中可靠且可解释地分类肿瘤，通过多模态监督提升轻量级CT模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决临床影像中肿瘤分类的挑战，如模态质量不均、标注有限和缺乏结构化解剖指导。

Method: 采用双教师设计，分别从PET/CT和低剂量CT数据中提取特征，通过语义对齐和区域图蒸馏指导学生模型。

Result: 在肝癌分期任务中，内部PET/CT队列的平均AUC为93.4%，外部CT测试中AUC为76.6%至81.5%。

Conclusion: REACT-KD在真实诊断中具有潜力，决策曲线分析显示其临床效益显著。

Abstract: Reliable and interpretable tumor classification from clinical imaging remains
a core challenge due to heterogeneous modality quality, limited annotations,
and the lack of structured anatomical guidance. We introduce REACT-KD, a
Region-Aware Cross-modal Topological Knowledge Distillation framework that
transfers rich supervision from high-fidelity multi-modal sources into a
lightweight CT-based student model. The framework uses a dual teacher design:
one branch captures structure-function relationships using dual-tracer PET/CT,
and the other models dose-aware features through synthetically degraded
low-dose CT data. These branches jointly guide the student model through two
complementary objectives. The first focuses on semantic alignment via logits
distillation, while the second models anatomical topology using region graph
distillation. A shared CBAM-3D module is employed to maintain consistent
attention across modalities. To improve reliability for deployment, REACT-KD
introduces modality dropout during training, allowing inference under partial
or noisy inputs. The staging task for hepatocellular carcinoma (HCC) is
conducted as a case study. REACT-KD achieves an average AUC of 93.4% on an
internal PET/CT cohort and maintains 76.6% to 81.5% AUC across varying dose
levels in external CT testing. Decision curve analysis shows that REACT-KD
consistently provides the highest clinical benefit across decision thresholds,
supporting its potential in real-world diagnostics. Code is available at
https://github.com/Kinetics-JOJO/REACT-KD.

</details>


### [20] [Tackling Ill-posedness of Reversible Image Conversion with Well-posed Invertible Network](https://arxiv.org/abs/2508.02111)
*Yuanfei Huang,Hua Huang*

Main category: eess.IV

TL;DR: 论文提出了一种解决可逆图像转换（RIC）中病态问题的方法，通过构建一个过定系统并设计一种新的可逆1×1卷积（WIC），消除了对随机变量的依赖，并开发了两种新型网络WIN-Naïve和WIN。


<details>
  <summary>Details</summary>
Motivation: 解决RIC中由于前向转换过程的不确定性导致的病态问题，现有方法依赖随机变量采样，无法完全解决这一问题。

Method: 提出WIC方法，构建过定系统以确保解的唯一性；设计WIN-Naïve和WIN网络，后者通过高级跳跃连接增强长期记忆。

Result: 在多种RIC任务（如图像隐藏、图像缩放和图像去色）中表现优异，达到最先进水平。

Conclusion: 该方法克服了现有RIC解决方案的瓶颈，为领域设定了新基准。

Abstract: Reversible image conversion (RIC) suffers from ill-posedness issues due to
its forward conversion process being considered an underdetermined system.
Despite employing invertible neural networks (INN), existing RIC methods
intrinsically remain ill-posed as inevitably introducing uncertainty by
incorporating randomly sampled variables. To tackle the ill-posedness dilemma,
we focus on developing a reliable approximate left inverse for the
underdetermined system by constructing an overdetermined system with a non-zero
Gram determinant, thus ensuring a well-posed solution. Based on this principle,
we propose a well-posed invertible $1\times1$ convolution (WIC), which
eliminates the reliance on random variable sampling and enables the development
of well-posed invertible networks. Furthermore, we design two innovative
networks, WIN-Na\"ive and WIN, with the latter incorporating advanced
skip-connections to enhance long-term memory. Our methods are evaluated across
diverse RIC tasks, including reversible image hiding, image rescaling, and
image decolorization, consistently achieving state-of-the-art performance.
Extensive experiments validate the effectiveness of our approach, demonstrating
its ability to overcome the bottlenecks of existing RIC solutions and setting a
new benchmark in the field. Codes are available in
https://github.com/BNU-ERC-ITEA/WIN.

</details>


### [21] [GR-Gaussian: Graph-Based Radiative Gaussian Splatting for Sparse-View CT Reconstruction](https://arxiv.org/abs/2508.02408)
*Yikuang Yuluo,Yue Ma,Kuan Shen,Tongtong Jin,Wang Liao,Yangpu Ma,Fuquan Wang*

Main category: eess.IV

TL;DR: GR-Gaussian是一种基于图的3D高斯溅射框架，用于稀疏视图条件下的CT重建，通过改进初始化和梯度计算策略，显著减少针状伪影并提高重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射方法在稀疏视图条件下容易产生针状伪影，影响重建精度。

Method: 提出两种创新策略：1）去噪点云初始化策略，减少初始化误差并加速收敛；2）像素图感知梯度策略，通过基于图的密度差异优化梯度计算。

Result: 在X-3D和真实数据集上验证，PSNR提升0.67 dB和0.92 dB，SSIM提升0.011和0.021。

Conclusion: GR-Gaussian在稀疏视图条件下能有效提高CT重建的准确性和适用性。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a promising approach for CT
reconstruction. However, existing methods rely on the average gradient
magnitude of points within the view, often leading to severe needle-like
artifacts under sparse-view conditions. To address this challenge, we propose
GR-Gaussian, a graph-based 3D Gaussian Splatting framework that suppresses
needle-like artifacts and improves reconstruction accuracy under sparse-view
conditions. Our framework introduces two key innovations: (1) a Denoised Point
Cloud Initialization Strategy that reduces initialization errors and
accelerates convergence; and (2) a Pixel-Graph-Aware Gradient Strategy that
refines gradient computation using graph-based density differences, improving
splitting accuracy and density representation. Experiments on X-3D and
real-world datasets validate the effectiveness of GR-Gaussian, achieving PSNR
improvements of 0.67 dB and 0.92 dB, and SSIM gains of 0.011 and 0.021. These
results highlight the applicability of GR-Gaussian for accurate CT
reconstruction under challenging sparse-view conditions.

</details>


### [22] [Identifying actionable driver mutations in lung cancer using an efficient Asymmetric Transformer Decoder](https://arxiv.org/abs/2508.02431)
*Biagio Brattoli,Jack Shi,Jongchan Park,Taebum Lee,Donggeun Yoo,Sergio Pereira*

Main category: eess.IV

TL;DR: 该研究评估了多种多实例学习（MIL）技术，用于检测非小细胞肺癌（NSCLC）中的六种关键驱动突变，并提出了一种非对称Transformer解码器模型，性能优于现有MIL模型。


<details>
  <summary>Details</summary>
Motivation: 尽管基因检测对NSCLC治疗决策至关重要，但其广泛应用仍受限于可用性和时间成本。机器学习方法虽具潜力，但现有研究多聚焦于少数常见突变，临床价值有限。

Method: 研究采用多实例学习技术，并引入非对称Transformer解码器模型，通过不同维度的查询和键值提取信息，同时直接利用组织类型优化模型。

Result: 该方法平均性能优于现有MIL模型3%，在罕见突变（如ERBB2和BRAF）预测中提升超过4%。

Conclusion: 该研究为ML-based基因检测提供了更实用的替代方案，尤其适用于罕见突变检测。

Abstract: Identifying actionable driver mutations in non-small cell lung cancer (NSCLC)
can impact treatment decisions and significantly improve patient outcomes.
Despite guideline recommendations, broader adoption of genetic testing remains
challenging due to limited availability and lengthy turnaround times. Machine
Learning (ML) methods for Computational Pathology (CPath) offer a potential
solution; however, research often focuses on only one or two common mutations,
limiting the clinical value of these tools and the pool of patients who can
benefit from them. This study evaluates various Multiple Instance Learning
(MIL) techniques to detect six key actionable NSCLC driver mutations: ALK,
BRAF, EGFR, ERBB2, KRAS, and MET ex14. Additionally, we introduce an Asymmetric
Transformer Decoder model that employs queries and key-values of varying
dimensions to maintain a low query dimensionality. This approach efficiently
extracts information from patch embeddings and minimizes overfitting risks,
proving highly adaptable to the MIL setting. Moreover, we present a method to
directly utilize tissue type in the model, addressing a typical MIL limitation
where either all regions or only some specific regions are analyzed, neglecting
biological relevance. Our method outperforms top MIL models by an average of
3%, and over 4% when predicting rare mutations such as ERBB2 and BRAF, moving
ML-based tests closer to being practical alternatives to standard genetic
testing.

</details>


### [23] [From Pixels to Pathology: Restoration Diffusion for Diagnostic-Consistent Virtual IHC](https://arxiv.org/abs/2508.02528)
*Jingsong Liu,Xiaofeng Deng,Han Li,Azar Kazemi,Christian Grashei,Gesa Wilkens,Xin You,Tanja Groll,Nassir Navab,Carolin Mogler,Peter J. Schüffler*

Main category: eess.IV

TL;DR: 论文提出了一种名为Star-Diff的结构感知染色恢复扩散模型，用于从H&E染色虚拟生成IHC图像，解决了现有方法在图像对齐和结构保留上的问题，并通过Semantic Fidelity Score (SFS)评估诊断一致性。


<details>
  <summary>Details</summary>
Motivation: H&E染色缺乏分子诊断信息，而IHC虽提供关键生物标志物表达信息，但成本高且耗时。虚拟染色技术有望填补这一空白，但面临图像对齐和结构保留的挑战。

Method: 提出Star-Diff模型，结合残差和噪声生成路径，将虚拟染色任务重新定义为图像恢复任务，并引入SFS作为临床分级驱动的评估指标。

Result: 在BCI数据集上，Star-Diff在视觉保真度和诊断相关性上达到SOTA性能，具有快速推理和临床实用性。

Conclusion: Star-Diff为术中虚拟IHC合成等应用提供了实用解决方案，解决了虚拟染色技术的核心挑战。

Abstract: Hematoxylin and eosin (H&E) staining is the clinical standard for assessing
tissue morphology, but it lacks molecular-level diagnostic information. In
contrast, immunohistochemistry (IHC) provides crucial insights into biomarker
expression, such as HER2 status for breast cancer grading, but remains costly
and time-consuming, limiting its use in time-sensitive clinical workflows. To
address this gap, virtual staining from H&E to IHC has emerged as a promising
alternative, yet faces two core challenges: (1) Lack of fair evaluation of
synthetic images against misaligned IHC ground truths, and (2) preserving
structural integrity and biological variability during translation. To this
end, we present an end-to-end framework encompassing both generation and
evaluation in this work. We introduce Star-Diff, a structure-aware staining
restoration diffusion model that reformulates virtual staining as an image
restoration task. By combining residual and noise-based generation pathways,
Star-Diff maintains tissue structure while modeling realistic biomarker
variability. To evaluate the diagnostic consistency of the generated IHC
patches, we propose the Semantic Fidelity Score (SFS), a
clinical-grading-task-driven metric that quantifies class-wise semantic
degradation based on biomarker classification accuracy. Unlike pixel-level
metrics such as SSIM and PSNR, SFS remains robust under spatial misalignment
and classifier uncertainty. Experiments on the BCI dataset demonstrate that
Star-Diff achieves state-of-the-art (SOTA) performance in both visual fidelity
and diagnostic relevance. With rapid inference and strong clinical alignment,it
presents a practical solution for applications such as intraoperative virtual
IHC synthesis.

</details>


### [24] [RL-U$^2$Net: A Dual-Branch UNet with Reinforcement Learning-Assisted Multimodal Feature Fusion for Accurate 3D Whole-Heart Segmentation](https://arxiv.org/abs/2508.02557)
*Jierui Qu,Jianchun Zhao*

Main category: eess.IV

TL;DR: 提出了一种基于强化学习的双分支U-Net架构（RL-U²Net），用于多模态3D心脏分割，解决了模态间空间不一致性和特征融合问题，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 多模态心脏分割在心血管疾病诊断中至关重要，但现有方法存在模态间空间不一致、融合策略静态且低效的问题。

Method: 采用双分支U-Net并行处理CT和MRI数据，引入RL-XAlign模块通过强化学习优化特征对齐，最后通过集成学习生成最终分割结果。

Result: 在MM-WHS 2017数据集上，CT和MRI的Dice系数分别达到93.1%和87.0%，优于现有方法。

Conclusion: RL-U²Net在多模态心脏分割中表现出高效性和优越性，为精准诊断提供了有力工具。

Abstract: Accurate whole-heart segmentation is a critical component in the precise
diagnosis and interventional planning of cardiovascular diseases. Integrating
complementary information from modalities such as computed tomography (CT) and
magnetic resonance imaging (MRI) can significantly enhance segmentation
accuracy and robustness. However, existing multi-modal segmentation methods
face several limitations: severe spatial inconsistency between modalities
hinders effective feature fusion; fusion strategies are often static and lack
adaptability; and the processes of feature alignment and segmentation are
decoupled and inefficient. To address these challenges, we propose a
dual-branch U-Net architecture enhanced by reinforcement learning for feature
alignment, termed RL-U$^2$Net, designed for precise and efficient multi-modal
3D whole-heart segmentation. The model employs a dual-branch U-shaped network
to process CT and MRI patches in parallel, and introduces a novel RL-XAlign
module between the encoders. The module employs a cross-modal attention
mechanism to capture semantic correspondences between modalities and a
reinforcement-learning agent learns an optimal rotation strategy that
consistently aligns anatomical pose and texture features. The aligned features
are then reconstructed through their respective decoders. Finally, an
ensemble-learning-based decision module integrates the predictions from
individual patches to produce the final segmentation result. Experimental
results on the publicly available MM-WHS 2017 dataset demonstrate that the
proposed RL-U$^2$Net outperforms existing state-of-the-art methods, achieving
Dice coefficients of 93.1% on CT and 87.0% on MRI, thereby validating the
effectiveness and superiority of the proposed approach.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Construction of $(n,n)$-functions with low differential-linear uniformity](https://arxiv.org/abs/2508.01190)
*Xi Xie,Nian Li,Qiang Wang,Xiangyong Zeng,Yinglong Du*

Main category: cs.IT

TL;DR: 本文研究了$(n,n)$-函数的差分-线性性质，提出了两类具有低差分-线性均匀性（DLU）的幂函数，并通过结合已知DLU的幂函数构造了多类低DLU的$(n,n)$-函数。


<details>
  <summary>Details</summary>
Motivation: 差分-线性攻击是密码分析中的重要方法，而差分-线性连通表（DLCT）是分析其子密码依赖性的新工具。本文旨在探索$(n,n)$-函数的差分-线性性质，以构造低DLU的函数。

Method: 通过细化指数和，提出两类低DLU的幂函数；结合已知DLU的幂函数，利用三次函数和二次函数以及广义分圆映射，构造多类低DLU的$(n,n)$-函数。

Result: 成功构造了多类低DLU的$(n,n)$-函数，部分结果达到或接近现有最优水平。

Conclusion: 本文通过理论分析和构造，扩展了低DLU函数的类别，为密码设计提供了新的选择。

Abstract: The differential-linear connectivity table (DLCT), introduced by Bar-On et
al. at EUROCRYPT'19, is a novel tool that captures the dependency between the
two subciphers involved in differential-linear attacks. This paper is devoted
to exploring the differential-linear properties of $(n,n)$-functions. First, by
refining specific exponential sums, we propose two classes of power functions
over $\mathbb{F}_{2^n}$ with low differential-linear uniformity (DLU). Next, we
further investigate the differential-linear properties of $(n,n)$-functions
that are polynomials by utilizing power functions with known DLU. Specifically,
by combining a cubic function with quadratic functions, and employing
generalized cyclotomic mappings, we construct several classes of
$(n,n)$-functions with low DLU, including some that achieve optimal or
near-optimal DLU compared to existing results.

</details>


### [26] [Near-Field Communication with Massive Movable Antennas: A Functional Perspective](https://arxiv.org/abs/2508.01201)
*Shicong Liu,Xianghao Yu,Jie Xu,Rui Zhang*

Main category: cs.IT

TL;DR: 论文研究了大规模MIMO系统中天线部署对近场通信速率的影响，提出了一种基于连续天线位置和密度函数的设计框架，并给出了优化算法和闭式解。


<details>
  <summary>Details</summary>
Motivation: 探索近场条件下天线部署对通信速率的优化潜力，解决传统离散天线部署方法的局限性。

Method: 提出连续天线位置函数（APF）和天线密度函数（ADF），将问题转化为连续域优化，利用泛函分析和变分法求解最优ADF，并设计梯度算法。

Result: 在近场视距场景下给出了最优ADF的闭式解，仿真验证了均匀圆形阵列在性能和可行性上的优势。

Conclusion: 提出的框架有效优化了近场通信速率，为实际部署提供了灵活且高效的解决方案。

Abstract: The advent of massive multiple-input multiple-output (MIMO) technology has
provided new opportunities for capacity improvement via strategic antenna
deployment, especially when the near-field effect is pronounced due to antenna
proliferation. In this paper, we investigate the optimal antenna placement for
maximizing the achievable rate of a point-to-point near-field channel, where
the transmitter is deployed with massive movable antennas. First, we propose a
novel design framework to explore the relationship between antenna positions
and achievable data rate. By introducing the continuous antenna position
function (APF) and antenna density function (ADF), we reformulate the antenna
position design problem from the discrete to the continuous domain, which
maximizes the achievable rate functional with respect to ADF. Leveraging
functional analysis and variational methods, we derive the optimal ADF
condition and propose a gradient-based algorithm for numerical solutions under
general channel conditions. Furthermore, for the near-field line-of-sight (LoS)
scenario, we present a closed-form solution for the optimal ADF, revealing the
critical role of edge antenna density in enhancing the achievable rate.
Finally, we propose a flexible antenna array-based deployment method that
ensures practical implementation while mitigating mutual coupling issues.
Simulation results demonstrate the effectiveness of the proposed framework,
with uniform circular arrays emerging as a promising geometry for balancing
performance and deployment feasibility in near-field communications.

</details>


### [27] [Towed Movable Antenna (ToMA) Array for Ultra Secure Airborne Communications](https://arxiv.org/abs/2508.01229)
*Lipeng Zhu,Haobin Mao,Wenyan Ma,Zhenyu Xiao,Jun Zhang,Rui Zhang*

Main category: cs.IT

TL;DR: 提出了一种新型拖曳式可移动天线（ToMA）阵列架构，以增强机载通信系统的物理层安全性。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线（FPA）阵列在机载通信中灵活性不足，ToMA阵列通过动态部署和几何重构提升安全性和性能。

Method: 采用拖曳式多子阵列设计，优化天线位置向量（APV），结合零波束成形和Riemannian流形优化算法。

Result: ToMA阵列显著提升了用户的可达速率，尤其在窃听者靠近用户的场景下优于传统FPA阵列。

Conclusion: ToMA阵列通过动态部署和优化设计，为机载通信提供了更高的安全性和性能增益。

Abstract: This paper proposes a novel towed movable antenna (ToMA) array architecture
to enhance the physical layer security of airborne communication systems.
Unlike conventional onboard arrays with fixed-position antennas (FPAs), the
ToMA array employs multiple subarrays mounted on flexible cables and towed by
distributed drones, enabling agile deployment in three-dimensional (3D) space
surrounding the central aircraft. This design significantly enlarges the
effective array aperture and allows dynamic geometry reconfiguration, offering
superior spatial resolution and beamforming flexibility. We consider a secure
transmission scenario where an airborne transmitter communicates with multiple
legitimate users in the presence of potential eavesdroppers. To ensure
security, zero-forcing beamforming is employed to nullify signal leakage toward
eavesdroppers. Based on the statistical distributions of locations of users and
eavesdroppers, the antenna position vector (APV) of the ToMA array is optimized
to maximize the users' ergodic achievable rate. Analytical results for the case
of a single user and a single eavesdropper reveal the optimal APV structure
that minimizes their channel correlation. For the general multiuser scenario,
we develop a low-complexity alternating optimization algorithm by leveraging
Riemannian manifold optimization. Simulation results confirm that the proposed
ToMA array achieves significant performance gains over conventional onboard FPA
arrays, especially in scenarios where eavesdroppers are closely located to
users under line-of-sight (LoS)-dominant channels.

</details>


### [28] [New constant-dimension subspace codes from parallel cosets of optimal Ferrers diagram rank-metric codes and multilevel inserting constructions](https://arxiv.org/abs/2508.01258)
*Gang Wang,Hong-Yang Yao,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 论文提出了一种新的恒定维度子空间码（CDC）构造方法，通过结合平行陪集和多级构造，建立了65个新的下界。


<details>
  <summary>Details</summary>
Motivation: 恒定维度子空间码在网络编码中有重要应用，研究其最大码字数量是一个基础问题。

Method: 利用平行陪集和最优FDRMCs构造CDC，结合多级构造和新的标识向量集。

Result: 提出了三类大尺寸CDC，其中一类使用了新的最优FDRMCs，并建立了65个新的下界。

Conclusion: 新方法显著提升了CDC的性能，为网络编码提供了更优的解决方案。

Abstract: Constant-dimension subspace codes (CDCs), a special class of subspace codes,
have attracted significant attention due to their applications in network
coding. A fundamental research problem of CDCs is to determine the maximum
number of codewords under the given parameters. The paper first proposes the
construction of parallel cosets of optimal Ferrers diagram rank-metric codes
(FDRMCs) by employing the list of CDCs and inverse list of CDCs. Then a new
class of CDCs is obtained by combining the parallel cosets of optimal FDRMCs
with parallel linkage construction. Next, we present a novel set of identifying
vectors and provide a new construction of CDCs via the multilevel constuction.
Finally, the coset construction is inserted into the multilevel construction
and three classes of large CDCs are provided, one of which is constructed by
using new optimal FDRMCs. Our results establish at least 65 new lower bounds
for CDCs with larger sizes than the previously best known codes.

</details>


### [29] [Information Rates of Approximate Message Passing for Bandlimited Direct-Detection Channels](https://arxiv.org/abs/2508.01438)
*Daniel Plabst,Mohamed Akrout,Amine Mezghani,Gerhard Kramer*

Main category: cs.IT

TL;DR: 论文提出了一种GVAMP检测器，用于解决带限直接检测信道的容量计算问题，通过多级编码和干扰消除提高速率，并在光纤信道中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 带限直接检测信道的容量计算因接收器非线性而困难，需要一种高效且复杂度可控的方法。

Method: 设计了GVAMP检测器，结合多级编码和连续干扰消除技术，应用于具有长符号间干扰的光纤信道。

Result: 双极性调制在功率效率上优于单极性调制，GVAMP检测器在复杂度和性能上优于现有神经网络方法。

Conclusion: GVAMP检测器在提高信道容量和功率效率方面表现出色，且对信道参数变化具有鲁棒性。

Abstract: The capacity of bandlimited direct-detection channels is difficult to compute
or approach because of the receiver nonlinearity. A generalized vector
approximate message passing (GVAMP) detector is designed to achieve high rates
with reasonable complexity. The rates increase by using multi-level coding and
successive interference cancellation. The methods are applied to optical fiber
channels with long intersymbol interference, as encountered in practice.
Bipolar modulation operates within 0.3 bits per channel use (bpcu) of the
real-alphabet coherent capacity for optically-amplified links, improving the
best existing gap of 1 bpcu based on theory. Remarkably, bipolar modulation
gains 6 decibels (dB) in power efficiency over unipolar modulation, and 3 dB
for unamplified links. The detector is robust to changes in channel parameters
such as the fiber length. The GVAMP complexity, measured in multiplications per
information bit (mpib), is proportional to the number of iterations and the
logarithm of the block length, and is substantially less than state-of-the-art
neural networks. The receiver requires approximately 38 iterations to achieve a
rate of 5 bpcu with 80 mpib.

</details>


### [30] [Explicit Function-Correcting Code Constructions for Lee Metric Channels](https://arxiv.org/abs/2508.01702)
*Hareesh K.,Rashid Ummer N. T.,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 本文提出了一种改进的Plotkin-like边界，用于不规则Lee距离码，并构建了针对特定函数类（如Lee权重、模和等）的显式函数校正Lee码（FCLCs），证明了其冗余度在某些情况下是最优的。


<details>
  <summary>Details</summary>
Motivation: 研究函数校正码（FCCs）以保护函数评估免受错误影响，同时最小化冗余度。

Method: 提出改进的Plotkin-like边界，构建显式FCLCs，并分析其冗余度。

Result: FCLCs在特定函数类中表现最优，且相比传统Lee纠错码能显著减少冗余。

Conclusion: FCLCs在保护函数正确性的同时，有效降低了冗余度，具有实际应用潜力。

Abstract: Function-Correcting Codes (FCCs) are a novel class of codes designed to
protect function evaluations of messages against errors while minimizing
redundancy. A theoretical framework for systematic FCCs to channels matched to
the Lee metric has been studied recently, which introduced function-correcting
Lee codes (FCLCs) and also derived upper and lower bounds on their optimal
redundancy. In this paper, we propose a Plotkin-like bound for irregular
Lee-distance codes, which improves an existing bound. We construct explicit
FCLCs for specific classes of functions, including the Lee weight, Lee weight
distribution, modular sum, and locally bounded function. For these functions,
lower bounds on redundancy are obtained, and our constructions are shown to be
optimal in certain cases. Finally, a comparative analysis with classical Lee
error-correcting codes and codes correcting errors in function values
demonstrates that FCLCs can significantly reduce redundancy while preserving
function correctness.

</details>


### [31] [Implementing Neural Networks Over-the-Air via Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2508.01840)
*Meng Hua,Chenghong Bian,Haotian Wu,Deniz Gunduz*

Main category: cs.IT

TL;DR: 论文提出了一种名为AirFC的新型计算范式，利用RIS辅助的MIMO OAC系统模拟神经网络的全连接层，并通过联合优化和两种训练策略实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用RIS和MIMO OAC系统模拟神经网络的FC层，以优化无线传播环境并实现高效计算。

Method: 提出了一种低复杂度的交替优化算法，联合优化预编码器、组合器和RIS相位矩阵，并采用集中式和分布式两种训练策略。

Result: 仿真结果表明，RIS辅助的MIMO配置实现的AirFC系统在分类任务中表现出色。

Conclusion: AirFC系统通过RIS和MIMO OAC的联合优化，能够有效模拟FC层并实现高性能计算。

Abstract: In this paper, we investigate reconfigurable intelligent surface (RIS)-aided
multiple-input-multiple-output (MIMO) OAC systems designed to emulate the
fully-connected (FC) layer of a neural network (NN) via analog OAC, where the
RIS and the transceivers are jointly adjusted to engineer the ambient wireless
propagation environment to emulate the weights of the target FC layer. We refer
to this novel computational paradigm as AirFC. We first study the case in which
the precoder, combiner, and RIS phase shift matrices are jointly optimized to
minimize the mismatch between the OAC system and the target FC layer. To solve
this non-convex optimization problem, we propose a low-complexity alternating
optimization algorithm, where semi-closed-form/closed-form solutions for all
optimization variables are derived. Next, we consider training of the system
parameters using two distinct learning strategies, namely centralized training
and distributed training. In the centralized training approach, training is
performed at either the transmitter or the receiver, whichever possesses the
channel state information (CSI), and the trained parameters are provided to the
other terminal. In the distributed training approach, the transmitter and
receiver iteratively update their parameters through back and forth
transmissions by leveraging channel reciprocity, thereby avoiding CSI
acquisition and significantly reducing computational complexity. Subsequently,
we extend our analysis to a multi-RIS scenario by exploiting its spatial
diversity gain to enhance the system performance. Simulation results show that
the AirFC system realized by the RIS-aided MIMO configuration achieves
satisfactory classification accuracy.

</details>


### [32] [Robust Detection of Planted Subgraphs in Semi-Random Models](https://arxiv.org/abs/2508.02158)
*Dor Elimelech,Wasim Huleihel*

Main category: cs.IT

TL;DR: 研究了在半随机模型中检测植入子图的问题，揭示了统计极限的尖锐二分性，并提出了新的高效检测算法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多基于纯随机生成模型，而现实中的扰动可能使算法失效，因此需要研究半随机模型的鲁棒性。

Method: 在半随机模型中，允许对手移除植入子图外的边，统计学家无法得知移除情况，研究了统计极限并设计了高效算法。

Result: 对于最大密度强亚对数的子图，检测在信息论上不可能；而对于超对数密度的子图，统计极限不变。

Conclusion: 建立了首个鲁棒的植入子图检测框架，为半随机模型和计算-统计权衡研究开辟了新方向。

Abstract: Detection of planted subgraphs in Erd\"os-R\'enyi random graphs has been
extensively studied, leading to a rich body of results characterizing both
statistical and computational thresholds. However, most prior work assumes a
purely random generative model, making the resulting algorithms potentially
fragile in the face of real-world perturbations. In this work, we initiate the
study of semi-random models for the planted subgraph detection problem, wherein
an adversary is allowed to remove edges outside the planted subgraph before the
graph is revealed to the statistician. Crucially, the statistician remains
unaware of which edges have been removed, introducing fundamental challenges to
the inference task. We establish fundamental statistical limits for detection
under this semi-random model, revealing a sharp dichotomy. Specifically, for
planted subgraphs with strongly sub-logarithmic maximum density detection
becomes information-theoretically impossible in the presence of an adversary,
despite being possible in the classical random model. In stark contrast, for
subgraphs with super-logarithmic density, the statistical limits remain
essentially unchanged; we prove that the optimal (albeit computationally
intractable) likelihood ratio test remains robust. Beyond these statistical
boundaries, we design a new computationally efficient and robust detection
algorithm, and provide rigorous statistical guarantees for its performance. Our
results establish the first robust framework for planted subgraph detection and
open new directions in the study of semi-random models,
computational-statistical trade-offs, and robustness in graph inference
problems.

</details>


### [33] [Sequence Reconstruction over Coloring Channels for Protein Identification](https://arxiv.org/abs/2508.02229)
*Jessica Bariffi,Antonia Wachter-Zeh,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究基于蛋白质识别的序列重构问题，提出一种着色通道模型，分析其信息率和容量，证明最优着色配置对应2-覆盖设计，并确定最大信息率所需的最小覆盖数。


<details>
  <summary>Details</summary>
Motivation: 研究序列重构问题，特别是受蛋白质识别启发的通道模型，以探索信息传输的效率和限制。

Method: 引入着色通道和着色配置概念，通过删除不属于固定子集的符号，分析信息率和容量，并证明最优配置与2-覆盖设计的关系。

Result: 证明最优着色配置对应2-覆盖设计，确定了最大信息率所需的最小覆盖数，以及任何配置均最优的最小数量。

Conclusion: 通过着色通道模型，揭示了序列重构问题的信息传输极限，为相关应用提供了理论支持。

Abstract: This paper studies the sequence reconstruction problem for a channel inspired
by protein identification. We introduce a coloring channel, where a sequence is
transmitted through a channel that deletes all symbols not belonging to a fixed
subset (the coloring) of the alphabet. By extending this to a coloring profile,
a tuple of distinct colorings, we analyze the channel's information rate and
capacity. We prove that optimal (i.e., achieving maximum information rate)
coloring profiles correspond to 2-covering designs and identify the minimal
covering number required for maximum information rate, as well as the minimum
number for which any coloring profile is optimal.

</details>


### [34] [Large AI Models for Wireless Physical Layer](https://arxiv.org/abs/2508.02314)
*Jiajia Guo,Yiming Cui,Shi Jin,Jun Zhang*

Main category: cs.IT

TL;DR: 本文综述了大型人工智能模型（LAMs）在无线物理层技术中的应用，探讨了其优势及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统AI方法在物理层通信中存在局限性，LAMs因其强大的泛化、多任务和多模态能力成为改进方向。

Method: LAM应用分为两类：利用预训练LAMs和开发专为物理层任务设计的原生LAMs。

Result: 两种策略显著提升了无线场景下的性能和适应性。

Conclusion: 未来研究需关注高效架构、可解释性、标准化数据集及大小模型协作，以推动下一代通信系统的LAM解决方案。

Abstract: Large artificial intelligence models (LAMs) are transforming wireless
physical layer technologies through their robust generalization, multitask
processing, and multimodal capabilities. This article reviews recent
advancements in LAM applications for physical layer communications, addressing
limitations of conventional AI-based approaches. LAM applications are
classified into two strategies: leveraging pre-trained LAMs and developing
native LAMs designed specifically for physical layer tasks. The motivations and
key frameworks of these approaches are comprehensively examined through
multiple use cases. Both strategies significantly improve performance and
adaptability across diverse wireless scenarios. Future research directions,
including efficient architectures, interpretability, standardized datasets, and
collaboration between large and small models, are proposed to advance LAM-based
physical layer solutions for next-generation communication systems.

</details>


### [35] [Properties and Decoding of Twisted GRS Codes and Their Extensions](https://arxiv.org/abs/2508.02382)
*Yang Li,Martianus Frederic Ezerman,Huimin Lao,San Ling*

Main category: cs.IT

TL;DR: 本文研究了非广义Reed-Solomon（GRS）MDS码和近MDS（NMDS）码，特别是通过扭曲GRS（TGRS）构造的两类候选码（$(+)$-TGRS和$(+)$-ETGRS），解决了其是否为非GRS MDS码的问题，并改进了其解码算法。


<details>
  <summary>Details</summary>
Motivation: 研究非GRS MDS码和NMDS码在通信、密码学和存储系统中的应用，并填补现有理论中的空白。

Method: 通过分析$(+)$-TGRS和$(+)$-ETGRS码的性质，解决其是否为非GRS MDS码的问题，并开发了一种优于现有算法的解码方法。

Result: 发现了两类非GRS MDS Hermitian自对偶TGRS码，证明了不存在Galois自对偶ETGRS码，并提出了一种高效的ETGRS解码算法。

Conclusion: 研究为TGRS和ETGRS码的理论和应用提供了新的见解，特别是在解码和自对偶性方面。

Abstract: Maximum distance separable (MDS) codes that are not equivalent to generalized
Reed-Solomon (GRS) codes are called non-GRS MDS codes. Alongside near MDS
(NMDS) codes, they are applicable in communication, cryptography, and storage
systems. From theoretical perspective, it is particularly intriguing to
investigate families of linear codes in which each element can be determined to
be either a non-GRS MDS or an NMDS code. Two promising candidates for such
families emerge from what is known as twisted GRS (TGRS) construction. These
candidates are the $(+)$-TGRS codes and their extended versions, called
$(+)$-extended TGRS (ETGRS) codes.
  Although many of their properties have been characterized, there are gaps to
fill. Which among the codes are non-GRS MDS? Can we improve on their decoding
by using their error-correcting pairs or deep holes? In this paper we solve
these problems. The answer to the first problem leads us to two classes of
non-GRS MDS Hermitian self-dual TGRS codes and a proof that there is no Galois
self-dual ETGRS code. Addressing the second problem, we present an explicit
decoding algorithm for ETGRS codes that outperforms existing decoding
algorithms given some conditions. By considering the duals of TGRS codes which
are MDS, we determine the covering radius and a class of deep holes of the
recently constructed non-GRS MDS codes due to Han and Zhang.

</details>


### [36] [CSI Obfuscation: Single-Antenna Transmitters Can Not Hide from Adversarial Multi-Antenna Radio Localization Systems](https://arxiv.org/abs/2508.02553)
*Phillip Stephan,Florian Euchner,Stephan ten Brink*

Main category: cs.IT

TL;DR: 论文探讨了现代电信系统中用户位置隐私的保护问题，提出了一种针对多天线接收器的CSI恢复方法，以对抗信号混淆技术。


<details>
  <summary>Details</summary>
Motivation: 现代电信系统能够通过无线电环境定位用户和物体，引发了隐私问题。信号混淆技术虽能防止单天线接收器的定位，但对多天线接收器无效。

Method: 提出了一种基于盲多通道识别的CSI恢复方法，用于多天线接收器提取信道特征，确保可靠的用户定位。

Result: 通过实际信道测量评估了信号混淆和恢复方法对CSI指纹、信道图表和三角定位的影响。

Conclusion: 研究表明需要进一步努力保护用户位置隐私，防止基于无线电的敌对定位系统。

Abstract: The ability of modern telecommunication systems to locate users and objects
in the radio environment raises justified privacy concerns. To prevent
unauthorized localization, single-antenna transmitters can obfuscate the signal
by convolving it with a randomized sequence prior to transmission, which alters
the channel state information (CSI) estimated at the receiver. However, this
strategy is only effective against CSI-based localization systems deploying
single-antenna receivers. Inspired by the concept of blind multichannel
identification, we propose a simple CSI recovery method for multi-antenna
receivers to extract channel features that ensure reliable user localization
regardless of the transmitted signal. We comparatively evaluate the impact of
signal obfuscation and the proposed recovery method on the localization
performance of CSI fingerprinting, channel charting, and classical
triangulation using real-world channel measurements. This work aims to
demonstrate the necessity for further efforts to protect the location privacy
of users from adversarial radio-based localization systems.

</details>


### [37] [The Length of Functional Batch and PIR Codes](https://arxiv.org/abs/2508.02586)
*Altan B. Kilic,Alberto Ravagnani,Flavio Salizzoni*

Main category: cs.IT

TL;DR: 论文研究了在任意有限域上计算固定维度和固定列表大小的功能批处理和PIR码的最小长度问题，推广并改进了先前针对二进制码的结果。


<details>
  <summary>Details</summary>
Motivation: 探讨非二进制有限域上功能批处理猜想中的“正确”列表大小，并填补相关研究的空白。

Method: 提出新的上下界，分析参数的渐进行为，并计算多个参数集的最小长度。

Result: 得出了最小长度的新上下界，并验证了多个参数集的具体值。

Conclusion: 论文为非二进制有限域的功能批处理猜想提供了理论支持和实际计算验证。

Abstract: We consider the problem of computing the minimum length of functional batch
and PIR codes of fixed dimension and for a fixed list size, over an arbitrary
finite field. We recover, generalize, and refine several results that were
previously obtained for binary codes. We present new upper and lower bounds for
the minimum length, and discuss the asymptotic behaviour of this parameter. We
also compute its value for several parameter sets. The paper also offers
insights into the "correct" list size to consider for the Functional Batch
Conjecture over non-binary finite fields, and establishes various supporting
results.

</details>


### [38] [RC-Gossip: Information Freshness in Clustered Networks with Rate-Changing Gossip](https://arxiv.org/abs/2508.02657)
*Irtiza Hasan,Ahmed Arafa*

Main category: cs.IT

TL;DR: 论文提出了一种名为RC-Gossip的智能信息传播机制，通过动态调整传播速率来提高网络中节点的信息新鲜度。


<details>
  <summary>Details</summary>
Motivation: 研究如何在集群化的Gossip网络中，通过优化信息传播策略，使节点尽可能保持与源节点信息同步。

Method: 提出RC-Gossip机制，根据网络中新鲜节点的数量动态调整传播速率，并采用基于更新奖励的方法分析信息新鲜度。

Result: RC-Gossip在优化集群大小的网络中显著提高了节点的信息新鲜度，优于传统Gossip技术。

Conclusion: RC-Gossip是一种有效的动态信息传播策略，适用于集群化网络，能显著提升信息新鲜度。

Abstract: A clustered gossip network is considered in which a source updates its
information over time, and end-nodes, organized in clusters through
clusterheads, are keeping track of it. The goal for the nodes is to remain as
fresh as possible, i.e., have the same information as the source, which we
assess by the long-term average binary freshness metric. We introduce a smart
mechanism of information dissemination which we coin rate-changing gossip
(RC-Gossip). Its main idea is that gossiping is directed towards nodes that
need it the most, and hence the rate of gossiping changes based on the number
of fresh nodes in the network at a given time. While Stochastic Hybrid System
(SHS) analysis has been the norm in studying freshness of gossip networks, we
present an equivalent way to analyze freshness using a renewal-reward-based
approach. Using that, we show that RC-gossip significantly increases freshness
of nodes in different clustered networks, with optimal cluster sizes, compared
to traditional gossiping techniques.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [39] [Binary Hypothesis Testing-Based Low-Complexity Beamspace Channel Estimation for mmWave Massive MIMO Systems](https://arxiv.org/abs/2508.01007)
*Hanyoung Park,Ji-Woong Choi*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯二元假设检验和波束空间稀疏性的低复杂度信道去噪方法，适用于毫米波通信系统。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信系统因信号特性（如严重路径损耗、散射差）需要高复杂度信道估计，但频繁更新信道带来计算负担。

Method: 利用Bernoulli-复高斯先验建模稀疏波束空间分量，通过似然比检验检测信号相关元素，并应用硬阈值规则抑制噪声主导分量。

Result: 尽管计算复杂度极低，该方法在信道估计精度上与复杂迭代或基于学习的方法相当。

Conclusion: 该方法为资源受限的毫米波系统提供了一种可行的信道估计方案。

Abstract: Millimeter-wave (mmWave) communications have gained attention as a key
technology for high-capacity wireless systems, owing to the wide available
bandwidth. However, mmWave signals suffer from their inherent characteristics
such as severe path loss, poor scattering, and limited diffraction, which
necessitate the use of large antenna arrays and directional beamforming,
typically implemented through massive MIMO architectures. Accurate channel
estimation is critical in such systems, but its computational complexity
increases proportionally with the number of antennas. This may become a
significant burden in mmWave systems where channels exhibit rapid fluctuations
and require frequent updates. In this paper, we propose a low-complexity
channel denoiser based on Bayesian binary hypothesis testing and beamspace
sparsity. By modeling each sparse beamspace component as a mixture of signal
and noise under a Bernoulli-complex Gaussian prior, we formulate a likelihood
ratio test to detect signal-relevant elements. Then, a hard-thresholding rule
is applied to suppress noise-dominant components in the noisy channel vector.
Despite its extremely low computational complexity, the proposed method
achieves channel estimation accuracy that is comparable to that of complex
iterative or learning-based approaches. This effectiveness is supported by both
theoretical analysis and numerical evaluation, suggesting that the method can
be a viable option for mmWave systems with strict resource constraints.

</details>


### [40] [Coordinated Decentralized Resource Optimization for Cell-Free ISAC Systems](https://arxiv.org/abs/2508.01044)
*Mehdi Zafari,Rang Liu,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 提出两种去中心化优化算法，用于无小区ISAC网络中的波束成形和功率分配，以解决集中式架构的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC解决方案依赖集中式架构，限制了分布式系统的可扩展性。

Method: 第一种算法结合本地设计的固定波束成形器和集中式功率分配；第二种算法通过完全去中心化的ADMM框架联合优化波束成形和功率控制。

Result: 仿真结果表明，两种算法在去中心化无小区架构中具有较低的fronthaul开销和良好的系统性能。

Conclusion: 提出的算法适用于可扩展的去中心化ISAC部署。

Abstract: Integrated Sensing and Communication (ISAC) is emerging as a key enabler for
6G wireless networks, allowing the joint use of spectrum and infrastructure for
both communication and sensing. While prior ISAC solutions have addressed
resource optimization, including power allocation, beamforming, and waveform
design, they often rely on centralized architectures with full network
knowledge, limiting their scalability in distributed systems. In this paper, we
propose two coordinated decentralized optimization algorithms for beamforming
and power allocation tailored to cell-free ISAC networks. The first algorithm
employs locally designed fixed beamformers at access points (APs), combined
with a centralized power allocation scheme computed at a central server (CS).
The second algorithm jointly optimizes beamforming and power control through a
fully decentralized consensus ADMM framework. Both approaches rely on local
information at APs and limited coordination with the CS. Simulation results
obtained using our proposed Python-based simulation framework evaluate their
fronthaul overhead and system-level performance, demonstrating their
practicality for scalable ISAC deployment in decentralized, cell-free
architectures.

</details>


### [41] [A Highly Available GTFS-RT Positions System](https://arxiv.org/abs/2508.01121)
*Joshua Wong,Kin Tsang*

Main category: eess.SP

TL;DR: 开发了一个基于GTFS-RT标准的实时公共交通数据系统，包括硬件设计、算法实现和高可用部署。


<details>
  <summary>Details</summary>
Motivation: 利用开放数据格式GTFS-RT，提供实时公共交通数据服务。

Method: 设计GPS传感器设备及固件，开发算法将原始数据转换为GTFS-RT格式，并通过多区域高可用集群部署。

Result: 成功实现了实时数据的高可用性传输。

Conclusion: 该系统为公共交通提供了可靠的实时数据解决方案。

Abstract: We develop a system for real-time public transportation data, deciding to use
the data standard GTFS-RT (GTFS Realtime), an open data format for public
transit data. We give an overview of the design of a physical GPS sensor
device, its firmware, and processes. Next, we give the algorithms used to
translate raw sensor data into a public GTFS-RT data feed. We deploy this feed
over a highly available cluster across multiple regions to maintain high
availability.

</details>


### [42] [On the Characterization and Evaluation of Doppler Squint in Wideband ODDM Systems](https://arxiv.org/abs/2508.01283)
*Xuehan Wang,Jinhong Yuan,Jintao Wang,Zhi Sun*

Main category: eess.SP

TL;DR: 本文研究了正交延迟-多普勒分复用（ODDM）调制中的宽带效应（多普勒斜视效应，DSE），分析了其对系统性能的影响，并提出了理论推导和数值验证。


<details>
  <summary>Details</summary>
Motivation: 先前的研究忽略了ODDM信号的宽带特性导致的交互色散，可能导致性能下降，因此需要深入研究DSE对系统的影响。

Method: 通过分析多径信道的时变频率响应，解释了DSE引起的额外延迟-多普勒色散，并推导了RCP和ZP宽带ODDM系统的特性。

Result: 理论分析表明DSE会导致额外的延迟-多普勒扩展和更复杂的功率泄漏，数值结果验证了DSE的重要性。

Conclusion: 本文的推导有助于开发更准确的信号处理技术，适用于基于ODDM的集成感知与通信系统。

Abstract: The recently proposed orthogonal delay-Doppler division multiplexing (ODDM)
modulation has been demonstrated to enjoy excellent reliability over
doubly-dispersive channels. However, most of the prior analysis tends to ignore
the interactive dispersion caused by the wideband property of ODDM signal,
which possibly leads to performance degradation. To solve this problem, we
investigate the input-output relation of ODDM systems considering the wideband
effect, which is also known as the Doppler squint effect (DSE) in the
literature. The extra delay-Doppler (DD) dispersion caused by the DSE is first
explicitly explained by employing the time-variant frequency response of
multipath channels. Its characterization is then derived for both reduced
cyclic prefix (RCP) and zero padded (ZP)-based wideband ODDM systems, where the
extra DD spread and more complicated power leakage outside the peak region are
presented theoretically. Numerical results are finally provided to confirm the
significance of DSE. The derivations in this paper are beneficial for
developing accurate signal processing techniques in ODDM-based integrated
sensing and communication systems.

</details>


### [43] [DIY hybrid SSVEP-P300 LED stimuli for BCI platform using EMOTIV EEG headset](https://arxiv.org/abs/2508.01510)
*Surej Mouli,Ramaswamy Palaniappan*

Main category: eess.SP

TL;DR: 本文介绍了一种可定制化的COB LED设计，用于同时诱发两种脑电反应（SSVEP和P300），旨在减少疲劳并提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 在脑机接口（BCI）中，SSVEP因其所需电极少且训练时间短而被广泛接受。本研究旨在开发一种混合BCI硬件平台，以精确诱发SSVEP和P300。

Method: 系统由四个独立的绿色视觉刺激和一个32位微控制器平台控制，用于诱发SSVEP；四个红色LED随机闪烁以生成P300事件，并记录时间戳以提高分类准确性。

Result: 混合刺激通过控制乐高机器人进行实时分类测试，验证了其准确性。

Conclusion: 该设计成功实现了SSVEP和P300的精确诱发，提高了分类性能和可靠性。

Abstract: A fully customisable chip-on board (COB) LED design to evoke two brain
responses simultaneously (steady state visual evoked potential (SSVEP) and
transient evoked potential, P300) is discussed in this paper. Considering
different possible modalities in braincomputer interfacing (BCI), SSVEP is
widely accepted as it requires a lesser number of electroencephalogram (EEG)
electrodes and minimal training time. The aim of this work was to produce a
hybrid BCI hardware platform to evoke SSVEP and P300 precisely with reduced
fatigue and improved classification performance. The system comprises of four
independent radial green visual stimuli controlled individually by a 32-bit
microcontroller platform to evoke SSVEP and four red LEDs flashing at random
intervals to generate P300 events. The system can also record the P300 event
timestamps that can be used in classification, to improve the accuracy and
reliability. The hybrid stimulus was tested for realtime classification
accuracy by controlling a LEGO robot to move in four directions.

</details>


### [44] [Balancing Latency and Model Accuracy for Fluid Antenna-Assisted LM-Embedded MIMO Network](https://arxiv.org/abs/2508.01689)
*Yichen Jin,Zongze Li,Zeyi Ren,Qingfeng Lin,Yik-Chung Wu*

Main category: eess.SP

TL;DR: 论文提出了一种基于流体天线（FA）技术的优化方法，用于解决大型模型（LM）嵌入无线网络中模型精度与网络延迟的权衡问题。通过量化LM和FA技术提升传输容量，降低延迟，同时保持推理精度。


<details>
  <summary>Details</summary>
Motivation: 解决LM嵌入无线网络中模型精度与网络延迟的权衡问题，以保障用户服务质量。

Method: 提出LM量化和FA技术，设计目标函数考虑延迟和峰值信噪比（PSNR），并在块坐标下降框架下提出优化算法。

Result: 仿真结果表明，所提算法收敛良好，FA辅助的LM嵌入网络在延迟和PSNR方面优于其他基准网络。

Conclusion: FA技术能有效降低网络延迟并保持LM推理精度，为LM嵌入无线网络提供了可行的解决方案。

Abstract: This paper addresses the challenge of large model (LM)-embedded wireless
network for handling the trade-off problem of model accuracy and network
latency. To guarantee a high-quality of users' service, the network latency
should be minimized while maintaining an acceptable inference accuracy. To meet
this requirement, LM quantization is proposed to reduce the latency. However,
the excessive quantization may destroy the accuracy of LM inference. To this
end, a promising fluid antenna (FA) technology is investigated for enhancing
the transmission capacity, leading to a lower network latency in the
LM-embedded multiple-input multiple-output (MIMO) network. To design the
FA-assisted LM-embedded network with the lower latency and higher accuracy
requirements, the latency and peak signal to noise ratio (PSNR) are considered
in the objective function. Then, an efficient optimization algorithm is
proposed under the block coordinate descent framework. Simulation results are
provided to show the convergence behavior of the proposed algorithm, and the
performance gains from the proposed FA-assisted LMembedded network over the
other benchmark networks in terms of network latency and PSNR.

</details>


### [45] [Spectrum Sensing with Deep Clustering: Label-Free Radio Access Technology Recognition](https://arxiv.org/abs/2508.01709)
*Ljupcho Milosheski,Mihael Mohorčič,Carolina Fortuna*

Main category: eess.SP

TL;DR: 论文提出了一种无需标记数据的频谱感知工作流，采用自监督深度聚类架构，显著提升了性能并减少了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 随着连接设备数量增加和网络密集化，对射频频谱资源的需求激增，但现有基于监督学习的RAT分类方法依赖大量标记数据，泛化能力存疑。

Method: 提出了一种无需先验知识的频谱感知工作流，采用自监督学习（SSL）深度聚类架构，从原始1D FFT数据中自主提取频谱特征。

Result: 在三个欧洲城市的真实数据集上评估，模型性能提升高达35个百分点，参数减少22%，FLOPS降低50%。

Conclusion: 该方法在无需标记数据的情况下实现了高性能，为未来6G频谱感知提供了可行方案。

Abstract: The growth of the number of connected devices and network densification is
driving an increasing demand for radio network resources, particularly Radio
Frequency (RF) spectrum. Given the dynamic and complex nature of contemporary
wireless environments, characterized by a wide variety of devices and multiple
RATs, spectrum sensing is envisioned to become a building component of future
6G, including as a component within O-RAN or digital twins. However, the
current SotA research for RAT classification predominantly revolves around
supervised Convolutional Neural Network (CNN)-based approach that require
extensive labeled dataset. Due to this, it is unclear how existing models
behave in environments for which training data is unavailable thus leaving open
questions regarding their generalization capabilities. In this paper, we
propose a new spectrum sensing workflow in which the model training does not
require any prior knowledge of the RATs transmitting in that area (i.e. no
labelled data) and the class assignment can be easily done through manual
mapping. Furthermore, we adapt a SSL deep clustering architecture capable of
autonomously extracting spectrum features from raw 1D Fast Fourier Transform
(FFT) data. We evaluate the proposed architecture on three real-world datasets
from three European cities, in the 868 MHz, 2.4 GHz and 5.9 GHz bands
containing over 10 RATs and show that the developed model achieves superior
performance by up to 35 percentage points with 22% fewer trainable parameters
and 50% less floating-point operations per second (FLOPS) compared to an SotA
AE-based reference architecture.

</details>


### [46] [ModFus-DM: Explore the Representation in Modulated Signal Diffusion Generated Models](https://arxiv.org/abs/2508.01719)
*Haoyue Tan,Yu Li,Zhenxi Zhang,Xiaoran Shi,Feng Zhou*

Main category: eess.SP

TL;DR: 提出了一种基于扩散模型的无监督自动调制分类框架ModFus-DM，解决了现有深度学习方法在信号长度不固定、分布偏移和标记信号有限等问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 自动调制分类在无线通信系统中至关重要，但现有深度学习方法需要大量标记信号且难以应对非固定信号长度、分布偏移和标记信号有限的挑战。

Method: 设计了调制信号扩散生成模型（MSDGM）和扩散感知特征融合模块（DAFFus），通过渐进去噪过程和多尺度特征融合增强表示学习。

Result: 在多个数据集上显著优于现有方法，特别是在标记信号有限、分布偏移和变长信号识别等场景下，24类识别任务中在SNR≥12dB时准确率达88.27%。

Conclusion: ModFus-DM是一种高效的无监督框架，适用于复杂无线通信环境中的自动调制分类任务。

Abstract: Automatic modulation classification (AMC) is essential for wireless
communication systems in both military and civilian applications. However,
existing deep learning-based AMC methods often require large labeled signals
and struggle with non-fixed signal lengths, distribution shifts, and limited
labeled signals. To address these challenges, we propose a modulation-driven
feature fusion via diffusion model (ModFus-DM), a novel unsupervised AMC
framework that leverages the generative capacity of diffusion models for robust
modulation representation learning. We design a modulated signal diffusion
generation model (MSDGM) to implicitly capture structural and semantic
information through a progressive denoising process. Additionally, we propose
the diffusion-aware feature fusion (DAFFus) module, which adaptively aggregates
multi-scale diffusion features to enhance discriminative representation.
Extensive experiments on RML2016.10A, RML2016.10B, RML2018.01A and RML2022
datasets demonstrate that ModFus-DM significantly outperforms existing methods
in various challenging scenarios, such as limited-label settings, distribution
shifts, variable-length signal recognition and channel fading scenarios.
Notably, ModFus-DM achieves over 88.27% accuracy in 24-type recognition tasks
at SNR $\geq $ 12dB with only 10 labeled signals per type.

</details>


### [47] [FAS Enabled UAV for Energy-Efficient WPCNs](https://arxiv.org/abs/2508.01771)
*Nagla Abuzgaia,Abdelhamid Salem,Ahmed Elbarsha*

Main category: eess.SP

TL;DR: 提出一种利用流体天线系统（FAS）提升无人机（UAV）在无线供电通信网络（WPCN）中通信速率和能量效率（EE）的创新方案。


<details>
  <summary>Details</summary>
Motivation: 通过动态端口切换能力优化信道增益，提升无人机在无线供电和数据传输中的性能。

Method: 利用FAS技术，无人机可自适应选择最佳天线位置，推导了Nakagami-m相关衰落信道下的遍历频谱速率表达式。

Result: 蒙特卡洛仿真验证了理论表达式的准确性，并显示FAS相比固定天线系统显著提高了能量效率。

Conclusion: FAS技术能有效提升无人机在WPCN中的通信和能量效率。

Abstract: This letter presents an innovative scheme to enhance the communication rate
and energy efficiency (EE) of Unmanned Aerial Vehicle (UAV) in wireless powered
communication networks (WPCNs) by deploying the emerging fluid antenna system
(FAS) technology onto the UAV. Our proposed approach leverages the dynamic port
switching capability of FAS, enabling the UAV to adaptively select the optimal
antenna location that maximizes channel gain for both downlink wireless power
transfer (WPT) and uplink wireless data transfer (WDT). We derive both exact
analytical expression of the ergodic spectral rate, and asymptotic expression
at high signal to noise ratio (SNR) regime under Nakagami-m correlated fading
channels. The Mont-Carlo simulation results confirms the accuracy of the
analytical expressions and demonstrate the substantial increase in energy
efficiency of UAV with FAS compared to fixed antenna systems.

</details>


### [48] [Statistical Multiport-Network Modeling and Efficient Discrete Optimization of RIS](https://arxiv.org/abs/2508.01776)
*Cheima Hammami,Luc Le Magoarou,Philipp del Hougne*

Main category: eess.SP

TL;DR: 论文研究了在存在互耦合和1位可调元件的RIS中物理一致性优化的方法，比较了模型驱动和模型无关方法，并评估了智能初始化的潜在优势。


<details>
  <summary>Details</summary>
Motivation: 填补现有RIS原型中硬件约束（如互耦合和1位可调元件）下物理一致性优化的研究空白。

Method: 比较了温度退火反向传播（模型驱动）和坐标下降、遗传算法（模型无关）等方法，并引入了一种生成多端口网络模型参数统计集合的技术。

Result: 发现当互耦合不可忽略时，随机初始化的坐标下降在性能、执行时间和内存使用方面表现最佳。

Conclusion: 研究结果可推广到超对角RIS、堆叠智能超表面、动态超表面天线和波域物理神经网络等领域。

Abstract: This Letter fills the research gap on physics-consistent optimization for
reconfigurable intelligent surfaces (RISs) with mutual coupling (MC) and
1-bit-tunable elements, a common hardware constraint in existing RIS
prototypes. We compare a model-based method (temperature-annealed
back-propagation) and model-agnostic methods (coordinate descent, genetic
algorithm), and evaluate potential benefits of intelligently initializing these
methods. To facilitate our evaluation, we introduce a technique for generating
statistical ensembles of multiport-network model parameters, wherein a single
hyper-parameter adjusts the MC strength. The technique is a generalization of
Rayleigh fading to radio environments with deterministic programmability, and
it accounts for passivity constraints as well as the coherent-backscattering
effect. We find that, except when MC is negligible, coordinate descent with
random initialization yields the most favorable trade-off in terms of
performance, execution time and memory usage. We expect our findings to extend
to beyond-diagonal RIS, stacked intelligent metasurfaces, dynamic metasurface
antennas, and wave-domain physical neural networks.

</details>


### [49] [A Heuristic Method for Simplified Resource Allocation based on Comparative Advantage in Wireless Access Systems](https://arxiv.org/abs/2508.01824)
*Lin Cheng,Bernardo A. Huberman*

Main category: eess.SP

TL;DR: 提出了一种基于比较优势的启发式方法，简化接入系统中的资源分配，降低计算复杂度并保持接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决多小区网络中功率分配的挑战，减少优化搜索空间，降低计算开销。

Method: 利用比较优势概念，以PD-NOMA为例，将搜索空间维度减半。

Result: 分析和仿真验证了方法的有效性，显著减少计算开销并保持高效频谱利用。

Conclusion: 该方法适用于下一代无线网络，提升系统性能和可扩展性。

Abstract: This paper presents a heuristic method for simplifying resource allocation in
access systems, leveraging the concept of comparative advantage to reduce
computational complexity while maintaining near-optimal performance. Using
power-division non-orthogonal multiple access (PD-NOMA) as an example, we
demonstrate how this approach mitigates the challenge of power allocation in
multi-cell networks. Our method reduces the search space for optimization,
significantly decreasing computational overhead while ensuring efficient
spectrum utilization. In principle, the method reduces the dimensions of search
space by half. Extensive analysis and simulations validate its effectiveness,
highlighting its potential for practical deployment in next-generation wireless
networks. The proposed framework can help streamline resource allocation in
complex communication environments, enhancing system performance and
scalability.

</details>


### [50] [RIS-Aided Near-Field Channel Estimation under Mutual Coupling and Spatial Correlation](https://arxiv.org/abs/2508.01828)
*Ahmad Dkhan,Simon Tarboush,Hadi Sarieddeen,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 论文提出了一种改进的RS-LS估计器，用于解决RIS辅助MIMO系统中高维信道矩阵和互耦效应带来的挑战，并在近场传播环境下验证了其性能优势。


<details>
  <summary>Details</summary>
Motivation: RIS与大规模MIMO阵列的集成提升了无线网络性能，但高维信道矩阵和互耦效应增加了信道估计的复杂性和开销。传统估计方法在高维场景下性能受限。

Method: 提出了一种改进的RS-LS估计器，结合阵列几何和互耦效应，适用于近场传播环境。

Result: 实验表明，考虑互耦效应的RS-LS估计器在5 dB SNR下性能提升约5 dB。

Conclusion: 改进的RS-LS估计器在RIS辅助MIMO系统中显著提升了信道估计性能，尤其在近场传播和互耦效应显著的环境中。

Abstract: The integration of reconfigurable intelligent surfaces (RIS) with extremely
large multiple-input multiple-output (MIMO) arrays at the base station has
emerged as a key enabler for enhancing wireless network performance. However,
this setup introduces high-dimensional channel matrices, leading to increased
computational complexity and pilot overhead in channel estimation. Mutual
coupling (MC) effects among densely packed unit cells, spatial correlation, and
near-field propagation conditions further complicate the estimation process.
Conventional estimators, such as linear minimum mean square error (MMSE),
require channel statistics that are challenging to acquire for high-dimensional
arrays, while least squares (LS) estimators suffer from performance
limitations. To address these challenges, the reduced-subspace least squares
(RS-LS) estimator leverages array geometry to enhance estimation accuracy. This
work advances the promising RS-LS estimation algorithm by explicitly
incorporating MC effects into the more realistic and challenging near-field
propagation environment within the increasingly relevant generalized RIS-aided
MIMO framework. Additionally, we investigate the impact of MC on the spatial
degrees of freedom (DoF). Our analysis reveals that accounting for MC effects
provides a significant performance gain of approximately 5 dB at an SNR of 5
dB, compared to conventional methods that ignore MC.

</details>


### [51] [Feature Reconstruction Aided Federated Learning for Image Semantic Communication](https://arxiv.org/abs/2508.02048)
*Yoon Huh,Bumjun Kim,Wan Choi*

Main category: eess.SP

TL;DR: 提出了一种名为FedSFR的联邦学习算法，通过语义特征重构优化图像传输中的联合源-信道编码模块，显著提升了训练稳定性和传输质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的联合源-信道编码系统因知识库过时而性能下降，需周期性更新。

Method: 采用联邦学习算法（FedSFR），结合语义特征重构，部分参与者传输特征向量而非本地更新信息。

Result: 实验表明，该方法显著提升了联邦学习的稳定性和图像传输质量，并通过数学推导验证了收敛速度的提升。

Conclusion: FedSFR算法通过特征重构和高效通信容量利用，有效解决了图像传输中的性能退化问题。

Abstract: Research in semantic communication has garnered considerable attention,
particularly in the area of image transmission, where joint source-channel
coding (JSCC)-based neural network (NN) modules are frequently employed.
However, these systems often experience performance degradation over time due
to an outdated knowledge base, highlighting the need for periodic updates. To
address this challenge in the context of training JSCC modules for image
transmission, we propose a federated learning (FL) algorithm with semantic
feature reconstruction (FR), named FedSFR. This algorithm more efficiently
utilizes the available communication capacity by allowing some of the selected
FL participants to transmit smaller feature vectors instead of local update
information. Unlike conventional FL methods, our approach integrates FR at the
parameter server (PS), stabilizing training and enhancing image transmission
quality. Experimental results demonstrate that the proposed scheme
significantly enhances both the stability and effectiveness of the FL process
compared to other algorithms. Furthermore, we mathematically derive the
convergence rate to validate the improved performance.

</details>


### [52] [Scoring ISAC: Benchmarking Integrated Sensing and Communications via Score-Based Generative Modeling](https://arxiv.org/abs/2508.02117)
*Lin Chen,Chang Cai,Huiyuan Yang,Xiaojun Yuan,Ying-Jun Angela Zhang*

Main category: eess.SP

TL;DR: 本文总结了基于分数的生成模型在ISAC系统性能评估中的最新进展，提出了一种称为“scoring ISAC”的框架，用于在现实条件下评估ISAC系统。


<details>
  <summary>Details</summary>
Motivation: ISAC系统在实际应用中面临硬件损伤、多径传播等非线性、多模态和非高斯分布问题，传统性能指标难以解析推导，需要新的数据驱动方法。

Method: 通过分数函数连接经典性能指标，并提供了学习分数函数以估计性能指标的实用训练技术。

Result: 目标检测和定位的概念验证实验表明，基于分数的性能估计器能够准确复现并扩展传统分析。

Conclusion: 基于分数的生成模型在ISAC性能分析、算法设计和系统优化中展现出巨大潜力。

Abstract: Integrated sensing and communications (ISAC) is a key enabler for
next-generation wireless systems, aiming to support both high-throughput
communication and high-accuracy environmental sensing using shared spectrum and
hardware. Theoretical performance metrics, such as mutual information (MI),
minimum mean squared error (MMSE), and Bayesian Cram\'{e}r--Rao bound (BCRB),
play a key role in evaluating ISAC system performance limits. However, in
practice, hardware impairments, multipath propagation, interference, and scene
constraints often result in nonlinear, multimodal, and non-Gaussian
distributions, making it challenging to derive these metrics analytically.
Recently, there has been a growing interest in applying score-based generative
models to characterize these metrics from data, although not discussed for
ISAC. This paper provides a tutorial-style summary of recent advances in
score-based performance evaluation, with a focus on ISAC systems. We refer to
the summarized framework as scoring ISAC, which not only reflects the core
methodology based on score functions but also emphasizes the goal of scoring
(i.e., evaluating) ISAC systems under realistic conditions. We present the
connections between classical performance metrics and the score functions and
provide the practical training techniques for learning score functions to
estimate performance metrics. Proof-of-concept experiments on target detection
and localization validate the accuracy of score-based performance estimators
against ground-truth analytical expressions, illustrating their ability to
replicate and extend traditional analyses in more complex, realistic settings.
This framework demonstrates the great potential of score-based generative
models in ISAC performance analysis, algorithm design, and system optimization.

</details>


### [53] [An Overview of Algorithms for Contactless Cardiac Feature Extraction from Radar Signals: Advances and Challenges](https://arxiv.org/abs/2508.02122)
*Yuanyuan Zhang,Rui Yang,Yutao Yue,Eng Gee Lim,Zidong Wang*

Main category: eess.SP

TL;DR: 本文是一篇关于雷达信号处理算法在无接触心脏监测中的综述，首次系统性地总结了从雷达信号中提取心脏特征的算法，并提出了新的分类法、公开数据集和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无接触心脏监测在未来智能家居和车内监测等场景中潜力巨大，而雷达因其高精度和鲁棒性成为理想选择。然而，雷达信号处理算法的研究尚未得到充分综述，本文填补了这一空白。

Method: 作者提出了一种新的分类法，详细评估了各种算法的优缺点，并列举了包含雷达信号和心脏特征信号的公开数据集及其配置。

Result: 本文为研究人员提供了快速了解心脏特征提取算法研究趋势和最新发展的指南，并提出了未来研究方向以解决该领域的主要障碍。

Conclusion: 本文可作为研究人员和实践者的参考，鼓励基于提出的挑战和未来方向进一步研究无接触心脏监测领域。

Abstract: Contactless cardiac monitoring has vast potential to replace contact-based
monitoring in various future scenarios such as smart home and in-cabin
monitoring. Various contactless sensors can be potentially implemented for
cardiac monitoring, such as cameras, acoustic sensors, Wi-Fi routers and
radars. Among all these sensors, radar could achieve unobtrusive monitoring
with high accuracy and robustness at the same time. The research about
radar-based cardiac monitoring can be generally divided into the radar
architecture design and signal-processing parts, where the former has been
thoroughly reviewed in the literature but not the latter. To the best of the
author knowledge, this is the first review paper that focuses on elaborating
the algorithms for extracting cardiac features from the received radar signal.
In addition, a new taxonomy is proposed to reveal the core feature of each
algorithm, with the pros and cons evaluated in detail. Furthermore, the public
datasets containing the received radar signal and ground-truth cardiac feature
signal are listed with detailed configurations, and the corresponding
evaluations may help the researchers select the suitable dataset. At last,
several unsolved challenges and future directions are suggested and discussed
in detail to encourage future research on solving the main obstacles in this
field. In summary, this review can be served as a guide for researchers and
practitioners to quickly understand the research trend and recent development
of the cardiac feature extraction algorithms, and it is worth further
investigating the relative area based on the proposed challenges and future
directions.

</details>


### [54] [Analysis of Broad Beam Beamforming for Collocated and Distributed MIMO](https://arxiv.org/abs/2508.02135)
*Ahmet Kaplan,Diana P. M. Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: 本文研究了双极化波束成形（DPBF）在视距和非视距条件下的性能，提出了改进方法以提高覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 避免扫描方法的开销并高效利用资源，同时验证DPBF在非视距条件下的有效性。

Method: 建模非视距条件下的反射系数，提出正交空时分组码改进覆盖，并设计分布式MIMO的DPBF方法。

Result: 分布式MIMO的DPBF方法比集中式MIMO的DPBF覆盖范围更广。

Conclusion: DPBF在分布式MIMO中表现更优，为实际应用提供了有效解决方案。

Abstract: Broad beam beamforming (BF) design in multiple-input multiple-output (MIMO)
can be convenient for initial access, synchronization, and sensing capabilities
in cellular networks by avoiding overheads of sweeping methods while making
efficient use of resources. Phase-only BF is key for maximizing power
efficiency across antennas. A successful method to produce broad beams is the
phase-only dual-polarization BF (DPBF). However, its efficiency has not been
proved in non-line-of-sight (NLoS). Therefore, this paper contributes by
evaluating DPBF in collocated and distributed MIMO configurations under both
line-of-sight (LoS) and NLoS channel conditions. We model the reflection
coefficients for different materials in NLoS conditions and propose the use of
orthogonal space-time block code to improve the coverage compared to the DPBF
in collocated MIMO (C-MIMO). We further propose a DPBF method for distributed
MIMO and show that it achieves better coverage than C-MIMO with DPBF.

</details>


### [55] [The ECME Algorithm Using Factor Analysis for DOA Estimation in Nonuniform Noise](https://arxiv.org/abs/2508.02223)
*Mingyan Gong*

Main category: eess.SP

TL;DR: 本文提出了一种基于ECME算法的方向到达估计方法，在非均匀噪声环境下比FAAN方法收敛更快且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 在未知非均匀噪声环境中，最大似然因子分析用于方向到达估计，但现有方法如FAAN虽收敛性好，仍有改进空间。

Method: 设计了ECME算法（期望/条件最大化算法），作为EM算法的扩展，每步计算复杂度与FAAN相近。

Result: 数值结果表明，ECME算法比FAAN收敛更快且计算效率更高。

Conclusion: ECME算法在非均匀噪声环境下的方向到达估计中表现优于FAAN方法。

Abstract: Maximum likelihood factor analysis has been used for direction of arrival
estimation in unknown nonuniform noise and some iterative approaches have been
developed. In particular, the Factor Analysis for Anisotropic Noise (FAAN)
method proposed by Stoica and Babu has excellent convergence properties. In
this letter, the Expectation/Conditional Maximization Either (ECME) algorithm,
an extension of the expectation-maximization algorithm, is designed, which has
almost the same computational complexity at each iteration as the FAAN method.
However, numerical results show that the ECME algorithm yields faster stable
convergence and is computationally more efficient.

</details>


### [56] [Adaptive Phase-Shifted Pilot Design for Uplink Multiple Access in ISAC Systems](https://arxiv.org/abs/2508.02334)
*Ahmet Sacid Sümer,Ebubekir Memişoğlu,Hüseyin Arslan*

Main category: eess.SP

TL;DR: APS-ISAC是一种新型的导频设计方法，通过自适应相位偏移和重叠块导频结构，显著提升了上行ISAC系统的频谱效率和感知性能。


<details>
  <summary>Details</summary>
Motivation: 传统导频分配方法在频谱效率和感知性能之间存在权衡，无法同时满足高效率和低模糊度的需求。

Method: 提出自适应相位偏移ISAC（APS-ISAC），采用重叠块导频结构和用户设备（UE）特定的相位偏移，以共享时频资源并保持可分离的信道响应。

Result: APS-ISAC在频谱效率上显著优于传统方法，支持更多UE复用，同时降低了均方误差（MSE）和复杂度，并实现了高分辨率和低模糊度的感知性能。

Conclusion: APS-ISAC为未来上行ISAC系统提供了一种可扩展、高效、低复杂度的导频设计范例。

Abstract: In uplink integrated sensing and communication (ISAC) systems, pilot signal
design is crucial for enabling accurate channel estimation and reliable radar
sensing. In orthogonal frequency-division multiple access (OFDMA)-based
frameworks, conventional pilot allocation schemes face a trade-off between
spectral efficiency (SE) and sensing performance. Interleaved pilots improve
user equipment (UE) multiplexing through sparse allocation but reduce the
maximum unambiguous range. Conversely, orthogonal block-based pilots reduce
range ambiguity but degrade sensing resolution due to limited delay
granularity. To address this trade-off, the phase-shifted ISAC (PS-ISAC) scheme
was recently proposed for uplink multiple access in ISAC systems. However,
PS-ISAC suffers from spectral inefficiency due to the fixed cyclic prefix (CP)
constraints. To overcome these limitations, we propose adaptive
phase-shifted-ISAC (APS-ISAC), an enhanced pilot scheme that employs an
overlapped block-pilot structure with UE-specific phase shifts determined by
maximum excess delay of each UE. This design enables UEs to share the same
time-frequency resources while preserving separable and contiguous channel
impulse responses (CIRs) at the base station (BS). Simulation results show that
APS-ISAC significantly outperforms conventional pilot allocation methods in
terms of SE, approximately doubling the number of multiplexed UEs. It also
achieves lower mean square error (MSE) under power constraints with reduced
complexity. Furthermore, it yields maximum range resolution and unambiguous
sensing performance. These results establish APS-ISAC as a scalable, spectrally
efficient, ambiguity-resilient, and low-complexity pilot design paradigm for
future uplink ISAC systems.

</details>


### [57] [Detecting and measuring respiratory events in horses during exercise with a microphone: deep learning vs. standard signal processing](https://arxiv.org/abs/2508.02349)
*Jeanne I. M. Parmentier,Rhana M. Aarts,Elin Hernlund,Marie Rhodin,Berend Jan van der Zwaag*

Main category: eess.SP

TL;DR: 比较深度学习和信号处理方法，用于从麦克风录音中自动检测马匹高强度运动时的呼吸事件和动态呼吸率。


<details>
  <summary>Details</summary>
Motivation: 监测呼吸参数（如呼吸率）有助于了解训练对马匹健康和表现的影响，从而改善马匹福利。

Method: 使用深度学习模型（如时间卷积网络和长短时记忆网络）与信号处理方法进行比较，检测呼气声音并提取动态呼吸率。

Result: 时间卷积网络表现最佳（F1分数中位数0.94，MAE±CI：1.44±1.04 bpm），优于长短时记忆网络和信号处理方法。

Conclusion: 这是首次自动检测马匹呼吸声音并计算动态呼吸率的研究，未来将验证模型在低强度运动时的表现和不同麦克风位置的效果。

Abstract: Monitoring respiration parameters such as respiratory rate could be
beneficial to understand the impact of training on equine health and
performance and ultimately improve equine welfare. In this work, we compare
deep learning-based methods to an adapted signal processing method to
automatically detect cyclic respiratory events and extract the dynamic
respiratory rate from microphone recordings during high intensity exercise in
Standardbred trotters. Our deep learning models are able to detect exhalation
sounds (median F1 score of 0.94) in noisy microphone signals and show promising
results on unlabelled signals at lower exercising intensity, where the
exhalation sounds are less recognisable. Temporal convolutional networks were
better at detecting exhalation events and estimating dynamic respiratory rates
(median F1: 0.94, Mean Absolute Error (MAE) $\pm$ Confidence Intervals (CI):
1.44$\pm$1.04 bpm, Limits Of Agreements (LOA): 0.63$\pm$7.06 bpm) than long
short-term memory networks (median F1: 0.90, MAE$\pm$CI: 3.11$\pm$1.58 bpm) and
signal processing methods (MAE$\pm$CI: 2.36$\pm$1.11 bpm). This work is the
first to automatically detect equine respiratory sounds and automatically
compute dynamic respiratory rates in exercising horses. In the future, our
models will be validated on lower exercising intensity sounds and different
microphone placements will be evaluated in order to find the best combination
for regular monitoring.

</details>


### [58] [Toward a reliable PWM-based light-emitting diode visual stimulus for improved SSVEP response with minimal visual fatigue](https://arxiv.org/abs/2508.02359)
*Surej Mouli,Ramaswamy Palaniappan*

Main category: eess.SP

TL;DR: 研究探讨了高占空比视觉刺激对减轻视觉疲劳和提高SSVEP性能的影响，发现85%占空比效果最佳。


<details>
  <summary>Details</summary>
Motivation: SSVEP在视觉诊断和脑机接口中应用广泛，但传统方法易导致视觉疲劳且精度不足，亟需改进。

Method: 使用50%至95%占空比的PWM刺激，通过定制LED硬件记录脑电图数据，测试10名受试者。

Result: 高占空比减轻视觉疲劳，85%占空比时SSVEP响应最佳且受试者独立。

Conclusion: 85%占空比可能推动SSVEP在实际应用中的更广泛使用。

Abstract: Steady state visual evoked response (SSVEP) is widely used in visual-based
diagnosis and applications such as brain computer interfacing due to its high
information transfer rate and the capability to activate commands through
simple gaze control. However, one major impediment in using flashing visual
stimulus to obtain SSVEP is eye fatigue that prevents continued long term use
preventing practical deployment. This combined with the difficulty in
establishing precise pulse-width modulation (PWM) that results in poorer
accuracy warrants the development of appropriate approach to solve these
issues. Various studies have suggested the usage of high frequencies of visual
stimulus to reduce the visual fatigue for the user but this results in poor
response performance. Here, the authors study the use of extremely high
duty-cycles in the stimulus in the hope of solving these constraints.
Electroencephalogram data was recorded with PWM duty-cycles of 50 to 95%
generated by a precise custom-made light-emitting diode hardware and tested ten
subjects responded that increasing duty-cycles had less visual strain for all
the frequency values and the SSVEP exhibited a subject-independent peak
response for duty-cycle of 85%. This could pave the way for increased usage of
SSVEP for practical applications.

</details>


### [59] [The Role of Review Process Failures in Affective State Estimation: An Empirical Investigation of DEAP Dataset](https://arxiv.org/abs/2508.02417)
*Nazmun N Khan,Taylor Sweet,Chase A Harvey,Calder Knapp,Dean J. Krusienski,David E Thompson*

Main category: eess.SP

TL;DR: 研究发现EEG情感状态估计的可靠性存在问题，87%的论文存在方法学错误，导致分类准确率被夸大高达46%。


<details>
  <summary>Details</summary>
Motivation: 评估EEG数据在情感状态估计中的可靠性，揭示现有研究中的方法学问题。

Method: 回顾101项研究，分析DEAP数据集的使用情况，识别数据泄漏、特征选择偏差等问题。

Result: 87%的论文存在方法学错误，实验显示这些错误可能使分类准确率夸大46%。

Conclusion: 需建立更严格的方法学标准和评估协议，改进神经科学中机器学习的同行评审。

Abstract: The reliability of affective state estimation using EEG data is in question,
given the variability in reported performance and the lack of standardized
evaluation protocols. To investigate this, we reviewed 101 studies, focusing on
the widely used DEAP dataset for emotion recognition. Our analysis revealed
widespread methodological issues that include data leakage from improper
segmentation, biased feature selection, flawed hyperparameter optimization,
neglect of class imbalance, and insufficient methodological reporting. Notably,
we found that nearly 87% of the reviewed papers contained one or more of these
errors. Moreover, through experimental analysis, we observed that such
methodological flaws can inflate the classification accuracy by up to 46%.
These findings reveal fundamental gaps in standardized evaluation practices and
highlight critical deficiencies in the peer review process for machine learning
applications in neuroscience, emphasizing the urgent need for stricter
methodological standards and evaluation protocols.

</details>


### [60] [Secure Energy Efficient Wireless Transmission: A Finite v/s Infinite-Horizon RL Solution](https://arxiv.org/abs/2508.02447)
*Shalini Tripathi,Ankur Bansal,Holger Claussen,Lester Ho,Chinmoy Kundu*

Main category: eess.SP

TL;DR: 论文提出了一种联合优化源节点和目的节点功率分配的方法，以最大化无线网络在有限时间内的平均保密能量效率（SEE）。通过有限时域强化学习（RL）算法FHJPA，性能优于贪婪算法（GA）和无限时域算法（IHJPA）。


<details>
  <summary>Details</summary>
Motivation: 提升无线网络的保密能量效率，同时考虑能量收集和有限电池容量的约束。

Method: 提出FHJPA算法（有限时域联合功率分配），并与GA和IHJPA算法进行比较。

Result: FHJPA算法在SEE和计算时间上优于其他算法，GA在电池充足时接近FHJPA性能。

Conclusion: FHJPA算法在有限时域传输中表现最佳，适合实际应用。

Abstract: In this paper, a joint optimal allocation of transmit power at the source and
jamming power at the destination is proposed to maximize the average secrecy
energy efficiency (SEE) of a wireless network within a finite time duration.
The destination transmits the jamming signal to improve secrecy by utilizing
full-duplex capability. The source and destination both have energy harvesting
(EH) capability with limited battery capacity. Due to the Markov nature of the
system, the problem is formulated as a finite-horizon reinforcement learning
(RL) problem. We propose the finite-horizon joint power allocation (FHJPA)
algorithm for the finite-horizon RL problem and compare it with a
low-complexity greedy algorithm (GA). An infinite-horizon joint power
allocation (IHJPA) algorithm is also proposed for the corresponding
infinite-horizon problem. A comparative analysis of these algorithms is carried
out in terms of SEE, expected total transmitted secure bits, and computational
complexity. The results show that the FHJPA algorithm outperforms the GA and
IHJPA algorithms due to its appropriate modelling in finite horizon
transmission. When the source node battery has sufficient energy, the GA can
yield performance close to the FHJPA algorithm despite its low-complexity. When
the transmission time horizon increases, the accuracy of the infinite-horizon
model improves, resulting in a reduced performance gap between FHJPA and IHJPA
algorithms. The computational time comparison shows that the FHJPA algorithm
takes $16.6$ percent less time than the IHJPA algorithm.

</details>


### [61] [Inverse harmonic clustering for multi-pitch estimation: an optimal transport approach](https://arxiv.org/abs/2508.02471)
*Anton Björkman,Filip Elvander*

Main category: eess.SP

TL;DR: 提出了一种基于最优传输理论的多音高估计方法，通过解耦正则化和字典设计，提高了估计性能和对非谐波性的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多音高估计问题，即在噪声测量中识别叠加的截断谐波序列。

Method: 将问题转化为恢复单位圆上的谐波结构测度，利用最优传输理论的正则化方法，同时推断信号的频谱内容并将其分配到少量谐波序列中。

Result: 在合成和真实数据上的数值研究表明，该方法优于统计信号处理文献中的其他方法，并与网络方法性能相当或更好。

Conclusion: 提出的框架在解耦正则化和字典设计方面具有优势，提高了估计性能和对非谐波性的鲁棒性。

Abstract: In this work, we consider the problem of multi-pitch estimation, i.e.,
identifying super-imposed truncated harmonic series from noisy measurements. We
phrase this as recovering a harmonically-structured measure on the unit circle,
where the structure is enforced using regularizers based on optimal transport
theory. In the resulting framework, a signal's spectral content is
simultaneously inferred and assigned, or transported, to a small set of
harmonic series defined by their corresponding fundamental frequencies. In
contrast to existing methods from the compressed sensing paradigm, the proposed
framework decouples regularization and dictionary design and mitigates
coherency problems. As a direct consequence, this also introduces robustness to
the phenomenon of inharmonicity. From this framework, we derive two estimation
methods, one for stochastic and one for deterministic signals, and propose
efficient numerical algorithms implementing them. In numerical studies on both
synthetic and real data, the proposed methods are shown to achieve better
estimation performance as compared to other methods from statistical signal
processing literature. Furthermore, they perform comparably or better than
network-based methods, except when the latter are specially trained on the
data-type considered and are given access to considerably more data during
inference.

</details>


### [62] [Cramér-Rao Bound for Direct Position Estimation in OFDM Based Cellular Systems](https://arxiv.org/abs/2508.02559)
*Sijia Li,Rui Sun,Bing Xu,Yuanwei Liu*

Main category: eess.SP

TL;DR: 本文探讨了直接位置估计（DPE）在OFDM定位系统中的性能，推导了其Cramér-Rao界（CRB），并与传统两步法对比。结果表明DPE在OFDM系统中表现更优，带宽和多符号利用对定位精度至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究DPE在OFDM定位系统中的理论极限和性能，填补现有研究的空白，并评估其在多径环境中的表现。

Method: 推导DPE的CRB，并与传统两步法进行性能对比，分析带宽、子载波间距和多符号利用的影响。

Result: DPE在OFDM系统中表现优于两步法；大带宽和多符号利用显著提升定位精度，但符号数过多会带来边际效益和计算复杂度增加。

Conclusion: DPE在OFDM系统中具有优势，带宽和多符号利用是关键因素，但需权衡计算复杂度。

Abstract: Although direct position estimation (DPE) has been demonstrated to offer
enhanced robustness in GNSS receivers, its theoretical limits and performance
in OFDM based positioning systems remain largely unexplored. In this paper, the
Cram\'er-Rao bound (CRB) for DPE using OFDM based cellular signals is derived
and benchmarked against the conventional two-step positioning method to assess
their relative performance in non-line-of-sight (NLOS) dominated multipath
environments. Numerical results reveal that 1) the DPE method consistently
outperforms the two-step approach in OFDM systems under all evaluated
conditions; 2) a large bandwidth is crucial in both methods, and increasing
subcarrier spacing is more beneficial for a fixed bandwidth; 3) utilizing
multiple OFDM symbols for positioning leads to substantial improvements in
localization accuracy compared to relying on a single symbol. However, further
increasing the number of symbols yields marginal improvements while
significantly increasing computational complexity.

</details>
