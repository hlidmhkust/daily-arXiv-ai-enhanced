<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 58]
- [cs.IT](#cs.IT) [Total: 18]
- [eess.IV](#eess.IV) [Total: 17]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Optimizing VO2max Prediction in Gamified Cardiac Assessment: Leveraging Effective Feature Selection and Refined Protocols for Robust Models](https://arxiv.org/abs/2507.14138)
*Vaishnavi C K,Sricharan Vijayarangan,Sri Gayathri G,Danush Adhithya N,Alex Joseph,Preejith SP,Mohanasankar Sivaprakasam*

Main category: eess.SP

TL;DR: 研究改进了心肺点慢跑测试（CPSJT）协议，通过性别、BMI、有氧和无氧持续时间等特征提取，提高了VO2max预测的准确性，并在44名印度参与者中验证了多种机器学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: VO2max是心肺健康的关键指标，但现有测量方法如心肺运动测试（CPET）成本高且需专业人员，限制了大规模筛查。早期替代方法如CPSJT误差较大，本研究旨在改进其预测精度。

Method: 通过改进CPSJT协议，提取性别、BMI、有氧和无氧持续时间等特征，使用线性回归、随机森林和支持向量回归等机器学习模型进行预测，并通过分层5折交叉验证评估性能。

Result: 在44名参与者中，线性回归的RMSE为5.78，随机森林为5.15，支持向量回归为5.17，所有模型均表现出强相关性和低误差。

Conclusion: 改进后的CPSJT协议结合机器学习模型，显著提高了VO2max预测的准确性和可靠性，为大规模筛查提供了可行方案。

Abstract: VO2max is a critical indicator of cardiopulmonary fitness, reflecting the
maximum amount of oxygen the body can utilize during intense exercise.
Accurately measuring VO2max is essential for assessing cardiovascular health
and predicting outcomes in clinical settings. However, current methods for
VO2max estimation, such as Cardiopulmonary Exercise Testing (CPET), require
expensive equipment and the supervision of trained personnel, limiting
accessibility for large-scale screening. Preliminary efforts have been made to
create a more accessible method, such as the Cardiopulmonary Spot Jog Test
(CPSJT). Unfortunately, these early attempts yielded high error margins,
rendering them unsuitable for widespread use. In our study, we address these
shortcomings by refining the CPSJT protocol to improve prediction accuracy. A
crucial contribution is improved feature extraction which include gender, body
mass index, aerobic duration, and anaerobic duration. This targeted approach
helps in streamlining the model to enhance prediction precision while
minimizing the risk of overfitting. In a cohort of 44 participants from the
Indian population, we assessed the performance of various machine learning
models using these features. With Stratified 5-Fold Cross-Validation, the Root
Mean Squared Error (RMSE) values were 5.78 for Linear Regression, 5.15 for
Random Forest, and 5.17 for Support Vector Regression. All models demonstrated
strong test correlations and low RMSE values, underscoring their robust and
reliable performance.

</details>


### [2] [DIVER-0 : A Fully Channel Equivariant EEG Foundation Model](https://arxiv.org/abs/2507.14141)
*Danny Dongyeop Han,Ahhyun Lucy Lee,Taeyang Lee,Yonghyeon Gwon,Sebin Lee,Seongjin Lee,David Keetae Park,Shinjae Yoo,Jiook Cha,Chun Kee Chung*

Main category: eess.SP

TL;DR: DIVER-0是一种新型EEG基础模型，通过全时空注意力和改进的位置编码技术，解决了现有模型在时空动态建模和通道置换等变性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有EEG基础模型在时空动态建模和通道置换等变性方面表现不足，限制了其在不同电极配置下的鲁棒性。

Method: 提出DIVER-0模型，采用全时空注意力机制，结合RoPE和二进制注意力偏置，并引入STCPE以保持时空平移和通道置换等变性。

Result: DIVER-0仅用10%的预训练数据即达到竞争性性能，且在未见过的电极配置下表现一致。

Conclusion: DIVER-0为处理神经记录设置的异质性提供了关键设计原则，验证了其在跨数据集泛化中的有效性。

Abstract: Electroencephalography (EEG) is a non-invasive technique widely used in
brain-computer interfaces and clinical applications, yet existing EEG
foundation models face limitations in modeling spatio-temporal brain dynamics
and lack channel permutation equivariance, preventing robust generalization
across diverse electrode configurations. To address these challenges, we
propose DIVER-0, a novel EEG foundation model that demonstrates how full
spatio-temporal attention-rather than segregated spatial or temporal
processing-achieves superior performance when properly designed with Rotary
Position Embedding (RoPE) for temporal relationships and binary attention
biases for channel differentiation. We also introduce Sliding Temporal
Conditional Positional Encoding (STCPE), which improves upon existing
conditional positional encoding approaches by maintaining both temporal
translation equivariance and channel permutation equivariance, enabling robust
adaptation to arbitrary electrode configurations unseen during pretraining.
Experimental results demonstrate that DIVER-0 achieves competitive performance
with only 10% of pretraining data while maintaining consistent results across
all channel permutation conditions, validating its effectiveness for
cross-dataset generalization and establishing key design principles for
handling the inherent heterogeneity of neural recording setups.

</details>


### [3] [Recursive KalmanNet: Analyse des capacités de généralisation d'un réseau de neurones récurrent guidé par un filtre de Kalman](https://arxiv.org/abs/2507.14144)
*Cyril Falcon,Hassan Mortada,Mathéo Clavaud,Jean-Philippe Michel*

Main category: eess.SP

TL;DR: Recursive KalmanNet是一种基于卡尔曼滤波的递归神经网络，用于估计动态系统的状态变量和误差协方差，无需噪声特性先验知识。本文探讨其在分布外场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究Recursive KalmanNet在测试数据与训练数据时间动态特性不同的情况下的表现，验证其泛化能力。

Method: 使用基于卡尔曼滤波的递归神经网络（Recursive KalmanNet），在分布外场景下测试其性能。

Result: 未明确提及具体结果，但重点在于泛化能力的探索。

Conclusion: Recursive KalmanNet在分布外场景中可能具备一定的泛化潜力，但需进一步验证。

Abstract: The Recursive KalmanNet, recently introduced by the authors, is a recurrent
neural network guided by a Kalman filter, capable of estimating the state
variables and error covariance of stochastic dynamic systems from noisy
measurements, without prior knowledge of the noise characteristics. This paper
explores its generalization capabilities in out-of-distribution scenarios,
where the temporal dynamics of the test measurements differ from those
encountered during training.
  Le Recursive KalmanNet, r\'ecemment introduit par les auteurs, est un
r\'eseau de neurones r\'ecurrent guid\'e par un filtre de Kalman, capable
d'estimer les variables d'\'etat et la covariance des erreurs des syst\`emes
dynamiques stochastiques \`a partir de mesures bruit\'ees, sans connaissance
pr\'ealable des caract\'eristiques des bruits. Cet article explore ses
capacit\'es de g\'en\'eralisation dans des sc\'enarios hors distribution, o\`u
les dynamiques temporelles des mesures de test diff\`erent de celles
rencontr\'ees \`a l'entra\^inement.

</details>


### [4] [Estimating Markers of Driving Stress through Multimodal Physiological Monitoring](https://arxiv.org/abs/2507.14146)
*Kleanthis Avramidis,Emily Zhou,Tiantian Feng,Hossein Hamidi Shishavan,Frederico Marcolino Quintao Severgnini,Danny J. Lohan,Paul Schmalenberg,Ercan M. Dede,Shrikanth Narayanan*

Main category: eess.SP

TL;DR: 研究探讨短期压力事件对驾驶员生理和行为的影响，利用多模态机器学习系统估计压力源，并分析其与车辆控制模式的关系。


<details>
  <summary>Details</summary>
Motivation: 理解和缓解驾驶压力对预防事故、提升道路安全和驾驶员福祉至关重要，现有安全系统在应对多变驾驶行为和环境方面存在局限。

Method: 通过驾驶模拟实验收集31名成年人的生理信号，设计多模态机器学习系统估计压力源，并分析模型敏感性和时间动态。

Result: 研究表明，将生理信号与上下文及行为线索结合，可提升驾驶压力的实时估计能力。

Conclusion: 研究展示了通过生理信号与行为模式结合改进驾驶压力实时监测的潜力。

Abstract: Understanding and mitigating driving stress is vital for preventing accidents
and advancing both road safety and driver well-being. While vehicles are
equipped with increasingly sophisticated safety systems, many limits exist in
their ability to account for variable driving behaviors and environmental
contexts. In this study we examine how short-term stressor events impact
drivers' physiology and their behavioral responses behind the wheel. Leveraging
a controlled driving simulation setup, we collected physiological signals from
31 adult participants and designed a multimodal machine learning system to
estimate the presence of stressors. Our analysis explores the model sensitivity
and temporal dynamics against both known and novel emotional inducers, and
examines the relationship between predicted stress and observable patterns of
vehicle control. Overall, this study demonstrates the potential of linking
physiological signals with contextual and behavioral cues in order to improve
real-time estimation of driving stress.

</details>


### [5] [Graph Convolutional Neural Networks to Model the Brain for Insomnia](https://arxiv.org/abs/2507.14147)
*Kevin Monteiro,Sam Nallaperuma-Herzberg,Martina Mason,Steve Niederer*

Main category: eess.SP

TL;DR: 该论文提出了一种基于脑电图（EEG）和图卷积神经网络（GCNN）的方法，用于识别失眠患者的脑功能特征，并实现分类任务。


<details>
  <summary>Details</summary>
Motivation: 现有失眠治疗方法存在副作用，且缺乏针对失眠的脑模型研究，因此需要开发新的方法。

Method: 使用连续长时程EEG数据，基于功能连接和空间距离构建脑网络，计算功率谱密度，并训练GCNN模型进行分类。

Result: 采用50秒非重叠滑动窗口时，窗口级别分类准确率为70%，受试者级别为68%。某些电极通道的缺失对模型性能影响显著。

Conclusion: 该方法能有效识别失眠相关的脑功能特征，为失眠治疗提供新思路。

Abstract: Insomnia affects a vast population of the world and can have a wide range of
causes. Existing treatments for insomnia have been linked with many side
effects like headaches, dizziness, etc. As such, there is a clear need for
improved insomnia treatment. Brain modelling has helped with assessing the
effects of brain pathology on brain network dynamics and with supporting
clinical decisions in the treatment of Alzheimer's disease, epilepsy, etc.
However, such models have not been developed for insomnia. Therefore, this
project attempts to understand the characteristics of the brain of individuals
experiencing insomnia using continuous long-duration EEG data. Brain networks
are derived based on functional connectivity and spatial distance between EEG
channels. The power spectral density of the channels is then computed for the
major brain wave frequency bands. A graph convolutional neural network (GCNN)
model is then trained to capture the functional characteristics associated with
insomnia and configured for the classification task to judge performance.
Results indicated a 50-second non-overlapping sliding window was the most
suitable choice for EEG segmentation. This approach achieved a classification
accuracy of 70% at window level and 68% at subject level. Additionally, the
omission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in
model performance than the removal of other channels. These channel electrodes
are positioned near brain regions known to exhibit atypical levels of
functional connectivity in individuals with insomnia, which can explain such
results.

</details>


### [6] [Visible Light Indoor Positioning with a Single LED and Distributed Single-Element OIRS: An Iterative Approach with Adaptive Beam Steering](https://arxiv.org/abs/2507.14148)
*Daniele Pugliese,Giovanni Iacovelli,Alessio Fascista,Domenico Striccoli,Oleksandr Romanov,Luigi Alfredo Grieco,Gennaro Boggia*

Main category: eess.SP

TL;DR: 论文研究了在单LED和多OIRS的VLC系统中低成本PD的定位问题，提出了一种基于ML估计器和IWLS算法的低复杂度定位方法。


<details>
  <summary>Details</summary>
Motivation: 利用OIRS增强VLC系统的定位能力，克服LoS遮挡问题，提高频谱效率和定位精度。

Method: 采用ML估计器分别计算LoS和NLoS距离，并通过噪声方差变换算法优化NLoS估计；结合IWLS算法和自适应波束控制实现低复杂度定位。

Result: 仿真结果表明，该方法在定位精度、抗OIRS失准能力和收敛速度方面表现优异。

Conclusion: 提出的方法在单LED和多OIRS的VLC系统中实现了高效、低复杂度的PD定位，具有实际应用潜力。

Abstract: The integration of Optical Intelligent Reflective Surfaces (OIRSs) into
Visible Light Communication (VLC) systems is gaining momentum as a valid
alternative to RF technologies, harnessing the existing lighting
infrastructures and the vast unlicensed optical spectrum to enable higher
spectral efficiency, improved resilience to Line-of-Sight (LoS) blockages, and
enhanced positioning capabilities. This paper investigates the problem of
localizing a low-cost Photo Detector (PD) in a VLC-based indoor environment
consisting of only a single Light Emitting Diode (LED) as an active anchor, and
multiple spatially distributed single-element OIRSs. We formulate the problem
within an indirect, computationally efficient localization framework: first,
the optimal Maximum Likelihood (ML) estimators of the LoS and Non-Line-of-Sight
(NLoS) distances are derived, using a suitable OIRS activation strategy to
prevent interferences. To overcome the grid-based optimization required by the
ML NLoS estimator, we devise a novel algorithm based on an unstructured noise
variance transformation, which admits a closed-form solution. The set of
estimated LoS/NLoS distances are then used within a low-complexity localization
algorithm combining an Iterative Weighted Least Squares (IWLS) procedure, whose
weights are set according to the inverse of the Cram\'er-Rao Lower Bound
(CRLB), with an adaptive beam steering strategy that allows the OIRSs network
to dynamically align with the PD, without any prior knowledge of its position.
Accordingly, we derive the CRLB for both LoS/NLoS distance estimation and PD
position estimation. Simulation results demonstrate the effectiveness of our
approach in terms of localization accuracy, robustness against OIRSs
misalignment conditions, and low number of iterations required to attain the
theoretical bounds.

</details>


### [7] [Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models](https://arxiv.org/abs/2507.14151)
*Giuliana Monachino,Nicolò La Porta,Beatrice Zanchi,Luigi Fiorillo,Alvise Dei Rossi,Georgiy Farina,Francesca Dalia Faraci*

Main category: eess.SP

TL;DR: Self-DANA是一种新型自监督架构，可适应减少的输入通道数，提高资源效率并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何将心电图（ECG）基础模型（FMs）适应于通道减少的下游场景。

Method: 提出Self-DANA和随机导联选择（Random Lead Selection）增强技术，用于自监督预训练。

Result: 在五种减少通道配置中，Self-DANA显著提升资源效率，性能达到SOTA。

Conclusion: Self-DANA为减少通道的ECG分析提供高效且高性能的解决方案。

Abstract: Foundation Models (FMs) are large-scale machine learning models trained on
extensive, diverse datasets that can be adapted to a wide range of downstream
tasks with minimal fine-tuning. In the last two years, interest in FMs has also
grown for applications in the cardiological field to analyze the
electrocardiogram (ECG) signals. One of the key properties of FMs is their
transferability to a wide range of downstream scenarios. With the spread of
wearable and portable devices, keen interest in learning from reduced-channel
configurations has arisen. However, the adaptation of ECG FMs to downstream
scenarios with fewer available channels still has to be properly investigated.
In this work, we propose Self-DANA, a novel, easy-to-integrate solution that
makes self-supervised architectures adaptable to a reduced number of input
channels, ensuring resource efficiency and high performance. We also introduce
Random Lead Selection, a novel augmentation technique to pre-train models in a
more robust and channel-agnostic way. Our experimental results on five
reduced-channel configurations demonstrate that Self-DANA significantly
enhances resource efficiency while reaching state-of-the-art performance. It
requires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about
17% less average epoch CPU time, and about 24% less average epoch GPU time.

</details>


### [8] [Machine learning-enabled river water quality monitoring using lithography-free 3D-printed sensors](https://arxiv.org/abs/2507.14152)
*Frank Efe Erukainure,Feidra Gjata,Matin Ataei Kachouei,Henry Cox,Md. Azahar Ali*

Main category: eess.SP

TL;DR: 本文提出了一种无光刻技术的磷酸盐传感器（P-sensor），用于检测河流水中的磷酸盐，检测限低至1 ppb，响应时间短于30秒。通过神经网络预测磷酸盐水平，验证了其在实际应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 河流水质监测对生态和人类健康至关重要，磷酸盐过量会导致富营养化问题。开发低成本、高效的传感器有助于预防这一问题。

Method: 采用3D打印的周期性聚合物图案（8微米特征尺寸）涂覆磷酸盐选择性膜，构建固态指示电极。使用神经网络预测磷酸盐水平。

Result: 传感器在0-475 ppm范围内检测低至1 ppb的磷酸盐，响应时间短于30秒。神经网络预测结果与商业磷酸盐仪高度一致（Pearson相关系数0.997）。

Conclusion: 该传感器为连续水质监测提供了实用工具，有助于改善公共健康和政策制定。

Abstract: River water quality monitoring is important for aquatic life, livestock, and
humans because clean water is critical to meeting food demand during the global
food crisis. Excessive contaminants, including phosphate, deplete dissolved
oxygen and trigger eutrophication, leading to serious health and ecological
problems. Continuous sensors that track phosphate levels can therefore help
prevent eutrophication. In this work we present a lithography-free phosphate
sensor (P-sensor) that detects phosphate in river water at parts-per-billion
levels. The device uses a solid-state indicator electrode formed by 3D-printed
periodic polymer patterns (8 um feature size) coated with a thin phosphate
ion-selective membrane. The P-sensor detects as little as 1 ppb phosphate
across 0 - 475 ppm with a response time under 30 seconds. We validated the
sensor on Rappahannock River water, Virginia (less than 0.8 ppm phosphate) at
sites upstream and downstream of a sewage treatment plant and benchmarked the
results against a commercial phosphate meter. A feed-forward neural network was
trained to predict phosphate levels, achieving a mean-squared error below 1e-3,
zero standard deviation, and a Pearson correlation coefficient of 0.997 for
river samples. These results demonstrate a practical tool for continuous
water-quality monitoring that can inform stakeholders and policymakers and
ultimately improve public health.

</details>


### [9] [Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM](https://arxiv.org/abs/2507.14153)
*Daniel Cieślak,Barbara Szyca,Weronika Bajko,Liwia Florkiewicz,Kinga Grzęda,Mariusz Kaczmarek,Helena Kamieniecka,Hubert Lis,Weronika Matwiejuk,Anna Prus,Michalina Razik,Inga Rozumowicz,Wiktoria Ziembakowska*

Main category: eess.SP

TL;DR: 研究利用表面肌电图（sEMG）评估帕金森病（PD）严重程度，通过改进的GCN-SVM模型达到92%准确率。


<details>
  <summary>Details</summary>
Motivation: 帕金森病的诊断和监测因症状复杂而具有挑战性，需要客观评估方法。

Method: 使用sEMG分析肱二头肌数据，比较PD患者和健康对照组，采用SVM和GCN-SVM模型进行分类。

Result: SVM模型准确率为83%，GCN-SVM提升至92%。

Conclusion: 该方法有望用于临床实践，但需更大样本验证。

Abstract: Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to
its progressive nature and complex symptoms. This study introduces a novel
approach utilizing surface electromyography (sEMG) to objectively assess PD
severity, focusing on the biceps brachii muscle. Initial analysis of sEMG data
from five PD patients and five healthy controls revealed significant
neuromuscular differences. A traditional Support Vector Machine (SVM) model
achieved up to 83% accuracy, while enhancements with a Graph Convolutional
Network-Support Vector Machine (GCN-SVM) model increased accuracy to 92%.
Despite the preliminary nature of these results, the study outlines a detailed
experimental methodology for future research with larger cohorts to validate
these findings and integrate the approach into clinical practice. The proposed
approach holds promise for advancing PD severity assessment and improving
patient care in Parkinson's disease management.

</details>


### [10] [Extreme Value Theory-based Distributed Interference Prediction for 6G Industrial Sub-networks](https://arxiv.org/abs/2507.14155)
*Pramesh Gautam,Sushmita Sapkota,Carsten Bockelmann,Shashi Raj Pandey,Armin Dekorsy*

Main category: eess.SP

TL;DR: 提出了一种结合统计与机器学习的干扰尾部预测框架，用于超密集子网络中的极端事件预测，并通过资源分配验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决超密集子网络中极端和罕见事件干扰预测的挑战，特别是在动态移动性、快速变化的信道统计和突发流量下。

Method: 结合倒置分位数补丁变换器（iQPTransformer）与极值理论（EVT），设计了一种分布式训练的分裂-iQPTransformer。

Result: 在超可靠区域中，BLER目标在95%以上百分位点持续达成，显著优于基线方法。

Conclusion: 该框架能有效处理深度衰落、随机流量和TDD错位，对极端干扰事件具有鲁棒性。

Abstract: Interference prediction that accounts for extreme and rare events remains a
key challenge for ultra-densely deployed sub-networks (SNs) requiring
hyper-reliable low-latency communication (HRLLC), particularly under dynamic
mobility, rapidly varying channel statistics, and sporadic traffic. This paper
proposes a novel calibrated interference tail prediction framework, a hybrid
statistical and machine learning (ML) approach that integrates an inverted
quantile patch transformer (iQPTransformer) within extreme value theory (EVT).
It captures interference dynamics and tail behavior while quantifying
uncertainty to provide statistical coverage guarantees. Its effectiveness is
demonstrated by leveraging the estimated interference tail distribution to
design predictive, risk-aware resource allocation. In resource-constrained SN
scenarios, we introduce the split-iQPTransformer, enabling collaborative
training by distributing neural network components between sensor-actuator (SA)
pairs and the SN controller, while maintaining minimal performance disparity
compared to the centralized iQPTransformer. The framework effectively handles
deep fading, random traffic, and time-division duplexing (TDD) misalignments
and is resilient to rare and extreme interference events. Extensive evaluations
are performed under two mobility models and two realistic SN traffic patterns,
using a spatially consistent 3GPP channel model across all scenarios.
Experimental results show consistent achievement of block error rate (BLER)
targets beyond the 95th percentile in the hyper-reliable regime, significantly
outperforming baseline approaches.

</details>


### [11] [UniPhyNet: A Unified Network For Multimodal Physiological Raw Signal Classification](https://arxiv.org/abs/2507.14163)
*Renxiang Qiu,Raghavendra Selvan*

Main category: eess.SP

TL;DR: UniPhyNet是一种新型神经网络架构，用于通过多模态生理数据（EEG、ECG、EDA信号）分类认知负荷，无需手工提取特征。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖手工特征提取的问题，提供端到端的解决方案。

Method: 结合多尺度并行卷积块、ResNet块、通道块注意力模块和双向门控循环单元，通过中间融合处理单模态和多模态信号。

Result: 在CL-Drive数据集上，二元分类准确率从70%提升至80%，三元分类从62%提升至74%。

Conclusion: UniPhyNet是一种有效的端到端解决方案，适用于现实世界中的认知状态监测。

Abstract: We present UniPhyNet, a novel neural network architecture to classify
cognitive load using multimodal physiological data -- specifically EEG, ECG and
EDA signals -- without the explicit need for extracting hand-crafted features.
UniPhyNet integrates multiscale parallel convolutional blocks and ResNet-type
blocks enhanced with channel block attention module to focus on the informative
features while a bidirectional gated recurrent unit is used to capture temporal
dependencies. This architecture processes and combines signals in both unimodal
and multimodal configurations via intermediate fusion of learned feature maps.
On the CL-Drive dataset, UniPhyNet improves raw signal classification accuracy
from 70% to 80% (binary) and 62% to 74% (ternary), outperforming feature-based
models, demonstrating its effectiveness as an end-to-end solution for
real-world cognitive state monitoring.

</details>


### [12] [A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy](https://arxiv.org/abs/2507.14164)
*Samuel Ruipérez-Campillo,Alain Ryser,Thomas M. Sutter,Ruibin Feng,Prasanth Ganesan,Brototo Deb,Kelly A. Brennan,Maxime Pedron,Albert J. Rogers,Maarten Z. H. Kolk,Fleur V. Y. Tjong,Sanjiv M. Narayan,Julia E. Vogt*

Main category: eess.SP

TL;DR: 本文提出了一种变分自编码器（VAE）模型，用于提高心室内单相动作电位（MAP）信号的质量，优于传统滤波方法。


<details>
  <summary>Details</summary>
Motivation: 心脏电生理学中，传统降噪方法难以处理信号中的非线性、非平稳噪声，影响心律失常和心肌病的诊断与治疗。

Method: 利用来自42名缺血性心肌病患者的5706个时间序列数据，构建VAE模型以生成干净信号的表示。

Result: VAE模型在多种噪声类型（包括临床常见的时变非线性噪声）下表现出优越的降噪性能。

Conclusion: VAE模型能够有效消除单次心跳中的多种噪声源，优于现有技术，有望提升心脏电生理学的治疗效果。

Abstract: In the field of cardiac electrophysiology (EP), effectively reducing noise in
intra-cardiac signals is crucial for the accurate diagnosis and treatment of
arrhythmias and cardiomyopathies. However, traditional noise reduction
techniques fall short in addressing the diverse noise patterns from various
sources, often non-linear and non-stationary, present in these signals. This
work introduces a Variational Autoencoder (VAE) model, aimed at improving the
quality of intra-ventricular monophasic action potential (MAP) signal
recordings. By constructing representations of clean signals from a dataset of
5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our
approach demonstrates superior denoising performance when compared to
conventional filtering methods commonly employed in clinical settings. We
assess the effectiveness of our VAE model using various metrics, indicating its
superior capability to denoise signals across different noise types, including
time-varying non-linear noise frequently found in clinical settings. These
results reveal that VAEs can eliminate diverse sources of noise in single
beats, outperforming state-of-the-art denoising techniques and potentially
improving treatment efficacy in cardiac EP.

</details>


### [13] [A Multi-Modal IoT Node for Energy-Efficient Environmental Monitoring with Edge AI Processing](https://arxiv.org/abs/2507.14165)
*Philip Wiese,Victor Kartsch,Marco Guermandi,Luca Benini*

Main category: eess.SP

TL;DR: 论文提出了一种紧凑型多模态MCU环境物联网节点，集成了11种传感器，支持实时边缘处理，显著节省能耗并延长设备运行时间。


<details>
  <summary>Details</summary>
Motivation: 当前物联网环境监测平台传感器种类有限且计算能力不足，无法支持高级ML/AI算法在边缘设备上的部署。

Method: 开发了基于GAP9芯片的紧凑型多传感器节点，集成了11种传感器，并实现了YOLOv5占用检测和自适应采样率的智能室内空气质量监测。

Result: 设备实现了42%的能耗节省，单次充电可运行143小时，支持高效的边缘AI处理。

Conclusion: 该平台为预测性室内空气质量监测等创新应用奠定了基础，推动了高效、自主的边缘AI解决方案。

Abstract: The widespread adoption of Internet of Things (IoT) technologies has
significantly advanced environmental monitoring (EM) by enabling cost-effective
and scalable sensing solutions. Concurrently, machine learning (ML) and
artificial intelligence (AI) are introducing powerful tools for the efficient
and accurate analysis of complex environmental data. However, current IoT
platforms for environmental sensing are typically limited to a narrow set of
sensors, preventing a comprehensive assessment of environmental conditions and
lacking sufficient computational capabilities to support the deployment of
advanced ML and AI algorithms on the edge. To overcome these limitations, we
introduce a compact (17x38 mm2), multi-modal, MCU-based environmental IoT node
integrating 11 sensors, including CO2 concentration, volatile organic compounds
(VOCs), light intensity, UV radiation, pressure, temperature, humidity, visual
sensing via an RGB camera, and precise geolocation through a GNSS module. It
features GAP9, a parallel ultra-low-power system-on-chip, enabling real-time,
energy-efficient edge processing of advanced ML models directly on-device. We
implemented a YOLOv5-based occupancy detection pipeline (0.3 M parameters, 42
MOP per inference), demonstrating 42% energy savings over raw data streaming.
Additionally, we present a smart indoor air quality (IAQ) monitoring setup that
combines occupancy detection with adaptive sample rates, achieving operational
times of up to 143 h on a single compact 600 mAh, 3.7 V battery. Our platform
lays the groundwork for innovative applications such as predictive indoor IAQ,
enabling efficient AI-driven on-edge forecasting for energy-efficient and
autonomous, proactive pollution-mitigation control strategies

</details>


### [14] [Automated Vigilance State Classification in Rodents Using Machine Learning and Feature Engineering](https://arxiv.org/abs/2507.14166)
*Sankalp Jajee,Gaurav Kumar,Homayoun Valafar*

Main category: eess.SP

TL;DR: 该研究提出了一种自动化框架，用于分类小啮齿动物的脑电图（EEG）记录，分为三种警觉状态：REM睡眠、慢波睡眠（SWS）和清醒状态，显著提高了分类准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 临床前睡眠研究受限于手动分类的劳动密集性和评分者间变异性，影响了通量和可重复性。

Method: 结合先进的信号处理和机器学习，利用时域和频域的工程特征（如频谱功率、最大-最小距离和跨频耦合指标）训练XGBoost模型。

Result: 在2024年大数据健康科学案例竞赛中，模型达到91.5%的总体准确率、86.8%的精确率、81.2%的召回率和83.5%的F1分数，优于所有基线方法。

Conclusion: 该框架是自动化睡眠状态分类的重要进展，有望加速睡眠科学的发现和慢性睡眠障碍的针对性干预开发。

Abstract: Preclinical sleep research remains constrained by labor intensive, manual
vigilance state classification and inter rater variability, limiting throughput
and reproducibility. This study presents an automated framework developed by
Team Neural Prognosticators to classify electroencephalogram (EEG) recordings
of small rodents into three critical vigilance states paradoxical sleep (REM),
slow wave sleep (SWS), and wakefulness. The system integrates advanced signal
processing with machine learning, leveraging engineered features from both time
and frequency domains, including spectral power across canonical EEG bands
(delta to gamma), temporal dynamics via Maximum-Minimum Distance, and
cross-frequency coupling metrics. These features capture distinct
neurophysiological signatures such as high frequency desynchronization during
wakefulness, delta oscillations in SWS, and REM specific bursts. Validated
during the 2024 Big Data Health Science Case Competition (University of South
Carolina Big Data Health Science Center, 2024), our XGBoost model achieved
91.5% overall accuracy, 86.8% precision, 81.2% recall, and an F1 score of
83.5%, outperforming all baseline methods. Our approach represents a critical
advancement in automated sleep state classification and a valuable tool for
accelerating discoveries in sleep science and the development of targeted
interventions for chronic sleep disorders. As a publicly available code (BDHSC)
resource is set to contribute significantly to advancements.

</details>


### [15] [Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization](https://arxiv.org/abs/2507.14167)
*Lucas Heublein,Christian Wielenberg,Thorsten Nowak,Tobias Feigl,Christopher Mutschler,Felix Ott*

Main category: eess.SP

TL;DR: 提出了一种基于注意力机制融合框架的新方法，用于检测和分类GNSS干扰信号，并估计干扰源的距离、方位和高度，在动态多径环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: GNSS干扰信号威胁定位可靠性，传统AoA方法在多径环境中精度不足且计算资源需求高。

Method: 结合IQ样本和FFT频谱图，引入22个AoA特征，通过注意力机制融合框架提升定位精度。

Result: 在动态多径环境中，新方法表现优于现有技术。

Conclusion: 提出的方法显著提高了干扰信号的检测和定位精度，适用于复杂环境。

Abstract: Jamming devices disrupt signals from the global navigation satellite system
(GNSS) and pose a significant threat by compromising the reliability of
accurate positioning. Consequently, the detection and localization of these
interference signals are essential to achieve situational awareness, mitigating
their impact, and implementing effective counter-measures. Classical Angle of
Arrival (AoA) methods exhibit reduced accuracy in multipath environments due to
signal reflections and scattering, leading to localization errors.
Additionally, AoA-based techniques demand substantial computational resources
for array signal processing. In this paper, we propose a novel approach for
detecting and classifying interference while estimating the distance, azimuth,
and elevation of jamming sources. Our benchmark study evaluates 128 vision
encoder and time-series models to identify the highest-performing methods for
each task. We introduce an attention-based fusion framework that integrates
in-phase and quadrature (IQ) samples with Fast Fourier Transform (FFT)-computed
spectrograms while incorporating 22 AoA features to enhance localization
accuracy. Furthermore, we present a novel dataset of moving jamming devices
recorded in an indoor environment with dynamic multipath conditions and
demonstrate superior performance compared to state-of-the-art methods.

</details>


### [16] [CQI-Based Interference Prediction for Link Adaptation in Industrial Sub-networks](https://arxiv.org/abs/2507.14169)
*Pramesh Gautam,Ravi Sharan B A G,Paolo Baracca,Carsten Bockelmann,Thorsten Wild,Armin Dekorsy*

Main category: eess.SP

TL;DR: 提出了一种新型干扰预测方案，用于改进高密度工业子网络中高可靠低延迟通信的链路自适应性能。


<details>
  <summary>Details</summary>
Motivation: 在密集部署的工业子网络中，高可靠性和低延迟通信需求对链路自适应提出了更高要求，传统方法难以应对干扰的复杂性和延迟问题。

Method: 通过预测和利用重尾干扰概率密度函数，采用向量离散时间状态空间模型和稀疏Student-t过程回归方法，结合改进的无迹卡尔曼滤波，实现对干扰功率的鲁棒估计。

Result: 数值结果表明，该方法复杂度降低10倍以上，且误块率保持在1e-6以下，性能接近仅使用CQI报告的先进监督技术。

Conclusion: 该方法显著提升了链路自适应的准确性和鲁棒性，适用于高密度工业子网络的高可靠低延迟通信场景。

Abstract: We propose a novel interference prediction scheme to improve link adaptation
(LA) in densely deployed industrial sub-networks (SNs) with high-reliability
and low-latency communication (HRLLC) requirements. The proposed method aims to
improve the LA framework by predicting and leveraging the heavy-tailed
interference probability density function (pdf). Interference is modeled as a
latent vector of available channel quality indicator (CQI), using a vector
discrete-time state-space model (vDSSM) at the SN controller, where the CQI is
subjected to compression, quantization, and delay-induced errors. To robustly
estimate interference power values under these impairments, we employ a
low-complexity, outlier-robust, sparse Student-t process regression (SPTPR)
method. This is integrated into a modified unscented Kalman filter, which
recursively refines predicted interference using CQI, enabling accurate
estimation and compensating protocol feedback delays, crucial for accurate LA.
Numerical results show that the proposed method achieves over 10x lower
complexity compared to a similar non-parametric baseline. It also maintains a
BLER below the 90th percentile target of 1e-6 while delivering performance
comparable to a state-of-the-art supervised technique using only CQI reports.

</details>


### [17] [Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model](https://arxiv.org/abs/2507.14173)
*Karim Alghoul,Hussein Al Osman,Abdulmotaleb El Saddik*

Main category: eess.SP

TL;DR: 本文提出了一种结合CNN、LSTM和TCN的混合架构，用于改进基于PPG信号的情感识别模型的泛化能力。实验表明，该模型在PPGE数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于PPG信号的情感识别模型在个体间的泛化能力不足，需要一种更鲁棒的解决方案。

Method: 提出了一种混合架构，结合CNN、LSTM和TCN，分别用于特征提取和时间序列处理，最终拼接特征进行分类。

Result: 模型在PPGE数据集上表现优于现有方法，AUC和F1分数证明了其有效性。

Conclusion: 混合架构显著提升了PPG信号情感识别的泛化能力，为未来研究提供了新方向。

Abstract: Human computer interaction has become integral to modern life, driven by
advancements in machine learning technologies. Affective computing, in
particular, has focused on systems that recognize, interpret, and respond to
human emotions, often using wearable devices, which provide continuous data
streams of physiological signals. Among various physiological signals, the
photoplethysmogram (PPG) has gained prominence due to its ease of acquisition
from widely available devices. However, the generalization of PPG-based emotion
recognition models across individuals remains an unresolved challenge. This
paper introduces a novel hybrid architecture that combines Convolutional Neural
Networks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal
Convolutional Networks (TCNs) to address this issue. The proposed model
integrates the strengths of these architectures to improve robustness and
generalization. Raw PPG signals are fed into the CNN for feature extraction.
These features are processed separately by LSTM and TCN. The outputs from these
components are concatenated to generate a final feature representation, which
serves as the input for classifying valence and arousal, the primary dimensions
of emotion. Experiments using the Photoplethysmogram Dataset for Emotional
Analysis (PPGE) demonstrate that the proposed hybrid model achieves better
model generalization than standalone CNN and LSTM architectures. Our results
show that the proposed solution outperforms the state-of-the-art CNN
architecture, as well as a CNN-LSTM model, in emotion recognition tasks with
PPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we
highlight the model's effectiveness in handling subject variability.

</details>


### [18] [NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment](https://arxiv.org/abs/2507.14184)
*ZhengXiao He,Jinghao Wen,Huayu Li,Ao Li*

Main category: eess.SP

TL;DR: 提出了一种结合超维计算（HDC）和可学习神经编码的新型心电图（ECG）疾病检测框架，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统HDC方法依赖静态随机投影，缺乏任务适应性。本文旨在通过可学习的编码管道提升ECG疾病检测的性能和可解释性。

Method: 采用基于RR间隔的节奏感知和可训练编码管道，结合神经蒸馏HDC架构，优化交叉熵和代理度量损失。

Result: 在Apnea-ECG和PTB-XL数据集上表现优异，精度达73.09%，F1分数0.626，且具有鲁棒性。

Conclusion: 该框架为边缘兼容的ECG分类提供了高效、可扩展且可解释的解决方案，适用于个性化健康监测。

Abstract: We present a novel and interpretable framework for electrocardiogram
(ECG)-based disease detection that combines hyperdimensional computing (HDC)
with learnable neural encoding. Unlike conventional HDC approaches that rely on
static, random projections, our method introduces a rhythm-aware and trainable
encoding pipeline based on RR intervals, a physiological signal segmentation
strategy that aligns with cardiac cycles. The core of our design is a
neural-distilled HDC architecture, featuring a learnable RR-block encoder and a
BinaryLinear hyperdimensional projection layer, optimized jointly with
cross-entropy and proxy-based metric loss. This hybrid framework preserves the
symbolic interpretability of HDC while enabling task-adaptive representation
learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model
significantly outperforms traditional HDC and classical ML baselines, achieving
73.09\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable
robustness on PTB-XL. Our framework offers an efficient and scalable solution
for edge-compatible ECG classification, with strong potential for interpretable
and personalized health monitoring.

</details>


### [19] [Latent Sensor Fusion: Multimedia Learning of Physiological Signals for Resource-Constrained Devices](https://arxiv.org/abs/2507.14185)
*Abdullah Ahmed,Jeremy Gummeson*

Main category: eess.SP

TL;DR: 提出了一种基于隐空间的模态无关统一编码器，通过传感器-隐空间融合分析多模态生理信号，解决了资源受限设备上的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 利用隐空间的高效性和隐含的元信息保留能力，开发一种适用于多模态生理信号分析的统一编码器。

Method: 采用压缩感知方法和基于自动编码器的隐空间融合技术，实现传感器-隐空间融合。

Result: 实验表明，该统一编码器比模态特定方法更快、更轻量、更具扩展性，且不损失表征准确性。

Conclusion: 该方法为资源受限设备上的多模态生理信号分析提供了一种高效、可扩展的解决方案。

Abstract: Latent spaces offer an efficient and effective means of summarizing data
while implicitly preserving meta-information through relational encoding. We
leverage these meta-embeddings to develop a modality-agnostic, unified encoder.
Our method employs sensor-latent fusion to analyze and correlate multimodal
physiological signals. Using a compressed sensing approach with
autoencoder-based latent space fusion, we address the computational challenges
of biosignal analysis on resource-constrained devices. Experimental results
show that our unified encoder is significantly faster, lighter, and more
scalable than modality-specific alternatives, without compromising
representational accuracy.

</details>


### [20] [AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms](https://arxiv.org/abs/2507.14187)
*Xiaojuan Zhang,Tianyu Jiang,Haoxiang Zong,Chen Zhang,Chendan Li,Marta Molinas*

Main category: eess.SP

TL;DR: 提出了一种基于AI的阻抗编码-解码方法，用于在线构建风电场的阻抗网络模型，解决了传统方法中高密度阻抗曲线传输的难题。


<details>
  <summary>Details</summary>
Motivation: 风电场的阻抗网络模型需要每台风力发电机在各自运行条件下的阻抗曲线，但高密度阻抗曲线的传输使得在线应用困难。

Method: 训练阻抗编码器压缩阻抗曲线，上传压缩数据至风电场，再训练阻抗解码器重构原始曲线，最后基于节点导纳矩阵方法获得阻抗网络模型。

Result: 通过模型训练和实时仿真验证，编码后的阻抗向量能够快速传输并准确重构原始阻抗曲线。

Conclusion: 该方法有效解决了阻抗曲线传输问题，为在线构建风电场阻抗网络模型提供了可行方案。

Abstract: The impedance network (IN) model is gaining popularity in the oscillation
analysis of wind farms. However, the construction of such an IN model requires
impedance curves of each wind turbine under their respective operating
conditions, making its online application difficult due to the transmission of
numerous high-density impedance curves. To address this issue, this paper
proposes an AI-based impedance encoding-decoding method to facilitate the
online construction of IN model. First, an impedance encoder is trained to
compress impedance curves by setting the number of neurons much smaller than
that of frequency points. Then, the compressed data of each turbine are
uploaded to the wind farm and an impedance decoder is trained to reconstruct
original impedance curves. At last, based on the nodal admittance matrix (NAM)
method, the IN model of the wind farm can be obtained. The proposed method is
validated via model training and real-time simulations, demonstrating that the
encoded impedance vectors enable fast transmission and accurate reconstruction
of the original impedance curves.

</details>


### [21] [Traffic Signal Phase and Timing Estimation with Large-Scale Floating Car Data](https://arxiv.org/abs/2507.14190)
*Mingcheng Liao,Zebang Feng,Miao Fan,Shengtong Xu,Haoyi Xiong*

Main category: eess.SP

TL;DR: 提出了一种工业级的FCD分析套件，用于从数据预处理到SPaT估计的全流程管理，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有FCD方法假设固定信号周期和简单路口设计，无法应对信号变化和多样化的路口结构，缺乏普适性框架。

Method: 开发了一套FCD分析套件，包括信号相位估计、TOD时段识别和红绿灯时长确定，具有稳定性和鲁棒性。

Result: 系统每天分析超过1500万条FCD记录，支持中国大陆200多万个交通信号，75%以上的估计误差小于5秒。

Conclusion: 该框架在多样条件下表现稳定，提供了清洗后的FCD数据集，支持未来研究。

Abstract: Effective modern transportation systems depend critically on accurate Signal
Phase and Timing (SPaT) estimation. However, acquiring ground-truth SPaT
information faces significant hurdles due to communication challenges with
transportation departments and signal installers. As a result, Floating Car
Data (FCD) has become the primary source for large-scale SPaT analyses. Current
FCD approaches often simplify the problem by assuming fixed schedules and basic
intersection designs for specific times and locations. These methods fail to
account for periodic signal changes, diverse intersection structures, and the
inherent limitations of real-world data, thus lacking a comprehensive framework
that is universally applicable. Addressing this limitation, we propose an
industrial-grade FCD analysis suite that manages the entire process, from
initial data preprocessing to final SPaT estimation. Our approach estimates
signal phases, identifies time-of-day (TOD) periods, and determines the
durations of red and green lights. The framework's notable stability and
robustness across diverse conditions, regardless of road geometry, is a key
feature. Furthermore, we provide a cleaned, de-identified FCD dataset and
supporting parameters to facilitate future research. Currently operational
within our navigation platform, the system analyses over 15 million FCD records
daily, supporting over two million traffic signals in mainland China, with more
than 75\% of estimations demonstrating less than five seconds of error.

</details>


### [22] [School Attendance Control System Based on RFID Technology with Raspberry Pi and Arduino: EDURFID](https://arxiv.org/abs/2507.14191)
*Cliver Oliver Turpo Benique*

Main category: eess.SP

TL;DR: EDURFID是一个基于RFID技术的自动化学校考勤系统，专为秘鲁农村教育机构设计，使用开源硬件和Python Django开发，实现了高精度和低成本。


<details>
  <summary>Details</summary>
Motivation: 为秘鲁农村教育机构提供低成本、高效的自动化考勤解决方案，减少行政时间。

Method: 集成Raspberry Pi 5、Arduino UNO R3和RC522 RFID模块，采用Python Django开发Web架构。

Result: 系统RFID读取精度100%，响应时间0.03秒，成本降低94%，每天节省50分钟行政时间。

Conclusion: EDURFID成功实现了考勤自动化，为农村学校提供了经济高效的解决方案。

Abstract: This paper presents EDURFID, an automated school attendance control system
based on RFID technology designed for rural educational institutions in Peru.
The system integrates open-source hardware (Raspberry Pi 5, Arduino UNO R3)
with RC522 RFID modules operating at 13.56 MHz, implementing a web architecture
developed in Python Django. The system demonstrates 100% precision in RFID
readings with 0.03-second response time, achieving 94% cost reduction compared
to commercial solutions. Validation at T\'upac Amaru Secondary Educational
Institution showed successful automation of attendance processes, saving 50
daily minutes of administrative time while providing real-time reporting
capabilities.

</details>


### [23] [Boosted Enhanced Quantile Regression Neural Networks with Spatiotemporal Permutation Entropy for Complex System Prognostics](https://arxiv.org/abs/2507.14194)
*David J Poland*

Main category: eess.SP

TL;DR: 提出了一种基于时空排列熵分析和增强分位数回归神经网络（BEQRNN）的新框架，用于模式预测和系统预后。


<details>
  <summary>Details</summary>
Motivation: 解决多维系统中复杂动态模式理解的挑战。

Method: 结合熵基复杂度测量与先进神经网络架构，采用双计算阶段：时空熵提取和BEQRNN层集成。

Result: 时空模式分类准确率达81.17%，预测时间步长可达200，关键过渡检测准确率提高79%，长期预测可靠性提升81.22%。

Conclusion: 该框架在处理复杂多模态熵特征方面表现出色，具有实时预后应用的潜力。

Abstract: This paper presents a novel framework for pattern prediction and system
prognostics centered on Spatiotemporal Permutation Entropy analysis integrated
with Boosted Enhanced Quantile Regression Neural Networks (BEQRNNs). We address
the challenge of understanding complex dynamical patterns in multidimensional
systems through an approach that combines entropy-based complexity measures
with advanced neural architectures. The system leverages dual computational
stages: first implementing spatiotemporal entropy extraction optimized for
multiscale temporal and spatial data streams, followed by an integrated BEQRNN
layer that enables probabilistic pattern prediction with uncertainty
quantification. This architecture achieves 81.17% accuracy in spatiotemporal
pattern classification with prediction horizons up to 200 time steps and
maintains robust performance across diverse regimes. Field testing across
chaotic attractors, reaction-diffusion systems, and industrial datasets shows a
79% increase in critical transition detection accuracy and 81.22% improvement
in long-term prediction reliability. The framework's effectiveness in
processing complex, multimodal entropy features demonstrates significant
potential for real-time prognostic applications.

</details>


### [24] [UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach](https://arxiv.org/abs/2507.14195)
*Elzbieta Gruzewska,Pooja Rao,Sebastien Baur,Matthew Baugh,Mathias M. J. Bellaiche,Sharanya Srinivas,Octavio Ponce,Matthew Thompson,Pramod Rudrapatna,Michael A. Sanchez,Lawrence Z. Cai,Timothy JA Chico,Robert F. Storey,Emily Maz,Umesh Telang,Shravya Shetty,Mayank Daswani*

Main category: eess.SP

TL;DR: 该研究展示了在FMCW和IR-UWB雷达系统之间进行迁移学习，用于心率监测，显著提高了IR-UWB系统的性能。


<details>
  <summary>Details</summary>
Motivation: 利用雷达技术实现非接触式心率监测，但不同雷达系统缺乏标准化，需大量配对数据集。

Method: 采用2D+1D ResNet架构，先在FMCW雷达数据上训练，再迁移到IR-UWB数据。

Result: FMCW雷达的MAE为0.85 bpm，MAPE为1.42%；迁移后IR-UWB的MAE降低25%，达到4.1 bpm。

Conclusion: 迁移学习可加速雷达心率监测技术在消费设备中的应用。

Abstract: Radar technology presents untapped potential for continuous, contactless, and
passive heart rate monitoring via consumer electronics like mobile phones.
However the variety of available radar systems and lack of standardization
means that a large new paired dataset collection is required for each radar
system. This study demonstrates transfer learning between frequency-modulated
continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems,
both increasingly integrated into consumer devices. FMCW radar utilizes a
continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW
radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3
receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz
bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we
achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage
error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119
participants, an average of 8 hours per participant). This model maintained
performance (under 5 MAE/10% MAPE) across various body positions and heart rate
ranges, with a 98.9% recall. We then fine-tuned a variant of this model,
trained on single-antenna and single-range bin FMCW data, using a small (N=376,
avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach
yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE
reduction over the IR-UWB baseline. This demonstration of transfer learning
between radar systems for heart rate monitoring has the potential to accelerate
its introduction into existing consumer devices.

</details>


### [25] [Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs](https://arxiv.org/abs/2507.14196)
*Zahra Teimouri-Jervekani,Fahimeh Nasimi,Mohammadreza Yazdchi,Ghazal MogharehZadeh,Javad Tezerji,Farzan Niknejad Mazandarani,Maryam Mohebbi*

Main category: eess.SP

TL;DR: 提出了一种轻量级并行深度学习架构，用于高效准确地区分宽QRS心动过速（WCT），并通过SHAP提供模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 临床中区分WCT（如室性心动过速和室上性心动过速伴差异性传导）具有挑战性且误诊风险高，需高效且可解释的解决方案。

Method: 采用轻量级并行深度学习架构，结合1D-CNN提取局部特征和LSTM捕捉时序依赖，并通过SHAP实现模型解释。

Result: 模型准确率达95.63%，敏感性和特异性均超过95%，计算效率优于现有方法，SHAP分析提供了临床可解释的特征贡献。

Conclusion: 该框架在高效分类WCT的同时增强了临床信任，适用于实时ECG分析工具。

Abstract: Background and Objective: Differentiating wide complex tachycardia (WCT) is
clinically critical yet challenging due to morphological similarities in
electrocardiogram (ECG) signals between life-threatening ventricular
tachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A).
Misdiagnosis carries fatal risks. We propose a computationally efficient deep
learning solution to improve diagnostic accuracy and provide model
interpretability for clinical deployment.
  Methods: A novel lightweight parallel deep architecture is introduced. Each
pipeline processes individual ECG leads using two 1D-CNN blocks to extract
local features. Feature maps are concatenated across leads, followed by LSTM
layers to capture temporal dependencies. Final classification employs fully
connected layers. Explainability is achieved via Shapley Additive Explanations
(SHAP) for local/global interpretation. The model was evaluated on a 35-subject
ECG database using standard performance metrics.
  Results: The model achieved $95.63\%$ accuracy ($95\%$ CI: $93.07-98.19\%$),
with sensitivity=$95.10\%$, specificity=$96.06\%$, and F1-score=$95.12\%$. It
outperformed state-of-the-art methods in both accuracy and computational
efficiency, requiring minimal CNN blocks per pipeline. SHAP analysis
demonstrated clinically interpretable feature contributions.
  Conclusions: Our end-to-end framework delivers high-precision WCT
classification with minimal computational overhead. The integration of SHAP
enhances clinical trust by elucidating decision logic, supporting rapid,
informed diagnosis. This approach shows significant promise for real-world ECG
analysis tools.

</details>


### [26] [Design of A New Multiple-Chirp-Rate Index Modulation for LoRa Networks](https://arxiv.org/abs/2507.14228)
*Xiaobin Zhu,Minling Zhang,Guofa Cai,Jiguang He,Georges Kaddoum*

Main category: eess.SP

TL;DR: 提出基于Zadoff-Chu序列的多重啁啾速率索引调制（MCR-IM）系统，解决传统LoRa网络传输速率低和大规模接入问题，并通过PD-SIC算法提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统LoRa网络低传输速率和大规模接入的局限性。

Method: 基于Zadoff-Chu序列设计MCR-IM系统，推导Nakagami-m衰落信道下的误码率闭式表达式，并提出PD-SIC算法以减少并行通道数。

Result: 仿真验证闭式表达式准确性，MCR-IM系统比现有系统频谱效率更高，吞吐量提升16%-21%，误码率更低。

Conclusion: MCR-IM系统适合大规模、高速率的LoRa网络应用。

Abstract: We propose a multiple chirp rate index modulation (MCR-IM) system based on
Zadoff-Chu (ZC) sequences that overcomes the problems of low transmission rate
and large-scale access in classical LoRa networks. We demonstrate the extremely
low cross-correlation of MCR-IM signals across different spread factors,
showing that the proposed MCR-IM system also inherits the characteristics of ZC
sequences modulation. Moreover, we derive an approximate closed-form expression
for the bit-error rate (BER) of the proposed MCR-IM system over Nakagami-m
fading channels. Simulation results confirm the accuracy of the derived
closed-form expression and demonstrate that the MCR-IM system achieves higher
levels of spectral efficiency (SE) compared to existing systems. In this
context, assigning multiple chirp rates to each user results in a reduction in
the number of parallel channels. To mitigate this issue, we propose a peak
detection based successive interference cancellation (PD-SIC) algorithm to
accommodate more users. Compared to orthogonal scatter chirp spreading spectrum
system that names OrthoRa, the MCR-IM system with PD-SIC algorithm achieves
lower BER levels. For a similar number of collision signals, the throughput of
the MCR-IM system is enhanced by 16% to 21%. Owing to these advantages, the
proposed MCR-IM is well suited for large-scale, high-rate LoRa network
applications.

</details>


### [27] [A Comprehensive Benchmark for Electrocardiogram Time-Series](https://arxiv.org/abs/2507.14206)
*Zhijiang Tang,Jiaxin Qi,Yuhua Zheng,Jianqiang Huang*

Main category: eess.SP

TL;DR: 本文深入研究了心电图（ECG）信号，提出了一个全面的基准，包括下游任务分类、新评价指标和新模型架构，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究常忽略ECG信号的独特性和专用下游应用，导致对其理解不完整，本文旨在填补这一空白。

Method: 将ECG下游应用分为四类任务，提出新评价指标，并设计新模型架构。

Result: 实验证明基准全面且稳健，新指标和模型架构有效。

Conclusion: 本文为ECG信号分析研究奠定了坚实基础。

Abstract: Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial
for assessing cardiac health and diagnosing various diseases. Given its
time-series format, ECG data is often incorporated into pre-training datasets
for large-scale time-series model training. However, existing studies often
overlook its unique characteristics and specialized downstream applications,
which differ significantly from other time-series data, leading to an
incomplete understanding of its properties. In this paper, we present an
in-depth investigation of ECG signals and establish a comprehensive benchmark,
which includes (1) categorizing its downstream applications into four distinct
evaluation tasks, (2) identifying limitations in traditional evaluation metrics
for ECG analysis, and introducing a novel metric; (3) benchmarking
state-of-the-art time-series models and proposing a new architecture. Extensive
experiments demonstrate that our proposed benchmark is comprehensive and
robust. The results validate the effectiveness of the proposed metric and model
architecture, which establish a solid foundation for advancing research in ECG
signal analysis.

</details>


### [28] [Pinching-Antenna-based Communications: Spectral Efficiency Analysis and Deployment Strategies](https://arxiv.org/abs/2507.14831)
*Mengyu Qian,Xidong Mu,Li You,Michail Matthaiou*

Main category: eess.SP

TL;DR: 研究了基于多波导夹持天线（PA）的多用户通信系统，比较了集中式和分布式部署策略的频谱效率（SE），并分析了在不同信噪比（SNR）下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 探索多波导夹持天线系统在多用户通信中的性能优化，比较集中式和分布式部署策略的优劣。

Method: 1. 集中式部署：通过波束成形增益最大化信道增益；2. 分布式部署：利用复用增益同时服务多用户，采用最大比传输（MRT）并近似分析SE。

Result: 高SNR下分布式部署更优，低SNR下集中式部署更合适。仿真验证了理论分析。

Conclusion: 分布式部署在高SNR下表现更佳，而集中式部署在低SNR下更具优势。

Abstract: A multiple-waveguide pinching-antenna (PA)-based multi-user communication
system is investigated. With a given number of PAs, two deployment strategies
are considered, namely the centralized PA deployment, where all PAs are
switched between waveguides to serve users in a time-division manner to avail
of beamforming gain, and the distributed PA deployment, where a single PA is
deployed on each waveguide to simultaneously serve multiple users by leveraging
the multiplexing gain. The spectral efficiency (SE) achieved by each deployment
strategy is analyzed: i) For the centralized deployment, the positioning
strategy of PAs on each waveguide is determined first with the aim of
maximizing the channel gain of the corresponding nearest served user. Based on
this, the corresponding system SE is derived. ii) For the distributed
deployment, the system SE under the maximum ratio transmission (MRT) is first
obtained. To obtain an analytically tractable form, the stationary phase method
is utilized to approximate the system SE. The approximation result reveals that
the average inter-user interference can be negligible with a large waveguide
spacing and thus the simple MRT is appealing for PA-based multi-user
communications. Furthermore, the system SEs achieved by the two strategies are
compared in both the high and low signal-to-noise ratio (SNR) regimes. Our
analysis suggests that at high SNRs, the distributed deployment is superior to
achieve the maximal system SE, while the centralized deployment is more
suitable for the low-SNR regime. Finally, the theoretical analysis is verified
through simulations.

</details>


### [29] [Toward intelligent wireless networks in computer chassis](https://arxiv.org/abs/2507.14208)
*Mohammadreza F. Imani,Alexander L. Colson,Leslie K. Miller,Jorge A. Valdez,Jose C. Sanchez,Richard F. Rader*

Main category: eess.SP

TL;DR: 论文提出利用可重构智能表面（RIS）优化计算机机箱内的短距离无线通信（SRWC），解决多径散射导致的信道脉冲响应（CIR）拉伸和符号间干扰（ISI）问题。


<details>
  <summary>Details</summary>
Motivation: 随着计算需求增加，传统有线互连在高速数据传输中效率下降，而SRWC虽灵活但受多径散射限制。

Method: 通过RIS调整反射波相位，使多径分量在接收端形成脉冲状CIR，减少ISI。

Result: 实验验证了RIS在典型计算机机箱内的有效性。

Conclusion: RIS支持的SRWC为当前和未来数据处理单元的无线链路优化提供了可行方案。

Abstract: Processing the exponentially growing amount of data produced daily requires
efficient communication between different processing units in a computer.
Traditionally, wired interconnects have been used to maintain these data links
due to their energy efficiency and ability to support high data rates. However,
as computing demands continue to increase in size and speed, these wired
interconnects can become longer and less effective. One possible solution is to
enhance the wired interconnects with short-range wireless communication (SRWC),
which offers flexible resource allocation and the ability to broadcast data.
However, implementing SRWC inside a computer chassis presents challenges due to
multiple scattering. This scattering stretches the channel impulse response
(CIR), leading to inter-symbol interference (ISI) and limiting data rates. To
address this issue, we propose transforming the computer chassis into a smart
radio environment by utilizing a reconfigurable intelligent surface (RIS). The
RIS elements adjust the phase of reflected waves so that the multipath
components combine at the receiver in a way that creates a pulse-like CIR. This
approach has been experimentally validated within a typical computer chassis.
The results of this study pave the way for integrating RIS-enabled SRWC to
enhance wireless links in both current and future data processing units.

</details>


### [30] [PAPR Analysis for MIMO FTN Signaling with Gaussian Symbols](https://arxiv.org/abs/2507.15116)
*Zichao Zhang,Melda Yuksel,Gokhan M. Guvensen,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 研究了MIMO FTN系统中高斯符号在两种功率约束下的PAPR行为，发现PAPR主要由加速因子和功率约束决定，功率分配优化对PAPR行为无影响。


<details>
  <summary>Details</summary>
Motivation: 探讨Faster-than-Nyquist信号在提高频谱效率的同时，如何优化其PAPR性能。

Method: 分析MIMO FTN系统中高斯符号在固定发射功率和固定接收信噪比两种功率约束下的PAPR行为。

Result: PAPR主要由加速因子和功率约束决定，功率分配优化对PAPR行为无显著影响。

Conclusion: 在MIMO FTN系统中，PAPR性能主要由系统参数决定，功率分配优化对其影响有限。

Abstract: Faster-than-Nyquist signaling serves as a promising solution for improving
spectral efficiency in future generations of communications. However, its
nature of fast acceleration brings highly overlapped pulses that lead to worse
peak-to-average power ratio (PAPR) performance. In this paper, we investigate
the PAPR behavior of MIMO FTN using Gaussian symbols under optimal power
allocation for two power constraints: fixed transmit power and fixed received
signal-to-noise-ratio (SNR). Our findings reveal that PAPR is mainly determined
by the acceleration factor and the power constraint, but power allocation
optimization does not change the PAPR behavior for Gaussian signaling.

</details>


### [31] [System Design and Performance Analysis for RIS-assisted Terahertz Self-Alignment Beamforming](https://arxiv.org/abs/2507.14210)
*Jiayuan Wei,Qingwei Jiang,Wen Fang,Mingqing Liu,Qingwen Liu,Wen Chen,Qingqing Wu*

Main category: eess.SP

TL;DR: 论文提出了一种基于可重构智能表面（RIS）的太赫兹频段无线信息和能量同传（SWIPT）系统，通过相位共轭电路实现自对准波束成形，提升传输效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备的广泛部署，需要可持续的无线解决方案以同时传输信息和能量。太赫兹频段虽然提供高数据速率和带宽，但存在路径损耗和波束对准问题。

Method: 提出RIS辅助的发射机架构，利用相位共轭电路实现自对准波束成形，并通过主动放大补偿信道衰减。

Result: 理论模型和仿真显示，系统显著减少旁瓣干扰，在2米距离内实现73.26%的传输效率。

Conclusion: RIS辅助的THz-SWIPT系统通过自对准和功率循环优化，有效解决了太赫兹波传输中的关键问题。

Abstract: The widespread deployment of Internet of Things(IoT) devices underscores the
need for sustainable wireless solutions capable of simultaneously transferring
both energy and information. Terahertz (THz) band-enabled simultaneous wireless
information and power transfer (SWIPT) systems offer ultra-high data rates and
expansive bandwidth. However, THz waves are inherently susceptible to severe
path loss and beam misalignment due to their narrow-beam characteristics. In
this context, this paper proposes a reconfigurable intelligent
surface(RIS)-assisted transmitter architecture for the THz-SWIPT system, which
enables end-to-end self-alignment for steady-state transmission. The proposed
system incorporates phase conjugate circuits to achieve self-aligned
beamforming, facilitating the dynamic tracking of mobile IoT devices without
the need for beam training. Additionally, active amplification within the RIS
arrays compensates for cascaded channel attenuation through an iterative power
cycle, thereby enhancing the energy transmission efficiency. Theoretical models
and simulations indicate that the proposed system significantly mitigates
sidelobe interference, achieving a transmission efficiency of up to 73.26% over
a 2 meter distance with self-alignment.

</details>


### [32] [Movable-Antenna Empowered AAV-Enabled Data Collection over Low-Altitude Wireless Networks](https://arxiv.org/abs/2507.15515)
*Xuhui Zhang,Wenchao Liu,Jinke Ren,Chunjie Wang,Huijun Xing,Yanyan Shen,Shuguang Cui*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可移动天线（MA）的自主飞行器（AAV）系统，用于低空无线网络（LAWNs）中地面用户的上行数据收集，通过联合优化AAV轨迹、接收波束成形和MA位置，最大化总可实现速率。


<details>
  <summary>Details</summary>
Motivation: 研究MA技术在低空无线网络中的应用潜力，通过灵活的波束成形和空间干扰管理提升频谱效率和收集可靠性。

Method: 开发了一种高效的交替优化（AO）算法，结合了逐次凸近似、加权最小均方误差和粒子群优化。

Result: 仿真结果表明，所提方案在总可实现速率和服务可靠性方面优于多种基准方案。

Conclusion: MA赋能的LAWNs具有显著的频谱效率提升和干扰管理优势，展示了其实际应用潜力。

Abstract: Movable-antennas (MAs) are revolutionizing spatial signal processing by
providing flexible beamforming in next-generation wireless systems. This paper
investigates an MA-empowered autonomous aerial vehicle (AAV) system in
low-altitude wireless networks (LAWNs) for uplink data collection from ground
users. We aim to maximize the sum achievable rate by jointly optimizing the AAV
trajectory, receive beamforming, and MA positions. An efficient alternating
optimization (AO) algorithm that incorporates successive convex approximation,
weighted minimum mean square error, and particle swarm optimization is
developed. The analysis of the computational complexity and convergence
features is provided. Extensive simulations demonstrate superior performance in
terms of the sum achievable rate and the service reliability comparing to
several benchmark schemes. These results demonstrate the distinctive advantages
of the proposed scheme: enhanced spectral efficiency via adaptive beam-user
alignment and improved collection reliability through spatial interference
management, highlighting the implementation potential of the MA-empowered
LAWNs.

</details>


### [33] [Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2507.14216)
*Manish Kumar,Tzu-Hsuan Chou,Byunghyun Lee,Nicolò Michelusi,David J. Love,Yaguang Zhang,James V. Krogmeier*

Main category: eess.SP

TL;DR: 提出了一种分布式机器学习框架，用于6G网络中的低延迟指纹定位，通过分散计算减少延迟和CPU负担。


<details>
  <summary>Details</summary>
Motivation: 支持实时应用的低延迟定位需求，适应6G网络的分布式架构。

Method: 每个接入点独立训练高斯过程回归模型，用户设备融合概率位置估计。

Result: 分布式框架在定位精度上与集中式方法相当，同时减少延迟和计算负担。

Conclusion: 分布式机器学习框架有望在6G网络中实现低延迟、高精度的定位。

Abstract: Low-latency localization is critical in cellular networks to support
real-time applications requiring precise positioning. In this paper, we propose
a distributed machine learning (ML) framework for fingerprint-based
localization tailored to cell-free massive multiple-input multiple-output
(MIMO) systems, an emerging architecture for 6G networks. The proposed
framework enables each access point (AP) to independently train a Gaussian
process regression model using local angle-of-arrival and received signal
strength fingerprints. These models provide probabilistic position estimates
for the user equipment (UE), which are then fused by the UE with minimal
computational overhead to derive a final location estimate. This decentralized
approach eliminates the need for fronthaul communication between the APs and
the central processing unit (CPU), thereby reducing latency. Additionally,
distributing computational tasks across the APs alleviates the processing
burden on the CPU compared to traditional centralized localization schemes.
Simulation results demonstrate that the proposed distributed framework achieves
localization accuracy comparable to centralized methods, despite lacking the
benefits of centralized data aggregation. Moreover, it effectively reduces
uncertainty of the location estimates, as evidenced by the 95\% covariance
ellipse. The results highlight the potential of distributed ML for enabling
low-latency, high-accuracy localization in future 6G networks.

</details>


### [34] [Zak-OTFS based Multiuser Uplink in Doubly-Spread Channels](https://arxiv.org/abs/2507.15621)
*Imran Ali Khan,Saif Khan Mohammed,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank*

Main category: eess.SP

TL;DR: 论文提出了一种基于Zak-OTFS的新型调制方案，解决了OFDM中子载波间距不灵活的问题，实现了多用户上行链路通信中的灵活资源分配。


<details>
  <summary>Details</summary>
Motivation: 下一代通信网络中，无线用户需要共享频谱资源。OFDM虽然易于分配非重叠时频资源，但其子载波间距固定，导致单个用户的载波间干扰会影响所有用户。Zak-OTFS作为一种延迟-多普勒域调制方案，具有可预测的输入输出关系，为解决这一问题提供了可能。

Method: 设计了一种延迟-多普勒域方法，通过调整Zak-OTFS脉冲形状实现灵活的非重叠时频资源分配。基站接收上行信号叠加后，应用匹配滤波器提取各用户数据。

Result: 通过理论分析和数值模拟，证明了在多用户Zak-OTFS上行链路系统中，无需保护频带即可实现单用户性能。

Conclusion: Zak-OTFS的可预测波形优势可在上行通信架构中实现，为下一代通信网络提供了更灵活的频谱共享方案。

Abstract: Wireless users with different characteristics will be expected to share
spectrum in next generation communication networks. One of the great strengths
of wireless networks based on Orthogonal Frequency Division Multiplexing (OFDM)
is the ease with which different non-overlapping time-frequency (TF) resources
can be allocated to different users by simply shifting each user's signal in
time and frequency. However, a significant weaknesses of OFDM is the
inflexibility of sub-carrier spacing. Since OFDM does not allow users to have
different sub-carrier spacing, a single user subject to inter-carrier
interference causes carrier spacing to increase for all users. Zak-OTFS is an
alternative delay-Doppler (DD) domain modulation scheme, where, in contrast to
OFDM, the Input-Output (I/O) relation is predictable. We match the strength of
OFDM by designing a novel DD domain method of shaping the transmitted Zak-OTFS
pulse on the uplink that enables flexible non-overlapping TF resource
allocation. The base station (BS) receives a superposition of uplink signals
and applies individual matched filters to obtain the data specific to
individual users. We develop theoretical measures of interference between
users, and present numerical simulations for a vehicular channel model
representative of next generation propagation environments. We demonstrate
single-user performance in a multiuser Zak-OTFS uplink system without needing
to provision guard bands between TF resources allocated to different users.
These performance results demonstrate that the benefits of a predictable
Zak-OTFS waveform can be realized within an architecture for uplink
communication.

</details>


### [35] [Advanced Space Mapping Technique Integrating a Shared Coarse Model for Multistate Tuning-Driven Multiphysics Optimization of Tunable Filters](https://arxiv.org/abs/2507.14220)
*Haitian Hu,Wei Zhang,Feng Feng,Zhiguo Zhang,Qi-Jun Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于共享电磁粗模型的高级空间映射技术，用于多状态调谐驱动的多物理场滤波器优化，结合了计算效率和精度。


<details>
  <summary>Details</summary>
Motivation: 解决多物理场优化中计算成本高和精度不足的问题，通过共享粗模型和映射神经网络实现高效建模。

Method: 使用共享电磁粗模型和多个子代理模型，每个子模型包含一个粗模型和两个映射神经网络，同时优化多个调谐状态。

Result: 相比现有方法，提出的技术以更少的训练样本和计算成本实现了更高的多物理场建模精度。

Conclusion: 该方法在多物理场优化中表现出高效性和准确性，适用于多状态调谐需求。

Abstract: This article introduces an advanced space mapping (SM) technique that applies
a shared electromagnetic (EM)-based coarse model for multistate tuning-driven
multiphysics optimization of tunable filters. The SM method combines the
computational efficiency of EM single-physics simulations with the precision of
multiphysics simulations. The shared coarse model is based on EM single-physics
responses corresponding to various nontunable design parameters values.
Conversely, the fine model is implemented to delineate the behavior of
multiphysics responses concerning both nontunable and tunable design parameter
values. The proposed overall surrogate model comprises multiple subsurrogate
models, each consisting of one shared coarse model and two distinct mapping
neural networks. The responses from the shared coarse model in the EM
single-physics filed offer a suitable approximation for the fine responses in
the multiphysics filed, whereas the mapping neural networks facilitate
transition from the EM single-physics field to the multiphysics field. Each
subsurrogate model maintains consistent nontunable design parameter values but
possesses unique tunable design parameter values. By developing multiple
subsurrogate models, optimization can be simultaneously performed for each
tuning state. Nontunable design parameter values are constrained by all tuning
states, whereas tunable design parameter values are confined to their
respective tuning states. This optimization technique simultaneously accounts
for all the tuning states to fulfill the necessary multiple tuning state
requirements. Multiple EM and multiphysics training samples are generated
concurrently to develop the surrogate model. Compared with existing direct
multiphysics parameterized modeling techniques, our proposed method achieves
superior multiphysics modeling accuracy with fewer training samples and reduced
computational costs.

</details>


### [36] [Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications](https://arxiv.org/abs/2507.15800)
*Yinchao Yang,Jingxuan Zhou,Zhaohui Yang,Mohammad Shikh-Bahaei*

Main category: eess.SP

TL;DR: 提出了一种结合近场感知、计算和语义通信的新框架（NF-ISCSC），利用流体天线（FAs）动态适应信道变化，通过联合优化提升数据速率和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 近场感知与通信（NF-ISAC）虽能提升性能，但面临数据量大和隐私风险问题，需通过语义通信和动态适应机制解决。

Method: 提出NF-ISCSC框架，结合流体天线（FAs）动态适应信道，通过交替优化（AO）方法解决联合优化问题，包括波束成形、FA定位和语义提取比例。

Result: 仿真结果显示，该框架在数据速率和隐私保护方面表现更优。

Conclusion: NF-ISCSC框架通过语义通信和流体天线有效解决了近场感知与通信的挑战，提升了系统性能。

Abstract: The integration of sensing and communication (ISAC) is a key enabler for
next-generation technologies. With high-frequency bands and large-scale antenna
arrays, the Rayleigh distance extends, necessitating near-field (NF) models
where waves are spherical. Although NF-ISAC improves both sensing and
communication, it also poses challenges such as high data volume and potential
privacy risks. To address these, we propose a novel framework: near-field
integrated sensing, computing, and semantic communication (NF-ISCSC), which
leverages semantic communication to transmit contextual information only,
thereby reducing data overhead and improving efficiency. However, semantic
communication is sensitive to channel variations, requiring adaptive
mechanisms. To this end, fluid antennas (FAs) are introduced to support the
NF-ISCSC system, enabling dynamic adaptability to changing channels. The
proposed FA-enabled NF-ISCSC framework considers multiple communication users
and extended targets comprising several scatterers. A joint optimization
problem is formulated to maximize data rate while accounting for sensing
quality, computational load, and power budget. Using an alternating
optimization (AO) approach, the original problem is divided into three
sub-problems: ISAC beamforming, FA positioning, and semantic extraction ratio.
Beamforming is optimized using the successive convex approximation method. FA
positioning is solved via a projected Broyden-Fletcher-Goldfarb-Shanno (BFGS)
algorithm, and the semantic extraction ratio is optimized using bisection
search. Simulation results demonstrate that the proposed framework achieves
higher data rates and better privacy preservation.

</details>


### [37] [Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG](https://arxiv.org/abs/2507.14224)
*Benoît Brebion,Alban Gallard,Katrin Sippel,Amer Zaylaa,Hubert Preissl,Sahar Moghimi,Fabrice Wallois,Yaël Frégier*

Main category: eess.SP

TL;DR: 研究利用人工智能改进胎儿脑磁图（fMEG）数据分析，通过新型扩散翻译方法显著提升信号保真度。


<details>
  <summary>Details</summary>
Motivation: 传统脑电图（EEG）无法研究胎儿期脑活动，而fMEG数据质量差且稀缺，需借助AI将EEG知识迁移至fMEG。

Method: 开发基于双扩散桥的非配对扩散翻译方法，优化数值积分，训练于30例新生儿EEG和44例fMEG数据集。

Result: 方法在时域均方误差上比GAN提升近5%，频域完全避免模式崩溃，信号保真度接近完美。

Conclusion: 为EEG-fMEG非配对翻译设新标杆，工具可推广至其他信号翻译应用。

Abstract: Background and objective: Brain activity in premature newborns has
traditionally been studied using electroencephalography (EEG), leading to
substantial advances in our understanding of early neural development. However,
since brain development takes root at the fetal stage, a critical window of
this process remains largely unknown. The only technique capable of recording
neural activity in the intrauterine environment is fetal magnetoencephalography
(fMEG), but this approach presents challenges in terms of data quality and
scarcity. Using artificial intelligence, the present research aims to transfer
the well-established knowledge from EEG studies to fMEG to improve
understanding of prenatal brain development, laying the foundations for better
detection and treatment of potential pathologies. Methods: We developed an
unpaired diffusion translation method based on dual diffusion bridges, which
notably includes numerical integration improvements to obtain more qualitative
results at a lower computational cost. Models were trained on our unpaired
dataset of bursts of spontaneous activity from 30 high-resolution premature
newborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that
our method achieves significant improvement upon previous results obtained with
Generative Adversarial Networks (GANs), by almost 5% on the mean squared error
in the time domain, and completely eliminating the mode collapse problem in the
frequency domain, thus achieving near-perfect signal fidelity. Conclusion: We
set a new state of the art in the EEG-fMEG unpaired translation problem, as our
developed tool completely paves the way for early brain activity analysis.
Overall, we also believe that our method could be reused for other unpaired
signal translation applications.

</details>


### [38] [Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems](https://arxiv.org/abs/2507.14299)
*Yu Bai,Yifan Zhang,Boxuan Xie,Zheng Chang,Yanru Zhang,Riku Jantti,Zhu Han*

Main category: eess.SP

TL;DR: 提出了一种基于信息新鲜度（AoI）的无人机-ISAC系统，通过深度强化学习优化无人机轨迹和波束成形，以同时实现目标感知和多用户通信。


<details>
  <summary>Details</summary>
Motivation: 无人机在无线网络中的灵活性和高效性使其成为未来网络的重要组成部分，但资源限制和时间紧迫条件下联合优化轨迹、通信和感知仍具挑战性。

Method: 采用深度强化学习（DRL）算法，结合卡尔曼滤波和目标状态预测，以及正则化零干扰技术，优化无人机轨迹和波束成形。

Result: 仿真结果表明，所提方法在平均AoI上优于基线方法。

Conclusion: 该框架有效平衡了感知精度和通信质量，为无人机-ISAC系统提供了实时决策支持。

Abstract: Unmanned aerial vehicles (UAVs) equipped with integrated sensing and
communication (ISAC) capabilities are envisioned to play a pivotal role in
future wireless networks due to their enhanced flexibility and efficiency.
However, jointly optimizing UAV trajectory planning, multi-user communication,
and target sensing under stringent resource constraints and time-critical
conditions remains a significant challenge. To address this, we propose an Age
of Information (AoI)-centric UAV-ISAC system that simultaneously performs
target sensing and serves multiple ground users, emphasizing information
freshness as the core performance metric. We formulate a long-term average AoI
minimization problem that jointly optimizes the UAV's flight trajectory and
beamforming. To tackle the high-dimensional, non-convexity of this problem, we
develop a deep reinforcement learning (DRL)-based algorithm capable of
providing real-time decisions on UAV movement and beamforming for both radar
sensing and multi-user communication. Specifically, a Kalman filter is employed
for accurate target state prediction, regularized zero-forcing is utilized to
mitigate inter-user interference, and the Soft Actor-Critic algorithm is
applied for training the DRL agent on continuous actions. The proposed
framework adaptively balances the trade-offs between sensing accuracy and
communication quality. Extensive simulation results demonstrate that our
proposed method consistently achieves lower average AoI compared to baseline
approaches.

</details>


### [39] [Fast and Robust Stationary Crowd Counting with Commodity WiFi](https://arxiv.org/abs/2507.14309)
*Mert Torun,Alireza Parsay,Yasamin Mostofi*

Main category: eess.SP

TL;DR: 提出了一种利用WiFi信号和身体微动行为估计坐姿人群数量的新方法，通过信号带宽的PDF建模和异常检测模块实现高精度计数。


<details>
  <summary>Details</summary>
Motivation: 现有方法对人群数量的估计通常基于二元的微动表示，缺乏细粒度和鲁棒性。本文旨在通过更精细的信号带宽分析提升准确性。

Method: 利用公开视频提取个体微动特征，通过Carson's Rule转换为带宽，建立信号带宽PDF与人群数量的数学模型，并引入异常检测模块过滤无关运动。

Result: 在42次实验中，平均绝对误差为1.04，归一化均方误差为0.15，收敛时间51秒，优于现有技术。仿真显示可扩展至更大规模人群。

Conclusion: 该方法实现了快速、鲁棒且高精度的坐姿人群计数，显著优于现有技术。

Abstract: This paper introduces a novel method for estimating the size of seated crowds
with commodity WiFi signals, by leveraging natural body fidgeting behaviors as
a passive sensing cue. Departing from prior binary fidget representations, our
approach leverages the bandwidth of the received signal as a finer-grained and
robust indicator of crowd counts. More specifically, we propose a mathematical
model that relates the probability density function (PDF) of the signal
bandwidth to the crowd size, using a principled derivation based on the PDF of
an individual's fidget-induced bandwidth. To characterize the individual
fidgeting PDF, we use publicly available online videos, each of a seated
individual, from which we extract body motion profiles using vision techniques,
followed by a speed-to-bandwidth conversion inspired by Carson's Rule from
analog FM radio design. Finally, to enhance robustness in real-world
deployments where unrelated motions may occur nearby, we further introduce an
anomaly detection module that filters out non-fidget movements. We validate our
system through 42 experiments across two indoor environments with crowd sizes
up to and including 13 people, achieving a mean absolute error of 1.04 and a
normalized mean square error of 0.15, with an average convergence time of 51
seconds, significantly reducing the convergence time as compared to the state
of the art. Additional simulation results demonstrate scalability to larger
crowd sizes. Overall, our results show that our pipeline enables fast, robust,
and highly accurate counting of seated crowds.

</details>


### [40] [Optimizing Network Performance and Resource Allocation in HAPS-UAV Integrated Sensing and Communication Systems for 6G](https://arxiv.org/abs/2507.14310)
*Parisa Kanani,Mohammad Javad Omidi,Mahmoud Modarres-Hashemi,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 本文提出了一种利用无人机（UAV）作为基站（BS）和高空平台站（HAPS）作为中央处理单元（CPU）的6G网络集成感知与通信（ISAC）系统，优化位置和功率控制以提升无线覆盖和性能。


<details>
  <summary>Details</summary>
Motivation: 探索ISAC系统在6G网络中的挑战、应用和优势，特别是在偏远地区增强无线覆盖的需求。

Method: 通过HAPS和UAV的集成，UAV作为双用途接入点（AP），分两个时隙操作：传输通信和感知信号，接收反射信号并中继至HAPS进行波束成形。

Result: 仿真结果表明，该方法在网络性能、资源分配、公平性和系统优化方面表现优异，同时通过HAPS卸载计算任务节省UAV能量。

Conclusion: 该方案有效提升了6G网络的ISAC性能，为未来网络优化提供了新思路。

Abstract: This paper proposes an innovative approach by leveraging uncrewed aerial
vehicles (UAVs) as base stations (BSs) and a high-altitude platform station
(HAPS) as the central processing unit (CPU) in an integrated sensing and
communication (ISAC) system for 6G networks. We explore the challenges,
applications, and advantages of ISAC systems in next-generation networks,
highlighting the significance of optimizing position and power control. Our
approach integrates HAPS and UAVs to enhance wireless coverage, particularly in
remote areas. UAVs function as dual-purpose access points (APs), using their
maneuverability and line-of-sight (LoS) aerial-to-ground (A2G) links to
transmit combined communication and sensing signals. The scheme operates in two
time slots: in the first slot, UAVs transmit dedicated signals to communication
users (CUs) and potential targets. UAVs detect targets in specific ground
locations and, after signal transmission, receive reflected signals from
targets. In the second slot, UAVs relay these signals to HAPS, which performs
beamforming to align signals for each CU from various UAVs. UAVs decode
information from HAPS and adjust transmissions to maximize the beam pattern
efficiency toward the desired targets. We formulate a multi-objective
optimization problem to maximize both the minimum
signal-to-interference-plus-noise ratio (SINR) for CUs and the echo signal
power from the targets. This is achieved by finding the optimal power
allocation for CUs in each UAV, subject to constraints on the maximum total
power in each UAV and the transmitted beam pattern gain. Simulation results
demonstrate the effectiveness of this approach in enhancing network
performance, resource allocation, fairness, and system optimization. Using HAPS
as the CPU, computational tasks are offloaded from UAVs, which conserves energy
and improves network performance.

</details>


### [41] [Spatially tailored spin wave excitation for spurious-free, low-loss magnetostatic wave filters with ultra-wide frequency tunability](https://arxiv.org/abs/2507.14469)
*Shuxian Wu,Shun Yao,Xingyu Du,Chin-Yu Chang,Roy H. Olsson III*

Main category: eess.SP

TL;DR: 提出了一种半锥形换能器，用于优化钇铁石榴石磁静波射频腔滤波器，显著抑制杂散模式，提升6G通信系统的性能。


<details>
  <summary>Details</summary>
Motivation: 钇铁石榴石磁静波射频腔滤波器在6G通信系统中具有潜力，但杂散模式严重影响了其性能。

Method: 采用半锥形换能器空间定制自旋波激发，选择性增强主腔模式并抑制杂散模式。

Result: 实验验证了单腔和双腔半锥形磁静波滤波器，分别实现了6.3-16.8 GHz和9.8-31.5 GHz的无杂散调谐范围，插入损耗低至2.4-3.8 dB。

Conclusion: 该技术显著提升了滤波器的性能，为6G网络提供了高度可重构和稳健的解决方案。

Abstract: Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity
filters are promising for sixth-generation (6G) communication systems due to
their wide frequency tunability. However, the presence of severe spurious modes
arising from the finite cavity dimensions severely degrades the filter
performance. We present a half-cone transducer that spatially tailors spin wave
excitation to selectively enhance the primary cavity modes comprising the MSW
filter passband, while strongly suppressing the undesired spurious modes.
Theoretical analysis, numerical simulations and experiments verify the
effectiveness of the spatially tailored technique. We utilize the half-cone
transducer to demonstrate a spurious-free, single-cavity half-cone MSW filter
(HC-MSWF) with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning
range of 6.3-16.8 GHz. Extending our study, we further demonstrate a
spurious-free, dual-cavity HC-MSWF with an unprecedented tuning range of 21.7
GHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB. This significant
advance in performance will enable highly reconfigurable and robust 6G
networks.

</details>


### [42] [Propagation Channel Modeling for LEO Satellite Missions Using Ray-Tracing Simulations](https://arxiv.org/abs/2507.14622)
*Wahab Khawaja,Ismail Guvenc,Rune Hylsberg Jacobsen*

Main category: eess.SP

TL;DR: 本文提出了一种基于射线追踪的高分辨率LEO卫星到地面X波段信道模型，结合了大尺度和小尺度衰落效应，并首次整合了射线追踪环境动态、仰角依赖衰落和相控阵波束失准效应。


<details>
  <summary>Details</summary>
Motivation: 研究LEO卫星到地面X波段通信在郊区环境中的信道特性，填补现有模型在仰角依赖性和环境动态性方面的不足。

Method: 使用Wireless InSite进行仿真，开发参数化信道模型，结合3GPP NTN模型比较大尺度衰落，并量化地面站天线失准对小尺度衰落的影响。

Result: 提出了首个综合仰角感知的信道模型，量化了环境动态和天线失准对链路性能的影响。

Conclusion: 该模型为LEO卫星通信系统设计提供了更精确的信道特性分析工具。

Abstract: This work presents a high-resolution, ray-tracing-based channel modeling for
Low Earth Orbit (LEO) satellite-to-ground links in a suburban environment at
X-band. Using simulations conducted in Wireless InSite, we develop a parametric
channel model that characterizes both large- and small-scale fading effects
across different satellite elevation angles. Large-scale fading incorporates
attenuation due to terrain-induced shadowing and dynamic environmental factors
such as weather conditions, and is compared with 3GPP NTN channel model.
Additionally, we quantify link degradation resulting from ground station (GS)
antenna misalignment, considering both fixed single-element and electronically
steerable phased-array antennas. Small-scale fading is modeled by fitting a
shadowed and non-shadowed Rician distribution to the fading statistics at
various satellite elevations. To the best of our knowledge, this is the first
study to propose a comprehensive elevation-aware channel model for
satellite-to-ground propagation at X-band, integrating ray-traced environmental
dynamics, elevation-dependent fading, and phased-array beam misalignment
effects.

</details>


### [43] [Movable-Element STARS-Aided Secure Communications](https://arxiv.org/abs/2507.14804)
*Jingjing Zhao,Qian Xu,Kaiquan Cai,Yanbo Zhu,Xidong Mu,Yuanwei Liu*

Main category: eess.SP

TL;DR: 论文提出了一种基于可移动元件（ME）的同时传输和反射表面（ME-STARS）的安全通信系统，通过优化被动波束成形、ME位置和主动波束成形来提升物理层安全性。


<details>
  <summary>Details</summary>
Motivation: 针对全空间窃听问题，利用ME-STARS提供更高的空间自由度以增强通信安全性。

Method: 采用交替优化算法，将问题分解为三个子问题：ME位置优化（使用梯度上升法）、主动和被动波束成形优化（使用逐次凸逼近）。

Result: ME-STARS显著提升了保密性能，且在有限移动区域内保密率趋于饱和。

Conclusion: ME-STARS在提升通信安全性方面具有显著优势，但其性能受限于ME的移动范围。

Abstract: A novel movable-element (ME) enabled simultaneously transmitting and
reflecting surface (ME-STARS)-aided secure communication system is
investigated. Against the full-space eavesdropping, MEs are deployed at the
STARS for enhancing the physical layer security by exploiting higher spatial
degrees of freedom. Specifically, a sum secrecy rate maximization problem is
formulated, which jointly optimizes the passive beamforming and the MEs
positions at the ME-STARS, as well as the active beamforming at the base
station. To solve the resultant non-convex optimization problem involving
highly-coupled variables, an alternating optimization-based iterative algorithm
is developed, decomposing the original problem into three subproblems. In
particular, for the MEs position optimization subproblem, a gradient ascent
algorithm is employed to iteratively refine the MEs' locations within the
confined region. Moreover, the the active and passive beamforming subproblems
are solved by employing successive convex approximation. Numerical results
unveil that: 1) ME-STARS significantly improves the secrecy performance
compared to the conventional STARS with fixed-position elements; and 2) The
secrecy rate achieved by the ME-STARS gets saturated within limited movable
region size.

</details>


### [44] [Integrated Radio Sensing Capabilities for 6G Networks: AI/ML Perspective](https://arxiv.org/abs/2507.14856)
*Victor Shatov,Steffen Schieler,Charlotte Muth,José Miguel Mateos-Ramos,Ivo Bizon,Florian Euchner,Sebastian Semper,Stephan ten Brink,Gerhard Fettweis,Christian Häger,Henk Wymeersch,Laurent Schmalen,Reiner Thomä,Norman Franchi*

Main category: eess.SP

TL;DR: 本文是一篇关于6G无线通信中AI和ML增强无线传感能力的教程式综述，涵盖雷达、频谱感知及非合作发射器定位等多种应用。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过AI和ML提升6G网络的感知能力，以实现环境感知和资源优化。

Method: 在集成感知与通信（ISAC）框架下，扩展无线传感的定义，并详细阐述AI技术在无线传感中的应用。

Result: 总结了AI技术在无线传感中的优势、推动因素及挑战，并展望了AI驱动的多模态多任务网络。

Conclusion: 本文为6G研究领域的新手提供了入门指南，并为无线通信背景的读者提供了全面的技术概述。

Abstract: The sixth-generation wireless communications (6G) is often labeled as
"connected intelligence". Radio sensing, aligned with machine learning (ML) and
artificial intelligence (AI), promises, among other benefits, breakthroughs in
the system's ability to perceive the environment and effectively utilize this
awareness. This article offers a tutorial-style survey of AI and ML approaches
to enhance the sensing capabilities of next-generation wireless networks. To
this end, while staying in the framework of integrated sensing and
communication (ISAC), we expand the term "sensing" from radar, via spectrum
sensing, to miscellaneous applications of radio sensing like non-cooperative
transmitter localization. We formulate the problems, explain the
state-of-the-art approaches, and detail AI-based techniques to tackle various
objectives in the context of wireless sensing. We discuss the advantages,
enablers, and challenges of integrating various sensing capabilities into an
envisioned AI-powered multimodal multi-task network. In addition to the
tutorial-style core of this work based on direct authors' involvement in 6G
research problems, we review the related literature, and provide both a good
start for those entering this field of research, and a topical overview for a
general reader with a background in wireless communications

</details>


### [45] [Stabilization of the bias point in MZM modulators](https://arxiv.org/abs/2507.14888)
*Zhuo Wang*

Main category: eess.SP

TL;DR: 本文介绍了MZM在通信系统中的作用、材料（如铌酸锂）、工作原理及环境因素对其的影响，提出了一种通过算法控制电压稳定MZM的方法，并通过实验验证，最后总结了MZM的未来发展。


<details>
  <summary>Details</summary>
Motivation: 研究MZM在通信系统中的实际应用及其稳定性问题，探索通过算法控制电压以提高其性能的方法。

Method: 提出一种算法控制电压的方法，以稳定MZM的工作点，并通过实验验证其有效性。

Result: 实验验证了算法控制电压方法的有效性，能够稳定MZM的工作点。

Conclusion: MZM在通信系统中具有重要应用，通过算法控制电压可提高其稳定性，未来仍有发展潜力。

Abstract: This article mainly introduces the role of MZM in practical communication
systems, the materials used to make MZM modulators such as lithium niobate, and
its working principle. It also explains why it changes due to environmental
factors. This leads to the introduction of a method that controls the stable
points of MZM by algorithmically controlling the voltage, and the algorithm is
verified through experiments. Finally, a summary and outlook on the future
development of MZM are provided.

</details>


### [46] [Phase-optimised linearly-constrained minimum-variance beamformers](https://arxiv.org/abs/2507.14937)
*Hugh L Kennedy*

Main category: eess.SP

TL;DR: 提出了一种确定LCMV波束形成器最优群延迟的新方法，包括最小化噪声功率和最小化处理延迟两种选择。


<details>
  <summary>Details</summary>
Motivation: 探索LCMV波束形成器中群延迟这一未被充分利用的设计自由度，以优化性能。

Method: 通过模拟VHF通信和UHF双基地雷达应用，验证了两种最优延迟选择方法。

Result: 证明了两种方法在噪声功率和处理延迟优化上的有效性。

Conclusion: 新方法为LCMV波束形成器的设计提供了灵活性，适用于多种应用场景。

Abstract: A novel procedure for the determination of the optimal group-delay for a
Linearly-Constrained Minimum-Variance (LCMV) beamformer is proposed. Two ways
of selecting the optimal delay are recommended: the first is the solution that
minimizes the noise power; the second is the solution that minimizes the
processing delay. The potential of this hitherto unexplored degree of design
freedom is explored using simulated Very-High-Frequency (VHF) communication,
and Ultra-High-Frequency (UHF) bistatic radar, applications.

</details>


### [47] [Jamming-Resistant AAV Communications: A Multichannel-Aided Approach](https://arxiv.org/abs/2507.14945)
*Bin Wang,Jun Fang,Jieru Du,Shihai Shao*

Main category: eess.SP

TL;DR: 提出了一种多通道辅助的干扰消除方法，用于无人自主车辆（AAV）的安全通信，无需信道状态信息，仅利用合法发送方的导频序列即可实现同步和干扰消除。


<details>
  <summary>Details</summary>
Motivation: 在恶意干扰存在的情况下，确保AAV通信的可靠性至关重要。

Method: 开发了一种多通道辅助的干扰消除方法，利用合法发送方的导频序列实现同步和干扰消除，无需信道状态信息。

Result: 实验结果表明，该方法在干扰信号比通信信号强40dB时仍能成功解码目标信号。

Conclusion: 该方法为AAV通信提供了一种实用的干扰消除解决方案，适用于现有通信协议。

Abstract: Jamming cancellation is essential to reliable unmanned autonomous vehicle
(AAV) communications in the presence of malicious jammers. In this paper, we
develop a practical multichannel-aided jamming cancellation method to realize
secure AAV communications. The proposed method is capable of simultaneously
achieving timing/frequency synchronization as well as jamming cancellation.
More importantly, our method does not need the signal's/jammer's channel state
information. It only utilizes the knowledge of the legitimate sender's preamble
sequence that is available in existing communication protocols. We also analyze
the length of the preamble sequence required for successful synchronization and
signal recovery. Experimental results on the built hardware platform show that,
with a two-antenna receiver, the proposed method can successfully decode the
signal of interest even when the jamming signal is $40$dB stronger than the
communication signal.

</details>


### [48] [Latent-attention Based Transformer for Near ML Polar Decoding in Short-code Regime](https://arxiv.org/abs/2507.14951)
*Hongzhi Zhu,Wei Xu,Xiaohu You*

Main category: eess.SP

TL;DR: 提出了一种基于潜在注意力的Transformer解码器（LAT），通过创新机制和训练框架，显著提升了短码极化码的解码性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的纠错码解码器在短码场景下性能与泛化能力不足，需改进以匹敌传统代数解码器。

Method: 1. 潜在注意力机制替代自注意力；2. 包含熵感知采样、经验回流和动态标签平滑的训练框架；3. 动态适应不同码配置的掩码方案。

Result: LAT解码器在短码极化码上实现了接近最大似然（ML）的性能（BER和BLER），并展现出跨码率和码长的强泛化能力。

Conclusion: LAT解码器通过创新设计和训练方法，显著提升了短码场景下的解码性能与泛化能力。

Abstract: Transformer architectures have emerged as promising deep learning (DL) tools
for modeling complex sequence-to-sequence interactions in channel decoding.
However, current transformer-based decoders for error correction codes (ECCs)
demonstrate inferior performance and generalization capabilities compared to
conventional algebraic decoders, especially in short-code regimes. In this
work, we propose a novel latent-attention based transformer (LAT) decoder for
polar codes that addresses the limitations on performance and generalization
through three pivotal innovations. First, we develop a latent-attention
mechanism that supersedes the conventional self-attention mechanism. This
architectural modification enables independent learning of the Query and Key
matrices for code-aware attention computation, decoupling them from the Value
matrix to emphasize position-wise decoding interactions while reducing context
correlation interference. Second, we devise an advanced training framework
incorporating three synergistic components: entropy-aware importance sampling
that emphasizes low-probability regions in the signal constellation space,
experience reflow that introduces empirical labels to improve characterization
of decoding boundaries, and dynamic label smoothing for likelihood-based
regularization. Third, we propose a code-aware mask scheme which allows dynamic
adaptation for varying code configurations. Numerical evaluations demonstrate
that the proposed LAT decoder achieves near maximum-likelihood (ML) performance
in terms of both bit error rate (BER) and block error rate (BLER) for
short-length polar codes. Furthermore, the architecture exhibits robust
generalization capabilities across diverse code rates and code lengths.

</details>


### [49] [How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?](https://arxiv.org/abs/2507.14982)
*Kareem M. Attiah,Wei Yu*

Main category: eess.SP

TL;DR: 论文研究了在ISAC系统中，同时优化通信和感知性能所需的最小波束成形器数量，给出了不同条件下的理论界限。


<details>
  <summary>Details</summary>
Motivation: 探索在集成感知与通信（ISAC）系统中，如何通过最小数量的波束成形器实现最优的通信和感知性能。

Method: 通过理论分析，建立基于Cramér-Rao界和信号干扰噪声比的性能指标，推导波束成形器数量的上下界。

Result: 在干扰可消除时，最多需要K + √(L(L+1)/2)个波束成形器；不可消除时为√(K² + L(L+1)/2)。对于复杂路径损失和角度估计，数量随K和N_tr线性增长。

Conclusion: ISAC系统的最小波束成形器数量取决于干扰消除能力和任务需求，理论界限为实际系统设计提供了指导。

Abstract: Consider a downlink integrated sensing and communications (ISAC) system in
which a base station employs linear beamforming to communicate to $K$ users,
while simultaneously uses sensing beams to perform a sensing task of estimating
$L$ real parameters. How many beamformers are needed to achieve the best
performance for both sensing and communications? This paper establishes bounds
on the minimum number of downlink beamformers, in which sensing performance is
measured in terms of the Cram\'{e}r-Rao bound for parameter estimation and
communications performance is measured in terms of the
signal-to-interference-and-noise ratios. We show that an ISAC system requires
at most $K + \sqrt{\frac{L(L+1)}{2}}$ beamformers if the remote users have the
ability to cancel the interference caused by the sensing beams. If cancelling
interference due to the sensing beams is not possible, the bound becomes
$\sqrt{K^2 + \frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound
on the number of beamformers is less than the sum of the bounds for each task
individually. These results can be extended to sensing tasks for which the
performance is measured as a function of $d$ quadratic terms in the
beamformers. In this case, the bound becomes $K + \sqrt{d}$ and $\sqrt{K^2 +
d}$, respectively. Specifically, for estimating complex path losses and
angles-of-arrival of $N_\text{tr}$ targets while communicating to $K$ users,
the bound on the minimum number of beamformers scales linearly in $K$ and in
$N_\text{tr}$, assuming interference from sensing can be cancelled. When
interference cancellation is not possible, the following exact characterization
for the case of $N_\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two
beamformers should be used; when $K \ge 2$, exactly $K$ beamformers should be
used, i.e., communication beamformers alone are already sufficient.

</details>


### [50] [Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings](https://arxiv.org/abs/2507.15118)
*Szymon Mazurek,Stephen Moore,Alessandro Crimi*

Main category: eess.SP

TL;DR: 提出基于图注意力网络（GAT）的深度学习框架，用于低成本EEG硬件检测癫痫，并在尼日利亚和几内亚比绍的测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 低收入国家癫痫诊断不足，缺乏神经科医生和昂贵设备，需公平、可解释的自动诊断工具。

Method: 将EEG信号建模为时空图，利用GAT分类并分析通道间关系；改进GAT以关注边特征；设计轻量级架构适配低成本硬件。

Result: 分类性能优于随机森林和图卷积网络，识别了额颞区特定连接。

Conclusion: GAT为欠发达地区提供可扩展、经济的癫痫诊断支持。

Abstract: Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce
neurologists and costly diagnostic tools. We propose a graph-based deep
learning framework to detect epilepsy from low-cost Electroencephalography
(EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus
is on fair, accessible automatic assessment and explainability to shed light on
epilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs,
classify them, and identify interchannel relationships and temporal dynamics
using graph attention networks (GAT). To emphasize connectivity biomarkers, we
adapt the inherently node-focused GAT to analyze edges. We also designed signal
preprocessing for low-fidelity recordings and a lightweight GAT architecture
trained on Google Colab and deployed on RaspberryPi devices. Results: The
approach achieves promising classification performance, outperforming a
standard classifier based on random forest and graph convolutional networks in
terms of accuracy and robustness over multiple sessions, but also highlighting
specific connections in the fronto-temporal region. Conclusions: The results
highlight the potential of GATs to provide insightful and scalable diagnostic
support for epilepsy in underserved regions, paving the way for affordable and
accessible neurodiagnostic tools.

</details>


### [51] [MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations](https://arxiv.org/abs/2507.15255)
*Deyun Zhang,Xiang Lan,Shijia Geng,Qinghao Zhao,Sumei Fan,Mengling Feng,Shenda Hong*

Main category: eess.SP

TL;DR: MEETI是一个新型的多模态ECG数据集，整合了原始波形、图像和文本解释，为开发可解释的心血管AI系统提供了基础。


<details>
  <summary>Details</summary>
Motivation: 现有ECG数据集多为单模态或双模态，限制了多模态AI系统的开发。MEETI填补了这一空白。

Method: MEETI数据集同步了原始ECG波形、高分辨率图像、详细文本解释和提取的特征参数。

Result: MEETI为多模态学习和细粒度分析提供了统一结构，支持可解释的心血管AI开发。

Conclusion: MEETI为下一代可解释的多模态心血管AI奠定了基础，是研究和评估ECG AI系统的全面基准。

Abstract: Electrocardiogram (ECG) plays a foundational role in modern cardiovascular
care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and
conduction disorders. While machine learning has achieved expert-level
performance in ECG interpretation, the development of clinically deployable
multimodal AI systems remains constrained, primarily due to the lack of
publicly available datasets that simultaneously incorporate raw signals,
diagnostic images, and interpretation text. Most existing ECG datasets provide
only single-modality data or, at most, dual modalities, making it difficult to
build models that can understand and integrate diverse ECG information in
real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext
ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw
waveform data, high-resolution plotted images, and detailed textual
interpretations generated by large language models. In addition, MEETI includes
beat-level quantitative ECG parameters extracted from each lead, offering
structured parameters that support fine-grained analysis and model
interpretability. Each MEETI record is aligned across four components: (1) the
raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature
parameters, and (4) detailed interpretation text. This alignment is achieved
using consistent, unique identifiers. This unified structure supports
transformer-based multimodal learning and supports fine-grained, interpretable
reasoning about cardiac health. By bridging the gap between traditional signal
analysis, image-based interpretation, and language-driven understanding, MEETI
established a robust foundation for the next generation of explainable,
multimodal cardiovascular AI. It offers the research community a comprehensive
benchmark for developing and evaluating ECG-based AI systems.

</details>


### [52] [Optimal Transceiver Design in Over-the-Air Federated Distillation](https://arxiv.org/abs/2507.15256)
*Zihao Hu,Jia Yan,Ying-Jun Angela Zhang,Jun Zhang,Khaled B. Letaief*

Main category: eess.SP

TL;DR: 提出了一种新型的空中联合蒸馏（FD）框架，结合联合学习（FL）和知识蒸馏，减少通信开销，优化收发器设计以提高学习收敛速度。


<details>
  <summary>Details</summary>
Motivation: 大型AI模型的出现使现有FL方法因通信开销大而效率低下，需减少模型参数传输。

Method: 通过共享模型输出（知识）而非参数，利用多址信道的叠加特性进行空中聚合，优化收发器设计和功率分配。

Result: 推导了空中FD的收敛率表达式，获得最优功率和估计器解，并通过半定松弛找到最优接收波束成形向量。

Conclusion: 所提方法显著减少通信开销，测试精度损失小，优于传统FL基准。

Abstract: The rapid proliferation and growth of artificial intelligence (AI) has led to
the development of federated learning (FL). FL allows wireless devices (WDs) to
cooperatively learn by sharing only local model parameters, without needing to
share the entire dataset. However, the emergence of large AI models has made
existing FL approaches inefficient, due to the significant communication
overhead required. In this paper, we propose a novel over-the-air federated
distillation (FD) framework by synergizing the strength of FL and knowledge
distillation to avoid the heavy local model transmission. Instead of sharing
the model parameters, only the WDs' model outputs, referred to as knowledge,
are shared and aggregated over-the-air by exploiting the superposition property
of the multiple-access channel. We shall study the transceiver design in
over-the-air FD, aiming to maximize the learning convergence rate while meeting
the power constraints of the transceivers. The main challenge lies in the
intractability of the learning performance analysis, as well as the non-convex
nature and the optimization spanning the whole FD training period. To tackle
this problem, we first derive an analytical expression of the convergence rate
in over-the-air FD. Then, the closed-form optimal solutions of the WDs'
transmit power and the estimator for over-the-air aggregation are obtained
given the receiver combining strategy. Accordingly, we put forth an efficient
approach to find the optimal receiver beamforming vector via semidefinite
relaxation. We further prove that there is no optimality gap between the
original and relaxed problem for the receiver beamforming design. Numerical
results will show that the proposed over-the-air FD approach achieves a
significant reduction in communication overhead, with only a minor compromise
in testing accuracy compared to conventional FL benchmarks.

</details>


### [53] [A Novel Domain-Aware CNN Architecture for Faster-than-Nyquist Signaling Detection](https://arxiv.org/abs/2507.15291)
*Osman Tokluoglu,Enver Cavus,Ebrahim Bedeer,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 提出一种基于固定核卷积神经网络（CNN）的检测器，用于更快-than-Nyquist（FTN）信号，通过结构化固定核层和领域知识掩码减少符号间干扰（ISI）。


<details>
  <summary>Details</summary>
Motivation: 传统滑动核CNN难以直接捕捉FTN信号中的ISI效应，需设计更高效的方法。

Method: 采用固定位置核直接捕获不同距离的ISI效应，并引入分层滤波器分配策略。

Result: 在τ≥0.7时接近最优BER性能，计算效率比M-BCJR提升46%（BPSK）和84%（QPSK）。

Conclusion: 固定核CNN架构首次应用于FTN检测，显著提升效率和准确性。

Abstract: This paper proposes a convolutional neural network (CNN)-based detector for
faster-than-Nyquist (FTN) signaling that employs structured fixed kernel layers
with domain-informed masking to mitigate intersymbol interference (ISI). Unlike
standard CNNs with sliding kernels, the proposed method utilizes fixed-position
kernels to directly capture ISI effects at varying distances from the central
symbol. A hierarchical filter allocation strategy is also introduced, assigning
more filters to earlier layers for strong ISI patterns and fewer to later
layers for weaker ones. This design improves detection accuracy while reducing
redundant operations. Simulation results show that the detector achieves
near-optimal bit error rate (BER) performance for $\tau \geq 0.7$, closely
matching the BCJR algorithm, and offers computational gains of up to $46\%$ and
$84\%$ over M-BCJR for BPSK and QPSK, respectively. Comparative analysis with
other methods further highlights the efficiency and effectiveness of the
proposed approach. To the best of our knowledge, this is the first application
of a fixed-kernel CNN architecture tailored for FTN detection in the
literature.

</details>


### [54] [BEAM-Net: A Deep Learning Framework with Bone Enhancement Attention Mechanism for High Resolution High Frame Rate Ultrasound Beamforming](https://arxiv.org/abs/2507.15306)
*Midhila Madhusoodanan,Mahesh Raveendranatha Panicker,Pisharody Harikrishnan Gopalakrishnan,Abhilash Rakkunedeth Hareendranathan*

Main category: eess.SP

TL;DR: 提出了一种名为BEAM-Net的深度学习网络，用于超声成像中的骨骼增强，显著提升了图像质量和结构保真度。


<details>
  <summary>Details</summary>
Motivation: 解决传统超声成像在骨骼应用中因噪声、低分辨率和各向异性反射导致的图像质量差的问题。

Method: 使用端到端深度神经网络（BEAM-Net），结合骨骼概率图（BPM）作为注意力机制，从单平面波射频数据中生成高质量的骨骼图像。

Result: BEAM-Net在对比度比（CR）、信噪比（SNR）等指标上显著优于传统方法，提升了图像质量。

Conclusion: BEAM-Net是一种创新的方法，将骨骼增强直接集成到超声波束形成中，为骨骼超声成像提供了更优的解决方案。

Abstract: Pocket-sized, low-cost point-of-care ultrasound (POCUS) devices are
increasingly used in musculoskeletal (MSK) applications for structural
examination of bone tissue. However, the image quality in MSK ultrasound is
often limited by speckle noise, low resolution, poor contrast, and anisotropic
reflections, making bone images difficult to interpret without additional
post-processing. Typically, medical ultrasound systems use delay and sum
beamforming (DASB) for image reconstruction, which is not specifically
optimized for bone structures. To address these limitations, we propose
BEAM-Net, a novel end-to-end deep neural network (DNN) that performs
high-frame-rate ultrasound beamforming with integrated bone enhancement, using
single-plane-wave (SPW) radio frequency (RF) data as input. Our approach embeds
a Bone Probability Map (BPM), which acts as an attention mechanism to enforce
higher structural similarity around bony regions in the image. The proposed
approach is the first of its kind to incorporate bone enhancement directly into
ultrasound beamforming using deep learning. BEAM-Net was trained and evaluated
on in-vivo MSK and synthetic RF ultrasound datasets. This paper introduces the
Edge Preservation Index (EPI) as a new region-focused metric for evaluating
structural fidelity in bone-enhanced ultrasound images. The performance of
BEAM-Net was compared with conventional DASB and existing deep learning
architectures using the EPI, Contrast Ratio (CR), Signal-to-Noise ratio (SNR),
Speckle Similarity Index (SSI), and Structural Similarity Index (SSIM).
BEAM-Net showed substantial gains over SPW-DASB, achieving 51.4-51% higher CR
and 94.2-73.3% higher SNR on in-vivo MSK and synthetic RF datasets. It
outperformed multiple steered plane wave DASB (MPW-DASB), with 19.8-24.0%
improvements in CR and SNR on in-vivo MSK and 2.5-12.8% improvements on
synthetic data.

</details>


### [55] [EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network](https://arxiv.org/abs/2507.15364)
*Ruifeng Zheng,Cong Chen,Shuang Wang,Yiming Liu,Lin You,Jindong Lu,Ruizhe Zhu,Guodao Zhang,Kejie Huang*

Main category: eess.SP

TL;DR: 提出了一种新型的两阶段通道感知Set Transformer网络，用于减少EEG通道传感器的数量，同时提高癫痫发作预测的敏感性和准确性。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作对患者生活质量有重大影响，现有可穿戴预测设备因EEG设备体积大而受限。

Method: 采用两阶段通道感知Set Transformer网络和癫痫无关的数据划分方法，以减少EEG通道数量并避免训练与测试数据相邻。

Result: 在CHB-MIT数据集上，通道选择后平均通道数从18降至2.8，敏感性从76.4%提升至80.1%，假阳性率为0.11/小时。

Conclusion: 癫痫无关的数据划分方法对EEG记录丰富的患者更为适用，且通道选择能显著提升预测性能。

Abstract: Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure
onsets can significantly impact patients' quality of life and health. However,
wearable seizure-predicting devices are still limited, partly due to the bulky
size of EEG-collecting devices. To relieve the problem, we proposed a novel
two-stage channel-aware Set Transformer Network that could perform seizure
prediction with fewer EEG channel sensors. We also tested a seizure-independent
division method which could prevent the adjacency of training and test data.
Experiments were performed on the CHB-MIT dataset which includes 22 patients
with 88 merged seizures. The mean sensitivity before channel selection was
76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection,
dominant channels emerged in 20 out of 22 patients; the average number of
channels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1%
with an FPR of 0.11/hour. Furthermore, experimental results on the
seizure-independent division supported our assertion that a more rigorous
seizure-independent division should be used for patients with abundant EEG
recordings.

</details>


### [56] [Robust ISAC Transceiver Beamforming Design under Low-Resolution AD/DA Converters](https://arxiv.org/abs/2507.15373)
*Tiantian Xu,Zhenyao He,Jindan Xu,Wei Xu,Jianfeng Wang,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 研究了低分辨率DACs和ADCs的ISAC系统中鲁棒波束成形设计，通过优化雷达SQNR并保证通信用户SQINR，提出SDR和MM算法解决非凸问题。


<details>
  <summary>Details</summary>
Motivation: 解决低分辨率量化噪声下ISAC系统的性能优化问题。

Method: 使用SDR技术获取全局最优解，开发基于MM的低复杂度算法处理混合DACs和扩展目标场景。

Result: 仿真验证了算法在低分辨率量化下的鲁棒性和有效性。

Conclusion: 提出的算法在低分辨率量化场景中表现出优越性能。

Abstract: In this letter, we investigate the robust beamforming design for an
integrated sensing and communication (ISAC) system featuring low-resolution
digital-to-analog converters (DACs) and analog-to-digital converters (ADCs).
Taking into account quantization noise, we aim at maximizing the radar
signal-to-quantization-plus-noise ratio (SQNR) while guaranteeing the minimum
required signal-to-quantization-plus-interference-plus-noise ratio (SQINR) for
communication users. To address this nonconvex design problem, we first examine
a scenario involving a point target and uniform-resolution DACs, where the
globally optimal solution is obtained by applying the semidefinite relaxation
(SDR) technique. For more general scenarios, including those with mixed-DACs
and/or an extended target, we develop a low-complexity
majorization-minimization (MM)-based algorithm to tackle the problem
iteratively. Compared to the non-robust algorithm, the proposed algorithm
demonstrates improved detection performance under practical quantization.
Simulation results confirm the robustness and efficacy of our proposed
algorithm in low-resolution quantization scenarios.

</details>


### [57] [On the Distribution of a Two-Dimensional Random Walk with Restricted Angles](https://arxiv.org/abs/2507.15475)
*Karl-Ludwig Besser*

Main category: eess.SP

TL;DR: 本文研究了二维（复数）随机游走的分布，其中每一步的角度限制在圆的一个子集内，推导了精确的联合和边缘分布，并提供了数值解和近似解。


<details>
  <summary>Details</summary>
Motivation: 研究这种随机游走的分布是为了解决信号处理等领域中的实际问题，如空中计算。

Method: 推导了两步的精确分布，提供了多步的数值解和大步数的近似解，并精确描述了任意步数的支持集。

Result: 得到了精确的联合和边缘分布、数值解和近似解，并精确描述了支持集。

Conclusion: 结果为未来涉及此类问题的研究提供了参考。

Abstract: In this paper, we derive the distribution of a two-dimensional (complex)
random walk in which the angle of each step is restricted to a subset of the
circle. This setting appears in various domains, such as in over-the-air
computation in signal processing. In particular, we derive the exact joint and
marginal distributions for two steps, numerical solutions for a general number
of steps, and approximations for a large number of steps. Furthermore, we
provide an exact characterization of the support for an arbitrary number of
steps. The results in this work provide a reference for future work involving
such problems.

</details>


### [58] [Sum-Rate Maximization for Movable-Antenna Array Enhanced Downlink NOMA Systems](https://arxiv.org/abs/2507.15555)
*Nianzu Li,Peiran Wu,Lipeng Zhu,Weidong Mei,Boyu Ning,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 论文研究了可移动天线（MA）系统在非正交多址（NOMA）下行链路中的资源分配问题，通过联合优化波束成形、天线位置、SIC解码顺序和解码指示矩阵，显著提升了系统总速率。


<details>
  <summary>Details</summary>
Motivation: 可移动天线系统因其能主动重构无线信道的潜力而备受关注，本研究旨在利用MA的灵活性提升NOMA系统的性能。

Method: 提出了一种两阶段优化算法：第一阶段通过信道增益最大化确定SIC解码顺序；第二阶段利用交替优化、SCA和GA迭代优化波束成形、MA位置和解码指示矩阵。

Result: 仿真结果表明，MA-NOMA系统的总速率显著优于传统固定天线系统，且天线位置优化进一步增强了NOMA相对于SDMA的优势。

Conclusion: MA系统通过灵活优化天线位置和资源分配，为NOMA系统提供了显著的性能提升，验证了其在实际应用中的潜力。

Abstract: Movable antenna (MA) systems have recently attracted significant attention in
the field of wireless communications owing to their exceptional capability to
proactively reconfigure wireless channels via flexible antenna movements. In
this paper, we investigate the resource allocation design for an MA
array-enhanced downlink non-orthogonal multiple access (NOMA) system, where a
base station deploys multiple MAs to serve multiple single-antenna users. Our
goal is to maximize the sum rate of all users by jointly optimizing the
transmit beamforming, positions of MAs, successive interference cancellation
(SIC) decoding order, and users' corresponding decoding indicator matrix, while
adhering to constraints on the maximum transmit power and finite MA moving
region. The formulated problem is inherently highly non-convex, rendering it
challenging to acquire a globally optimal solution. As a compromise, we propose
a low-complexity two-stage optimization algorithm to obtain an effective
suboptimal solution. Specifically, in stage one, the SIC decoding order is
first determined by solving a channel gain maximization problem. Then, in stage
two, with the given SIC decoding order, the beamforming vectors, MA positions,
and users' decoding indicator matrix are iteratively optimized by capitalizing
on alternating optimization, successive convex approximation (SCA), and genetic
algorithm (GA). Simulation results unveil that the sum-rate performance of the
proposed MA-enabled downlink NOMA system significantly outperforms that of
conventional fixed-position antenna (FPA) systems. Moreover, the results also
show that the antenna position optimization in the proposed algorithm can
further enhance the advantages of NOMA over space division multiple access
(SDMA).

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [59] [Information Theoretic Analysis of a Dual-Band MIMO Cellphone Antenna with ANSYS HFSS SBR+](https://arxiv.org/abs/2507.14704)
*Volodymyr Shyianov,Bamelak Tadele,Vladimir I. Okhmatovski,Amine Mezghani*

Main category: cs.IT

TL;DR: 该论文提出了一种结合信息论和电磁理论的方法，用于评估手机上的双频双极化MIMO天线阵列设计，并通过仿真和概率分析比较了不同方法的性能差异。


<details>
  <summary>Details</summary>
Motivation: 传统天线设计与香农理论分离，本文旨在结合信息论和电磁理论，优化MIMO天线阵列设计。

Method: 使用ANSYS HFSS进行电磁仿真，获取天线阵列模型和信道矩阵，通过线性与最优处理估计中断概率曲线，分析分集增益和复用增益。

Result: 在中等信噪比下获得分集增益，高信噪比下获得复用增益，与传统方法（如包络相关系数）相比存在显著差异。

Conclusion: 信息论方法为天线设计提供了新的分析视角，与传统方法相比具有优势。

Abstract: Historically, the design of antenna arrays has evolved separately from
Shannon theory. Shannon theory adopts a probabilistic approach in the design of
communication systems, while antenna design approaches have relied on the
deterministic Maxwell theory alone. In this paper, we investigate an
information-theoretic analysis approach which we apply to evaluate the design
of a dual-band, dual-polarized multiple-input multiple-output (MIMO) array on a
cellphone. To this end, we use ANSYS HFSS, a commercial electromagnetic (EM)
simulation software suitable for the numerical optimization of antenna systems.
HFSS is used to obtain an accurate model of the cellphone MIMO antenna array
and HFSS SBR+ is utilized to obtain channel matrices for a large number of
users. Taking advantage of linear and optimal processing at the cellphone, we
estimate the outage probability curves. The curves are then used to determine
the diversity gain in a moderate signal-to-noise ratio (SNR) regime and the
multiplexing gain at a high SNR regime. This approach is then compared with the
method of estimating the diversity gain from the envelope correlation
coefficients or the beam-coupling matrix showing substantial differences in the
two methodologies.

</details>


### [60] [Study of Delay-Calibrated Joint User Activity Detection, Channel Estimation and Data Detection for Asynchronous mMTC Systems](https://arxiv.org/abs/2507.14733)
*Z. Shao,X. Yuan,R. de Lamare*

Main category: cs.IT

TL;DR: 论文提出了一种基于期望最大化的延迟校准联合用户活动检测、信道估计和数据检测算法，解决了大规模机器类型通信中的异步传输和碰撞问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模机器类型通信中，低功耗设备异步传输短数据包会导致大量碰撞，现有正交前导码方法因数量有限无法解决。

Method: 采用期望最大化方法，通过交替估计延迟和检测活跃用户及其信道与数据，利用近似消息传递原理开发高效迭代算法。

Result: 数值结果表明，所提算法在信道和数据符号的归一化均方误差以及误检概率方面表现优异。

Conclusion: 该算法有效解决了异步大规模机器类型通信中的碰撞问题，提升了系统性能。

Abstract: This work considers uplink asynchronous massive machine-type communications,
where a large number of low-power and low-cost devices asynchronously transmit
short packets to an access point equipped with multiple receive antennas. If
orthogonal preambles are employed, massive collisions will occur due to the
limited number of orthogonal preambles given the preamble sequence length. To
address this problem, we propose a delay-calibrated joint user activity
detection, channel estimation, and data detection algorithm, and investigate
the benefits of oversampling in estimating continuous-valued time delays at the
receiver. The proposed algorithm is based on the expectation-maximization
method, which alternately estimates the delays and detects active users and
their channels and data by noting that the collided users have different
delays. Under the Bayesian inference framework, we develop a computationally
efficient iterative algorithm using the approximate message passing principle
to resolve the joint user activity detection, channel estimation, and data
detection problem. Numerical results demonstrate the effectiveness of the
proposed algorithm in terms of the normalized mean-squared errors of channel
and data symbols, and the probability of misdetection.

</details>


### [61] [An Information-Theoretic Intersectional Data Valuation Theory](https://arxiv.org/abs/2507.14742)
*Eduardo C. Garrido-Merchán*

Main category: cs.IT

TL;DR: 提出了一种基于互信息的定价规则，量化并内部化交叉隐私损失，以货币形式衡量数据对熵的减少，旨在减少有害数据交易并鼓励透明度。


<details>
  <summary>Details</summary>
Motivation: 当代数字市场中，个人数据暴露了复杂的交叉身份特征，企业从中获益，而用户面临社会风险和歧视的隐性成本。

Method: 引入一种形式化的定价规则，利用互信息量化交叉隐私损失，并通过离散化联合概率分布实现实际应用。

Result: 提出了一种庇古式附加费，可独立于底层统计模型运行，并能根据社会价值观进行校准。

Conclusion: 该规则不仅解决了市场失灵问题，还为弱势群体提供了再分配保护，以应对数字权力的不对称。

Abstract: In contemporary digital markets, personal data often reveals not just
isolated traits, but complex, intersectional identities based on combinations
of race, gender, disability, and other protected characteristics. This exposure
generates a privacy externality: firms benefit economically from profiling,
prediction, and personalization, while users face hidden costs in the form of
social risk and discrimination. We introduce a formal pricing rule that
quantifies and internalizes this intersectional privacy loss using mutual
information, assigning monetary value to the entropy reduction induced by each
datum. The result is a Pigouvian-style surcharge that discourages harmful data
trades and rewards transparency. Our formulation has the advantage that it
operates independently of the underlying statistical model of the
intersectional variables, be it parametric, nonparametric, or learned, and can
be approximated in practice by discretizing the intersectional joint
probability distributions. We illustrate how regulators can calibrate this
surcharge to reflect different societal values, and argue that it provides not
just a technical fix to market failures, but also a redistributive shield that
empowers vulnerable groups in the face of asymmetric digital power.

</details>


### [62] [Collusion-Resilient Hierarchical Secure Aggregation with Heterogeneous Security Constraints](https://arxiv.org/abs/2507.14768)
*Zhou Li,Xiang Zhang,Jiawen Lv,Jihao Fan,Haiqiang Chen,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文研究了分层安全聚合（HSA）中的弱安全性问题，提出了一种灵活框架（WS-HSA）以应对异构安全需求，并分析了最优密钥率。


<details>
  <summary>Details</summary>
Motivation: 解决HSA中因用户数量增加导致的异构安全需求问题，例如不同集群用户需要不同级别的输入保护。

Method: 提出弱安全HSA（WS-HSA）框架，允许自定义安全输入集和合谋集，并分析最优密钥率。

Result: 确定了最优总密钥率，并对其他情况提供了上下界和常数倍最优性保证。

Conclusion: WS-HSA为HSA中的异构安全需求提供了灵活且高效的解决方案。

Abstract: Motivated by federated learning (FL), secure aggregation (SA) aims to
securely compute, as efficiently as possible, the sum of a set of inputs
distributed across many users. To understand the impact of network topology,
hierarchical secure aggregation (HSA) investigated the communication and secret
key generation efficiency in a 3-layer relay network, where clusters of users
are connected to the aggregation server through an intermediate layer of
relays. Due to the pre-aggregation of the messages at the relays, HSA reduces
the communication burden on the relay-to-server links and is able to support a
large number of users. However, as the number of users increases, a practical
challenge arises from heterogeneous security requirements--for example, users
in different clusters may require varying levels of input protection. Motivated
by this, we study weakly-secure HSA (WS-HSA) with collusion resilience, where
instead of protecting all the inputs from any set of colluding users, only the
inputs belonging to a predefined collection of user groups (referred to as
security input sets) need to be protected against another predefined collection
of user groups (referred to as collusion sets). Since the security input sets
and collusion sets can be arbitrarily defined, our formulation offers a
flexible framework for addressing heterogeneous security requirements in HSA.
We characterize the optimal total key rate, i.e., the total number of
independent key symbols required to ensure both server and relay security, for
a broad range of parameter configurations. For the remaining cases, we
establish lower and upper bounds on the optimal key rate, providing
constant-factor gap optimality guarantees.

</details>


### [63] [Enhancing Resilience Against Jamming Attacks: A Cooperative Anti-Jamming Method Using Direction Estimation](https://arxiv.org/abs/2507.14775)
*Amir Mehrabian,Georges Kaddoum*

Main category: cs.IT

TL;DR: 本文提出了一种基于多传感节点协作的抗干扰方法（CAJ），利用特征向量（EV）方法估计信道方向，性能接近完美信道状态信息（CSI）的情况，且在强干扰下表现优异。


<details>
  <summary>Details</summary>
Motivation: 无线通信易受干扰攻击，需提升安全性。

Method: 提出EV方法估计信道方向，结合多传感节点协作抗干扰。

Result: 在强干扰下性能仅下降0.7 dB，且能处理多干扰源。

Conclusion: EV-CAJ方法在快速衰落信道中表现稳健，适用于移动干扰源。

Abstract: The inherent vulnerability of wireless communication necessitates strategies
to enhance its security, particularly in the face of jamming attacks. This
paper uses the collaborations of multiple sensing nodes (SNs) in the wireless
network to present a cooperative anti-jamming approach (CAJ) designed to
neutralize the impact of jamming attacks. We propose an eigenvector (EV) method
to estimate the direction of the channel vector from pilot symbols. Through our
analysis, we demonstrate that with an adequate number of pilot symbols, the
performance of the proposed EV method is comparable to the scenario where the
perfect channel state information (CSI) is utilized. Both analytical formulas
and simulations illustrate the excellent performance of the proposed EV-CAJ
under strong jamming signals. Considering severe jamming, the proposed EV-CAJ
method exhibits only a 0.7 dB degradation compared to the case without jamming
especially when the number of SNs is significantly larger than the number of
jamming nodes (JNs). Moreover, the extension of the proposed method can handle
multiple jammers at the expense of degrees of freedom (DoF). We also
investigate the method's ability to remain robust in fast-fading channels with
different coherence times. Our proposed approach demonstrates good resilience,
particularly when the ratio of the channel's coherence time to the time frame
is small. This is especially important in the case of mobile jammers with large
Doppler shifts.

</details>


### [64] [Enhancing Communications and Sensing Simultaneously by Zero-Order Optimization of MTS](https://arxiv.org/abs/2507.14794)
*Wenhai Lai,Kaiming Shen,Zhi-Quan Luo*

Main category: cs.IT

TL;DR: 论文提出了一种无需信道状态信息（CSI）的盲配置方法，通过接收信号强度（RSS）数据优化超表面（MTS）的相位偏移，以增强信道强度并实现发射器定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖CSI，而本文旨在在缺乏CSI的情况下，通过统计方法优化MTS相位偏移，同时探索其在主动感知中的应用。

Method: 利用RSS数据提取无线环境特征，通过条件样本均值进行盲配置优化，并与相位恢复问题建立联系。

Result: 原型系统验证表明，该方法在2.6 GHz频段显著提升信噪比（约10 dB），并在主动感知任务中优于基准方法（如MUSIC）。

Conclusion: 盲配置方法不仅优化了无线通信性能，还实现了发射器定位，仅需RSS数据即可实现。

Abstract: Metasurface (MTS) comprises an array of metaatoms, each reflecting and
inducing a phase shift into the incident wireless signal. We seek the optimal
combination of phase shifts across all the meta-atoms to maximize the channel
strength from transmitter to receiver. Unlike many existing works that heavily
rely on channel state information (CSI), this paper proposes a statistical
approach to the phase shift optimization in the absence of CSI, namely blind
configuration or zero-order optimization. The main idea is to extract the key
features of the wireless environment from the received signal strength (RSS)
data via conditional sample mean, with provable performance. Furthermore, as a
windfall profit, we show that the proposed blind configuration method has a
nontrivial connection to phase retrieval which can be utilized for active
sensing. In a nutshell, by configuring a pair of MTSs blindly without channel
estimation, we not only enhance the channel strength to facilitate wireless
communication, but also enable receiver to localize transmitter. All we need is
the RSS data that can be readily measured at receiver. Our algorithm is
verified in prototype systems in the 2.6 GHz spectral band. As shown in field
tests, the proposed algorithm outperforms the benchmarks (e.g., MUSIC) in the
active sensing task, and in the meanwhile raises the signal-to-noise ratio
(SNR) significantly by about 10 dB.

</details>


### [65] [A DPI-PAC-Bayesian Framework for Generalization Bounds](https://arxiv.org/abs/2507.14795)
*Muhan Guan,Farhad Farokhi,Jingge Zhu*

Main category: cs.IT

TL;DR: 提出了一种统一的DPI-PAC-Bayesian框架，用于监督学习中的泛化误差界推导，通过结合数据处理不等式和变测技术，得到了更紧的泛化间隙界。


<details>
  <summary>Details</summary>
Motivation: 旨在通过信息论工具（如数据处理不等式）改进PAC-Bayesian框架，消除经典界限中的冗余项，获得更紧的泛化误差界。

Method: 将数据处理不等式嵌入变测技术，推导基于Rényi散度和f-散度的二元KL泛化间隙界，并展示了与经典界限的联系。

Result: 提出了三种基于Rényi、Hellinger和Chi-Squared散度的界限，并在均匀先验下恢复了Occam's Razor界限，消除了PAC-Bayes界限中的冗余项。

Conclusion: 该框架连接了数据处理和PAC-Bayesian视角，为构建泛化保证提供了灵活的信息论工具。

Abstract: We develop a unified Data Processing Inequality PAC-Bayesian framework --
abbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the
supervised learning setting. By embedding the Data Processing Inequality (DPI)
into the change-of-measure technique, we obtain explicit bounds on the binary
Kullback-Leibler generalization gap for both R\'enyi divergence and any
$f$-divergence measured between a data-independent prior distribution and an
algorithm-dependent posterior distribution. We present three bounds derived
under our framework using R\'enyi, Hellinger \(p\) and Chi-Squared divergences.
Additionally, our framework also demonstrates a close connection with other
well-known bounds. When the prior distribution is chosen to be uniform, our
bounds recover the classical Occam's Razor bound and, crucially, eliminate the
extraneous \(\log(2\sqrt{n})/n\) slack present in the PAC-Bayes bound, thereby
achieving tighter results. The framework thus bridges data-processing and
PAC-Bayesian perspectives, providing a flexible, information-theoretic tool to
construct generalization guarantees.

</details>


### [66] [Rate-Distortion-Perception Trade-off with Strong Realism Constraints: Role of Side Information and Common Randomness](https://arxiv.org/abs/2507.14825)
*Yassine Hamdi,Aaron B. Wagner,Deniz Gündüz*

Main category: cs.IT

TL;DR: 论文探讨了在图像压缩中，生成模型对率失真与感知质量之间权衡的影响，特别是在强完美真实感约束下，分析了不同场景下的信息理论极限。


<details>
  <summary>Details</summary>
Motivation: 研究在图像压缩中，生成模型如何影响率失真与感知质量的权衡，并探讨强完美真实感约束对信息理论极限的影响。

Method: 分析了两种场景：边信息仅在解码器可用，或在编码器和解码器均可用。研究了不同真实感约束（边缘真实感、联合真实感和近完美真实感）下的信息理论极限。

Result: 当边信息在编码器和解码器均可用时，揭示了其双重作用：作为共同随机性和接收者对源的二次观察。在高斯场景下，推导了显式解。

Conclusion: 强完美真实感约束下，边信息仅在解码器可用时，需要足够的共同随机性才能避免率损失。

Abstract: In image compression, with recent advances in generative modeling, existence
of a trade-off between the rate and perceptual quality has been brought to
light, where the perceptual quality is measured by the closeness of the output
and source distributions. We consider the compression of a memoryless source
sequence $X^n=(X_1, \ldots, X_n)$ in the presence of memoryless side
information $Z^n=(Z_1, \ldots, Z_n),$ originally studied by Wyner and Ziv, but
elucidate the impact of a strong perfect realism constraint, which requires the
joint distribution of output symbols $Y^n=(Y_1,...,Y_n)$ to match the
distribution of the source sequence. We consider two cases: when $Z^n$ is
available only at the decoder, or at both the encoder and decoder, and
characterize the information theoretic limits under various scenarios. Previous
works show the superiority of randomized codes under strong perceptual quality
constraints. When $Z^n$ is available at both terminals, we characterize its
dual role, as a source of common randomness, and as a second look on the source
for the receiver. We also study different notions of strong perfect realism
which we call marginal realism, joint realism and near-perfect realism. We
derive explicit solutions when $X$ and $Z$ are jointly Gaussian under the
squared error distortion measure. In traditional lossy compression, having $Z$
only at the decoder imposes no rate penalty in the Gaussian scenario. We show
that, when strong perfect realism constraints are imposed this holds only when
sufficient common randomness is available.

</details>


### [67] [Variable Min-Cut Max-Flow Bounds and Algorithms in Finite Regime](https://arxiv.org/abs/2507.14852)
*Rivka Gitik,Alejandro Cohen*

Main category: cs.IT

TL;DR: 论文提出了一种基于计算几何的新框架，分析异构网络中可变链路容量的吞吐量，并展示了增加链路数量可减少吞吐量变异性。


<details>
  <summary>Details</summary>
Motivation: 研究网络链路容量波动对吞吐量的影响，突破传统min-cut max-flow限制。

Method: 利用计算几何工具分析吞吐量，提出算法强制网络稳定性，并采用自适应无速率随机线性网络编码（AR-RLNC）优化延迟与吞吐量权衡。

Result: 增加链路数量可减少吞吐量变异性近90%，不稳定图可能具有指数级数量的min-cut集。

Conclusion: 提出的框架和算法有效提升网络稳定性，AR-RLNC进一步优化性能。

Abstract: The maximum achievable capacity from source to destination in a network is
limited by the min-cut max-flow bound; this serves as a converse limit. In
practice, link capacities often fluctuate due to dynamic network conditions. In
this work, we introduce a novel analytical framework that leverages tools from
computational geometry to analyze throughput in heterogeneous networks with
variable link capacities in a finite regime. Within this model, we derive new
performance bounds and demonstrate that increasing the number of links can
reduce throughput variability by nearly $90\%$. We formally define a notion of
network stability and show that an unstable graph can have an exponential
number of different min-cut sets, up to $O(2^{|E|})$. To address this
complexity, we propose an algorithm that enforces stability with time
complexity $O(|E|^2 + |V|)$, and further suggest mitigating the
delay-throughput tradeoff using adaptive rateless random linear network coding
(AR-RLNC).

</details>


### [68] [Reconfigurable Antenna Arrays With Tunable Loads: Expanding Solution Space via Coupling Control](https://arxiv.org/abs/2507.15074)
*Elio Faddoul,Konstantinos Ntougias,Ioannis Krikidis*

Main category: cs.IT

TL;DR: 论文提出两种技术解决可重构天线阵列的互耦问题，并开发高效算法优化配置，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，可重构天线阵列因互耦问题和配置空间庞大而受限，需解决这些挑战以提升性能。

Method: 1) 利用被动天线和可调负载增强增益；2) 采用全主动设计消除互耦。同时开发贪婪和元启发式算法优化配置。

Result: 数值模拟显示，相比基准方法，性能显著提升，并提供了对量化负载性能下降的鲁棒设计。

Conclusion: 所提方法解锁了可重构天线阵列的完整解决方案空间，显著提升了性能，为实际应用提供了有效指导。

Abstract: The emerging reconfigurable antenna (RA) array technology promises capacity
enhancement through dynamic antenna positioning. Traditional approaches enforce
half-wavelength or greater spacing among RA elements to avoid mutual coupling,
limiting the solution space. Additionally, achieving sufficient spatial channel
sampling requires numerous discrete RA positions (ports), while high-frequency
scenarios with hybrid processing demand many physical RAs to maintain array
gains. This leads to exponential growth in the solution space. We propose two
techniques to address the former challenge: (1) surrounding a limited number of
active RAs with passive ones terminated to tunable analog loads to
\textit{exploit} mutual coupling and increase array gain, and (2) employing
tunable loads on each RA in an all-active design to \textit{eliminate} mutual
coupling in the analog domain. Both methods enable arbitrary RA spacing,
unlocking the full solution space. Regarding the latter challenge, we develop
greedy and meta-heuristic port selection algorithms, alongside low-complexity
heuristic variants, that efficiently handle over $10^{20}$ array
configurations, and optimize the loading values to maximize the sum-rate in a
multiple-input single-output broadcast channel under transmission power
constraints, assuming a heuristic linear precoder. Furthermore, we analyze
performance degradation from quantized loads and propose corresponding robust
designs. Numerical simulations reveal significant performance gains over
benchmarks and provide valuable insights.

</details>


### [69] [Noise Quantification and Control in Circuits via Strong Data-Processing Inequalities](https://arxiv.org/abs/2507.15108)
*Chenyang Sun*

Main category: cs.IT

TL;DR: 本文探讨了强数据处理不等式（SPDI's）在噪声电路计算中的应用，改进了Evans和Schulman以及von Neumann的工作框架，并推广了von Neumann的分析到任意阶多数门。


<details>
  <summary>Details</summary>
Motivation: 研究噪声电路中的可靠计算问题，改进现有框架并填补原始工作中的计算空缺。

Method: 首先基于Evans和Schulman的框架提出深度下界和噪声上界，然后引入von Neumann的3-多数门并推广到任意阶多数门，分析其噪声阈值。

Result: 证明了任意阶多数门的噪声阈值，并给出了可靠计算所需的阶数上界。

Conclusion: 通过改进和推广现有工作，为噪声电路中的可靠计算提供了更全面的理论支持。

Abstract: This essay explores strong data-processing inequalities (SPDI's) as they
appear in the work of Evans and Schulman \cite{ES} and von Neumann \cite{vN} on
computing with noisy circuits. We first develop the framework in \cite{ES},
which leads to lower bounds on depth and upper bounds on noise that permit
reliable computation. We then introduce the $3$-majority gate, introduced by
\cite{vN} for the purpose of controlling noise, and obtain an upper bound on
noise necessary for its function. We end by generalizing von Neumann's analysis
to majority gates of any order, proving an analogous noise threshold and giving
a sufficient upper bound for order given a desired level of reliability.
  The presentation of material has been modified in a way deemed more natural
by the author, occasionally leading to simplifications of existing proofs.
Furthermore, many computations omitted from the original works have been worked
out, and some new commentary added. The intended audience has a rudimentary
understanding of information theory similar to that of the author.

</details>


### [70] [The Exact Parameters of A Family of BCH Codes](https://arxiv.org/abs/2507.15247)
*Zhonghua Sun*

Main category: cs.IT

TL;DR: 本文确定了窄带BCH码的最小距离和维数，解决了Li等人提出的三个开放问题，并补充了Ding的开创性框架。


<details>
  <summary>Details</summary>
Motivation: BCH码的最小距离和维数在许多家族中仍未知，具有理论和实践意义。

Method: 研究窄带BCH码$\C_{(q, m, \lambda, \ell_0, \ell_1)}$的最小距离和维数，基于特定参数条件。

Result: 精确确定了这些码的最小距离和维数。

Conclusion: 解决了Li等人的开放问题，并扩展了Ding的研究成果。

Abstract: Despite the theoretical and practical significance of BCH codes, the exact
minimum distance and dimension remain unknown for many families. This paper
establishes the precise minimum distance and dimension of narrow-sense BCH
codes $\C_{(q, m, \lambda, \ell_0, \ell_1)}$ over $\gf(q)$ of length
$\frac{q^m-1}{\lambda}$ and designed distance $\frac{(q-\lambda
\ell_0)q^{m-1-\ell_1}-1}{\lambda}$, where $\lambda\mid (q-1)$, $0\leq \ell_0<
\frac{q-1}{\lambda}$, and $0\leq \ell_1\leq m-1$. These results conclusively
resolve the three open problems posed by Li et al. (IEEE Trans. Inf. Theory,
vol. 63, no. 11, pp. 7219-7236, Nov. 2017) while establishing complementary
advances to Ding's seminal framework (IEEE Trans. Inf. Theory, vol. 61, no. 10,
pp. 5322-5330, Oct. 2015).

</details>


### [71] [A Novel Two-Dimensional Smoothing Algorithm](https://arxiv.org/abs/2507.15301)
*Xufeng Chen,Liang Yan,Xiaoshan Gao*

Main category: cs.IT

TL;DR: 提出了一种新型二维平滑（TDS）算法，用于二维序列的平滑和滤波问题，无需噪声分布假设，仅需调整单一参数即可有效提取趋势并减少噪声影响。


<details>
  <summary>Details</summary>
Motivation: 传统滤波算法依赖滤波窗口选择，限制了其适用性，因此需要一种更简单、更通用的方法。

Method: 通过引入损失函数，将趋势序列定义为损失函数最小化时的解，将二维序列分解为趋势序列和波动序列。

Result: TDS算法在数值模拟和图像处理案例中验证了其准确性和有效性。

Conclusion: TDS算法提供了一种简单、通用的二维序列平滑和滤波方法，适用于多种场景。

Abstract: Smoothing and filtering two-dimensional sequences are fundamental tasks in
fields such as computer vision. Conventional filtering algorithms often rely on
the selection of the filtering window, limiting their applicability in certain
scenarios. To this end, we propose a novel Two-Dimensional Smoothing (TDS)
algorithm for the smoothing and filtering problem of two-dimensional sequences.
Typically, the TDS algorithm does not require assumptions about the type of
noise distribution. It is simple and easy to implement compared to conventional
filtering methods, such as 2D adaptive Wiener filtering and Gaussian filtering.
The TDS algorithm can effectively extract the trend contained in the
two-dimensional sequence and reduce the influence of noise on the data by
adjusting only a single parameter. In this work, unlike existing algorithms
that depend on the filtering window, we introduce a loss function, where the
trend sequence is identified as the solution when this loss function takes a
minimum value. Therefore, within the framework of the TDS algorithm, a general
two-dimensional sequence can be innovatively decomposed into a trend sequence
and a fluctuation sequence, in which the trend sequence contains the main
features of the sequence and the fluctuation sequence contains the detailed
features or noise interference of the sequence. To ensure the reliability of
the TDS algorithm, a crucial lemma is first established, indicating that the
trend sequence and fluctuation sequence obtained by the TDS algorithm are
existent and unique when the global smoothing parameter is determined. Three
modified algorithms are then proposed based on the TDS algorithm, with
corresponding lemmas and corollaries demonstrating their reliability. Finally,
the accuracy and effectiveness of the TDS algorithm are further verified
through numerical simulations and image processing cases.

</details>


### [72] [Cross Mutual Information](https://arxiv.org/abs/2507.15372)
*Chetan Gohil,Oliver M Cliff,James M. Shine,Ben D. Fulcher,Joseph T. Lizier*

Main category: cs.IT

TL;DR: 提出了一种名为“交叉互信息”的新方法，用于比较非平稳分布样本中变量X和Y的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 传统互信息无法直接比较非平稳分布样本中的依赖关系，需要一种新方法。

Method: 提出交叉互信息作为替代度量，并通过模拟研究验证其有效性。

Result: 模拟研究表明交叉互信息能有效比较不同样本集的依赖关系。

Conclusion: 交叉互信息在非平稳分布中具有应用潜力，未来可用于神经影像数据分析。

Abstract: Mutual information (MI) is a useful information-theoretic measure to quantify
the statistical dependence between two random variables: $X$ and $Y$. Often, we
are interested in understanding how the dependence between $X$ and $Y$ in one
set of samples compares to another. Although the dependence between $X$ and $Y$
in each set of samples can be measured separately using MI, these estimates
cannot be compared directly if they are based on samples from a non-stationary
distribution. Here, we propose an alternative measure for characterising how
the dependence between $X$ and $Y$ as defined by one set of samples is
expressed in another, \textit{cross mutual information}. We present a
comprehensive set of simulation studies sampling data with $X$-$Y$ dependencies
to explore this measure. Finally, we discuss how this relates to measures of
model fit in linear regression, and some future applications in neuroimaging
data analysis.

</details>


### [73] [Galois equiangular tight frames from Galois self-dual codes](https://arxiv.org/abs/2507.15448)
*Junmin An,Jon-Lark Kim*

Main category: cs.IT

TL;DR: 论文扩展了有限域上的框架理论，引入了Galois内积，定义了Galois框架及相关概念，并构造了Galois ETFs。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上的框架理论，推广内积概念，为编码理论提供新工具。

Method: 引入Galois内积，定义Galois框架及相关概念，构造Galois ETFs。

Result: 成功构造了Galois ETFs，并证明了Galois自对偶码可诱导Galois ETFs。

Conclusion: Galois框架理论为有限域上的编码和信号处理提供了新视角。

Abstract: Greaves et al. (2022) extended frames over real or complex numbers to frames
over finite fields. In this paper, we study the theory of frames over finite
fields by incorporating the Galois inner products introduced by Fan and Zhang
(2017), which generalize the Euclidean and Hermitian inner products. We define
a class of frames, called Galois frames over finite fields, along with related
notions such as Galois Gram matrices, Galois frame operators, and Galois
equiangular tight frames (Galois ETFs). We also characterize when Galois
self-dual codes induce Galois ETFs. Furthermore, we construct explicitly Galois
ETFs from Galois self-dual constacyclic codes.

</details>


### [74] [Estimating Rate-Distortion Functions Using the Energy-Based Model](https://arxiv.org/abs/2507.15700)
*Shitong Wu,Sicheng Xu,Lingyi Chen,Huihui Wu,Wenyi Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于能量建模的创新框架，通过连接率失真对偶形式与统计物理中的自由能，有效重建最优条件分布，解决了高维场景下Blahut-Arimoto算法的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 高维场景下Blahut-Arimoto算法计算困难，现有神经方法常忽略最优条件分布重建或依赖不合理假设。

Method: 利用能量建模框架，避免计算归一化因子，仅需训练单一神经网络。

Result: 实验证明该算法在高维率失真函数估计和最优条件分布重建中显著有效。

Conclusion: 提出的方法为高维率失真问题提供了高效解决方案。

Abstract: The rate-distortion (RD) theory is one of the key concepts in information
theory, providing theoretical limits for compression performance and guiding
the source coding design, with both theoretical and practical significance. The
Blahut-Arimoto (BA) algorithm, as a classical algorithm to compute RD
functions, encounters computational challenges when applied to high-dimensional
scenarios. In recent years, many neural methods have attempted to compute
high-dimensional RD problems from the perspective of implicit generative
models. Nevertheless, these approaches often neglect the reconstruction of the
optimal conditional distribution or rely on unreasonable prior assumptions. In
face of these issues, we propose an innovative energy-based modeling framework
that leverages the connection between the RD dual form and the free energy in
statistical physics, achieving effective reconstruction of the optimal
conditional distribution.The proposed algorithm requires training only a single
neural network and circumvents the challenge of computing the normalization
factor in energy-based models using the Markov chain Monte Carlo (MCMC)
sampling. Experimental results demonstrate the significant effectiveness of the
proposed algorithm in estimating high-dimensional RD functions and
reconstructing the optimal conditional distribution.

</details>


### [75] [Remote Channel Synthesis](https://arxiv.org/abs/2507.15757)
*Yassine Hamdi,Deniz Gündüz*

Main category: cs.IT

TL;DR: 论文研究了在无记忆信道中合成编码器与解码器之间的协调问题，提出了最优压缩和公共随机性速率的单字母表征，并指出低公共随机性速率下标准信道合成方案的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决在部分或噪声观测下，如何通过编码器和解码器协调生成与远程源序列匹配的输出序列的问题。

Method: 通过无噪声链路和有限的公共随机性，编码器将部分观测信息传递给解码器，目标是使输出序列与源序列的联合分布接近目标分布。

Result: 提出了最优压缩和公共随机性速率的单字母表征，并证明低公共随机性速率下标准信道合成方案通常不最优。

Conclusion: 在低公共随机性速率下，标准信道合成方案无法达到最优协调效果，需要更高效的方案。

Abstract: We consider the problem of synthesizing a memoryless channel between an
unobserved source and a remote terminal. An encoder has access to a partial or
noisy version $Z^n = (Z_1, \ldots, Z_n)$ of a remote source sequence $X^n =
(X_1, \ldots, X_n),$ with $(X_i,Z_i)$ independent and identically distributed
with joint distribution $q_{X,Z}.$ The encoder communicates through a noiseless
link to a decoder which aims to produce an output $Y^n$ coordinated with the
remote source; that is, the total variation distance between the joint
distribution of $X^n$ and $Y^n$ and some i.i.d. target distribution
$q_{X,Y}^{\otimes n}$ is required to vanish as $n$ goes to infinity. The two
terminals may have access to a source of rate-limited common randomness. We
present a single-letter characterization of the optimal compression and common
randomness rates. We also show that when the common randomness rate is small,
then in most cases, coordinating $Z^n$ and $Y^n$ using a standard channel
synthesis scheme is strictly sub-optimal. In other words, schemes for which the
joint distribution of $Z^n$ and $Y^n$ approaches a product distribution
asymptotically are strictly sub-optimal.

</details>


### [76] [The Capacity of Semantic Private Information Retrieval with Colluding Servers](https://arxiv.org/abs/2507.15818)
*Mohamed Nomeir,Alptug Aytekin,Sennur Ulukus*

Main category: cs.IT

TL;DR: 研究了语义私有信息检索（Sem-PIR）在服务器共谋（Sem-TPIR）下的问题，推导了其精确容量。


<details>
  <summary>Details</summary>
Motivation: 扩展经典PIR问题，考虑消息大小不等和检索概率不均的情况，并引入服务器共谋（T < N）。

Method: 提出上界并设计达到该上界的方案。

Result: 推导出Sem-TPIR的精确容量。

Conclusion: 解决了服务器共谋下的语义私有信息检索问题，为实际应用提供了理论基础。

Abstract: We study the problem of semantic private information retrieval (Sem-PIR) with
$T$ colluding servers (Sem-TPIR), i.e., servers that collectively share user
queries. In Sem-TPIR, the message sizes are different, and message retrieval
probabilities by any user are not uniform. This is a generalization of the
classical PIR problem where the message sizes are equal and message retrieval
probabilities are identical. The earlier work on Sem-PIR considered the case of
no collusions, i.e., the collusion parameter of $T=1$. In this paper, we
consider the general problem for arbitrary $T < N$. We find an upper bound on
the retrieval rate and design a scheme that achieves this rate, i.e., we derive
the exact capacity of Sem-TPIR.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [77] [MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images](https://arxiv.org/abs/2507.14271)
*Refik Samet,Nooshin Nemati,Emrah Hancer,Serpil Sak,Bilge Ayca Kirmizi,Zeynep Yildirim*

Main category: eess.IV

TL;DR: MiDeSeC数据集包含25名患者的H&E染色乳腺癌切片，共50个区域，用于训练和测试，包含500多个有丝分裂。


<details>
  <summary>Details</summary>
Motivation: 创建大规模数据集以覆盖多种有丝分裂形态，提高乳腺癌病理分析的准确性。

Method: 从40倍放大的玻璃切片中选择50个1024*1024像素区域，使用3D Histech和Olympus设备扫描。

Result: 数据集包含500多个有丝分裂，2/3区域用于训练，1/3用于测试。

Conclusion: MiDeSeC数据集为乳腺癌有丝分裂研究提供了丰富的资源。

Abstract: The MiDeSeC dataset is created through H&E stained invasive breast carcinoma,
no special type (NST) slides of 25 different patients captured at 40x
magnification from the Department of Medical Pathology at Ankara University.
The slides have been scanned by 3D Histech Panoramic p250 Flash-3 scanner and
Olympus BX50 microscope. As several possible mitosis shapes exist, it is
crucial to have a large dataset to cover all the cases. Accordingly, a total of
50 regions is selected from glass slides for 25 patients, each of regions with
a size of 1024*1024 pixels. There are more than 500 mitoses in total in these
50 regions. Two-thirds of the regions are reserved for training, the other
third for testing.

</details>


### [78] [NuSeC: A Dataset for Nuclei Segmentation in Breast Cancer Histopathology Images](https://arxiv.org/abs/2507.14272)
*Refik Samet,Nooshin Nemati,Emrah Hancer,Serpil Sak,Bilge Ayca Kirmizi*

Main category: eess.IV

TL;DR: NuSeC数据集包含100张图像，分为75%训练集和25%测试集，用于未来方法开发的比较分析。


<details>
  <summary>Details</summary>
Motivation: 为研究人员提供一个标准数据集，用于开发和分析新方法。

Method: 从25名患者中每名患者选4张图像，随机抽取1张作为测试集，其余为训练集。

Result: 训练集含75张图像约30000个核结构，测试集含25张图像约6000个核结构。

Conclusion: NuSeC数据集设计合理，适用于未来研究方法的比较分析。

Abstract: The NuSeC dataset is created by selecting 4 images with the size of 1024*1024
pixels from the slides of each patient among 25 patients. Therefore, there are
a total of 100 images in the NuSeC dataset. To carry out a consistent
comparative analysis between the methods that will be developed using the NuSeC
dataset by the researchers in the future, we divide the NuSeC dataset 75% as
the training set and 25% as the testing set. In detail, an image is randomly
selected from 4 images of each patient among 25 patients to build the testing
set, and then the remaining images are reserved for the training set. While the
training set includes 75 images with around 30000 nuclei structures, the
testing set includes 25 images with around 6000 nuclei structures.

</details>


### [79] [Self-Supervised Joint Reconstruction and Denoising of T2-Weighted PROPELLER MRI of the Lungs at 0.55T](https://arxiv.org/abs/2507.14308)
*Jingjia Chen,Haoyang Pei,Christoph Maier,Mary Bruno,Qiuting Wen,Seon-Hi Shin,William Moore,Hersh Chandarana,Li Feng*

Main category: eess.IV

TL;DR: 研究通过自监督联合重建和去噪模型改进0.55T T2加权PROPELLER肺部MRI。


<details>
  <summary>Details</summary>
Motivation: 提高0.55T T2加权PROPELLER肺部MRI的清晰度和结构完整性，同时减少扫描时间。

Method: 使用44名新冠康复患者的MRI数据集，开发自监督学习框架，将PROPELLER采集的每个叶片分为两部分，分别用于训练重建网络和损失计算，并与MPPCA去噪方法对比。

Result: 自监督模型显著提升图像质量，与CT图像对齐良好，扫描时间减少一半，且优于MPPCA方法（p<0.001）。

Conclusion: 自监督模型通过利用k空间子集的结构冗余性，有效重建图像并抑制噪声。

Abstract: Purpose: This study aims to improve 0.55T T2-weighted PROPELLER lung MRI
through a self-supervised joint reconstruction and denoising model.
  Methods: T2-weighted 0.55T lung MRI dataset including 44 patients with
previous covid infection were used. A self-supervised learning framework was
developed, where each blade of the PROPELLER acquisition was split along the
readout direction into two partitions. One subset trains the unrolled
reconstruction network, while the other subset is used for loss calculation,
enabling self-supervised training without clean targets and leveraging matched
noise statistics for denoising. For comparison, Marchenko-Pastur Principal
Component Analysis (MPPCA) was performed along the coil dimension, followed by
conventional parallel imaging reconstruction. The quality of the reconstructed
lung MRI was assessed visually by two experienced radiologists independently.
  Results: The proposed self-supervised model improved the clarity and
structural integrity of the lung images. For cases with available CT scans, the
reconstructed images demonstrated strong alignment with corresponding CT
images. Additionally, the proposed model enables further scan time reduction by
requiring only half the number of blades. Reader evaluations confirmed that the
proposed method outperformed MPPCA-denoised images across all categories
(Wilcoxon signed-rank test, p<0.001), with moderate inter-reader agreement
(weighted Cohen's kappa=0.55; percentage of exact and within +/-1 point
agreement=91%).
  Conclusion: By leveraging intrinsic structural redundancies between two
disjoint splits of k-space subsets, the proposed self-supervised learning model
effectively reconstructs the image while suppressing the noise for 0.55T
T2-weighted lung MRI with PROPELLER sampling.

</details>


### [80] [Classification of Histopathology Slides with Persistence Homology Convolutions](https://arxiv.org/abs/2507.14378)
*Shrunal Pothagoni,Benjamin Schweinhart*

Main category: eess.IV

TL;DR: 提出了一种基于局部持久同调的新方法，通过改进的卷积算子（Persistent Homology Convolutions）提升医学图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 典型CNN模型可能丢失拓扑信息，而拓扑在医学图像（如组织病理学）中至关重要。现有方法仅使用全局拓扑摘要，缺乏局部特征信息。

Method: 提出Persistent Homology Convolutions方法，生成局部持久同调数据，捕捉拓扑特征的局部性和平移不变性。

Result: 实验表明，该方法优于传统模型，对超参数不敏感，能有效提取组织病理学图像的几何信息。

Conclusion: Persistent Homology Convolutions能显著提升医学诊断的准确性，尤其在拓扑信息关键的应用场景。

Abstract: Convolutional neural networks (CNNs) are a standard tool for computer vision
tasks such as image classification. However, typical model architectures may
result in the loss of topological information. In specific domains such as
histopathology, topology is an important descriptor that can be used to
distinguish between disease-indicating tissue by analyzing the shape
characteristics of cells. Current literature suggests that reintroducing
topological information using persistent homology can improve medical
diagnostics; however, previous methods utilize global topological summaries
which do not contain information about the locality of topological features. To
address this gap, we present a novel method that generates local persistent
homology-based data using a modified version of the convolution operator called
Persistent Homology Convolutions. This method captures information about the
locality and translation invariance of topological features. We perform a
comparative study using various representations of histopathology slides and
find that models trained with persistent homology convolutions outperform
conventionally trained models and are less sensitive to hyperparameters. These
results indicate that persistent homology convolutions extract meaningful
geometric information from the histopathology slides.

</details>


### [81] [Spatiotemporal Maps for Dynamic MRI Reconstruction](https://arxiv.org/abs/2507.14429)
*Rodrigo A. Lobos,Xiaokai Wang,Rex T. L. Fung,Yongli He,David Frey,Dinank Gupta,Zhongming Liu,Jeffrey A. Fessler,Douglas C. Noll*

Main category: eess.IV

TL;DR: 提出了一种新的时空映射（STM）模型，用于动态MRI重建，解决了部分可分离函数（PSF）模型在时空特性变化场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: PSF模型在动态MRI重建中应用广泛，但在时空特性变化的场景中表现不足，因此需要改进。

Method: 利用自回归性质和先进信号处理技术，将时空MRI信号分解为空间和时空函数的乘积。

Result: STM模型成功应用于2D和3D MRI数据重建，证明了其有效性。

Conclusion: STM模型是PSF模型的扩展，能更灵活地处理动态MRI数据，适用于多种重建框架。

Abstract: The partially separable functions (PSF) model is commonly adopted in dynamic
MRI reconstruction, as is the underlying signal model in many reconstruction
methods including the ones relying on low-rank assumptions. Even though the PSF
model offers a parsimonious representation of the dynamic MRI signal in several
applications, its representation capabilities tend to decrease in scenarios
where voxels present different temporal/spectral characteristics at different
spatial locations. In this work we account for this limitation by proposing a
new model, called spatiotemporal maps (STMs), that leverages autoregressive
properties of (k, t)-space. The STM model decomposes the spatiotemporal MRI
signal into a sum of components, each one consisting of a product between a
spatial function and a temporal function that depends on the spatial location.
The proposed model can be interpreted as an extension of the PSF model whose
temporal functions are independent of the spatial location. We show that
spatiotemporal maps can be efficiently computed from autocalibration data by
using advanced signal processing and randomized linear algebra techniques,
enabling STMs to be used as part of many reconstruction frameworks for
accelerated dynamic MRI. As proof-of-concept illustrations, we show that STMs
can be used to reconstruct both 2D single-channel animal gastrointestinal MRI
data and 3D multichannel human functional MRI data.

</details>


### [82] [QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems](https://arxiv.org/abs/2507.14760)
*Cassandra Tong Ye,Shamus Li,Tyler King,Kristina Monakhova*

Main category: eess.IV

TL;DR: QUTCC是一种非线性、非均匀的量化不确定性训练和校准技术，用于改善深度学习模型在医学成像任务中的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学成像任务中可能产生幻觉（不真实的伪影），而现有方法的不确定性边界较大且信息量不足。

Method: 提出QUTCC技术，通过U-Net架构和量化嵌入预测完整的条件分布，并通过迭代查询上下分位数来校准不确定性边界。

Result: QUTCC能准确定位幻觉，并在保持统计覆盖的同时提供更紧的不确定性区间。

Conclusion: QUTCC在医学成像任务中显著提升了不确定性估计的精度和可靠性。

Abstract: Deep learning models often hallucinate, producing realistic artifacts that
are not truly present in the sample. This can have dire consequences for
scientific and medical inverse problems, such as MRI and microscopy denoising,
where accuracy is more important than perceptual quality. Uncertainty
quantification techniques, such as conformal prediction, can pinpoint outliers
and provide guarantees for image regression tasks, improving reliability.
However, existing methods utilize a linear constant scaling factor to calibrate
uncertainty bounds, resulting in larger, less informative bounds. We propose
QUTCC, a quantile uncertainty training and calibration technique that enables
nonlinear, non-uniform scaling of quantile predictions to enable tighter
uncertainty estimates. Using a U-Net architecture with a quantile embedding,
QUTCC enables the prediction of the full conditional distribution of quantiles
for the imaging task. During calibration, QUTCC generates uncertainty bounds by
iteratively querying the network for upper and lower quantiles, progressively
refining the bounds to obtain a tighter interval that captures the desired
coverage. We evaluate our method on several denoising tasks as well as
compressive MRI reconstruction. Our method successfully pinpoints
hallucinations in image estimates and consistently achieves tighter uncertainty
intervals than prior methods while maintaining the same statistical coverage.

</details>


### [83] [PET Image Reconstruction Using Deep Diffusion Image Prior](https://arxiv.org/abs/2507.15078)
*Fumio Hashimoto,Kuang Gong*

Main category: eess.IV

TL;DR: 提出了一种基于扩散模型的解剖先验引导PET图像重建方法，通过交替扩散采样和模型微调，实现了跨示踪剂的高质量重建，并采用HQS算法提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决PET成像中示踪剂特异性对比度变化和高计算需求的问题，扩展扩散模型在医学图像重建中的应用。

Method: 结合扩散采样和模型微调，利用PET正弦图引导重建，采用HQS算法优化计算效率。

Result: 在仿真和临床数据上验证了方法的有效性，能够跨示踪剂和扫描仪类型实现稳健重建。

Conclusion: 该方法为低剂量PET成像提供了高效且通用的重建框架。

Abstract: Diffusion models have shown great promise in medical image denoising and
reconstruction, but their application to Positron Emission Tomography (PET)
imaging remains limited by tracer-specific contrast variability and high
computational demands. In this work, we proposed an anatomical prior-guided PET
image reconstruction method based on diffusion models, inspired by the deep
diffusion image prior (DDIP) framework. The proposed method alternated between
diffusion sampling and model fine-tuning guided by the PET sinogram, enabling
the reconstruction of high-quality images from various PET tracers using a
score function pretrained on a dataset of another tracer. To improve
computational efficiency, the half-quadratic splitting (HQS) algorithm was
adopted to decouple network optimization from iterative PET reconstruction. The
proposed method was evaluated using one simulation and two clinical datasets.
For the simulation study, a model pretrained on [$^{18}$F]FDG data was tested
on amyloid-negative PET data to assess out-of-distribution (OOD) performance.
For the clinical-data validation, ten low-dose [$^{18}$F]FDG datasets and one
[$^{18}$F]Florbetapir dataset were tested on a model pretrained on data from
another tracer. Experiment results show that the proposed PET reconstruction
method can generalize robustly across tracer distributions and scanner types,
providing an efficient and versatile reconstruction framework for low-dose PET
imaging.

</details>


### [84] [Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection](https://arxiv.org/abs/2507.15151)
*Sebastian A. Cruz Romero,Wilfredo E. Lugo Beauchamp*

Main category: eess.IV

TL;DR: 该研究利用深度学习模型通过结膜苍白检测贫血，使用MobileNet架构和CP-AnemiC数据集，取得了高准确率，并探索了量化技术对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 传统贫血检测方法成本高且依赖专家知识，限制了早期诊断。研究旨在开发一种低成本、高效的深度学习解决方案。

Method: 采用MobileNet架构，结合数据增强和交叉验证策略，对CP-AnemiC数据集进行端到端微调，并测试不同量化位宽对模型性能的影响。

Result: 模型准确率为0.9313，精确度为0.9374，F1分数为0.9773。FP16量化后性能保持较高，但INT8和INT4量化导致性能显著下降。

Conclusion: 研究支持进一步探索量化方案和硬件优化，以在移动医疗应用中平衡模型大小、推理时间和诊断准确性。

Abstract: Anemia is a widespread global health issue, particularly among young children
in low-resource settings. Traditional methods for anemia detection often
require expensive equipment and expert knowledge, creating barriers to early
and accurate diagnosis. To address these challenges, we explore the use of deep
learning models for detecting anemia through conjunctival pallor, focusing on
the CP-AnemiC dataset, which includes 710 images from children aged 6-59
months. The dataset is annotated with hemoglobin levels, gender, age and other
demographic data, enabling the development of machine learning models for
accurate anemia detection. We use the MobileNet architecture as a backbone,
known for its efficiency in mobile and embedded vision applications, and
fine-tune our model end-to-end using data augmentation techniques and a
cross-validation strategy. Our model implementation achieved an accuracy of
0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong
performance on the dataset. To optimize the model for deployment on edge
devices, we performed post-training quantization, evaluating the impact of
different bit-widths (FP32, FP16, INT8, and INT4) on model performance.
Preliminary results suggest that while FP16 quantization maintains high
accuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive
quantization (INT8 and INT4) leads to significant performance degradation.
Overall, our study supports further exploration of quantization schemes and
hardware optimizations to assess trade-offs between model size, inference time,
and diagnostic accuracy in mobile healthcare applications.

</details>


### [85] [A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT](https://arxiv.org/abs/2507.15193)
*Tanjin Taher Toma,Tejas Sudharshan Mathai,Bikash Santra,Pritam Mukherjee,Jianfei Liu,Wesley Jong,Darwish Alabyad,Vivek Batheja,Abhishek Jha,Mayank Patel,Darko Pucar,Jayadira del Rivero,Karel Pacak,Ronald M. Summers*

Main category: eess.IV

TL;DR: 研究通过引入基于器官特异性解剖先验的多类标注策略，显著提升了深度学习模型对腹部CT中嗜铬细胞瘤的3D分割精度，其中TKA标注策略表现最佳。


<details>
  <summary>Details</summary>
Motivation: 准确分割嗜铬细胞瘤对肿瘤负荷估计、预后和治疗规划至关重要，同时可减少对昂贵基因检测的依赖。

Method: 使用nnU-Net框架评估11种标注策略，引入基于邻近器官的多类解剖先验，并在105例CT扫描上训练和测试。

Result: TKA标注策略在DSC、NSD和F1分数上显著优于传统TB策略，且在不同基因亚型中表现稳健。

Conclusion: 结合相关解剖背景的深度学习模型能实现更精确的嗜铬细胞瘤分割，支持临床评估和长期监测。

Abstract: Accurate segmentation of pheochromocytoma (PCC) in abdominal CT scans is
essential for tumor burden estimation, prognosis, and treatment planning. It
may also help infer genetic clusters, reducing reliance on expensive testing.
This study systematically evaluates anatomical priors to identify
configurations that improve deep learning-based PCC segmentation. We employed
the nnU-Net framework to evaluate eleven annotation strategies for accurate 3D
segmentation of pheochromocytoma, introducing a set of novel multi-class
schemes based on organ-specific anatomical priors. These priors were derived
from adjacent organs commonly surrounding adrenal tumors (e.g., liver, spleen,
kidney, aorta, adrenal gland, and pancreas), and were compared against a broad
body-region prior used in previous work. The framework was trained and tested
on 105 contrast-enhanced CT scans from 91 patients at the NIH Clinical Center.
Performance was measured using Dice Similarity Coefficient (DSC), Normalized
Surface Distance (NSD), and instance-wise F1 score. Among all strategies, the
Tumor + Kidney + Aorta (TKA) annotation achieved the highest segmentation
accuracy, significantly outperforming the previously used Tumor + Body (TB)
annotation across DSC (p = 0.0097), NSD (p = 0.0110), and F1 score (25.84%
improvement at an IoU threshold of 0.5), measured on a 70-30 train-test split.
The TKA model also showed superior tumor burden quantification (R^2 = 0.968)
and strong segmentation across all genetic subtypes. In five-fold
cross-validation, TKA consistently outperformed TB across IoU thresholds (0.1
to 0.5), reinforcing its robustness and generalizability. These findings
highlight the value of incorporating relevant anatomical context in deep
learning models to achieve precise PCC segmentation, supporting clinical
assessment and longitudinal monitoring.

</details>


### [86] [Personalized 3D Myocardial Infarct Geometry Reconstruction from Cine MRI with Explicit Cardiac Motion Modeling](https://arxiv.org/abs/2507.15194)
*Yilin Lyu,Fan Yang,Xiaoyue Liu,Zichen Jiang,Joshua Dillon,Debbie Zhao,Martyn Nash,Charlene Mauger,Alistair Young,Ching-Hui Sia,Mark YY Chan,Lei Li*

Main category: eess.IV

TL;DR: 提出了一种基于2D标准电影MRI的无对比剂高保真3D心肌梗死几何重建框架。


<details>
  <summary>Details</summary>
Motivation: LGE MRI需要对比剂且空间分辨率受限，而现有方法依赖稀疏2D切片，影响精度。

Method: 通过自动深度形状拟合模型重建4D双心室网格，并设计CMotion2Infarct-Net利用动态几何运动模式定位梗死区域。

Result: 在205例患者数据中，与手动分割结果一致。

Conclusion: 证明了无对比剂、心脏运动驱动的3D梗死重建的可行性，为MI数字孪生提供了高效途径。

Abstract: Accurate representation of myocardial infarct geometry is crucial for
patient-specific cardiac modeling in MI patients. While Late gadolinium
enhancement (LGE) MRI is the clinical gold standard for infarct detection, it
requires contrast agents, introducing side effects and patient discomfort.
Moreover, infarct reconstruction from LGE often relies on sparsely sampled 2D
slices, limiting spatial resolution and accuracy. In this work, we propose a
novel framework for automatically reconstructing high-fidelity 3D myocardial
infarct geometry from 2D clinically standard cine MRI, eliminating the need for
contrast agents. Specifically, we first reconstruct the 4D biventricular mesh
from multi-view cine MRIs via an automatic deep shape fitting model, biv-me.
Then, we design a infarction reconstruction model, CMotion2Infarct-Net, to
explicitly utilize the motion patterns within this dynamic geometry to localize
infarct regions. Evaluated on 205 cine MRI scans from 126 MI patients, our
method shows reasonable agreement with manual delineation. This study
demonstrates the feasibility of contrast-free, cardiac motion-driven 3D infarct
reconstruction, paving the way for efficient digital twin of MI.

</details>


### [87] [Personalized 4D Whole Heart Geometry Reconstruction from Cine MRI for Cardiac Digital Twins](https://arxiv.org/abs/2507.15203)
*Xiaoyue Liu,Xicheng Sheng,Xiahai Zhuang,Vicente Grau,Mark YY Chan,Ching-Hui Sia,Lei Li*

Main category: eess.IV

TL;DR: 提出了一种弱监督学习模型，从多视角2D心脏电影MRI直接重建4D心脏网格，为个性化心脏数字孪生提供支持。


<details>
  <summary>Details</summary>
Motivation: 目前全心脏数字孪生模型在模拟所有四个心腔的全器官尺度电机械活动方面仍有限，需要更高效的方法。

Method: 通过自监督映射学习，从多视角2D心脏电影MRI生成4D心脏网格。

Result: 生成的4D心脏网格能自动提取关键心脏变量（如射血分数和动态心腔体积变化），且与输入MRI高度对应。

Conclusion: 该方法展示了从心脏MRI推断个性化4D心脏模型的可行性，为精准医学的高效心脏数字孪生平台铺平道路。

Abstract: Cardiac digital twins (CDTs) provide personalized in-silico cardiac
representations and hold great potential for precision medicine in cardiology.
However, whole-heart CDT models that simulate the full organ-scale
electromechanics of all four heart chambers remain limited. In this work, we
propose a weakly supervised learning model to reconstruct 4D (3D+t) heart mesh
directly from multi-view 2D cardiac cine MRIs. This is achieved by learning a
self-supervised mapping between cine MRIs and 4D cardiac meshes, enabling the
generation of personalized heart models that closely correspond to input cine
MRIs. The resulting 4D heart meshes can facilitate the automatic extraction of
key cardiac variables, including ejection fraction and dynamic chamber volume
changes with high temporal resolution. It demonstrates the feasibility of
inferring personalized 4D heart models from cardiac MRIs, paving the way for an
efficient CDT platform for precision medicine. The code will be publicly
released once the manuscript is accepted.

</details>


### [88] [EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro](https://arxiv.org/abs/2507.15292)
*An Wanga,Rulin Zhou,Mengya Xu,Yiru Ye,Longfei Gou,Yiting Chang,Hao Chen,Chwee Ming Lim,Jiankun Wang,Hongliang Ren*

Main category: eess.IV

TL;DR: EndoControlMag是一种无需训练的、基于拉格朗日的方法，通过掩码条件血管运动放大技术，显著提升内窥镜手术中血管细微运动的可视化效果。


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术中血管细微运动的可视化对手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这一任务极具挑战性。

Method: 提出EndoControlMag框架，包含周期性参考重置（PRR）方案和分层组织感知放大（HTM）框架。PRR通过动态更新参考帧防止误差累积，HTM通过双模式掩码扩张策略（基于运动或距离的软化）适应不同手术场景。

Result: 在EndoVMM24数据集上的实验表明，EndoControlMag在放大精度和视觉质量上显著优于现有方法，且在复杂手术条件下保持鲁棒性。

Conclusion: EndoControlMag为内窥镜手术中的血管运动可视化提供了一种高效且鲁棒的解决方案，具有广泛的应用潜力。

Abstract: Visualizing subtle vascular motions in endoscopic surgery is crucial for
surgical precision and decision-making, yet remains challenging due to the
complex and dynamic nature of surgical scenes. To address this, we introduce
EndoControlMag, a training-free, Lagrangian-based framework with
mask-conditioned vascular motion magnification tailored to endoscopic
environments. Our approach features two key modules: a Periodic Reference
Resetting (PRR) scheme that divides videos into short overlapping clips with
dynamically updated reference frames to prevent error accumulation while
maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification
(HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores
using a pretrained visual tracking model to maintain accurate localization
despite occlusions and view changes. It then applies one of two adaptive
softening strategies to surrounding tissues: motion-based softening that
modulates magnification strength proportional to observed tissue displacement,
or distance-based exponential decay that simulates biomechanical force
attenuation. This dual-mode approach accommodates diverse surgical
scenarios-motion-based softening excels with complex tissue deformations while
distance-based softening provides stability during unreliable optical flow
conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four
different surgery types and various challenging scenarios, including
occlusions, instrument disturbance, view changes, and vessel deformations.
Quantitative metrics, visual assessments, and expert surgeon evaluations
demonstrate that EndoControlMag significantly outperforms existing methods in
both magnification accuracy and visual quality while maintaining robustness
across challenging surgical conditions. The code, dataset, and video results
are available at https://szupc.github.io/EndoControlMag/.

</details>


### [89] [MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis](https://arxiv.org/abs/2507.15340)
*Marc Boubnovski Martell,Kristofer Linton-Reid,Mitchell Chen,Sumeet Hindocha,Benjamin Hunter,Marco A. Calzado,Richard Lee,Joram M. Posma,Eric O. Aboagye*

Main category: eess.IV

TL;DR: TVSRN-V2是一种基于Transformer的超分辨率框架，用于提升低剂量CT图像质量，显著改善肺部疾病诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率CT对胸部疾病诊断至关重要，但受限于辐射剂量和硬件成本，需要一种高效的低剂量CT图像超分辨率方法。

Method: 采用Through-Plane Attention Blocks和Swin Transformer V2构建模型，结合伪低分辨率增强技术提升鲁棒性。

Result: 在肺叶分割、放射组学和预后任务中，TVSRN-V2显著提升了分割精度（+4% Dice）、特征可重复性和预测性能（+0.06 C-index和AUC）。

Conclusion: TVSRN-V2是一种临床可行的系统，能够通过超分辨率技术提升CT图像质量，支持临床决策。

Abstract: High-resolution volumetric computed tomography (CT) is essential for accurate
diagnosis and treatment planning in thoracic diseases; however, it is limited
by radiation dose and hardware costs. We present the Transformer Volumetric
Super-Resolution Network (\textbf{TVSRN-V2}), a transformer-based
super-resolution (SR) framework designed for practical deployment in clinical
lung CT analysis. Built from scalable components, including Through-Plane
Attention Blocks (TAB) and Swin Transformer V2 -- our model effectively
reconstructs fine anatomical details in low-dose CT volumes and integrates
seamlessly with downstream analysis pipelines. We evaluate its effectiveness on
three critical lung cancer tasks -- lobe segmentation, radiomics, and prognosis
-- across multiple clinical cohorts. To enhance robustness across variable
acquisition protocols, we introduce pseudo-low-resolution augmentation,
simulating scanner diversity without requiring private data. TVSRN-V2
demonstrates a significant improvement in segmentation accuracy (+4\% Dice),
higher radiomic feature reproducibility, and enhanced predictive performance
(+0.06 C-index and AUC). These results indicate that SR-driven recovery of
structural detail significantly enhances clinical decision support, positioning
TVSRN-V2 as a well-engineered, clinically viable system for dose-efficient
imaging and quantitative analysis in real-world CT workflows.

</details>


### [90] [Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation](https://arxiv.org/abs/2507.15361)
*Muhammad Aqeel,Maham Nazir,Zanxi Ruan,Francesco Setti*

Main category: eess.IV

TL;DR: SynDiff是一个结合文本引导合成数据生成和高效扩散分割的框架，用于解决医学图像分割中的数据稀缺问题，特别是在息肉检测中。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割（如息肉检测）面临数据稀缺和标注专业性要求高的问题，需要一种高效且临床可行的解决方案。

Method: 使用潜在扩散模型通过文本条件修复生成临床真实的合成息肉，并引入直接潜在估计实现单步推理，显著提升计算效率。

Result: 在CVC-ClinicDB数据集上，SynDiff达到96.0% Dice和92.9% IoU，同时保持实时性能。

Conclusion: SynDiff通过可控的合成数据增强提高了分割的鲁棒性，为资源有限的医疗环境提供了高效解决方案。

Abstract: Medical image segmentation suffers from data scarcity, particularly in polyp
detection where annotation requires specialized expertise. We present SynDiff,
a framework combining text-guided synthetic data generation with efficient
diffusion-based segmentation. Our approach employs latent diffusion models to
generate clinically realistic synthetic polyps through text-conditioned
inpainting, augmenting limited training data with semantically diverse samples.
Unlike traditional diffusion methods requiring iterative denoising, we
introduce direct latent estimation enabling single-step inference with T x
computational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9%
IoU while maintaining real-time capability suitable for clinical deployment.
The framework demonstrates that controlled synthetic augmentation improves
segmentation robustness without distribution shift. SynDiff bridges the gap
between data-hungry deep learning models and clinical constraints, offering an
efficient solution for deployment in resourcelimited medical settings.

</details>


### [91] [A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization](https://arxiv.org/abs/2507.15476)
*Cong Chen,Ming Chen,Hoileong Lee,Yan Li,Jiyang Yu*

Main category: eess.IV

TL;DR: 提出了一种基于YOLOv9s的深度学习框架，结合C3Ghost、SCConv和CARAFE模块，用于提高多尺度钢表面缺陷检测的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂环境中对小目标缺陷检测精度不足且漏检率高，亟需改进。

Method: 结合SCConv模块优化特征表示，C3Ghost模块增强特征提取能力，CARAFE上采样算子精细化重组特征图。

Result: 实验表明，该方法在钢表面缺陷检测中具有更高的准确性和鲁棒性。

Conclusion: 所提框架有效解决了钢表面缺陷检测问题，优于其他方法。

Abstract: Surface defect detection of steel, especially the recognition of multi-scale
defects, has always been a major challenge in industrial manufacturing. Steel
surfaces not only have defects of various sizes and shapes, which limit the
accuracy of traditional image processing and detection methods in complex
environments. However, traditional defect detection methods face issues of
insufficient accuracy and high miss-detection rates when dealing with small
target defects. To address this issue, this study proposes a detection
framework based on deep learning, specifically YOLOv9s, combined with the
C3Ghost module, SCConv module, and CARAFE upsampling operator, to improve
detection accuracy and model performance. First, the SCConv module is used to
reduce feature redundancy and optimize feature representation by reconstructing
the spatial and channel dimensions. Second, the C3Ghost module is introduced to
enhance the model's feature extraction ability by reducing redundant
computations and parameter volume, thereby improving model efficiency. Finally,
the CARAFE upsampling operator, which can more finely reorganize feature maps
in a content-aware manner, optimizes the upsampling process and ensures
detailed restoration of high-resolution defect regions. Experimental results
demonstrate that the proposed model achieves higher accuracy and robustness in
steel surface defect detection tasks compared to other methods, effectively
addressing defect detection problems.

</details>


### [92] [DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification](https://arxiv.org/abs/2507.15487)
*Dezhen Wang,Sheng Miao,Rongxin Chai,Jiufa Cui*

Main category: eess.IV

TL;DR: DeSamba框架通过解耦表示学习和动态融合空间与频谱特征，显著提升了多序列MRI数据的3D病灶分类性能。


<details>
  <summary>Details</summary>
Motivation: 多序列MRI数据在病灶分类中的有效整合仍具挑战性，需要一种能自适应融合空间和频谱特征的解决方案。

Method: 提出DeSamba框架，包含解耦表示学习模块（DRLM）和频谱自适应调制块（SAMB），通过自重建和交叉重建解耦特征，并动态融合空间与频谱信息。

Result: 在两个临床数据集上表现优异，优于现有方法，如脊柱转移数据集上Top-1准确率达62.10%，AUC为87.71%。

Conclusion: DeSamba是一种通用且有效的3D病灶分类解决方案，DRLM和SAMB对性能提升贡献显著。

Abstract: Magnetic Resonance Imaging (MRI) sequences provide rich spatial and frequency
domain information, which is crucial for accurate lesion classification in
medical imaging. However, effectively integrating multi-sequence MRI data for
robust 3D lesion classification remains a challenge. In this paper, we propose
DeSamba (Decoupled Spectral Adaptive Network and Mamba-Based Model), a novel
framework designed to extract decoupled representations and adaptively fuse
spatial and spectral features for lesion classification. DeSamba introduces a
Decoupled Representation Learning Module (DRLM) that decouples features from
different MRI sequences through self-reconstruction and cross-reconstruction,
and a Spectral Adaptive Modulation Block (SAMB) within the proposed SAMNet,
enabling dynamic fusion of spectral and spatial information based on lesion
characteristics. We evaluate DeSamba on two clinically relevant 3D datasets. On
a six-class spinal metastasis dataset (n=1,448), DeSamba achieves 62.10% Top-1
accuracy, 63.62% F1-score, 87.71% AUC, and 93.55% Top-3 accuracy on an external
validation set (n=372), outperforming all state-of-the-art (SOTA) baselines. On
a spondylitis dataset (n=251) involving a challenging binary classification
task, DeSamba achieves 70.00%/64.52% accuracy and 74.75/73.88 AUC on internal
and external validation sets, respectively. Ablation studies demonstrate that
both DRLM and SAMB significantly contribute to overall performance, with over
10% relative improvement compared to the baseline. Our results highlight the
potential of DeSamba as a generalizable and effective solution for 3D lesion
classification in multi-sequence medical imaging.

</details>


### [93] [RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation](https://arxiv.org/abs/2507.15524)
*Simon Winther Albertsen,Hjalte Svaneborg Bjørnstrup,Mostafa Mehdipour Ghazi*

Main category: eess.IV

TL;DR: RARE-UNet是一种分辨率感知的多尺度分割架构，动态适应输入分辨率，提升低分辨率数据的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在低分辨率数据上性能显著下降，限制了临床应用的准确性。

Method: 提出RARE-UNet，包含多尺度块、分辨率感知路由机制和一致性驱动训练。

Result: 在脑部影像任务中，RARE-UNet的平均Dice分数最高（0.84和0.65），且推理时间显著减少。

Conclusion: RARE-UNet在分辨率鲁棒性和效率上表现优异，适用于实际临床场景。

Abstract: Accurate segmentation is crucial for clinical applications, but existing
models often assume fixed, high-resolution inputs and degrade significantly
when faced with lower-resolution data in real-world scenarios. To address this
limitation, we propose RARE-UNet, a resolution-aware multi-scale segmentation
architecture that dynamically adapts its inference path to the spatial
resolution of the input. Central to our design are multi-scale blocks
integrated at multiple encoder depths, a resolution-aware routing mechanism,
and consistency-driven training that aligns multi-resolution features with
full-resolution representations. We evaluate RARE-UNet on two benchmark brain
imaging tasks for hippocampus and tumor segmentation. Compared to standard
UNet, its multi-resolution augmented variant, and nnUNet, our model achieves
the highest average Dice scores of 0.84 and 0.65 across resolution, while
maintaining consistent performance and significantly reduced inference time at
lower resolutions. These results highlight the effectiveness and scalability of
our architecture in achieving resolution-robust segmentation. The codes are
available at: https://github.com/simonsejse/RARE-UNet.

</details>
