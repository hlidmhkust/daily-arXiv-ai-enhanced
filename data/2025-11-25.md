<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 14]
- [eess.SP](#eess.SP) [Total: 25]
- [cs.IT](#cs.IT) [Total: 21]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [SALPA: Spaceborne LiDAR Point Adjustment for Enhanced GEDI Footprint Geolocation](https://arxiv.org/abs/2511.17600)
*Narumasa Tsutsumida,Rei Mitsuhashi,Yoshito Sawada,Akira Kato*

Main category: eess.IV

TL;DR: SALPA是一个用于校正星载LiDAR地理定位误差的多算法优化框架，仅使用全球可用的数字高程模型和大地水准面数据，在复杂地形和平坦地形上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 星载LiDAR系统（如GEDI）的地理定位不确定性（5-15米）会系统性地传播到衍生产品中，影响森林剖面估计和碳储量评估。现有校正方法存在局限性：波形模拟方法需要高分辨率LiDAR数据，而地形方法可能错过连续解空间中的最优解。

Method: SALPA集成三种优化范式（梯度基、进化、群体智能）和五种距离度量，仅使用全球可用的数字高程模型和大地水准面数据，在连续解空间中探索最优地理定位校正。

Result: 在日本复杂地形和法国平坦地形的验证中，SALPA相比原始GEDI位置改进15-16%，相比最先进的GeoGEDI算法改进0.5-2%。L-BFGS-B与基于面积的度量实现最佳精度-效率权衡，群体智能算法在复杂地形中表现优异。

Conclusion: SALPA提供了一个平台无关的通用地理定位校正框架，为可靠的全球森林监测和气候政策决策提供了基础，可轻松适应新兴星载LiDAR任务。

Abstract: Spaceborne Light Detection and Ranging (LiDAR) systems, such as NASA's Global Ecosystem Dynamics Investigation (GEDI), provide forest structure for global carbon assessments. However, geolocation uncertainties (typically 5-15 m) propagate systematically through derived products, undermining forest profile estimates, including carbon stock assessments. Existing correction methods face critical limitations: waveform simulation approaches achieve meter-level accuracy but require high-resolution LiDAR data unavailable in most regions, while terrain-based methods employ deterministic grid searches that may overlook optimal solutions in continuous solution spaces. We present SALPA (Spaceborne LiDAR Point Adjustment), a multi-algorithm optimization framework integrating three optimization paradigms with five distance metrics. Operating exclusively with globally available digital elevation models and geoid data, SALPA explores continuous solution spaces through gradient-based, evolutionary, and swarm intelligence approaches. Validation across contrasting sites: topographically complex Nikko, Japan, and flat Landes, France, demonstrates 15-16% improvements over original GEDI positions and 0.5-2% improvements over the state-of-the-art GeoGEDI algorithm. L-BFGS-B with Area-based metrics achieves optimal accuracy-efficiency trade-offs, while population-based algorithms (genetic algorithms, particle swarm optimization) excel in complex terrain. The platform-agnostic framework facilitates straightforward adaptation to emerging spaceborne LiDAR missions, providing a generalizable foundation for universal geolocation correction essential for reliable global forest monitoring and climate policy decisions.

</details>


### [2] [Reconfigurable, large-format D-ToF/photon-counting SPAD image sensors with embedded FPGA for scene adaptability](https://arxiv.org/abs/2511.17651)
*Tommaso Milanese,Baris Can Efe,Claudio Bruschini,Nobukazu Teranishi,Edoardo Charbon*

Main category: eess.IV

TL;DR: 提出将FPGA集成到SPAD芯片上，直接在像素或簇级别处理时间戳和光子计数，通过查找表实现可编程加权和，降低功耗并简化I/O。


<details>
  <summary>Details</summary>
Motivation: SPAD作为数字光学接口适合原位逻辑处理和事件驱动计算，但通常需要外接FPGA。为了减少功耗和简化接口，提出将FPGA功能集成到芯片上。

Method: 设计基于查找表的可编程加权和架构，分层处理时间戳和光子计数，高效实现人工神经网络的可重编程。

Result: 展示了该方法适用于SPAD系统，能够有效处理光子计数和时间戳数据。

Conclusion: 将FPGA功能集成到SPAD芯片上的方法可行，能够降低系统功耗并简化I/O接口，同时支持神经网络的灵活设计。

Abstract: CMOS-compatible single-photon avalanche diodes (SPADs) have emerged in many systems as the solution of choice for cameras with photon-number resolution and photon counting capabilities. Being natively digital optical interfaces, SPADs are naturally drawn to in situ logic processing and event-driven computation; they are usually coupled to discrete FPGAs to enable reconfigurability. In this work, we propose to bring the FPGA on-chip, in direct contact with the SPADs at pixel or cluster level. To demonstrate the suitability of this approach, we created an architecture for processing timestamps and photon counts using programmable weighted sums based on an efficient use of look-up tables. The outputs are processed hierarchically, similarly to what is done in FPGAs, reducing power consumption and simplifying I/Os. Finally, we show how artificial neural networks can be designed and reprogrammed by using look-up tables in an efficient way.

</details>


### [3] [Robust Detection of Retinal Neovascularization in Widefield Optical Coherence Tomography](https://arxiv.org/abs/2511.17744)
*Jinyi Hao,Jie Wang,Kotaro Tsuboi,Liqin Gao,Tristan T. Hormel,Yukun Guo,An-Lun Wu,Min Gao,Christina J. Flaxel,Steven T. Bailey,Thomas S. Hwang,Yali Jia*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的新方法，用于在广角OCT/OCTA图像上进行视网膜新生血管(RNV)的诊断和分期，将RNV识别重新定义为直接的二元定位任务，在多个设备上取得了优异的诊断和分割性能。


<details>
  <summary>Details</summary>
Motivation: 视网膜新生血管(RNV)是糖尿病视网膜病变中威胁视力的并发症，及时干预可以预防视力丧失。随着广角OCTA成像技术的商业化应用，需要开发能够适应广视野的有效RNV检测和量化算法，而现有算法主要针对窄视野图像优化。

Method: 将RNV识别重新定义为直接的二元定位任务，不依赖传统的多层视网膜分割。使用深度学习模型在589张广角OCT/OCTA扫描上进行训练和验证，扫描范围从17x17-mm到26x21-mm，数据来自多个设备和诊所。

Result: 在RNV诊断方面，设备相关的曲线下面积(AUC)达到0.96到0.99；在分割方面，平均交并比(IOU)达到0.76到0.88。还展示了该方法在纵向监测病变生长方面的能力。

Conclusion: 基于深度学习的广角OCTA图像分析可以为改善RNV筛查和管理提供有价值的手段。

Abstract: Retinal neovascularization (RNV) is a vision threatening development in diabetic retinopathy (DR). Vision loss associated with RNV is preventable with timely intervention, making RNV clinical screening and monitoring a priority. Optical coherence tomography (OCT) angiography (OCTA) provides high-resolution imaging and high-sensitivity detection of RNV lesions. With recent commercial devices introducing widefield OCTA imaging to the clinic, the technology stands to improve early detection of RNV pathology. However, to meet clinical requirements these imaging capabilities must be combined with effective RNV detection and quantification, but existing algorithms for OCTA images are optimized for conventional, i.e. narrow, fields of view. Here, we present a novel approach for RNV diagnosis and staging on widefield OCT/OCTA. Unlike conventional methods dependent on multi-layer retinal segmentation, our model reframes RNV identification as a direct binary localization task. Our fully automated approach was trained and validated on 589 widefield scans (17x17-mm to 26x21-mm) collected from multiple devices at multiple clinics. Our method achieved a device-dependent area under curve (AUC) ranging from 0.96 to 0.99 for RNV diagnosis, and mean intersection over union (IOU) ranging from 0.76 to 0.88 for segmentation. We also demonstrate our method's ability to monitor lesion growth longitudinally. Our results indicate that deep learning-based analysis for widefield OCTA images could offer a valuable means for improving RNV screening and management.

</details>


### [4] [Generative MR Multitasking with complex-harmonic cardiac encoding: Bridging the gap between gated imaging and real-time imaging](https://arxiv.org/abs/2511.17847)
*Xinguo Fang,Anthony G. Christodoulou*

Main category: eess.IV

TL;DR: 开发了一个统一的图像重建框架，通过生成式多任务学习方法将实时和门控心脏MRI整合在一起，使用条件变分自编码器和复谐波心脏坐标来建模心脏运动。


<details>
  <summary>Details</summary>
Motivation: 为了弥合实时和门控心脏MRI之间的差距，包括定量MRI，实现单一自由呼吸、非ECG门控采集即可获得多种成像模式。

Method: 使用条件变分自编码器(CVAE)和复谐波心脏坐标，学习隐式神经时间基和可解释的潜在空间来建模心脏和呼吸运动。心脏运动被建模为复谐波，相位编码时序和潜在振幅捕捉心跳间功能变异性。

Result: 生成式多任务学习提供了灵活的心脏运动表示，能够重建典型的心脏相位分辨电影（类似门控）以及显示心跳间变异性的时间分辨序列（类似实时成像）。在定量映射方面，与传统多任务方法相比，降低了T1和T2的变异系数（T1：0.13 vs 0.31；T2：0.12 vs 0.32；p<0.001），表明更高的信噪比。

Conclusion: 生成式多任务学习使用CVAE和复谐波心脏坐标，在单一自由呼吸、非ECG门控采集内统一了门控和实时心脏MRI，允许灵活的心脏运动表示，抑制轨迹相关伪影，并改善T1和T2映射，为无需单独门控和实时扫描的电影、多对比和定量成像提供了路径。

Abstract: Purpose: To develop a unified image reconstruction framework that bridges real-time and gated cardiac MRI, including quantitative MRI. Methods: We introduce Generative Multitasking, which learns an implicit neural temporal basis from sequence timings and an interpretable latent space for cardiac and respiratory motion. Cardiac motion is modeled as a complex harmonic, with phase encoding timing and a latent amplitude capturing beat-to-beat functional variability, linking cardiac phase-resolved ("gated-like") and time-resolved ("real-time-like") views. We implemented the framework using a conditional variational autoencoder (CVAE) and evaluated it for free-breathing, non-ECG-gated radial GRE in three settings: steady-state cine imaging, multicontrast T2prep/IR imaging, and dual-flip-angle T1/T2 mapping, compared with conventional Multitasking. Results: Generative Multitasking provided flexible cardiac motion representation, enabling reconstruction of archetypal cardiac phase-resolved cines (like gating) as well as time-resolved series that reveal beat-to-beat variability (like real-time imaging). Conditioning on the previous k-space angle and modifying this term at inference removed eddy-current artifacts without globally smoothing high temporal frequencies. For quantitative mapping, Generative Multitasking reduced intraseptal T1 and T2 coefficients of variation compared with conventional Multitasking (T1: 0.13 vs. 0.31; T2: 0.12 vs. 0.32; p<0.001), indicating higher SNR. Conclusion: Generative Multitasking uses a CVAE with complex harmonic cardiac coordinates to unify gated and real-time CMR within a single free-breathing, non-ECG-gated acquisition. It allows flexible cardiac motion representation, suppresses trajectory-dependent artifacts, and improves T1 and T2 mapping, suggesting a path toward cine, multicontrast, and quantitative imaging without separate gated and real-time scans.

</details>


### [5] [A Versatile Optical Frontend for Multicolor Fluorescence Imaging with Miniaturized Lensless Sensors](https://arxiv.org/abs/2511.17860)
*Lukas Harris,Micah Roschelle,Jack Bartley,Mekhail Anwar*

Main category: eess.IV

TL;DR: 本文提出了一种使用光纤板（FOP）的无透镜荧光成像光学前端设计，通过优化FOP的数值孔径来平衡收集效率与分辨率，解决了传统薄膜干涉滤光片对入射角敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 无透镜成像在体内成像和低成本即时诊断应用中具有优势，但传统薄膜干涉滤光片对入射角敏感，限制了其在无透镜系统中的应用。需要一种角度不敏感的滤光方案来有效阻挡激发光同时通过荧光发射。

Method: 使用光纤板（FOP）吸收离轴光线，同时在FOP两侧放置滤光片。通过模拟分析FOP数值孔径（NA）的设计权衡，优化了两种光学前端设计：高NA（45.7° FWHM）和低NA（8.3° FWHM）。

Result: 高NA设计（520μm厚度）的荧光灵敏度提高了59倍，分辨率仅下降3.2倍；低NA设计在1mm工作距离下实现了110μm分辨率的三色荧光成像。实验证明需要在FOP两侧放置滤光片以实现角度不敏感性。

Conclusion: 开发了一种多功能光学前端，适用于不同荧光团、照明配置和无透镜成像技术，为各种应用提供了灵活的解决方案。

Abstract: Lensless imaging enables exceptionally compact fluorescence sensors, advancing applications in \textit{in vivo} imaging and low-cost, point-of-care diagnostics. These sensors require a filter to block the excitation light while passing fluorescent emissions. However, conventional thin-film interference filters are sensitive to angle of incidence (AOI), complicating their use in lensless systems. Here we thoroughly analyze and optimize a technique using a fiber optic plate (FOP) to absorb off-axis light that would bleed through the interference filter while improving image resolution. Through simulations, we show that the numerical aperture (NA) of the FOP drives inherent design tradeoffs: collection efficiency improves rapidly with a higher NA, but at the cost of resolution, increased device thickness, and fluorescence excitation efficiency. To illustrate this, we optimize two optical frontends with full-width at half maximums (FWHMs) of 8.3° and 45.7°. Implementing these designs, we show that angle-insensitivity requires filters on both sides of the FOP, due to scattering. In imaging experiments, the 520-$μ$m-thick high-NA design is 59$\times$ more sensitive to fluorescence while only degrading resolution by 3.2$\times$. Alternatively, the low-NA design is capable of three-color fluorescence imaging with 110-$μ$m resolution at a 1-mm working distance. Overall, we demonstrate a versatile optical frontend that is adaptable to a range of applications using different fluorophores, illumination configurations, and lensless imaging techniques.

</details>


### [6] [INT-DTT+: Low-Complexity Data-Dependent Transforms for Video Coding](https://arxiv.org/abs/2511.17867)
*Samuel Fernández-Menduiña,Eduardo Pavez,Antonio Ortega,Tsung-Wei Huang,Thuong Nguyen Canh,Guan-Ming Su,Peng Yin*

Main category: eess.IV

TL;DR: 提出了一种低复杂度数据相关变换框架DTT+，通过秩一更新DTT图构建GBST，并开发整数近似INT-DTT+，在VVC标准中实现超过3%的BD-rate节省，复杂度与整数DCT-2相当。


<details>
  <summary>Details</summary>
Motivation: 传统离散三角变换(DTT)在视频编码中平衡了编码性能和计算效率，但数据相关变换如KLT和GBST虽然能量压缩更好，却缺乏可降低计算复杂度的对称性。本文旨在弥合这一差距。

Method: 基于DTT+框架，通过秩一更新DTT图构建GBST；提出图学习算法联合估计行列图的秩一更新；利用DTT+的渐进结构将核分解为基础DTT和结构化柯西矩阵；结合低复杂度整数DTT和稀疏化柯西矩阵构建INT-DTT+。

Result: 在VVC标准的多变换选择框架中，INT-DTT+相比VVC MTS基线实现了超过3%的BD-rate节省，且一旦基础DTT系数可用，其复杂度与整数DCT-2相当。

Conclusion: DTT+框架成功弥合了数据相关变换和低复杂度变换之间的差距，INT-DTT+在保持接近KLT性能的同时显著降低了计算和内存复杂度，为视频编码提供了高效的数据相关变换方案。

Abstract: Discrete trigonometric transforms (DTTs), such as the DCT-2 and the DST-7, are widely used in video codecs for their balance between coding performance and computational efficiency. In contrast, data-dependent transforms, such as the Karhunen-Loève transform (KLT) and graph-based separable transforms (GBSTs), offer better energy compaction but lack symmetries that can be exploited to reduce computational complexity. This paper bridges this gap by introducing a general framework to design low-complexity data-dependent transforms. Our approach builds on DTT+, a family of GBSTs derived from rank-one updates of the DTT graphs, which can adapt to signal statistics while retaining a structure amenable to fast computation. We first propose a graph learning algorithm for DTT+ that estimates the rank-one updates for rows and column graphs jointly, capturing the statistical properties of the overall block. Then, we exploit the progressive structure of DTT+ to decompose the kernel into a base DTT and a structured Cauchy matrix. By leveraging low-complexity integer DTTs and sparsifying the Cauchy matrix, we construct an integer approximation to DTT+, termed INT-DTT+. This approximation significantly reduces both computational and memory complexities with respect to the separable KLT with minimal performance loss. We validate our approach in the context of mode-dependent transforms for the VVC standard, following a rate-distortion optimized transform (RDOT) design approach. Integrated into the explicit multiple transform selection (MTS) framework of VVC in a rate-distortion optimization setup, INT-DTT+ achieves more than 3% BD-rate savings over the VVC MTS baseline, with complexity comparable to the integer DCT-2 once the base DTT coefficients are available.

</details>


### [7] [TransLK-Net: Entangling Transformer and Large Kernel for Progressive and Collaborative Feature Encoding and Decoding in Medical Image Segmentation](https://arxiv.org/abs/2511.17873)
*Jin Yang,Daniel S. Marcus,Aristeidis Sotiras*

Main category: eess.IV

TL;DR: 提出了TransLK-Net网络，通过PTLK和CTLK模块结合自注意力和大核卷积的优势，解决CNN和ViT在医学图像分割中的局限性，实现高效的局部和全局特征建模。


<details>
  <summary>Details</summary>
Motivation: CNN受限于固定大小核无法捕捉多尺度特征和全局上下文信息，ViT缺乏空间局部信息建模能力且计算复杂度高，需要结合两者优势解决医学图像分割的挑战。

Method: 提出PTLK和CTLK模块，使用多头大核卷积捕捉多尺度局部特征，高效分解自注意力建模全局信息，通过注意力纠缠机制实现局部和全局特征的渐进式和协作式增强。还提出AG-MLP模块增强MLP的空间建模能力，构建CED解码块进行特征融合。

Result: 构建了TransLK-Net网络，采用编码器-解码器架构，编码器使用层次化ViT架构整合PTLK、CTLK和AG-MLP，解码器使用CED块。

Conclusion: TransLK-Net有效结合了自注意力和大核卷积的优势，克服了CNN和ViT在医学图像分割中的固有局限性，实现了高效的局部和全局特征建模。

Abstract: Convolutional neural networks (CNNs) and vision transformers (ViTs) are widely employed for medical image segmentation, but they are still challenged by their intrinsic characteristics. CNNs are limited from capturing varying-scaled features and global contextual information due to the employment of fixed-sized kernels. In contrast, ViTs employ self-attention and MLP for global information modeling, but they lack mechanisms to learn spatial-wise local information. Additionally, self-attention leads the network to show high computational complexity. To tackle these limitations, we propose Progressively Entangled Transformer Large Kernel (PTLK) and Collaboratively Entangled Transformer Large Kernel (CTLK) modules to leverage the benefits of self-attention and large kernel convolutions and overcome shortcomings. Specifically, PTLK and CTLK modules employ the Multi-head Large Kernel to capture multi-scale local features and the Efficient Decomposed Self-attention to model global information efficiently. Subsequently, they employ the Attention Entanglement mechanism to enable local and global features to enhance and calibrate each other progressively and collaboratively. Additionally, an Attention-gated Channel MLP (AG-MLP) module is proposed to equip the standard MLP module with the capabilities of modeling spatial information. PTLK and CTLK modules are further incorporated as a Cross Entanglement Decoding (CED) block for efficient feature fusion and decoding. Finally, we propose a novel network for volumetric medical image segmentation that employs an encoder-decoder architecture, termed TransLK-Net. The encoder employs a hierarchical ViT architecture whose block is built by incorporating PTLK and CTLK with AG-MLP into a ViT block, and the decoder employs the CED block.

</details>


### [8] [Spectral Super-Resolution Neural Operator with Atmospheric Radiative Transfer Prior](https://arxiv.org/abs/2511.17895)
*Ziye Zhang,Bin Pan,Zhenwei Shi*

Main category: eess.IV

TL;DR: 提出SSRNO框架，将大气辐射传输先验融入数据驱动的光谱超分辨率方法，实现更物理一致的高光谱图像重建


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法忽视物理原理，导致大气影响波段的光谱重建不真实，需要结合物理先验提高重建质量

Method: 三阶段框架：上采样（利用先验信息扩展多光谱输入）、重建（神经算子学习连续光谱映射）、精炼（硬约束消除颜色失真），采用GMP方法和U形SAC层

Result: 实验验证了方法的有效性和泛化能力，实现了连续光谱重建和零样本外推

Conclusion: SSRNO通过结合物理先验和数据驱动方法，成功解决了光谱超分辨率中的物理一致性问题

Abstract: Spectral super-resolution (SSR) aims to reconstruct hyperspectral images (HSIs) from multispectral observations, with broad applications in remote sensing. Data-driven methods are widely used, but they often overlook physical principles, leading to unrealistic spectra, particularly in atmosphere-affected bands. To address this challenge, we propose the Spectral Super-Resolution Neural Operator (SSRNO), which incorporates atmospheric radiative transfer (ART) prior into the data-driven procedure, yielding more physically consistent predictions. The proposed SSRNO framework consists of three stages: upsampling, reconstruction, and refinement. In the upsampling stage, we leverage prior information to expand the input multispectral image, producing a physically plausible hyperspectral estimate. Subsequently, we utilize a neural operator in the reconstruction stage to learn a continuous mapping across the spectral domain. Finally, the refinement stage imposes a hard constraint on the output HSI to eliminate color distortion. The upsampling and refinement stages are implemented via the proposed guidance matrix projection (GMP) method, and the reconstruction neural operator adopts U-shaped spectral-aware convolution (SAC) layers to capture multi-scale features. Moreover, we theoretically demonstrate the optimality of the GMP method. With the neural operator and ART priors, SSRNO also achieves continuous spectral reconstruction and zero-shot extrapolation. Various experiments validate the effectiveness and generalization ability of the proposed approach.

</details>


### [9] [Diverse Instance Generation via Diffusion Models for Enhanced Few-Shot Object Detection in Remote Sensing Images](https://arxiv.org/abs/2511.18031)
*Yanxing Liu,Jiancheng Pan,Jianwei Yang,Tiancheng Chen,Peiling Zhou,Bingchen Zhang*

Main category: eess.IV

TL;DR: 提出了一种利用扩散模型生成多样化遥感图像实例来提升少样本目标检测性能的新框架，通过切片生成和语义对齐实现数据增强。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像少样本目标检测中实例多样性不足的问题，特别是在濒危物种监测和灾害评估等应用中。

Method: 使用预训练扩散模型生成实例级切片，通过切片到切片模块和图像反演模块适配遥感场景，引入对比损失进行语义对齐。

Result: 在多个数据集和不同方法上平均性能提升4.4%，反演模块和对比损失均能有效提升检测性能。

Conclusion: 该框架能有效利用扩散模型增强遥感图像实例多样性，显著提升少样本目标检测性能。

Abstract: Few-shot object detection (FSOD) aims to detect novel instances with only a limited number of labeled training samples, presenting a challenge that is particularly prominent in numerous remote sensing applications such as endangered species monitoring and disaster assessment. Existing FSOD methods for remote sensing images (RSIs) have achieved promising progress but remain constrained by the limited diversity of instances. To address this issue, we propose a novel framework that can leverage a diffusion model pretrained on large-scale natural images to synthesize diverse remote sensing instances, thereby improving the performance of few-shot object detectors. Instead of directly synthesizing complete remote sensing images, we first generate instance-level slices via a specialized slice-to-slice module, and then embed these slices into full-scale imagery for enhanced data augmentation. To further adapt diffusion models for remote sensing scenarios, we develop a class-agnostic image inversion module that can invert remote sensing instance slices into semantic space. Additionally, we introduce contrastive loss to semantically align the synthesized images with their corresponding classes. Experimental results show that our method hasachieved an average performance improvement of 4.4% across multiple datasets and various approaches. Ablation experiments indicate that the elaborately designed inversion module can effectively enhance the performance of FSOD methods, and the semantic contrastive loss can further boost the performance.

</details>


### [10] [Linear Algebraic Approaches to Neuroimaging Data Compression: A Comparative Analysis of Matrix and Tensor Decomposition Methods for High-Dimensional Medical Images](https://arxiv.org/abs/2511.18197)
*Jaeho Kim,Daniel David,Ana Vizitiv*

Main category: eess.IV

TL;DR: 比较Tucker分解和SVD在神经影像数据压缩中的表现，Tucker分解在保持多维关系方面更优，而SVD在极端压缩时表现更好但牺牲保真度。


<details>
  <summary>Details</summary>
Motivation: 评估不同分解方法在神经影像数据压缩中的效果，寻找最适合保持数据结构和时间关系的方法。

Method: 使用Tucker分解和奇异值分解(SVD)对神经影像数据进行压缩，比较两种方法的性能。

Result: Tucker分解在重建保真度和感知相似性方面表现更优，能更好地保持多维关系；SVD在极端压缩情况下表现更好但牺牲了保真度。

Conclusion: Tucker分解更适合需要保持结构和时间关系的应用场景。

Abstract: This paper evaluates Tucker decomposition and Singular Value Decomposition (SVD) for compressing neuroimaging data. Tucker decomposition preserves multi-dimensional relationships, achieving superior reconstruction fidelity and perceptual similarity. SVD excels in extreme compression but sacrifices fidelity. The results highlight Tucker decomposition's suitability for applications requiring the preservation of structural and temporal relationships.

</details>


### [11] [Shape-Adapting Gated Experts: Dynamic Expert Routing for Colonoscopic Lesion Segmentation](https://arxiv.org/abs/2511.18493)
*Gia Huy Thai,Hoang-Nguyen Vu,Anh-Minh Phan,Quang-Thinh Ly,Tram Dinh,Thi-Ngoc-Truc Nguyen,Nhat Ho*

Main category: eess.IV

TL;DR: 提出SAGE框架，通过动态专家路由解决WSI中细胞异质性带来的挑战，在三个医学基准测试中达到最先进的分割性能。


<details>
  <summary>Details</summary>
Motivation: 细胞尺度和形态的多样性是WSI癌症检测的主要挑战，现有CNN-Transformer混合模型采用静态计算图导致计算冗余且无法适应输入变化。

Method: SAGE框架将静态骨干网络重构为动态路由的专家架构，采用双路径设计：骨干流保持表示，专家路径通过分层门控选择性激活，在共享和专用专家间进行两级分层选择。

Result: 在EBHI、DigestPath和GlaS三个医学基准测试中分别达到95.57%、95.16%和94.17%的Dice分数，实现最先进的分割性能。

Conclusion: SAGE为动态专家路由提供了可扩展基础，通过自适应平衡局部细化和全局上下文，实现了灵活的视觉推理和跨领域鲁棒泛化。

Abstract: The substantial diversity in cell scale and form remains a primary challenge in computer-aided cancer detection on gigapixel Whole Slide Images (WSIs), attributable to cellular heterogeneity. Existing CNN-Transformer hybrids rely on static computation graphs with fixed routing, which consequently causes redundant computation and limits their adaptability to input variability. We propose Shape-Adapting Gated Experts (SAGE), an input-adaptive framework that enables dynamic expert routing in heterogeneous visual networks. SAGE reconfigures static backbones into dynamically routed expert architectures. SAGE's dual-path design features a backbone stream that preserves representation and selectively activates an expert path through hierarchical gating. This gating mechanism operates at multiple hierarchical levels, performing a two-level, hierarchical selection between shared and specialized experts to modulate model logits for Top-K activation. Our Shape-Adapting Hub (SA-Hub) harmonizes structural and semantic representations across the CNN and the Transformer module, effectively bridging diverse modules. Embodied as SAGE-UNet, our model achieves superior segmentation on three medical benchmarks: EBHI, DigestPath, and GlaS, yielding state-of-the-art Dice Scores of 95.57%, 95.16%, and 94.17%, respectively, and robustly generalizes across domains by adaptively balancing local refinement and global context. SAGE provides a scalable foundation for dynamic expert routing, enabling flexible visual reasoning.

</details>


### [12] [Equivariant Deep Equilibrium Models for Imaging Inverse Problems](https://arxiv.org/abs/2511.18667)
*Alexander Mehta,Ruangrawee Kitichotkul,Vivek K Goyal,Julián Tachella*

Main category: eess.IV

TL;DR: 本文提出了一种模块化实现反向传播的方法，用于训练具有复杂等变成像损失的深度平衡模型，简化了训练过程并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 深度平衡模型（DEQs）是一类强大的神经网络，其输出是学习算子的固定点。然而，在训练具有复杂等变成像损失的DEQs时，需要通过固定点计算进行隐式微分，其实现具有挑战性。

Method: 展示了反向传播可以模块化实现，简化了训练过程。通过隐式微分训练DEQs，并与Jacobian-free反向传播和其他基线方法进行比较。

Result: 实验表明，使用隐式微分训练的DEQs在性能上优于使用Jacobian-free反向传播和其他基线方法训练的模型。

Conclusion: 研究发现，等变成像训练的DEQs近似于不变先验的近端映射，这为理解其工作机制提供了理论依据。

Abstract: Equivariant imaging (EI) enables training signal reconstruction models without requiring ground truth data by leveraging signal symmetries. Deep equilibrium models (DEQs) are a powerful class of neural networks where the output is a fixed point of a learned operator. However, training DEQs with complex EI losses requires implicit differentiation through fixed-point computations, whose implementation can be challenging. We show that backpropagation can be implemented modularly, simplifying training. Experiments demonstrate that DEQs trained with implicit differentiation outperform those trained with Jacobian-free backpropagation and other baseline methods. Additionally, we find evidence that EI-trained DEQs approximate the proximal map of an invariant prior.

</details>


### [13] [Evaluation of Hardware-based Video Encoders on Modern GPUs for UHD Live-Streaming](https://arxiv.org/abs/2511.18686)
*Kasidis Arunruangsirilert,Jiro Katto*

Main category: eess.IV

TL;DR: 评估多代NVIDIA、Intel GPU和Qualcomm Snapdragon移动SoC中硬件视频编码器的率失真性能、编码速度和功耗，并与软件编码器对比，包括最新的H.266/VVC编解码器。


<details>
  <summary>Details</summary>
Motivation: 随着VTuber、游戏直播和现场活动等实时视频内容的兴起，对GPU中高效硬件编码器的需求增加，特别是处理4K/8K超高清分辨率。

Method: 使用PSNR、SSIM和基于机器学习的VMAF等多种指标，评估硬件编码器的率失真性能、编码速度和功耗。

Result: 现代GPU硬件编码器在实时编码场景中能与软件编码器的率失真性能相匹配；新硬件的编码速度有所提升，但硬件代际间的率失真性能改进大多可以忽略。

Conclusion: 计算了每个硬件编码器匹配YouTube转码质量所需的比特率，硬件编码器在实时场景下表现良好，但代际性能提升有限。

Abstract: Many GPUs have incorporated hardware-accelerated video encoders, which allow video encoding tasks to be offloaded from the main CPU and provide higher power efficiency. Over the years, many new video codecs such as H.265/HEVC, VP9, and AV1 were added to the latest GPU boards. Recently, the rise of live video content such as VTuber, game live-streaming, and live event broadcasts, drives the demand for high-efficiency hardware encoders in the GPUs to tackle these real-time video encoding tasks, especially at higher resolutions such as 4K/8K UHD. In this paper, RD performance, encoding speed, as well as power consumption of hardware encoders in several generations of NVIDIA, Intel GPUs as well as Qualcomm Snapdragon Mobile SoCs were evaluated and compared to the software counterparts, including the latest H.266/VVC codec, using several metrics including PSNR, SSIM, and machine-learning based VMAF. The results show that modern GPU hardware encoders can match the RD performance of software encoders in real-time encoding scenarios, and while encoding speed increased in newer hardware, there is mostly negligible RD performance improvement between hardware generations. Finally, the bitrate required for each hardware encoder to match YouTube transcoding quality was also calculated.

</details>


### [14] [Neural B-Frame Coding: Tackling Domain Shift Issues with Lightweight Online Motion Resolution Adaptation](https://arxiv.org/abs/2511.18724)
*Sang NguyenQuang,Xiem HoangVan,Wen-Hsiao Peng*

Main category: eess.IV

TL;DR: 提出了轻量级分类器来预测下采样因子，解决B帧编解码器中因训练和测试GOP大小不匹配导致的域偏移问题，在保持编码性能的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 分层时间预测的B帧编解码器由于训练和测试时GOP大小不匹配存在域偏移问题，导致大运动估计不准确。传统方法通过下采样将大运动转为小运动，但确定最优下采样因子需要昂贵的率失真优化。

Method: 提出了三种轻量级分类器变体：1) 使用Focal Loss训练的二分类器选择高低分辨率；2) 基于率失真成本软标签训练的多分类器；3) 结合多分类器预测能力和二分类器选择性搜索的协同分类器。所有方法都无需重新训练编解码器。

Result: 实验结果表明，这些方法在保持与穷举搜索方法相当的编码性能的同时，显著降低了计算复杂度。

Conclusion: 提出的轻量级分类器方法有效解决了B帧编解码器的域偏移问题，在编码性能和计算效率之间取得了良好平衡。

Abstract: Learned B-frame codecs with hierarchical temporal prediction often encounter the domain-shift issue due to mismatches between the Group-of-Pictures (GOP) sizes for training and testing, leading to inaccurate motion estimates, particularly for large motion. A common solution is to turn large motion into small motion by downsampling video frames during motion estimation. However, determining the optimal downsampling factor typically requires costly rate-distortion optimization. This work introduces lightweight classifiers to predict downsampling factors. These classifiers leverage simple state signals from current and reference frames to balance rate-distortion performance with computational cost. Three variants are proposed: (1) a binary classifier (Bi-Class) trained with Focal Loss to choose between high and low resolutions, (2) a multi-class classifier (Mu-Class) trained with novel soft labels based on rate-distortion costs, and (3) a co-class approach (Co-Class) that combines the predictive capability of the multi-class classifier with the selective search of the binary classifier. All classifier methods can work seamlessly with existing B-frame codecs without requiring codec retraining. Experimental results show that they achieve coding performance comparable to exhaustive search methods while significantly reducing computational complexity. The code is available at: https://github.com/NYCU-MAPL/Fast-OMRA.git.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [15] [SYNAPSE: Synergizing an Adapter and Finetuning for High-Fidelity EEG Synthesis from a CLIP-Aligned Encoder](https://arxiv.org/abs/2511.17547)
*Jeyoung Lee,Hochul Kang*

Main category: eess.SP

TL;DR: SYNAPSE是一个两阶段框架，通过CLIP对齐的EEG自编码器学习语义结构化的潜在表示，然后与轻量化的Stable Diffusion结合，实现从脑电图信号到高质量图像的生成。


<details>
  <summary>Details</summary>
Motivation: 将扩散生成模型扩展到脑信号可以加深对人类感知和心理表征的理解，但EEG信号存在高噪声、低空间分辨率和强个体间变异性的挑战。现有方法通常需要复杂对齐或分类流程，参数量大且可解释性有限。

Method: 两阶段框架：第一阶段使用CLIP对齐的EEG自编码器学习语义结构化潜在表示；第二阶段冻结预训练编码器，与轻量化Stable Diffusion集成，以最小可训练参数实现EEG特征的条件生成。

Result: 在CVPR40数据集上实现了语义一致的潜在空间和最先进的感知保真度，在重建效率和图像质量方面优于现有EEG到图像模型，能有效跨主体泛化并保持视觉语义。

Conclusion: 重建大脑感知的内容而非分类的内容，是实现忠实EEG图像生成的关键。

Abstract: Recent progress in diffusion-based generative models has enabled high-quality image synthesis conditioned on diverse modalities. Extending such models to brain signals could deepen our understanding of human perception and mental representations. However,electroencephalography (EEG) presents major challenges for image generation due to high noise, low spatial resolution, and strong inter-subject variability. Existing approaches,such as DreamDiffusion, BrainVis, and GWIT, primarily adapt EEG features to pre-trained Stable Diffusion models using complex alignment or classification pipelines, often resulting in large parameter counts and limited interpretability. We introduce SYNAPSE, a two-stage framework that bridges EEG signal representation learning and high-fidelity image synthesis. In Stage1, a CLIP-aligned EEG autoencoder learns a semantically structured latent representation by combining signal reconstruction and cross-modal alignment objectives. In Stage2, the pretrained encoder is frozen and integrated with a lightweight adaptation of Stable Diffusion, enabling efficient conditioning on EEG features with minimal trainable parameters. Our method achieves a semantically coherent latent space and state-of-the-art perceptual fidelity on the CVPR40 dataset, outperforming prior EEG-to-image models in both reconstruction efficiency and image quality. Quantitative and qualitative analyses demonstrate that SYNAPSE generalizes effectively across subjects, preserving visual semantics even when class-level agreement is reduced. These results suggest that reconstructing what the brain perceives, rather than what it classifies, is key to faithful EEG-based image generation.

</details>


### [16] [Semantic-driven Wireless Environment Knowledge Representation for Efficiency-Accuracy Balanced Beam Prediction in Vehicular Networks](https://arxiv.org/abs/2511.17552)
*Jialin Wang,Jianhua Zhang,Yu Li,Yutong Sun,Yuxiang Zhang*

Main category: eess.SP

TL;DR: 提出了PES-WEKBP框架，通过电磁知识蒸馏将原始视觉数据转换为超精简的无线环境知识矩阵，实现高维度压缩和可解释性，在车联网高移动性环境中实现超可靠低延迟通信。


<details>
  <summary>Details</summary>
Motivation: 解决车联网高移动性环境中传统波束预测方法面临的高维输入、训练时间长和可解释性差的问题。

Method: 采用电磁知识蒸馏方法，将原始视觉数据转换为材料与位置相关的无线环境知识矩阵，通过物理信息参数化过程编码传播环境语义，然后使用轻量级决策网络进行低复杂度波束预测。

Result: 实现了99.75%至99.96%的维度压缩，准确率提升5.52%至8.19%，在预测一致性效率指数上优于现有方法。

Conclusion: PES-WEKBP框架在车联网场景中实现了高效可靠的波束预测，平衡了可靠性和计算效率。

Abstract: The rapid evolution of the internet of vehicles demands ultra-reliable low-latency communication in high-mobility environments, where conventional beam prediction methods suffer from high-dimensional inputs, prolonged training times, and limited interpretability. To address these challenges, the propagation environment semantics-aware wireless environment knowledge beam prediction (PES-WEKBP) framework is proposed. PES-WEKBP pioneers a novel electromagnetic (EM)-grounded knowledge distillation method, transforming raw visual data into an ultra-lean, interpretable material and location-related wireless environment knowledge matrix. This matrix explicitly encodes critical propagation environment semantics, which is material EM properties and spatial relationships through a physics-informed parameterization process, distilling the environment and channel interplay into a minimal yet information-dense representation. A lightweight decision network then leverages this highly compressed knowledge for low-complexity beam prediction. To holistically evaluate the performance of PES-WEKBP, we first design the prediction consistency-efficiency index (PCEI), which combines prediction accuracy with a stability-penalized logarithmic training time to ensure a balanced optimization of reliability and computational efficiency. Experiments validate that PES-WEKBP achieves a 99.75% to 99.96% dimension reduction and improves accuracy by 5.52% to 8.19%, which outperforms state-of-the-art methods in PCEI scores across diverse vehicular scenarios.

</details>


### [17] [WaveC2R: Wavelet-Driven Coarse-to-Refined Hierarchical Learning for Radar Retrieval](https://arxiv.org/abs/2511.17558)
*Chunlei Shi,Han Xu,Yinghao Li,Yi-Lin Wei,Yongchao Feng,Yecheng Zhang,Dan Niu*

Main category: eess.SP

TL;DR: WaveC2R是一个基于小波变换的粗到精雷达反演框架，通过频域分解和多源数据融合，分别建模低频降水模式和高频气象边界，显著提升了卫星雷达反演的精度。


<details>
  <summary>Details</summary>
Motivation: 现有卫星雷达反演方法主要依赖单一数据源的简单空间域架构，难以准确捕捉复杂降水模式和锐利气象边界，需要更先进的方法来克服这些限制。

Method: WaveC2R包含两个阶段：1）强度-边界解耦学习，利用小波分解和频域特定损失函数分别优化低频强度和高频边界；2）细节增强扩散细化，采用频域感知条件先验和多源数据逐步增强精细降水结构。

Result: 在SEVIR数据集上的实验表明，WaveC2R在卫星雷达反演中达到了最先进的性能，特别擅长保持高强度降水特征和锐利气象边界。

Conclusion: WaveC2R通过频域分解和多源数据融合，有效解决了现有卫星雷达反演方法的局限性，为复杂降水模式和气象边界的准确捕捉提供了创新解决方案。

Abstract: Satellite-based radar retrieval methods are widely employed to fill coverage gaps in ground-based radar systems, especially in remote areas affected by terrain blockage and limited detection range. Existing methods predominantly rely on overly simplistic spatial-domain architectures constructed from a single data source, limiting their ability to accurately capture complex precipitation patterns and sharply defined meteorological boundaries. To address these limitations, we propose WaveC2R, a novel wavelet-driven coarse-to-refined framework for radar retrieval. WaveC2R integrates complementary multi-source data and leverages frequency-domain decomposition to separately model low-frequency components for capturing precipitation patterns and high-frequency components for delineating sharply defined meteorological boundaries. Specifically, WaveC2R consists of two stages (i)Intensity-Boundary Decoupled Learning, which leverages wavelet decomposition and frequency-specific loss functions to separately optimize low-frequency intensity and high-frequency boundaries; and (ii)Detail-Enhanced Diffusion Refinement, which employs frequency-aware conditional priors and multi-source data to progressively enhance fine-scale precipitation structures while preserving coarse-scale meteorological consistency. Experimental results on the publicly available SEVIR dataset demonstrate that WaveC2R achieves state-of-the-art performance in satellite-based radar retrieval, particularly excelling at preserving high-intensity precipitation features and sharply defined meteorological boundaries.

</details>


### [18] [OFDM-ISAC Beyond CP Limit: Performance Analysis and Mitigation Algorithms](https://arxiv.org/abs/2511.17878)
*Peishi Li,Ming Li,Rang Liu,Qian Liu,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 提出了一个统一的OFDM-ISAC框架，用于解决循环前缀不足导致的干扰问题，并开发了两种标准兼容的连续干扰消除方法。


<details>
  <summary>Details</summary>
Motivation: OFDM的循环前缀通常为通信级多径设计，对于感知应用来说往往不足。当回波超过CP持续时间时，符号间干扰和载波间干扰会破坏子载波正交性并降低感知性能。

Method: 开发了通用的回波模型，捕获了CP不足导致的ISI和ICI结构化耦合。提出了两种标准兼容的SIC方法：低复杂度的SIC-DFT和超分辨率的SIC-ESPRIT。

Result: 在CP不足条件下，两种算法都提供了超过4dB的SINR改进，SIC-ESPRIT将距离/速度均方根误差降低了约一个数量级，接近足够长CP可实现的性能。

Conclusion: 该研究为超越CP限制的可靠长距离OFDM-ISAC感知提供了理论见解和实用解决方案。

Abstract: Orthogonal frequency division multiplexing (OFDM) is well-suited for integrated sensing and communications (ISAC), yet its cyclic prefix (CP) is dimensioned for communications-grade multipath and is generally insufficient for sensing. When echoes exceed the CP duration, inter-symbol and inter-carrier interference (ISI/ICI) break subcarrier orthogonality and degrade sensing. This paper presents a unified analytical and algorithmic framework for OFDM-ISAC beyond the CP limit. We first develop a general echo model that explicitly captures the structured coupling of ISI and ICI caused by CP insufficiency. Building on this model, we derive closed-form expressions for the sensing signal-to-interference-plus-noise ratio (SINR) and the range-Doppler peak sidelobe level ratio (PSLR), both of which are shown to deteriorate approximately linearly with the normalized excess delay beyond the CP. To mitigate these effects, we propose two standard-compatible successive interference cancellation (SIC) methods: SIC-DFT, a low-complexity DFT-based scheme, and SIC-ESPRIT, a super-resolution subspace approach. Simulations corroborate the analysis and demonstrate consistent gains over representative benchmarks. Both algorithms provide more than $4$dB SINR improvement under CP-insufficient conditions, while SIC-ESPRIT reduces range/velocity root-mean-square-errors (RMSE) by about one order of magnitude, approaching the performance achievable with a sufficiently long CP. These results offer both theoretical insight and practical solutions for reliable long-range OFDM-ISAC sensing beyond the CP limit.

</details>


### [19] [On the Performance of Dual-Antenna Repeater Assisted Bi-Static MIMO ISAC](https://arxiv.org/abs/2511.17980)
*Anubhab Chowdhury,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出了中继器辅助的双基地集成感知通信系统中的目标检测与下行数据传输框架，通过中继器增强感知性能并改善通信覆盖，但需权衡感知与通信间的干扰问题。


<details>
  <summary>Details</summary>
Motivation: 中继器作为主动散射体可以即时重传信号，增强目标反射回波从而提升感知性能，同时能够改善下行通信的覆盖漏洞问题。

Method: 设计了一个考虑感知-通信权衡的框架，通过基站精心设计的预编码器来优化系统性能。

Result: 研究发现，在目标热点区域部署中继器可以显著降低目标雷达截面积方差，同时获得更高的检测概率。

Conclusion: 中继器辅助的集成感知通信系统通过精心设计的预编码器可以有效平衡感知与通信性能，在目标热点区域部署中继器能够显著提升系统性能。

Abstract: This paper presents a framework for target detection and downlink data transmission in a repeater-assisted bi-static integrated sensing and communication system. A repeater is an active scatterer that retransmits incoming signals with a complex gain almost instantaneously, thereby enhancing sensing performance by amplifying the echoes reflected by the targets. The same mechanism can also improve downlink communication by mitigating coverage holes. However, the repeater introduces noise and increases interference at the sensing receiver, while also amplifying the interference from target detection signals at the downlink users. The proposed framework accounts for these sensing-communication trade-offs and demonstrates the potential benefits achievable through a carefully designed precoder at the transmitting base station. In particular, our finding is that a higher value of probability of detection can be attained with considerably lower target radar-cross-section variance by deploying repeaters in the target hot-spot areas.

</details>


### [20] [Orthogonal Chirp Delay-Doppler Division Multiplexing (CDDM) Modulation for High Mobility Communications](https://arxiv.org/abs/2511.17991)
*Chaoyuan Bai,Pingzhi Fan,Zhengchun Zhou,Zilong Liu*

Main category: eess.SP

TL;DR: 提出了一种基于正交chirp-Zak变换的多载波调制框架CDDM，在高速移动通信场景中通过在延迟-多普勒域扩展数据符号，实现了低计算复杂度和改进的检测性能。


<details>
  <summary>Details</summary>
Motivation: 针对高速移动通信场景，需要开发能够有效处理时变信道和多普勒频移的调制方案，传统方法在延迟-多普勒域的性能和计算效率有限。

Method: 采用正交chirp-Zak变换在延迟-多普勒域扩展数据符号，提出基于CZT的叠加稀疏导频结构用于同时估计延迟-多普勒偏移和信道系数，并开发嵌入式导频方案。

Result: 仿真结果显示CDDM在完美信道状态信息下相比现有调制方案显著改善了误码率，并具有优越的带外发射性能；在不完美CSI情况下，提出的CZT导频方案显著降低了归一化均方误差，且以更低计算复杂度达到与ODDM相当的估计精度。

Conclusion: CDDM调制方案成功地将chirp波形特性与延迟-多普勒域信道结构协同集成，在高速移动通信中实现了性能提升和计算效率的平衡。

Abstract: This paper proposes a novel multi-carrier modulation framework for high-mobility communication scenarios. Our key idea lies in spreading data symbols across the delay-Doppler (DD) domain through orthogonal chirp-Zak transform (CZT). To enable efficient signal multiplexing, the proposed modulation scheme employs a transmitter signal that maintains orthogonality with the inherent resolution characteristics of the DD plane. Termed as Orthogonal Chirp Delay-Doppler Division Multiplexing (CDDM), we demonstrate a synergistic integration of chirp waveform properties with the channel structure of the DD domain, thereby achieving advantages with both lower computational efficiency and improved detection performance. We introduce a novel CZT-based superimposed sparse pilot structure to enable simultaneous estimation of delay-Doppler shifts and channel coefficients. For enhanced performance, we further develop an embedded pilot scheme that demonstrates channel estimation performance comparable to that of Orthogonal Delay-Doppler Division Multiplexing (ODDM) systems. Simulation results demonstrate that CDDM achieves significant bit error rate (BER) improvements over existing modulation schemes , under perfect channel state information (CSI), as well as superior out-of-band emissions (OOBE). Further, for the imperfect CSI case, the proposed CZT-based superimposed pilot scheme leads to significantly reduced normalized mean square error (NMSE), whilst attaining equivalent estimation accuracy to that of ODDM with lower computational complexity.

</details>


### [21] [Channel Estimation for RIS-Aided MU-MIMO mmWave Systems with Direct Channel Links](https://arxiv.org/abs/2511.18009)
*Taihao Zhang,Zhendong Peng,Cunhua Pan,Hong Ren,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 提出了一种三阶段统一信道估计策略，用于RIS辅助的多用户MIMO毫米波系统，通过精心设计的导频序列和RIS向量配置，有效估计直接信道和级联信道参数。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的MIMO毫米波系统中，存在直接信道和级联信道，传统方法难以准确分离这些信道分量，导致估计性能受限。需要开发能够有效处理直接信道干扰并准确估计级联信道参数的方法。

Method: 三阶段策略：第一阶段通过配置π相位差的RIS向量消除级联信道分量，估计所有用户的直接信道；第二阶段使用正交子空间投影获得等效信号矩阵，估计用户-RIS信道的离开角；第三阶段结合相同导频的时隙信号，通过正交补空间投影去除直接信道分量，利用稀疏性和相关性估计RIS-BS信道的到达角和级联信道剩余参数。

Result: 仿真结果表明，所提方法在估计性能上优于现有方法，能够有效避免直接信道误差传播到级联信道估计中。

Conclusion: 提出的三阶段统一信道估计策略能够有效分离直接信道和级联信道分量，通过精心设计的导频序列和RIS配置，实现了更准确的信道参数估计，为RIS辅助的毫米波系统提供了可靠的信道估计解决方案。

Abstract: In this paper, we propose a three-stage unified channel estimation strategy for reconfigurable intelligent surface (RIS)-aided multi-user (MU) multiple-input multiple-output (MIMO) millimeter wave (mmWave) systems with the existence of the direct channels, where the base station (BS), the users and the RIS are equipped with uniform planar array (UPA). The effectiveness of the developed three-stage strategy stems from the careful design of both the pilot signal sequence of the users and the vectors of RIS. Specifically, in Stage I, the cascaded channel components are eliminated by configuring the RIS phase shift vectors with a π difference to estimate the direct channels for all users. The orthogonal subspace projection is employed in Stage II to obtain equivalent signal matrices, enabling the estimation of angles of departure (AoDs) of the user-RIS channel for all users. In Stage III, we combine the signals of the time slots with the same pilots and project obtained measurement matrix to the orthogonal complement space of the component consisting of the portion of the direct channel, which removes the direct components and thus prevents error propagation from the direct channels to the cascaded channels. Then, we estimate the angles of arrival (AoAs) of the RIS-BS channel and remaining parameters of the cascaded channel for all users by exploiting the sparsity and correlation in the obtained equivalent matrices. Simulation results demonstrate that the proposed method yields better estimation performance than the existing methods.

</details>


### [22] [Precise Localization of High-Voltage Breakdown Events using $φ$-Optical Time-Domain Reflectometry on an Optical Ground Wire](https://arxiv.org/abs/2511.18130)
*Konstantinos Alexoudis,Luke Silvestre,Tom Huiskamp,Jasper Müller,Vincent Sleiffer,Florian Azendorf,Sander Jansen,Chigo Okonkwo,Tom Bradley*

Main category: eess.SP

TL;DR: 使用φ-OTDR技术通过分析高压放电期间背向散射光的相位和频域特征来检测和定位完整的火花间隙击穿，结合示波器记录的事件进行同步分析。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够检测和定位高压放电事件的方法，特别是在长距离链路上实现高空间分辨率的放电监测。

Method: 采用φ-OTDR（相位敏感光时域反射计）技术，分析背向散射光的相位和频域特征，并与示波器记录的高压放电事件同步，测量亚kHz信号以确认放电特征。

Result: 成功检测到清晰的放电特征，并在长链路上实现了约10米空间分辨率的声学重建。

Conclusion: φ-OTDR技术能够有效检测和定位高压放电事件，在长距离监测中提供高空间分辨率的放电特征分析。

Abstract: We present $φ$-OTDR for detecting and localising full spark-gap breakdowns by analysing backscattered light phase and frequency-domain signatures during high-voltage discharges synchronised with oscilloscope-recorded events. Measuring sub-kHz confirms clear discharge signatures and acoustic reconstruction over long links with $\approx$ 10 m spatial resolution.

</details>


### [23] [CT-CFAR A Robust CFAR Detector Based on CLEAN and Truncated Statistics in Sidelobe-Contaminated Environments](https://arxiv.org/abs/2511.18358)
*Jiachen Zhu,Fangjiong Chen,Jie Wu,Ming Xia*

Main category: eess.SP

TL;DR: 提出了一种基于CLEAN概念和截断统计的CFAR目标检测算法，通过截断统计分离目标和噪声分量，引入可学习的历史旁瓣信息，结合Candan算法和最小二乘估计建立目标重建模型，在旁瓣污染等复杂场景下实现高精度目标检测。


<details>
  <summary>Details</summary>
Motivation: 解决传统CFAR算法在参考窗口中由于旁瓣污染和其他异常干扰导致的参考样本非均匀性问题，克服参考窗口的限制，提高在复杂场景下的检测性能。

Method: 使用截断统计分离雷达回波功率谱中的目标和噪声分量，恢复参考窗口的均匀性假设；引入可学习的历史旁瓣信息；基于多通道回波数据，结合Candan算法和最小二乘估计建立目标重建模型，融入CLEAN概念抑制旁瓣干扰。

Result: 蒙特卡洛仿真和实际测量实验表明，CT-CFAR算法无需异常样本的先验知识即可实现高精度目标检测，相比各种CFAR算法，能够准确估计噪声谱，在受旁瓣污染的复杂场景中表现出优越的检测性能和计算效率。

Conclusion: 提出的CT-CFAR算法有效克服了参考窗口的限制，在旁瓣污染等复杂干扰环境下具有优异的检测性能和计算效率，为雷达目标检测提供了有效的解决方案。

Abstract: This paper proposes a constant false alarm rate (CFAR) target detection algorithm based on the CLEAN concept and truncated statistics to mitigate the non-homogeneity of reference samples caused by sidelobe contamination and other abnormal interferences within the reference window. The proposed algorithm employs truncated statistics to separate target and noise components in the radar echo power spectrum, thereby restoring the homogeneity assumption of the reference window. In addition, learnable historical sidelobe information is introduced to enhance the robustness and environmental adaptability of the detection process. Furthermore, based on multichannel echo data, a target reconstruction model that combines the Candan algorithm with least-squares estimation is established, incorporating the CLEAN concept to suppress sidelobe interference. Monte Carlo simulations and real-world measurement experiments demonstrate that the proposed CT-CFAR algorithm achieves high-precision target detection without requiring prior knowledge of abnormal samples. Compared with various CFAR algorithms, the proposed approach overcomes the limitations of the reference window, accurately estimates the noise spectrum, and exhibits superior detection performance and computational efficiency in complex scenarios affected by sidelobe contamination.

</details>


### [24] [BeamCKM: A Framework of Channel Knowledge Map Construction for Multi-Antenna Systems](https://arxiv.org/abs/2511.18376)
*Haohan Wang,Xu Shi,Hengyu Zhang,Yashuai Cao,Sufang Yang,Jintao Wang,Kaibin Huang*

Main category: eess.SP

TL;DR: 本文提出了BeamCKM概念和CKMTransUNet架构，解决传统路径损耗图与多自由度相干波束成形的冲突，通过多模态学习进一步提升地图构建精度。


<details>
  <summary>Details</summary>
Motivation: 现有信道知识图研究主要局限于单天线系统，无法为多天线通信场景提供专门指导，需要解决传统实值路径损耗图与B5G/6G系统中多自由度相干波束成形的内在冲突。

Method: 提出CKMTransUNet架构，结合UNet骨干网络进行多尺度特征提取和视觉变换器模块捕获编码线性向量间的全局依赖关系；进一步提出M3ChanNet方法，利用多模态学习和交叉注意力机制从环境轮廓和实时多波束观测中提取内在侧信息。

Result: 仿真结果表明，所提方法在环境轮廓不准确的情况下仍能持续优于最先进的插值方法和深度学习方法，提供更优越的性能。

Conclusion: BeamCKM和CKMTransUNet架构有效解决了多天线系统中的信道映射问题，通过多模态学习进一步提升了地图构建精度，为B5G/6G系统提供了有效的解决方案。

Abstract: The channel knowledge map (CKM) enables efficient construction of high-fidelity mapping between spatial environments and channel parameters via electromagnetic information analysis. Nevertheless, existing studies are largely confined to single-antenna systems, failing to offer dedicated guidance for multi-antenna communication scenarios. To address the inherent conflict between traditional real-value pathloss map and multi-degree-of-freedom (DoF) coherent beamforming in B5G/6G systems, this paper proposes a novel concept of BeamCKM and CKMTransUNet architecture. The CKMTransUNet approach combines a UNet backbone for multi-scale feature extraction with a vision transformer (ViT) module to capture global dependencies among encoded linear vectors, utilizing a composite loss function to characterize the beam propagation characteristics. Furthermore, based on the CKMTransUNet backbone, this paper presents a methodology named M3ChanNet. It leverages the multi-modal learning technique and cross-attention mechanisms to extract intrinsic side information from environmental profiles and real-time multi-beam observations, thereby further improving the map construction accuracy. Simulation results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) interpolation methods and deep learning (DL) approaches, delivering superior performance even when environmental contours are inaccurate. For reproducibility, the code is publicly accessible at https://github.com/github-whh/BeamCKM.

</details>


### [25] [AutoMAS: A Generic Multi-Agent System for Algorithm Self-Adaptation in Wireless Networks](https://arxiv.org/abs/2511.18414)
*Dingli Yuan,Jingchen Peng,Jie Fan,Boxiang Ren,Lu Yang,Peng Liu*

Main category: eess.SP

TL;DR: AutoMAS是一个通用的多智能体系统，能够根据动态无线环境自主选择最合适的无线优化算法，将理论保证的无线算法与智能体感知能力相结合，为复杂任务提供更可靠的解决方案。


<details>
  <summary>Details</summary>
Motivation: 无线通信环境具有强动态特性，传统无线网络基于静态规则和预定义算法运行，缺乏自适应能力。人工智能的快速发展为无线网络实现更智能化和完全自动化提供了可能。

Method: 提出AutoMAS多智能体系统，结合理论保证的无线算法和智能体感知能力，能够自主选择最适合当前无线环境的优化算法。以信道估计问题为例进行案例研究，移动用户在不同信道传播特性的环境中移动。

Result: 仿真结果表明，AutoMAS在变化场景下能够保证最高的准确率。

Conclusion: AutoMAS可以推广到6G无线网络中，以高精度自主处理各种任务。

Abstract: The wireless communication environment has the characteristic of strong dynamics. Conventional wireless networks operate based on the static rules with predefined algorithms, lacking the self-adaptation ability. The rapid development of artificial intelligence (AI) provides a possibility for wireless networks to become more intelligent and fully automated. As such, we plan to integrate the cognitive capability and high intelligence of the emerging AI agents into wireless networks. In this work, we propose AutoMAS, a generic multi-agent system which can autonomously select the most suitable wireless optimization algorithm according to the dynamic wireless environment. Our AutoMAS combines theoretically guaranteed wireless algorithms with agents' perception ability, thereby providing sounder solutions to complex tasks no matter how the environment changes. As an example, we conduct a case study on the classical channel estimation problem, where the mobile user moves in diverse environments with different channel propagation characteristics. Simulation results demonstrate that our AutoMAS can guarantee the highest accuracy in changing scenarios. Similarly, our AutoMAS can be generalized to autonomously handle various tasks in 6G wireless networks with high accuracy.

</details>


### [26] [A Comparative Study of Rare-Event Simulation Methods for Outage Probability in GSC/MRC Systems under Rician Fading](https://arxiv.org/abs/2511.18419)
*Mahmoud Ghazal,Nadhir Ben Rached,Tareq Al-Naffouri*

Main category: eess.SP

TL;DR: 本文研究了使用增强蒙特卡洛技术评估Rician衰落下SIMO系统的中断概率，比较了多种重要性采样方法，发现CE方法表现最优且最稳健。


<details>
  <summary>Details</summary>
Motivation: 评估SIMO系统在Rician衰落下的中断概率对于无线通信系统设计至关重要，传统蒙特卡洛方法在罕见事件估计中效率低下，需要更高效的重要性采样技术。

Method: 采用了多种增强蒙特卡洛技术：UIS、MLS、ET、CE以及新提出的PIS方法，用于评估GSC/MRC组合的SIMO系统在Rician衰落下的中断概率。

Result: 通过标准效率指标评估，ET、CE和PIS方法表现最佳，其中CE方法在所有方法中展现出最强的稳健性。

Conclusion: 交叉熵（CE）方法在评估SIMO系统中断概率方面是最稳健且高效的蒙特卡洛技术，为无线通信系统性能评估提供了可靠工具。

Abstract: This paper explores the use of enhanced Monte-Carlo (MC) techniques to evaluate the outage probability of single-input-multiple-output (SIMO) systems under Rician fading, in which the input is combined using generalized selection combining with maximum ratio combining (GSC/MRC). The studied set of methods includes previously established methods: universal importance sampling (UIS) and multilevel splitting (MLS), alongside readapted methods: exponential twisting (ET) and cross-entropy (CE), and a novel method introduced here: partition importance sampling (PIS). Performance is assessed across standard efficiency metrics, revealing that ET, CE, and PIS exhibit the best performance. CE is found to be the most robust method among them.

</details>


### [27] [6G Satellite Direct-to-Cell Connectivity: "To distribute, or not to distribute, that is the question"](https://arxiv.org/abs/2511.18455)
*Diego Tuzi,Thomas Delamotte,Andreas Knopp*

Main category: eess.SP

TL;DR: 提出使用小型卫星群替代传统单颗大型卫星，构建分布式虚拟孔径，实现卫星与地面手持设备的直接连接，以降低成本并提高可扩展性和容错性。


<details>
  <summary>Details</summary>
Motivation: 6G需要实现卫星与地面手持设备的直接连接，传统单星方案成本高，希望通过分布式小卫星群降低生产和发射成本，同时获得可扩展性和容错性优势。

Method: 将传统单颗卫星分解为由多个小型平台（如立方星）组成的卫星群，每个平台配备少量辐射单元，通过远距离分布形成大型虚拟孔径。

Result: 该方法有望显著降低生产和发射成本，同时提供可扩展性和故障容忍能力，为6G卫星通信提供新的技术路径。

Conclusion: 分布式小卫星群方案为6G卫星通信提供了有前景的替代方案，但仍需进一步研究解决相关技术挑战以实现可行性。

Abstract: Direct-to-cell connectivity between satellites and common terrestrial handheld devices represents an essential feature of 6G. The industry is considering different type of constellations but using classical single satellite solutions based on phased array antennas. This article proposes to decompose a classical single satellite into a swarm of multiple small platforms (e.g. CubeSats) each equipped with one or a small number of radiating elements. The platforms are spaced far apart to create a large virtual aperture. The use of small satellites promises cost reduction for production and launch, while the distributed nature of the system introduces interesting features, such as scalability and fault tolerance. This perspective article provides insights into the opportunities and a discussion of the research challenges for the feasibility of the proposed approach.

</details>


### [28] [Autoencoder for Position-Assisted Beam Prediction in mmWave ISAC Systems](https://arxiv.org/abs/2511.18594)
*Ahmad A. Aziz El-Banna,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 提出一种轻量级自编码器模型，用于位置辅助的波束预测，相比传统深度全连接神经网络可减少83%的计算复杂度，同时保持相似的预测精度。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信需要精确的波束对准，但传统方法训练开销大。通过结合位置信息可以减少训练开销，但现有方法计算复杂度高。

Method: 设计三层欠完备网络的轻量级自编码器，利用其降维能力来降低训练模型的计算需求。

Result: 仿真结果显示，提出的模型在波束预测精度上与基线方法相似，但计算复杂度降低了83%。

Conclusion: 轻量级自编码器模型能有效解决位置辅助波束预测问题，在保持性能的同时显著降低计算复杂度。

Abstract: Integrated sensing and communication and millimeter wave (mmWave) have emerged as pivotal technologies for 6G networks. However, the narrow nature of mmWave beams requires precise alignments that typically necessitate large training overhead. This overhead can be reduced by incorporating the position information with beam adjustments. This letter proposes a lightweight autorencoder (LAE) model that addresses the position-assisted beam prediction problem while significantly reducing computational complexity compared to the conventional baseline method, i.e., deep fully connected neural network. The proposed LAE is designed as a three-layer undercomplete network to exploit its dimensionality reduction capabilities and thereby mitigate the computational requirements of the trained model. Simulation results show that the proposed model achieves a similar beam prediction accuracy to the baseline with an 83% complexity reduction.

</details>


### [29] [Leveraging Language Models for Interpretable Analysis of Narratives in a Large Corpus](https://arxiv.org/abs/2511.18599)
*Eric A. Bai,Minling Zhou,Ricardo Henao,Kyle M. Schwing,Lawrence Carin*

Main category: eess.SP

TL;DR: 提出了一种可解释的模型，结合词袋主题表示和基于LLM的问答叙事模型，在共享的RKHS空间中量化文档，解决了使用LLM分析大型语料库的成本、可解释性和泛化性问题。


<details>
  <summary>Details</summary>
Motivation: 叙事驱动人类行为并处于地缘政治核心，但一直难以量化其重叠和演变。需要开发能够测量叙事重叠和演变的量化方法。

Method: 集成词袋主题表示和基于LLM的问答叙事模型，共享RKHS表示；推导高效的功能梯度下降更新；引入受Transformer架构启发的上下文问答外推方法。

Result: 开发了可解释的模型，能够在不进行完整推理的情况下分析大型语料库，准确预测未查询文档的问答结果。

Conclusion: 该方法为量化叙事提供了有效工具，解决了LLM在大型语料分析中的关键挑战，具有重要的应用价值。

Abstract: Narratives drive human behavior and lay at the core of geopolitics, but have eluded quantification that would permit measurement of their overlap and evolution. We present an interpretable model that integrates an established bag-of-words (BoW) topical representation and a novel LLM-based question answering (Q&A) narrative model, which share a latent Reproducing Kernel Hilbert Space representation, to quantify written documents. Our approach mitigates the cost, interpretability, and generalization challenges of using a LLM to analyze large corpora without full inference. We derive efficient functional gradient descent updates that are interpretable and structurally analogous to the self-attention mechanism in Transformers. We further introduce an in-context Q&A extrapolation method inspired by Transformer architectures, enabling accurate prediction of Q&A outcomes for unqueried documents.

</details>


### [30] [LLM4AMC: Adapting Large Language Models for Adaptive Modulation and Coding](https://arxiv.org/abs/2511.18690)
*Xinyu Pan,Boxun Liu,Xiang Cheng,Chen Chen*

Main category: eess.SP

TL;DR: 提出了一种基于大语言模型的信道质量预测方法LLM4AMC，用于优化5G NR中的自适应调制编码技术，通过冻结大部分LLM参数并微调来提升信道条件预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统自适应调制编码方法因信道质量指示器老化问题导致性能下降，而大语言模型在上下文理解和时序建模方面的能力与AMC技术的动态信道自适应需求天然契合。

Method: 冻结大部分预训练LLM参数并进行微调，设计了包含预处理层、嵌入层、骨干网络和输出层的四模块网络架构，有效捕捉信道质量的时变特性。

Result: 仿真实验表明，该方法显著提升了链路性能，并展现出实际部署的潜力。

Conclusion: 基于大语言模型的信道质量预测方法LLM4AMC能够有效优化自适应调制编码技术，提高5G NR系统的传输效率和可靠性。

Abstract: Adaptive modulation and coding (AMC) is a key technology in 5G new radio (NR), enabling dynamic link adaptation by balancing transmission efficiency and reliability based on channel conditions. However, traditional methods often suffer from performance degradation due to the aging issues of channel quality indicator (CQI). Recently, the emerging capabilities of large language models (LLMs) in contextual understanding and temporal modeling naturally align with the dynamic channel adaptation requirements of AMC technology. Leveraging pretrained LLMs, we propose a channel quality prediction method empowered by LLMs to optimize AMC, termed LLM4AMC. We freeze most parameters of the LLM and fine-tune it to fully utilize the knowledge acquired during pretraining while better adapting it to the AMC task. We design a network architecture composed of four modules, a preprocessing layer, an embedding layer, a backbone network, and an output layer, effectively capturing the time-varying characteristics of channel quality to achieve accurate predictions of future channel conditions. Simulation experiments demonstrate that our proposed method significantly improves link performance and exhibits potential for practical deployment.

</details>


### [31] [Near-Field Sparse Bayesian Channel Estimation and Tracking for XL-IRS-Aided Wideband mmWave Systems](https://arxiv.org/abs/2511.18752)
*Xiaokun Tuo,Zijian Chen,Ming-Min Zhao,Changsheng You,Min-Jian Zhao*

Main category: eess.SP

TL;DR: 提出了一种基于张量的稀疏信道估计与跟踪算法(TS-CET)，用于XL-IRS辅助的宽带MIMO-OFDM系统，通过利用信道的时空稀疏性来提高估计精度并降低导频开销。


<details>
  <summary>Details</summary>
Motivation: 6G系统中XL-IRS辅助毫米波通信面临信道状态信息获取的挑战，包括近场传播、高维宽带级联信道和IRS的无源特性，现有方法未能充分利用信道固有的时空稀疏性。

Method: 首先提出统一的近场级联信道表示模型，构建分层时空稀疏先验，然后提出TS-CET算法，结合张量正交匹配追踪、基于粒子的变分贝叶斯推理和消息传递。

Result: 仿真结果表明，与现有基准方法相比，TS-CET框架显著提高了估计精度并降低了导频开销。

Conclusion: 所提出的TS-CET算法能有效解决XL-IRS辅助宽带系统中的信道估计挑战，为6G通信系统提供了高效的解决方案。

Abstract: The rapid development of 6G systems demands advanced technologies to boost network capacity and spectral efficiency, particularly in the context of intelligent reflecting surfaces (IRS)-aided millimeter-wave (mmWave) communications. A key challenge here is obtaining accurate channel state information (CSI), especially with extremely large IRS (XL-IRS), due to near-field propagation, high-dimensional wideband cascaded channels, and the passive nature of the XL-IRS. In addition, most existing CSI acquisition methods fail to leverage the spatio-temporal sparsity inherent in the channel, resulting in suboptimal estimation performance. To address these challenges, we consider an XL-IRS-aided wideband multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) system and propose an efficient channel estimation and tracking (CET) algorithm. Specifically, a unified near-field cascaded channel representation model is presented first, and a hierarchical spatio-temporal sparse prior is then constructed to capture two-dimensional (2D) block sparsity in the polar domain, one-dimensional (1D) clustered sparsity in the angle-delay domain, and temporal correlations across different channel estimation frames. Based on these priors, a tensor-based sparse CET (TS-CET) algorithm is proposed that integrates tensor-based orthogonal matching pursuit (OMP) with particle-based variational Bayesian inference (VBI) and message passing. Simulation results demonstrate that the TS-CET framework significantly improves the estimation accuracy and reduces the pilot overhead as compared to existing benchmark methods.

</details>


### [32] [Robust Nonlinear Transform Coding: A Framework for Generalizable Joint Source-Channel Coding](https://arxiv.org/abs/2511.18884)
*Jihun Park,Junyong Shin,Jinsung Park,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 提出了Robust-NTC框架，将变分潜在建模与信道自适应传输结合，通过显式建模潜在分布和信道噪声，实现无需信道特定训练的数字联合源信道编码。


<details>
  <summary>Details</summary>
Motivation: 现有学习型JSCC方法隐式吸收信道变化，缺乏对信道不确定性的显式建模，限制了在实际系统中的适应性和性能稳定性。

Method: 使用变分目标和高斯代理显式建模元素级潜在分布，结合速率-失真优化自适应选择量化器和比特深度，并集成到OFDM系统中联合优化量化、比特分配、调制阶数和功率分配。

Result: 在实用OFDM系统中，Robust-NTC在宽范围SNR条件下相比数字JSCC基线方法实现了更优的速率-失真效率和稳定的重建保真度。

Conclusion: Robust-NTC框架通过显式建模潜在不确定性和信道自适应传输，为实际通信系统提供了高效且鲁棒的数字联合源信道编码解决方案。

Abstract: This paper proposes robust nonlinear transform coding (Robust-NTC), a generalizable digital joint source-channel coding (JSCC) framework that couples variational latent modeling with channel adaptive transmission. Unlike learning-based JSCC methods that implicitly absorb channel variations, Robust-NTC explicitly models element-wise latent distributions via a variational objective with a Gaussian proxy for quantization and channel noise, allowing encoder-decoder to capture latent uncertainty without channel-specific training. Using the learned statistics, Robust-NTC also facilitates rate-distortion optimization to adaptively select element-wise quantizers and bit depths according to online channel condition. To support practical deployment, Robust-NTC is integrated into an orthogonal frequency-division multiplexing (OFDM) system, where a unified resource allocation framework jointly optimizes latent quantization, bit allocation, modulation order, and power allocation to minimize transmission latency while guaranteeing learned distortion targets. Simulation results demonstrate that for practical OFDM systems, Robust-NTC achieves superior rate-distortion efficiency and stable reconstruction fidelity compared to digital JSCC baselines across wide-ranging SNR conditions.

</details>


### [33] [Semi-Passive IRS Enabled Sensing with Group Movable Sensors](https://arxiv.org/abs/2511.18892)
*Qiaoyan Peng,Qingqing Wu,Wen Chen,Guangji Chen,Ying Gao,Lexi Xu,Shaodan Ma*

Main category: eess.SP

TL;DR: 本文研究了半被动智能反射面(IRS)辅助非视距(NLoS)感知系统中的传感器位置选择问题，提出了移动传感器方案以优化Cramer-Rao界(CRB)，并通过理论分析和数值结果验证了其相对于固定位置方案的优越性。


<details>
  <summary>Details</summary>
Motivation: 感知系统性能受到信号衰减和接收组件数量的限制，特别是在NLoS环境中。通过将传感器集成到可移动组中，可以优化传感器位置以提升DoA估计性能。

Method: 考虑IRS由被动元件和主动传感器组成，传感器可接收和处理回波信号进行DoA估计。借鉴可移动天线阵列和流体天线系统思想，将传感器集成到可移动组中，推导相应的CRB，并以闭式形式得到移动传感器位置的最优解。

Result: 推导了CRB与系统参数之间的关系，理论分析和数值结果表明所提出的移动传感器方案在CRB最小化方面优于固定位置方案。

Conclusion: 移动传感器方案能够有效优化传感器位置配置，显著提升半被动IRS辅助NLoS感知系统的DoA估计性能，为实际系统设计提供了理论指导。

Abstract: The performance of the sensing system is limited by the signal attenuation and the number of receiving components. In this letter, we investigate the sensor position selection in a semi-passive intelligent reflecting surface (IRS) enabled non-line-of-sight (NLoS) sensing system. The IRS consists of passive elements and active sensors, where the sensors can receive and process the echo signal for direction-of-arrival (DoA) estimation. Motivated by the movable antenna array and fluid antenna system, we consider the case where the sensors are integrated into a group for movement and derive the corresponding Cramer-Rao bound (CRB). Then, the optimal solution for the positions of the movable sensors (MSs) to the CRB minimization problem is derived in closed form. Moreover, we characterize the relationship between the CRB and system parameters. Theoretical analysis and numerical results are provided to demonstrate the superiority of the proposed MS scheme over the fixed-position (FP) scheme.

</details>


### [34] [Movable-Antenna Array Enhanced Multi-Target Sensing: CRB Characterization and Optimization](https://arxiv.org/abs/2511.18907)
*Haobin Mao,Lipeng Zhu,Wenyan Ma,Zhenyu Xiao,Xiang-Gen Xia,Rui Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于可移动天线阵列的新型无线感知系统，通过优化天线位置来提升多目标空间角度估计性能，相比传统固定天线阵列和单目标优化的可移动天线阵列，在CRB和实际AoA估计MSE方面都取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 可移动天线技术通过灵活调整天线位置，有望提升第六代(6G)网络的无线通信和感知性能。本文旨在利用可移动天线阵列来增强多目标空间角度估计的覆盖性能。

Method: 首先建立多目标到达角估计的Cramér-Rao界矩阵与天线位置的关系，然后通过优化天线位置来最小化CRB矩阵迹的期望值。采用蒙特卡洛方法逼近目标函数，并提出基于群体的梯度下降算法求解优化问题。

Result: 数值结果表明，所提出的基于可移动天线的设计在降低CRB和实际AoA估计均方误差方面，优于传统固定位置天线阵列和单目标优化的可移动天线阵列。

Conclusion: 设计的可移动天线阵列几何结构在角度域中具有低相关性和高有效灵敏度向量功率，显著改善了多目标感知的CRB性能，同时低相关的导向向量有助于减轻角度估计模糊，从而提升MSE性能。

Abstract: Movable antennas (MAs) have emerged as a promising technology to improve wireless communication and sensing performance towards sixth-generation (6G) networks through flexible antenna movement. In this paper, we propose a novel wireless sensing system based on MA arrays to enhance multi-target spatial angle estimation performance. We begin by characterizing the Cramér-Rao bound (CRB) matrix for multi-target angle of arrival (AoA) estimation as a function of the antenna's positions in MA arrays, thereby establishing a theoretical foundation for antenna position optimization. Then, aiming at improving the sensing coverage performance, we formulate an optimization problem to minimize the expectation of the trace of the CRB matrix over random target angles subject to a given distribution by optimizing the antennas' positions. To tackle the formulated challenging optimization problem, the Monte Carlo method is employed to approximate the intractable objective function, and a swarm-based gradient descent algorithm is subsequently proposed to address the approximated problem. In addition, a lower-bound on the sum of CRBs for multi-target AoA estimation is derived. Numerical results demonstrate that the proposed MA-based design achieves superior sensing performance compared to conventional systems using fixed-position antenna (FPA) arrays and single-target-oriented MA arrays, in terms of decreasing both CRB and the actual AoA estimation mean square error (MSE). Fundamentally, the designed MA array geometry exhibits low correlation and high effective power of sensitivity vectors for multi-target sensing in the angular domain, leading to significant CRB performance improvement. The resultant low correlation of steering vectors over multiple targets' directions further helps mitigate angle estimation ambiguity and thus enhances MSE performance.

</details>


### [35] [Adaptive Probabilistic Constellation Shaping based on Enumerative Sphere Shaping for FSO Channel with Turbulence and Pointing Errors](https://arxiv.org/abs/2511.18911)
*Jingtian Liu,Xiongwei Yang,Yi Wei,Jianjun Yu,Feng Zhao*

Main category: eess.SP

TL;DR: 提出了一种基于枚举球形整形的自适应概率星座整形相干系统，用于自由空间光通信，实现了从QPSK到64QAM的连续速率控制，在强湍流和大指向误差下达到99.999%的可靠性。


<details>
  <summary>Details</summary>
Motivation: 自由空间光通信面临大气湍流、指向误差等导致的随机衰减问题，需要自适应速率控制技术来提高频谱利用率和链路可靠性。

Method: 采用枚举球形整形进行分布匹配的自适应概率星座整形系统，使用PCS-64QAM实现连续速率控制。

Result: 系统实现了约0.05 bits/4D的频谱效率粒度和0.1 dB的后FEC SNR阈值粒度，最大控制深度达12.5 dB，在σ_R²=1.39和σ_s=0.5m条件下达到99.999%可靠性。

Conclusion: 基于ESS的A-PCS系统比CCDM系统具有更高的频谱利用率和更精细的控制粒度，能够满足强湍流和大指向误差环境下的可靠性要求。

Abstract: Free-space optical (FSO) transmission enables fast, secure, and efficient next-generation communications with abundant spectrum resources. However, atmospheric turbulence, pointing errors, path loss, and atmospheric loss induce random attenuation, challenging link reliability. Adaptive rate control technology enhances spectrum utilization and reliability. We propose an adaptive probabilistic constellation shaping (A-PCS) coherent system utilizing enumerated spherical shaping (ESS) for distribution matching. With PCS-64QAM, the system achieves continuous rate control from conventional QPSK-equivalent to 64QAM spectral efficiency, providing quasi-continuous control with granularities of approximately $0.05$~bits/4D for spectral efficiency and $0.1$~dB for the post-FEC SNR threshold, and a maximum control depth of $12.5$~dB. Leveraging ESS for efficient sequence utilization, it offers higher spectral utilization and finer control granularity than constant composition DM (CCDM)-based A-PCS systems. We further model and analyze the FSO channel, presenting calculations and comparisons of outage probability and ergodic capacity under varying turbulence intensities and pointing errors. Results demonstrate 99.999~\% reliability at maximum $σ_\mathrm{R}^2 = 1.39$ and $σ_\mathrm{s} = 0.5~\mathrm{m}$, meeting requirements under severe turbulence and large pointing errors.

</details>


### [36] [Development of a Transit-Time Ultrasonic Flow Measurement System for Partially Filled Pipes: Incorporating Flow Profile Correction Factor and Real-Time Clogging Detection](https://arxiv.org/abs/2511.19310)
*Mohammadhadi Mesmarian,Mohammad Mahdi Kharidar,Hossein Nejat Pishkenari*

Main category: eess.SP

TL;DR: 开发了一种能够同时测量流速和液位的超声波流量计，通过流量剖面修正因子(FPCF)显著提高了部分填充管道流量测量的准确性，实验显示最大测量误差从8.51%降至2.44%。


<details>
  <summary>Details</summary>
Motivation: 部分填充管道中的流量测量比完全填充系统更复杂，主要由于截面内复杂的流速分布导致测量不准确，需要开发更精确的测量方法。

Method: 设计开发了超声波流量计，基于流速分布特性推导了流量剖面修正因子(FPCF)，在250mm直径管道中构建专用明渠流量回路进行测试和校准。

Result: 应用FPCF后，最大流量测量误差从8.51%降至2.44%，校准后FWME从1.78%降至0.08%。在堵塞场景下，设备能可靠测量流量并成功检测堵塞。

Conclusion: 所提出的方法有效提高了部分填充管道流量测量的准确性，超声波流量计在堵塞条件下仍能可靠工作并发出警报。

Abstract: Flow measurement in partially filled pipes presents greater complexity compared to fully filled systems, primarily due to the complex velocity distribution within the cross-section, which is a key source of measurement inaccuracy. To address this challenge, an ultrasonic flow meter was designed and developed, capable of simultaneously measuring both flow velocity and fluid level. To improve measurement accuracy, a flow profile correction factor (FPCF) was derived based on the velocity distribution characteristics and applied to the raw flow meter output. A dedicated open-channel flow loop incorporating a 250 mm diameter pipe was constructed to test and calibrate the system under controlled conditions. Flow rates in the loop varied from 2 to 6 liters per second. The accuracy of the flow meter was evaluated using the Flow-Weighted Mean Error (FWME) metric. Experimental results showed that applying the FPCF significantly improved accuracy, reducing the maximum flow measurement error from 8.51% to 2.44%. Furthermore, calibration led to a substantial decrease in FWME from 1.78% to 0.08%, confirming the effectiveness of the proposed methodology. The flow meter was also subjected to clogging scenarios by artificially obstructing the flow. Under these conditions, the device was able to reliably measure the flow and successfully detected the clogging, triggering an alarm to the operator to take necessary action.

</details>


### [37] [Secure Beamforming Design for IRS-ISAC Systems with a Hardware-Efficient Hybrid Beamforming Architecture](https://arxiv.org/abs/2511.19321)
*Weijie Xiong,Zhenglan Zhao,Jingran Lin,Zhiling Xiao,Qiang Li*

Main category: eess.SP

TL;DR: 提出了一种基于硬件效率混合波束成形的IRS辅助ISAC系统，通过联合优化波束成形器和IRS反射系数来最大化通信保密间隙，同时满足波束图相似性和功率约束。


<details>
  <summary>Details</summary>
Motivation: 在IRS辅助的集成感知与通信系统中，需要平衡通信保密性和感知性能，同时考虑硬件成本效率。

Method: 采用惩罚对偶分解(PDD)框架，将雷达约束作为惩罚项加入目标函数，通过闭式解逐步优化模拟/数字波束成形器、IRS反射系数和雷达缩放因子。

Result: 仿真结果表明所提算法有效，IRS-ISAC系统在HB架构下能够很好地平衡性能与硬件成本。

Conclusion: 所提出的基于PDD的优化方法能够有效解决IRS-ISAC系统中的保密间隙最大化问题，为实际系统部署提供了可行的解决方案。

Abstract: In this paper, we employ a hardware-efficient hybrid beamforming (HB) architecture to achieve balanced performance in an intelligent reflecting surface (IRS)-assisted integrated sensing and communication (ISAC) system. We consider a scenario where a multi-antenna, dual-function base station (BS) performs secure beamforming for a multi-antenna legitimate receiver while simultaneously detecting potential targets. Our objective is to maximize the communication secrecy gap by jointly optimizing the analog and digital beamformers, IRS reflection coefficients, and radar scaling factor, subject to constraints on beampattern similarity, total transmit power budget, and the constant modulus of both the analog beamformer and IRS reflection coefficients. This secrecy gap maximization problem is generally non-convex. To address this, we incorporate the exterior penalty method by adding the radar constraint as a penalty term in the objective function. We then propose an efficient approach based on the penalty dual decomposition (PDD) framework to solve the reformulated problem, featuring closed-form solutions at each step and guaranteeing convergence to a stationary point. Simulation results validate the effectiveness of the proposed algorithm and demonstrate the superiority of the IRS-ISAC system with HB architecture in balancing performance and hardware costs.

</details>


### [38] [Secure Analog Beamforming for Multi-user MISO Systems with Movable Antennas](https://arxiv.org/abs/2511.19360)
*Weijie Xiong,Jingran Lin,Kai Zhong,Liu Yang,Hongli Liu,Qiang Li,Cunhua Pan*

Main category: eess.SP

TL;DR: 本文研究了基于模拟波束成形的可移动天线系统在物理层安全中的应用，通过联合优化相位偏移和天线位置来最大化多播保密速率，解决了传统全数字波束成形硬件成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统可移动天线系统采用全数字波束成形需要每个天线配备专用射频链，硬件成本高昂。模拟波束成形提供了一种成本效益更高的替代方案，但需要解决其相位偏移和天线位置联合优化的挑战。

Method: 提出惩罚约束乘积流形框架，将位置约束重构为惩罚函数，在乘积流形空间进行无约束优化，并使用并行共轭梯度下降算法高效更新变量。

Result: 仿真结果表明，基于模拟波束成形的可移动天线系统能在多播保密速率和硬件成本之间实现良好平衡。

Conclusion: 该研究证明了模拟波束成形在可移动天线系统中的可行性，为解决硬件成本问题提供了有效方案，同时保持了系统性能。

Abstract: Movable antennas (MAs) represent a novel approach that enables flexible adjustments to antenna positions, effectively altering the channel environment and thereby enhancing the performance of wireless communication systems. However, conventional MA implementations often adopt fully digital beamforming (FDB), which requires a dedicated RF chain for each antenna. This requirement significantly increase hardware costs, making such systems impractical for multi-antenna deployments. To address this, hardware-efficient analog beamforming (AB) offers a cost-effective alternative. This paper investigates the physical layer security (PLS) in an MA-enabled multiple-input single-output (MISO) communication system with an emphasis on AB. In this scenario, an MA-enabled transmitter with AB broadcasts common confidential information to a group of legitimate receivers, while a number of eavesdroppers overhear the transmission and attempt to intercept the information. Our objective is to maximize the multicast secrecy rate (MSR) by jointly optimizing the phase shifts of the AB and the positions of the MAs, subject to constraints on the movement area of the MAs and the constant modulus (CM) property of the analog phase shifters. This MSR maximization problem is highly challenging, as we have formally proven it to be NP-hard. To solve it efficiently, we propose a penalty constrained product manifold (PCPM) framework. Specifically, we first reformulate the position constraints as a penalty function, enabling unconstrained optimization on a product manifold space (PMS), and then propose a parallel conjugate gradient descent algorithm to efficiently update the variables. Simulation results demonstrate that MA-enabled systems with AB can achieve a well-balanced performance in terms of MSR and hardware costs.

</details>


### [39] [Connectivity-Aware Task Offloading for Remote Northern Regions: a Hybrid LEO-MEO Architecture](https://arxiv.org/abs/2511.19369)
*Mohammed Almekhlafi,Antoine Lesage-Landry,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 提出了一种结合MEO和LEO卫星的混合架构用于任务卸载，通过优化框架提高任务准入率并平衡能耗与延迟，在北极等偏远地区显著改善连接性能。


<details>
  <summary>Details</summary>
Motivation: 北极地区由于LEO卫星覆盖稀疏，难以实现稳定连接和低延迟计算服务，需要增强偏远地区的服务可靠性。

Method: 开发优化框架最大化任务准入率，结合动态路径选择和频率计算资源分配，使用析取约束和凸松弛技术将NP难问题转化为混合整数凸形式。

Result: 相比单独LEO网络，混合LEO-MEO架构将任务准入率提高15%，平均延迟降低12%。

Conclusion: 该混合架构有潜力显著增强偏远北极地区的连接性和用户体验。

Abstract: Arctic regions, such as northern Canada, face significant challenges in achieving consistent connectivity and low-latency computing services due to the sparse coverage of Low Earth Orbit (LEO) satellites. To enhance service reliability in remote areas, this paper proposes a hybrid satellite architecture for task offloading that combines Medium Earth Orbit (MEO) and LEO satellites. We develop an optimization framework to maximize task offloading admission rate while balancing the energy consumption and delay requirements. Accounting for satellite visibility and limited computing resources, our approach integrates dynamic path selection with frequency and computational resource allocation. Because the formulated problem is NP-hard, we reformulate it into a mixed-integer convex form using disjunctive constraints and convex relaxation techniques, enabling efficient use of off-the-shelf optimization solvers. Simulation results show that, compared to a standalone LEO network, the proposed hybrid LEO-MEO architecture improves the task admission rate by 15\% and reduces the average delay by 12\%. These findings highlight the architecture's potential to enhance connectivity and user experience in remote Arctic areas.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [40] [How to Expand a Self-orthogonal Code](https://arxiv.org/abs/2511.17503)
*Jon-Lark Kim,Hongwei Liu,Jinquan Luo*

Main category: cs.IT

TL;DR: 本文展示了如何扩展欧几里得/埃尔米特自正交码并保持其正交性质。结果表明，每个k维埃尔米特自正交码都包含在(k+1)维埃尔米特自正交码中；对于k<n/2-1的情况，每个[n,k]欧几里得自正交码都包含在[n,k+1]欧几里得自正交码中。


<details>
  <summary>Details</summary>
Motivation: 研究自正交码的扩展问题，旨在找到保持正交性质的扩展方法，这对于编码理论和应用具有重要意义。

Method: 提出了两种可行的算法来实现自正交码的扩展过程，并分析了不同参数条件下的扩展可行性。

Result: 证明了埃尔米特自正交码总能扩展一维；欧几里得自正交码在k<n/2-1时总能扩展，在k=n/2-1且p=2时也能扩展，但在k=n/2-1且p为奇素数时需要满足额外条件。

Conclusion: 自正交码的扩展过程在大多数情况下是可行的，但在特定参数条件下需要满足额外约束条件，这为自正交码的构造和应用提供了理论指导。

Abstract: In this paper, we show how to expand Euclidean/Hermitian self-orthogonal code preserving their orthogonal property. Our results show that every $k$-dimension Hermitian self-orthogonal code is contained in a $(k+1)$-dimensional Hermitian self-orthogonal code. Also, for $k< n/2-1$, every $[n,k]$ Euclidean self-orthogonal code is contained in an $[n,k+1]$ Euclidean self-orthogonal code. Moreover, for $k=n/2-1$ and $p=2$, we can also fulfill the expanding process. But for $k=n/2-1$ and $p$ odd prime, the expanding process can be fulfilled if and only if an extra condition must be satisfied. We also propose two feasible algorithms on these expanding procedures.

</details>


### [41] [Covert Communication and Key Generation Over Quantum State-Dependent Channels](https://arxiv.org/abs/2511.17504)
*Hassan ZivariFard,Rémi A. Chou,Xiaodong Wang*

Main category: cs.IT

TL;DR: 本文研究了在量子态相关信道上实现正速率的隐蔽通信和隐蔽密钥生成，提出了两种安全度量下的可实现方案，并证明了在经典信道情况下的最优性。


<details>
  <summary>Details</summary>
Motivation: 研究量子态相关信道上的隐蔽通信和密钥生成，填补了量子隐蔽通信正速率和隐蔽密钥生成正速率的空白，扩展了经典隐蔽通信的结果到量子领域。

Method: 使用完全量子态相关信道模型，发射器与信道共享纠缠态。采用两种安全度量：1) 隐蔽通信同时生成隐蔽密钥；2) 传输安全消息同时生成隐蔽密钥。提出了一次性和渐近可达的隐蔽-秘密密钥速率对。

Result: 实现了正速率的隐蔽秘密密钥生成和量子信道上的隐蔽通信，在经典信道且状态在发射器和接收器处非因果可用时结果是最优的。

Conclusion: 这是首次实现隐蔽密钥生成正速率和量子信道隐蔽通信正速率的研究，将经典隐蔽通信的最佳结果推广到量子领域，并在特定条件下证明了最优性。

Abstract: We study covert communication and covert secret key generation with positive rates over quantum state-dependent channels. Specifically, we consider fully quantum state-dependent channels when the transmitter shares an entangled state with the channel. We study this problem setting under two security metrics. For the first security metric, the transmitter aims to communicate covertly with the receiver while simultaneously generating a covert secret key, and for the second security metric, the transmitter aims to transmit a secure message covertly and generate a covert secret key with the receiver simultaneously. Our main results include one-shot and asymptotic achievable positive covert-secret key rate pairs for both security metrics. Our results recover as a special case the best-known results for covert communication over state-dependent classical channels. To the best of our knowledge, our results are the first instance of achieving a positive rate for covert secret key generation and the first instance of achieving a positive covert rate over a quantum channel. Additionally, we show that our results are optimal when the channel is classical and the state is available non-causally at both the transmitter and the receiver.

</details>


### [42] [Unified Error Analysis for Synchronous and Asynchronous Two-User Random Access](https://arxiv.org/abs/2511.17718)
*Nazanin Mirhosseini,Jie Luo*

Main category: cs.IT

TL;DR: 本文研究了一个双用户随机接入系统，其中每个用户独立选择编码方案，接收机主要解码用户1的消息，但也可解码用户2的消息以提升性能。在同步和异步设置下，接收机使用并行子解码器，通过划分编码空间为操作区、边界区和碰撞区来实现解码或碰撞检测，并推导了广义错误性能的上界。


<details>
  <summary>Details</summary>
Motivation: 研究在没有用户间协调的情况下，如何设计高效的随机接入系统，使接收机能够灵活解码目标用户消息，同时利用其他用户信息提升性能。

Method: 在同步设置中使用两个并行子解码器（一个解码用户1，一个联合解码两个用户）；在异步设置中使用2^2L个并行子解码器，每个负责解码特定的消息-码索引对子集。所有子解码器都将编码空间划分为操作区、边界区和碰撞区。

Result: 推导了同步和异步场景下广义错误性能（错误解码、碰撞和漏检概率的加权和）的可实现上界。

Conclusion: 提出的并行子解码器架构在双用户随机接入系统中能够有效处理同步和异步情况，通过空间划分和并行处理实现了良好的错误性能。

Abstract: We consider a two-user random access system in which each user independently selects a coding scheme from a finite set for every message, without sharing these choices with the other user or with the receiver. The receiver aims to decode only user 1 message but may also decode user 2 message when beneficial. In the synchronous setting, the receiver employs two parallel sub-decoders: one dedicated to decoding user 1 message and another that jointly decodes both users messages. Their outputs are synthesized to produce the final decoding or collision decision. For the asynchronous setting, we examine a time interval containing $L$ consecutive codewords from each user. The receiver deploys $2^{2L}$ parallel sub-decoders, each responsible for decoding a subset of the message-code index pairs. In both synchronous and asynchronous cases, every sub-decoder partitions the coding space into three disjoint regions: operation, margin, and collision, and outputs either decoded messages or a collision report according to the region in which the estimated code index vector lies. Error events are defined for each sub-decoder and for the overall receiver whenever the expected output is not produced. We derive achievable upper bounds on the generalized error performance, defined as a weighted sum of incorrect-decoding, collision, and miss-detection probabilities, for both synchronous and asynchronous scenarios.

</details>


### [43] [Multi-Port Selection for FAMA: Massive Connectivity with Fewer RF Chains than Users](https://arxiv.org/abs/2511.17897)
*Hanjiang Hong,Kai-Kit Wong,Xusheng Zhu,Hao Xu,Han Xiao,Farshad Rostami Ghadi,Hyundong Shin*

Main category: cs.IT

TL;DR: 本文研究了多活动端口流体天线多址接入技术，提出了三种端口选择方法：最优穷举搜索、增量端口选择和减量端口选择，旨在提升系统复用能力并降低复杂度。


<details>
  <summary>Details</summary>
Motivation: 从单活动端口过渡到多活动端口可以显著增强慢速FAMA的复用能力，但这一机制尚未得到充分理解，因此需要研究有效的端口选择方法。

Method: 提出了三种端口选择方法：最优穷举搜索端口选择作为性能上界，以及两种次优低复杂度算法——增量端口选择和减量端口选择。

Result: 仿真结果表明，所提方法优于当前最先进的多端口FAMA技术，其中增量端口选择在保持可管理计算复杂度的同时实现了接近最优的性能。

Conclusion: 这项研究为FAMA系统中的端口选择提供了一个更通用的框架，增量端口选择是性能与复杂度之间的良好折衷方案。

Abstract: Fluid antenna multiple access (FAMA) is an emerging technology in massive access designed to meet the demands of future wireless communication networks by naturally mitigating multiuser interference through the utilization of the fluid antenna system (FAS) at RF-chain-limited mobile device. The transition from single-active-port to multi-active-port on a shared RF chain for slow FAMA can greatly enhance its multiplexing capability but is not well understood. Motivated by this, this paper proposes and studies three port selection methods: the optimal exhaustive-search port selection (EPS) as a performance upper bound, and two suboptimal, low-complexity algorithms, namely incremental port selection (IPS) and decremental port selection (DPS). Then the performance of multi-active-port slow FAMA is analyzed, and the complexity of the proposed methods is compared. Simulation results indicate that the proposed methods outperform current state-of-the-art multi-port FAMA techniques. In particular, IPS achieves near-optimal performance while maintaining manageable computational complexity. This research provides a more general framework for port selection in FAMA systems.

</details>


### [44] [Asymptotic Performance Analysis of Fluid Antenna Systems: An Extreme Value Theory Perspective](https://arxiv.org/abs/2511.17916)
*Yi Zhang,Jintao Wang,Zheng Shi,Xu Wang,Guanghua Yang,Shaodan Ma,Kai-Kit Wong*

Main category: cs.IT

TL;DR: 本文利用极值理论分析了流体天线系统在大规模天线端口下的性能，发现中断概率随端口数近似指数衰减，遍历容量呈双对数缩放规律，并证明了空间相关性会降低系统性能。


<details>
  <summary>Details</summary>
Motivation: 量化流体天线系统在大规模天线端口下的性能缩放规律，为系统设计提供理论指导。

Method: 采用极值理论进行渐近分析，推导中断概率和遍历容量的上下界，并利用Gumbel分布模式的对数缩放特性重新验证缩放规律。

Result: 中断概率随天线端口数近似指数衰减，遍历容量呈双对数缩放，空间相关性会降低系统性能。

Conclusion: 流体天线系统在大规模配置下具有优异的性能缩放特性，但需注意空间相关性的负面影响。

Abstract: Fluid antenna systems (FAS) allow dynamic reconfiguration to achieve superior diversity gains and reliability. To quantify the performance scaling of FAS with a large number of antenna ports, this paper leverages extreme value theory (EVT) to conduct an asymptotic analysis of the outage probability (OP) and ergodic capacity (EC). The analysis reveals that the OP decays approximately exponentially with the number of antenna ports. Moreover, we establish upper and lower bounds for the asymptotic EC, uncovering its double-logarithmic scaling law. Furthermore, we re-substantiate these scaling laws by exploiting the fact that the mode of the Gumbel distribution scales logarithmically. Besides, we theoretically prove that spatial correlation among antenna ports degrades both OP and EC. All analytical findings are conclusively validated by numerical results.

</details>


### [45] [A Reinforcement Learning Framework for Resource Allocation in Uplink Carrier Aggregation in the Presence of Self Interference](https://arxiv.org/abs/2511.17931)
*Jaswanth Bodempudi,Batta Siva Sairam,Madepalli Haritha,Sandesh Rao Mattu,Ananthanarayanan Chockalingam*

Main category: cs.IT

TL;DR: 提出了一种基于强化学习的上行载波聚合资源分配方案，使用复合动作演员-评论家算法来同时优化载波选择和功率分配，有效处理自干扰约束。


<details>
  <summary>Details</summary>
Motivation: 在功率受限的上行链路中，需要高效的资源分配方案来分配用户可用功率到多个载波。传统方法难以解决混合优化变量和自干扰约束的问题。

Method: 采用强化学习框架，使用复合动作演员-评论家算法，设计了专门处理自干扰约束的新型奖励函数，在线学习载波分配和激活策略。

Result: 数值结果表明，与简单方案相比，所提出的基于强化学习的方案能够实现更高的总吞吐量，且奖励函数使算法能在有无自干扰情况下自适应优化。

Conclusion: 强化学习方法能有效解决上行载波聚合中的混合优化问题，提出的CA2C算法和奖励函数为处理自干扰约束提供了有效解决方案。

Abstract: Carrier aggregation (CA) is a technique that allows mobile networks to combine multiple carriers to increase user data rate. On the uplink, for power constrained users, this translates to the need for an efficient resource allocation scheme, where each user distributes its available power among its assigned uplink carriers. Choosing a good set of carriers and allocating appropriate power on the carriers is important. If the carrier allocation on the uplink is such that a harmonic of a user's uplink carrier falls on the downlink frequency of that user, it leads to a self coupling-induced sensitivity degradation of that user's downlink receiver. In this paper, we model the uplink carrier aggregation problem as an optimal resource allocation problem with the associated constraints of non-linearities induced self interference (SI). This involves optimization over a discrete variable (which carriers need to be turned on) and a continuous variable (what power needs to be allocated on the selected carriers) in dynamic environments, a problem which is hard to solve using traditional methods owing to the mixed nature of the optimization variables and the additional need to consider the SI constraint. We adopt a reinforcement learning (RL) framework involving a compound-action actor-critic (CA2C) algorithm for the uplink carrier aggregation problem. We propose a novel reward function that is critical for enabling the proposed CA2C algorithm to efficiently handle SI. The CA2C algorithm along with the proposed reward function learns to assign and activate suitable carriers in an online fashion. Numerical results demonstrate that the proposed RL based scheme is able to achieve higher sum throughputs compared to naive schemes. The results also demonstrate that the proposed reward function allows the CA2C algorithm to adapt the optimization both in the presence and absence of SI.

</details>


### [46] [Block Length Gain for Nanopore Channels](https://arxiv.org/abs/2511.18027)
*Yu-Ting Lin,Hsin-Po Wang,Venkatesan Guruswami*

Main category: cs.IT

TL;DR: 本文扩展了Geno-Weaving方法，将其应用于DNA存储中的删除错误防护，证明该方法不仅能达到容量极限，还能消除有限长度惩罚，并在实际删除率下表现良好。


<details>
  <summary>Details</summary>
Motivation: DNA作为数据存储介质具有高密度和长寿命优势，但当前技术只能合成200-300核苷酸长的链，导致内码率受到显著有限长度惩罚。需要一种能有效对抗删除错误的方法。

Method: 扩展Geno-Weaving方法，通过使用一个代码保护多个链中的相同位置来对抗删除错误。利用链数量远大于链长度的特性消除有限长度惩罚。

Result: Geno-Weaving方法在0.1%-10%的实际删除率下表现良好，无需针对删除信道进行专门设计即可有效工作。

Conclusion: Geno-Weaving方法不仅能达到容量极限对抗替换错误，还能有效对抗删除错误，同时消除有限长度惩罚，为DNA数据存储提供了实用的错误防护方案。

Abstract: DNA is an attractive candidate for data storage. Its millennial durability and nanometer scale offer exceptional data density and longevity. Its relevance to medical applications also drives advances in DNA-related biotechnology.
  To protect our data against errors, a straightforward approach uses one error-correcting code per DNA strand, with a Reed--Solomon code protecting the collection of strands. A downside is that current technology can only synthesize strands 200--300 nucleotides long. At this block length, the inner code rate suffers a significant finite-length penalty, making its effective capacity hard to characterize.
  Last year, we proposed $\textit{Geno-Weaving}$ in a JSAIT publication. The idea is to protect the same position across multiple strands using one code; this provably achieves capacity against substitution errors. In this paper, we extend the idea to combat deletion errors and show two more advantages of Geno-Weaving: (1) Because the number of strands is 3--4 orders of magnitude larger than the strand length, the finite-length penalty vanishes. (2) At realistic deletion rates $0.1\%$--$10\%$, Geno-Weaving designed for BSCs works well empirically, bypassing the need to tailor the design for deletion channels.

</details>


### [47] [Average Secrecy Capacity Maximization of Rotatable Antenna-Assisted Secure Communications](https://arxiv.org/abs/2511.18097)
*Pengchuan Jiang,Quanzhong Li,Lifeng Mai,Qi Zhang*

Main category: cs.IT

TL;DR: 本文研究了可旋转天线辅助的安全通信系统，通过理论证明平均保密率最大化问题关于天线调整因子是拟凹的，提出了二分搜索法求最优解，并推导了LOS信道下的闭式最优偏转角作为近似最优解。


<details>
  <summary>Details</summary>
Motivation: 可旋转天线能动态调整偏转角以提升物理层安全性能，但在非实时调整的实际场景中，需要研究如何最大化平均保密率。

Method: 理论证明目标函数的拟凹性，使用二分搜索法求最优解，推导LOS信道下的闭式最优偏转角作为近似最优解，并分析高信噪比下的保密中断概率。

Result: 仿真结果显示近似最优解与最优解的平均保密容量几乎相同，高信噪比下理论保密中断概率与仿真结果匹配。

Conclusion: 提出的闭式近似最优解在性能上接近最优解，且理论分析在高信噪比下准确，为可旋转天线安全通信系统提供了有效解决方案。

Abstract: A rotatable antenna, which is able to dynamically adjust its deflection angle, is promising to achieve better physical layer security performance for wireless communications. In this paper, considering practical scenarios with non-real-time rotatable antenna adjustment, we investigate the average secrecy rate maximization problem of a rotatable antenna-assisted secure communication system. We theoretically prove that the objective function of the average secrecy rate maximization problem is quasi-concave with respect to an adjustment factor of the rotatable antenna. Under this condition, the optimal solution can be found by the bisection search. Furthermore, we derive the closed-form optimal deflection angle for the secrecy capacity maximization problem, considering the existence of only line-of-sight components of wireless channels. This solution serves as a near optimal solution to the average secrecy rate maximization problem. Based on the closed-form near optimal solution, we obtain the system secrecy outage probability at high signal-to-noise ratio (SNR). It is shown through simulation results that the near optimal solution achieves almost the same average secrecy capacity as the optimal solution. It is also found that at high SNR, the theoretical secrecy outage probabilities match the simulation ones.

</details>


### [48] [On the Hamming Weight Functions of Linear Codes](https://arxiv.org/abs/2511.18250)
*Dongmei Huang,Qunying Liao,Sihem Mesnager,Gaohua Tang,Haode Yan*

Main category: cs.IT

TL;DR: 提出了一种基于权重函数的线性码二次构造新方法，通过固定汉明权重的码字构造新线性码，分析了维度、权重数和权重分布，建立了与原始码可扩展性的联系。


<details>
  <summary>Details</summary>
Motivation: 现有的线性码二次构造技术主要包括截短、缩短和扩展，需要新的构造方法来生成新的线性码族并探索现有码的内在组合和几何结构。

Method: 基于权重函数的线性码二次构造框架，从给定码中固定汉明权重的码字集合构造新线性码。

Result: 建立了双权重码最小权重的上界，并刻画了达到该界的所有双权重码，推导了双权重码参数的若干可除性性质。

Conclusion: 该方法不仅能生成新的线性码族，还为探索现有码的内在组合和几何结构提供了有力工具。

Abstract: Currently known secondary construction techniques for linear codes mainly include puncturing, shortening, and extending. In this paper, we propose a novel method for the secondary construction of linear codes based on their weight functions. Specifically, we develop a general framework that constructs new linear codes from the set of codewords in a given code having a fixed Hamming weight. We analyze the dimension, number of weights, and weight distribution of the constructed codes, and establish connections with the extendability of the original codes as well as the partial weight distribution of the derived codes. As a new tool, this framework enables us to establish an upper bound on the minimum weight of two-weight codes and to characterize all two-weight codes attaining this bound. Moreover, several divisibility properties concerning the parameters of two-weight codes are derived. The proposed method not only generates new families of linear codes but also provides a powerful approach for exploring the intrinsic combinatorial and geometric structures of existing codes.

</details>


### [49] [Function-Correcting Codes With Data Protection](https://arxiv.org/abs/2511.18420)
*Charul Rajput,B. Sundar Rajan,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 提出了一个保护数据和函数值的函数纠错码通用框架，重点研究函数值比数据本身需要更强保护的情况。通过两步构造方法，展示了在不增加冗余的情况下为现有FCC添加数据保护的可能性，并为特定函数族提供了显式构造。


<details>
  <summary>Details</summary>
Motivation: 现有函数纠错码通常只保护函数值而不保护底层数据，但在实际应用中，数据本身也需要保护。本文旨在构建一个同时保护数据和函数值的通用框架，特别关注函数值需要比数据更强保护的场景。

Method: 提出了一个包含数据保护的FCC通用框架，采用两步构造过程：先构造保护函数值的码，再添加数据保护。使用最小距离图分析完美码和MDS码的保护能力，并首次研究了线性FCC的结构特性。

Result: 展示了在不增加冗余的情况下为现有FCC添加数据保护的可能性，为局部有界函数和汉明权重函数提供了显式构造。证明了完美码和MDS码无法为函数值提供超过数据保护的保护级别。

Conclusion: 成功构建了同时保护数据和函数值的函数纠错码框架，为特定函数族提供了有效构造方法，并将经典编码理论中的Plotkin界和Hamming界推广到带数据保护的FCC中。

Abstract: Function-correcting codes (FCCs) are designed to provide error protection for the value of a function computed on the data. Existing work typically focuses solely on protecting the function value and not the underlying data. In this work, we propose a general framework that offers protection for both the data and the function values. Since protecting the data inherently contributes to protecting the function value, we focus on scenarios where the function value requires stronger protection than the data itself. We first introduce a more general approach and a framework for function-correcting codes that incorporates data protection along with protection of function values. A two-step construction procedure for such codes is proposed, and bounds on the optimal redundancy of general FCCs with data protection are reported. Using these results, we exhibit examples that show that data protection can be added to existing FCCs without increasing redundancy. Using our two-step construction procedure, we present explicit constructions of FCCs with data protection for specific families of functions, such as locally bounded functions and the Hamming weight function. We associate a graph called minimum-distance graph to a code and use it to show that perfect codes and maximum distance separable (MDS) codes cannot provide additional protection to function values over and above the amount of protection for data for any function. Then we focus on linear FCCs and provide some results for linear functions, leveraging their inherent structural properties. To the best of our knowledge, this is the first instance of FCCs with a linear structure. Finally, we generalize the Plotkin and Hamming bounds well known in classical error-correcting coding theory to FCCs with data protection.

</details>


### [50] [Aerial Semantic Relay-Enabled SAGIN: Joint UAV Deployment and Resource Allocation](https://arxiv.org/abs/2511.18456)
*Yanbo Yin,Dingzhu Wen,Changsheng You,XiaoWen Cao,Tat-Ming Lok,Dusit Niyato*

Main category: cs.IT

TL;DR: 提出了一种多集群无人机辅助的空间-空中-地面集成网络语义通信架构，通过语义通信提升卫星到无人机链路的传输效率，并采用智能自适应中继策略同时支持语义用户和传统用户。


<details>
  <summary>Details</summary>
Motivation: 解决SAGIN中卫星到地面链路严重受损的问题，特别是卫星到无人机链路这一关键瓶颈，同时需要支持不同类型的用户接入网络。

Method: 设计多集群无人机辅助的SAGIN语义通信架构，在卫星到无人机链路使用语义通信，无人机采用智能自适应中继策略；提出联合优化问题，通过交替优化算法协调分配功率、带宽和无人机位置。

Result: 数值结果表明，所提算法在各种信道条件和用户分布下，在总速率和频谱效率方面显著优于基线方案。

Conclusion: 该设计在保证语义通信高效率优势的同时，实现了更大覆盖区域的网络接入，联合资源分配和智能无人机部署对系统性能至关重要。

Abstract: Space-Air-Ground Integrated Networks (SAGINs) are pivotal for enabling ubiquitous connectivity in 6G systems, yet they face significant challenges due to severe satellite-to-ground link impairments. Although Unmanned Aerial Vehicles (UAVs) can function as relay nodes to compensate for air-to-ground channel degradation, the satellite-to-UAV link remains a critical bottleneck. Semantic Communication (SemCom) emerges as a promising solution to enhance spectral efficiency by transmitting essential semantic information. This paper proposes a novel multi-cluster UAV-aided SAGIN SemCom architecture that supports both semantic users (SemUsers) and conventional users (ConUsers). While SemCom is employed in the satellite-to-UAV link to improve transmission efficiency, the UAVs implement an intelligent adaptive relay strategy, capable of either directly forwarding semantic data to SemUsers or converting it into bit-level data for ConUsers. Compared to existing similar schemes, this design guarantees the high-efficiency advantages of SemCom while enabling network access for larger coverage area. A joint optimization problem is formulated to maximize the system's sum-rate through coordinated allocation of power, bandwidth, and UAV positions. To address this non-convex problem, we develop an efficient alternating optimization (AO) algorithm, which decomposes the original problem into tractable subproblems. Numerical results demonstrate that the proposed algorithm significantly outperforms baseline schemes in terms of both sum-rate and spectral efficiency across various channel conditions and user distributions, underscoring the importance of joint resource allocation and intelligent UAV deployment.

</details>


### [51] [Performance Evaluation of Dual RIS-Assisted Received Space Shift Keying Modulation](https://arxiv.org/abs/2511.18610)
*Ferhat Bayar,Haci Ilhan,Erdogan Aydin*

Main category: cs.IT

TL;DR: 提出了一种新颖的双RIS辅助架构，用于智能室内无线信号路由，其中第二个RIS根据源数据比特动态配置，将信号导向特定接收器或室内区域。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要探索单RIS部署和静态/半静态反射控制，需要更动态的RIS配置方法来提升无线环境的重塑能力。

Method: 使用双RIS架构：RIS1被动反射信号，RIS2通过轻量级控制器执行比特驱动的空间调制，基于SSK进行信号检测。

Result: 在不同RIS间距离和载波频率下评估了可实现容量和中断概率的性能。

Conclusion: 双RIS架构能够实现数据依赖的物理层方向选择，为智能室内无线信号路由提供了有效解决方案。

Abstract: Reconfigurable intelligent surfaces (RISs) are gaining traction for their ability to reshape wireless environments with low energy consumption. However, prior studies primarily explore single-RIS deployments with static or semi-static reflection control. In this paper, we propose a novel dual-RIS-assisted architecture for smart indoor wireless signal routing, wherein the second RIS (RIS$_2$) is dynamically configured based on source data bits to steer signals toward specific receivers or indoor zones. The first RIS (RIS$_1$), positioned near a fed antenna or access point, passively reflects the incident signal. RIS$_2$, equipped with a lightweight controller, performs bit-driven spatial modulation to enable data-dependent direction selection at the physical layer. We develop a complete end-to-end system model, including multi-hop channel representation, RIS phase configuration mapping, and signal detection based on space shift keying (SSK). Performance analysis is evaluated in terms of achievable capacity and outage probability under varying inter-RIS distances and carrier frequencies.

</details>


### [52] [Understanding the Role of Phase and Position Design in Fluid Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2511.18663)
*J. D. Vega-Sánchez,V. H. Garzón Pacheco,N. V. Orozco Garzón,H. R. Carvajal Mora,F. J. López-Martínez*

Main category: cs.IT

TL;DR: 本文通过对比流体可重构智能表面(FRIS)与传统RIS的性能，发现在没有相位设计时FRIS的空间位置优化能带来明显增益，但在使用最优波束成形和相位设计时这种优势消失；FRIS始终优于紧凑型RIS。


<details>
  <summary>Details</summary>
Motivation: 澄清FRIS性能增益的来源：是空间灵活性还是等效孔径或相位设计的差异，为FRIS的实际应用提供理论依据。

Method: 在两种实际场景中对比FRIS与传统RIS：传统RIS（相同有源元件数量和整体孔径）和紧凑型RIS（相同有源元件数量，但孔径更小且元件间距小于波长），并进行统计分析。

Result: 统计结果表明：(i)无相位设计时FRIS空间位置优化比传统RIS有明显增益；(ii)使用最优波束成形和相位设计时，位置优化变得无关紧要；(iii)FRIS始终优于紧凑型RIS，归因于空间相关性和更小孔径。

Conclusion: FRIS的性能优势主要来自空间灵活性，但在最优波束成形和相位设计下，位置优化的价值有限；FRIS相比紧凑型RIS具有持续优势。

Abstract: Fluid Reconfigurable Intelligent Surfaces (FRISs) are gaining momentum as an improved alternative over classical RIS. However, it remains unclear whether their performance gains can be entirely attributed to spatial flexibility, or instead to differences in equivalent aperture or phase design. In this work, we shed light onto this problem by benchmarking FRIS vs. RIS performances in two practical scenarios: conventional RIS (same number of active elements and same overall aperture) and compact RIS (same number of active elements, and smaller aperture with sub-λ inter-element spacing). Statistical analysis demonstrates that: (i) spatial position optimization in FRIS provides noticeable gains over conventional RIS in the absence of phase-shift design; (ii) such benefits vanish when FRIS and conventional RIS employ optimal beamforming (BF) and phase shift (PS) design, making position optimization irrelevant; (iii) FRIS consistently outperforms compact RIS with optimized BF and PS design, owing to spatial correlation and smaller aperture.

</details>


### [53] [Study of Iterative Dynamic Channel Tracking for Multiple RIS-Assisted MIMO Systems](https://arxiv.org/abs/2511.18669)
*Roberto C. G. Porto,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出了一种基于LDPC码的迭代信道估计方案，通过利用信道相干时间和迭代处理来提高多RIS系统中的估计精度，同时显著降低导频开销。


<details>
  <summary>Details</summary>
Motivation: 6G网络中多RIS部署面临信道估计效率和导频开销的挑战，需要开发既能提高估计精度又能减少导频长度的解决方案。

Method: 使用LDPC编码导频，结合信道相干时间和迭代处理，利用导频和校验位来增强迭代处理，并整合先前估计结果以进一步降低开销。

Result: 在sub-6 GHz场景下，无论是LOS还是NLOS条件下，所提方法都优于现有方法，在显著降低导频开销的同时获得了可观的性能增益。

Conclusion: 该迭代信道估计方案有效解决了多RIS系统中的信道估计挑战，为6G网络的实际部署提供了可行的解决方案。

Abstract: The use of multiple Reconfigurable Intelligent Sur- faces (RIS) has gained attention in 6G networks to enhance coverage. However, the feasibility of deploying multiple RIS relies on efficient channel estimation and reduced pilot overhead. To address these challenges, this work proposes an iterative channel estimation scheme that exploits low-density parity-check (LDPC) codes, channel coherence time, and iterative processing to improve estimation accuracy while minimizing pilot length. Encoded pilots are used to strengthen the iterative processing, leveraging both pilot and parity bits, while previous estimates are incorporated to further reduce overhead. Simulations consider a sub-6 GHz scenario with non-sparse channels and multiple RIS under both LOS and NLOS conditions. The results show that the proposed method outperforms existing approaches, achieving significant gains with substantially lower pilot overhead.

</details>


### [54] [Exploring Spatial Flexibility and Phase Design in Fluid Reconfigurable Intelligent Surfaces: A Physical Layer Security Perspective](https://arxiv.org/abs/2511.18675)
*J. D. Vega-Sánchez,V. H. Garzón Pacheco,N. V. Orozco Garzón,D. A. Riofrío Almeida,D. P. Moya Osorio*

Main category: cs.IT

TL;DR: 本文分析了流体可重构智能表面(FRIS)的保密中断概率(SOP)性能，并与传统平面RIS和紧凑型RIS架构进行对比。通过最大似然估计和Q学习算法优化FRIS元素位置，结果显示FRIS在空间分集方面具有优势，但与传统RIS相比的改进在后者实施波束成形和相位控制后变得不明显。


<details>
  <summary>Details</summary>
Motivation: 研究不同RIS架构对无线通信安全性能的影响，特别是FRIS在保密中断概率方面的表现，以及空间相关性对安全性能的重要性。

Method: 使用最大似然估计(MLE)方法表征端到端FRIS信道，并采用Q学习算法自适应选择FRIS元素的空间位置。通过数值评估比较FRIS与传统平面RIS、紧凑型RIS的性能。

Result: FRIS通过优化元素放置显著改善了SOP性能，但与传统RIS实施优化波束成形和相位控制后的性能差距变小。FRIS在空间相关性方面优于紧凑型RIS设计。减小元素间距对SOP产生负面影响。

Conclusion: FRIS在无线通信安全方面具有优势，特别是在空间分集方面。然而，传统RIS通过适当的波束成形和相位控制也能达到类似性能。空间多样性对保密性能至关重要。

Abstract: This work examines the secrecy outage probability (SOP) in Fluid Reconfigurable Intelligent Surfaces (FRIS) and contrasts their performance against two alternative RIS architectures: a traditional planar RIS and a compact RIS layout. To characterize the end-to-end FRIS channel, a maximum likelihood estimation (MLE) approach is introduced, while a Q-learning algorithm is employed to adaptively select the spatial positions of FRIS elements. Numerical evaluations show that optimizing element placement in FRIS significantly improves SOP compared to conventional RIS without phase adaptation. However, these improvements become less evident once the conventional RIS implements optimized beamforming (BF) and phase-shift (PS) controlling. In addition, FRIS maintains a clear advantage over compact RIS designs with optimized BF and PS, mainly due to its lower spatial correlation. Results further indicate that reducing the inter-element distance negatively impacts SOP, highlighting the importance of spatial diversity.

</details>


### [55] [On Construction of Linear (Euclidean) Hull Codes over Finite Extensions Binary Fields](https://arxiv.org/abs/2511.18779)
*Sanjit Bhowmick,Deepak Kumar Dalai,Sihem Mesnager*

Main category: cs.IT

TL;DR: 本文研究线性码的hull（与对偶码的交集）问题，特别关注一维hull的构造，并展示了LCD码与一维hull码的等价关系，以及hull维度递增的构造方法。


<details>
  <summary>Details</summary>
Motivation: hull概念最初用于分类有限射影平面，在检查线性码置换等价性和计算自同构群算法中起关键作用。研究表明当hull尺寸较小时这些算法更有效，其中LCD码具有最小hull，一维hull为次小。

Method: 首先探索有限域上线性码的一维hull；证明在弱条件下，扩展二元域上的LCD码等价于一维hull码；提供从ℓ维hull构造ℓ+1维hull的方法；基于结果推导多种ℓ维hull构造。

Result: 建立了LCD码与一维hull码的等价关系；提出了hull维度递增的构造方法；获得了多种ℓ维hull的构造方案。

Conclusion: 本文系统研究了线性码的hull问题，特别在一维hull和hull维度变换方面取得了重要进展，为相关算法效率提升提供了理论基础。

Abstract: The hull of a linear code is defined as the intersection of the code and its dual. This concept was initially introduced to classify finite projective planes. The hull plays a crucial role in determining the complexity of algorithms used to check the permutation equivalence of two linear codes and compute a linear code's automorphism group. Research has shown that these algorithms are very effective when the hull size is small. Linear complementary dual (LCD) codes have the smallest hulls, while codes with a one-dimensional hull have the second smallest.
  A recent notable paper that directs our investigation is authored by H. Chen, titled ``On the Hull-Variation Problem of Equivalent Linear Codes", published in IEEE Transactions on Information Theory, volume 69, issue 5, in 2023. In this paper, we first explore the one-dimensional hull of a linear code over finite fields. Additionally, we demonstrate that any LCD code over an extended binary field \( \FF_q \) (where \( q > 3 \)) with a minimum distance of at least $2$ is equivalent to the one-dimensional hull of a linear code under a specific weak condition. Furthermore, we provide a construction for creating hulls with \( \ell + 1 \)-dimensionality from an \( \ell \)-dimensional hull of a linear code, again under a weak condition. This corresponds to a particularly challenging direction, as creating \( \ell \)-dimensional hulls from \( \ell + 1 \)-dimensional hulls. Finally, we derive several constructions for the \( \ell \)-dimensional hulls of linear codes as a consequence of our results.

</details>


### [56] [Detection of Number of Subcarriers of OFDM Systems using Eigen-Spectral Analysis](https://arxiv.org/abs/2511.19020)
*Vishnu Priya Chekuru,Ganapathiraju S S Ananya Varma,Arti Yardi,Praful Mankar*

Main category: cs.IT

TL;DR: 提出一种基于协方差矩阵特征谱分析的盲OFDM参数估计方法，能够准确估计子载波数量，适用于认知无线电等非协作场景。


<details>
  <summary>Details</summary>
Motivation: 在认知无线电等非协作场景中，接收机缺乏OFDM参数先验知识，需要盲估计子载波数量等关键参数。

Method: 通过分析接收数据协方差矩阵的特征谱特性，利用正确符号分段下协方差矩阵的独特秩特性来估计子载波数量。

Result: 数值结果表明，该方法即使在低信噪比下也能以高概率准确检测子载波数量，且性能不受调制方案影响。

Conclusion: 所提出的方法比现有方法更通用，能够检测任意数量的子载波，为盲OFDM参数估计提供了有效的解决方案。

Abstract: Orthogonal Frequency-Division Multiplexing (OFDM) is widely used in modern wireless communication systems due to its robustness against time-dispersive channels. In this work, we consider a non-cooperative scenario where the receiver does not have prior knowledge of the OFDM parameters such as the number of subcarriers and the aim is to estimate them using the received data. Such a setup has applications in cognitive radio networks. For this blind OFDM parameter estimation problem, we provide a novel method based on eigen-spectral analysis of the covariance matrix corresponding to the received data. In particular, we show that the covariance matrix exhibits a distinctive rank property under correct segmentation of the received symbols, reflecting a characteristic behavior in its eigenvalue spectrum that facilitates accurate estimation of the number of subcarriers. The proposed method is more general than existing approaches in the literature, as it can detect an arbitrary number of subcarriers and its performance remains independent of the modulation scheme. The numerical results show that the proposed method accurately detects the number of subcarriers with high probability even at low SNR.

</details>


### [57] [On the Tail Transition of First Arrival Position Channels: From Cauchy to Exponential Decay](https://arxiv.org/abs/2511.19074)
*Yen-Chi Lee*

Main category: cs.IT

TL;DR: 该论文分析了非零漂移分子通信系统中第一到达位置(FAP)信道的统计特性，揭示了从重尾柯西分布到轻尾指数衰减的转变过程。


<details>
  <summary>Details</summary>
Motivation: 虽然零漂移FAP信道严格符合柯西分布，但实际分子通信系统通常在非零漂移条件下运行，需要理解漂移对信道特性的影响。

Method: 通过渐近分析识别了区分扩散主导和漂移主导区域的关键空间尺度nc=σ²/v，并提出了"截断柯西"模型来描述信道行为。

Result: 数值结果表明，高斯近似在低漂移条件下严重低估信道容量，而零漂移情况为漂移辅助粒子传输系统提供了适当的性能下界。

Conclusion: 该研究提供了对非零漂移分子通信信道统计特性的深入理解，揭示了从柯西行为到指数衰减的转变机制，为系统设计提供了理论指导。

Abstract: While the zero-drift First Arrival Position (FAP) channel is rigorously known to be Cauchy-distributed, practical molecular communication systems typically operate with non-zero drift. This letter characterizes the transition from heavy-tailed Cauchy behavior to light-tailed exponential decay. Through asymptotic analysis, we identify a critical spatial scale $n_c=σ^2/v$ separating diffusion- and drift-dominated regimes, revealing that the channel effectively behaves as a ``Truncated Cauchy'' model. Numerical results show that Gaussian approximations severely underestimate capacity at low drift, while the zero-drift case provides the appropriate performance lower bound for systems where drift assists particle transport.

</details>


### [58] [Directional Pinching-Antenna Systems](https://arxiv.org/abs/2511.19133)
*Runxin Zhang,Yulin Shao,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出了DiPASS框架，将PASS建模从理想化抽象转向物理一致性，引入了首个准确捕捉捏合天线方向性辐射的通道模型，包含1.3 dB/m的波导衰减和随机视距阻塞。


<details>
  <summary>Details</summary>
Motivation: 将PASS建模从理想化抽象转向物理一致性，解决实际部署中的关键障碍。

Method: 引入"等配额分配"功率分配策略，保证预定的耦合长度与天线位置无关；推导单PA场景下最优天线放置和方向的闭式解；开发多PA系统的可扩展优化框架。

Result: 波导多样性在提升系统容量方面优于天线密度；通过广泛仿真验证分析，DiPASS提供了现实的性能基准。

Conclusion: DiPASS从根本上重塑了对未来支持PASS的6G网络的理解和设计原则。

Abstract: We propose a directional pinching-antenna system (DiPASS), a comprehensive framework that transitions PASS modeling from idealized abstraction to physical consistency. DiPASS introduces the first channel model that accurately captures the directional, pencil-like radiation of pinching antennas, incorporates a practical waveguide attenuation of 1.3 dB/m, and accounts for stochastic line-of-sight blockage. A key enabler of DiPASS is our new "equal quota division" power allocation strategy, which guarantees predetermined coupling lengths independent of antenna positions, thereby overcoming a critical barrier to practical deployment. Our analysis yields foundational insights: we derive closed-form solutions for optimal antenna placement and orientation in single-PA scenarios, quantifying the core trade-off between waveguide and free-space losses. For multi-PA systems, we develop a scalable optimization framework that leverages directional sparsity, revealing that waveguide diversity surpasses antenna density in enhancing system capacity. Extensive simulations validate our analysis and demonstrate that DiPASS provides a realistic performance benchmark, fundamentally reshaping the understanding and design principles for future PASS-enabled 6G networks.

</details>


### [59] [Information Physics of Intelligence: Unifying Logical Depth and Entropy under Thermodynamic Constraints](https://arxiv.org/abs/2511.19156)
*Jianfeng Xu,Zeyan Li*

Main category: cs.IT

TL;DR: 提出了一个统一的理论框架，通过引入推导熵来量化信息处理的能量成本，揭示了存储与计算之间的相变临界点，为设计节能AI架构提供了物理基础。


<details>
  <summary>Details</summary>
Motivation: 人工智能模型的快速扩展揭示了模型容量（存储）与推理效率（计算）之间的基本矛盾，经典信息理论缺乏统一的物理框架来量化从压缩定律生成信息与从内存检索信息的热力学成本。

Method: 提出了将信息处理视为从本体状态到载体状态的映射的理论框架，引入了推导熵这一新指标来量化从给定逻辑深度计算目标状态所需的有效功。

Result: 通过分析香农熵（存储）与计算复杂度（时间/能量）之间的相互作用，证明了临界相变点的存在：低于该阈值时内存检索在热力学上更有利，高于该阈值时生成计算成为最优策略。

Conclusion: 推导熵的最小化是生物和人工智能演化的支配原则，能量-时间-空间守恒定律为生成模型的效率提供了物理解释，并为设计下一代节能AI架构提供了严格的数学界限。

Abstract: The rapid scaling of artificial intelligence models has revealed a fundamental tension between model capacity (storage) and inference efficiency (computation). While classical information theory focuses on transmission and storage limits, it lacks a unified physical framework to quantify the thermodynamic costs of generating information from compressed laws versus retrieving it from memory. In this paper, we propose a theoretical framework that treats information processing as an enabling mapping from ontological states to carrier states. We introduce a novel metric, Derivation Entropy, which quantifies the effective work required to compute a target state from a given logical depth. By analyzing the interplay between Shannon entropy (storage) and computational complexity (time/energy), we demonstrate the existence of a critical phase transition point. Below this threshold, memory retrieval is thermodynamically favorable; above it, generative computation becomes the optimal strategy. This "Energy-Time-Space" conservation law provides a physical explanation for the efficiency of generative models and offers a rigorous mathematical bound for designing next-generation, energy-efficient AI architectures. Our findings suggest that the minimization of Derivation Entropy is a governing principle for the evolution of both biological and artificial intelligence.

</details>


### [60] [Stitched Polar Codes](https://arxiv.org/abs/2511.19249)
*Yuan Li,Zicheng Ye,Huazi Zhang,Jun Wang,Wen Tong,Guiying Yan,Zhiming Ma*

Main category: cs.IT

TL;DR: 提出缝合极化码，作为Arikan正则极化码的新泛化，通过缝合额外结构增强原始码中不可靠信息比特的可靠性，保持相同编解码复杂度且性能更优。


<details>
  <summary>Details</summary>
Motivation: 解决正则极化码在速率匹配场景下的性能下降问题，通过增强不可靠信息比特的可靠性来提升整体性能。

Method: 重新配置基本极化过程，通过缝合额外结构来增强原始码中不可靠信息比特的可靠性，同时保持极化变换结构和相同编解码复杂度。

Result: 缝合极化码在性能上持续优于正则极化码，有效解决了速率匹配场景下的性能下降问题。

Conclusion: 缝合极化码通过灵活的配置和理论分析证明了其在权重谱和极化速度方面的优越性，是正则极化码的有效改进方案。

Abstract: In this paper, we introduce stitched polar codes, a novel generalization of Arıkan's regular polar codes. Our core methodology reconfigures the fundamental polarization process by stitching additional structures to enhance the reliability of less reliable information bits in the original code. This approach preserves the polar transformation structure and maintains the same encoding and decoding complexity. Thanks to the flexible configuration, stitched polar codes consistently outperform regular polar codes, effectively solving the performance degradation issue in rate-matched scenarios. Furthermore, we provide theoretical analysis on the weight spectrum and the polarization speed of stitched polar codes to prove their superiority.

</details>
