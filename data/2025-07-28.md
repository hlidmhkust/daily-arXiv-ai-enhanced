<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 7]
- [eess.SP](#eess.SP) [Total: 12]
- [cs.IT](#cs.IT) [Total: 9]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Estimating Sensitivity Maps for X-Nuclei Magnetic Resonance Spectroscopic Imaging](https://arxiv.org/abs/2507.18850)
*Nicholas Dwork,Jeremy W. Gordon,Shuyu Tang,Peder E. Z. Larson*

Main category: eess.IV

TL;DR: 研究提出了一种L2最优方法，用于估计X核成像中的灵敏度图，相比常用的RefPeak方法，能更准确地提取测量信息，提高信噪比。


<details>
  <summary>Details</summary>
Motivation: 在X核成像中，灵敏度图的准确估计对成像质量至关重要，尤其是当X核在视野中分布不均时。

Method: 通过解决最小二乘问题，利用光谱、动态成像或频谱激励的多重估计来优化灵敏度图。

Result: L2最优方法在数值模型和实际脑、胰腺、心脏成像中均表现出更高的准确性和信噪比。

Conclusion: L2最优方法能更有效地利用测量信息，优于传统RefPeak方法。

Abstract: The purpose of this research is to estimate sensitivity maps when imaging
X-nuclei that may not have a significant presence throughout the field of view.
We propose to estimate the coil's sensitivities by solving a least-squares
problem where each row corresponds to an individual estimate of the sensitivity
for a given voxel. Multiple estimates come from the multiple bins of the
spectrum with spectroscopy, multiple times with dynamic imaging, or multiple
frequencies when utilizing spectral excitation. The method presented in this
manuscript, called the L2 optimal method, is compared to the commonly used
RefPeak method which uses the spectral bin with the highest energy to estimate
the sensitivity maps. The L2 optimal method yields more accurate sensitivity
maps when imaging a numerical phantom and is shown to yield a higher
signal-to-noise ratio when imaging the brain, pancreas, and heart with
hyperpolarized pyruvate as the contrast agent with hyperpolarized MRI. The L2
optimal method is able to better estimate the sensitivity by extracting more
information from the measurements.

</details>


### [2] [RealisVSR: Detail-enhanced Diffusion for Real-World 4K Video Super-Resolution](https://arxiv.org/abs/2507.19138)
*Weisong Zhao,Jingkai Zhou,Xiangyu Zhu,Weihua Chen,Xiao-Yu Zhang,Zhen Lei,Fan Wang*

Main category: eess.IV

TL;DR: RealisVSR提出了一种基于扩散模型的高频细节增强视频超分辨率方法，解决了GAN方法的过平滑问题，并通过新架构、损失函数和4K基准数据集提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频超分辨率（VSR）存在三个主要问题：时间动态建模不一致、高频细节恢复不足，以及缺乏4K超分辨率评估。

Method: 1) 提出Consistency Preserved ControlNet (CPC)架构；2) 引入High-Frequency Rectified Diffusion Loss (HR-Loss)；3) 构建RealisVideo-4K数据集。

Result: 在多个VSR基准测试中表现优异，尤其在超高分辨率场景下，且训练数据量仅为现有方法的5-25%。

Conclusion: RealisVSR通过创新架构和损失函数，显著提升了视频超分辨率的细节恢复能力，并填补了4K评估的空白。

Abstract: Video Super-Resolution (VSR) has achieved significant progress through
diffusion models, effectively addressing the over-smoothing issues inherent in
GAN-based methods. Despite recent advances, three critical challenges persist
in VSR community: 1) Inconsistent modeling of temporal dynamics in foundational
models; 2) limited high-frequency detail recovery under complex real-world
degradations; and 3) insufficient evaluation of detail enhancement and 4K
super-resolution, as current methods primarily rely on 720P datasets with
inadequate details. To address these challenges, we propose RealisVSR, a
high-frequency detail-enhanced video diffusion model with three core
innovations: 1) Consistency Preserved ControlNet (CPC) architecture integrated
with the Wan2.1 video diffusion to model the smooth and complex motions and
suppress artifacts; 2) High-Frequency Rectified Diffusion Loss (HR-Loss)
combining wavelet decomposition and HOG feature constraints for texture
restoration; 3) RealisVideo-4K, the first public 4K VSR benchmark containing
1,000 high-definition video-text pairs. Leveraging the advanced spatio-temporal
guidance of Wan2.1, our method requires only 5-25% of the training data volume
compared to existing approaches. Extensive experiments on VSR benchmarks (REDS,
SPMCS, UDM10, YouTube-HQ, VideoLQ, RealisVideo-720P) demonstrate our
superiority, particularly in ultra-high-resolution scenarios.

</details>


### [3] [RegScore: Scoring Systems for Regression Tasks](https://arxiv.org/abs/2507.19155)
*Michal K. Grzeszczyk,Tomasz Szczepański,Pawel Renc,Siyeop Yoon,Jerome Charton,Tomasz Trzciński,Arkadiusz Sitek*

Main category: eess.IV

TL;DR: RegScore是一种新型、稀疏且可解释的评分系统，专为回归任务设计，通过放宽整数系数限制提升性能，并扩展到双模态深度学习。


<details>
  <summary>Details</summary>
Motivation: 解决传统评分系统在回归任务中的局限性，提供透明且可解释的解决方案。

Method: 结合波束搜索和k稀疏岭回归，集成表格数据和医学图像，生成个性化评分。

Result: 在估计肺动脉平均压任务中表现优于或媲美黑盒模型。

Conclusion: RegScore为临床回归任务提供了透明、可解释的方法，促进更可信的决策。

Abstract: Scoring systems are widely adopted in medical applications for their inherent
simplicity and transparency, particularly for classification tasks involving
tabular data. In this work, we introduce RegScore, a novel, sparse, and
interpretable scoring system specifically designed for regression tasks. Unlike
conventional scoring systems constrained to integer-valued coefficients,
RegScore leverages beam search and k-sparse ridge regression to relax these
restrictions, thus enhancing predictive performance. We extend RegScore to
bimodal deep learning by integrating tabular data with medical images. We
utilize the classification token from the TIP (Tabular Image Pretraining)
transformer to generate Personalized Linear Regression parameters and a
Personalized RegScore, enabling individualized scoring. We demonstrate the
effectiveness of RegScore by estimating mean Pulmonary Artery Pressure using
tabular data and further refine these estimates by incorporating cardiac MRI
images. Experimental results show that RegScore and its personalized bimodal
extensions achieve performance comparable to, or better than, state-of-the-art
black-box models. Our method provides a transparent and interpretable approach
for regression tasks in clinical settings, promoting more informed and
trustworthy decision-making. We provide our code at
https://github.com/SanoScience/RegScore.

</details>


### [4] [Extreme Cardiac MRI Analysis under Respiratory Motion: Results of the CMRxMotion Challenge](https://arxiv.org/abs/2507.19165)
*Kang Wang,Chen Qin,Zhang Shi,Haoran Wang,Xiwen Zhang,Chen Chen,Cheng Ouyang,Chengliang Dai,Yuanhan Mo,Chenchen Dai,Xutong Kuang,Ruizhe Li,Xin Chen,Xiuzheng Yue,Song Tian,Alejandro Mora-Rubio,Kumaradevan Punithakumar,Shizhan Gong,Qi Dou,Sina Amirrajab,Yasmina Al Khalil,Cian M. Scannell,Lexiaozi Fan,Huili Yang,Xiaowu Sun,Rob van der Geest,Tewodros Weldebirhan Arega,Fabrice Meriaudeau,Caner Özer,Amin Ranem,John Kalkhof,İlkay Öksüz,Anirban Mukhopadhyay,Abdul Qayyum,Moona Mazher,Steven A Niederer,Carles Garcia-Cabrera,Eric Arazo,Michal K. Grzeszczyk,Szymon Płotka,Wanqin Ma,Xiaomeng Li,Rongjun Ge,Yongqing Kou,Xinrong Chen,He Wang,Chengyan Wang,Wenjia Bai,Shuo Wang*

Main category: eess.IV

TL;DR: 论文探讨了深度学习模型在心脏磁共振（CMR）分析中的性能受图像质量影响的问题，并组织了MICCAI CMRxMotion挑战赛，发布了包含运动伪影的数据集，评估了22种算法在图像质量分类和心肌分割任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 临床实践中CMR图像常因呼吸运动伪影而质量下降，但深度学习模型对此类伪影的鲁棒性研究不足，因此组织了挑战赛以推动相关研究。

Method: 通过40名健康志愿者的特定呼吸协议生成包含运动伪影的320个CMR序列数据集，设计了图像质量分类和心肌分割两个任务，评估了22种算法。

Result: 挑战赛展示了多种算法在运动伪影下的表现，并分析了运动伪影对五种临床相关生物标志物的影响。

Conclusion: 研究强调了运动伪影对CMR分析的影响，公开的数据集和代码为未来研究提供了资源。

Abstract: Deep learning models have achieved state-of-the-art performance in automated
Cardiac Magnetic Resonance (CMR) analysis. However, the efficacy of these
models is highly dependent on the availability of high-quality, artifact-free
images. In clinical practice, CMR acquisitions are frequently degraded by
respiratory motion, yet the robustness of deep learning models against such
artifacts remains an underexplored problem. To promote research in this domain,
we organized the MICCAI CMRxMotion challenge. We curated and publicly released
a dataset of 320 CMR cine series from 40 healthy volunteers who performed
specific breathing protocols to induce a controlled spectrum of motion
artifacts. The challenge comprised two tasks: 1) automated image quality
assessment to classify images based on motion severity, and 2) robust
myocardial segmentation in the presence of motion artifacts. A total of 22
algorithms were submitted and evaluated on the two designated tasks. This paper
presents a comprehensive overview of the challenge design and dataset, reports
the evaluation results for the top-performing methods, and further investigates
the impact of motion artifacts on five clinically relevant biomarkers. All
resources and code are publicly available at: https://github.com/CMRxMotion

</details>


### [5] [Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning](https://arxiv.org/abs/2507.19199)
*Abdul Hannan,Zahid Mahmood,Rizwan Qureshi,Hazrat Ali*

Main category: eess.IV

TL;DR: 提出了一种结合全局注意力块（GAB）和类别注意力块（CAB）的深度学习模型，有效解决了糖尿病视网膜病变（DR）分类中的数据不平衡问题，并在公开数据集上取得了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）的自动分类对临床实践至关重要，但数据分布不平衡限制了深度学习模型的泛化能力。

Method: 采用基于注意力机制的深度学习模型，结合三种预训练网络（MobileNetV3-small、EfficientNet-b0、DenseNet-169）作为主干架构。

Result: 在APTOS和EYEPACS数据集上，模型分别达到最高83.20%和80%的准确率，并展示了较低的参数量。

Conclusion: 所提方法在DR分类中表现优异，与现有工作性能相当，同时参数量较少。

Abstract: Automatic classification of Diabetic Retinopathy (DR) can assist
ophthalmologists in devising personalized treatment plans, making it a critical
component of clinical practice. However, imbalanced data distribution in the
dataset becomes a bottleneck in the generalization of deep learning models
trained for DR classification. In this work, we combine global attention block
(GAB) and category attention block (CAB) into the deep learning model, thus
effectively overcoming the imbalanced data distribution problem in DR
classification. Our proposed approach is based on an attention mechanism-based
deep learning model that employs three pre-trained networks, namely,
MobileNetV3-small, Efficientnet-b0, and DenseNet-169 as the backbone
architecture. We evaluate the proposed method on two publicly available
datasets of retinal fundoscopy images for DR. Experimental results show that on
the APTOS dataset, the DenseNet-169 yielded 83.20% mean accuracy, followed by
the MobileNetV3-small and EfficientNet-b0, which yielded 82% and 80%
accuracies, respectively. On the EYEPACS dataset, the EfficientNet-b0 yielded a
mean accuracy of 80%, while the DenseNet-169 and MobileNetV3-small yielded
75.43% and 76.68% accuracies, respectively. In addition, we also compute the
F1-score of 82.0%, precision of 82.1%, sensitivity of 83.0%, specificity of
95.5%, and a kappa score of 88.2% for the experiments. Moreover, in our work,
the MobileNetV3-small has 1.6 million parameters on the APTOS dataset and 0.90
million parameters on the EYEPACS dataset, which is comparatively less than
other methods. The proposed approach achieves competitive performance that is
at par with recently reported works on DR classification.

</details>


### [6] [SAM2-Aug: Prior knowledge-based Augmentation for Target Volume Auto-Segmentation in Adaptive Radiation Therapy Using Segment Anything Model 2](https://arxiv.org/abs/2507.19282)
*Guoping Xu,Yan Dai,Hengrui Zhao,Ying Zhang,Jie Deng,Weiguo Lu,You Zhang*

Main category: eess.IV

TL;DR: 论文提出了一种基于先验知识的增强策略（SAM2-Aug），用于提升Segment Anything Model 2（SAM2）在肿瘤分割中的准确性，特别是在自适应放射治疗（ART）中的应用。


<details>
  <summary>Details</summary>
Motivation: 准确的肿瘤分割对自适应放射治疗至关重要，但现有方法耗时且依赖用户操作。SAM2在基于提示的分割中表现有潜力，但在肿瘤分割精度上仍有不足。

Method: 引入两种策略：1）使用先前的MR图像和标注作为上下文输入；2）通过随机边界框扩展和掩模腐蚀/膨胀增强提示鲁棒性。模型在One-Seq-Liver数据集上微调和测试，并在Mix-Seq-Abdomen和Mix-Seq-Brain数据集上验证泛化能力。

Result: SAM2-Aug在所有数据集上优于卷积、基于Transformer和提示驱动模型，Dice分数分别为0.86（肝脏）、0.89（腹部）和0.90（脑部），在边界敏感指标上表现更优。

Conclusion: 结合先验图像和增强提示多样性显著提升了分割精度和泛化能力。SAM2-Aug为ART中的肿瘤分割提供了高效、鲁棒的解决方案。

Abstract: Purpose: Accurate tumor segmentation is vital for adaptive radiation therapy
(ART) but remains time-consuming and user-dependent. Segment Anything Model 2
(SAM2) shows promise for prompt-based segmentation but struggles with tumor
accuracy. We propose prior knowledge-based augmentation strategies to enhance
SAM2 for ART.
  Methods: Two strategies were introduced to improve SAM2: (1) using prior MR
images and annotations as contextual inputs, and (2) improving prompt
robustness via random bounding box expansion and mask erosion/dilation. The
resulting model, SAM2-Aug, was fine-tuned and tested on the One-Seq-Liver
dataset (115 MRIs from 31 liver cancer patients), and evaluated without
retraining on Mix-Seq-Abdomen (88 MRIs, 28 patients) and Mix-Seq-Brain (86
MRIs, 37 patients).
  Results: SAM2-Aug outperformed convolutional, transformer-based, and
prompt-driven models across all datasets, achieving Dice scores of 0.86(liver),
0.89(abdomen), and 0.90(brain). It demonstrated strong generalization across
tumor types and imaging sequences, with improved performance in
boundary-sensitive metrics.
  Conclusions: Incorporating prior images and enhancing prompt diversity
significantly boosts segmentation accuracy and generalizability. SAM2-Aug
offers a robust, efficient solution for tumor segmentation in ART. Code and
models will be released at https://github.com/apple1986/SAM2-Aug.

</details>


### [7] [A multi-dynamic low-rank deep image prior (ML-DIP) for real-time 3D cardiovascular MRI](https://arxiv.org/abs/2507.19404)
*Chong Chen,Marc Vornehm,Preethi Chandrasekaran,Muhammad A. Sultan,Syed M. Arshad,Yingmin Liu,Yuchi Han,Rizwan Ahmad*

Main category: eess.IV

TL;DR: 开发了一种无需全采样训练数据的3D实时心血管磁共振（CMR）重建框架，通过多动态低秩深度图像先验（ML-DIP）方法实现高加速因子。


<details>
  <summary>Details</summary>
Motivation: 传统CMR重建需要全采样训练数据，限制了实时性和应用范围。ML-DIP旨在直接从欠采样数据中重建高质量动态图像。

Method: 使用分离的神经网络分别建模空间图像内容和时间变形场，通过每扫描优化直接重建动态图像序列。

Result: 在数字模体和人体实验中，ML-DIP表现出高信噪比和结构相似性，功能测量与2D cine相当，图像质量优于5D-Cine。

Conclusion: ML-DIP通过从欠采样数据中学习低秩时空表示，实现了高加速因子的高质量3D实时CMR重建，无需外部全采样数据。

Abstract: Purpose: To develop a reconstruction framework for 3D real-time cine
cardiovascular magnetic resonance (CMR) from highly undersampled data without
requiring fully sampled training data.
  Methods: We developed a multi-dynamic low-rank deep image prior (ML-DIP)
framework that models spatial image content and temporal deformation fields
using separate neural networks. These networks are optimized per scan to
reconstruct the dynamic image series directly from undersampled k-space data.
ML-DIP was evaluated on (i) a 3D cine digital phantom with simulated premature
ventricular contractions (PVCs), (ii) ten healthy subjects (including two
scanned during both rest and exercise), and (iii) five patients with PVCs.
Phantom results were assessed using peak signal-to-noise ratio (PSNR) and
structural similarity index measure (SSIM). In vivo performance was evaluated
by comparing left-ventricular function quantification (against 2D real-time
cine) and image quality (against 2D real-time cine and binning-based 5D-Cine).
  Results: In the phantom study, ML-DIP achieved PSNR > 29 dB and SSIM > 0.90
for scan times as short as two minutes, while recovering cardiac motion,
respiratory motion, and PVC events. In healthy subjects, ML-DIP yielded
functional measurements comparable to 2D cine and higher image quality than
5D-Cine, including during exercise with high heart rates and bulk motion. In
PVC patients, ML-DIP preserved beat-to-beat variability and reconstructed
irregular beats, whereas 5D-Cine showed motion artifacts and information loss
due to binning.
  Conclusion: ML-DIP enables high-quality 3D real-time CMR with acceleration
factors exceeding 1,000 by learning low-rank spatial and temporal
representations from undersampled data, without relying on external fully
sampled training datasets.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [8] [Design and Implementation of Parametrized Look-Up Tables for Post-Correction of Oversampling Low-Resolution ADCs](https://arxiv.org/abs/2507.18673)
*Morriel Kasher,Michael Tinston,Predrag Spasojevic*

Main category: eess.SP

TL;DR: 提出了一种用于设计、优化和实现查找表（LUT）的框架，用于恢复噪声、过采样和量化信号，并通过后量化数字解决方案模拟预量化抖动的频谱效果。


<details>
  <summary>Details</summary>
Motivation: 解决量化信号恢复中的频谱纯度问题，同时减少LUT的内存开销和计算复杂度。

Method: 将LUT设计问题分解为四个阶段，采用模型驱动方法，无需训练；研究了三种抖动方法并提出两种新颖的索引方案。

Result: LUT大小压缩超过四个数量级，性能损失极小；在3位量化信号中，SFDR提升超过19 dBc，仅需324字节内存。

Conclusion: 该框架适用于低分辨率宽带设备，具有超低延迟和高效性能。

Abstract: We propose a framework for the design, optimization, and implementation of
Look-Up Tables (LUTs) used to recover noisy, oversampled, quantized signals
given a parametric input model. The LUTs emulate the spectral effects of
pre-quantization dithering through an all-digital solution applied after
quantization. This methodology decomposes the intractable LUT design problem
into four distinct stages, each of which is addressed analytically using a
model-driven approach without reliance on training. Three dithering methods are
studied to improve spectral purity metrics. Two novel indexing schemes are
proposed to limit the LUT memory overhead shown to compress the LUT size by
over four orders of magnitude with marginal performance loss. The LUT design is
tested with an oversampled noisy sinusoidal input quantized to 3 bits and shown
to improve its Spurious-Free Dynamic Range (SFDR) by over 19 dBc with only 324
bytes of memory while maintaining the same 3-bit fixed-point precision at the
digital output. This correction can be implemented using two-level
combinational logic ensuring ultra-low latency and, hence, suitable for
low-resolution wideband devices.

</details>


### [9] [Exploiting Movable Antennas in NOMA Networks: Joint Beamforming, Power Allocation and Antenna Position Optimization](https://arxiv.org/abs/2507.18730)
*Yufeng Zhou,Wen Chen,Qingqing Wu,Xusheng Zhu,Zhendong Li,Kunlun Wang,Qiong Wu*

Main category: eess.SP

TL;DR: 论文研究了基于可移动天线（MA）的非正交多址（NOMA）下行链路网络，通过优化波束成形、功率分配和天线位置，最大化系统吞吐量。


<details>
  <summary>Details</summary>
Motivation: 利用可移动天线提供的自由度，提升NOMA网络的性能，解决传统固定天线系统的限制。

Method: 提出基于交替优化（AO）框架的算法，将问题分解为三个子问题，并采用SPCA和SCA技术处理非凸约束。

Result: 数值结果表明，所提系统在吞吐量上显著优于基准方法。

Conclusion: 通过联合优化天线位置和通信参数，可移动天线技术能有效提升NOMA网络的性能。

Abstract: This paper investigates the movable antenna (MA)- assisted downlink
non-orthogonal multiple access (NOMA) network to maximize system throughput. In
the considered scenario, both the base station (BS) and users are equipped with
MA, and a predetermined successive interference cancellation (SIC) decoding
order is adopted. Based on the field-response channel model, we formulate a
complex, non-convex problem to jointly optimize the BS beamforming, power
allocation, and MA positions at both the transmitter and receivers. To address
this, we propose an efficient algorithm based on an alternating optimization
(AO) framework, which decomposes the original problem into three distinct
subproblems. By employing sequential parametric convex approximation (SPCA) and
successive convex approximation (SCA) techniques, the non-convex constraints
within each subproblem are transformed into tractable. This methodology ensures
the algorithm converges to a stable, locally optimal solution. Numerical
results validate that the proposed system, which fully exploits the degrees of
freedom from antenna mobility at both ends, significantly outperforms
benchmarks in terms of throughput.

</details>


### [10] [Max-Min Rate Optimization for Multigroup Multicast MISO Systems Via Novel Transmissive RIS Transceiver](https://arxiv.org/abs/2507.18733)
*Yuan Guo,Wen Chen,Qingqing Wu,Yanze Zhu,Yang Liu,Zhendong Li,Ying Wang*

Main category: eess.SP

TL;DR: 论文提出了一种基于透射可重构智能表面（RIS）的多组多播下行通信系统，通过优化算法解决用户最小速率最大化问题，并提出了三种算法以降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究透射RIS在多组多播通信中的应用，解决传统方法计算复杂度高和性能受限的问题。

Method: 采用逐次凸近似（SCA）和惩罚函数法设计迭代算法，进一步提出基于二阶锥规划（SOCP）和加权最小均方误差（WMMSE）的高效方法，以及结合平滑近似理论和MM方法的低复杂度算法。

Result: 数值结果表明，SOCP方法在最小速率和计算复杂度上优于惩罚算法，而低复杂度算法在性能略有下降的情况下显著降低了复杂度。

Conclusion: 透射RIS架构在多组多播通信中具有潜力，提出的算法在性能和复杂度之间实现了有效平衡。

Abstract: This paper investigates a novel transmissive reconfigurable intelligent
surface (RIS) transceiver architectureenabled multigroup multicast downlink
communication system. Under this setup, an optimization problem is formulated
to maximize the minimum rate of users across all groups, subject to the maximum
available power of each RIS unit. Due to the nondifferentiable nature of the
objective function, the max-min rate problem is challenging to solve. To tackle
this difficult problem, we develop an iterative solution by leveraging the
successive convex approximation (SCA) and the penalty function method. However,
the above approach has high computational complexity and may lead to
compromised performance. To overcome these drawbacks, we design an efficient
second-order cone programming (SOCP)-based method using the weighted minimum
mean squared error (WMMSE) framework to reduce computational complexity.
Furthermore, to further reduce the computational complexity, we also propose a
low-complexity and solver-free algorithm that analytically updates all
variables by combining the smooth approximation theory and the
majorization-minimization (MM) method. Numerical results are provided to verify
the convergence and effectiveness of our proposed three algorithms. It is also
demonstrated that the SOCP-based method outperforms the penalty-based algorithm
in terms of both the achieved min rate and the computational complexity. In
contrast, the lowcomplexity design achieves significantly lower complexity with
only slightly degraded performance.

</details>


### [11] [Max-Min Fairness-Oriented Beamforming Design in HAPS-Enabled ISAC for 6G Networks](https://arxiv.org/abs/2507.18764)
*Parisa Kanani,Mohammad Javad Omidi,Mahmoud Modarres-Hashemi,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 论文提出了一种基于高空平台站（HAPS）的集成感知与通信（ISAC）系统，用于6G网络，通过优化资源分配实现公平性和高效性。


<details>
  <summary>Details</summary>
Motivation: 解决6G网络中公平服务分配的需求，同时提升感知与通信的性能。

Method: 采用非凸优化方法，通过最大-最小公平性策略平衡感知波束增益和通信用户的SINR需求，并满足功率约束。

Result: 仿真结果表明，HAPS-ISAC系统能高效分配资源，提供可靠覆盖并提升感知精度。

Conclusion: HAPS-ISAC系统是6G网络和集成通信-感知系统的关键推动者。

Abstract: This paper presents a high-altitude platform station (HAPS)-enabled
integrated sensing and communication (ISAC) system designed for
sixth-generation (6G) networks. Positioned in the stratosphere, HAPS serves as
a super-macro base station, leveraging advanced beamforming techniques to
enable communication and sensing simultaneously. This research addresses the
need for equitable service distribution in 6G networks by focusing on fairness
within the HAPS-ISAC system. It tackles a non-convex optimization problem that
balances sensing beampattern gain and signal-to-interference-plus-noise ratio
(SINR) requirements among communication users (CUs) using a max-min fairness
approach while adhering to power constraints. The proposed HAPS-ISAC framework
ensures efficient resource allocation, reliable coverage, and improved sensing
accuracy. Simulation results validate the potential of HAPS-ISAC as a pivotal
enabler for 6G networks and integrated communication-sensing systems.

</details>


### [12] [Flexible Intelligent Metasurfaces in High-Mobility MIMO Integrated Sensing and Communications](https://arxiv.org/abs/2507.18793)
*Kuranage Roche Rayan Ranasinghe,Jiancheng An,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Chau Yuen,Mérouane Debbah*

Main category: eess.SP

TL;DR: 提出了一种结合灵活智能超表面（FIM）的双色散（DD）MIMO信道模型，用于高移动性场景下的集成感知与通信（ISAC），并优化了多种波形的可实现速率。


<details>
  <summary>Details</summary>
Motivation: 高移动性场景下，传统信道模型难以满足ISAC需求，需结合FIM技术提升性能。

Method: 提出FIM参数化的DD信道模型（FPDD），应用于OFDM、OTFS和AFDM波形，并通过梯度上升算法优化可实现速率。

Result: 数值结果表明，FIM技术及参数化对提升ISAC性能至关重要。

Conclusion: FIM技术能显著改善DD信道下的ISAC性能，需精细参数化以实现最佳效果。

Abstract: We propose a novel doubly-dispersive (DD) multiple-input multiple-output
(MIMO) channel model incorporating flexible intelligent metasurfaces (FIMs),
which is suitable for integrated sensing and communications (ISAC) in
high-mobility scenarios. We then discuss how the proposed FIM-parameterized DD
(FPDD) channel model can be applied in a logical manner to ISAC waveforms that
are known to perform well in DD environments, namely, orthogonal frequency
division multiplexing (OFDM), orthogonal time frequency space (OTFS), and
affine frequency division multiplexing (AFDM). Leveraging the proposed model,
we formulate an achievable rate maximization problem with a strong sensing
constraint for all the aforementioned waveforms, which we then solve via a
gradient ascent algorithm with closed-form gradients presented as a bonus. Our
numerical results indicate that the achievable rate is significantly impacted
by the emerging FIM technology with careful parametrization essential in
obtaining strong ISAC performance across all waveforms suitable to mitigating
the effects of DD channels.

</details>


### [13] [A Fingerprint Database Generation Method for RIS-Assisted Indoor Positioning](https://arxiv.org/abs/2507.18927)
*Xin Cheng,Yu He,Menglu Li,Ruoguang Li,Feng Shu,Guangjie Han*

Main category: eess.SP

TL;DR: 提出了一种生成RIS辅助RSS指纹数据库的新方法，解决了现有方法在空间一致性和信道建模上的不足。


<details>
  <summary>Details</summary>
Motivation: 解决RIS辅助室内定位中缺乏现实且空间一致的RSS指纹数据库生成方法的挑战。

Method: 通过扩展的基于簇的信道建模和RIS/Tx的物理电磁特性，模拟RIS辅助的多径行为，并在相邻位置模拟数据收集时保持空间一致性。

Result: 生成的指纹数据库具有高度灵活性，支持RIS和Tx参数配置，并通过KNN和DNN验证了定位性能。

Conclusion: 该方法为RIS辅助室内定位系统设计提供了有价值的工具和见解。

Abstract: Reconfigurable intelligent surface (RIS) has emerged as a promising
technology to enhance indoor wireless communication and sensing performance.
However, the construction of reliable received signal strength (RSS)-based
fingerprint databases for RIS-assisted indoor positioning remains an open
challenge due to the lack of realistic and spatially consistent channel
modeling methods. In this paper, we propose a novel method with open-source
codes for generating RIS-assisted RSS fingerprint databases. Our method
captures the complex RIS-assisted multipath behaviors by extended cluster-based
channel modeling and the physical and electromagnetic properties of RIS and
transmitter (Tx). And the spatial consistency is incorporated when simulating
the fingerprint data collection across neighboring positions. Furthermore, the
proposed method offers exceptional flexibility in configuring RIS and Tx
parameters. Extensive simulations are conducted to evaluate the fingerprint
database generated by the proposed method. Moreover, the positioning
performance on the database using K-nearest neighbors (KNN) and deep neural
network (DNN) is analyzed, providing valuable insights for the system design.

</details>


### [14] [Assessing the Reliability and Validity of a Balance Mat for Measuring Postural Stability: A Combined Robot-Human Approach](https://arxiv.org/abs/2507.18943)
*Abishek Shrestha,Damith Herath,Angie Fearon,Maryam Ghahramani*

Main category: eess.SP

TL;DR: 研究评估了一种新型平衡垫（BM）的可靠性和有效性，作为实验室条件下金标准力板（FP）的低成本便携替代方案。通过机器人实验和人体实验验证了BM的性能。


<details>
  <summary>Details</summary>
Motivation: 力板（FP）在实验室条件下是评估姿势摇摆的金标准，但其便携性差且需要专业知识，限制了广泛应用。研究旨在验证BM作为替代方案的可行性。

Method: 研究分为两部分：机器人实验使用UR10机械臂生成受控摇摆模式评估BM的可靠性和灵敏度；人体实验通过51名健康年轻参与者在BM和FP上完成平衡任务，比较摇摆指标。

Result: 机器人实验显示BM在单腿和双腿站立中具有良好至优秀的可靠性（ICC>0.75）。人体实验显示摇摆路径和范围的中等到强相关性，但BM高估了摇摆指标，需校准改进一致性。

Conclusion: BM在多种站立条件下表现出稳定的摇摆测量性能，经过校准后具备可靠性和有效性，可作为FP的便携替代方案。

Abstract: Postural sway assessment is important for detecting balance problems and
identifying people at risk of falls. Force plates (FP) are considered the gold
standard postural sway assessment method in laboratory conditions, but their
lack of portability and requirement of high-level expertise limit their
widespread usage. This study evaluates the reliability and validity of a novel
Balance Mat (BM) device, a low-cost portable alternative that uses optical
fibre technology. The research includes two studies: a robot study and a human
study. In the robot study, a UR10 robotic arm was used to obtain controlled
sway patterns to assess the reliability and sensitivity of the BM. In the human
study, 51 healthy young participants performed balance tasks on the BM in
combination with an FP to evaluate the BM's validity. Sway metrics such as sway
mean, sway absolute mean, sway root mean square (RMS), sway path, sway range,
and sway velocity were calculated from both BM and FP and compared. Reliability
was evaluated using the intra-class correlation coefficient (ICC), where values
greater than 0.9 were considered excellent and values between 0.75 and 0.9 were
considered good. Results from the robot study demonstrated good to excellent
ICC values in both single and double-leg stances. The human study showed
moderate to strong correlations for sway path and range. Using Bland-Altman
plots for agreement analysis revealed proportional bias between the BM and the
FP where the BM overestimated sway metrics compared to the FP. Calibration was
used to improve the agreement between the devices. The device demonstrated
consistent sway measurement across varied stance conditions, establishing both
reliability and validity following appropriate calibration.

</details>


### [15] [Max-Min Beamforming for Large-Scale Cell-Free Massive MIMO: A Randomized ADMM Algorithm](https://arxiv.org/abs/2507.18980)
*Bin Wang,Jun Fang,Yue Xiao,Martin Haardt*

Main category: eess.SP

TL;DR: 提出了一种随机ADMM算法，用于解决大规模最大最小波束成形问题，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有确定性优化方法在问题规模增大时计算效率低下，需改进。

Method: 将可行性检查问题转化为线性约束优化问题，并开发随机ADMM算法，每次迭代仅需解决少量子问题。

Result: 算法具有O(1/\bar{t})收敛速度，数值结果显示其复杂度优势显著。

Conclusion: 随机ADMM算法在大规模MMB问题中高效且计算复杂度低。

Abstract: We consider the problem of max-min beamforming (MMB) for cell-free massive
multi-input multi-output (MIMO) systems, where the objective is to maximize the
minimum achievable rate among all users. Existing MMB methods are mainly based
on deterministic optimization methods, which are computationally inefficient
when the problem size grows large. To address this issue, we, in this paper,
propose a randomized alternating direction method of multiplier (ADMM)
algorithm for large-scale MMB problems. We first propose a novel formulation
that transforms the highly challenging feasibility-checking problem into a
linearly constrained optimization problem. An efficient randomized ADMM is then
developed for solving the linearly constrained problem. Unlike standard ADMM,
randomized ADMM only needs to solve a small number of subproblems at each
iteration to ensure convergence, thus achieving a substantial complexity
reduction. Our theoretical analysis reveals that the proposed algorithm
exhibits an O(1/\bar{t}) convergence rate (\bar{t} represents the number of
iterations), which is on the same order as its deterministic counterpart.
Numerical results show that the proposed algorithm offers a significant
complexity advantage over existing methods in solving the MMB problem.

</details>


### [16] [Machine Learning based Radio Environment Map Estimation for Indoor Visible Light Communication](https://arxiv.org/abs/2507.19149)
*Helena Serpi,Christina,Politi*

Main category: eess.SP

TL;DR: 提出了一种基于机器学习的无线光通信中无线电地图估计的创新方法，替代传统仿真技术。


<details>
  <summary>Details</summary>
Motivation: 传统仿真技术可能耗时且复杂，机器学习方法旨在提供更快速、准确的信号传播估计。

Method: 使用多层感知机（MLP）建模室内可见光通信（VLC）系统，并通过调整MLP参数（如样本量、训练轮次和批量大小）优化性能。

Result: 该方法在仿真和性能预测上表现准确、快速，且所需训练样本量较少，适合实时估计。

Conclusion: 通过调整MLP参数，可以在推理准确性和训练时间之间取得平衡，满足实时需求。

Abstract: An innovative method for radio map estimation in optical wireless
communications is proposed that is based on Machine Learning rather than
simulation techniques. Multi-Layer Perceptron (MLP) representation of indoor
Visible Light Communication (VLC) systems is suggested, and signal propagation
is estimated. The simulation and performance predictions are accurate, fast and
require a reduced set of training sample size with respect to other
counterparts, making this solution very suitable for real time estimation of an
indoor VLC system. It is shown that by tweaking MLP parameters, such as sample
size, number of epochs and batch size, one can balance the desired level of
inference accuracy with training time and optimize the model's performance to
meet real-time requirements.

</details>


### [17] [High-Fidelity RF Mapping: Assessing Environmental Modeling in 6G Network Digital Twins](https://arxiv.org/abs/2507.19173)
*Lorenzo Cazzella,Francesco Linsalata,Damiano Badini,Matteo Matteucci,Maurizio Magarini,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 论文提出了两种度量方法（HRT和CRT）来比较不同环境变化下3D场景中的射线追踪模拟结果，并通过米兰高保真数字孪生模型验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 评估电磁环境数字孪生（DT）建模的准确性，需要比较不同建模精度下的射线追踪模拟差异。

Method: 提出了Hausdorff射线追踪（HRT）和chamfer射线追踪（CRT）距离度量方法，并在米兰数字孪生模型中测试了两种环境变化（停车车辆和建筑窗户分割）的影响。

Result: HRT和CRT成功识别了模拟中因环境变化导致的无线电传播特征差异，并揭示了车辆轨迹上的距离模式。

Conclusion: 提出的HRT和CRT方法能有效评估环境变化对射线追踪模拟的影响，为数字孪生建模提供了实用工具。

Abstract: The design of accurate Digital Twins (DTs) of electromagnetic environments
strictly depends on the fidelity of the underlying environmental modeling.
Evaluating the differences among diverse levels of modeling accuracy is key to
determine the relevance of the model features towards both efficient and
accurate DT simulations. In this paper, we propose two metrics, the Hausdorff
ray tracing (HRT) and chamfer ray tracing (CRT) distances, to consistently
compare the temporal, angular and power features between two ray tracing
simulations performed on 3D scenarios featured by environmental changes. To
evaluate the introduced metrics, we considered a high-fidelity digital twin
model of an area of Milan, Italy and we enriched it with two different types of
environmental changes: (i) the inclusion of parked vehicles meshes, and (ii)
the segmentation of the buildings facade faces to separate the windows mesh
components from the rest of the building. We performed grid-based and vehicular
ray tracing simulations at 28 GHz carrier frequency on the obtained scenarios
integrating the NVIDIA Sionna RT ray tracing simulator with the SUMO vehicular
traffic simulator. Both the HRT and CRT metrics highlighted the areas of the
scenarios where the simulated radio propagation features differ owing to the
introduced mesh integrations, while the vehicular ray tracing simulations
allowed to uncover the distance patterns arising along realistic vehicular
trajectories.

</details>


### [18] [Bespoke multiresolution analysis of graph signals](https://arxiv.org/abs/2507.19181)
*Giacomo Elefante,Gianluca Giacchi,Michael Multerer,Jacopo Quizi*

Main category: eess.SP

TL;DR: 提出了一种基于图信号的多分辨率分析框架，利用样本变换（samplet transform）实现高效压缩和分析，显著优于传统Haar小波方法。


<details>
  <summary>Details</summary>
Motivation: 传统Haar小波方法在图信号分析中存在局限性，需要一种更灵活且高效的多分辨率分析工具。

Method: 将图划分为多个子图，嵌入欧几里得空间构造样本变换，再映射回图，结合重边聚类和Isomap实现高效数值计算。

Result: 方法具有鲁棒性、可扩展性，并能生成稀疏表示，压缩效率和分辨率保真度显著优于Haar小波。

Conclusion: 样本变换框架为图信号分析提供了更高效的工具，适用于复杂图结构信号的处理。

Abstract: We present a novel framework for discrete multiresolution analysis of graph
signals. The main analytical tool is the samplet transform, originally defined
in the Euclidean framework as a discrete wavelet-like construction, tailored to
the analysis of scattered data. The first contribution of this work is defining
samplets on graphs. To this end, we subdivide the graph into a fixed number of
patches, embed each patch into a Euclidean space, where we construct samplets,
and eventually pull the construction back to the graph. This ensures
orthogonality, locality, and the vanishing moments property with respect to
properly defined polynomial spaces on graphs. Compared to classical Haar
wavelets, this framework broadens the class of graph signals that can
efficiently be compressed and analyzed. Along this line, we provide a
definition of a class of signals that can be compressed using our construction.
We support our findings with different examples of signals defined on graphs
whose vertices lie on smooth manifolds. For efficient numerical implementation,
we combine heavy edge clustering, to partition the graph into meaningful
patches, with landmark \texttt{Isomap}, which provides low-dimensional
embeddings for each patch. Our results demonstrate the method's robustness,
scalability, and ability to yield sparse representations with controllable
approximation error, significantly outperforming traditional Haar wavelet
approaches in terms of compression efficiency and multiresolution fidelity.

</details>


### [19] [Real-time rail vehicle localisation using spatially resolved magnetic field measurements](https://arxiv.org/abs/2507.19327)
*Niklas Dieckow,Katharina Ostaszewski,Philip Heinisch,Henriette Struckmann,Hendrik Ranocha*

Main category: eess.SP

TL;DR: 论文提出了两种基于磁场测量的实时铁路车辆定位方法，结合粒子滤波和序列对齐技术，实现了高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决铁路车辆在复杂环境中的实时定位问题，尤其是在低速和冷启动情况下的性能挑战。

Method: 1. 粒子滤波方法：通过磁相似性重加权，使用重尾非高斯核增强稳定性。2. 序列对齐方法：将实时磁信号转换为空间域并与地图匹配。

Result: 粒子滤波在21.6公里范围内实现亚5米精度，但在低速和冷启动时性能下降；对齐方法在冷启动时表现优异，92%测试中定位误差小于30米。

Conclusion: 混合方法结合两种技术，提供了适用于安全关键铁路应用的准确、鲁棒定位方案。

Abstract: This work presents two complementary real-time rail vehicle localization
methods based on magnetic field measurements and a pre-recorded magnetic map.
The first uses a particle filter reweighted via magnetic similarity, employing
a heavy-tailed non-Gaussian kernel for enhanced stability. The second is a
stateless sequence alignment technique that transforms real-time magnetic
signals into the spatial domain and matches them to the map using a similarity
measure. Experiments with operational train data show that the particle filter
achieves track-selective, sub-5-meter accuracy over 21.6 km, though its
performance degrades at low speeds and during cold starts. Accuracy tests were
constrained by the GNSS-based reference system. In contrast, the
alignment-based method excels in cold-start scenarios, localizing within 30 m
in 92 % of tests (100 % using top-3 matches). A hybrid approach combines both
methods$\unicode{x2014}$alignment-based initialization followed by particle
filter tracking. Runtime analysis confirms real-time capability on
consumer-grade hardware. The system delivers accurate, robust localization
suitable for safety-critical rail applications.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [20] [RIS Codebook Index Assignment under Imperfect Control Links Using TSP-Inspired Optimization](https://arxiv.org/abs/2507.18727)
*Liangshun Wu,Wen Chen,Qingqing Wu,Xudong Bai,Kunlun Wang*

Main category: cs.IT

TL;DR: 论文提出了一种鲁棒的RIS码本索引分配方法，通过组合优化问题（类似TSP）解决反馈错误导致的性能下降问题，并提出了一种三阶段启发式算法。


<details>
  <summary>Details</summary>
Motivation: 实际部署中，RIS的相位状态控制通过有限码本实现，但反馈通道的比特错误会导致RIS状态与应用状态不匹配，从而降低系统性能。

Method: 将问题建模为组合优化问题（类似TSP），并提出三阶段启发式算法（预备阶段、散弹阶段和模糊连接阶段）来解决。

Result: 仿真结果表明，该方法优于传统索引策略，对索引错误具有接近最优的鲁棒性，且可扩展性强、硬件无关。

Conclusion: 该方法在实时部署中表现出色，未来工作包括多比特错误校正和时变信道的在线自适应映射。

Abstract: Reconfigurable Intelligent Surfaces (RIS) promise transformative gains in
wireless communications by enabling programmable control of the propagation
environment through discrete phase configurations. In practical deployments,
the control of RIS phase states is typically managed using finite codebooks,
with configuration indices transmitted over low latency, yet imperfect,
wireless feedback channels. Even rare feedback bit errors can lead to
significant mismatches between intended and applied RIS states, degrading
system performance. This paper addresses the challenge of robust RIS codebook
index assignment by formulating it as a combinatorial optimization problem,
equivalent to the Traveling Salesman Problem (TSP), where codewords are
"cities" and edge weights reflect SNR degradation under codeword confusion. A
novel three-phase heuristic algorithm is proposed to solve this, consisting of
a provision phase, a shotgun phase, and a fuzzy concatenation phase. Simulation
results show that the method outperforms conventional indexing strategies and
achieves near-optimal robustness to index errors, while also being scalable and
hardwareagnostic for real time deployment. Future work includes multiple bits
error correction and online adaptive mapping for time varying channels.

</details>


### [21] [EDPC: Accelerating Lossless Compression via Lightweight Probability Models and Decoupled Parallel Dataflow](https://arxiv.org/abs/2507.18969)
*Zeyi Lu,Xiaoxiao Ma,Yujun Huang,Minxiao Chen,Bin Chen,Baoyi An,Shu-Tao Xia*

Main category: cs.IT

TL;DR: 论文提出了一种高效的双路径并行压缩框架（EDPC），通过优化建模能力和执行效率，显著提升了压缩速度和压缩比。


<details>
  <summary>Details</summary>
Motivation: 多源多媒体数据的爆炸性增长对传输和存储提出了更高要求，现有自回归压缩模型（ACMs）因特征提取不足和实时处理瓶颈而受限。

Method: EDPC结合信息流细化（IFR）和多路径字节细化块（MBRB）优化建模，并利用潜在变换引擎（LTE）和解耦管道压缩架构（DPCA）提升系统效率。

Result: 实验表明，EDPC压缩速度提升2.7倍，压缩比提高3.2%，优于现有方法。

Conclusion: EDPC为带宽受限场景下的大规模多媒体数据实时处理提供了高效解决方案。

Abstract: The explosive growth of multi-source multimedia data has significantly
increased the demands for transmission and storage, placing substantial
pressure on bandwidth and storage infrastructures. While Autoregressive
Compression Models (ACMs) have markedly improved compression efficiency through
probabilistic prediction, current approaches remain constrained by two critical
limitations: suboptimal compression ratios due to insufficient fine-grained
feature extraction during probability modeling, and real-time processing
bottlenecks caused by high resource consumption and low compression speeds. To
address these challenges, we propose Efficient Dual-path Parallel Compression
(EDPC), a hierarchically optimized compression framework that synergistically
enhances modeling capability and execution efficiency via coordinated dual-path
operations. At the modeling level, we introduce the Information Flow Refinement
(IFR) metric grounded in mutual information theory, and design a Multi-path
Byte Refinement Block (MBRB) to strengthen cross-byte dependency modeling via
heterogeneous feature propagation. At the system level, we develop a Latent
Transformation Engine (LTE) for compact high-dimensional feature representation
and a Decoupled Pipeline Compression Architecture (DPCA) to eliminate
encoding-decoding latency through pipelined parallelization. Experimental
results demonstrate that EDPC achieves comprehensive improvements over
state-of-the-art methods, including a 2.7x faster compression speed, and a 3.2%
higher compression ratio. These advancements establish EDPC as an efficient
solution for real-time processing of large-scale multimedia data in
bandwidth-constrained scenarios. Our code is available at
https://github.com/Magie0/EDPC.

</details>


### [22] [Dynamic Agile Reconfigurable Intelligent Surface Antenna (DARISA) MIMO: DoF Analysis and Effective DoF Optimization](https://arxiv.org/abs/2507.19136)
*Jiale Bai,Hui-Ming Wang,Liang Jin*

Main category: cs.IT

TL;DR: 提出了一种动态敏捷可重构智能表面天线（DARISA）阵列，集成到MIMO收发器中，通过并行馈电网络实现快速相位响应调整，提升系统自由度（DoF）和有效自由度（EDoF）。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过动态调整智能表面相位响应，提升MIMO系统的自由度和信道容量。

Method: 采用动态敏捷相位响应调整（DAAPR）策略，结合分数规划（FP）和半定松弛（SDR）算法优化相位响应。

Result: 理论分析和仿真表明，DAAPR策略可显著提升系统DoF和EDoF，密集部署元件可弥补低相位量化精度带来的性能损失。

Conclusion: DARISA MIMO系统通过动态相位调整和优化算法，显著提升了信道容量和性能。

Abstract: In this paper, we propose a dynamic agile reconfigurable intelligent surface
antenna (DARISA) array integrated into multi-input multi-output (MIMO)
transceivers. Each DARISA comprises a number of metasurface elements activated
simultaneously via a parallel feed network. The proposed system enables rapid
and intelligent phase response adjustments for each metasurface element within
a single symbol duration, facilitating a dynamic agile adjustment of phase
response (DAAPR) strategy. By analyzing the theoretical degrees of freedom
(DoF) of the DARISA MIMO system under the DAAPR framework, we derive an
explicit relationship between DoF and critical system parameters, including
agility frequentness (i.e., the number of phase adjustments of metasurface
elements during one symbol period), cluster angular spread of wireless
channels, DARISA array size, and the number of transmit/receive DARISAs. The
DoF result reveals a significant conclusion: when the number of receive DARISAs
is smaller than that of transmit DARISAs, the DAAPR strategy of the DARISA MIMO
enhances the overall system DoF. Furthermore, relying on DoF alone to measure
channel capacity is insufficient, so we analyze the effective DoF (EDoF) that
reflects the impacts of the DoF and channel matrix singular value distribution
on capacity. We show channel capacity monotonically increases with EDoF, and
optimize the agile phase responses of metasurface elements by using fractional
programming (FP) and semidefinite relaxation (SDR) algorithms to maximize the
EDoF. Simulations validate the theoretical DoF gains and reveal that increasing
agility frequentness, metasurface element density, and phase quantization
accuracy can enhance the EDoF. Additionally, densely deployed elements can
compensate for the loss in communication performance caused by lower phase
quantization accuracy.

</details>


### [23] [Achievable Rates for a Distributed Antenna System with No Channel State Information at the Central Processor](https://arxiv.org/abs/2507.19177)
*Yi Song,Hao Xu,Kai Wan,Kai-Kit Wong,Giuseppe Caire,Shlomo Shamai*

Main category: cs.IT

TL;DR: 论文研究了无线通信中分散式架构的上行链路性能，重点关注了信道状态随机性和前传容量限制对速率的影响。


<details>
  <summary>Details</summary>
Motivation: 实际中信道状态是随机的，且需要通过上行链路导频符号估计，这可能导致显著的开销，尤其是在前传容量较小的情况下。

Method: 分析了由单个用户和两个中继组成的钻石网络，假设中继已知信道状态而中央处理器未知。

Result: 推导了在高斯信道下的遍历可达速率。

Conclusion: 论文为分散式架构在随机信道状态下的性能提供了理论分析，强调了导频和前传容量的重要性。

Abstract: A recent trend in wireless communications considers the migration of
traditional monolithic base stations to the so-called disaggregated
architecture, where radio units (RUs) implement only the low-level physical
layer functionalities such as demodulation, and A/D conversion, while the
high-level physical layer, such as channel decoding, is implemented as
software-defined functions running on general-purpose hardware in some remote
central processing unit (CP). The corresponding information theoretic model for
the uplink (from the wireless users to the CP) is a multiaccess-relay channel
with primitive oblivious relays. The relays (RUs) are oblivious, as they are
agnostic of the users codebooks, and primitive, since the fronthaul links (from
RUs to CP) are error-free with limited capacity. This class of networks has
been intensely studied in the information theoretic literature, where several
approximated or exact (under certain conditions) capacity results have been
derived. In particular, in the Gaussian case, the model has been analyzed for
fixed and known channel state. This paper is motivated by the fact that, in
practice, the channel state is a random process, and it is estimated at the
base station side through uplink pilot symbols sent by the users. The pilot
dimension may take up a large portion of the channel coherence block, i.e., the
number of symbols over which the channel state remains approximately constant.
Hence, sending both pilot and data symbols from the relays to the CP may
require a significant overhead, especially when the fronthaul capacity is
small. As a prototypical problem, we consider the ergodic achievable rate for a
diamond network formed by a single user and two relays where the channel state
is known at the relays, but not known at the CP.

</details>


### [24] [Overview of 3GPP Release 19 Study on Channel Modeling Enhancements to TR 38.901 for 6G](https://arxiv.org/abs/2507.19266)
*Hitesh Poddar,Dimitri Gold,Daewon Lee,Nan Zhang,Gokul Sridharan,Henrik Asplund,Mansoor Shaf*

Main category: cs.IT

TL;DR: 本文介绍了3GPP Rel 19对7-24 GHz频段信道模型的改进，填补了6G技术中的关键空白。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统的发展需要更准确的信道模型，尤其是7-24 GHz频段在6G中的潜力。

Method: 通过3GPP Rel 19研究，改进了信道模型，包括场景建模、天线模型、簇和射线数量可变性等。

Result: 研究增强了3GPP TR 38.901信道模型，支持未来6G部署的关键特性。

Conclusion: 3GPP Rel 19的信道模型改进为6G技术提供了重要支持。

Abstract: Channel models are a fundamental component of wireless communication systems,
providing critical insights into the physics of radio wave propagation. As
wireless systems evolve every decade, the development of accurate and
standardized channel models becomes increasingly important for the development,
evaluation and performance assessment of emerging technologies. An effort to
develop a standardized channel model began around 2000 through the Third
Generation Partnership Project (3GPP) and the International Telecommunication
Union (ITU) with the aim of addressing a broad range of frequencies from sub-1
GHz to 100 GHz. Prior efforts focused heavily on sub-6 GHz bands and mmWave
bands, and there exist some gaps in accurately modeling the 7-24 GHz frequency
range, a promising candidate band for 6G. To address these gaps, 3GPP approved
a Release (Rel) 19 channel modeling study. This study resulted in several
enhancements to the channel models, including the ability to accurately model a
Suburban Macrocell (SMa) scenario, realistic User Terminal (UT) antenna models,
variability in the number of clusters, variability in the number of rays per
cluster, a framework for capturing variability in power among all
polarizations, near field (NF) propagation, and spatial non-stationarity (SNS)
effects, all of which may be crucial for future 6G deployments. This paper
presents the outcomes of this study and provides an overview of the underlying
rationale, and key discussions that guided the validation, refinement, and
enhancements of the 3GPP TR 38.901 channel models.

</details>


### [25] [Sparse Recovery from Group Orbits](https://arxiv.org/abs/2507.19274)
*Timm Gilles,Hartmut Führ*

Main category: cs.IT

TL;DR: 论文提出了一个框架，用于处理由有限群表示的随机轨道生成的结构化测量，分析了固定和随机采样集两种情况，并推导了确保受限等距性质所需的测量数量。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏恢复结果通常仅允许测量方案中的最小结构，而许多实际问题具有显著结构，因此需要填补这一空白。

Method: 通过有限群表示的随机轨道生成结构化测量，分析固定和随机采样集两种情况，推导所需测量数量的估计。

Result: 结果表明，所需测量数量取决于具体表示，并分析了多种表示（如左正则表示）对恢复结果的影响。

Conclusion: 该工作不仅为群结构测量的稀疏恢复建立了框架，还推广了已有的测量方案（如部分随机循环矩阵）。

Abstract: While most existing sparse recovery results allow only minimal structure
within the measurement scheme, many practical problems possess significant
structure. To address this gap, we present a framework for structured
measurements that are generated by random orbits of a group representation
associated with a finite group. We differentiate between two scenarios: one in
which the sampling set is fixed and another in which the sampling set is
randomized. For each case, we derive an estimate for the number of measurements
required to ensure that the restricted isometry property holds with high
probability. These estimates are contingent upon the specific representation
employed. For this reason, we analyze and characterize various representations
that yield favorable recovery outcomes, including the left regular
representation. Our work not only establishes a comprehensive framework for
sparse recovery of group-structured measurements but also generalizes
established measurement schemes, such as those derived from partial random
circulant matrices.

</details>


### [26] [Low-Complexity 6DMA Rotation and Position Optimization Based on Statistical Channel Information](https://arxiv.org/abs/2507.19309)
*Qijun Jiang,Xiaodan Shao,Rui Zhang*

Main category: cs.IT

TL;DR: 提出了一种新的6DMA优化方法，通过顺序优化旋转和位置，显著降低计算复杂度，同时保持通信性能。


<details>
  <summary>Details</summary>
Motivation: 充分利用6DMA技术通过灵活调整天线位置和旋转来优化无线信道性能。

Method: 提出顺序优化方法，先确定最优旋转，再在约束条件下找到可行位置。

Result: 仿真结果显示，该方法计算复杂度显著降低，通信性能与交替优化方法相当，优于固定天线阵列。

Conclusion: 新方法在性能和复杂度之间取得了良好平衡，适用于6DMA基站设计。

Abstract: The six-dimensional movable antenna (6DMA) is a promising technology to fully
exploit spatial variation in wireless channels by allowing flexible adjustment
of three-dimensional (3D) positions and rotations of antennas at the
transceiver. In this paper, we consider a 6DMA-equipped base station (BS) and
aim to maximize the average sum logarithmic rate of all users served by the BS
by jointly designing 6DMA surface positions and rotations based on statistical
channel information (SCI). Different from prior works on 6DMA design which use
alternating optimization to iteratively update surface positions and rotations,
we propose a new sequential optimization method that first determines the
optimal rotations and then identifies feasible positions to realize these
rotations under practical antenna placement constraints. Simulation results
show that our proposed optimization scheme significantly reduces the
computational complexity of conventional alternating optimization (AO), while
achieving communication performance comparable to the AO-based approach and
superior to existing fixed-position/rotation antenna arrays.

</details>


### [27] [On Anti-collusion Codes for Averaging Attack in Multimedia Fingerprinting](https://arxiv.org/abs/2507.19384)
*Jing Jiang,Cailin Wen,Minquan Cheng*

Main category: cs.IT

TL;DR: 论文提出了一种新型的多媒体指纹追踪算法，并引入了二进制强可识别父属性码（SMIPPC）及其级联码，以提高抗平均攻击的指纹码率。


<details>
  <summary>Details</summary>
Motivation: 现有的多媒体指纹码因强组合结构导致码率低，且追踪算法简单，无法高效追踪所有共谋者。

Method: 提出新的追踪算法，并设计具有较弱组合结构的SMIPPC及其级联码。

Result: 理论及数值比较显示，SMIPPC码率高于现有码，且新算法具有更强的追踪能力。

Conclusion: SMIPPC及其级联码在提高码率的同时，通过新算法实现了更强的共谋者追踪能力。

Abstract: Multimedia fingerprinting is a technique to protect the copyrighted contents
against being illegally redistributed under various collusion attack models.
Averaging attack is the most fair choice for each colluder to avoid detection,
and also makes the pirate copy have better perceptional quality. This makes
such an attack one of the most feasible approaches to carrying out collusion.
In order to trace all the colluders, several types of multimedia fingerprinting
codes were introduced to construct fingerprints resistant to averaging attacks
on multimedia contents, such as AND anti-collusion codes (AND-ACCs), binary
separable codes (SCs), logical anti-collusion codes (LACCs), binary frameproof
codes (FPCs), binary strongly-separable codes (SSCs) and binary secure code
with list decoding (SCLDs). Then codes with the rate as high as possible are
desired. However, the existing fingerprinting codes have low code rate due to
the strong combinatorial structure. The reason is that the previous research
methods adopted simple tracing algorithms. In this paper, we first propose
novel tracing algorithms and then find appropriate fingerprinting codes with
weaker combinatorial structure, i.e., the binary strongly identifiable parent
property code for multimedia fingerprinting (SMIPPC) and its concatenated code.
Theoretical comparisons and numerical comparisons show that SMIPPCs have higher
code rates than those of the existing codes due to their weaker combinatorial
structures. It is worth noting that SMIPPCs can only trace a part of colluders
by using the previous tracing algorithm and the concatenated SMIPPC may be not
an SMIPPC. This implies that our tracing algorithms have strong traceability.

</details>


### [28] [Sample Abundance for Signal Processing: A Brief Introduction](https://arxiv.org/abs/2507.19415)
*Arian Eamaz,Farhang Yeganegi,Mojtaba Soltanalian*

Main category: cs.IT

TL;DR: 论文介绍了在低精度信号处理中样本丰富的概念及其优势，展示了如何通过大量低精度测量简化传统复杂约束，并提供了算法和理论保证。


<details>
  <summary>Details</summary>
Motivation: 探讨在低精度信号处理框架中样本丰富的现象及其潜在优势，以简化传统信号处理中的复杂约束。

Method: 利用大量低精度测量，将传统复杂约束（如矩阵半定性和秩条件）转化为简单的超定线性可行性问题。

Result: 通过有限体积性质和样本丰富奇点现象，展示了计算复杂度显著下降的效果。

Conclusion: 样本丰富现象在低精度信号处理中具有显著优势，能够简化问题并降低计算复杂度。

Abstract: This paper reports, by way of introduction, on the advances made by our group
and the broader signal processing community on the concept of sample abundance;
a phenomenon that naturally arises in one-bit and few-bit signal processing
frameworks. By leveraging large volumes of low-precision measurements, we show
how traditionally costly constraints, such as matrix semi-definiteness and rank
conditions, become redundant, yielding simple overdetermined linear feasibility
problems. We illustrate key algorithms, theoretical guarantees via the Finite
Volume Property, and the sample abundance singularity phenomenon, where
computational complexity sharply drops.

</details>
