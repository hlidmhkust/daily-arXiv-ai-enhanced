{"id": "2512.14776", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.14776", "abs": "https://arxiv.org/abs/2512.14776", "authors": ["Xiangxiang Li", "Haiyan Wang", "Yao Ge", "Xiaohong Shen", "Miaowen Wen", "Shun Zhang", "Yong Liang Guan"], "title": "Low-Complexity Channel Estimation for Internet of Vehicles AFDM Communications With Sparse Bayesian Learning", "comment": null, "summary": "Affine frequency division multiplexing (AFDM) has been considered as a promising waveform to enable high-reliable connectivity in the internet of vehicles. However, accurate channel estimation is critical and challenging to achieve the expected performance of the AFDM systems in doubly-dispersive channels. In this paper, we propose a sparse Bayesian learning (SBL) framework for AFDM systems and develop a dynamic grid update strategy with two off-grid channel estimation methods, i.e., grid-refinement SBL (GR-SBL) and grid-evolution SBL (GE-SBL) estimators. Specifically, the GR-SBL employs a localized grid refinement method and dynamically updates grid for a high-precision estimation. The GE-SBL estimator approximates the off-grid components via first-order linear approximation and enables gradual grid evolution for estimation accuracy enhancement. Furthermore, we develop a distributed computing scheme to decompose the large-dimensional channel estimation model into multiple manageable small-dimensional sub-models for complexity reduction of GR-SBL and GE-SBL, denoted as distributed GR-SBL (D-GR-SBL) and distributed GE-SBL (D-GE-SBL) estimators, which also support parallel processing to reduce the computational latency. Finally, simulation results demonstrate that the proposed channel estimators outperform existing competitive schemes. The GR-SBL estimator achieves high-precision estimation with fine step sizes at the cost of high complexity, while the GE-SBL estimator provides a better trade-off between performance and complexity. The proposed D-GR-SBL and D-GE-SBL estimators effectively reduce complexity and maintain comparable performance to GR-SBL and GE-SBL estimators, respectively.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7a00\u758f\u8d1d\u53f6\u65af\u5b66\u4e60\u7684AFDM\u7cfb\u7edf\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u5305\u62ec\u7f51\u683c\u7ec6\u5316SBL\u548c\u7f51\u683c\u6f14\u5316SBL\u4e24\u79cd\u79bb\u7f51\u683c\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u5206\u5e03\u5f0f\u8ba1\u7b97\u65b9\u6848\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "AFDM\u5728\u8f66\u8054\u7f51\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\u9700\u8981\u7cbe\u786e\u7684\u4fe1\u9053\u4f30\u8ba1\u6765\u5b9e\u73b0\u9884\u671f\u6027\u80fd\uff0c\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51faSBL\u6846\u67b6\uff0c\u5f00\u53d1\u4e24\u79cd\u79bb\u7f51\u683c\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff1aGR-SBL\u91c7\u7528\u5c40\u90e8\u7f51\u683c\u7ec6\u5316\u52a8\u6001\u66f4\u65b0\u7f51\u683c\uff1bGE-SBL\u901a\u8fc7\u4e00\u9636\u7ebf\u6027\u8fd1\u4f3c\u903c\u8fd1\u79bb\u7f51\u683c\u5206\u91cf\u5b9e\u73b0\u6e10\u8fdb\u7f51\u683c\u6f14\u5316\u3002\u8fd8\u5f00\u53d1\u5206\u5e03\u5f0f\u8ba1\u7b97\u65b9\u6848\u5c06\u5927\u7ef4\u6a21\u578b\u5206\u89e3\u4e3a\u591a\u4e2a\u5c0f\u7ef4\u5b50\u6a21\u578b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u4fe1\u9053\u4f30\u8ba1\u5668\u4f18\u4e8e\u73b0\u6709\u7ade\u4e89\u65b9\u6848\u3002GR-SBL\u4ee5\u9ad8\u590d\u6742\u5ea6\u4e3a\u4ee3\u4ef7\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\uff0cGE-SBL\u5728\u6027\u80fd\u548c\u590d\u6742\u5ea6\u95f4\u63d0\u4f9b\u66f4\u597d\u6298\u8877\u3002\u5206\u5e03\u5f0f\u7248\u672c\u6709\u6548\u964d\u4f4e\u590d\u6742\u5ea6\u5e76\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684SBL\u6846\u67b6\u548c\u5206\u5e03\u5f0f\u8ba1\u7b97\u65b9\u6848\u4e3aAFDM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0cGR-SBL\u9002\u5408\u9ad8\u7cbe\u5ea6\u9700\u6c42\uff0cGE-SBL\u63d0\u4f9b\u66f4\u597d\u5e73\u8861\uff0c\u5206\u5e03\u5f0f\u7248\u672c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2512.15049", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15049", "abs": "https://arxiv.org/abs/2512.15049", "authors": ["Kai Huang", "Xinyu Xie", "Chunpeng Chen", "Wenjie Guan", "Xiaoran Wang", "Jinbei Zhang"], "title": "On the Stochastic Analysis of Random Linear Streaming Codes in Multi-Hop Relay Networks", "comment": null, "summary": "In this paper, we aim to explore the stochastic performance limit of large-field-size Random Linear Streaming Codes (RLSCs) in multi-hop relay networks. In our model, a source transmits a sequence of streaming messages to a destination through multiple relays subject to a delay constraint. Most previous research focused on deterministic adversarial channel which introduces only restricted types of erasure patterns, and aimed to design the optimal capacity-achieving codes. In this paper, we focus on stochastic channel where each hop is subject to i.i.d. packet erasures, and carry out stochastic analysis on the error probability of multi-hop RLSCs. Our contributions are three-folds. Firstly, the error event of large-field-size RLSCs is characterized in two-hop relay network with a novel framework, which features quantification of information flowing through each node in the network. Due to the erasures in different hops, some source symbols can be \"detained\" at the source or relay while others have arrived at the destination. By iteratively computing the number of detained symbols at each node, this framework extends the concept \"information debt\" from point-to-point network [Pinwen Su et al. 2022] into two-hop relay networks. Secondly, based on the error event, the expression of average error probability in two-hop network is derived by carefully analyzing the expectation terms. To handle the expectation over all possible erasure patterns along two hops of the network, the transition matrices of the detained symbols are novelly constructed in a \"band fashion\" with nested structure. Thirdly, the derived results in two-hop network are further generalized into relay networks with arbitrary number of hops. Furthermore, simulations are conducted to verify the accuracy of our stochastic analysis, and compare with some existing streaming codes for the adversarial channels.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u591a\u8df3\u4e2d\u7ee7\u7f51\u7edc\u4e2d\u5927\u89c4\u6a21\u968f\u673a\u7ebf\u6027\u6d41\u7801\u7684\u968f\u673a\u6027\u80fd\u6781\u9650\uff0c\u901a\u8fc7\u91cf\u5316\u7f51\u7edc\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u4fe1\u606f\u6d41\uff0c\u5c06\"\u4fe1\u606f\u503a\u52a1\"\u6982\u5ff5\u4ece\u70b9\u5bf9\u70b9\u7f51\u7edc\u6269\u5c55\u5230\u4e24\u8df3\u4e2d\u7ee7\u7f51\u7edc\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a8\u5e7f\u5230\u4efb\u610f\u8df3\u6570\u7684\u4e2d\u7ee7\u7f51\u7edc\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u786e\u5b9a\u6027\u5bf9\u6297\u4fe1\u9053\uff0c\u4ec5\u8003\u8651\u53d7\u9650\u7c7b\u578b\u7684\u64e6\u9664\u6a21\u5f0f\uff0c\u65e8\u5728\u8bbe\u8ba1\u6700\u4f18\u5bb9\u91cf\u5b9e\u73b0\u7801\u3002\u672c\u6587\u8f6c\u5411\u968f\u673a\u4fe1\u9053\u6a21\u578b\uff0c\u5176\u4e2d\u6bcf\u8df3\u90fd\u53d7\u5230\u72ec\u7acb\u540c\u5206\u5e03\u7684\u5305\u64e6\u9664\uff0c\u5bf9\u591a\u8df3\u968f\u673a\u7ebf\u6027\u6d41\u7801\u7684\u8bef\u7801\u6982\u7387\u8fdb\u884c\u968f\u673a\u5206\u6790\u3002", "method": "1. \u5728\u4e24\u8df3\u4e2d\u7ee7\u7f51\u7edc\u4e2d\uff0c\u901a\u8fc7\u91cf\u5316\u6bcf\u4e2a\u8282\u70b9\u7684\u4fe1\u606f\u6d41\uff0c\u5c06\"\u4fe1\u606f\u503a\u52a1\"\u6982\u5ff5\u6269\u5c55\u5230\u4e24\u8df3\u7f51\u7edc\uff1b2. \u57fa\u4e8e\u8bef\u5dee\u4e8b\u4ef6\uff0c\u901a\u8fc7\u6784\u9020\u5177\u6709\u5d4c\u5957\u7ed3\u6784\u7684\"\u5e26\u72b6\"\u8f6c\u79fb\u77e9\u9635\uff0c\u63a8\u5bfc\u4e24\u8df3\u7f51\u7edc\u7684\u5e73\u5747\u8bef\u7801\u6982\u7387\u8868\u8fbe\u5f0f\uff1b3. \u5c06\u4e24\u8df3\u7f51\u7edc\u7684\u7ed3\u679c\u63a8\u5e7f\u5230\u4efb\u610f\u8df3\u6570\u7684\u4e2d\u7ee7\u7f51\u7edc\uff1b4. \u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u5206\u6790\u51c6\u786e\u6027\u3002", "result": "1. \u63d0\u51fa\u4e86\u91cf\u5316\u7f51\u7edc\u4e2d\u6bcf\u4e2a\u8282\u70b9\u4fe1\u606f\u6d41\u7684\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u63cf\u8ff0\u5927\u89c4\u6a21\u968f\u673a\u7ebf\u6027\u6d41\u7801\u7684\u8bef\u5dee\u4e8b\u4ef6\uff1b2. \u63a8\u5bfc\u4e86\u4e24\u8df3\u7f51\u7edc\u4e2d\u5e73\u5747\u8bef\u7801\u6982\u7387\u7684\u7cbe\u786e\u8868\u8fbe\u5f0f\uff1b3. \u5c06\u5206\u6790\u7ed3\u679c\u63a8\u5e7f\u5230\u4efb\u610f\u8df3\u6570\u7684\u4e2d\u7ee7\u7f51\u7edc\uff1b4. \u4eff\u771f\u9a8c\u8bc1\u4e86\u968f\u673a\u5206\u6790\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e0e\u73b0\u6709\u5bf9\u6297\u4fe1\u9053\u6d41\u7801\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c06\u968f\u673a\u5206\u6790\u6846\u67b6\u4ece\u70b9\u5bf9\u70b9\u7f51\u7edc\u6269\u5c55\u5230\u591a\u8df3\u4e2d\u7ee7\u7f51\u7edc\uff0c\u4e3a\u968f\u673a\u4fe1\u9053\u4e0b\u7684\u5927\u89c4\u6a21\u968f\u673a\u7ebf\u6027\u6d41\u7801\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u6027\u80fd\u5206\u6790\u5de5\u5177\uff0c\u586b\u8865\u4e86\u5bf9\u6297\u4fe1\u9053\u5206\u6790\u4e0e\u968f\u673a\u4fe1\u9053\u5206\u6790\u4e4b\u95f4\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.15092", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15092", "abs": "https://arxiv.org/abs/2512.15092", "authors": ["Chao Zhou", "Changsheng You", "Cong Zhou", "Liujia Yao", "Weijie Yuan", "Beixiong Zheng", "Nan Wu"], "title": "Rotatable IRS-Assisted 6DMA Communications: A Two-timescale Design", "comment": "13 pages, 8 figures, submitted to IEEE for possible publication", "summary": "Intelligent reflecting surface (IRS) and movable antenna (MA) are promising technologies to enhance wireless communication by reconfiguring channels at the environment and transceiver sides. However, their performance is constrained by practical limitations. To address this, we propose a multi-functional antenna/surface system that leverages their complementary advantages. A rotatable IRS (R-IRS) is deployed to enhance downlink communications from a six-dimensional MA (6DMA)-equipped base station (BS) to multiple single-antenna users. To reduce the complexity of real-time channel estimation and beamforming, we formulate an optimization problem to maximize the average sum-rate using a two-timescale (TTS) transmission protocol. Specifically, the BS antenna configuration (including position and rotation) and IRS rotation and reflection are optimized based on statistical channel state information (S-CSI), while BS transmit beamforming is designed using instantaneous CSI (I-CSI) in the short timescale. We first consider a single-user case and show that the 6DMA at the BS should form a sparse array for multi-beam transmission towards both the IRS and the user, allowing efficient coordination of direct and reflected channels, while the IRS rotation achieves effective multi-path alignment. For the general multi-user case, the optimization problem is non-convex and challenging to solve. To tackle this, we propose an efficient algorithm combining weighted minimum mean-square error (WMMSE) and stochastic successive convex approximation (SSCA) techniques. A low-complexity algorithm is also proposed to reduce computational complexity. Numerical results validate the proposed system, showing significant performance gains by jointly exploiting the spatial degrees of freedom of the 6DMA-BS and R-IRS under the TTS protocol.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u54086DMA\u57fa\u7ad9\u548c\u53ef\u65cb\u8f6cIRS\u7684\u591a\u529f\u80fd\u5929\u7ebf/\u8868\u9762\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u65f6\u95f4\u5c3a\u5ea6\u534f\u8bae\u4f18\u5316\u5929\u7ebf\u914d\u7f6e\u548c\u6ce2\u675f\u6210\u5f62\uff0c\u663e\u8457\u63d0\u5347\u591a\u7528\u6237\u4e0b\u884c\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "IRS\u548cMA\u6280\u672f\u867d\u7136\u80fd\u91cd\u6784\u65e0\u7ebf\u4fe1\u9053\uff0c\u4f46\u5404\u81ea\u5b58\u5728\u6027\u80fd\u9650\u5236\u3002\u4e3a\u4e86\u5145\u5206\u53d1\u6325\u4e24\u8005\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u96c6\u6210\u7cfb\u7edf\u6765\u63d0\u5347\u591a\u7528\u6237\u4e0b\u884c\u901a\u4fe1\u6027\u80fd\u3002", "method": "\u90e8\u7f72\u53ef\u65cb\u8f6cIRS(R-IRS)\u548c\u516d\u7ef4MA(6DMA)\u57fa\u7ad9\uff0c\u91c7\u7528\u4e24\u65f6\u95f4\u5c3a\u5ea6\u4f20\u8f93\u534f\u8bae\uff1a\u57fa\u4e8e\u7edf\u8ba1CSI\u4f18\u5316\u5929\u7ebf\u914d\u7f6e\u548cIRS\u65cb\u8f6c\u53cd\u5c04\uff0c\u57fa\u4e8e\u77ac\u65f6CSI\u8bbe\u8ba1\u6ce2\u675f\u6210\u5f62\u3002\u9488\u5bf9\u591a\u7528\u6237\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7ed3\u5408WMMSE\u548cSSCA\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5355\u7528\u6237\u573a\u666f\u4e2d\uff0c6DMA\u5e94\u5f62\u6210\u7a00\u758f\u9635\u5217\u8fdb\u884c\u591a\u6ce2\u675f\u4f20\u8f93\uff0cIRS\u65cb\u8f6c\u5b9e\u73b0\u591a\u5f84\u5bf9\u9f50\uff1b\u591a\u7528\u6237\u573a\u666f\u4e2d\uff0c\u6240\u63d0\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u95ee\u9898\u3002\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728TTS\u534f\u8bae\u4e0b\u901a\u8fc7\u8054\u5408\u5229\u75286DMA-BS\u548cR-IRS\u7684\u7a7a\u95f4\u81ea\u7531\u5ea6\u83b7\u5f97\u663e\u8457\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u529f\u80fd\u5929\u7ebf/\u8868\u9762\u7cfb\u7edf\u901a\u8fc7\u7ed3\u54086DMA\u548cR-IRS\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u91c7\u7528TTS\u534f\u8bae\u548c\u9ad8\u6548\u4f18\u5316\u7b97\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u591a\u7528\u6237\u4e0b\u884c\u901a\u4fe1\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.15191", "categories": ["cs.IT", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.15191", "abs": "https://arxiv.org/abs/2512.15191", "authors": ["Mengchu Xu", "Jian Wang", "Yonina C. Eldar"], "title": "Sparse Principal Component Analysis with Energy Profile Dependent Sample Complexity", "comment": "33 pages, 7 figures", "summary": "We study sparse principal component analysis in the high-dimensional, sample-limited regime, aiming to recover a leading component supported on a few coordinates. Despite extensive progress, most methods and analyses are tailored to the flat-spike case, offering little guidance when spike energy is unevenly distributed across the support. Motivated by this, we propose Spectral Energy Pursuit (SEP), an effective iterative scheme that repeatedly screens and reselects coordinates, with a sample complexity that adapts to the energy profile. We develop our framework around a structure function \\(s(p)\\) that quantifies how spike energy accumulates over its top \\(p\\) entries. We establish that SEP succeeds with a sample size of order \\(\\max_{1\\le p\\le k} p\\,s^2(p)\\,\\log n\\), which matches the classical \\(k^2\\log n\\) sample complexity for flat spikes and improves toward the \\(k\\log n\\) regime as the profile becomes more concentrated. As a lightweight post-processing, a single truncated power iteration is proven to enable the final estimator to attain a uniform statistical error bound. Empirical simulations across flat, power-law, and exponential signals validate that SEP adapts to profile structure without tuning and outperforms existing algorithms.", "AI": {"tldr": "\u63d0\u51faSEP\u7b97\u6cd5\u7528\u4e8e\u7a00\u758f\u4e3b\u6210\u5206\u5206\u6790\uff0c\u901a\u8fc7\u8fed\u4ee3\u7b5b\u9009\u5750\u6807\u6765\u9002\u5e94\u80fd\u91cf\u5206\u5e03\u4e0d\u5747\u5300\u7684\u4fe1\u53f7\uff0c\u6837\u672c\u590d\u6742\u5ea6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7a00\u758fPCA\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u80fd\u91cf\u5747\u5300\u5206\u5e03\u7684\u5e73\u5766\u4fe1\u53f7\uff0c\u5bf9\u80fd\u91cf\u5206\u5e03\u4e0d\u5747\u5300\u7684\u4fe1\u53f7\u7f3a\u4e4f\u6709\u6548\u6307\u5bfc\uff0c\u9700\u8981\u80fd\u9002\u5e94\u4e0d\u540c\u80fd\u91cf\u5206\u5e03\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u8c31\u80fd\u91cf\u8ffd\u8e2a(SEP)\u8fed\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u91cd\u590d\u7b5b\u9009\u548c\u91cd\u9009\u5750\u6807\u6765\u9002\u5e94\u4fe1\u53f7\u7684\u80fd\u91cf\u5206\u5e03\uff0c\u4f7f\u7528\u7ed3\u6784\u51fd\u6570s(p)\u91cf\u5316\u80fd\u91cf\u7d2f\u79ef\uff0c\u6700\u540e\u901a\u8fc7\u622a\u65ad\u5e42\u8fed\u4ee3\u8fdb\u884c\u540e\u5904\u7406\u3002", "result": "SEP\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e3amax_{1\u2264p\u2264k} p s\u00b2(p) log n\uff0c\u5728\u5e73\u5766\u4fe1\u53f7\u4e0b\u5339\u914d\u7ecf\u5178\u7684k\u00b2 log n\uff0c\u5728\u96c6\u4e2d\u5206\u5e03\u65f6\u63a5\u8fd1k log n\uff0c\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "SEP\u7b97\u6cd5\u80fd\u81ea\u9002\u5e94\u4e0d\u540c\u80fd\u91cf\u5206\u5e03\uff08\u5e73\u5766\u3001\u5e42\u5f8b\u3001\u6307\u6570\uff09\u7684\u7a00\u758f\u4fe1\u53f7\uff0c\u65e0\u9700\u8c03\u53c2\uff0c\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6548\u679c\u3002"}}
{"id": "2512.14796", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14796", "abs": "https://arxiv.org/abs/2512.14796", "authors": ["Mahmut S. Gokmen", "Mitchell A. Klusty", "Peter T. Nelson", "Allison M. Neltner", "Sen-Ching Samson Cheung", "Thomas M. Pearce", "David A Gutman", "Brittany N. Dugger", "Devavrat S. Bisht", "Margaret E. Flanagan", "V. K. Cody Bumgardner"], "title": "Magnification-Aware Distillation (MAD): A Self-Supervised Framework for Unified Representation Learning in Gigapixel Whole-Slide Images", "comment": "10 pages, 4 figures, 5 tables, submitted to AMIA 2026 Informatics Summit", "summary": "Whole-slide images (WSIs) contain tissue information distributed across multiple magnification levels, yet most self-supervised methods treat these scales as independent views. This separation prevents models from learning representations that remain stable when resolution changes, a key requirement for practical neuropathology workflows. This study introduces Magnification-Aware Distillation (MAD), a self-supervised strategy that links low-magnification context with spatially aligned high-magnification detail, enabling the model to learn how coarse tissue structure relates to fine cellular patterns. The resulting foundation model, MAD-NP, is trained entirely through this cross-scale correspondence without annotations. A linear classifier trained only on 10x embeddings maintains 96.7% of its performance when applied to unseen 40x tiles, demonstrating strong resolution-invariant representation learning. Segmentation outputs remain consistent across magnifications, preserving anatomical boundaries and minimizing noise. These results highlight the feasibility of scalable, magnification-robust WSI analysis using a unified embedding space", "AI": {"tldr": "\u63d0\u51faMAD-NP\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u5c3a\u5ea6\u81ea\u76d1\u7763\u84b8\u998f\u5b66\u4e60\u5206\u8fa8\u7387\u4e0d\u53d8\u7684WSI\u8868\u793a\uff0c\u65e0\u9700\u6807\u6ce8\u5373\u53ef\u5b9e\u73b0\u653e\u5927\u500d\u6570\u9c81\u68d2\u7684\u7ec4\u7ec7\u75c5\u7406\u5b66\u5206\u6790", "motivation": "\u73b0\u6709\u81ea\u76d1\u7763\u65b9\u6cd5\u5c06WSI\u7684\u4e0d\u540c\u653e\u5927\u500d\u6570\u89c6\u4e3a\u72ec\u7acb\u89c6\u56fe\uff0c\u65e0\u6cd5\u5b66\u4e60\u5206\u8fa8\u7387\u53d8\u5316\u65f6\u4fdd\u6301\u7a33\u5b9a\u7684\u8868\u793a\uff0c\u800c\u5b9e\u9645\u795e\u7ecf\u75c5\u7406\u5b66\u5de5\u4f5c\u6d41\u9700\u8981\u8fd9\u79cd\u7a33\u5b9a\u6027", "method": "\u63d0\u51fa\u653e\u5927\u500d\u6570\u611f\u77e5\u84b8\u998f(MAD)\u7b56\u7565\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u65b9\u5f0f\u5c06\u4f4e\u500d\u4e0a\u4e0b\u6587\u4e0e\u7a7a\u95f4\u5bf9\u9f50\u7684\u9ad8\u500d\u7ec6\u8282\u8054\u7cfb\u8d77\u6765\uff0c\u5b66\u4e60\u7c97\u7ec4\u7ec7\u7ed3\u6784\u4e0e\u7cbe\u7ec6\u7ec6\u80de\u6a21\u5f0f\u7684\u5173\u7cfb", "result": "MAD-NP\u6a21\u578b\u4ec5\u752810x\u5d4c\u5165\u8bad\u7ec3\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u5728\u672a\u89c1\u8fc7\u768440x\u5207\u7247\u4e0a\u4fdd\u630196.7%\u6027\u80fd\uff1b\u5206\u5272\u8f93\u51fa\u5728\u4e0d\u540c\u653e\u5927\u500d\u6570\u4e0b\u4fdd\u6301\u4e00\u81f4\uff0c\u4fdd\u7559\u89e3\u5256\u8fb9\u754c\u5e76\u51cf\u5c11\u566a\u58f0", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u7684\u5d4c\u5165\u7a7a\u95f4\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u653e\u5927\u500d\u6570\u9c81\u68d2\u7684WSI\u5206\u6790\u662f\u53ef\u884c\u7684\uff0cMAD\u65b9\u6cd5\u4e3a\u65e0\u6807\u6ce8\u7684\u7ec4\u7ec7\u75c5\u7406\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.14893", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.14893", "abs": "https://arxiv.org/abs/2512.14893", "authors": ["Reza Mohammadkhani", "Azad Azizzadeh", "Seyed Vahab Al-Din Makki", "John Thompson", "Maziar Nekovee"], "title": "Compensation of Coarse Quantization Effects on Channel Estimation and BER in Massive MIMO", "comment": "12 pages, submitted to IEEE Transactions", "summary": "Low-resolution quantization is essential to reduce implementation cost and power consumption in massive multiple-input multiple-output (MIMO) systems for 5G and 6G. While most existing studies assume perfect channel state information (CSI), we model the impact of coarse quantization noise on both channel estimation and data transmission, yielding a more realistic assessment of system performance under imperfect CSI conditions in the uplink. We develop a tight approximation for the bit-error ratio (BER) of uncoded M-QAM with zero-forcing detection, based on the linear minimum mean-square error (LMMSE) channel estimate. These analytical results enable compensation strategies that jointly optimize quantization resolution, transmit power, and pilot length across different numbers of users and base station antennas. We further demonstrate the applicability of the proposed framework through several design scenarios that highlight its effectiveness in optimizing system parameters and improving energy efficiency under quantization constraints. For example, in a 16-QAM system, extending the pilot sequence by 2.5 times and lowering transmit power by 0.5 dB enables a 3-bit quantized system to match the BER of the full-resolution case. The proposed framework offers a fast and accurate alternative to Monte Carlo simulations, enabling practical system optimization under realistic quantization constraints.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u6790\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u5bf9\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u6027\u80fd\u5f71\u54cd\u7684\u6846\u67b6\uff0c\u8003\u8651\u4e86\u4e0d\u5b8c\u7f8eCSI\u6761\u4ef6\u4e0b\u7684\u4fe1\u9053\u4f30\u8ba1\u548c\u6570\u636e\u4f20\u8f93\uff0c\u5e76\u5f00\u53d1\u4e86BER\u8fd1\u4f3c\u516c\u5f0f\u4ee5\u4f18\u5316\u7cfb\u7edf\u53c2\u6570\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u5047\u8bbe\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u4f46\u5b9e\u9645\u7cfb\u7edf\u4e2d\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u4f1a\u4ea7\u751f\u91cf\u5316\u566a\u58f0\uff0c\u5f71\u54cd\u4fe1\u9053\u4f30\u8ba1\u548c\u6570\u636e\u4f20\u8f93\u6027\u80fd\u3002\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u4f18\u53165G/6G\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u5728\u91cf\u5316\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u57fa\u4e8eLMMSE\u4fe1\u9053\u4f30\u8ba1\uff0c\u5f00\u53d1\u4e86\u96f6\u8feb\u68c0\u6d4b\u4e0b\u672a\u7f16\u7801M-QAM\u7684BER\u7d27\u81f4\u8fd1\u4f3c\u516c\u5f0f\u3002\u5efa\u6a21\u91cf\u5316\u566a\u58f0\u5bf9\u4fe1\u9053\u4f30\u8ba1\u548c\u6570\u636e\u4f20\u8f93\u7684\u5f71\u54cd\uff0c\u5efa\u7acb\u8054\u5408\u4f18\u5316\u91cf\u5316\u5206\u8fa8\u7387\u3001\u53d1\u5c04\u529f\u7387\u548c\u5bfc\u9891\u957f\u5ea6\u7684\u8865\u507f\u7b56\u7565\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u7684\u5206\u6790\u6846\u67b6\u80fd\u51c6\u786e\u8bc4\u4f30\u91cf\u5316\u7cfb\u7edf\u6027\u80fd\uff0c\u4f8b\u5982\u572816-QAM\u7cfb\u7edf\u4e2d\uff0c\u5c06\u5bfc\u9891\u5e8f\u5217\u5ef6\u957f2.5\u500d\u5e76\u964d\u4f4e\u53d1\u5c04\u529f\u73870.5dB\uff0c\u53ef\u4f7f3\u6bd4\u7279\u91cf\u5316\u7cfb\u7edf\u8fbe\u5230\u5168\u5206\u8fa8\u7387\u7cfb\u7edf\u7684BER\u6027\u80fd\u3002\u8be5\u6846\u67b6\u4e3a\u8499\u7279\u5361\u6d1b\u4eff\u771f\u63d0\u4f9b\u4e86\u5feb\u901f\u51c6\u786e\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u6709\u6548\u4f18\u5316\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u5728\u91cf\u5316\u7ea6\u675f\u4e0b\u7684\u53c2\u6570\u914d\u7f6e\uff0c\u63d0\u9ad8\u80fd\u91cf\u6548\u7387\uff0c\u4e3a5G/6G\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2512.15241", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15241", "abs": "https://arxiv.org/abs/2512.15241", "authors": ["Yinghui Ye", "Ying Li", "Xiaoli Chu", "Gan Zheng", "Sumei Sun"], "title": "Symbol Detection in Ambient Backscatter Communications Under Residual Time Synchronization Errors", "comment": null, "summary": "Ambient backscatter communications (AmBC), where a backscatter transmitter (BT) modulates and reflects ambient signals to a backscatter receiver (BR), have been deemed a low-power communication technology for the Internet of Things. Previous work on symbol detection in AmBC assumed perfect time synchronization (TS), which is unrealistic in practice. The residual TS errors (RTSE) cause \\emph{partial sample mismatch}, degrading symbol detection performance. To address this, we propose a new AmBC symbol detection framework that incorporates the BT's current and adjacent symbols, as well as channel coefficients. Using energy detector (ED) as a case study, we derive both exact and approximate bit error rate (BER) expressions. Our results show that the ED's BER performance degrades significantly under RTSE, with the symbol detection threshold optimized under the assumption of perfect TS. We then derive a closed-form expression for a near-optimal symbol detection threshold that minimizes BER under RTSE. To estimate the required parameters for the detection threshold, we propose a novel method exploiting the attributes of the BR's received signal samples. The analytical results are verified by simulation results.", "AI": {"tldr": "\u63d0\u51fa\u8003\u8651\u65f6\u95f4\u540c\u6b65\u8bef\u5dee\u7684AmBC\u7b26\u53f7\u68c0\u6d4b\u6846\u67b6\uff0c\u63a8\u5bfcBER\u8868\u8fbe\u5f0f\uff0c\u8bbe\u8ba1\u8fd1\u6700\u4f18\u68c0\u6d4b\u9608\u503c\uff0c\u5e76\u63d0\u51fa\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5", "motivation": "\u73b0\u6709AmBC\u7b26\u53f7\u68c0\u6d4b\u5047\u8bbe\u5b8c\u7f8e\u65f6\u95f4\u540c\u6b65\u4e0d\u5207\u5b9e\u9645\uff0c\u6b8b\u7559\u65f6\u95f4\u540c\u6b65\u8bef\u5dee\u5bfc\u81f4\u90e8\u5206\u6837\u672c\u5931\u914d\uff0c\u964d\u4f4e\u68c0\u6d4b\u6027\u80fd", "method": "\u63d0\u51fa\u5305\u542b\u5f53\u524d\u548c\u76f8\u90bb\u7b26\u53f7\u4ee5\u53ca\u4fe1\u9053\u7cfb\u6570\u7684AmBC\u7b26\u53f7\u68c0\u6d4b\u6846\u67b6\uff1b\u4ee5\u80fd\u91cf\u68c0\u6d4b\u5668\u4e3a\u4f8b\u63a8\u5bfcBER\u8868\u8fbe\u5f0f\uff1b\u63a8\u5bfc\u6700\u5c0f\u5316BER\u7684\u8fd1\u6700\u4f18\u68c0\u6d4b\u9608\u503c\uff1b\u63d0\u51fa\u5229\u7528\u63a5\u6536\u4fe1\u53f7\u6837\u672c\u7279\u6027\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5", "result": "\u65f6\u95f4\u540c\u6b65\u8bef\u5dee\u663e\u8457\u964d\u4f4e\u80fd\u91cf\u68c0\u6d4b\u5668BER\u6027\u80fd\uff1b\u63a8\u5bfc\u7684\u68c0\u6d4b\u9608\u503c\u80fd\u6709\u6548\u6700\u5c0f\u5316BER\uff1b\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u53ef\u884c\uff1b\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790", "conclusion": "\u63d0\u51fa\u7684AmBC\u7b26\u53f7\u68c0\u6d4b\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u65f6\u95f4\u540c\u6b65\u8bef\u5dee\uff0c\u901a\u8fc7\u4f18\u5316\u68c0\u6d4b\u9608\u503c\u548c\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd"}}
{"id": "2512.14797", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.14797", "abs": "https://arxiv.org/abs/2512.14797", "authors": ["Riccardo Oliva", "Farahdiba Zarin", "Alice Zampolini Faustini", "Armine Vardazaryan", "Andrea Rosati", "Vinkle Srivastav", "Nunzia Del Villano", "Jacques Marescaux", "Giovanni Scambia", "Pietro Mascagni", "Nicolas Padoy", "Anna Fagotti"], "title": "Artificial Intelligence for the Assessment of Peritoneal Carcinosis during Diagnostic Laparoscopy for Advanced Ovarian Cancer", "comment": null, "summary": "Advanced Ovarian Cancer (AOC) is often diagnosed at an advanced stage with peritoneal carcinosis (PC). Fagotti score (FS) assessment at diagnostic laparoscopy (DL) guides treatment planning by estimating surgical resectability, but its subjective and operator-dependent nature limits reproducibility and widespread use. Videos of patients undergoing DL with concomitant FS assessments at a referral center were retrospectively collected and divided into a development dataset, for data annotation, AI training and evaluation, and an independent test dataset, for internal validation. In the development dataset, FS-relevant frames were manually annotated for anatomical structures and PC. Deep learning models were trained to automatically identify FS-relevant frames, segment structures and PC, and predict video-level FS and indication to surgery (ItS). AI performance was evaluated using Dice score for segmentation, F1-scores for anatomical stations (AS) and ItS prediction, and root mean square error (RMSE) for final FS estimation. In the development dataset, the segmentation model trained on 7,311 frames, achieved Dice scores of 70$\\pm$3% for anatomical structures and 56$\\pm$3% for PC. Video-level AS classification achieved F1-scores of 74$\\pm$3% and 73$\\pm$4%, FS prediction showed normalized RMSE values of 1.39$\\pm$0.18 and 1.15$\\pm$0.08, and ItS reached F1-scores of 80$\\pm$8% and 80$\\pm$2% in the development (n=101) and independent test datasets (n=50), respectively. This is the first AI model to predict the feasibility of cytoreductive surgery providing automated FS estimation from DL videos. Its reproducible and reliable performance across datasets suggests that AI can support surgeons through standardized intraoperative tumor burden assessment and clinical decision-making in AOC.", "AI": {"tldr": "\u5f00\u53d1\u9996\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u4ece\u8bca\u65ad\u6027\u8179\u8154\u955c\u89c6\u9891\u81ea\u52a8\u9884\u6d4bFagotti\u8bc4\u5206\u548c\u624b\u672f\u53ef\u884c\u6027\u7684AI\u6a21\u578b\uff0c\u7528\u4e8e\u665a\u671f\u5375\u5de2\u764c\u7684\u6807\u51c6\u5316\u80bf\u7624\u8d1f\u8377\u8bc4\u4f30", "motivation": "Fagotti\u8bc4\u5206\u5728\u8bca\u65ad\u6027\u8179\u8154\u955c\u4e2d\u7528\u4e8e\u8bc4\u4f30\u665a\u671f\u5375\u5de2\u764c\u624b\u672f\u53ef\u5207\u9664\u6027\uff0c\u4f46\u5176\u4e3b\u89c2\u6027\u548c\u64cd\u4f5c\u8005\u4f9d\u8d56\u6027\u9650\u5236\u4e86\u53ef\u91cd\u590d\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u66f4\u5ba2\u89c2\u3001\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u56de\u987e\u6027\u6536\u96c6\u8bca\u65ad\u6027\u8179\u8154\u955c\u89c6\u9891\uff0c\u624b\u52a8\u6807\u6ce8Fagotti\u8bc4\u5206\u76f8\u5173\u5e27\u4e2d\u7684\u89e3\u5256\u7ed3\u6784\u548c\u8179\u819c\u764c\u7076\uff0c\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u76f8\u5173\u5e27\u3001\u5206\u5272\u7ed3\u6784\u3001\u9884\u6d4b\u89c6\u9891\u7ea7Fagotti\u8bc4\u5206\u548c\u624b\u672f\u6307\u5f81", "result": "\u5206\u5272\u6a21\u578b\u57287311\u5e27\u4e0a\u8bad\u7ec3\uff0c\u89e3\u5256\u7ed3\u6784Dice\u5206\u657070\u00b13%\uff0c\u8179\u819c\u764c\u707656\u00b13%\uff1b\u89c6\u9891\u7ea7\u89e3\u5256\u7ad9\u5206\u7c7bF1\u5206\u657074\u00b13%\u548c73\u00b14%\uff0cFagotti\u8bc4\u5206\u9884\u6d4b\u5f52\u4e00\u5316RMSE\u4e3a1.39\u00b10.18\u548c1.15\u00b10.08\uff0c\u624b\u672f\u6307\u5f81\u9884\u6d4bF1\u5206\u657080\u00b18%\u548c80\u00b12%\uff08\u5f00\u53d1\u96c6n=101\uff0c\u6d4b\u8bd5\u96c6n=50\uff09", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4ece\u8bca\u65ad\u6027\u8179\u8154\u955c\u89c6\u9891\u81ea\u52a8\u9884\u6d4b\u80bf\u7624\u7ec6\u80de\u51cf\u706d\u672f\u53ef\u884c\u6027\u7684AI\u6a21\u578b\uff0c\u5176\u53ef\u91cd\u590d\u4e14\u53ef\u9760\u7684\u6027\u80fd\u8868\u660eAI\u53ef\u4ee5\u901a\u8fc7\u6807\u51c6\u5316\u672f\u4e2d\u80bf\u7624\u8d1f\u8377\u8bc4\u4f30\u652f\u6301\u5916\u79d1\u533b\u751f\u7684\u4e34\u5e8a\u51b3\u7b56"}}
{"id": "2512.15045", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15045", "abs": "https://arxiv.org/abs/2512.15045", "authors": ["Aparna Parameswaran", "Hoyoung Kim", "Sangkil Kim"], "title": "Janus Metasurface Breaking Polarization Symmetry: Surface-Modulated Electromagnetic Wave Radiation with Coexistent Linear and Circular Polarization", "comment": null, "summary": "In this work, a Janus metasurface based tensor impedance holographic antenna (JHA) is proposed that simultaneously radiates linearly polarized (LP) and circularly polarized (CP) beams from a single aperture excited by a single feed. The proposed design introduces modified tensor impedance equations to significantly reduce cross-polarization at higher radiation angles. It demonstrates broadband operation bandwidth of 0.5 GHz while maintaining high circular polarization purity. The design methodology is verified using aperture field integration theory, ensuring that the impedance distribution produces the desired far-field radiation patterns. Prototypes of three variations of the holographic antenna are fabricated, validating its performance. The radiation characteristics of the proposed antenna make it an attractive choice for advanced broadband communication applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eJanus\u8d85\u8868\u9762\u7684\u5f20\u91cf\u963b\u6297\u5168\u606f\u5929\u7ebf\uff0c\u80fd\u591f\u901a\u8fc7\u5355\u4e2a\u9988\u6e90\u540c\u65f6\u8f90\u5c04\u7ebf\u6781\u5316\u548c\u5706\u6781\u5316\u6ce2\u675f\uff0c\u5177\u6709\u5bbd\u5e26\u7279\u6027\u548c\u4f4e\u4ea4\u53c9\u6781\u5316\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8f90\u5c04\u7ebf\u6781\u5316\u548c\u5706\u6781\u5316\u6ce2\u675f\u7684\u5355\u5b54\u5f84\u5929\u7ebf\uff0c\u6ee1\u8db3\u5148\u8fdb\u5bbd\u5e26\u901a\u4fe1\u5e94\u7528\u4e2d\u5bf9\u591a\u529f\u80fd\u3001\u9ad8\u6027\u80fd\u5929\u7ebf\u7684\u9700\u6c42\uff0c\u540c\u65f6\u89e3\u51b3\u4f20\u7edf\u8bbe\u8ba1\u4e2d\u9ad8\u8f90\u5c04\u89d2\u5ea6\u4ea4\u53c9\u6781\u5316\u8fc7\u5927\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u5f20\u91cf\u963b\u6297\u65b9\u7a0b\u6765\u663e\u8457\u964d\u4f4e\u9ad8\u8f90\u5c04\u89d2\u5ea6\u7684\u4ea4\u53c9\u6781\u5316\uff0c\u91c7\u7528\u5b54\u5f84\u573a\u79ef\u5206\u7406\u8bba\u9a8c\u8bc1\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u786e\u4fdd\u963b\u6297\u5206\u5e03\u4ea7\u751f\u6240\u9700\u7684\u8fdc\u573a\u8f90\u5c04\u65b9\u5411\u56fe\uff0c\u5e76\u5236\u4f5c\u4e86\u4e09\u79cd\u53d8\u4f53\u7684\u5168\u606f\u5929\u7ebf\u539f\u578b\u8fdb\u884c\u6027\u80fd\u9a8c\u8bc1\u3002", "result": "\u5929\u7ebf\u5b9e\u73b0\u4e860.5 GHz\u7684\u5bbd\u5e26\u5de5\u4f5c\u5e26\u5bbd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5706\u6781\u5316\u7eaf\u5ea6\uff0c\u539f\u578b\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u8f90\u5c04\u7279\u6027\uff0c\u9002\u5408\u5148\u8fdb\u5bbd\u5e26\u901a\u4fe1\u5e94\u7528\u3002", "conclusion": "Janus\u8d85\u8868\u9762\u5f20\u91cf\u963b\u6297\u5168\u606f\u5929\u7ebf\u6210\u529f\u5b9e\u73b0\u4e86\u5355\u9988\u6e90\u540c\u65f6\u8f90\u5c04\u7ebf\u6781\u5316\u548c\u5706\u6781\u5316\u6ce2\u675f\u7684\u529f\u80fd\uff0c\u5177\u6709\u5bbd\u5e26\u7279\u6027\u548c\u4f4e\u4ea4\u53c9\u6781\u5316\uff0c\u4e3a\u5148\u8fdb\u5bbd\u5e26\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u5438\u5f15\u529b\u7684\u5929\u7ebf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15342", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15342", "abs": "https://arxiv.org/abs/2512.15342", "authors": ["Zhentian Zhang", "Jian Dang", "David Morales-Jimenez", "Hao Jiang", "Zaichen Zhang", "Christos Masouros", "Chan-Byoung Chae"], "title": "Joint Activity Detection and Channel Estimation For Fluid Antenna System Exploiting Geographical and Angular Information", "comment": null, "summary": "The fluid antenna system (FAS) refers to a family of reconfigurable antenna technologies that provide substantial spatial gains within a compact, predefined small space, thereby offering extensive degrees of freedom in the physical layer for future communication networks. The acquisition of channel state information (CSI) is critical, as it determines the placement of ports/antennas, which directly impacts FAS-based optimization. Although various channel estimation methods have been developed, significant flaws persist. For instance, the performance of greedy-based algorithms is heavily influenced by signal assumptions, and current model-free methods are infeasible due to prohibitively high computational complexity issue. Consequently, there is a pressing need for a well-balanced solution that exhibits flexibility, feasibility, and low complexity to support massive connectivity in FAS. In this work, we propose methods based on approximate message passing (AMP) integrated with adaptive expectation maximization (EM). The EM-AMP framework uniquely enables efficient large matrix computations with adaptive learning capabilities, independent of prior knowledge of the model or parameters within potential distributions, making it a robust candidate for FAS networks. We introduce two variants of the EM-AMP framework that leverage geographical and angular features in a FAS network. These proposed algorithms demonstrate improved estimation precision, fast convergence, and low computational complexity in large activity regions. Additionally, we analytically elucidate the reasons behind the inherent performance floor of greedy-based methods and highlight the critical role of angular information in algorithm design. Extensive numerical results validate the promising efficacy of the proposed algorithm designs and the derived analytical findings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\u4e0e\u81ea\u9002\u5e94\u671f\u671b\u6700\u5927\u5316\u7684EM-AMP\u6846\u67b6\uff0c\u7528\u4e8e\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u3001\u53ef\u884c\u6027\u548c\u590d\u6742\u5ea6\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u9700\u8981\u9ad8\u6548\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u6765\u4f18\u5316\u5929\u7ebf\u7aef\u53e3\u4f4d\u7f6e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u8d2a\u5a6a\u7b97\u6cd5\u6027\u80fd\u53d7\u4fe1\u53f7\u5047\u8bbe\u5f71\u54cd\u5927\uff0c\u65e0\u6a21\u578b\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u8fc7\u9ad8\uff0c\u9700\u8981\u5e73\u8861\u7075\u6d3b\u6027\u3001\u53ef\u884c\u6027\u548c\u4f4e\u590d\u6742\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\u4e0e\u81ea\u9002\u5e94\u671f\u671b\u6700\u5927\u5316\u7684EM-AMP\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u77e9\u9635\u8ba1\u7b97\u5e76\u5177\u5907\u81ea\u9002\u5e94\u5b66\u4e60\u80fd\u529b\uff0c\u65e0\u9700\u5148\u9a8c\u6a21\u578b\u6216\u53c2\u6570\u5206\u5e03\u77e5\u8bc6\u3002\u5f00\u53d1\u4e86\u4e24\u79cd\u5229\u7528FAS\u7f51\u7edc\u5730\u7406\u548c\u89d2\u5ea6\u7279\u5f81\u7684EM-AMP\u53d8\u4f53\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5927\u578b\u6d3b\u52a8\u533a\u57df\u4e2d\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u4f30\u8ba1\u7cbe\u5ea6\u3001\u5feb\u901f\u6536\u655b\u548c\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u8bbe\u8ba1\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u8d2a\u5a6a\u65b9\u6cd5\u6027\u80fd\u74f6\u9888\u7684\u539f\u56e0\uff0c\u5f3a\u8c03\u4e86\u89d2\u5ea6\u4fe1\u606f\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "EM-AMP\u6846\u67b6\u4e3aFAS\u7f51\u7edc\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u884c\u4e14\u4f4e\u590d\u6742\u5ea6\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u652f\u6301\u5927\u89c4\u6a21\u8fde\u63a5\u9700\u6c42\uff0c\u662fFAS\u7f51\u7edc\u7684\u7a33\u5065\u5019\u9009\u65b9\u6848\u3002"}}
{"id": "2512.14929", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14929", "abs": "https://arxiv.org/abs/2512.14929", "authors": ["Paul J. Weiser", "Jiye Kim", "Jongho Lee", "Amirmohammad Shamaei", "Gulnur Ungan", "Malte Hoffmann", "Antoine Klauser", "Berkin Bilgic", "Ovidiu C. Andronesi"], "title": "Deep learning water-unsuppressed MRSI at ultra-high field for simultaneous quantitative metabolic, susceptibility and myelin water imaging", "comment": null, "summary": "Purpose: Magnetic Resonance Spectroscopic Imaging (MRSI) maps endogenous brain metabolism while suppressing the overwhelming water signal. Water-unsuppressed MRSI (wu-MRSI) allows simultaneous imaging of water and metabolites, but large water sidebands cause challenges for metabolic fitting. We developed an end-to-end deep-learning pipeline to overcome these challenges at ultra-high field. Methods:Fast high-resolution wu-MRSI was acquired at 7T with non-cartesian ECCENTRIC sampling and ultra-short echo time. A water and lipid removal network (WALINET+) was developed to remove lipids, water signal, and sidebands. MRSI reconstruction was performed by DeepER and a physics-informed network for metabolite fitting. Water signal was used for absolute metabolite quantification, quantitative susceptibility mapping (QSM), and myelin water fraction imaging (MWF). Results: WALINET+ provided the lowest NRMSE (< 2%) in simulations and in vivo the smallest bias (< 20%) and limits-of-agreement (+-63%) between wu-MRSI and ws-MRSI scans. Several metabolites such as creatine and glutamate showed higher SNR in wu-MRSI. QSM and MWF obtained from wu-MRSI and GRE showed good agreement with 0 ppm/5.5% bias and +-0.05 ppm/ +- 12.75% limits-of-agreement. Conclusion: High-quality metabolic, QSM, and MWF mapping of the human brain can be obtained simultaneously by ECCENTRIC wu-MRSI at 7T with 2 mm isotropic resolution in 12 min. WALINET+ robustly removes water sidebands while preserving metabolite signal, eliminating the need for water suppression and separate water acquisitions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u7ba1\u9053\uff0c\u7528\u4e8e\u5904\u74067T\u8d85\u5f3a\u78c1\u573a\u4e0b\u7684\u6c34\u672a\u6291\u5236MRSI\u6570\u636e\uff0c\u540c\u65f6\u83b7\u53d6\u4ee3\u8c22\u7269\u3001QSM\u548c\u9ad3\u9798\u6c34\u5206\u6570\u6210\u50cf\u3002", "motivation": "\u4f20\u7edfMRSI\u9700\u8981\u6291\u5236\u6c34\u4fe1\u53f7\uff0c\u800c\u6c34\u672a\u6291\u5236MRSI\u80fd\u540c\u65f6\u6210\u50cf\u6c34\u548c\u4ee3\u8c22\u7269\uff0c\u4f46\u6c34\u8fb9\u5e26\u5e72\u6270\u7ed9\u4ee3\u8c22\u7269\u62df\u5408\u5e26\u6765\u6311\u6218\u3002\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u5728\u8d85\u9ad8\u573a\u5f3a\u4e0b\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u4f7f\u7528\u975e\u7b1b\u5361\u5c14ECCENTRIC\u91c7\u6837\u548c\u8d85\u77ed\u56de\u6ce2\u65f6\u95f4\u57287T\u83b7\u53d6\u5feb\u901f\u9ad8\u5206\u8fa8\u7387wu-MRSI\u3002\u5f00\u53d1WALINET+\u7f51\u7edc\u53bb\u9664\u8102\u8d28\u3001\u6c34\u4fe1\u53f7\u548c\u8fb9\u5e26\u3002\u4f7f\u7528DeepER\u8fdb\u884cMRSI\u91cd\u5efa\uff0c\u7269\u7406\u4fe1\u606f\u7f51\u7edc\u8fdb\u884c\u4ee3\u8c22\u7269\u62df\u5408\u3002\u5229\u7528\u6c34\u4fe1\u53f7\u8fdb\u884c\u7edd\u5bf9\u4ee3\u8c22\u7269\u5b9a\u91cf\u3001QSM\u548cMWF\u6210\u50cf\u3002", "result": "WALINET+\u5728\u6a21\u62df\u548c\u4f53\u5185\u5b9e\u9a8c\u4e2d\u8868\u73b0\u6700\u4f73\uff08NRMSE<2%\uff0c\u504f\u5dee<20%\uff0c\u4e00\u81f4\u6027\u9650\u00b163%\uff09\u3002wu-MRSI\u4e2d\u808c\u9178\u548c\u8c37\u6c28\u9178\u7b49\u4ee3\u8c22\u7269SNR\u66f4\u9ad8\u3002wu-MRSI\u83b7\u5f97\u7684QSM\u548cMWF\u4e0eGRE\u7ed3\u679c\u4e00\u81f4\uff08\u504f\u5dee0 ppm/5.5%\uff0c\u4e00\u81f4\u6027\u9650\u00b10.05 ppm/\u00b112.75%\uff09\u3002", "conclusion": "\u901a\u8fc7ECCENTRIC wu-MRSI\u57287T\u4e0b12\u5206\u949f\u5185\u53ef\u83b7\u5f972mm\u5404\u5411\u540c\u6027\u5206\u8fa8\u7387\u7684\u9ad8\u8d28\u91cf\u4ee3\u8c22\u7269\u3001QSM\u548cMWF\u8111\u90e8\u6210\u50cf\u3002WALINET+\u80fd\u7a33\u5065\u53bb\u9664\u6c34\u8fb9\u5e26\u540c\u65f6\u4fdd\u7559\u4ee3\u8c22\u7269\u4fe1\u53f7\uff0c\u65e0\u9700\u6c34\u6291\u5236\u548c\u5355\u72ec\u6c34\u91c7\u96c6\u3002"}}
{"id": "2512.15062", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.15062", "abs": "https://arxiv.org/abs/2512.15062", "authors": ["Nadia Abdolkhani", "Nada Abdel Khalek", "Walaa Hamouda", "Iyad Dayoub"], "title": "Deep Reinforcement Learning for Joint Time and Power Management in SWIPT-EH CIoT", "comment": "Published in IEEE Communications Letters, 2025. This arXiv version is the authors' accepted manuscript", "summary": "This letter presents a novel deep reinforcement learning (DRL) approach for joint time allocation and power control in a cognitive Internet of Things (CIoT) system with simultaneous wireless information and power transfer (SWIPT). The CIoT transmitter autonomously manages energy harvesting (EH) and transmissions using a learnable time switching factor while optimizing power to enhance throughput and lifetime. The joint optimization is modeled as a Markov decision process under small-scale fading, realistic EH, and interference constraints. We develop a double deep Q-network (DDQN) enhanced with an upper confidence bound. Simulations benchmark our approach, showing superior performance over existing DRL methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8ba4\u77e5\u7269\u8054\u7f51\u7cfb\u7edf\u8054\u5408\u65f6\u95f4\u5206\u914d\u4e0e\u529f\u7387\u63a7\u5236\u65b9\u6cd5\uff0c\u91c7\u7528DDQN\u589e\u5f3a\u7b97\u6cd5\u4f18\u5316\u80fd\u91cf\u6536\u96c6\u4e0e\u4f20\u8f93", "motivation": "\u8ba4\u77e5\u7269\u8054\u7f51\u7cfb\u7edf\u9700\u8981\u5728\u80fd\u91cf\u6536\u96c6\u548c\u4fe1\u606f\u4f20\u8f93\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u540c\u65f6\u8003\u8651\u5c0f\u5c3a\u5ea6\u8870\u843d\u3001\u5b9e\u9645\u80fd\u91cf\u6536\u96c6\u6a21\u578b\u548c\u5e72\u6270\u7ea6\u675f\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u8054\u5408\u4f18\u5316\u95ee\u9898", "method": "\u5c06\u8054\u5408\u4f18\u5316\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u589e\u5f3a\u578b\u53cc\u6df1\u5ea6Q\u7f51\u7edc\uff08DDQN\uff09\u7b97\u6cd5\uff0c\u5f15\u5165\u7f6e\u4fe1\u4e0a\u754c\u673a\u5236\uff0c\u8ba9CIoT\u53d1\u5c04\u673a\u81ea\u4e3b\u5b66\u4e60\u65f6\u95f4\u5207\u6362\u56e0\u5b50\u548c\u529f\u7387\u63a7\u5236\u7b56\u7565", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u541e\u5410\u91cf\u548c\u7cfb\u7edf\u5bff\u547d\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "\u63d0\u51fa\u7684DRL\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8ba4\u77e5\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u80fd\u91cf\u6536\u96c6\u4e0e\u4fe1\u606f\u4f20\u8f93\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.15399", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15399", "abs": "https://arxiv.org/abs/2512.15399", "authors": ["Phillip Stephan", "Florian Euchner", "Stephan ten Brink"], "title": "Three-Dimensional Radio Localization: A Channel Charting-Based Approach", "comment": null, "summary": "Channel charting creates a low-dimensional representation of the radio environment in a self-supervised manner using manifold learning. Preserving relative spatial distances in the latent space, channel charting is well suited to support user localization. While prior work on channel charting has mainly focused on two-dimensional scenarios, real-world environments are inherently three-dimensional. In this work, we investigate two distinct three-dimensional indoor localization scenarios using simulated, but realistic ray tracing-based datasets: a factory hall with a three-dimensional spatial distribution of datapoints, and a multistory building where each floor exhibits a two-dimensional datapoint distribution. For the first scenario, we apply the concept of augmented channel charting, which combines classical localization and channel charting, to a three-dimensional setting. For the second scenario, we introduce multistory channel charting, a two-stage approach consisting of floor classification via clustering followed by the training of a dedicated expert neural network for channel charting on each individual floor, thereby enhancing the channel charting performance. In addition, we propose a novel feature engineering method designed to extract sparse features from the beamspace channel state information that are suitable for localization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e09\u7ef4\u5ba4\u5185\u5b9a\u4f4d\u573a\u666f\u4e0b\u7684\u4fe1\u9053\u56fe\u8868\u6280\u672f\uff0c\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a\u9488\u5bf9\u4e09\u7ef4\u6570\u636e\u5206\u5e03\u7684\u589e\u5f3a\u4fe1\u9053\u56fe\u8868\uff0c\u4ee5\u53ca\u9488\u5bf9\u591a\u5c42\u5efa\u7b51\u7684\u697c\u5c42\u5206\u7c7b+\u4e13\u5bb6\u7f51\u7edc\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u51fa\u65b0\u7684\u7a00\u758f\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4fe1\u9053\u56fe\u8868\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e8c\u7ef4\u573a\u666f\uff0c\u4f46\u771f\u5b9e\u73af\u5883\u672c\u8d28\u4e0a\u662f\u4e09\u7ef4\u7684\u3002\u9700\u8981\u7814\u7a76\u4e09\u7ef4\u5ba4\u5185\u5b9a\u4f4d\u573a\u666f\u4e0b\u7684\u4fe1\u9053\u56fe\u8868\u6280\u672f\uff0c\u4ee5\u652f\u6301\u66f4\u5b9e\u9645\u7684\u5e94\u7528\u9700\u6c42\u3002", "method": "1. \u9488\u5bf9\u4e09\u7ef4\u6570\u636e\u5206\u5e03\u573a\u666f\uff1a\u5e94\u7528\u589e\u5f3a\u4fe1\u9053\u56fe\u8868\u6982\u5ff5\uff0c\u7ed3\u5408\u4f20\u7edf\u5b9a\u4f4d\u548c\u4fe1\u9053\u56fe\u8868\u6280\u672f\n2. \u9488\u5bf9\u591a\u5c42\u5efa\u7b51\u573a\u666f\uff1a\u63d0\u51fa\u591a\u697c\u5c42\u4fe1\u9053\u56fe\u8868\u65b9\u6cd5\uff0c\u5305\u62ec\u697c\u5c42\u805a\u7c7b\u5206\u7c7b\u548c\u6bcf\u5c42\u4e13\u7528\u4e13\u5bb6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\n3. \u63d0\u51fa\u65b0\u7684\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\uff0c\u4ece\u6ce2\u675f\u7a7a\u95f4\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e2d\u63d0\u53d6\u9002\u5408\u5b9a\u4f4d\u7684\u7a00\u758f\u7279\u5f81", "result": "\u4f7f\u7528\u57fa\u4e8e\u5c04\u7ebf\u8ffd\u8e2a\u7684\u6a21\u62df\u4f46\u771f\u5b9e\u7684\u6570\u636e\u96c6\uff0c\u5728\u4e24\u79cd\u4e09\u7ef4\u5ba4\u5185\u5b9a\u4f4d\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff1a\u5de5\u5382\u5927\u5385\uff08\u4e09\u7ef4\u6570\u636e\u5206\u5e03\uff09\u548c\u591a\u5c42\u5efa\u7b51\uff08\u6bcf\u5c42\u4e8c\u7ef4\u6570\u636e\u5206\u5e03\uff09\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6269\u5c55\u4e86\u4fe1\u9053\u56fe\u8868\u6280\u672f\u5230\u4e09\u7ef4\u5ba4\u5185\u5b9a\u4f4d\u573a\u666f\uff0c\u63d0\u51fa\u7684\u589e\u5f3a\u4fe1\u9053\u56fe\u8868\u548c\u591a\u697c\u5c42\u4fe1\u9053\u56fe\u8868\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u4e09\u7ef4\u73af\u5883\uff0c\u540c\u65f6\u65b0\u7684\u7a00\u758f\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u63d0\u5347\u4e86\u5b9a\u4f4d\u6027\u80fd\u3002"}}
{"id": "2512.15034", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15034", "abs": "https://arxiv.org/abs/2512.15034", "authors": ["Nalini M. Singh", "Tiffany Chien", "Arthur R. C. McCray", "Colin Ophus", "Laura Waller"], "title": "A Gaussian Parameterization for Direct Atomic Structure Identification in Electron Tomography", "comment": "Published in ICCP 2025. 14 pages, 10 figures. Keywords: Atomic electron tomography, Gaussian splatting", "summary": "Atomic electron tomography (AET) enables the determination of 3D atomic structures by acquiring a sequence of 2D tomographic projection measurements of a particle and then computationally solving for its underlying 3D representation. Classical tomography algorithms solve for an intermediate volumetric representation that is post-processed into the atomic structure of interest. In this paper, we reformulate the tomographic inverse problem to solve directly for the locations and properties of individual atoms. We parameterize an atomic structure as a collection of Gaussians, whose positions and properties are learnable. This representation imparts a strong physical prior on the learned structure, which we show yields improved robustness to real-world imaging artifacts. Simulated experiments and a proof-of-concept result on experimentally-acquired data confirm our method's potential for practical applications in materials characterization and analysis with Transmission Electron Microscopy (TEM). Our code is available at https://github.com/nalinimsingh/gaussian-atoms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u539f\u5b50\u53c2\u6570\u5316\u7684\u76f4\u63a5\u539f\u5b50\u7ed3\u6784\u91cd\u5efa\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u4f53\u79ef\u8868\u793a\u4e2d\u95f4\u6b65\u9aa4\uff0c\u63d0\u9ad8\u5bf9\u5b9e\u9645\u6210\u50cf\u4f2a\u5f71\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u539f\u5b50\u7535\u5b50\u65ad\u5c42\u626b\u63cf\uff08AET\uff09\u65b9\u6cd5\u5148\u91cd\u5efa\u4e2d\u95f4\u4f53\u79ef\u8868\u793a\uff0c\u518d\u540e\u5904\u7406\u5f97\u5230\u539f\u5b50\u7ed3\u6784\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u53d7\u5230\u5b9e\u9645\u6210\u50cf\u4f2a\u5f71\u7684\u5f71\u54cd\u3002\u4f5c\u8005\u5e0c\u671b\u76f4\u63a5\u6c42\u89e3\u539f\u5b50\u4f4d\u7f6e\u548c\u6027\u8d28\uff0c\u5229\u7528\u7269\u7406\u5148\u9a8c\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002", "method": "\u5c06\u539f\u5b50\u7ed3\u6784\u53c2\u6570\u5316\u4e3a\u53ef\u5b66\u4e60\u7684\u9ad8\u65af\u51fd\u6570\u96c6\u5408\uff0c\u76f4\u63a5\u4f18\u5316\u539f\u5b50\u4f4d\u7f6e\u548c\u6027\u8d28\u53c2\u6570\uff0c\u800c\u4e0d\u662f\u5148\u91cd\u5efa\u4f53\u79ef\u8868\u793a\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u5f3a\u7269\u7406\u5148\u9a8c\u878d\u5165\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u548c\u5b9e\u9a8c\u6570\u636e\u7684\u6982\u5ff5\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5bf9\u5b9e\u9645\u6210\u50cf\u4f2a\u5f71\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u5728\u6750\u6599\u8868\u5f81\u548c\u900f\u5c04\u7535\u5b50\u663e\u5fae\u955c\u5206\u6790\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u76f4\u63a5\u53c2\u6570\u5316\u539f\u5b50\u7ed3\u6784\u4e3a\u9ad8\u65af\u51fd\u6570\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u539f\u5b50\u7535\u5b50\u65ad\u5c42\u626b\u63cf\u91cd\u5efa\u65b9\u6cd5\uff0c\u6709\u671b\u5728\u5b9e\u9645\u6750\u6599\u5206\u6790\u4e2d\u5f97\u5230\u5e94\u7528\u3002"}}
{"id": "2512.15105", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15105", "abs": "https://arxiv.org/abs/2512.15105", "authors": ["Jundong Qi", "Weize Sun", "Shaowu Chen", "Lei Huang", "Qiuchen Liu"], "title": "CF-Net: A Cross-Feature Reconstruction Network for High-Accuracy 1-Bit Target Classification", "comment": "14 pages, 10 figures. Submitted to IEEE Transactions on Geoscience and Remote Sensing", "summary": "Target classification is a fundamental task in radar systems, and its performance critically depends on the quantization precision of the signal. While high-precision quantization (e.g. 16-bit) is well established, 1-bit quantization offers distinct advantages by enabling direct sampling at high frequencies and eliminating complex intermediate stages. However, its extreme quantization leads to significant information loss. Although higher sampling rates can compensate for this loss, such oversampling is impractical at the high frequencies targeted for direct sampling. To achieve high-accuracy classification directly from 1-bit radar data under the same sampling rate, this paper proposes a novel two-stage deep learning framework, CF-Net. First, we introduce a self-supervised pre-training strategy based on a dual-branch U-Net architecture. This network learns to restore high-fidelity 16-bit images from their 1-bit counterparts via a cross-feature reconstruction task, forcing the 1-bit encoder to learn robust features despite extreme quantization. Subsequently, this pre-trained encoder is repurposed and fine-tuned for the downstream multi-class target classification task. Experiments on two radar target datasets demonstrate that CF-Net can effectively extract discriminative features from 1-bit imagery, achieving comparable and even superior accuracy to some 16-bit methods without oversampling.", "AI": {"tldr": "\u63d0\u51faCF-Net\u5169\u968e\u6bb5\u6df1\u5ea6\u5b78\u7fd2\u6846\u67b6\uff0c\u5f9e1\u4f4d\u5143\u96f7\u9054\u6578\u64da\u5be6\u73fe\u9ad8\u7cbe\u5ea6\u76ee\u6a19\u5206\u985e\uff0c\u7121\u9700\u904e\u63a1\u6a23\u5373\u53ef\u9054\u5230\u820716\u4f4d\u5143\u65b9\u6cd5\u76f8\u7576\u7684\u6027\u80fd", "motivation": "1\u4f4d\u5143\u91cf\u5316\u5728\u96f7\u9054\u7cfb\u7d71\u4e2d\u5177\u6709\u76f4\u63a5\u9ad8\u983b\u63a1\u6a23\u548c\u7c21\u5316\u786c\u9ad4\u7d50\u69cb\u7684\u512a\u52e2\uff0c\u4f46\u6975\u7aef\u91cf\u5316\u5c0e\u81f4\u56b4\u91cd\u4fe1\u606f\u640d\u5931\u3002\u50b3\u7d71\u901a\u904e\u904e\u63a1\u6a23\u88dc\u511f\u7684\u65b9\u6cd5\u5728\u9ad8\u983b\u4e0b\u4e0d\u5207\u5be6\u969b\uff0c\u56e0\u6b64\u9700\u8981\u958b\u767c\u80fd\u5f9e1\u4f4d\u5143\u6578\u64da\u76f4\u63a5\u5be6\u73fe\u9ad8\u7cbe\u5ea6\u5206\u985e\u7684\u65b9\u6cd5", "method": "\u63d0\u51faCF-Net\u5169\u968e\u6bb5\u6846\u67b6\uff1a1) \u81ea\u76e3\u7763\u9810\u8a13\u7df4\u968e\u6bb5\uff0c\u4f7f\u7528\u96d9\u5206\u652fU-Net\u67b6\u69cb\uff0c\u901a\u904e\u4ea4\u53c9\u7279\u5fb5\u91cd\u5efa\u4efb\u52d9\u5b78\u7fd2\u5f9e1\u4f4d\u5143\u5716\u50cf\u6062\u5fa916\u4f4d\u5143\u9ad8\u4fdd\u771f\u5716\u50cf\uff1b2) \u5fae\u8abf\u968e\u6bb5\uff0c\u5c07\u9810\u8a13\u7df4\u76841\u4f4d\u5143\u7de8\u78bc\u5668\u91cd\u65b0\u7528\u65bc\u4e0b\u6e38\u591a\u985e\u76ee\u6a19\u5206\u985e\u4efb\u52d9", "result": "\u5728\u5169\u500b\u96f7\u9054\u76ee\u6a19\u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0cCF-Net\u80fd\u6709\u6548\u5f9e1\u4f4d\u5143\u5716\u50cf\u4e2d\u63d0\u53d6\u5224\u5225\u6027\u7279\u5fb5\uff0c\u5728\u4e0d\u9032\u884c\u904e\u63a1\u6a23\u7684\u60c5\u6cc1\u4e0b\uff0c\u9054\u5230\u8207\u67d0\u4e9b16\u4f4d\u5143\u65b9\u6cd5\u76f8\u7576\u751a\u81f3\u66f4\u512a\u7684\u5206\u985e\u6e96\u78ba\u7387", "conclusion": "CF-Net\u6846\u67b6\u6210\u529f\u89e3\u6c7a\u4e861\u4f4d\u5143\u96f7\u9054\u6578\u64da\u5206\u985e\u7684\u6311\u6230\uff0c\u8b49\u660e\u4e86\u901a\u904e\u81ea\u76e3\u7763\u9810\u8a13\u7df4\u5b78\u7fd2\u9b6f\u68d2\u7279\u5fb5\u7684\u6709\u6548\u6027\uff0c\u70ba\u9ad8\u983b\u96f7\u9054\u7cfb\u7d71\u4e2d\u7684\u9ad8\u6548\u76ee\u6a19\u5206\u985e\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2512.15419", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15419", "abs": "https://arxiv.org/abs/2512.15419", "authors": ["Shilei Li", "Dawei Shi", "Hao Yu", "Ling Shi"], "title": "Variational Robust Kalman Filters: A Unified Framework", "comment": "23 pages", "summary": "Robustness and adaptivity are two competing objectives in Kalman filters (KF). Robustness involves temporarily inflating prior estimates of noise covariances, while adaptivity updates prior beliefs using real-time information. In practical applications, both process and measurement noise can be influenced by outliers, be time-varying, or both. Existing works may not effectively address the above complex noise scenarios, as there is an intrinsic incompatibility between robust filters and adaptive filters. In this work, we propose a unified variational robust Kalman filter, built on a Student's t-distribution induced loss function and variational inference, and solved through fixed-point iteration in a computationally efficient manner. We demonstrate that robustness can be understood as a prerequisite for adaptivity, making it possible to merge the above two competing goals into a single framework through switching rules. Additionally, our proposed filter can recover conventional KF, robust KF, and adaptive KF by adjusting parameters, and can suppress both the imperfect process and measurement noise, enabling it to perform superiorly in complex noise environments. Simulations verify the effectiveness of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b66\u751ft\u5206\u5e03\u548c\u53d8\u5206\u63a8\u7406\u7684\u7edf\u4e00\u53d8\u5206\u9c81\u68d2\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u5207\u6362\u89c4\u5219\u5c06\u9c81\u68d2\u6027\u548c\u81ea\u9002\u5e94\u6027\u7ed3\u5408\uff0c\u80fd\u5904\u7406\u590d\u6742\u566a\u58f0\u73af\u5883\u3002", "motivation": "\u9c81\u68d2\u6027\u548c\u81ea\u9002\u5e94\u6027\u662f\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\u4e24\u4e2a\u76f8\u4e92\u7ade\u4e89\u7684\u76ee\u6807\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u8fc7\u7a0b\u566a\u58f0\u548c\u6d4b\u91cf\u566a\u58f0\u53ef\u80fd\u540c\u65f6\u53d7\u5230\u5f02\u5e38\u503c\u3001\u65f6\u53d8\u7279\u6027\u6216\u4e24\u8005\u7684\u5f71\u54cd\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u590d\u6742\u566a\u58f0\u573a\u666f\uff0c\u56e0\u4e3a\u9c81\u68d2\u6ee4\u6ce2\u5668\u548c\u81ea\u9002\u5e94\u6ee4\u6ce2\u5668\u5b58\u5728\u5185\u5728\u4e0d\u517c\u5bb9\u6027\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u53d8\u5206\u9c81\u68d2\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u57fa\u4e8e\u5b66\u751ft\u5206\u5e03\u8bf1\u5bfc\u7684\u635f\u5931\u51fd\u6570\u548c\u53d8\u5206\u63a8\u7406\uff0c\u901a\u8fc7\u56fa\u5b9a\u70b9\u8fed\u4ee3\u4ee5\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u5f0f\u6c42\u89e3\u3002\u901a\u8fc7\u5207\u6362\u89c4\u5219\u5c06\u9c81\u68d2\u6027\u548c\u81ea\u9002\u5e94\u6027\u76ee\u6807\u878d\u5408\u5230\u5355\u4e00\u6846\u67b6\u4e2d\u3002", "result": "\u8be5\u6ee4\u6ce2\u5668\u80fd\u591f\u901a\u8fc7\u8c03\u6574\u53c2\u6570\u6062\u590d\u4f20\u7edfKF\u3001\u9c81\u68d2KF\u548c\u81ea\u9002\u5e94KF\uff0c\u5e76\u80fd\u540c\u65f6\u6291\u5236\u4e0d\u5b8c\u7f8e\u7684\u8fc7\u7a0b\u566a\u58f0\u548c\u6d4b\u91cf\u566a\u58f0\uff0c\u5728\u590d\u6742\u566a\u58f0\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u9c81\u68d2\u6027\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u81ea\u9002\u5e94\u6027\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u4f7f\u5f97\u901a\u8fc7\u5207\u6362\u89c4\u5219\u5c06\u8fd9\u4e24\u4e2a\u7ade\u4e89\u76ee\u6807\u878d\u5408\u5230\u5355\u4e00\u6846\u67b6\u6210\u4e3a\u53ef\u80fd\u3002\u6240\u63d0\u51fa\u7684\u6ee4\u6ce2\u5668\u4e3a\u5904\u7406\u590d\u6742\u566a\u58f0\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15061", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15061", "abs": "https://arxiv.org/abs/2512.15061", "authors": ["Pandega Abyan Zumarsyah", "Igi Ardiyanto", "Hanung Adi Nugroho"], "title": "Meta-learners for few-shot weakly-supervised optic disc and cup segmentation on fundus images", "comment": "Submitted to Computers in Biology and Medicine", "summary": "This study develops meta-learners for few-shot weakly-supervised segmentation (FWS) to address the challenge of optic disc (OD) and optic cup (OC) segmentation for glaucoma diagnosis with limited labeled fundus images. We significantly improve existing meta-learners by introducing Omni meta-training which balances data usage and diversifies the number of shots. We also develop their efficient versions that reduce computational costs. In addition, we develop sparsification techniques that generate more customizable and representative scribbles and other sparse labels. After evaluating multiple datasets, we find that Omni and efficient versions outperform the original versions, with the best meta-learner being Efficient Omni ProtoSeg (EO-ProtoSeg). It achieves intersection over union (IoU) scores of 88.15% for OD and 71.17% for OC on the REFUGE dataset using just one sparsely labeled image, outperforming few-shot and semi-supervised methods which require more labeled images. Its best performance reaches 86.80% for OD and 71.78%for OC on DRISHTIGS, 88.21% for OD and 73.70% for OC on REFUGE, 80.39% for OD and 52.65% for OC on REFUGE. EO-ProtoSeg is comparable to unsupervised domain adaptation methods yet much lighter with less than two million parameters and does not require any retraining.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u7528\u4e8e\u5c11\u6837\u672c\u5f31\u76d1\u7763\u5206\u5272\u7684\u5143\u5b66\u4e60\u5668\uff0c\u901a\u8fc7Omni\u5143\u8bad\u7ec3\u5e73\u8861\u6570\u636e\u4f7f\u7528\u5e76\u591a\u6837\u5316\u6837\u672c\u6570\u91cf\uff0c\u63d0\u51fa\u9ad8\u6548\u7248\u672c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5f00\u53d1\u7a00\u758f\u5316\u6280\u672f\u751f\u6210\u66f4\u53ef\u5b9a\u5236\u548c\u4ee3\u8868\u6027\u7684\u6807\u6ce8\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u9752\u5149\u773c\u8bca\u65ad\u4e2d\u89c6\u76d8\u548c\u89c6\u676f\u5206\u5272\u4efb\u52a1\u9762\u4e34\u7684\u6311\u6218\uff1a\u6807\u8bb0\u773c\u5e95\u56fe\u50cf\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u5c11\u91cf\u7a00\u758f\u6807\u6ce8\u4e0b\u6709\u6548\u5de5\u4f5c\u7684\u5206\u5272\u65b9\u6cd5\u3002", "method": "1. \u5f00\u53d1\u5143\u5b66\u4e60\u5668\u7528\u4e8e\u5c11\u6837\u672c\u5f31\u76d1\u7763\u5206\u5272\uff1b2. \u5f15\u5165Omni\u5143\u8bad\u7ec3\u5e73\u8861\u6570\u636e\u4f7f\u7528\u5e76\u591a\u6837\u5316\u6837\u672c\u6570\u91cf\uff1b3. \u5f00\u53d1\u9ad8\u6548\u7248\u672c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff1b4. \u5f00\u53d1\u7a00\u758f\u5316\u6280\u672f\u751f\u6210\u66f4\u53ef\u5b9a\u5236\u548c\u4ee3\u8868\u6027\u7684\u6d82\u9e26\u53ca\u5176\u4ed6\u7a00\u758f\u6807\u6ce8\u3002", "result": "EO-ProtoSeg\u8868\u73b0\u6700\u4f73\uff1a\u5728REFUGE\u6570\u636e\u96c6\u4e0a\u4ec5\u4f7f\u7528\u4e00\u5f20\u7a00\u758f\u6807\u6ce8\u56fe\u50cf\uff0cOD IoU\u8fbe88.15%\uff0cOC IoU\u8fbe71.17%\uff0c\u4f18\u4e8e\u9700\u8981\u66f4\u591a\u6807\u6ce8\u56fe\u50cf\u7684\u5c11\u6837\u672c\u548c\u534a\u76d1\u7763\u65b9\u6cd5\u3002\u5728DRISHTIGS\u6570\u636e\u96c6\u4e0aOD IoU 86.80%\uff0cOC IoU 71.78%\uff1b\u5728REFUGE\u6570\u636e\u96c6\u4e0aOD IoU 88.21%\uff0cOC IoU 73.70%\u3002", "conclusion": "\u63d0\u51fa\u7684Omni\u548c\u9ad8\u6548\u7248\u672c\u5143\u5b66\u4e60\u5668\u4f18\u4e8e\u539f\u59cb\u7248\u672c\uff0cEO-ProtoSeg\u5728\u4ec5\u4f7f\u7528\u4e00\u5f20\u7a00\u758f\u6807\u6ce8\u56fe\u50cf\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4f18\u5f02\u6027\u80fd\uff0c\u4e0e\u65e0\u76d1\u7763\u57df\u9002\u5e94\u65b9\u6cd5\u76f8\u5f53\u4f46\u66f4\u8f7b\u91cf\uff08\u53c2\u6570\u5c11\u4e8e200\u4e07\uff09\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002"}}
{"id": "2512.15109", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15109", "abs": "https://arxiv.org/abs/2512.15109", "authors": ["Zhuoran Li", "Zhen Gao", "Xinhua Liu", "Zheng Wang", "Xiaotian Zhou", "Lei Liu", "Yongpeng Wu", "Wei Feng", "Yongming Huang"], "title": "Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network", "comment": null, "summary": "The advent of sixth-generation (6G) places intelligence at the core of wireless architecture, fusing perception, communication, and computation into a single closed-loop. This paper argues that large artificial intelligence models (LAMs) can endow base stations with perception, reasoning, and acting capabilities, thus transforming them into intelligent base station agents (IBSAs). We first review the historical evolution of BSs from single-functional analog infrastructure to distributed, software-defined, and finally LAM-empowered IBSA, highlighting the accompanying changes in architecture, hardware platforms, and deployment. We then present an IBSA architecture that couples a perception-cognition-execution pipeline with cloud-edge-end collaboration and parameter-efficient adaptation. Subsequently,we study two representative scenarios: (i) cooperative vehicle-road perception for autonomous driving, and (ii) ubiquitous base station support for low-altitude uncrewed aerial vehicle safety monitoring and response against unauthorized drones. On this basis, we analyze key enabling technologies spanning LAM design and training, efficient edge-cloud inference, multi-modal perception and actuation, as well as trustworthy security and governance. We further propose a holistic evaluation framework and benchmark considerations that jointly cover communication performance, perception accuracy, decision-making reliability, safety, and energy efficiency. Finally, we distill open challenges on benchmarks, continual adaptation, trustworthy decision-making, and standardization. Together, this work positions LAM-enabled IBSAs as a practical path toward integrated perception, communication, and computation native, safety-critical 6G systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5c06\u57fa\u7ad9\u8f6c\u53d8\u4e3a\u667a\u80fd\u57fa\u7ad9\u4ee3\u7406\uff0c\u5b9e\u73b0\u611f\u77e5\u3001\u901a\u4fe1\u4e0e\u8ba1\u7b97\u7684\u878d\u5408\uff0c\u4e3a6G\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u9645\u8def\u5f84", "motivation": "6G\u65f6\u4ee3\u9700\u8981\u5c06\u667a\u80fd\u7f6e\u4e8e\u65e0\u7ebf\u67b6\u6784\u6838\u5fc3\uff0c\u878d\u5408\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u3002\u4f20\u7edf\u57fa\u7ad9\u529f\u80fd\u5355\u4e00\uff0c\u65e0\u6cd5\u6ee1\u8db3\u672a\u6765\u667a\u80fd\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u9700\u8981\u5229\u7528\u5927\u578bAI\u6a21\u578b\u8d4b\u4e88\u57fa\u7ad9\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\u80fd\u529b", "method": "\u63d0\u51fa\u667a\u80fd\u57fa\u7ad9\u4ee3\u7406\u67b6\u6784\uff0c\u7ed3\u5408\u611f\u77e5-\u8ba4\u77e5-\u6267\u884c\u6d41\u7a0b\u4e0e\u4e91\u8fb9\u7aef\u534f\u540c\uff0c\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u9002\u914d\u3002\u7814\u7a76\u4e24\u4e2a\u4ee3\u8868\u6027\u573a\u666f\uff1a\u534f\u540c\u8f66\u8def\u611f\u77e5\u548c\u65e0\u4eba\u673a\u5b89\u5168\u76d1\u63a7\uff0c\u5206\u6790\u5173\u952e\u6280\u672f\u5305\u62ecLAM\u8bbe\u8ba1\u8bad\u7ec3\u3001\u8fb9\u7f18\u4e91\u63a8\u7406\u3001\u591a\u6a21\u6001\u611f\u77e5\u4e0e\u53ef\u4fe1\u5b89\u5168", "result": "\u63d0\u51fa\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u51c6\u8003\u91cf\uff0c\u6db5\u76d6\u901a\u4fe1\u6027\u80fd\u3001\u611f\u77e5\u7cbe\u5ea6\u3001\u51b3\u7b56\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u80fd\u6548\u3002\u8bc6\u522b\u51fa\u57fa\u51c6\u6d4b\u8bd5\u3001\u6301\u7eed\u9002\u914d\u3001\u53ef\u4fe1\u51b3\u7b56\u548c\u6807\u51c6\u5316\u7b49\u5f00\u653e\u6311\u6218", "conclusion": "\u57fa\u4e8e\u5927\u578bAI\u6a21\u578b\u7684\u667a\u80fd\u57fa\u7ad9\u4ee3\u7406\u662f\u5b9e\u73b0\u611f\u77e5\u3001\u901a\u4fe1\u3001\u8ba1\u7b97\u539f\u751f\u878d\u5408\u76846G\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u7684\u5b9e\u7528\u8def\u5f84\uff0c\u4e3a6G\u667a\u80fd\u65e0\u7ebf\u67b6\u6784\u63d0\u4f9b\u91cd\u8981\u65b9\u5411"}}
{"id": "2512.15425", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15425", "abs": "https://arxiv.org/abs/2512.15425", "authors": ["Peng Yuan", "Zulin Wang", "Tao Luo", "Yuanhan Ni"], "title": "An Anti-Interference AFDM System: Interference Impacts Analyses and Parameter Optimization", "comment": null, "summary": "This paper proposes an anti-interference affine frequency division multiplexing (AFDM) system to ensure reliability and resource efficiency under malicious high-power interference originating from adversarial devices in high-mobility scenarios. Closed-form expressions of interferences in the discrete affine Fourier transform (DAFT) domain are derived by utilizing the stationary phase principle and the Affine Fourier transform convolution theorem, which indicates that interference impacts can be classified into stationary and non-stationary categories. On this basis, we reveal the analytical relationship between packet throughput and the paramerters of spread spectrum and error correction coding in our proposed anti-interference system, which enables the design of a parameter optimization algorithm that maximizes packet throughput. For reception, by jointly utilizing the autocorrelation function of spreading sequence and the cyclic-shift property of AFDM input-output relation, we design a linear-complexity correlation-based DAFT domain detector (CDD) capable of achieving full diversity gain, which performs correlation-based equalization to avoid matrix inversion. Numerical results validate the accuracy of the derived closed-form expressions and verify that the proposed anti-interference AFDM system could achieve high packet throughput under interference in high-mobility scenarios.", "AI": {"tldr": "\u63d0\u51fa\u6297\u5e72\u6270\u4eff\u5c04\u9891\u5206\u590d\u7528\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u79fb\u52a8\u573a\u666f\u4e0b\u5bf9\u6297\u6076\u610f\u9ad8\u529f\u7387\u5e72\u6270\uff0c\u901a\u8fc7\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\u6700\u5927\u5316\u5305\u541e\u5410\u91cf\uff0c\u8bbe\u8ba1\u7ebf\u6027\u590d\u6742\u5ea6\u76f8\u5173\u68c0\u6d4b\u5668\u5b9e\u73b0\u5168\u5206\u96c6\u589e\u76ca\u3002", "motivation": "\u5728\u9ad8\u79fb\u52a8\u573a\u666f\u4e2d\uff0c\u5bf9\u6297\u6027\u8bbe\u5907\u4ea7\u751f\u7684\u6076\u610f\u9ad8\u529f\u7387\u5e72\u6270\u4f1a\u4e25\u91cd\u5f71\u54cd\u901a\u4fe1\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u8d44\u6e90\u6548\u7387\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u6297\u5e72\u6270\u65b9\u6848\u3002", "method": "1) \u5229\u7528\u5e73\u7a33\u76f8\u4f4d\u539f\u7406\u548c\u4eff\u5c04\u5085\u91cc\u53f6\u53d8\u6362\u5377\u79ef\u5b9a\u7406\u63a8\u5bfc\u79bb\u6563\u4eff\u5c04\u5085\u91cc\u53f6\u53d8\u6362\u57df\u5e72\u6270\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b2) \u8bbe\u8ba1\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\u6700\u5927\u5316\u5305\u541e\u5410\u91cf\uff1b3) \u5229\u7528\u6269\u9891\u5e8f\u5217\u81ea\u76f8\u5173\u51fd\u6570\u548cAFDM\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\u7684\u5faa\u73af\u79fb\u4f4d\u7279\u6027\uff0c\u8bbe\u8ba1\u7ebf\u6027\u590d\u6742\u5ea6\u76f8\u5173\u68c0\u6d4b\u5668\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u95ed\u5f0f\u8868\u8fbe\u5f0f\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u6297\u5e72\u6270AFDM\u7cfb\u7edf\u5728\u9ad8\u79fb\u52a8\u5e72\u6270\u573a\u666f\u4e0b\u80fd\u591f\u5b9e\u73b0\u9ad8\u5305\u541e\u5410\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6297\u5e72\u6270AFDM\u7cfb\u7edf\u901a\u8fc7\u53c2\u6570\u4f18\u5316\u548c\u76f8\u5173\u68c0\u6d4b\u5668\u8bbe\u8ba1\uff0c\u5728\u9ad8\u79fb\u52a8\u573a\u666f\u4e0b\u6709\u6548\u5bf9\u6297\u6076\u610f\u5e72\u6270\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u6027\u548c\u8d44\u6e90\u6548\u7387\u7684\u5e73\u8861\u3002"}}
{"id": "2512.15262", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15262", "abs": "https://arxiv.org/abs/2512.15262", "authors": ["Youmin Xu", "Mengxi Guo", "Shijie Zhao", "Weiqi Li", "Junlin Li", "Li Zhang", "Jian Zhang"], "title": "Audio-Visual Cross-Modal Compression for Generative Face Video Coding", "comment": "Accepted as a PAPER and for publication in the DCC 2026 proceedings", "summary": "Generative face video coding (GFVC) is vital for modern applications like video conferencing, yet existing methods primarily focus on video motion while neglecting the significant bitrate contribution of audio. Despite the well-established correlation between audio and lip movements, this cross-modal coherence has not been systematically exploited for compression. To address this, we propose an Audio-Visual Cross-Modal Compression (AVCC) framework that jointly compresses audio and video streams. Our framework extracts motion information from video and tokenizes audio features, then aligns them through a unified audio-video diffusion process. This allows synchronized reconstruction of both modalities from a shared representation. In extremely low-rate scenarios, AVCC can even reconstruct one modality from the other. Experiments show that AVCC significantly outperforms the Versatile Video Coding (VVC) standard and state-of-the-art GFVC schemes in rate-distortion performance, paving the way for more efficient multimodal communication systems.", "AI": {"tldr": "\u63d0\u51faAVCC\u6846\u67b6\uff0c\u901a\u8fc7\u97f3\u9891-\u89c6\u89c9\u8de8\u6a21\u6001\u538b\u7f29\u8054\u5408\u5904\u7406\u97f3\u89c6\u9891\u6d41\uff0c\u5229\u7528\u97f3\u9891\u4e0e\u5507\u90e8\u8fd0\u52a8\u7684\u5173\u8054\u6027\u63d0\u5347\u538b\u7f29\u6548\u7387", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u4eba\u8138\u89c6\u9891\u7f16\u7801\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u89c6\u9891\u8fd0\u52a8\uff0c\u5ffd\u89c6\u4e86\u97f3\u9891\u5bf9\u7801\u7387\u7684\u663e\u8457\u8d21\u732e\u3002\u5c3d\u7ba1\u97f3\u9891\u4e0e\u5507\u90e8\u8fd0\u52a8\u5b58\u5728\u660e\u786e\u5173\u8054\uff0c\u4f46\u8fd9\u79cd\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u5c1a\u672a\u88ab\u7cfb\u7edf\u6027\u5730\u7528\u4e8e\u538b\u7f29", "method": "\u63d0\u51fa\u97f3\u9891-\u89c6\u89c9\u8de8\u6a21\u6001\u538b\u7f29\u6846\u67b6\uff0c\u4ece\u89c6\u9891\u63d0\u53d6\u8fd0\u52a8\u4fe1\u606f\uff0c\u5bf9\u97f3\u9891\u7279\u5f81\u8fdb\u884c\u6807\u8bb0\u5316\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u97f3\u9891-\u89c6\u9891\u6269\u6563\u8fc7\u7a0b\u5bf9\u9f50\u4e24\u8005\uff0c\u5b9e\u73b0\u4ece\u5171\u4eab\u8868\u793a\u4e2d\u540c\u6b65\u91cd\u5efa\u4e24\u79cd\u6a21\u6001", "result": "AVCC\u5728\u7387\u5931\u771f\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8eVVC\u6807\u51c6\u548c\u6700\u5148\u8fdb\u7684GFVC\u65b9\u6848\uff0c\u5728\u6781\u4f4e\u7801\u7387\u573a\u666f\u4e0b\u751a\u81f3\u53ef\u4ee5\u4ece\u4e00\u79cd\u6a21\u6001\u91cd\u5efa\u53e6\u4e00\u79cd\u6a21\u6001", "conclusion": "AVCC\u4e3a\u66f4\u9ad8\u6548\u7684\u591a\u6a21\u6001\u901a\u4fe1\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u901a\u8fc7\u5229\u7528\u97f3\u9891\u4e0e\u89c6\u89c9\u7684\u8de8\u6a21\u6001\u5173\u8054\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u538b\u7f29\u6548\u7387\u63d0\u5347"}}
{"id": "2512.15119", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15119", "abs": "https://arxiv.org/abs/2512.15119", "authors": ["Jiayang Wan", "Ke He", "Yafei Wang", "Fan Liu", "Wenjin Wang", "Shi Jin"], "title": "QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Due to the significant variations in unmanned aerial vehicle (UAV) altitude and horizontal mobility, it becomes difficult for any single network to ensure continuous and reliable threedimensional coverage. Towards that end, the space-air-ground integrated network (SAGIN) has emerged as an essential architecture for enabling ubiquitous UAV connectivity. To address the pronounced disparities in coverage and signal characteristics across heterogeneous networks, this paper formulates UAV mobility management in SAGIN as a constrained multi-objective joint optimization problem. The formulation couples discrete link selection with continuous trajectory optimization. Building on this, we propose a two-level multi-agent hierarchical deep reinforcement learning (HDRL) framework that decomposes the problem into two alternately solvable subproblems. To map complex link selection decisions into a compact discrete action space, we conceive a double deep Q-network (DDQN) algorithm in the top-level, which achieves stable and high-quality policy learning through double Q-value estimation. To handle the continuous trajectory action space while satisfying quality of service (QoS) constraints, we integrate the maximum-entropy mechanism of the soft actor-critic (SAC) and employ a Lagrangian-based constrained SAC (CSAC) algorithm in the lower-level that dynamically adjusts the Lagrange multipliers to balance constraint satisfaction and policy optimization. Moreover, the proposed algorithm can be extended to multi-UAV scenarios under the centralized training and decentralized execution (CTDE) paradigm, which enables more generalizable policies. Simulation results demonstrate that the proposed scheme substantially outperforms existing benchmarks in throughput, link switching frequency and QoS satisfaction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u79fb\u52a8\u7ba1\u7406\u65b9\u6848\uff0c\u901a\u8fc7DDQN\u548c\u7ea6\u675fSAC\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u94fe\u8def\u9009\u62e9\u548c\u8f68\u8ff9\u89c4\u5212", "motivation": "\u65e0\u4eba\u673a\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u79fb\u52a8\u65f6\uff0c\u5355\u4e00\u7f51\u7edc\u96be\u4ee5\u4fdd\u8bc1\u8fde\u7eed\u53ef\u9760\u8986\u76d6\uff0c\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u6210\u4e3a\u5fc5\u8981\u67b6\u6784\uff0c\u4f46\u5f02\u6784\u7f51\u7edc\u95f4\u7684\u8986\u76d6\u548c\u4fe1\u53f7\u7279\u6027\u5dee\u5f02\u663e\u8457\uff0c\u9700\u8981\u6709\u6548\u7684\u79fb\u52a8\u7ba1\u7406\u65b9\u6848", "method": "\u91c7\u7528\u4e24\u5c42\u591a\u667a\u80fd\u4f53\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a\u9876\u5c42\u4f7f\u7528\u53cc\u6df1\u5ea6Q\u7f51\u7edc\u5904\u7406\u79bb\u6563\u94fe\u8def\u9009\u62e9\uff1b\u5e95\u5c42\u4f7f\u7528\u57fa\u4e8e\u62c9\u683c\u6717\u65e5\u7684\u7ea6\u675f\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\u5904\u7406\u8fde\u7eed\u8f68\u8ff9\u4f18\u5316\u548cQoS\u7ea6\u675f", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u5728\u541e\u5410\u91cf\u3001\u94fe\u8def\u5207\u6362\u9891\u7387\u548cQoS\u6ee1\u610f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3SAGIN\u4e2d\u65e0\u4eba\u673a\u79fb\u52a8\u7ba1\u7406\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u652f\u6301\u591a\u65e0\u4eba\u673a\u573a\u666f\uff0c\u5177\u6709\u8f83\u597d\u7684\u6cdb\u5316\u80fd\u529b"}}
{"id": "2512.15562", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15562", "abs": "https://arxiv.org/abs/2512.15562", "authors": ["Xingyu Zhou", "Le Liang", "Hao Ye", "Jing Zhang", "Chao-Kai Wen", "Shi Jin"], "title": "Reducing Pilots in Channel Estimation With Predictive Foundation Models", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Accurate channel state information (CSI) acquisition is essential for modern wireless systems, which becomes increasingly difficult under large antenna arrays, strict pilot overhead constraints, and diverse deployment environments. Existing artificial intelligence-based solutions often lack robustness and fail to generalize across scenarios. To address this limitation, this paper introduces a predictive-foundation-model-based channel estimation framework that enables accurate, low-overhead, and generalizable CSI acquisition. The proposed framework employs a predictive foundation model trained on large-scale cross-domain CSI data to extract universal channel representations and provide predictive priors with strong cross-scenario transferability. A pilot processing network based on a vision transformer architecture is further designed to capture spatial, temporal, and frequency correlations from pilot observations. An efficient fusion mechanism integrates predictive priors with real-time measurements, enabling reliable CSI reconstruction even under sparse or noisy conditions. Extensive evaluations across diverse configurations demonstrate that the proposed estimator significantly outperforms both classical and data-driven baselines in accuracy, robustness, and generalization capability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9884\u6d4b\u57fa\u7840\u6a21\u578b\u7684\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u8de8\u57dfCSI\u6570\u636e\u8bad\u7ec3\u63d0\u53d6\u901a\u7528\u4fe1\u9053\u8868\u793a\uff0c\u7ed3\u5408ViT\u67b6\u6784\u7684\u5bfc\u9891\u5904\u7406\u7f51\u7edc\uff0c\u5b9e\u73b0\u51c6\u786e\u3001\u4f4e\u5f00\u9500\u3001\u53ef\u6cdb\u5316\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u3002", "motivation": "\u73b0\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u3001\u4e25\u683c\u5bfc\u9891\u5f00\u9500\u7ea6\u675f\u548c\u591a\u6837\u5316\u90e8\u7f72\u73af\u5883\u4e0b\uff0c\u51c6\u786e\u83b7\u53d6\u4fe1\u9053\u72b6\u6001\u4fe1\u606f(CSI)\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002\u73b0\u6709\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u65e0\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u95f4\u6cdb\u5316\u3002", "method": "1) \u4f7f\u7528\u5927\u89c4\u6a21\u8de8\u57dfCSI\u6570\u636e\u8bad\u7ec3\u9884\u6d4b\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u53d6\u901a\u7528\u4fe1\u9053\u8868\u793a\u5e76\u63d0\u4f9b\u5177\u6709\u5f3a\u8de8\u573a\u666f\u53ef\u8fc1\u79fb\u6027\u7684\u9884\u6d4b\u5148\u9a8c\uff1b2) \u8bbe\u8ba1\u57fa\u4e8e\u89c6\u89c9Transformer\u67b6\u6784\u7684\u5bfc\u9891\u5904\u7406\u7f51\u7edc\uff0c\u4ece\u5bfc\u9891\u89c2\u6d4b\u4e2d\u6355\u83b7\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u9891\u7387\u76f8\u5173\u6027\uff1b3) \u5f00\u53d1\u9ad8\u6548\u878d\u5408\u673a\u5236\uff0c\u5c06\u9884\u6d4b\u5148\u9a8c\u4e0e\u5b9e\u65f6\u6d4b\u91cf\u76f8\u7ed3\u5408\uff0c\u5373\u4f7f\u5728\u7a00\u758f\u6216\u566a\u58f0\u6761\u4ef6\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u53ef\u9760\u7684CSI\u91cd\u5efa\u3002", "result": "\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u9884\u6d4b\u57fa\u7840\u6a21\u578b\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u3001\u4f4e\u5f00\u9500\u548c\u53ef\u6cdb\u5316\u7684CSI\u83b7\u53d6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709AI\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u548c\u8de8\u573a\u666f\u6cdb\u5316\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.15270", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15270", "abs": "https://arxiv.org/abs/2512.15270", "authors": ["Mengxi Guo", "Shijie Zhao", "Junlin Li", "Li Zhang"], "title": "Generative Preprocessing for Image Compression with Pre-trained Diffusion Models", "comment": "Accepted as a PAPER and for publication in the DCC 2026 proceedings", "summary": "Preprocessing is a well-established technique for optimizing compression, yet existing methods are predominantly Rate-Distortion (R-D) optimized and constrained by pixel-level fidelity. This work pioneers a shift towards Rate-Perception (R-P) optimization by, for the first time, adapting a large-scale pre-trained diffusion model for compression preprocessing. We propose a two-stage framework: first, we distill the multi-step Stable Diffusion 2.1 into a compact, one-step image-to-image model using Consistent Score Identity Distillation (CiD). Second, we perform a parameter-efficient fine-tuning of the distilled model's attention modules, guided by a Rate-Perception loss and a differentiable codec surrogate. Our method seamlessly integrates with standard codecs without any modification and leverages the model's powerful generative priors to enhance texture and mitigate artifacts. Experiments show substantial R-P gains, achieving up to a 30.13% BD-rate reduction in DISTS on the Kodak dataset and delivering superior subjective visual quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u538b\u7f29\u9884\u5904\u7406\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u7528\u4e8e\u538b\u7f29\u9884\u5904\u7406\uff0c\u5b9e\u73b0\u7387-\u611f\u77e5\u4f18\u5316\u800c\u975e\u4f20\u7edf\u7684\u7387-\u5931\u771f\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u538b\u7f29\u9884\u5904\u7406\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u7387-\u5931\u771f\u4f18\u5316\uff0c\u53d7\u9650\u4e8e\u50cf\u7d20\u7ea7\u4fdd\u771f\u5ea6\u3002\u672c\u6587\u65e8\u5728\u8f6c\u5411\u7387-\u611f\u77e5\u4f18\u5316\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5927\u751f\u6210\u5148\u9a8c\u6765\u63d0\u5347\u7eb9\u7406\u8d28\u91cf\u548c\u51cf\u5c11\u538b\u7f29\u4f2a\u5f71\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u4f7f\u7528\u4e00\u81f4\u6027\u5206\u6570\u6052\u7b49\u84b8\u998f\u5c06\u591a\u6b65Stable Diffusion 2.1\u84b8\u998f\u4e3a\u7d27\u51d1\u7684\u5355\u6b65\u56fe\u50cf\u5230\u56fe\u50cf\u6a21\u578b\uff1b2) \u5728\u84b8\u998f\u6a21\u578b\u6ce8\u610f\u529b\u6a21\u5757\u4e0a\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u4f7f\u7528\u7387-\u611f\u77e5\u635f\u5931\u548c\u53ef\u5fae\u5206\u7f16\u89e3\u7801\u5668\u66ff\u4ee3\u8fdb\u884c\u6307\u5bfc\u3002", "result": "\u5728Kodak\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u7387-\u611f\u77e5\u589e\u76ca\uff0cDISTS\u6307\u6807\u4e0a\u8fbe\u523030.13%\u7684BD-rate\u51cf\u5c11\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u4e3b\u89c2\u89c6\u89c9\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5c06\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u6210\u529f\u5e94\u7528\u4e8e\u538b\u7f29\u9884\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u4ece\u7387-\u5931\u771f\u4f18\u5316\u5411\u7387-\u611f\u77e5\u4f18\u5316\u7684\u8f6c\u53d8\uff0c\u65e0\u9700\u4fee\u6539\u6807\u51c6\u7f16\u89e3\u7801\u5668\u5373\u53ef\u65e0\u7f1d\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u538b\u7f29\u56fe\u50cf\u7684\u611f\u77e5\u8d28\u91cf\u3002"}}
{"id": "2512.15246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15246", "abs": "https://arxiv.org/abs/2512.15246", "authors": ["Nguyen Thanh Vinh", "Manoj Vishwanath", "Thinh Nguyen-Quang", "Nguyen Viet Ha", "Bui Thanh Tung", "Huy-Dung Han", "Nguyen Quang Linh", "Nguyen Hai Linh", "Hung Cao"], "title": "Enhancing Alzheimer's Detection through Late Fusion of Multi-Modal EEG Features", "comment": null, "summary": "Alzheimer s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline, where early detection is essential for timely intervention and improved patient outcomes. Traditional diagnostic methods are time-consuming and require expert interpretation, thus, automated approaches are highly desirable. This study presents a novel deep learning framework for AD diagnosis using Electroencephalograph (EEG) signals, integrating multiple feature extraction techniques including alpha-wave analysis, Discrete Wavelet Transform (DWT), and Markov Transition Fields (MTF). A late-fusion strategy is employed to combine predictions from separate neural networks trained on these diverse representations, capturing both temporal and frequency-domain patterns in the EEG data. The proposed model attains a classification accuracy of 87.23%, with a precision of 87.95%, a recall of 86.91%, and an F1 score of 87.42% when evaluated on a publicly available dataset, demonstrating its potential for reliable, scalable, and early AD screening. Rigorous preprocessing and targeted frequency band selection, particularly in the alpha range due to its cognitive relevance, further enhance performance. This work highlights the promise of deep learning in supporting physicians with efficient and accessible tools for early AD diagnosis.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eEEG\u4fe1\u53f7\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7279\u5f81\u63d0\u53d6\u548c\u665a\u671f\u878d\u5408\u7b56\u7565\u5b9e\u73b0\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u8bca\u65ad\uff0c\u51c6\u786e\u7387\u8fbe87.23%", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u68c0\u6d4b\u5bf9\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u8017\u65f6\u4e14\u9700\u8981\u4e13\u5bb6\u89e3\u8bfb\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5", "method": "\u4f7f\u7528EEG\u4fe1\u53f7\uff0c\u6574\u5408alpha\u6ce2\u5206\u6790\u3001\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u548c\u9a6c\u5c14\u53ef\u592b\u8f6c\u79fb\u573a\u4e09\u79cd\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u91c7\u7528\u665a\u671f\u878d\u5408\u7b56\u7565\u7ed3\u5408\u4e0d\u540c\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fbe\u523087.23%\u51c6\u786e\u7387\u300187.95%\u7cbe\u786e\u7387\u300186.91%\u53ec\u56de\u7387\u548c87.42% F1\u5206\u6570\uff0c\u7279\u522b\u5173\u6ce8alpha\u9891\u6bb5\u63d0\u5347\u6027\u80fd", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e3a\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u6709\u671b\u652f\u6301\u533b\u751f\u8fdb\u884c\u9ad8\u6548\u8bca\u65ad"}}
{"id": "2512.15394", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.15394", "abs": "https://arxiv.org/abs/2512.15394", "authors": ["Ruibo Shang", "Sidhartha Jandhyala", "Yujia Wu", "Kevin Hoffer-Hawlik", "Austin Van Namen", "Matthew O'Donnell", "Geoffrey P. Luke"], "title": "Deep Learning-Driven Quantitative Spectroscopic Photoacoustic Imaging for Segmentation and Oxygen Saturation Estimation", "comment": "18 pages, 6 figures", "summary": "Spectroscopic photoacoustic (sPA) imaging can potentially estimate blood oxygenation saturation (sO2) in vivo noninvasively. However, quantitatively accurate results require accurate optical fluence estimates. Robust modeling in heterogeneous tissue, where light with different wavelengths can experience significantly different absorption and scattering, is difficult. In this work, we developed a deep neural network (Hybrid-Net) for sPA imaging to simultaneously estimate sO2 in blood vessels and segment those vessels from surrounding background tissue. sO2 error was minimized only in blood vessels segmented in Hybrid-Net, resulting in more accurate predictions. Hybrid-Net was first trained on simulated sPA data (at 700 nm and 850 nm) representing initial pressure distributions from three-dimensional Monte Carlo simulations of light transport in breast tissue. Then, for experimental verification, the network was retrained on experimental sPA data (at 700 nm and 850 nm) acquired from simple tissue mimicking phantoms with an embedded blood pool. Quantitative measures were used to evaluate Hybrid-Net performance with an averaged segmentation accuracy of >= 0.978 in simulations with varying noise levels (0dB-35dB) and 0.998 in the experiment, and an averaged sO2 mean squared error of <= 0.048 in simulations with varying noise levels (0dB-35dB) and 0.003 in the experiment. Overall, these results show that Hybrid-Net can provide accurate blood oxygenation without estimating the optical fluence, and this study could lead to improvements in in-vivo sO2 estimation.", "AI": {"tldr": "\u5f00\u53d1\u4e86Hybrid-Net\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff0c\u7528\u4e8e\u5149\u8c31\u5149\u58f0\u6210\u50cf\u4e2d\u540c\u65f6\u4f30\u8ba1\u8840\u6c27\u9971\u548c\u5ea6\u548c\u5206\u5272\u8840\u7ba1\uff0c\u65e0\u9700\u5149\u5b66\u901a\u91cf\u4f30\u8ba1\uff0c\u63d0\u9ad8\u4e86\u8840\u6c27\u5b9a\u91cf\u51c6\u786e\u6027\u3002", "motivation": "\u5149\u8c31\u5149\u58f0\u6210\u50cf\u53ef\u4ee5\u65e0\u521b\u4f30\u8ba1\u4f53\u5185\u8840\u6c27\u9971\u548c\u5ea6\uff0c\u4f46\u9700\u8981\u51c6\u786e\u7684\u5149\u5b66\u901a\u91cf\u4f30\u8ba1\u3002\u5728\u5f02\u8d28\u7ec4\u7ec7\u4e2d\uff0c\u4e0d\u540c\u6ce2\u957f\u7684\u5149\u7ecf\u5386\u4e0d\u540c\u7684\u5438\u6536\u548c\u6563\u5c04\uff0c\u4f7f\u5f97\u9c81\u68d2\u5efa\u6a21\u56f0\u96be\u3002", "method": "\u5f00\u53d1\u4e86Hybrid-Net\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u540c\u65f6\u4f30\u8ba1\u8840\u7ba1\u4e2d\u7684\u8840\u6c27\u9971\u548c\u5ea6\u5e76\u5206\u5272\u8840\u7ba1\u3002\u9996\u5148\u5728\u6a21\u62df\u6570\u636e\u4e0a\u8bad\u7ec3\uff08700nm\u548c850nm\uff09\uff0c\u7136\u540e\u5728\u5b9e\u9a8c\u6570\u636e\u4e0a\u5fae\u8c03\u3002\u7f51\u7edc\u4ec5\u5728\u5206\u5272\u51fa\u7684\u8840\u7ba1\u533a\u57df\u6700\u5c0f\u5316\u8840\u6c27\u8bef\u5dee\u3002", "result": "\u5728\u6a21\u62df\u6570\u636e\u4e2d\uff080dB-35dB\u566a\u58f0\u6c34\u5e73\uff09\uff0c\u5206\u5272\u51c6\u786e\u7387\u22650.978\uff0c\u8840\u6c27\u5747\u65b9\u8bef\u5dee\u22640.048\uff1b\u5728\u5b9e\u9a8c\u4e2d\uff0c\u5206\u5272\u51c6\u786e\u73870.998\uff0c\u8840\u6c27\u5747\u65b9\u8bef\u5dee0.003\u3002\u7f51\u7edc\u65e0\u9700\u4f30\u8ba1\u5149\u5b66\u901a\u91cf\u5373\u53ef\u63d0\u4f9b\u51c6\u786e\u8840\u6c27\u3002", "conclusion": "Hybrid-Net\u80fd\u591f\u5728\u4e0d\u4f30\u8ba1\u5149\u5b66\u901a\u91cf\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u51c6\u786e\u7684\u8840\u6c27\u9971\u548c\u5ea6\uff0c\u8fd9\u9879\u7814\u7a76\u53ef\u80fd\u6539\u8fdb\u4f53\u5185\u8840\u6c27\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2512.15268", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15268", "abs": "https://arxiv.org/abs/2512.15268", "authors": ["Joachim Tapparel", "Andreas Burg"], "title": "Dataset and UAV Propagation Channel Modeling for LoRa in the 860 MHz ISM Band", "comment": "Accepted for publication in ACSSC", "summary": "LoRa is one of the most widely used low-power wide-area network technology for the Internet of Things. To achieve long-range communication with low power consumption at a low cost, LoRa uses a chirp spread spectrum modulation and transmits in the sub-GHz unlicensed industrial, scientific, and medical (ISM) frequency bands. Due to the rapid densification of IoT networks, it is crucial to obtain tailored channel models to evaluate the performance of LoRa networks. While channel models for cellular technologies have been investigated extensively, specific characteristics of LoRa transmissions operating at long range with a rather small (~ 250kHz) bandwidth require dedicated measurement campaigns and modeling efforts. In this work, we leverage an SDR-based testbed to gather and publish a dataset of LoRa frames transmitted in a campus environment. The dataset includes IQ samples of the received frames at multiple locations and allows for the evaluation of channel variations with high time resolution. Using the gathered data, we derive empirical propagation channel models for LoRa that include receiver correlation over distance for three scenarios: unmanned aerial vehicle (UAV) line-of-sight (LoS), UAV non-LoS, and pedestrian non-LoS. Furthermore, the dataset is annotated with synchronization information, enabling the evaluation of receiver algorithms using experimental data.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7SDR\u6d4b\u8bd5\u5e73\u53f0\u6536\u96c6\u5e76\u53d1\u5e03\u4e86\u6821\u56ed\u73af\u5883\u4e2d\u7684LoRa\u5e27\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u8be5\u6570\u636e\u63a8\u5bfc\u4e86\u4e09\u79cd\u573a\u666f\u4e0b\u7684\u7ecf\u9a8c\u4f20\u64ad\u4fe1\u9053\u6a21\u578b\uff0c\u4e3aLoRa\u7f51\u7edc\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e13\u7528\u4fe1\u9053\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u7f51\u7edc\u5feb\u901f\u5bc6\u96c6\u5316\uff0c\u9700\u8981\u9488\u5bf9LoRa\u4f20\u8f93\u7279\u6027\uff08\u957f\u8ddd\u79bb\u3001\u5c0f\u5e26\u5bbd~250kHz\uff09\u7684\u4e13\u7528\u4fe1\u9053\u6a21\u578b\u6765\u8bc4\u4f30\u7f51\u7edc\u6027\u80fd\uff0c\u800c\u73b0\u6709\u8702\u7a9d\u6280\u672f\u7684\u4fe1\u9053\u6a21\u578b\u4e0d\u9002\u7528\u4e8eLoRa\u3002", "method": "\u5229\u7528\u57fa\u4e8eSDR\u7684\u6d4b\u8bd5\u5e73\u53f0\u6536\u96c6\u6821\u56ed\u73af\u5883\u4e2d\u7684LoRa\u5e27\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u4f4d\u7f6e\u63a5\u6536\u5e27\u7684IQ\u6837\u672c\uff0c\u652f\u6301\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u8bc4\u4f30\u4fe1\u9053\u53d8\u5316\u3002\u57fa\u4e8e\u6536\u96c6\u6570\u636e\u63a8\u5bfc\u4e86\u4e09\u79cd\u573a\u666f\u7684\u7ecf\u9a8c\u4f20\u64ad\u4fe1\u9053\u6a21\u578b\uff1a\u65e0\u4eba\u673a\u89c6\u8ddd\u3001\u65e0\u4eba\u673a\u975e\u89c6\u8ddd\u548c\u884c\u4eba\u975e\u89c6\u8ddd\u3002", "result": "\u53d1\u5e03\u4e86\u5305\u542b\u540c\u6b65\u4fe1\u606f\u6ce8\u91ca\u7684LoRa\u5e27\u6570\u636e\u96c6\uff0c\u80fd\u591f\u4f7f\u7528\u5b9e\u9a8c\u6570\u636e\u8bc4\u4f30\u63a5\u6536\u7b97\u6cd5\u3002\u63a8\u5bfc\u4e86\u5305\u542b\u63a5\u6536\u5668\u8ddd\u79bb\u76f8\u5173\u6027\u7684\u7ecf\u9a8c\u4f20\u64ad\u4fe1\u9053\u6a21\u578b\uff0c\u4e3aLoRa\u7f51\u7edc\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e13\u7528\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86LoRa\u4e13\u7528\u4fe1\u9053\u6a21\u578b\u548c\u516c\u5f00\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86LoRa\u7f51\u7edc\u6027\u80fd\u8bc4\u4f30\u4e2d\u4e13\u7528\u4fe1\u9053\u6a21\u578b\u7684\u7a7a\u767d\uff0c\u652f\u6301\u66f4\u51c6\u786e\u7684LoRa\u7f51\u7edc\u8bbe\u8ba1\u548c\u4f18\u5316\u3002"}}
{"id": "2512.15543", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.15543", "abs": "https://arxiv.org/abs/2512.15543", "authors": ["Naveenkumar G Venkataswamy", "Masudul H Imtiaz", "Stephanie Schuckers"], "title": "Nine Years of Pediatric Iris Recognition: Evidence for Biometric Permanence", "comment": null, "summary": "Biometric permanence in pediatric populations remains poorly understood despite widespread deployment of iris recognition for children in national identity programs such as India's Aadhaar and trusted traveler programs like Canada's NEXUS. This study presents a comprehensive longitudinal evaluation of pediatric iris recognition, analyzing 276 subjects enrolled between ages 4-12 and followed up to nine years through adolescence. Using 18,318 near-infrared iris images acquired semi-annually, we evaluated commercial (VeriEye) and open-source (OpenIris) systems through linear mixed-effects models that disentangle enrollment age, developmental maturation, and elapsed time while controlling for image quality and physiological factors. False non-match rates remained below 0.5% across the nine-year period for both matchers using pediatric-calibrated thresholds, approaching adult-level performance. However, we reveal significant algorithm-dependent temporal behaviors: VeriEye's apparent decline reflects developmental confounding across enrollment cohorts rather than genuine template aging, while OpenIris exhibits modest but genuine temporal aging (0.5 standard deviations over eight years). Image quality and pupil dilation constancy dominated longitudinal performance, with dilation effects reaching 3.0-3.5 standard deviations, substantially exceeding temporal factors. Failures concentrated in 9.4% of subjects with persistent acquisition challenges rather than accumulating with elapsed time, confirming acquisition conditions as the primary limitation. These findings justify extending conservative re-enrollment policies, potentially to 10-12 year validity periods for high-quality enrollments at ages 7+, and demonstrate iris recognition remains viable throughout childhood and adolescence with proper imaging control.", "AI": {"tldr": "\u513f\u7ae5\u8679\u819c\u8bc6\u522b\u751f\u7269\u7279\u5f81\u6301\u4e45\u6027\u7814\u7a76\uff1a\u901a\u8fc79\u5e74\u7eb5\u5411\u5206\u6790\u53d1\u73b0\uff0c\u5728\u9002\u5f53\u6210\u50cf\u63a7\u5236\u4e0b\uff0c\u513f\u7ae5\u8679\u819c\u8bc6\u522b\u6027\u80fd\u63a5\u8fd1\u6210\u4eba\u6c34\u5e73\uff0c\u4e3b\u8981\u9650\u5236\u56e0\u7d20\u662f\u91c7\u96c6\u6761\u4ef6\u800c\u975e\u65f6\u95f4\u63a8\u79fb\u3002", "motivation": "\u5c3d\u7ba1\u513f\u7ae5\u8679\u819c\u8bc6\u522b\u5df2\u5728\u5370\u5ea6Aadhaar\u548c\u52a0\u62ff\u5927NEXUS\u7b49\u56fd\u5bb6\u7ea7\u8eab\u4efd\u9879\u76ee\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u513f\u7ae5\u751f\u7269\u7279\u5f81\u7684\u6301\u4e45\u6027\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7814\u7a76\u6765\u8bc4\u4f30\u957f\u671f\u6027\u80fd\u3002", "method": "\u5bf9276\u540d4-12\u5c81\u513f\u7ae5\u8fdb\u884c\u957f\u8fbe9\u5e74\u7684\u7eb5\u5411\u7814\u7a76\uff0c\u91c7\u96c618,318\u5f20\u8fd1\u7ea2\u5916\u8679\u819c\u56fe\u50cf\uff0c\u4f7f\u7528\u5546\u4e1a\u7cfb\u7edfVeriEye\u548c\u5f00\u6e90\u7cfb\u7edfOpenIris\uff0c\u901a\u8fc7\u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b\u5206\u6790\u5165\u5b66\u5e74\u9f84\u3001\u53d1\u80b2\u6210\u719f\u5ea6\u548c\u65f6\u95f4\u56e0\u7d20\uff0c\u540c\u65f6\u63a7\u5236\u56fe\u50cf\u8d28\u91cf\u548c\u751f\u7406\u56e0\u7d20\u3002", "result": "\u4f7f\u7528\u513f\u7ae5\u6821\u51c6\u9608\u503c\u65f6\uff0c\u4e24\u79cd\u5339\u914d\u5668\u7684\u9519\u8bef\u4e0d\u5339\u914d\u7387\u57289\u5e74\u5185\u5747\u4f4e\u4e8e0.5%\uff0c\u63a5\u8fd1\u6210\u4eba\u6c34\u5e73\u3002\u7814\u7a76\u53d1\u73b0\u7b97\u6cd5\u4f9d\u8d56\u7684\u65f6\u95f4\u884c\u4e3a\u5dee\u5f02\uff1aVeriEye\u7684\u4e0b\u964d\u53cd\u6620\u7684\u662f\u53d1\u80b2\u6df7\u6742\u800c\u975e\u771f\u5b9e\u6a21\u677f\u8001\u5316\uff0c\u800cOpenIris\u663e\u793a\u9002\u5ea6\u7684\u771f\u5b9e\u65f6\u95f4\u8001\u5316\u3002\u56fe\u50cf\u8d28\u91cf\u548c\u77b3\u5b54\u6269\u5f20\u7a33\u5b9a\u6027\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u5931\u8d25\u96c6\u4e2d\u57289.4%\u6709\u6301\u7eed\u91c7\u96c6\u56f0\u96be\u7684\u53d7\u8bd5\u8005\u4e2d\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u8679\u819c\u8bc6\u522b\u5728\u6574\u4e2a\u513f\u7ae5\u671f\u548c\u9752\u6625\u671f\u4fdd\u6301\u53ef\u884c\u6027\uff0c\u4e3b\u8981\u9650\u5236\u662f\u91c7\u96c6\u6761\u4ef6\u800c\u975e\u65f6\u95f4\u56e0\u7d20\u3002\u5efa\u8bae\u5ef6\u957f\u4fdd\u5b88\u7684\u91cd\u65b0\u6ce8\u518c\u653f\u7b56\uff0c\u5bf9\u4e8e7\u5c81\u4ee5\u4e0a\u9ad8\u8d28\u91cf\u6ce8\u518c\uff0c\u6709\u6548\u671f\u53ef\u8fbe10-12\u5e74\u3002"}}
{"id": "2512.15279", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15279", "abs": "https://arxiv.org/abs/2512.15279", "authors": ["Le Hao", "Robin Neuder", "Mohamadreza Delbari", "Alejandro Jim\u00e9nez-S\u00e1ez", "Vahid Jamali", "Arash Asadi", "Andrea Ortiz"], "title": "Learning-Based Phase Shift Optimization of Liquid Crystal RIS in Dynamic mmWave Networks", "comment": null, "summary": "To enhance coverage and signal quality in millimeter-wave (mmWave) frequencies, reconfigurable intelligent surfaces (RISs) have emerged as a game-changing solution to manipulate the wireless environment. Traditional semiconductor-based RISs face scalability issues due to high power consumption. Meanwhile, liquid crystal-based RISs (LC-RISs) offer energy-efficient and cost-effective operation even for large arrays. However, this promise has a caveat. LC-RISs suffer from long reconfiguration times, on the order of tens of milliseconds, which limits their applicability in dynamic scenarios. To date, prior works have focused on hardware design aspects or static scenarios to address this limitation, but little attention has been paid to optimization solutions for dynamic settings. Our paper fills this gap by proposing a reinforcement learning-based optimization framework to dynamically control the phase shifts of LC-RISs and maximize the data rate of a moving user. Specifically, we propose a Deep Deterministic Policy Gradient (DDPG) algorithm that adapts the LC-RIS phase shifts without requiring perfect channel state information and balances the tradeoff between signal-to-noise ratio (SNR) and configuration time. We validate our approach through high-fidelity ray tracing simulations, leveraging measurement data from an LC-RIS prototype. Our results demonstrate the potential of our solution to bring adaptive control to dynamic LC-RIS-assisted mmWave systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u63a7\u5236\u6db2\u6676\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08LC-RIS\uff09\u7684\u76f8\u79fb\uff0c\u4ee5\u6700\u5927\u5316\u79fb\u52a8\u7528\u6237\u7684\u6570\u636e\u901f\u7387\uff0c\u89e3\u51b3\u4e86LC-RIS\u5728\u52a8\u6001\u573a\u666f\u4e2d\u91cd\u914d\u7f6e\u65f6\u95f4\u957f\u7684\u9650\u5236\u3002", "motivation": "\u6beb\u7c73\u6ce2\u901a\u4fe1\u9700\u8981\u589e\u5f3a\u8986\u76d6\u548c\u4fe1\u53f7\u8d28\u91cf\uff0c\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u6210\u4e3a\u5173\u952e\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edf\u534a\u5bfc\u4f53RIS\u5b58\u5728\u529f\u8017\u9ad8\u3001\u53ef\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\uff0c\u800c\u6db2\u6676RIS\uff08LC-RIS\uff09\u867d\u7136\u80fd\u6548\u9ad8\u3001\u6210\u672c\u4f4e\uff0c\u4f46\u91cd\u914d\u7f6e\u65f6\u95f4\u957f\u8fbe\u6570\u5341\u6beb\u79d2\uff0c\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u786c\u4ef6\u8bbe\u8ba1\u6216\u9759\u6001\u573a\u666f\uff0c\u7f3a\u4e4f\u9488\u5bf9\u52a8\u6001\u8bbe\u7f6e\u7684\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\uff0c\u91c7\u7528\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u7b97\u6cd5\u52a8\u6001\u63a7\u5236LC-RIS\u76f8\u79fb\u3002\u8be5\u7b97\u6cd5\u4e0d\u9700\u8981\u5b8c\u7f8e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u80fd\u591f\u5e73\u8861\u4fe1\u566a\u6bd4\uff08SNR\uff09\u548c\u914d\u7f6e\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u3002\u901a\u8fc7\u9ad8\u4fdd\u771f\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5e76\u5229\u7528LC-RIS\u539f\u578b\u6d4b\u91cf\u6570\u636e\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\uff0c\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u52a8\u6001LC-RIS\u8f85\u52a9\u6beb\u7c73\u6ce2\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u5c55\u793a\u4e86\u5728\u52a8\u6001\u573a\u666f\u4e2d\u4f18\u5316LC-RIS\u6027\u80fd\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86LC-RIS\u5728\u52a8\u6001\u573a\u666f\u4f18\u5316\u65b9\u9762\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3LC-RIS\u91cd\u914d\u7f6e\u65f6\u95f4\u957f\u7684\u95ee\u9898\uff0c\u4e3a\u52a8\u6001LC-RIS\u8f85\u52a9\u6beb\u7c73\u6ce2\u7cfb\u7edf\u5e26\u6765\u4e86\u81ea\u9002\u5e94\u63a7\u5236\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.15548", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.15548", "abs": "https://arxiv.org/abs/2512.15548", "authors": ["Naveenkumar G. Venkataswamy", "Yu Liu", "Soumyabrata Dey", "Stephanie Schuckers", "Masudul H. Imtiaz"], "title": "An Open-Source Framework for Quality-Assured Smartphone-Based Visible Light Iris Recognition", "comment": null, "summary": "Smartphone-based iris recognition in the visible spectrum (VIS) offers a low-cost and accessible biometric alternative but remains a challenge due to lighting variability, pigmentation effects, and the limited adoption of standardized capture protocols. In this work, we present CUVIRIS, a dataset of 752 ISO/IEC 29794-6 compliant iris images from 47 subjects, collected with a custom Android application that enforces real-time framing, sharpness assessment, and quality feedback. We further introduce LightIrisNet, a MobileNetV3-based multi-task segmentation model optimized for on-device deployment. In addition, we adapt IrisFormer, a transformer-based matcher, to the VIS domain. We evaluate OSIRIS and IrisFormer under a standardized protocol and benchmark against published CNN baselines reported in prior work. On CUVIRIS, the open-source OSIRIS system achieves a TAR of 97.9% at FAR = 0.01 (EER = 0.76%), while IrisFormer, trained only on the UBIRIS.v2 dataset, achieves an EER of 0.057\\%. To support reproducibility, we release the Android application, LightIrisNet, trained IrisFormer weights, and a subset of the CUVIRIS dataset. These results show that, with standardized acquisition and VIS-adapted lightweight models, accurate iris recognition on commodity smartphones is feasible under controlled conditions, bringing this modality closer to practical deployment.", "AI": {"tldr": "\u63d0\u51faCUVIRIS\u53ef\u89c1\u5149\u8679\u819c\u6570\u636e\u96c6\u548cLightIrisNet\u8f7b\u91cf\u5206\u5272\u6a21\u578b\uff0c\u7ed3\u5408IrisFormer\u5339\u914d\u5668\uff0c\u5728\u667a\u80fd\u624b\u673a\u4e0a\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u53ef\u89c1\u5149\u8679\u819c\u8bc6\u522b\u3002", "motivation": "\u667a\u80fd\u624b\u673a\u53ef\u89c1\u5149\u8679\u819c\u8bc6\u522b\u9762\u4e34\u5149\u7167\u53d8\u5316\u3001\u8272\u7d20\u5f71\u54cd\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u91c7\u96c6\u534f\u8bae\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u4f4e\u6210\u672c\u3001\u53ef\u8bbf\u95ee\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u521b\u5efaCUVIRIS\u6570\u636e\u96c6\uff1a47\u4e2a\u53d7\u8bd5\u8005\u7684752\u5f20ISO/IEC 29794-6\u5408\u89c4\u8679\u819c\u56fe\u50cf\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49Android\u5e94\u7528\u5b9e\u65f6\u8bc4\u4f30\u8d28\u91cf\uff1b2) \u5f00\u53d1LightIrisNet\uff1a\u57fa\u4e8eMobileNetV3\u7684\u591a\u4efb\u52a1\u5206\u5272\u6a21\u578b\uff0c\u4f18\u5316\u8bbe\u5907\u7aef\u90e8\u7f72\uff1b3) \u9002\u914dIrisFormer\uff1a\u5c06transformer-based\u5339\u914d\u5668\u5e94\u7528\u4e8e\u53ef\u89c1\u5149\u57df\u3002", "result": "OSIRIS\u7cfb\u7edf\u5728CUVIRIS\u4e0a\u8fbe\u5230TAR=97.9% @ FAR=0.01 (EER=0.76%)\uff1bIrisFormer\u4ec5\u5728UBIRIS.v2\u8bad\u7ec3\uff0cEER\u8fbe0.057%\u3002\u5f00\u6e90Android\u5e94\u7528\u3001\u6a21\u578b\u548c\u90e8\u5206\u6570\u636e\u96c6\u3002", "conclusion": "\u901a\u8fc7\u6807\u51c6\u5316\u91c7\u96c6\u548c\u53ef\u89c1\u5149\u4f18\u5316\u7684\u8f7b\u91cf\u6a21\u578b\uff0c\u5728\u5546\u7528\u667a\u80fd\u624b\u673a\u4e0a\u5b9e\u73b0\u51c6\u786e\u8679\u819c\u8bc6\u522b\u662f\u53ef\u884c\u7684\uff0c\u4f7f\u8be5\u6a21\u6001\u66f4\u63a5\u8fd1\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2512.15283", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15283", "abs": "https://arxiv.org/abs/2512.15283", "authors": ["Colin Cros", "Laurent Ferro-Famil"], "title": "Moment-Matching Array Processing Technique for diffuse source estimation", "comment": null, "summary": "Direction of Arrival (DOA) estimation is a fundamental problem in signal processing. Diffuse sources, whose power density cannot be represented with a single angular coordinate, are usually characterized based on prior assumptions, which associate the source angular density with a specific set of functions. However, these assumptions can lead to significant estimation biases when they are incorrect. This paper introduces the Moment-Matching Estimation Technique (MoMET), a low-complexity method for estimating the mean DOA, spread, and power of a narrow diffuse source without requiring prior knowledge on the source distribution. The unknown source density is characterized by its mean DOA and its first central moments, which are estimated through covariance matching techniques which fit the empirical covariance of the measurements to that modeled from the moments. The MoMET parameterization is robust to incorrect model assumptions, and numerically efficient. The asymptotic bias and covariance of the new estimator are derived and its performance is demonstrated through simulations.", "AI": {"tldr": "\u63d0\u51faMoMET\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u9a8c\u5206\u5e03\u5047\u8bbe\u5373\u53ef\u4f30\u8ba1\u7a84\u5e26\u6269\u6563\u6e90\u7684\u5747\u503cDOA\u3001\u5c55\u5bbd\u548c\u529f\u7387", "motivation": "\u4f20\u7edfDOA\u4f30\u8ba1\u65b9\u6cd5\u5bf9\u6269\u6563\u6e90\u9700\u8981\u5148\u9a8c\u5206\u5e03\u5047\u8bbe\uff0c\u5f53\u5047\u8bbe\u9519\u8bef\u65f6\u4f1a\u5bfc\u81f4\u663e\u8457\u4f30\u8ba1\u504f\u5dee", "method": "\u4f7f\u7528\u77e9\u5339\u914d\u4f30\u8ba1\u6280\u672f\uff0c\u901a\u8fc7\u534f\u65b9\u5dee\u5339\u914d\u5c06\u6d4b\u91cf\u503c\u7684\u7ecf\u9a8c\u534f\u65b9\u5dee\u4e0e\u77e9\u5efa\u6a21\u7684\u534f\u65b9\u5dee\u62df\u5408\uff0c\u4f30\u8ba1\u5747\u503cDOA\u548c\u4e2d\u5fc3\u77e9", "result": "MoMET\u53c2\u6570\u5316\u5bf9\u9519\u8bef\u6a21\u578b\u5047\u8bbe\u5177\u6709\u9c81\u68d2\u6027\uff0c\u6570\u503c\u6548\u7387\u9ad8\uff0c\u63a8\u5bfc\u4e86\u4f30\u8ba1\u91cf\u7684\u6e10\u8fd1\u504f\u5dee\u548c\u534f\u65b9\u5dee", "conclusion": "MoMET\u662f\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u9a8c\u5206\u5e03\u77e5\u8bc6\u5373\u53ef\u51c6\u786e\u4f30\u8ba1\u6269\u6563\u6e90\u53c2\u6570\uff0c\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u6027\u80fd"}}
{"id": "2512.15681", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.15681", "abs": "https://arxiv.org/abs/2512.15681", "authors": ["Ines Faria", "Matheus Silva", "Crystian Saraiva", "Jose Soares", "Victor Alves"], "title": "Radiomics and Clinical Features in Predictive Modelling of Brain Metastases Recurrence", "comment": "14 pages, 6 figures, 3 tables", "summary": "Brain metastases affect approximately between 20% and 40% of cancer patients and are commonly treated with radiotherapy or radiosurgery. Early prediction of recurrence following treatment could enable timely clinical intervention and improve patient outcomes. This study proposes an artificial intelligence based approach for predicting brain metastasis recurrence using multimodal imaging and clinical data. A retrospective cohort of 97 patients was collected, including Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) acquired before treatment and at first follow-up, together with relevant clinical variables. Image preprocessing included CT windowing and artifact reduction, MRI enhancement, and multimodal CT MRI registration. After applying inclusion criteria, 53 patients were retained for analysis. Radiomics features were extracted from the imaging data, and delta radiomics was employed to characterize temporal changes between pre-treatment and follow-up scans. Multiple machine learning classifiers were trained and evaluated, including an analysis of discrepancies between treatment planning target volumes and delivered isodose volumes. Despite limitations related to sample size and class imbalance, the results demonstrate the feasibility of radiomics based models, namely ensemble models, for recurrence prediction and suggest a potential association between radiation dose discrepancies and recurrence risk. This work supports further investigation of AI-driven tools to assist clinical decision-making in brain metastasis management.", "AI": {"tldr": "\u57fa\u4e8e\u591a\u6a21\u6001\u5f71\u50cf\u548c\u4e34\u5e8a\u6570\u636e\uff0c\u4f7f\u7528AI\u65b9\u6cd5\u9884\u6d4b\u8111\u8f6c\u79fb\u7624\u653e\u7597\u540e\u590d\u53d1\uff0c\u901a\u8fc7\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b9e\u73b0\u9884\u6d4b\uff0c\u5e76\u53d1\u73b0\u653e\u7597\u5242\u91cf\u5dee\u5f02\u4e0e\u590d\u53d1\u98ce\u9669\u76f8\u5173\u3002", "motivation": "\u8111\u8f6c\u79fb\u7624\u5f71\u54cd20-40%\u7684\u764c\u75c7\u60a3\u8005\uff0c\u653e\u7597\u662f\u5e38\u7528\u6cbb\u7597\u65b9\u6cd5\u3002\u65e9\u671f\u9884\u6d4b\u590d\u53d1\u53ef\u4ee5\u53ca\u65f6\u5e72\u9884\u5e76\u6539\u5584\u60a3\u8005\u9884\u540e\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u9884\u6d4b\u5de5\u5177\u3002", "method": "\u6536\u96c697\u540d\u60a3\u8005\u7684\u591a\u6a21\u6001\u5f71\u50cf\uff08CT\u548cMRI\uff09\u53ca\u4e34\u5e8a\u6570\u636e\uff0c\u4fdd\u755953\u540d\u60a3\u8005\u8fdb\u884c\u5206\u6790\u3002\u8fdb\u884c\u56fe\u50cf\u9884\u5904\u7406\uff08CT\u7a97\u5bbd\u8c03\u6574\u3001\u4f2a\u5f71\u51cf\u5c11\u3001MRI\u589e\u5f3a\u3001\u591a\u6a21\u6001\u914d\u51c6\uff09\uff0c\u63d0\u53d6\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\uff0c\u4f7f\u7528delta\u653e\u5c04\u7ec4\u5b66\u5206\u6790\u6cbb\u7597\u524d\u540e\u53d8\u5316\u3002\u8bad\u7ec3\u591a\u79cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\uff0c\u5206\u6790\u6cbb\u7597\u8ba1\u5212\u9776\u533a\u4e0e\u5b9e\u9645\u7b49\u5242\u91cf\u4f53\u79ef\u7684\u5dee\u5f02\u3002", "result": "\u5c3d\u7ba1\u6837\u672c\u91cf\u6709\u9650\u4e14\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7ed3\u679c\u663e\u793a\u57fa\u4e8e\u653e\u5c04\u7ec4\u5b66\u7684\u96c6\u6210\u6a21\u578b\u80fd\u591f\u9884\u6d4b\u590d\u53d1\uff0c\u5e76\u53d1\u73b0\u653e\u7597\u5242\u91cf\u5dee\u5f02\u53ef\u80fd\u4e0e\u590d\u53d1\u98ce\u9669\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86AI\u9a71\u52a8\u5de5\u5177\u5728\u8111\u8f6c\u79fb\u7624\u7ba1\u7406\u4e2d\u8f85\u52a9\u4e34\u5e8a\u51b3\u7b56\u7684\u53ef\u884c\u6027\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u7684\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2512.15290", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15290", "abs": "https://arxiv.org/abs/2512.15290", "authors": ["Jie Zhou", "Junhao Xie"], "title": "On the Asymptotic Performance of Diagonally Loaded Detectors for Large Arrays: To Achieve CFAR and Optimality", "comment": null, "summary": "This paper addresses two critical limitations in diagonally loaded (DL) adaptive matched filter (AMF) detector: (1) the lack of CFAR property with respect to arbitrary covariance matrices, and (2) the absence of selection criteria for optimal loading factor from the perspective of maximizing the detection probability (Pd). We provide solutions to both challenges through a comprehensive analysis for the asymptotic performance of DL-AMF under large dimensional regime (LDR) where the dimension N and sample size K tend to infinity whereas their ratio N/K converges to a constant c\\in(0,1). The analytical results show that any DL detectors constructed by normalizing the random variable |a|2=|sH(R+\u03bbIN)-1y0|2 with a deterministic quantity or a random variable that converges almost surely to a deterministic value will exhibit equivalent performance under LDR. Following this idea, we derive two CFAR DL detectors: CFAR DL semi-clairvoyant matched filter (CFAR-DL-SCMF) detector and CFAR DL adaptive matched filter (CFAR-DL-AMF) detector, by normalizing |a|2 with an appropriate deterministic quantity and its consistent estimate, respectively. The theoretical analysis and simulations show that both CFAR-DL-SCMF and CFAR-DL-AMF achieve CFAR with respect to covariance matrix, target steering vector and loading factor. Furthermore, we derive the asymptotically optimal loading factor \u03bb_opt by maximizing the explicit expression of asymptotic Pd. For practical implementation, we provide a consistent estimator for \u03bb_opt under LDR. Based on \u03bb_opt and its consistent estimate, we establish the optimal CFAR-DL-SCMF (opt-CFAR-DL-SCMF) and the optimal CFAR-DL-AMF (opt-CFAR-DL-AMF). Numerical examples demonstrate that the proposed opt-CFAR-DL-SCMF and opt-CFAR-DL-AMF consistently outperform EL-AMF and persymmetric AMF in both full-rank and low-rank clutter plus noise environments.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u5177\u6709CFAR\u7279\u6027\u7684\u5bf9\u89d2\u52a0\u8f7d\u81ea\u9002\u5e94\u5339\u914d\u6ee4\u6ce2\u5668\u68c0\u6d4b\u5668\uff0c\u5e76\u63a8\u5bfc\u51fa\u6e10\u8fd1\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\uff0c\u5728\u591a\u79cd\u6742\u6ce2\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5bf9\u89d2\u52a0\u8f7dAMF\u68c0\u6d4b\u5668\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1) \u5bf9\u4efb\u610f\u534f\u65b9\u5dee\u77e9\u9635\u7f3a\u4e4fCFAR\u7279\u6027\uff1b2) \u4ece\u6700\u5927\u5316\u68c0\u6d4b\u6982\u7387\u89d2\u5ea6\u7f3a\u4e4f\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u9009\u62e9\u6807\u51c6\u3002", "method": "\u5728\u5927\u7ef4\u6e10\u8fd1\u6846\u67b6\u4e0b\u5206\u6790DL-AMF\u6027\u80fd\uff0c\u63d0\u51faCFAR-DL-SCMF\u548cCFAR-DL-AMF\u4e24\u79cd\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u9002\u5f53\u5f52\u4e00\u5316\u5b9e\u73b0CFAR\u7279\u6027\uff0c\u5e76\u63a8\u5bfc\u6e10\u8fd1\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u03bb_opt\u3002", "result": "\u6240\u63d0\u68c0\u6d4b\u5668\u5bf9\u534f\u65b9\u5dee\u77e9\u9635\u3001\u76ee\u6807\u5bfc\u5411\u5411\u91cf\u548c\u52a0\u8f7d\u56e0\u5b50\u5747\u5177\u6709CFAR\u7279\u6027\uff0copt-CFAR-DL-SCMF\u548copt-CFAR-DL-AMF\u5728\u5168\u79e9\u548c\u4f4e\u79e9\u6742\u6ce2\u52a0\u566a\u58f0\u73af\u5883\u4e2d\u5747\u4f18\u4e8eEL-AMF\u548cpersymmetric AMF\u3002", "conclusion": "\u901a\u8fc7\u5927\u7ef4\u6e10\u8fd1\u5206\u6790\u89e3\u51b3\u4e86DL-AMF\u7684CFAR\u548c\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u6700\u4f18CFAR\u68c0\u6d4b\u5668\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.15441", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15441", "abs": "https://arxiv.org/abs/2512.15441", "authors": ["Gilderlan Tavares de Ara\u00fajo", "Andr\u00e9 L. F. de Almeida Buno Sokal", "Gabor Fodor", "Paulo R. B. Gomes"], "title": "Semi-Blind Joint Channel and Symbol Estimation for Beyond Diagonal Reconfigurable Surfaces", "comment": null, "summary": "The beyond-diagonal reconfigurable intelligent surface (BD-RIS) is a recent architecture in which scattering elements are interconnected to enhance the degrees of freedom for wave control, yielding performance gains over traditional single-connected RISs. For BD-RIS, channel estimation - well-studied for conventional RIS - becomes more challenging due to the complex connections and a larger number of coefficients. Prior works rely on pilot-assisted estimation followed by data decoding. This paper introduces a semi-blind tensor-based approach for joint channel and symbol estimation that eliminates the need for training sequences by leveraging data symbols directly. A practical scenario with time-varying user terminal-RIS channels under mobility is considered. By reformulating the received signal from a tensor decomposition perspective, we develop two semi-blind receivers: a two-stage method transforming the fourth-order PARATUCK model into a third-order PARAFAC model, and a single-stage iterative process based on fourth-order TUCKER decomposition. Identifiability conditions for reliable joint recovery are derived, and numerical results demonstrate the performance advantages and trade-offs of the proposed schemes over existing solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u5206\u89e3\u7684\u534a\u76f2\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8eBD-RIS\u7cfb\u7edf\uff0c\u65e0\u9700\u8bad\u7ec3\u5e8f\u5217\uff0c\u901a\u8fc7\u6570\u636e\u7b26\u53f7\u76f4\u63a5\u8fdb\u884c\u8054\u5408\u4fe1\u9053\u548c\u7b26\u53f7\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edfBD-RIS\u4fe1\u9053\u4f30\u8ba1\u9762\u4e34\u6311\u6218\uff1a\u590d\u6742\u8fde\u63a5\u548c\u66f4\u591a\u7cfb\u6570\u4f7f\u5f97\u4fe1\u9053\u4f30\u8ba1\u66f4\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5bfc\u9891\u8f85\u52a9\u4f30\u8ba1\uff0c\u800c\u672c\u6587\u65e8\u5728\u6d88\u9664\u8bad\u7ec3\u5e8f\u5217\u9700\u6c42\uff0c\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u534a\u76f2\u63a5\u6536\u5668\uff1a1) \u4e24\u9636\u6bb5\u65b9\u6cd5\u5c06\u56db\u9636PARATUCK\u6a21\u578b\u8f6c\u5316\u4e3a\u4e09\u9636PARAFAC\u6a21\u578b\uff1b2) \u5355\u9636\u6bb5\u8fed\u4ee3\u65b9\u6cd5\u57fa\u4e8e\u56db\u9636TUCKER\u5206\u89e3\u3002\u8003\u8651\u79fb\u52a8\u6027\u4e0b\u65f6\u53d8\u7528\u6237\u7ec8\u7aef-RIS\u4fe1\u9053\u7684\u5b9e\u9645\u573a\u666f\u3002", "result": "\u63a8\u5bfc\u4e86\u53ef\u9760\u8054\u5408\u6062\u590d\u7684\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\uff0c\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6848\u76f8\u6bd4\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5177\u6709\u6027\u80fd\u4f18\u52bf\u548c\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u534a\u76f2\u5f20\u91cf\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3BD-RIS\u7cfb\u7edf\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u6311\u6218\uff0c\u65e0\u9700\u8bad\u7ec3\u5e8f\u5217\uff0c\u5728\u79fb\u52a8\u573a\u666f\u4e0b\u5b9e\u73b0\u8054\u5408\u4fe1\u9053\u548c\u7b26\u53f7\u4f30\u8ba1\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15546", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15546", "abs": "https://arxiv.org/abs/2512.15546", "authors": ["Heedong Do", "Angel Lozano"], "title": "Optimum Discrete Beamforming via Minkowski Sum of Polygons", "comment": null, "summary": "This letter casts the problem of optimum discrete beamforming as the computation of the Minkowski sum of convex polygons, which is itself a convex polygon. The number of vertices of the latter is at most the sum of the number of vertices of the original polygons, enabling its efficient computation. This original and intuitive formulation confirms that the optimum beamforming solution can be found efficiently.", "AI": {"tldr": "\u5c06\u6700\u4f18\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u591a\u8fb9\u5f62Minkowski\u548c\u8ba1\u7b97\uff0c\u8bc1\u660e\u8be5\u95ee\u9898\u53ef\u9ad8\u6548\u6c42\u89e3", "motivation": "\u89e3\u51b3\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u7684\u6700\u4f18\u89e3\u8ba1\u7b97\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u8ba1\u7b97\u590d\u6742\uff0c\u9700\u8981\u66f4\u76f4\u89c2\u9ad8\u6548\u7684\u65b9\u6cd5", "method": "\u5c06\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u51f8\u591a\u8fb9\u5f62\u7684Minkowski\u548c\u8ba1\u7b97\uff0c\u5229\u7528\u51f8\u591a\u8fb9\u5f62Minkowski\u548c\u7684\u6027\u8d28\uff08\u7ed3\u679c\u4ecd\u4e3a\u51f8\u591a\u8fb9\u5f62\uff0c\u9876\u70b9\u6570\u6700\u591a\u4e3a\u539f\u591a\u8fb9\u5f62\u9876\u70b9\u6570\u4e4b\u548c\uff09", "result": "\u8bc1\u660e\u6700\u4f18\u6ce2\u675f\u6210\u5f62\u89e3\u53ef\u4ee5\u901a\u8fc7\u9ad8\u6548\u8ba1\u7b97Minkowski\u548c\u5f97\u5230\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u63a7", "conclusion": "\u901a\u8fc7\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u591a\u8fb9\u5f62Minkowski\u548c\u8ba1\u7b97\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u59cb\u4e14\u76f4\u89c2\u7684\u8868\u8ff0\uff0c\u786e\u8ba4\u4e86\u6700\u4f18\u6ce2\u675f\u6210\u5f62\u89e3\u53ef\u4ee5\u9ad8\u6548\u627e\u5230"}}
{"id": "2512.15558", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.15558", "abs": "https://arxiv.org/abs/2512.15558", "authors": ["Nadia Abdolkhani", "Nada Abdel Khalek", "Walaa Hamouda"], "title": "Deep Reinforcement Learning for EH-Enabled Cognitive-IoT Under Jamming Attacks", "comment": "Published in IEEE Internet of Things Journal. This arXiv version is the authors' accepted manuscript", "summary": "In the evolving landscape of the Internet of Things (IoT), integrating cognitive radio (CR) has become a practical solution to address the challenge of spectrum scarcity, leading to the development of cognitive IoT (CIoT). However, the vulnerability of radio communications makes radio jamming attacks a key concern in CIoT networks. In this paper, we introduce a novel deep reinforcement learning (DRL) approach designed to optimize throughput and extend network lifetime of an energy-constrained CIoT system under jamming attacks. This DRL framework equips a CIoT device with the autonomy to manage energy harvesting (EH) and data transmission, while also regulating its transmit power to respect spectrum-sharing constraints. We formulate the optimization problem under various constraints, and we model the CIoT device's interactions within the channel as a model-free Markov decision process (MDP). The MDP serves as a foundation to develop a double deep Q-network (DDQN), designed to help the CIoT agent learn the optimal communication policy to navigate challenges such as dynamic channel occupancy, jamming attacks, and channel fading while achieving its goal. Additionally, we introduce a variant of the upper confidence bound (UCB) algorithm, named UCB-IA, which enhances the CIoT network's ability to efficiently navigate jamming attacks within the channel. The proposed DRL algorithm does not rely on prior knowledge and uses locally observable information such as channel occupancy, jamming activity, channel gain, and energy arrival to make decisions. Extensive simulations prove that our proposed DRL algorithm that utilizes the UCB-IA strategy surpasses existing benchmarks, allowing for a more adaptive, energy-efficient, and secure spectrum sharing in CIoT networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8ba4\u77e5\u7269\u8054\u7f51\u6297\u5e72\u6270\u901a\u4fe1\u7b56\u7565\uff0c\u4f18\u5316\u541e\u5410\u91cf\u548c\u7f51\u7edc\u5bff\u547d", "motivation": "\u8ba4\u77e5\u7269\u8054\u7f51\u9762\u4e34\u9891\u8c31\u7a00\u7f3a\u548c\u65e0\u7ebf\u7535\u5e72\u6270\u653b\u51fb\u7684\u6311\u6218\uff0c\u9700\u8981\u667a\u80fd\u7684\u901a\u4fe1\u7b56\u7565\u6765\u4fdd\u969c\u7f51\u7edc\u6027\u80fd\u548c\u5b89\u5168", "method": "\u91c7\u7528\u65e0\u6a21\u578b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\uff0c\u5f00\u53d1\u53cc\u6df1\u5ea6Q\u7f51\u7edc\u548cUCB-IA\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5c40\u90e8\u53ef\u89c2\u6d4b\u4fe1\u606f\u8fdb\u884c\u51b3\u7b56", "result": "\u63d0\u51fa\u7684DRL\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u5b9e\u73b0\u66f4\u81ea\u9002\u5e94\u3001\u8282\u80fd\u548c\u5b89\u5168\u7684\u9891\u8c31\u5171\u4eab", "conclusion": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u8ba4\u77e5\u7269\u8054\u7f51\u4e2d\u7684\u5e72\u6270\u653b\u51fb\uff0c\u4f18\u5316\u7f51\u7edc\u6027\u80fd"}}
