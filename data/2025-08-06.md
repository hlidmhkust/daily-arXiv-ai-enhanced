<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 11]
- [cs.IT](#cs.IT) [Total: 7]
- [eess.SP](#eess.SP) [Total: 28]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves](https://arxiv.org/abs/2508.02726)
*Lucio Pinello,Francesco Cadini,Luca Lomazzi*

Main category: eess.IV

TL;DR: 提出了一种基于MPCA的迁移学习框架，用于解决超声导波在结构健康监测中的数据稀缺和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 超声导波与机器学习结合在结构健康监测中具有潜力，但数据稀缺和泛化能力限制了其大规模应用。

Method: 结合MPCA和微调技术，通过提取共享潜在特征实现跨域适应，无需大量训练数据。

Result: 在12个案例中验证，显著降低了定位误差，优于传统迁移学习方法。

Conclusion: 该方法为超声导波监测提供了高效、稳健的迁移学习框架。

Abstract: Ultrasonic Guided Waves (UGWs) represent a promising diagnostic tool for
Structural Health Monitoring (SHM) in thin-walled structures, and their
integration with machine learning (ML) algorithms is increasingly being adopted
to enable real-time monitoring capabilities. However, the large-scale
deployment of UGW-based ML methods is constrained by data scarcity and limited
generalisation across different materials and sensor configurations. To address
these limitations, this work proposes a novel transfer learning (TL) framework
based on Multilinear Principal Component Analysis (MPCA). First, a
Convolutional Neural Network (CNN) for regression is trained to perform damage
localisation for a plated structure. Then, MPCA and fine-tuning are combined to
have the CNN work for a different plate. By jointly applying MPCA to the source
and target domains, the method extracts shared latent features, enabling
effective domain adaptation without requiring prior assumptions about
dimensionality. Following MPCA, fine-tuning enables adapting the pre-trained
CNN to a new domain without the need for a large training dataset. The proposed
MPCA-based TL method was tested against 12 case studies involving different
composite materials and sensor arrays. Statistical metrics were used to assess
domains alignment both before and after MPCA, and the results demonstrate a
substantial reduction in localisation error compared to standard TL techniques.
Hence, the proposed approach emerges as a robust, data-efficient, and
statistically based TL framework for UGW-based SHM.

</details>


### [2] [Spatial-Temporal-Spectral Mamba with Sparse Deformable Token Sequence for Enhanced MODIS Time Series Classification](https://arxiv.org/abs/2508.02839)
*Zack Dewis,Zhengsen Xu,Yimin Zhu,Motasem Alkayid,Mabel Heffring,Lincoln Linlin Xu*

Main category: eess.IV

TL;DR: 提出了一种名为STSMamba的新方法，通过解耦时空光谱特征和改进Mamba序列，提升了MODIS时间序列数据的分类精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: MODIS时间序列数据在动态大尺度土地利用分类中至关重要，但由于高时间维度、混合像素和时空光谱耦合效应等问题，捕捉细微类别信息具有挑战性。

Method: 设计了TGS模块解耦时空光谱特征，提出SDMS方法优化Mamba序列，并构建了包含SDSpaM、SDSpeM和SDTM模块的STSMamba架构。

Result: 实验表明，该方法在MODIS时间序列数据上比现有方法具有更高的分类精度和更低的计算复杂度。

Conclusion: STSMamba通过创新的模块设计和序列优化，显著提升了MODIS时间序列分类的性能。

Abstract: Although MODIS time series data are critical for supporting dynamic,
large-scale land cover land use classification, it is a challenging task to
capture the subtle class signature information due to key MODIS difficulties,
e.g., high temporal dimensionality, mixed pixels, and spatial-temporal-spectral
coupling effect. This paper presents a novel spatial-temporal-spectral Mamba
(STSMamba) with deformable token sequence for enhanced MODIS time series
classification, with the following key contributions. First, to disentangle
temporal-spectral feature coupling, a temporal grouped stem (TGS) module is
designed for initial feature learning. Second, to improve Mamba modeling
efficiency and accuracy, a sparse, deformable Mamba sequencing (SDMS) approach
is designed, which can reduce the potential information redundancy in Mamba
sequence and improve the adaptability and learnability of the Mamba sequencing.
Third, based on SDMS, to improve feature learning, a novel
spatial-temporal-spectral Mamba architecture is designed, leading to three
modules, i.e., a sparse deformable spatial Mamba module (SDSpaM), a sparse
deformable spectral Mamba module (SDSpeM), and a sparse deformable temporal
Mamba module (SDTM) to explicitly learn key information sources in MODIS. The
proposed approach is tested on MODIS time series data in comparison with many
state-of-the-art approaches, and the results demonstrate that the proposed
approach can achieve higher classification accuracy with reduced computational
complexity.

</details>


### [3] [Evaluation of 3D Counterfactual Brain MRI Generation](https://arxiv.org/abs/2508.02880)
*Pengwei Sun,Wei Peng,Lun Yu Li,Yixin Wang,Kilian M. Pohl*

Main category: eess.IV

TL;DR: 该论文提出了一种基于因果图的解剖引导框架，将六种生成模型转化为3D反事实方法，用于生成脑部MRI图像，并评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决生成真实且符合解剖和因果约束的3D脑部MRI图像的挑战，以理解疾病机制和生成生理上合理的数据。

Method: 通过将六种生成模型结合解剖引导框架（基于因果图），以区域脑体积作为直接条件输入，生成3D反事实脑部MRI图像。

Result: 解剖引导的条件化成功修改了目标解剖区域，但在保留非目标结构方面存在局限性。

Conclusion: 该研究为更可解释和临床相关的脑部MRI生成建模奠定了基础，同时指出需要新架构以更准确地捕捉解剖依赖关系。

Abstract: Counterfactual generation offers a principled framework for simulating
hypothetical changes in medical imaging, with potential applications in
understanding disease mechanisms and generating physiologically plausible data.
However, generating realistic structural 3D brain MRIs that respect anatomical
and causal constraints remains challenging due to data scarcity, structural
complexity, and the lack of standardized evaluation protocols. In this work, we
convert six generative models into 3D counterfactual approaches by
incorporating an anatomy-guided framework based on a causal graph, in which
regional brain volumes serve as direct conditioning inputs. Each model is
evaluated with respect to composition, reversibility, realism, effectiveness
and minimality on T1-weighted brain MRIs (T1w MRIs) from the Alzheimer's
Disease Neuroimaging Initiative (ADNI). In addition, we test the
generalizability of each model with respect to T1w MRIs of the National
Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA). Our results
indicate that anatomically grounded conditioning successfully modifies the
targeted anatomical regions; however, it exhibits limitations in preserving
non-targeted structures. Beyond laying the groundwork for more interpretable
and clinically relevant generative modeling of brain MRIs, this benchmark
highlights the need for novel architectures that more accurately capture
anatomical interdependencies.

</details>


### [4] [REFLECT: Rectified Flows for Efficient Brain Anomaly Correction Transport](https://arxiv.org/abs/2508.02889)
*Farzad Beizaee,Sina Hajimiri,Ismail Ben Ayed,Gregory Lodygensky,Christian Desrosiers,Jose Dolz*

Main category: eess.IV

TL;DR: REFLECT是一种基于整流流的无监督异常检测框架，用于脑成像中的异常定位，通过单步推理显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 脑成像中的无监督异常检测（UAD）需要解决异常定位的挑战，尤其是在缺乏标记数据和复杂脑结构的情况下。

Method: REFLECT利用整流流建立直接、线性的轨迹，将异常MR图像校正到正常分布，通过单步推理实现高效异常定位。

Result: 在多个UAD脑分割基准测试中，REFLECT显著优于现有无监督异常检测方法。

Conclusion: REFLECT通过整流流实现了高效的单步异常校正和定位，为无监督脑成像异常检测提供了新思路。

Abstract: Unsupervised anomaly detection (UAD) in brain imaging is crucial for
identifying pathologies without the need for labeled data. However, accurately
localizing anomalies remains challenging due to the intricate structure of
brain anatomy and the scarcity of abnormal examples. In this work, we introduce
REFLECT, a novel framework that leverages rectified flows to establish a
direct, linear trajectory for correcting abnormal MR images toward a normal
distribution. By learning a straight, one-step correction transport map, our
method efficiently corrects brain anomalies and can precisely localize
anomalies by detecting discrepancies between anomalous input and corrected
counterpart. In contrast to the diffusion-based UAD models, which require
iterative stochastic sampling, rectified flows provide a direct transport map,
enabling single-step inference. Extensive experiments on popular UAD brain
segmentation benchmarks demonstrate that REFLECT significantly outperforms
state-of-the-art unsupervised anomaly detection methods. The code is available
at https://github.com/farzad-bz/REFLECT.

</details>


### [5] [AMD-Mamba: A Phenotype-Aware Multi-Modal Framework for Robust AMD Prognosis](https://arxiv.org/abs/2508.02957)
*Puzhen Wu,Mingquan Lin,Qingyu Chen,Emily Y. Chew,Zhiyong Lu,Yifan Peng,Hexin Dong*

Main category: eess.IV

TL;DR: AMD-Mamba是一种新型多模态框架，用于AMD预后，结合眼底图像、遗传变异和社会人口学变量，通过创新的度量学习策略和Vision Mamba技术提升预后能力。


<details>
  <summary>Details</summary>
Motivation: AMD是导致不可逆视力丧失的主要原因，需要有效的预后方法以进行及时干预。

Method: 提出AMD-Mamba框架，整合多模态数据，采用度量学习策略和Vision Mamba技术，结合局部和全局信息。

Result: 在AREDS数据集上验证，提出的生物标志物显著提升了AMD进展预测能力。

Conclusion: AMD-Mamba框架有望为AMD的精准管理提供新工具。

Abstract: Age-related macular degeneration (AMD) is a leading cause of irreversible
vision loss, making effective prognosis crucial for timely intervention. In
this work, we propose AMD-Mamba, a novel multi-modal framework for AMD
prognosis, and further develop a new AMD biomarker. This framework integrates
color fundus images with genetic variants and socio-demographic variables. At
its core, AMD-Mamba introduces an innovative metric learning strategy that
leverages AMD severity scale score as prior knowledge. This strategy allows the
model to learn richer feature representations by aligning learned features with
clinical phenotypes, thereby improving the capability of conventional prognosis
methods in capturing disease progression patterns. In addition, unlike existing
models that use traditional CNN backbones and focus primarily on local
information, such as the presence of drusen, AMD-Mamba applies Vision Mamba and
simultaneously fuses local and long-range global information, such as vascular
changes. Furthermore, we enhance prediction performance through multi-scale
fusion, combining image information with clinical variables at different
resolutions. We evaluate AMD-Mamba on the AREDS dataset, which includes 45,818
color fundus photographs, 52 genetic variants, and 3 socio-demographic
variables from 2,741 subjects. Our experimental results demonstrate that our
proposed biomarker is one of the most significant biomarkers for the
progression of AMD. Notably, combining this biomarker with other existing
variables yields promising improvements in detecting high-risk AMD patients at
early stages. These findings highlight the potential of our multi-modal
framework to facilitate more precise and proactive management of AMD.

</details>


### [6] [ClinicalFMamba: Advancing Clinical Assessment using Mamba-based Multimodal Neuroimaging Fusion](https://arxiv.org/abs/2508.03008)
*Meng Zhou,Farzad Khalvati*

Main category: eess.IV

TL;DR: 论文提出了一种名为ClinicalFMamba的新型混合架构，结合CNN和Mamba模型，用于2D和3D医学图像融合，解决了现有方法在全局上下文建模和计算效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 多模态医学图像融合能提升诊断和治疗规划的准确性，但现有深度学习方法在全局建模和计算效率上存在局限。

Method: 提出CNN-Mamba混合架构ClinicalFMamba，结合局部和全局特征建模，并设计三平面扫描策略处理3D数据。

Result: 在三个数据集上表现优异，支持实时融合，并在脑肿瘤分类任务中超越基线方法。

Conclusion: ClinicalFMamba为高效多模态医学图像融合提供了新范式，适合临床实时部署。

Abstract: Multimodal medical image fusion integrates complementary information from
different imaging modalities to enhance diagnostic accuracy and treatment
planning. While deep learning methods have advanced performance, existing
approaches face critical limitations: Convolutional Neural Networks (CNNs)
excel at local feature extraction but struggle to model global context
effectively, while Transformers achieve superior long-range modeling at the
cost of quadratic computational complexity, limiting clinical deployment.
Recent State Space Models (SSMs) offer a promising alternative, enabling
efficient long-range dependency modeling in linear time through selective scan
mechanisms. Despite these advances, the extension to 3D volumetric data and the
clinical validation of fused images remains underexplored. In this work, we
propose ClinicalFMamba, a novel end-to-end CNN-Mamba hybrid architecture that
synergistically combines local and global feature modeling for 2D and 3D
images. We further design a tri-plane scanning strategy for effectively
learning volumetric dependencies in 3D images. Comprehensive evaluations on
three datasets demonstrate the superior fusion performance across multiple
quantitative metrics while achieving real-time fusion. We further validate the
clinical utility of our approach on downstream 2D/3D brain tumor classification
tasks, achieving superior performance over baseline methods. Our method
establishes a new paradigm for efficient multimodal medical image fusion
suitable for real-time clinical deployment.

</details>


### [7] [A Survey of Medical Point Cloud Shape Learning: Registration, Reconstruction and Variation](https://arxiv.org/abs/2508.03057)
*Tongxu Zhang,Zhiming Liang,Bei Wang*

Main category: eess.IV

TL;DR: 本文综述了基于点云的医学形状分析，涵盖配准、重建和变异建模三大任务，总结了2021-2025年的代表性方法、数据集和评估指标，并探讨了临床应用的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 点云在3D医学成像中成为重要表示方法，深度学习的发展推动了直接从点云数据中提取、建模和分析解剖形状的进展。本文旨在系统综述相关研究。

Method: 综述了2021-2025年的文献，总结了代表性方法、数据集和评估指标，重点关注配准、重建和变异建模三大任务。

Result: 关键趋势包括混合表示、大规模自监督模型和生成技术的整合，但也面临数据稀缺、患者间变异性和临床部署需求等挑战。

Conclusion: 未来方向包括推进点云形状学习在医学成像中的应用，解决数据稀缺和临床部署的挑战。

Abstract: Point clouds have become an increasingly important representation for 3D
medical imaging, offering a compact, surface-preserving alternative to
traditional voxel or mesh-based approaches. Recent advances in deep learning
have enabled rapid progress in extracting, modeling, and analyzing anatomical
shapes directly from point cloud data. This paper provides a comprehensive and
systematic survey of learning-based shape analysis for medical point clouds,
focusing on three fundamental tasks: registration, reconstruction, and
variation modeling. We review recent literature from 2021 to 2025, summarize
representative methods, datasets, and evaluation metrics, and highlight
clinical applications and unique challenges in the medical domain. Key trends
include the integration of hybrid representations, large-scale self-supervised
models, and generative techniques. We also discuss current limitations, such as
data scarcity, inter-patient variability, and the need for interpretable and
robust solutions for clinical deployment. Finally, future directions are
outlined for advancing point cloud-based shape learning in medical imaging.

</details>


### [8] [Nexus-INR: Diverse Knowledge-guided Arbitrary-Scale Multimodal Medical Image Super-Resolution](https://arxiv.org/abs/2508.03073)
*Bo Zhang,JianFei Huo,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang*

Main category: eess.IV

TL;DR: Nexus-INR提出了一种基于多样化知识引导的任意分辨率超分辨率框架，通过多模态图像处理和下游任务提升医学图像超分辨率质量。


<details>
  <summary>Details</summary>
Motivation: 传统CNN方法无法适应任意分辨率超分辨率需求，而现有INR方法在多模态图像处理上仍有不足。

Method: Nexus-INR包含双分支编码器、知识蒸馏模块和集成分割模块，结合解剖结构和模态特征。

Result: 在BraTS2020数据集上，Nexus-INR在超分辨率和分割任务中均优于现有方法。

Conclusion: Nexus-INR通过多样化知识引导和下游任务嵌入，显著提升了医学图像超分辨率和分割性能。

Abstract: Arbitrary-resolution super-resolution (ARSR) provides crucial flexibility for
medical image analysis by adapting to diverse spatial resolutions. However,
traditional CNN-based methods are inherently ill-suited for ARSR, as they are
typically designed for fixed upsampling factors. While INR-based methods
overcome this limitation, they still struggle to effectively process and
leverage multi-modal images with varying resolutions and details. In this
paper, we propose Nexus-INR, a Diverse Knowledge-guided ARSR framework, which
employs varied information and downstream tasks to achieve high-quality,
adaptive-resolution medical image super-resolution. Specifically, Nexus-INR
contains three key components. A dual-branch encoder with an auxiliary
classification task to effectively disentangle shared anatomical structures and
modality-specific features; a knowledge distillation module using cross-modal
attention that guides low-resolution modality reconstruction with
high-resolution reference, enhanced by self-supervised consistency loss; an
integrated segmentation module that embeds anatomical semantics to improve both
reconstruction quality and downstream segmentation performance. Experiments on
the BraTS2020 dataset for both super-resolution and downstream segmentation
demonstrate that Nexus-INR outperforms state-of-the-art methods across various
metrics.

</details>


### [9] [GL-LCM: Global-Local Latent Consistency Models for Fast High-Resolution Bone Suppression in Chest X-Ray Images](https://arxiv.org/abs/2508.03357)
*Yifei Sun,Zhanghao Chen,Hao Zheng,Yuqing Lu,Lixin Duan,Fenglei Fan,Ahmed Elazab,Xiang Wan,Changmiao Wang,Ruiquan Ge*

Main category: eess.IV

TL;DR: 提出了一种名为GL-LCM的模型，用于快速高效地抑制CXR图像中的骨骼结构，同时保留局部纹理细节，显著提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: CXR成像中骨骼结构会遮挡关键细节，影响诊断准确性。现有扩散模型在骨骼抑制和细节保留之间存在平衡问题，且计算成本高。

Method: 采用Global-Local Latent Consistency Model（GL-LCM），结合肺部分割、双路径采样和全局-局部融合，并引入局部增强引导以减少边界伪影和细节模糊。

Result: 在SZCH-X-Rays和JSRT数据集上的实验表明，GL-LCM在骨骼抑制和计算效率上显著优于现有方法。

Conclusion: GL-LCM为CXR图像骨骼抑制提供了一种高效且高质量的解决方案，具有临床应用的潜力。

Abstract: Chest X-Ray (CXR) imaging for pulmonary diagnosis raises significant
challenges, primarily because bone structures can obscure critical details
necessary for accurate diagnosis. Recent advances in deep learning,
particularly with diffusion models, offer significant promise for effectively
minimizing the visibility of bone structures in CXR images, thereby improving
clarity and diagnostic accuracy. Nevertheless, existing diffusion-based methods
for bone suppression in CXR imaging struggle to balance the complete
suppression of bones with preserving local texture details. Additionally, their
high computational demand and extended processing time hinder their practical
use in clinical settings. To address these limitations, we introduce a
Global-Local Latent Consistency Model (GL-LCM) architecture. This model
combines lung segmentation, dual-path sampling, and global-local fusion,
enabling fast high-resolution bone suppression in CXR images. To tackle
potential boundary artifacts and detail blurring in local-path sampling, we
further propose Local-Enhanced Guidance, which addresses these issues without
additional training. Comprehensive experiments on a self-collected dataset
SZCH-X-Rays, and the public dataset JSRT, reveal that our GL-LCM delivers
superior bone suppression and remarkable computational efficiency,
significantly outperforming several competitive methods. Our code is available
at https://github.com/diaoquesang/GL-LCM.

</details>


### [10] [Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy](https://arxiv.org/abs/2508.03461)
*Gideon N. L. Rouwendaal,Daniël Boeke,Inge L. Cox,Henk G. van der Poel,Margriet C. van Dijk-de Haan,Regina G. H. Beets-Tan,Thierry N. Boellaard,Wilson Silva*

Main category: eess.IV

TL;DR: MRI在预测前列腺切除术后勃起功能障碍（ED）中的附加价值有限，临床特征仍是主要预测因素。


<details>
  <summary>Details</summary>
Motivation: 探讨术前MRI是否能为12个月后ED预测提供额外价值，超越现有的临床特征预测方法。

Method: 评估了四种建模策略：仅临床特征、基于MRI手工特征、深度学习MRI切片、多模态融合。

Result: MRI模型（AUC 0.569）略优于手工特征（AUC 0.554），但不及临床基线（AUC 0.663）。多模态融合略有提升（AUC 0.586），但未超越临床模型。

Conclusion: MRI模型未能超越临床特征，但可能通过捕捉相关解剖结构模式，为未来多模态方法提供补充。

Abstract: Accurate preoperative prediction of erectile dysfunction (ED) is important
for counseling patients undergoing radical prostatectomy. While clinical
features are established predictors, the added value of preoperative MRI
remains underexplored. We investigate whether MRI provides additional
predictive value for ED at 12 months post-surgery, evaluating four modeling
strategies: (1) a clinical-only baseline, representing current
state-of-the-art; (2) classical models using handcrafted anatomical features
derived from MRI; (3) deep learning models trained directly on MRI slices; and
(4) multimodal fusion of imaging and clinical inputs. Imaging-based models
(maximum AUC 0.569) slightly outperformed handcrafted anatomical approaches
(AUC 0.554) but fell short of the clinical baseline (AUC 0.663). Fusion models
offered marginal gains (AUC 0.586) but did not exceed clinical-only
performance. SHAP analysis confirmed that clinical features contributed most to
predictive performance. Saliency maps from the best-performing imaging model
suggested a predominant focus on anatomically plausible regions, such as the
prostate and neurovascular bundles. While MRI-based models did not improve
predictive performance over clinical features, our findings suggest that they
try to capture patterns in relevant anatomical structures and may complement
clinical predictors in future multimodal approaches.

</details>


### [11] [CADD: Context aware disease deviations via restoration of brain images using normative conditional diffusion models](https://arxiv.org/abs/2508.03594)
*Ana Lawry Aguila,Ayodeji Ijishakin,Juan Eugenio Iglesias,Tomomi Takenaga,Yukihiro Nomura,Takeharu Yoshikawa,Osamu Abe,Shouhei Hanaoka*

Main category: eess.IV

TL;DR: CADD是一种基于条件扩散模型的3D图像规范建模方法，通过结合临床信息优化异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在医学图像异常检测中缺乏临床信息引导和健康区域恢复不佳的问题。

Method: 提出条件扩散模型CADD，结合临床信息，并采用新颖的推理修复策略平衡异常去除与保留个体特征。

Result: 在三个具有挑战性的数据集上，CADD在检测神经异常方面达到最先进性能。

Conclusion: CADD通过结合临床信息和优化恢复策略，显著提升了异质性队列中的疾病检测效果。

Abstract: Applying machine learning to real-world medical data, e.g. from hospital
archives, has the potential to revolutionize disease detection in brain images.
However, detecting pathology in such heterogeneous cohorts is a difficult
challenge. Normative modeling, a form of unsupervised anomaly detection, offers
a promising approach to studying such cohorts where the ``normal'' behavior is
modeled and can be used at subject level to detect deviations relating to
disease pathology. Diffusion models have emerged as powerful tools for anomaly
detection due to their ability to capture complex data distributions and
generate high-quality images. Their performance relies on image restoration;
differences between the original and restored images highlight potential
abnormalities. However, unlike normative models, these diffusion model
approaches do not incorporate clinical information which provides important
context to guide the disease detection process. Furthermore, standard
approaches often poorly restore healthy regions, resulting in poor
reconstructions and suboptimal detection performance. We present CADD, the
first conditional diffusion model for normative modeling in 3D images. To guide
the healthy restoration process, we propose a novel inference inpainting
strategy which balances anomaly removal with retention of subject-specific
features. Evaluated on three challenging datasets, including clinical scans,
which may have lower contrast, thicker slices, and motion artifacts, CADD
achieves state-of-the-art performance in detecting neurological abnormalities
in heterogeneous cohorts.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [12] [Exponential convergence rate for Iterative Markovian Fitting](https://arxiv.org/abs/2508.02770)
*Kirill Sokolov,Alexander Korotin*

Main category: cs.IT

TL;DR: 本文首次证明了离散时间Schrödinger桥问题中IMF算法的指数收敛性，并给出了明确的收缩因子。


<details>
  <summary>Details</summary>
Motivation: 研究IMF算法在有限状态空间上的收敛速度，填补了之前未量化收敛速度的空白。

Method: 使用离散时间Schrödinger桥问题模型，分析IMF算法的收敛性。

Result: 证明了IMF算法具有指数收敛性，并给出了明确的收缩因子。

Conclusion: IMF算法在离散时间Schrödinger桥问题中具有高效的收敛性能。

Abstract: We consider the discrete-time Schr\"odinger bridge problem on a finite state
space. Although it has been known that the Iterative Markovian Fitting (IMF)
algorithm converges in Kullback-Leibler divergence to the ground truth
solution, the speed of that convergence remained unquantified. In this work, we
establish for the first time that IMF exhibits exponential convergence with an
explicit contraction factor.

</details>


### [13] [Distributed Source Coding for Compressing Vector-Linear Functions](https://arxiv.org/abs/2508.02996)
*Xuan Guang,Xiufang Sun,Ruze Zhang*

Main category: cs.IT

TL;DR: 论文研究了分布式源编码模型中向量线性函数的压缩问题，提出了功能压缩容量的通用下界，并针对特定模型分类矩阵T，证明了部分情况下下界的紧性。


<details>
  <summary>Details</summary>
Motivation: 受移动卫星通信系统和计算任务应用的启发，研究如何高效压缩向量线性函数以提升系统效率。

Method: 提出通用下界，分类矩阵T为T1和T2两类，通过上下界分析编码函数图像集大小，明确功能压缩容量。

Result: 证明了通用下界在T1和部分T2模型中的紧性，并解决了网络函数计算中的一个开放问题。

Conclusion: 研究为功能压缩容量提供了理论支持，并验证了已知上界的渐进紧性。

Abstract: Inspired by mobile satellite communication systems and the important and
prevalent applications of computational tasks, we consider a distributed source
coding model for compressing vector-linear functions, which consists of
multiple sources, multiple encoders and a decoder linked to all the encoders.
Each encoder has access to a certain subset of the sources and the decoder is
required to compute with zero error a vector-linear function of the source
information, which corresponds to a matrix $T$. The connectivity state between
the sources and the encoders and the vector-linear function are all arbitrary.
In the paper, we are interested in the function-compression capacity to measure
the efficiency of using the system. We first present a general lower bound on
the function-compression capacity applicable to arbitrary connectivity states
and vector-linear functions. Next, we confine to the nontrivial models with
only three sources and no more than three encoders, and prove that all the
$3\times2$ column-full-rank matrices $T$ can be divided into two types $T_1$
and $T_2$, for which the function-compression capacities are identical if the
matrices $T$ have the same type. We explicitly characterize the
function-compression capacities for two most nontrivial models associated with
$T_2$ by a novel approach of both upper bounding and lower bounding the size of
image sets of encoding functions. This shows that the lower bound thus obtained
is not always tight. Rather, by completely characterizing their capacities, the
lower bound is tight for all the models associated with $T_1$ and all the
models associated with $T_2$ except for the two most nontrivial models. We
finally apply the obtained results to network function computation and answer
the open problem whether the best known upper bound proved by Guang et. al.
(2019) on computing capacity is in general asymptotically tight.

</details>


### [14] [Multilevel inserting constructions for constant dimension subspace codes](https://arxiv.org/abs/2508.03196)
*Gang Wang,Xuan Gao,Sihem Mesnager,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 本文提出了一种基于逆双边多级构造的恒定维度子空间码（CDC）构建方法，通过引入逆双边识别向量和逆双边Ferrers图秩度量码，并结合多级构造，实现了CDC的高效构建。此外，通过新的双边识别向量集，提供了另一种高效构建方法。实验结果表明，新构建的CDC在规模上优于现有文献中的结果，且在某些情况下，新下界与已知上界的比率超过0.94548。


<details>
  <summary>Details</summary>
Motivation: 恒定维度子空间码（CDC）在随机网络编码中有广泛应用，但现有构建方法在规模和效率上存在局限。本文旨在通过新的构造方法提升CDC的性能。

Method: 引入逆双边识别向量和逆双边Ferrers图秩度量码，结合多级构造（双多级构造和双边多级构造），提出高效的CDC构建方法。此外，通过新的双边识别向量集提供另一种构建方式。

Result: 实验展示了多个规模大于现有文献的CDC实例，且在某些情况下，新下界与已知上界的比率超过0.94548。

Conclusion: 本文提出的方法在CDC构建中表现出色，为网络编码中的恒定维度提升秩度量码提供了实用框架。

Abstract: Subspace codes, especially constant dimension subspace codes (CDCs),
represent an intriguing domain that can be used to conduct basic coding theory
investigations. They have received widespread attention due to their
applications in random network coding. This paper presents inverse bilateral
multilevel construction by introducing inverse bilateral identifying vectors
and inverse bilateral Ferrers diagram rank-metric codes. By inserting the
inverse bilateral multilevel construction into the double multilevel
construction and bilateral multilevel construction, an effective construction
for CDCs is provided. Furthermore, via providing a new set of bilateral
identifying vectors, we give another efficient construction for CDCs. In this
article, several CDCs are exhibited, equipped with the rank-metric, with larger
sizes than the known ones in the existing literature. From a practical
standpoint, our results could help in the pragmatic framework of
constant-dimension-lifted rank-metric codes for applications in network coding.
The ratio of the new lower bound to the known upper bound for some CDCs is
calculated, which is greater than 0.94548 for any prime power $q \geq 3.$

</details>


### [15] [Channel Coding for Unequal Error Protection in Digital Semantic Communication](https://arxiv.org/abs/2508.03381)
*Seonjung Kim,Yongjeong Oh,Yongjune Kim,Namyoon Lee,Yo-Seb Jeon*

Main category: cs.IT

TL;DR: 论文提出两种新型信道编码框架，用于数字语义通信中的不等错误保护问题，通过优化重复编码和分组策略，显著提升任务性能和传输效率。


<details>
  <summary>Details</summary>
Motivation: 解决数字语义通信中比特级语义重要性不等的问题，确保高重要性比特得到更强保护。

Method: 提出基于重复编码的比特级UEP框架和基于现代信道码的块级UEP框架，结合比特分组算法优化保护策略。

Result: 仿真实验表明，所提框架在图像传输任务中显著优于传统方法，提升了任务性能和传输效率。

Conclusion: 通过联合学习语义编码器和解码器，优化比特级保护策略，实现了高效的语义通信。

Abstract: Semantic communication is an emerging paradigm that prioritizes transmitting
task-relevant information over accurately delivering raw data bits. In this
paper, we address an unequal error protection (UEP) problem in digital semantic
communication, where bits of higher semantic importance require stronger
protection. To quantify bit-level importance, we leverage bit-flip
probabilities of semantic bits as target error protection levels, which are
jointly learned with semantic encoder and decoder. We propose two novel channel
coding frameworks aimed at minimizing the total blocklength while satisfying
UEP constraints. First, we develop a bit-level UEP framework based on
repetition coding, in which the repetition number for each bit is optimized to
precisely meet its target bit-flip probability. Second, we introduce a
block-level UEP framework utilizing modern channel codes, where semantic bits
with similar target bit-flip probabilities are grouped to exploit coding gains.
Within this framework, we propose a bit-grouping algorithm guided by finite
blocklength capacity analysis. Simulation results conducted on image
transmission tasks confirm that the proposed frameworks significantly
outperform conventional approaches, yielding substantial improvements in both
task performance and transmission efficiency.

</details>


### [16] [Dual Domain Expurgated Error Exponents for Source Coding with Side Information](https://arxiv.org/abs/2508.03467)
*Mehdi Dabirnia,Hamdi Joudeh,Albert Guillén i Fàbregas*

Main category: cs.IT

TL;DR: 提出了一种用于带边信息的源编码的剔除方法，通过双域推导直接得到剔除错误指数。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在优化分布时的复杂性，双域方法能简化参数优化并适用于更广泛的场景。

Method: 采用双域方法推导两种不同的剔除错误指数，比较其性能。

Result: 证明其中一种指数与Csiszár-Körner指数一致，数值示例展示了两种指数的差异。

Conclusion: 在无边信息的源编码中，剔除指数与最优源编码的错误指数一致。

Abstract: We introduce an expurgation method for source coding with side information
that enables direct dual-domain derivations of expurgated error exponents.
Dual-domain methods yield optimization problems over few parameters, with any
sub-optimal choice resulting in an achievable exponent, as opposed to
primal-domain optimization over distributions. In addition, dual-domain methods
naturally allow for general alphabets and/or memory. We derive two such
expurgated error exponents for different random-coding ensembles. We show the
better of the exponents coincides with the Csisz\'ar-K\"orner exponent obtained
via a graph decomposition lemma. We show some numerical examples that
illustrate the differences between the two exponents and show that in the case
of source coding without side information, the expurgated exponent coincides
with the error exponent of the source optimal code.

</details>


### [17] [Decoding Algorithms for Twisted GRS Codes](https://arxiv.org/abs/2508.03552)
*Guanghui Zhang,Liren Lin,Bocong Chen*

Main category: cs.IT

TL;DR: 本文提出了针对MDS TGRS码的新解码算法，基于高斯消元法，能够纠正特定数量的错误，并适用于近MDS TGRS码。


<details>
  <summary>Details</summary>
Motivation: 扩展TGRS码的代数能力，构建新的非GRS MDS码并提升密码学安全性。

Method: 使用高斯消元法设计解码算法，适用于MDS和近MDS TGRS码，计算复杂度为O(n^3)。

Result: 算法能纠正奇数n-k时⌊(n-k)/2⌋错误，偶数时⌊(n-k)/2⌋-1错误，且适用于近MDS码。

Conclusion: 新算法填补了现有文献空白，适用于更广泛的TGRS码解码场景，保持多项式时间复杂度。

Abstract: Twisted generalized Reed-Solomon (TGRS) codes were introduced to extend the
algebraic capabilities of classical generalized Reed-Solomon (GRS) codes. This
extension holds the potential for constructing new non-GRS maximum distance
separable (MDS) codes and enhancing cryptographic security. It is known that
TGRS codes with $1$ twist can either be MDS or near-MDS. In this paper, we
employ the Gaussian elimination method to propose new decoding algorithms for
MDS TGRS codes with parameters $[n,k,n-k+1]$. The algorithms can correct up to
$\lfloor \frac{n-k}{2}\rfloor$ errors when $n-k$ is odd, and $\lfloor
\frac{n-k}{2}\rfloor-1$ errors when $n-k$ is even. The computational complexity
for both scenarios is $O(n^3)$. %, where $\omega\approx 2.37286$ is the matrix
multiplication exponent. Our approach diverges from existing methods based on
Euclidean algorithm and addresses situations that have not been considered in
the existing literature \cite{SYJL}. Furthermore, this method is also
applicable to decoding near-MDS TGRS codes with parameters $[n, k, n-k]$,
enabling correction of up to $\lfloor \frac{n-k-1}{2} \rfloor$ errors, while
maintaining polynomial time complexity in $n$.

</details>


### [18] [What If, But Privately: Private Counterfactual Retrieval](https://arxiv.org/abs/2508.03681)
*Shreya Meel,Mohamed Nomeir,Pasan Dissanayake,Sanghamitra Dutta,Sennur Ulukus*

Main category: cs.IT

TL;DR: 论文提出了一种保护用户隐私的反事实解释检索框架，通过信息论隐私保护机制，确保用户特征向量不被泄露，并探讨了不可变特征和用户偏好的扩展方案。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用中，黑盒机器学习模型需要透明性和可解释性，但反事实解释可能威胁用户和机构的隐私。论文旨在解决用户在不泄露特征向量的情况下获取反事实解释的问题。

Method: 提出了私有反事实检索（PCR）基线方案，并在此基础上改进以减少数据库信息泄露；进一步扩展到不可变PCR（I-PCR）和用户偏好整合方案。

Result: 理论分析和数值结果表明，所提方案能实现用户隐私的完美保护，并在不同程度上减少数据库信息泄露。

Conclusion: 论文提出的框架有效解决了反事实解释中的隐私问题，并通过扩展方案增强了实用性和灵活性。

Abstract: Transparency and explainability are two important aspects to be considered
when employing black-box machine learning models in high-stake applications.
Providing counterfactual explanations is one way of catering this requirement.
However, this also poses a threat to the privacy of the institution that is
providing the explanation, as well as the user who is requesting it. In this
work, we are primarily concerned with the user's privacy who wants to retrieve
a counterfactual instance, without revealing their feature vector to the
institution. Our framework retrieves the exact nearest neighbor counterfactual
explanation from a database of accepted points while achieving perfect,
information-theoretic, privacy for the user. First, we introduce the problem of
private counterfactual retrieval (PCR) and propose a baseline PCR scheme that
keeps the user's feature vector information-theoretically private from the
institution. Building on this, we propose two other schemes that reduce the
amount of information leaked about the institution database to the user,
compared to the baseline scheme. Second, we relax the assumption of mutability
of all features, and consider the setting of immutable PCR (I-PCR). Here, the
user retrieves the nearest counterfactual without altering a private subset of
their features, which constitutes the immutable set, while keeping their
feature vector and immutable set private from the institution. For this, we
propose two schemes that preserve the user's privacy information-theoretically,
but ensure varying degrees of database privacy. Third, we extend our PCR and
I-PCR schemes to incorporate user's preference on transforming their
attributes, so that a more actionable explanation can be received. Finally, we
present numerical results to support our theoretical findings, and compare the
database leakage of the proposed schemes.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [19] [An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method](https://arxiv.org/abs/2508.02687)
*Yijia Hao,Maarten Strackx,Miguel Gandara,Sandy Cochran,Bo Liu*

Main category: eess.SP

TL;DR: 本文提出了一种AI驱动的EDA算法，用于LDO供电的LC-tank VCO的协同设计，优化了高频和低频相位噪声的权衡，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统设计方法未能完全解决高频和LDO引起的低频相位噪声之间的权衡问题，因此需要一种协同设计方法。

Method: 采用AI驱动的EDA算法进行LDO和LC-tank VCO的协同设计，并通过65 nm CMOS工艺实现验证。

Result: 仿真结果显示，协同设计方法在1 MHz偏移处相位噪声改善了1.2 dB，动态功耗降低了28.8%，FoM提升了2.4 dBc/Hz。

Conclusion: 协同设计方法显著优于传统顺序设计方法，为高性能VCO设计提供了新思路。

Abstract: Traditionally, the output noise and power supply rejection of low-dropout
regulators (LDOs) are optimized to minimize power supply fluctuations, reducing
their impact on the low-frequency noise of target voltage-controlled
oscillators (VCOs). However, this sequential design approach does not fully
address the trade-offs between high-frequency and LDO-induced low-frequency
phase noise. To overcome this limitation, this paper presents a co-design
method for low phase-noise LC-tank VCOs powered by LDOs. It is difficult to
carry out the co-design using traditional manual design techniques. Hence, an
efficient AI-driven EDA algorithm is used. To validate the proposed method, a
5.6 GHz LC-tank VCO with an integrated LDO is designed using a 65 nm CMOS
process. Simulations show that the co-design method improves phase noise by 1.2
dB at a 1 MHz offset and reduces dynamic power consumption by 28.8%, with FoM
increased by 2.4 dBc/Hz compared to the conventional sequential design method.

</details>


### [20] [On Improving PPG-Based Sleep Staging: A Pilot Study](https://arxiv.org/abs/2508.02689)
*Jiawei Wang,Yu Guan,Chen Chen,Ligang Zhou,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 通过双流交叉注意力架构结合PPG及其辅助信息，显著提升了基于PPG的睡眠分期性能。


<details>
  <summary>Details</summary>
Motivation: PPG传感器在消费设备中广泛应用，但仅依赖PPG实现可靠的睡眠分期仍具挑战性。

Method: 比较单流模型与双流交叉注意力策略，利用PPG及其衍生模态（如增强PPG或合成ECG）学习互补信息。

Result: 在MESA数据集上的实验表明，双流架构结合辅助信息显著提升了性能。

Conclusion: 双流交叉注意力架构是提升PPG睡眠分期性能的有效方法。

Abstract: Sleep monitoring through accessible wearable technology is crucial to
improving well-being in ubiquitous computing. Although
photoplethysmography(PPG) sensors are widely adopted in consumer devices,
achieving consistently reliable sleep staging using PPG alone remains a
non-trivial challenge. In this work, we explore multiple strategies to enhance
the performance of PPG-based sleep staging. Specifically, we compare
conventional single-stream model with dual-stream cross-attention strategies,
based on which complementary information can be learned via PPG and PPG-derived
modalities such as augmented PPG or synthetic ECG. To study the effectiveness
of the aforementioned approaches in four-stage sleep monitoring task, we
conducted experiments on the world's largest sleep staging dataset, i.e., the
Multi-Ethnic Study of Atherosclerosis(MESA). We found that substantial
performance gain can be achieved by combining PPG and its auxiliary information
under the dual-stream cross-attention architecture. Source code of this project
can be found at https://github.com/DavyWJW/sleep-staging-models

</details>


### [21] [Federated Learning in Active STARS-Aided Uplink Networks](https://arxiv.org/abs/2508.02693)
*Xinwei Yue,Xinning Guo,Xidong Mu,Jingjing Zhao,Peng Yang,Junsheng Mu,Zhiping Lu*

Main category: eess.SP

TL;DR: ASTARS辅助的联邦学习（FL）通过OTA计算技术减少上传参数数量，优化模型聚合误差和训练损失，提升学习效率和信号传输质量。


<details>
  <summary>Details</summary>
Motivation: 利用ASTARS缓解多径衰落并重塑电磁环境，以提升FL上行链路模型传输效率。

Method: 通过OTA-FL模型聚合误差的上界分析，联合优化接收波束分配和ASTARS相位偏移，以最大化学习效率。

Result: ASTARS辅助的FL网络在准确性和效率上优于现有技术，尤其在离散数据集下表现更优。

Conclusion: 适当放大功率可提升FL准确性，但过度放大会导致热噪声成为主要误差源。

Abstract: Active simultaneously transmitting and reflecting surfaces (ASTARS) have
attracted growing research interest due to its ability to alleviate
multiplicative fading and reshape the electromagnetic environment across the
entire space. In this paper, we utilise ASTARS to assist the federated learning
(FL) uplink model transfer and further reduce the number of uploaded parameter
counts through over-the-air (OTA) computing techniques. The impact of model
aggregation errors on ASTARS-aided FL uplink networks is characterized. We
derive an upper bound on the aggregation error of the OTA-FL model and quantify
the training loss due to communication errors. Then, we define the performance
of OTA-FL as a joint optimization problem that encompasses both the assignment
of received beams and the phase shifting of ASTARS, aiming to achieve the
maximum learning efficiency and high-quality signal transmission. Numerical
results demonstrate that: i) The FL accuracy in ASTARS uplink networks are
enhanced compared to that in state-of-the-art networks; ii) The ASTARS enabled
FL system achieves the better learning accuracy using fewer active units than
other baseline, especially when the dataset is more discrete; and iii) FL
accuracy improves with higher amplification power, but excessive amplification
makes thermal noise the dominant source of error.

</details>


### [22] [A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting](https://arxiv.org/abs/2508.02698)
*Sameera Bharadwaja H.,D. K. Mehra*

Main category: eess.SP

TL;DR: 提出了一种基于频域线性非冗余预编码和交替子载波星座分裂的方法，解决了OFDM系统中二阶统计量盲信道估计的复数标量模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于二阶统计量的方法普遍存在复数标量模糊问题，通常需要借助导频或参考符号解决，本文旨在提出一种无需导频的盲估计方法。

Method: 采用频域线性非冗余预编码和交替子载波星座分裂技术，实现复数标量模糊的盲解析。

Result: 数值仿真表明，该方法在M进制PAM系统中的性能与半盲方法相当。

Conclusion: 所提方法有效解决了盲信道估计中的复数标量模糊问题，且性能接近半盲方法。

Abstract: The problem of second-order statistics (SOS)-based blind channel estimation
in OFDM systems is addressed in this paper. Almost all SOS-based methods
proposed so far suffer from a complex-scalar estimation ambiguity, which is
resolved by using pilots or reference symbols. We propose an algorithm to
resolve this ambiguity in blind manner using frequency-domain linear
non-redundant precoding and constellation-splitting among the alternate
subcarriers. The performance of the proposed scheme is evaluated via numerical
simulations in MATLAB environment. Simulation results show that the proposed
approach performs as good as its semi-blind counterpart for M-ary PAM systems.

</details>


### [23] [Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations](https://arxiv.org/abs/2508.02703)
*Evangelos Sariyanidi,John D. Herrington,Lisa Yankowitz,Pratik Chaudhari,Theodore D. Satterthwaite,Casey J. Zampella,Robert T. Schultz,Russell T. Shinohara,Birkan Tunc*

Main category: eess.SP

TL;DR: 论文提出了一种自监督方法“concurrence”，用于测量复杂非线性信号之间的统计依赖性，无需先验知识。


<details>
  <summary>Details</summary>
Motivation: 生物系统常表现出复杂的非线性相互作用，现有方法难以捕捉这些依赖关系。

Method: 通过区分时间对齐与不对齐的信号段来测量依赖性。

Result: 实验表明，该方法能广泛适用于多种信号，并提取科学相关差异。

Conclusion: 该方法为跨领域科学发现提供了有力工具，但需注意外部因素导致的依赖关系。

Abstract: Measuring the statistical dependence between observed signals is a primary
tool for scientific discovery. However, biological systems often exhibit
complex non-linear interactions that currently cannot be captured without a
priori knowledge regarding the nature of dependence. We introduce a
self-supervised approach, concurrence, which is inspired by the observation
that if two signals are dependent, then one should be able to distinguish
between temporally aligned vs. misaligned segments extracted from them.
Experiments with fMRI, physiological and behavioral signals show that, to our
knowledge, concurrence is the first approach that can expose relationships
across such a wide spectrum of signals and extract scientifically relevant
differences without ad-hoc parameter tuning or reliance on a priori
information, providing a potent tool for scientific discoveries across fields.
However, depencencies caused by extraneous factors remain an open problem, thus
researchers should validate that exposed relationships truely pertain to the
question(s) of interest.

</details>


### [24] [Evaluation of Deep Learning Models for LBBB Classification in ECG Signals](https://arxiv.org/abs/2508.02710)
*Beatriz Macas Ordóñez,Diego Vinicio Orellana Villavicencio,José Manuel Ferrández,Paula Bonomini*

Main category: eess.SP

TL;DR: 研究探索不同神经网络架构对心电图信号时空模式的提取能力，并分类为健康、LBBB和sLBBB三组。


<details>
  <summary>Details</summary>
Motivation: 通过创新技术优化LBBB分类，为心脏再同步治疗（CRT）候选者选择提供支持。

Method: 评估不同神经网络架构对ECG信号的时空模式提取和分类能力。

Result: 未明确提及具体结果，但目标是优化分类性能。

Conclusion: 研究有助于改进CRT候选者的筛选方法。

Abstract: This study explores different neural network architectures to evaluate their
ability to extract spatial and temporal patterns from electrocardiographic
(ECG) signals and classify them into three groups: healthy subjects, Left
Bundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB).
  Clinical Relevance, Innovative technologies enable the selection of
candidates for Cardiac Resynchronization Therapy (CRT) by optimizing the
classification of subjects with Left Bundle Branch Block (LBBB).

</details>


### [25] [Physics-guided denoiser network for enhanced additive manufacturing data quality](https://arxiv.org/abs/2508.02712)
*Pallock Halder,Satyajit Mojumder*

Main category: eess.SP

TL;DR: 提出了一种基于物理信息的去噪框架，结合能量模型和Fisher分数正则化，有效降低数据噪声并保持物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现代工程系统中的传感器数据常受噪声干扰，难以用于实时控制和诊断。

Method: 提出物理信息去噪框架，结合能量模型和Fisher分数正则化，并通过基准问题和实际LPBF实验验证。

Result: 在多种噪声水平下优于基线神经网络去噪方法，适用于LPBF实时数据。

Conclusion: 该方法能有效提升低成本传感器数据的实时解释能力，助力增材制造中的预测控制和缺陷缓解。

Abstract: Modern engineering systems are increasingly equipped with sensors for
real-time monitoring and decision-making. However, the data collected by these
sensors is often noisy and difficult to interpret, limiting its utility for
control and diagnostics. In this work, we propose a physics-informed denoising
framework that integrates energy-based model and Fisher score regularization to
jointly reduce data noise and enforce physical consistency with a physics-based
model. The approach is first validated on benchmark problems, including the
simple harmonic oscillator, Burgers' equation, and Laplace's equation, across
varying noise levels. We then apply the denoising framework to real thermal
emission data from laser powder bed fusion (LPBF) additive manufacturing
experiments, using a trained Physics-Informed Neural Network (PINN) surrogate
model of the LPBF process to guide denoising. Results show that the proposed
method outperforms baseline neural network denoisers, effectively reducing
noise under a range of LPBF processing conditions. This physics-guided
denoising strategy enables robust, real-time interpretation of low-cost sensor
data, facilitating predictive control and improved defect mitigation in
additive manufacturing.

</details>


### [26] [Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach](https://arxiv.org/abs/2508.02713)
*Pengxu Lin,An-An Lu,Xiqi Gao*

Main category: eess.SP

TL;DR: 论文提出了一种基于辛优化的预编码器设计方法，用于用户中心网络（UCN）大规模MIMO系统，避免了传统线性预编码中的矩阵求逆，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 在UCN大规模MIMO系统中，传统线性预编码的矩阵求逆计算复杂度高，因此需要一种更高效的方法来设计预编码器。

Method: 利用辛优化框架，将接收模型转换到实数域，并重新表述加权和速率（WSR）最大化问题，通过离散化连续动力系统获得迭代方法。

Result: 仿真结果表明，基于辛优化的预编码器设计在UCN大规模MIMO系统中优于加权最小均方误差（WMMSE）预编码器。

Conclusion: 辛优化方法在降低计算复杂度的同时，提高了预编码器的性能，适用于实际系统。

Abstract: In this paper, we utilize symplectic optimization to design a precoder for
user-centric network (UCN) massive multiple-input multiple-output (MIMO)
systems, where a subset of base stations (BSs) serves each user terminal (UT)
instead of using all BSs. In UCN massive MIMO systems, the dimension of the
precoders is reduced compared to conventional network massive MIMO. It
simplifies the implementation of precoders in practical systems. However, the
matrix inversion in traditional linear precoders still requires high
computational complexity. To avoid the matrix inversion, we employ the
symplectic optimization framework, where optimization problems are solved based
on dissipative Hamiltonian dynamical systems. To better fit symplectic
optimization, we transform the received model into the real field and
reformulate the weighted sum-rate (WSR) maximization problem. The objective
function of the optimization problem is viewed as the potential energy of the
dynamical system. Due to energy dissipation, the continuous dynamical system
always converges to a state with minimal potential energy. By discretizing the
continuous system while preserving the symplectic structure, we obtain an
iterative method for the precoder design. The complexity analysis of the
proposed symplectic method is also provided to show its high computational
efficiency. Simulation results demonstrate that the proposed precoder design
based on symplectic optimization outperforms the weighted minimum mean-square
error (WMMSE) precoder in the UCN massive MIMO system.

</details>


### [27] [SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG](https://arxiv.org/abs/2508.02718)
*Zahra Mohammadi,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 提出了一种基于单导联心电图的高效睡眠呼吸暂停亚型分类方法SleepLiteCNN，适用于可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 睡眠呼吸暂停亚型的准确、高时间分辨率检测对治疗和管理至关重要。

Method: 评估多种机器学习算法和深度学习架构，提出紧凑且节能的SleepLiteCNN。

Result: SleepLiteCNN准确率超95%，能耗仅1.8微焦耳/次，适合实时监测。

Conclusion: SleepLiteCNN是适用于可穿戴设备的实用高效解决方案。

Abstract: Apnea is a common sleep disorder characterized by breathing interruptions
lasting at least ten seconds and occurring more than five times per hour.
Accurate, high-temporal-resolution detection of sleep apnea subtypes -
Obstructive, Central, and Mixed - is crucial for effective treatment and
management. This paper presents an energy-efficient method for classifying
these subtypes using a single-lead electrocardiogram (ECG) with high temporal
resolution to address the real-time needs of wearable devices. We evaluate a
wide range of classical machine learning algorithms and deep learning
architectures on 1-second ECG windows, comparing their accuracy, complexity,
and energy consumption. Based on this analysis, we introduce SleepLiteCNN, a
compact and energy-efficient convolutional neural network specifically designed
for wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92%
macro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit
quantization. Field Programmable Gate Array (FPGA) synthesis further
demonstrates significant reductions in hardware resource usage, confirming its
suitability for continuous, real-time monitoring in energy-constrained
environments. These results establish SleepLiteCNN as a practical and effective
solution for wearable device sleep apnea subtype detection.

</details>


### [28] [Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction](https://arxiv.org/abs/2508.02724)
*Yahia Dalbah,Marcel Worring,Yen-Chia Hsu*

Main category: eess.SP

TL;DR: Veli是一种无监督贝叶斯模型，通过变分推理校正低成本传感器的读数，无需依赖参考站，解决了传感器漂移和环境干扰问题，并引入了AQ-SDR作为大规模空气质量传感器基准。


<details>
  <summary>Details</summary>
Motivation: 城市空气污染导致大量早逝，亟需准确且可扩展的空气质量监测方法。低成本传感器虽具扩展性，但易受漂移、校准误差和环境干扰影响。

Method: Veli利用变分推理构建解耦表示，分离真实污染物读数与传感器噪声，无需与参考站共置。同时提出AQ-SDR作为标准化基准。

Result: Veli在分布内外均表现优异，有效处理传感器漂移和异常行为。AQ-SDR是目前最大的空气质量传感器基准。

Conclusion: Veli为低成本传感器提供了一种无需参考站的校正方法，结合AQ-SDR推动了空气质量监测的标准化和可扩展性。

Abstract: Urban air pollution is a major health crisis causing millions of premature
deaths annually, underscoring the urgent need for accurate and scalable
monitoring of air quality (AQ). While low-cost sensors (LCS) offer a scalable
alternative to expensive reference-grade stations, their readings are affected
by drift, calibration errors, and environmental interference. To address these
challenges, we introduce Veli (Reference-free Variational Estimation via Latent
Inference), an unsupervised Bayesian model that leverages variational inference
to correct LCS readings without requiring co-location with reference stations,
eliminating a major deployment barrier. Specifically, Veli constructs a
disentangled representation of the LCS readings, effectively separating the
true pollutant reading from the sensor noise. To build our model and address
the lack of standardized benchmarks in AQ monitoring, we also introduce the Air
Quality Sensor Data Repository (AQ-SDR). AQ-SDR is the largest AQ sensor
benchmark to date, with readings from 23,737 LCS and reference stations across
multiple regions. Veli demonstrates strong generalization across both
in-distribution and out-of-distribution settings, effectively handling sensor
drift and erratic sensor behavior. Code for model and dataset will be made
public when this paper is published.

</details>


### [29] [SpectrumFM: A New Paradigm for Spectrum Cognition](https://arxiv.org/abs/2508.02742)
*Chunyu Liu,Hao Zhang,Wei Wu,Fuhui Zhou,Qihui Wu,Derrick Wing Kwan Ng,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 提出了一种名为SpectrumFM的频谱基础模型，通过创新的频谱编码器和自监督学习任务，显著提升了频谱认知的泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有频谱认知方法在多样化的频谱环境和任务中泛化能力有限且准确性不足，亟需一种更高效、适应性更强的解决方案。

Method: 提出SpectrumFM模型，结合卷积神经网络和多头自注意力机制的频谱编码器，并开发了掩码重建和下一时隙信号预测两种自监督学习任务进行预训练，采用LoRA参数高效微调技术适应下游任务。

Result: 实验表明，SpectrumFM在频谱感知、异常检测和无线技术分类任务中表现优异，检测概率提升30%，AUC提升10%，分类准确率提升9.6%。

Conclusion: SpectrumFM为频谱认知提供了新范式，显著提升了性能和适应性，适用于多种频谱任务。

Abstract: The enhancement of spectrum efficiency and the realization of secure spectrum
utilization are critically dependent on spectrum cognition. However, existing
spectrum cognition methods often exhibit limited generalization and suboptimal
accuracy when deployed across diverse spectrum environments and tasks. To
overcome these challenges, we propose a spectrum foundation model, termed
SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative
spectrum encoder that exploits the convolutional neural networks and the
multi-head self attention mechanisms is proposed to effectively capture both
fine-grained local signal structures and high-level global dependencies in the
spectrum data. To enhance its adaptability, two novel self-supervised learning
tasks, namely masked reconstruction and next-slot signal prediction, are
developed for pre-training SpectrumFM, enabling the model to learn rich and
transferable representations. Furthermore, low-rank adaptation (LoRA)
parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly
adapt to various downstream spectrum cognition tasks, including spectrum
sensing (SS), anomaly detection (AD), and wireless technology classification
(WTC). Extensive experiments demonstrate the superiority of SpectrumFM over
state-of-the-art methods. Specifically, it improves detection probability in
the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under
the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.

</details>


### [30] [Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition](https://arxiv.org/abs/2508.02847)
*Ke Xu,Chaitanya Krishna Prasad Vallabh,Souran Manoochehri*

Main category: eess.SP

TL;DR: 提出了一种多模态监测框架，结合声发射传感与同轴相机视觉，用于激光定向能量沉积（DED）增材制造中的熔池动态和工艺质量评估。


<details>
  <summary>Details</summary>
Motivation: DED增材制造因熔池动态复杂和工艺变化导致零件质量不稳定，现有研究多关注缺陷检测，缺乏对熔池动态和工艺质量的验证。

Method: 通过声发射传感和同轴相机视觉的多模态监测，提取时域、频域特征和形态特征，并评估多种机器学习算法。

Result: 多模态策略的分类性能达94.4%，优于单独使用声发射（87.8%）或相机（86.7%）。

Conclusion: 该系统能有效捕捉几何变化相关的振动和表面形态变化，为未来零件质量评估奠定技术基础。

Abstract: Laser directed energy deposition (DED) additive manufacturing struggles with
consistent part quality due to complex melt pool dynamics and process
variations. While much research targets defect detection, little work has
validated process monitoring systems for evaluating melt pool dynamics and
process quality. This study presents a novel multimodal monitoring framework,
synergistically integrating contact-based acoustic emission (AE) sensing with
coaxial camera vision to enable layer-wise identification and evaluation of
geometric variations in DED parts. The experimental study used three part
configurations: a baseline part without holes, a part with a 3mm diameter
through-hole, and one with a 5mm through-hole to test the system's discerning
capabilities. Raw sensor data was preprocessed: acoustic signals were filtered
for time-domain and frequency-domain feature extraction, while camera data
underwent melt pool segmentation and morphological feature extraction. Multiple
machine learning algorithms (including SVM, random forest, and XGBoost) were
evaluated to find the optimal model for classifying layer-wise geometric
variations. The integrated multimodal strategy achieved a superior
classification performance of 94.4%, compared to 87.8% for AE only and 86.7%
for the camera only. Validation confirmed the integrated system effectively
captures both structural vibration signatures and surface morphological changes
tied to the geometric variations. While this study focuses on specific
geometries, the demonstrated capability to discriminate between features
establishes a technical foundation for future applications in characterizing
part variations like geometric inaccuracies and manufacturing-induced defects.

</details>


### [31] [Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information](https://arxiv.org/abs/2508.02799)
*Jessica Sanson,Rahul C. Shah,Maximilian Pinaroc,Valerio Frascolla*

Main category: eess.SP

TL;DR: 提出一种新方法，首次从商用Wi-Fi CSI中提取距离和多普勒信息，解决了硬件异步和天线耦合问题，验证了高精度传感的可行性。


<details>
  <summary>Details</summary>
Motivation: 商用Wi-Fi CSI在单收发器设置下提取距离和多普勒信息面临硬件异步和天线耦合的挑战，需要新的信号处理方法。

Method: 提出时间偏移消除、相位对齐校正和收发耦合抑制三项创新信号处理技术。

Result: 在商用Intel Wi-Fi AX211 NIC上验证，实现厘米级精度的距离和多普勒估计，成功检测和跟踪移动目标。

Conclusion: 证明了使用标准Wi-Fi硬件无需修改或全双工能力即可实现高精度传感的可行性。

Abstract: This paper presents, for the first time, a method to extract both range and
Doppler information from commercial Wi-Fi Channel State Information (CSI) using
a monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi
sensing from a Network Interface Card (NIC) not designed for full-duplex
operation is challenging due to (1) Hardware asynchronization, which introduces
significant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx)
antennas, which creates strong coupling that overwhelms the motion signal of
interest. We propose a new signal processing approach that addresses both
challenges via three key innovations: Time offset cancellation, Phase alignment
correction, and Tx/Rx coupling mitigation. Our method achieves cm-level
accuracy in range and Doppler estimation for moving targets, validated using a
commercial Intel Wi-Fi AX211 NIC. Our results show successful detection and
tracking of moving objects in realistic environments, establishing the
feasibility of high-precision sensing using standard Wi-Fi packet
communications and off-the-shelf hardware without requiring any modification or
specialized full-duplex capabilities.

</details>


### [32] [Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks](https://arxiv.org/abs/2508.02856)
*Seyed Bagher Hashemi Natanzi,Hossein Mohammadi,Bo Tang,Vuk Marojevic*

Main category: eess.SP

TL;DR: 提出了一种基于深度强化学习（DRL）的毫米波通信系统防御框架，通过集成感知与通信（ISAC）能力主动应对波束窃取攻击。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信系统面临高级波束窃取攻击的威胁，需要一种主动且自适应的防御方法。

Method: 采用基于近端策略优化（PPO）的DRL代理，结合ISAC能力动态探测可疑活动，并通过课程学习策略优化训练。

Result: 框架实现了92.8%的平均攻击检测率，同时保持用户平均SINR超过13 dB。

Conclusion: 该框架在安全性和通信性能之间取得了平衡，为毫米波通信系统提供了有效的防御方案。

Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility
to advanced beam-stealing attacks, posing a significant physical layer security
threat. This paper introduces a novel framework employing an advanced Deep
Reinforcement Learning (DRL) agent for proactive and adaptive defense against
these sophisticated attacks. A key innovation is leveraging Integrated Sensing
and Communications (ISAC) capabilities for active, intelligent threat
assessment. The DRL agent, built on a Proximal Policy Optimization (PPO)
algorithm, dynamically controls ISAC probing actions to investigate suspicious
activities. We introduce an intensive curriculum learning strategy that
guarantees the agent experiences successful detection during training to
overcome the complex exploration challenges inherent to such a
security-critical task. Consequently, the agent learns a robust and adaptive
policy that intelligently balances security and communication performance.
Numerical results demonstrate that our framework achieves a mean attacker
detection rate of 92.8% while maintaining an average user SINR of over 13 dB.

</details>


### [33] [Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility & Delay Spread](https://arxiv.org/abs/2508.02950)
*Sandesh Rao Mattu,Nishant Mehrotra,Robert Calderbank*

Main category: eess.SP

TL;DR: 论文提出了一种基于Zak-OTFS调制的超Nyquist信号传输方法，通过叠加信息符号并利用慢变信道特性，实现了优于Nyquist信号的高信噪比性能。


<details>
  <summary>Details</summary>
Motivation: 传统正交信号传输限制了带宽和时间内的信息符号数量，超Nyquist信号通过非正交方式传输更多符号，但会引入干扰。本文旨在通过Zak-OTFS调制和慢变信道特性，简化接收处理并提升性能。

Method: 使用Zak-OTFS调制，在延迟-多普勒域叠加信息符号，保持Nyquist间隔。通过构造相互无偏基和预编码器，将干扰转化为高斯噪声，简化检测。

Result: 数值结果表明，未编码性能与Nyquist信号相当，编码后在高信噪比下性能更优。

Conclusion: 提出的方法通过Zak-OTFS调制和慢变信道特性，实现了高效的超Nyquist信号传输，性能优于传统方法。

Abstract: Orthogonal signaling limits the number of information symbols transmitted in
bandwidth $B$ and time $T$ to be $BT$. This corresponds to the Nyquist
signaling and is achieved by mounting information symbols on $BT$-dimensional
basis spanning the $BT$-dimensional space spaced $\frac{1}{B}$ and
$\frac{1}{T}$ apart. Faster-than-Nyquist signaling involves transmitting more
than $BT$ informational symbols in a $BT$-dimensional space. This leads to loss
of orthogonality. This is achieved by time and/or bandwidth expansion resulting
from packing more information symbols in the same $BT$-dimensional space
(spacing less than $\frac{1}{B}$ and/or $\frac{1}{T}$). In this paper, we take
a different approach to faster-than-Nyquist signaling. We propose to
superimpose the information symbols on one another maintaining the original
spacing in the Nyquist signaling. We carry this out in the delay-Doppler (DD)
domain using Zak-transform based orthogonal time frequency space (Zak-OTFS)
modulation. In Zak-OTFS, the channel varies slowly. Further Zak-OTFS also
allows construction of mutually unbiased bases the interference between which
appear like Gaussian noise. The proposed scheme leverages the slow variation in
the DD channel to construct a precoder that mitigates the effect of the
doubly-spread channel. Further, in the proposed scheme we mount information
symbols on two mutually unbiased bases which allows superposition of
information symbols. This simplifies receiver processing to detection in
Gaussian noise since each basis appears to the other as Gaussian noise. This
reduction makes it possible to use trellis coded modulation to enhance
bit-error performance. Numerical results demonstrate that the
faster-than-Nyquist signaling scheme achieves similar uncoded performance as
that of Nyquist signaling and with coding the performance is better than
Nyquist signaling at high signal-to-noise ratios.

</details>


### [34] [Generating Light-based Fingerprints for Indoor Localization](https://arxiv.org/abs/2508.03011)
*Hsun-Yu Lee,Jie Lin,Fang-Jing Wu*

Main category: eess.SP

TL;DR: 论文提出了一种基于可见光通信（VLC）的室内定位方法，通过低成本AS7341传感器捕获光谱特征，并采用两阶段框架（MLP训练和GAN数据增强）显著提升了定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有射频定位技术（如Wi-Fi、RFID）易受多径衰落和干扰影响，而VLC提供了一种替代方案，利用光谱特征作为稳健的位置指纹。

Method: 采用两阶段框架：1）用真实光谱数据训练多层感知机（MLP）；2）通过TabGAN生成合成数据以扩充训练集。

Result: 实验显示，数据增强后平均定位误差从62.9cm降至49.3cm（提升20%），仅需额外5%的数据收集成本。

Conclusion: GAN数据增强有效缓解了数据稀缺问题，提升了模型的泛化能力，验证了VLC在室内定位中的潜力。

Abstract: Accurate indoor localization underpins applications ranging from wayfinding
and emergency response to asset tracking and smart-building services.
Radio-frequency solutions (e.g. Wi-Fi, RFID, UWB) are widely adopted but remain
vulnerable to multipath fading, interference, and uncontrollable coverage
variation. We explore an orthogonal modality -- visible light communication
(VLC) -- and demonstrate that the spectral signatures captured by a low-cost
AS7341 sensor can serve as robust location fingerprints.
  We introduce a two-stage framework that (i) trains a multi-layer perceptron
(MLP) on real spectral measurements and (ii) enlarges the training corpus with
synthetic samples produced by TabGAN. The augmented dataset reduces the mean
localization error from 62.9cm to 49.3cm -- a 20% improvement -- while
requiring only 5% additional data-collection effort. Experimental results
obtained on 42 reference points in a U-shaped laboratory confirm that GAN-based
augmentation mitigates data-scarcity issues and enhances generalization.

</details>


### [35] [Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation](https://arxiv.org/abs/2508.03021)
*Zhengyu Wang,Tiebin Mi,Gui Zhou,Robert C. Qiu*

Main category: eess.SP

TL;DR: 论文提出了一种基于超表面的极大规模天线（MELA）系统，通过可重构透射超表面实现高效的射频-天线耦合和相位控制，避免了传统方案中的笨重开关矩阵和高成本移相器网络。


<details>
  <summary>Details</summary>
Motivation: 解决下一代无线通信系统对极大规模天线阵列（ELAA）的迫切需求，提升其实用性。

Method: 提出MELA架构，开发物理基础模型描述电磁场传播，并引入距离依赖近似模型；提出两阶段信道估计框架，包括快速角度域扫描和超分辨率估计。

Result: MELA显示出接近传统ELAA架构的最优空间分辨率，数值实验验证了信道估计算法的高分辨率和电磁模型的准确性。

Conclusion: MELA架构是一种具有高度竞争力和前瞻性的解决方案，适用于实际ELAA部署。

Abstract: Extremely large-scale antenna arrays (ELAAs) have emerged as a pivotal
technology for addressing the unprecedented performance demands of
next-generation wireless communication systems. To enhance their practicality,
we propose metasurface-enabled extremely large-scale antenna (MELA) systems --
novel transceiver architectures that employ reconfigurable transmissive
metasurfaces to facilitate efficient over-the-air RF-to-antenna coupling and
phase control. This architecture eliminates the need for bulky switch matrices
and costly phase-shifter networks typically required in conventional solutions.
Physically grounded models are developed to characterize electromagnetic field
propagation through individual transmissive unit cells, capturing the
fundamental physics of wave transformation and transmission. Additionally,
distance-dependent approximate models are introduced, exhibiting structural
properties conducive to efficient parameter estimation and signal processing.
Based on the channel model, a two stage channel estimation framework is
proposed for the scenarios comprising users in the hybrid near- and far-fields.
In the first stage, a dictionary-driven beamspace filtering technique enables
rapid angular-domain scanning. In the refinement stage, the rotational symmetry
of subarrays is exploited to design super-resolution estimators that jointly
recover angular and range parameters. An analytical expression for the
half-power beamwidth of MELA is derived, revealing its near-optimal spatial
resolution relative to conventional ELAA architectures. Numerical experiments
further validate the high-resolution of the proposed channel estimation
algorithm and the fidelity of the electromagnetic model, positioning the MELA
architecture as a highly competitive and forward-looking solution for practical
ELAA deployment.

</details>


### [36] [Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training](https://arxiv.org/abs/2508.03084)
*Lingyan Zhang,Yuanfeng Qiu,Dachuan Li,Shaohua Wu,Tingting Zhang,Qinyu Zhang*

Main category: eess.SP

TL;DR: CSSLoc是一种基于对比自监督预训练的新框架，旨在学习通用表示以实现多场景下的高精度无线定位。


<details>
  <summary>Details</summary>
Motivation: 无线定位技术在特定场景下精度有所提升，但环境动态脆弱性限制了其实际应用，因此需要一种更通用的解决方案。

Method: 通过对比自监督预训练学习无线电数据的相似性度量，无需位置信息监督，实现场景无关的表示学习。训练后的特征编码器可直接用于下游定位任务。

Result: 实验表明，CSSLoc在典型室内场景中优于传统和基于DNN的最新定位方案。

Conclusion: CSSLoc将基于深度学习的定位从特定性推向通用性，提升了环境动态鲁棒性。

Abstract: Wireless localization has become a promising technology for offering
intelligent location-based services. Although its localization accuracy is
improved under specific scenarios, the short of environmental dynamic
vulnerability still hinders this approach from being fully practical
applications. In this paper, we propose CSSLoc, a novel framework on
contrastive self-supervised pre-training to learn generic representations for
accurate localization in various scenarios. Without the location information
supervision, CSSLoc attempts to learn an insightful metric on the similarity
discrimination of radio data, in such a scenario-agnostic manner that the
similar samples are closely clustered together and different samples are
separated in the representation space. Furthermore, the trained feature encoder
can be directly transferred for downstream localization tasks, and the location
predictor is trained to estimate accurate locations with the robustness of
environmental dynamics. With extensive experimental results, CSSLoc can
outperform classical and state-of-the-art DNN-based localization schemes in
typical indoor scenarios, pushing deep-learning-based localization from
specificity to generality.

</details>


### [37] [Can Large Language Models Identify Materials from Radar Signals?](https://arxiv.org/abs/2508.03120)
*Jiangyou Zhu,Hongyu Deng,He Chen*

Main category: eess.SP

TL;DR: LLMaterial首次探索了利用预训练大语言模型（LLM）直接从雷达信号中识别材料的方法，通过物理信号处理管道和检索增强生成策略，实现了开放集材料识别。


<details>
  <summary>Details</summary>
Motivation: 现有雷达技术结合深度学习在材料识别中表现良好，但局限于封闭集对象且需任务特定数据训练，限制了实际应用。因此，研究如何利用LLM直接从雷达信号推断材料成分。

Method: 1. 提出物理信号处理管道，将高冗余雷达数据压缩为包含材料特性的中间参数；2. 采用检索增强生成（RAG）策略，为LLM提供领域知识，使其能解释和推理中间参数。

Result: 初步结果表明，LLMaterial能有效区分多种常见材料，展现了在实际材料识别应用中的潜力。

Conclusion: LLMaterial通过结合信号处理和LLM推理能力，为开放集材料识别提供了新思路，具有实际应用前景。

Abstract: Accurately identifying the material composition of objects is a critical
capability for AI robots powered by large language models (LLMs) to perform
context-aware manipulation. Radar technologies offer a promising sensing
modality for material recognition task. When combined with deep learning, radar
technologies have demonstrated strong potential in identifying the material of
various objects. However, existing radar-based solutions are often constrained
to closed-set object categories and typically require task-specific data
collection to train deep learning models, largely limiting their practical
applicability. This raises an important question: Can we leverage the powerful
reasoning capabilities of pre-trained LLMs to directly infer material
composition from raw radar signals? Answering this question is non-trivial due
to the inherent redundancy of radar signals and the fact that pre-trained LLMs
have no prior exposure to raw radar data during training. To address this, we
introduce LLMaterial, the first study to investigate the feasibility of using
LLM to identify materials directly from radar signals. First, we introduce a
physics-informed signal processing pipeline that distills high-redundancy radar
raw data into a set of compact intermediate parameters that encapsulate the
material's intrinsic characteristics. Second, we adopt a retrieval-augmented
generation (RAG) strategy to provide the LLM with domain-specific knowledge,
enabling it to interpret and reason over the extracted intermediate parameters.
Leveraging this integration, the LLM is empowered to perform step-by-step
reasoning on the condensed radar features, achieving open-set material
recognition directly from raw radar signals. Preliminary results show that
LLMaterial can effectively distinguish among a variety of common materials,
highlighting its strong potential for real-world material identification
applications.

</details>


### [38] [Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition](https://arxiv.org/abs/2508.03131)
*Na Liu,Chengliang Dai,Qiuyue Wu,Qiuqi Li,Guoxiong Cai*

Main category: eess.SP

TL;DR: 本文提出了一种高阶动态模态分解（HODMD）方法，用于提升大规模瞬态电路模拟的计算效率，解决了传统DMD方法在空间分辨率不足时无法重构输出信号的问题。


<details>
  <summary>Details</summary>
Motivation: 传统动态模态分解（DMD）方法在空间分辨率不足时无法重构输出信号，限制了其在大规模电路模拟中的应用。本文旨在通过引入延迟嵌入技术，提出HODMD方法以解决这一问题。

Method: 本文首先推导了DMD算法，随后提出了结合延迟嵌入技术的高阶动态模态分解（HODMD）方法，适用于大规模电路模拟。

Result: 通过三个代表性数值测试案例验证了HODMD方法的计算效率和准确性，表明其优于传统DMD方法。

Conclusion: HODMD方法适用于一般电路，不受电路拓扑或组件类型的限制，显著提升了大规模电路模拟的效率。

Abstract: Model order reduction (MOR) has long been a mainstream strategy to accelerate
large-scale transient circuit simulation. Dynamic Mode Decomposition (DMD)
represents a novel data-driven characterization method, extracting dominant
dynamical modes directly from time-domain simulation data without requiring
explicit system equations. This paper first deduces the DMD algorithm and then
proposes high order dynamic mode decomposition (HODMD) incorporating delayed
embedding technique, specifically targeting computational efficiency in
large-scale circuit simulations. Compared with the DMD method, the HODMD method
overcomes the problem that the output signal cannot be reconstructed when the
spatial resolution is insufficient. The proposed HODMD algorithm is applicable
to general circuits and does not impose any constraints on the topology of the
pertinent circuit or type of the components. Three representative numerical
test cases are presented to systematically validate both the computational
efficiency and accuracy of the proposed HODMD method.

</details>


### [39] [Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication](https://arxiv.org/abs/2508.03248)
*Yoon Huh,Bumjun Kim,Wan Choi*

Main category: eess.SP

TL;DR: FedSFR是一种基于联邦学习的框架，通过语义特征重构提升图像语义通信系统的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决语义通信中因知识库不匹配和模型过时导致的错误和性能下降问题。

Method: 引入语义特征重构步骤，允许部分客户端传输紧凑特征向量而非完整模型更新，设计专用损失函数并进行收敛分析。

Result: 在两个基准数据集上验证了FedSFR的优越性，尤其在容量受限环境中表现突出。

Conclusion: FedSFR在提升通信效率和训练稳定性方面有效且鲁棒。

Abstract: Recent advancements in semantic communication have primarily focused on image
transmission, where neural network (NN)-based joint source-channel coding
(JSCC) modules play a central role. However, such systems often experience
semantic communication errors due to mismatched knowledge bases between users
and performance degradation from outdated models, necessitating regular model
updates. To address these challenges in vector quantization (VQ)-based image
semantic communication systems, we propose FedSFR, a novel federated learning
(FL) framework that incorporates semantic feature reconstruction (FR). FedSFR
introduces an FR step at the parameter server (PS) and allows a subset of
clients to transmit compact feature vectors in lieu of sending full local model
updates, thereby improving training stability and communication efficiency. To
enable effective FR learning, we design a loss function tailored for VQ-based
image semantic communication and demonstrate its validity as a surrogate for
image reconstruction error. Additionally, we provide a rigorous convergence
analysis and present a differentially private variant of FedSFR, along with
formal privacy analysis. Experimental results on two benchmark datasets
validate the superiority of FedSFR over existing baselines, especially in
capacity-constrained settings, confirming both its effectiveness and
robustness.

</details>


### [40] [Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG](https://arxiv.org/abs/2508.03274)
*Ramaswamy Palaniappan,Surej Mouli,Howard Bowman,Ian McLoughlin*

Main category: eess.SP

TL;DR: 论文研究了不同刹车灯设计对驾驶员反应时间的影响，发现LED刹车灯比白炽灯刹车灯能更快引发认知反应。


<details>
  <summary>Details</summary>
Motivation: 研究动机是减少因驾驶员注意力不足或车距不足导致的交通事故，尤其是追尾事故。

Method: 方法包括在模拟驾驶环境中测试多种刹车灯设计，记录22名受试者的脑电图（EEG）数据，分析P3成分的反应时间。

Result: 结果显示白炽灯刹车灯的认知反应时间显著慢于LED刹车灯，但不同LED设计之间的差异不显著。

Conclusion: 结论是LED刹车灯设计在提升驾驶员反应速度方面优于白炽灯设计。

Abstract: Half of all road accidents result from either lack of driver attention or
from maintaining insufficient separation between vehicles. Collision from the
rear, in particular, has been identified as the most common class of accident
in the UK, and its influencing factors have been widely studied for many years.
Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to
alert following drivers to the need to reduce speed or brake. This paper
develops a novel brain response approach to measuring subject reaction to
different brake light designs. A variety of off-the-shelf brake light
assemblies are tested in a physical simulated driving environment to assess the
cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs
of incandescent bulb-based brake light assemblies are used and
electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the
P3 component evoked during the decision making process that occurs in the brain
when a participant decides to lift their foot from the accelerator and depress
the brake. EEG analysis shows that both incandescent bulb-based lights are
statistically slower to evoke cognitive responses than all tested LED-based
lights. Between the LED designs, differences are evident, but not statistically
significant, attributed to the significant amount of movement artifact in the
EEG signal.

</details>


### [41] [Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks](https://arxiv.org/abs/2508.03279)
*Vasileios Kouvakis,Stylianos E. Trevlakis,Ioannis Arapakis,Alexandros-Apostolos A. Boulogeorgos*

Main category: eess.SP

TL;DR: 提出了一种基于脉冲神经网络（SNN）的非地面网络（NTN）中用户设备-基站（UE-BS）关联方法，比较了集中式和分布式策略。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UAV）引入无线网络，系统架构变得异构，需要动态高效的管理以避免拥塞并维持性能。

Method: 采用基于泄漏积分发放（LIF）神经元的SNN，比较了集中式和分布式两种优化策略。

Result: 分布式模型达到90%以上准确率，集中式模型为80-100%，两者在部署场景中各有优劣。

Conclusion: 两种方法在UE-BS关联的可行性和最优解之间存在权衡，适用于不同场景。

Abstract: This work presents a new spiking neural network (SNN)-based approach for user
equipment-base station (UE-BS) association in non-terrestrial networks (NTNs).
With the introduction of UAV's in wireless networks, the system architecture
becomes heterogeneous, resulting in the need for dynamic and efficient
management to avoid congestion and sustain overall performance. The presented
framework compares two SNN-based optimization strategies. Specifically, a
top-down centralized approach with complete network visibility and a bottom-up
distributed approach for individual network nodes. The SNN is based on leak
integrate-and-fire neurons with temporal components, which can perform fast and
efficient event-driven inference. Realistic ray-tracing simulations are
conducted, which showcase that the bottom-up model attains over 90\% accuracy,
while the top-down model maintains 80-100\% accuracy. Both approaches reveal a
trade-off between individually optimal solutions and UE-BS association
feasibility, thus revealing the effectiveness of both approaches depending on
deployment scenarios.

</details>


### [42] [Quantum Deep Learning for Massive MIMO User Scheduling](https://arxiv.org/abs/2508.03327)
*Xingyu Huang,Ruining Fan,Mouli Chakraborty,Avishek Nag,Anshu Mukherjee*

Main category: eess.SP

TL;DR: 提出了一种混合量子神经网络（QNN）架构，用于5G/B5G大规模MIMO系统中的高效用户调度，解决了传统方法的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在大规模MIMO系统中存在可扩展性问题，需要更高效的调度方案。

Method: 结合经典神经网络和变分量子电路核，利用统计信道状态信息（CSI）减少计算开销。

Result: 模型在噪声信道中表现稳健，优于经典卷积神经网络（CNN），提高了频谱效率。

Conclusion: 展示了量子增强机器学习在无线调度中的潜力。

Abstract: We introduce a hybrid Quantum Neural Networks (QNN) architecture for the
efficient user scheduling in 5G/Beyond 5G (B5G) massive Multiple Input Multiple
Output (MIMO) systems, addressing the scalability issues of traditional
methods. By leveraging statistical Channel State Information (CSI), our model
reduces computational overhead and enhances spectral efficiency. It integrates
classical neural networks with a variational quantum circuit kernel,
outperforming classical Convolutional Neural Networks (CNNs) and maintaining
robust performance in noisy channels. This demonstrates the potential of
quantum-enhanced Machine Learning (ML) for wireless scheduling.

</details>


### [43] [Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications](https://arxiv.org/abs/2508.03391)
*Seunghyeon Jeon,Seonjung Kim,Gyeongrae Im,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 论文研究了低地球轨道（LEO）卫星通信系统中的波束跳跃模式设计，提出了一种动态分配资源的方法以应对流量需求不均的问题。


<details>
  <summary>Details</summary>
Motivation: 偏远地区对大规模设备连接的需求推动了LEO卫星通信系统的发展，波束跳跃系统无需建立连接即可实现需求感知的资源分配和低接入延迟。

Method: 提出了一种交替优化框架的波束跳跃设计算法，结合二分法和ADMM方法优化资源分配和解码成功率。

Result: 仿真结果表明，所提算法在管理流量需求不均方面优于其他波束跳跃方法，并具有鲁棒性。

Conclusion: 该研究为LEO卫星通信系统的动态资源分配提供了有效解决方案，显著提升了系统性能。

Abstract: Increasing demand for massive device connectivity in underserved regions
drives the development of advanced low Earth orbit (LEO) satellite
communication systems. Beam-hopping LEO systems without connection
establishment provide a promising solution for achieving both demand-aware
resource allocation and low access latency. This paper investigates
beam-hopping pattern design for the grant-free random access systems to
dynamically allocate satellite resources according to traffic demands across
serving cells. We formulate a binary optimization problem that aims to maximize
the minimum successful transmission probability across cells, given limited
satellite beam generation capacity. To solve this problem, we propose novel
beam-hopping design algorithms that alternately enhance the collision avoidance
rate and decoding success probability within an alternating optimization
framework. Specifically, the algorithms employ a bisection method to optimize
illumination allocation for each cell based on demand, while using the
alternating direction method of multipliers (ADMM) to optimize beam-hopping
patterns for maximizing decoding success probability. Furthermore, we enhance
the ADMM by replacing the strict binary constraint with two equivalent
continuous-valued constraints. Simulation results demonstrate the superiority
of the proposed algorithms compared to other beam-hopping methods and verify
robustness in managing traffic demand imbalance.

</details>


### [44] [How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.03423)
*Isabella W. G. da Silva,Zahra Mobini,Hien Q. Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 论文研究了无小区大规模多输入多输出（CF-mMIMO）主动监控系统，提出了一种有效的信道状态信息（CSI）获取方案，并通过优化模式分配和干扰功率控制提高了监控性能。


<details>
  <summary>Details</summary>
Motivation: 研究目的是设计一种高效的监控系统，用于观察不可信发射机的传输或干扰不可信接收机的接收，以提升监控成功率。

Method: 利用上行和下行链路中的导频信号，通过最小均方误差（MMSE）估计有效信道，并提出了基于贝叶斯优化的联合模式分配和干扰功率控制优化方法。

Result: 数值结果表明，所提出的CF-mMIMO主动监控系统在CSI获取和优化方面显著优于基准方法，监控成功率超过0.8。

Conclusion: 提出的系统和方法在监控性能和鲁棒性方面表现出色，适用于不同天线数量和预编码方案。

Abstract: This paper studies a cell-free massive multiple-input multiple-output
(CF-mMIMO) proactive monitoring system in which multiple multi-antenna
monitoring nodes (MNs) are assigned to either observe the transmissions from an
untrusted transmitter (UT) or to jam the reception at the untrusted receiver
(UR). We propose an effective channel state information (CSI) acquisition
scheme for the monitoring system. In our approach, the MNs leverage the pilot
signals transmitted during the uplink and downlink phases of the untrusted link
and estimate the effective channels corresponding to the UT and UR via a
minimum mean-squared error (MMSE) estimation scheme. We derive new spectral
efficiency (SE) expressions for the untrusted link and the monitoring system.
For the latter, the SE is derived for two CSI availability cases at the central
processing unit (CPU); namely case-1: imperfect CSI knowledge at both MNs and
CPU, case-2: imperfect CSI knowledge at the MNs and no CSI knowledge at the
CPU. To improve the monitoring performance, we propose a novel joint mode
assignment and jamming power control optimization method to maximize the
monitoring success probability (MSP) based on the Bayesian optimization
framework. Numerical results show that (a) our CF-mMIMO proactive monitoring
system relying on the proposed CSI acquisition and optimization approach
significantly outperforms the considered benchmarks; (b) the MSP performance of
our CF-mMIMO proactive monitoring system is greater than 0.8, regardless of the
number of antennas at the untrusted nodes or the precoding scheme for the
untrusted transmission link.

</details>


### [45] [Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO](https://arxiv.org/abs/2508.03460)
*Anubhab Chowdhury,Sai Subramanyam Thoota,Erik G. Larsson*

Main category: eess.SP

TL;DR: 本文研究了动态时分双工（DTDD）的无蜂窝大规模多输入多输出（CF mMIMO）系统中的集成感知与通信（ISAC）。通过DTDD，系统能够同时服务上下行用户，并利用上下行AP进行感知任务。提出了集中式和分布式GLRT检测方法，分析了其最优性与复杂度的权衡，并提出了联合上行数据检测与目标RCS估计的统一框架。数值结果表明，GLRT对AP间干扰具有鲁棒性，且DTDD显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何在CF mMIMO系统中实现高效的ISAC，同时解决上下行用户共存和感知任务带来的挑战。

Method: 采用DTDD技术，利用上下行AP分别处理通信和感知任务；提出集中式和分布式GLRT检测方法；设计联合上行数据检测与RCS估计的框架；优化上下行信号处理方案。

Result: GLRT对AP间干扰具有鲁棒性；DTDD显著提升了系统性能，与传统TDD相比，上下行和速率翻倍。

Conclusion: DTDD和GLRT的结合为CF mMIMO ISAC系统提供了高效且鲁棒的解决方案，显著提升了系统性能。

Abstract: This paper studies integrated sensing and communication (ISAC) with dynamic
time division duplex (DTDD) cell-free (CF) massive multiple-input
multiple-output~(mMIMO) systems. DTDD enables the CF mMIMO system to
concurrently serve both uplink~(UL) and downlink~(DL) users with spatially
separated \emph{half-duplex~(HD)} access points~(APs) using the same
time-frequency resources. Further, to facilitate ISAC, the UL APs are utilized
for both UL data and target echo reception, while the DL APs jointly transmit
the precoded DL data streams and target signal. In this context, we present
centralized and distributed generalized likelihood-ratio tests~(GLRTs) for
target detection treating UL users' signals as sensing interference. We then
quantify the optimality and complexity trade-off between distributed and
centralized GLRTs and benchmark the respective estimators with the Bayesian
Cram\'er-Rao lower bound for target radar-cross section~(RCS). Then, we present
a unified framework for joint UL users' data detection and RCS estimation.
Next, for communication, we derive the signal-to-noise-plus-interference~(SINR)
optimal combiner accounting for the cross-link and radar interference for UL
data processing. In DL, we use regularized zero-forcing for the users and
propose two types of precoders for the target: one ``user-centric" that
nullifies the interference caused by the target signal to the DL users and one
``target-centric" based on the dominant eigenvector of the composite channel
between the target and the APs. Finally, numerical studies corroborate with our
theoretical findings and reveal that the \emph{GLRT is robust to inter-AP
interference, and DTDD doubles the $90\%$-likely sum UL-DL SE compared to
traditional TDD-based CF-mMIMO ISAC systems}; while using HD hardware.

</details>


### [46] [Decoding and Engineering the Phytobiome Communication for Smart Agriculture](https://arxiv.org/abs/2508.03584)
*Fatih Gulec,Hamdan Awan,Nigel Wallbridge,Andrew W. Eckford*

Main category: eess.SP

TL;DR: 论文提出利用通信工程视角理解植物生物群系通信，并将其与智能农业结合，通过分子和电生理信号建模，提出智能灌溉和精准农业应用。


<details>
  <summary>Details</summary>
Motivation: 解决现代农业面临的粮食需求增长、环境污染和水资源短缺等问题，通过通信理论推动农业科学发展。

Method: 提出多尺度框架建模植物生物群系为通信网络，结合分子通信和电生理信号实验验证。

Result: 展示了智能灌溉和精准农业等应用，结合ML/AI和生物纳米物联网技术。

Conclusion: 该框架为高效、可持续和环保的农业生产提供了新途径，但需解决实施挑战和研究问题。

Abstract: Smart agriculture applications, integrating technologies like the Internet of
Things and machine learning/artificial intelligence (ML/AI) into agriculture,
hold promise to address modern challenges of rising food demand, environmental
pollution, and water scarcity. Alongside the concept of the phytobiome, which
defines the area including the plant, its environment, and associated
organisms, and the recent emergence of molecular communication (MC), there
exists an important opportunity to advance agricultural science and practice
using communication theory. In this article, we motivate to use the
communication engineering perspective for developing a holistic understanding
of the phytobiome communication and bridge the gap between the phytobiome
communication and smart agriculture. Firstly, an overview of phytobiome
communication via molecular and electrophysiological signals is presented and a
multi-scale framework modeling the phytobiome as a communication network is
conceptualized. Then, how this framework is used to model electrophysiological
signals is demonstrated with plant experiments. Furthermore, possible smart
agriculture applications, such as smart irrigation and targeted delivery of
agrochemicals, through engineering the phytobiome communication are proposed.
These applications merge ML/AI methods with the Internet of Bio-Nano-Things
enabled by MC and pave the way towards more efficient, sustainable, and
eco-friendly agricultural production. Finally, the implementation challenges,
open research issues, and industrial outlook for these applications are
discussed.

</details>
