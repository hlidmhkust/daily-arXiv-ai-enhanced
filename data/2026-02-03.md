<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 28]
- [cs.IT](#cs.IT) [Total: 19]
- [eess.IV](#eess.IV) [Total: 18]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [JSR-GFNet: Jamming-to-Signal Ratio-Aware Dynamic Gating for Interference Classification in future Cognitive Global Navigation Satellite Systems](https://arxiv.org/abs/2602.00042)
*Zhihan Zeng,Hongyuan Shu,Kaihe Wang,Lu Chen,Amir Hussian,Yanjun Huang,Junchu Zhao,Yue Xiu,Zhongpei Zhang*

Main category: eess.SP

TL;DR: 提出JSR-GFNet多模态网络，结合IQ信号和STFT谱图，通过物理启发的动态门控机制自适应融合，解决GNSS干扰分类在低JSR下的性能下降和相位信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于时频分析和CNN的方法在低JSR下性能严重下降，且幅度谱图丢失相位信息导致"特征退化"，使频谱相似的信号（如高阶QAM与带限高斯噪声）难以区分。

Method: 提出JSR-GFNet多模态架构，结合相位敏感的复数IQ样本和STFT谱图。核心是物理启发的动态门控机制，基于统计信号描述符估计信号可靠性，动态重新加权复数ResNet（IQ流）和EfficientNet骨干（STFT流）的贡献。

Result: 在CGI-21数据集（模拟21种干扰类别）上的实验表明，JSR-GFNet在10-50 dB JSR范围内实现更高准确率。可解释性分析证实模型学习到物理直观策略：在噪声受限区域优先考虑频谱能量整合，在高SNR场景转向相位精度以解决调制模糊性。

Conclusion: 该框架为下一代航空航天导航安全提供鲁棒解决方案，通过自适应多模态融合克服传统方法的局限性，实现更准确的干扰分类。

Abstract: The transition toward cognitive global navigation satellite system (GNSS) receivers requires accurate interference classification to trigger adaptive mitigation strategies. However, conventional methods relying on Time-Frequency Analysis (TFA) and Convolutional Neural Networks (CNNs) face two fundamental limitations: severe performance degradation in low Jamming-to-Signal Ratio (JSR) regimes due to noise obscuration, and ``feature degeneracy'' caused by the loss of phase information in magnitude-only spectrograms. Consequently, spectrally similar signals -- such as high-order Quadrature Amplitude Modulation versus Band-Limited Gaussian Noise -- become indistinguishable. To overcome these challenges, this paper proposes the \textbf{JSR-Guided Fusion Network (JSR-GFNet)}. This multi-modal architecture combines phase-sensitive complex In-Phase/Quadrature (IQ) samples with Short-Time Fourier Transform (STFT) spectrograms. Central to this framework is a physics-inspired dynamic gating mechanism driven by statistical signal descriptors. Acting as a conditional controller, it autonomously estimates signal reliability to dynamically reweight the contributions of a Complex-Valued ResNet (IQ stream) and an EfficientNet backbone (STFT stream). To validate the model, we introduce the Comprehensive GNSS Interference (CGI-21) dataset, simulating 21 jamming categories including software-defined waveforms from aerial platforms. Extensive experiments demonstrate that JSR-GFNet achieves higher accuracy across the full 10--50 dB JSR spectrum. Notably, interpretability analysis confirms that the model learns a physically intuitive strategy: prioritizing spectral energy integration in noise-limited regimes while shifting focus to phase precision in high-SNR scenarios to resolve modulation ambiguities. This framework provides a robust solution for next-generation aerospace navigation security.

</details>


### [2] [Experimental Validation of SBFD ISAC in an FR3 Distributed SIMO Testbed](https://arxiv.org/abs/2602.00054)
*Bixing Yan,Kwadwo Mensah Obeng Afrane,Achiel Colpaert,Andre Kokkeler,Sofie Pollin,Yang Miao*

Main category: eess.SP

TL;DR: 提出了一种子带全双工ISAC系统，通过非重叠OFDM子带分配实现感知与通信的同时运行，在室内测试中验证了可行性，相比多频带基准节省了频谱资源。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信是未来无线网络的关键使能技术，需要解决感知与通信同时运行时的干扰问题，并提高频谱利用效率。

Method: 采用子带全双工架构，将2048个OFDM子载波划分为三个非重叠子带：两个用于感知（使用Zadoff-Chu序列），一个用于通信（使用QPSK）。构建了基于USRP X410设备的分布式测试平台，工作在6.8GHz频段，每信道20MHz带宽，形成1x3 SIMO节点。通过主机-服务器协调实现时间同步，无需外部时钟分发。

Result: 室内测量验证了SBFD ISAC系统的可行性：单站感知达到0.145m/s的速度分辨率；在NLoS条件下的通信BER为3.63e-3。相比需要三倍频谱的多频带基准，SBFD配置在保持可比速度估计精度的同时节省了资源。感知与通信的性能权衡主要取决于子载波分配策略而非相互干扰。

Conclusion: 子带全双工ISAC系统能够有效实现感知与通信的同时运行，通过合理的子载波分配策略可以在保持性能的同时显著提高频谱效率，为未来集成感知通信网络提供了可行的技术方案。

Abstract: Integrated sensing and communication (ISAC) is a key enabler for future radio networks. This paper presents a sub-band full-duplex (SBFD) ISAC system that assigns non-overlapping OFDM subbands to sensing and communication, enabling simultaneous operation with minimal interference. A distributed testbed with three SIMO nodes is implemented using USRP X410 devices operating at 6.8 GHz with 20 MHz bandwidth per channel. A total of 2048 OFDM subcarriers are partitioned into three subbands: two for sensing using Zadoff-Chu sequences and one for communication using QPSK. Each USRP transmits one subband while receiving signals across all three, forming a 1 x 3 SIMO node. Time synchronization is achieved through host-server coordination without external clock distribution. Indoor measurements, validated against MOCAP ground truth, confirm the feasibility of the SBFD ISAC system. The results demonstrate monostatic sensing with a velocity resolution of 0.145 m/s, and communication under NLoS conditions with a BER of 3.63e-3. Compared with a multiband benchmark requiring three times more spectrum, the SBFD configuration achieves comparable velocity estimation accuracy while conserving resources. The sensing and communication performance trade-off is determined by subcarrier allocation strategy rather than mutual interference.

</details>


### [3] [Dual-Tier IRS-Assisted Mid-Band 6G Mobile Networks: Robust Beamforming and User Association](https://arxiv.org/abs/2602.00431)
*Muddasir Rahim,Soumaya Cherkaoui*

Main category: eess.SP

TL;DR: 提出一种结合地面和空中智能可重构表面(IRS)的框架，用于6G网络FR3频段的资源分配，通过联合波束成形和用户关联优化解决大规模物联网连接问题。


<details>
  <summary>Details</summary>
Motivation: 物联网应用快速增长需要6G网络在FR3频段（7-15GHz）实现稳健的资源分配，特别是在严重视距阻塞环境下确保可靠连接。现有研究局限于地面IRS和毫米波/太赫兹频段，而FR3频段作为6G的"黄金频段"需要新的解决方案。

Method: 提出结合地面IRS(TIRS)和空中IRS(AIRS)的新型框架，将联合波束成形和用户关联(JBUA)问题建模为混合整数非线性规划(MINLP)，通过问题分解、迫零波束成形和稳定匹配算法求解。

Result: 综合仿真表明，该方法接近穷举搜索的性能，但复杂度显著降低，优于现有的贪婪和随机基准方法，为实际6G部署提供了可扩展的蓝图。

Conclusion: 该研究为6G FR3频段在挑战性环境下支持大规模物联网连接提供了有效的解决方案，结合地面和空中IRS的框架具有实际部署潜力。

Abstract: The rapid growth of Internet of Things (IoT) applications necessitates robust resource allocation in future sixth-generation (6G) networks, particularly at the upper mid-band (7-15 GHz, FR3). This paper presents a novel intelligent reconfigurable surface (IRS)-assisted framework combining terrestrial IRS (TIRS) and aerial IRS (AIRS) mounted on low-altitude platform stations, to ensure reliable connectivity under severe line-of-sight (LoS) blockages. Distinguishing itself from prior work restricted to terrestrial IRS and mmWave and THz bands, this work targets the FR3 spectrum, the so-called Golden Band for 6G. The joint beamforming and user association (JBUA) problem is formulated as a mixed-integer nonlinear program (MINLP), solved through problem decomposition, zero-forcing beamforming, and a stable matching algorithm. Comprehensive simulations show our method approaches exhaustive search performance with significantly lower complexity, outperforming existing greedy and random baselines. These results provide a scalable blueprint for real-world 6G deployments, supporting massive IoT connectivity in challenging environments.

</details>


### [4] [Reliable IoT Communications in 6G Non-Terrestrial Networks with Dual RIS](https://arxiv.org/abs/2602.00438)
*Muddasir Rahim,Soumaya Cherkaoui*

Main category: eess.SP

TL;DR: 提出一种RIS辅助的6G中上频段通信框架，采用双层RIS结构（地面RIS和高空平台RIS），通过联合波束成形、功率分配和物联网设备关联优化网络总速率


<details>
  <summary>Details</summary>
Motivation: 物联网应用需求增长推动6G网络需要更鲁棒的资源分配，特别是在严重视距阻塞情况下需要确保可靠连接

Method: 使用双层RIS结构（TRIS和HRIS），将网络总速率最大化问题建模为MINLP，采用分解方法：ZF技术优化波束成形矩阵，推导闭式功率分配表达式，基于可实现数据率提出稳定匹配算法进行设备-RIS关联

Result: 仿真表明所提方案性能接近穷举搜索但复杂度显著降低，始终优于贪婪搜索和随机搜索基准，收敛速度远快于穷举搜索方案

Conclusion: 提出的RIS辅助通信框架能有效解决6G网络中物联网应用的资源分配问题，在性能和复杂度之间取得良好平衡

Abstract: The increasing demand for Internet of Things (IoT) applications has accelerated the need for robust resource allocation in sixth-generation (6G) networks. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted upper mid-band communication framework. To ensure robust connectivity under severe line-of-sight (LoS) blockages, we use a two-tier RIS structure comprising terrestrial RISs (TRISs) and high-altitude platform station (HAPS)-mounted RISs (HRISs). To maximize network sum rate, we formulate a joint beamforming, power allocation, and IoT device association (JBPDA) problem as a mixed-integer nonlinear program (MINLP). The formulated MINLP problem is challenging to solve directly; therefore, we tackle it via a decomposition approach. The zero-forcing (ZF) technique is used to optimize the beamforming matrix, a closed-form expression for power allocation is derived, and a stable matching-based algorithm is proposed for device-RIS association based on achievable data rates. Comprehensive simulations demonstrate that the proposed scheme approaches the performance of exhaustive search (ES) while exhibiting substantially lower complexity, and it consistently outperforms greedy search (GS) and random search (RS) baselines. Moreover, the proposed scheme converges much faster than the ES scheme.

</details>


### [5] [Fronthaul-Efficient Distributed Cooperative 3D Positioning with Quantized Latent CSI Embeddings](https://arxiv.org/abs/2602.00664)
*Tong An,Jiwei Zhao,Jiayang Shi,Bin Zheng,Kai Yu,Maged Elkashlan,George K. Karagiannidis,Hongsheng Chen*

Main category: eess.SP

TL;DR: 提出基于学习的边云协同定位框架，在有限前传容量下通过神经网络压缩CSI，实现密集城市NLOS环境中的高精度3D定位


<details>
  <summary>Details</summary>
Motivation: 在密集城市NLOS环境中，多基站协同定位需要传输原始CSI，但前传开销过大限制了实际可扩展性，需要解决有限前传容量下的高效协同定位问题

Method: 采用边云协同架构：每个基站部署神经网络压缩本地CSI为量化表示（固定前传负载），CU联合处理多基站压缩CSI进行协同3D定位；采用两阶段训练策略：基站自监督本地训练和CU端到端联合训练

Result: 在3.5GHz 5G NR城市射线追踪场景（6个基站，20MHz带宽）中，平均3D定位误差0.48m，90%分位误差0.83m，前传负载降至无损CSI传输的6.25%，性能接近全CSI交换的协同定位

Conclusion: 提出的学习型边云协同定位框架在显著降低前传开销的同时，保持了接近全CSI交换的定位精度，为密集城市NLOS环境中的可扩展协同定位提供了有效解决方案

Abstract: High-precision three-dimensional (3D) positioning in dense urban non-line-of-sight (NLOS) environments benefits significantly from cooperation among multiple distributed base stations (BSs). However, forwarding raw CSI from multiple BSs to a central unit (CU) incurs prohibitive fronthaul overhead, which limits scalable cooperative positioning in practice. This paper proposes a learning-based edge-cloud cooperative positioning framework under limited-capacity fronthaul constraints. In the proposed architecture, a neural network is deployed at each BS to compress the locally estimated CSI into a quantized representation subject to a fixed fronthaul payload. The quantized CSI is transmitted to the CU, which performs cooperative 3D positioning by jointly processing the compressed CSI received from multiple BSs. The proposed framework adopts a two-stage training strategy consisting of self-supervised local training at the BSs and end-to-end joint training for positioning at the CU. Simulation results based on a 3.5~GHz 5G NR compliant urban ray-tracing scenario with six BSs and 20~MHz bandwidth show that the proposed method achieves a mean 3D positioning error of 0.48~m and a 90th-percentile error of 0.83~m, while reducing the fronthaul payload to 6.25% of lossless CSI forwarding. The achieved performance is close to that of cooperative positioning with full CSI exchange.

</details>


### [6] [CMANet: Channel-Masked Attention Network for Cooperative Multi-Base-Station 3D Positioning](https://arxiv.org/abs/2602.00696)
*Tong An,Huan Lu,Jiayang Shi,Kai Yu,Rongrong Zhu,Bin Zheng,Jiwei Zhao,Haibo Zhou*

Main category: eess.SP

TL;DR: CMANet：基于通道掩码注意力机制的多基站协作定位架构，利用原始CSI进行特征级融合，在5G NR城市环境中实现亚米级定位精度。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统需要实现无处不在的高精度定位，但在多径丰富的城市环境中仍面临挑战。通过利用CSI中嵌入的细粒度多径特征，可以实现更可靠和精确的定位。

Method: 提出CMANet多基站协作定位架构，采用通道掩码注意力（CMA）机制对原始CSI进行特征级融合。CMA编码器将物理基础的先验知识（每个基站的通道增益）注入注意力权重，强调可靠链路并抑制虚假多径。轻量级LSTM解码器将子载波视为序列，在频域积累证据以生成最终的3D位置估计。

Result: 在典型的5G NR兼容城市模拟中，CMANet实现中值误差小于0.5米，90%分位数误差小于1.0米，优于现有最先进基准方法。消融实验验证了CMA和频率积累的必要性。

Conclusion: CMANet可部署在边缘设备上，体现了面向多基站CSI定位的集成感知与通信（ISAC）对齐的协作范式，为城市环境中的高精度定位提供了有效解决方案。

Abstract: Achieving ubiquitous high-accuracy localization is crucial for next-generation wireless systems, yet remains challenging in multipath-rich urban environments. By exploiting the fine-grained multipath characteristics embedded in channel state information (CSI), more reliable and precise localization can be achieved. To address this, we present CMANet, a multi-BS cooperative positioning architecture that performs feature-level fusion of raw CSI using the proposed Channel Masked Attention (CMA) mechanism. The CMA encoder injects a physically grounded prior--per-BS channel gain--into the attention weights, thus emphasizing reliable links and suppressing spurious multipath. A lightweight LSTM decoder then treats subcarriers as a sequence to accumulate frequency-domain evidence into a final 3D position estimate. In a typical 5G NR-compliant urban simulation, CMANet achieves less than 0.5m median error and 1.0m 90th-percentile error, outperforming state-of-the-art benchmarks. Ablations verify the necessity of CMA and frequency accumulation. CMANet is edge-deployable and exemplifies an Integrated Sensing and Communication (ISAC)-aligned, cooperative paradigm for multi-BS CSI positioning.

</details>


### [7] [Comparative Analysis of Differential and Collision Entropy for Finite-Regime QKD in Hybrid Quantum Noisy Channels](https://arxiv.org/abs/2602.00705)
*Mouli Chakraborty,Subhash Chandra,Avishek Nag,Trung Q. Duong,Merouane Debbah,Anshu Mukherjee*

Main category: eess.SP

TL;DR: 该论文比较了混合量子信道中三种基本熵度量：微分熵、量子Rényi熵和量子碰撞熵，使用高斯混合模型建模混合量子噪声，并展示了在特定条件下这些熵度量的等价性及其在量子密钥分发中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子通信系统中不确定性度量的统一框架，混合量子噪声同时包含离散和连续变量噪声分量，需要建立不同熵度量之间的理论联系。

Method: 使用高斯混合模型统计建模混合量子噪声，构建并可视化3D概率景观中的点状熵函数，通过解析和数值计算比较微分熵、量子Rényi熵和量子碰撞熵。

Result: 在特定混合条件下，微分熵趋近于量子碰撞熵，这与α=2时的Rényi熵一致，建立了这些度量在混合量子信道框架下的理论和计算等价性。

Conclusion: 为混合量子通信系统的不确定性量化提供了统一视角，并将分析扩展到有限密钥QKD操作域，展示了10%近似阈值对窃听者成功概率和安全密钥率的显著影响。

Abstract: In this work, a comparative study between three fundamental entropic measures, differential entropy, quantum Renyi entropy, and quantum collision entropy for a hybrid quantum channel (HQC) was investigated, where hybrid quantum noise (HQN) is characterized by both discrete and continuous variables (CV) noise components. Using a Gaussian mixture model (GMM) to statistically model the HQN, we construct as well as visualize the corresponding pointwise entropic functions in a given 3D probabilistic landscape. When integrated over the relevant state space, these entropic surfaces yield values of the respective global entropy. Through analytical and numerical evaluation, it is demonstrated that the differential entropy approaches the quantum collision entropy under certain mixing conditions, which aligns with the Renyi entropy for order $α= 2$. Within the HQC framework, the results establish a theoretical and computational equivalence between these measures. This provides a unified perspective on quantifying uncertainty in hybrid quantum communication systems. Extending the analysis to the operational domain of finite key QKD, we demonstrated that the same $10\%$ approximation threshold corresponds to an order-of-magnitude change in Eves success probability and a measurable reduction in the secure key rate.

</details>


### [8] [Denoising deterministic networks using iterative Fourier transforms](https://arxiv.org/abs/2602.00790)
*H. Robert Frost*

Main category: eess.SP

TL;DR: 提出一种基于傅里叶变换的迭代方法(IterativeFT)，用于在存在边剪裁和高斯噪声的情况下识别确定性网络结构，通过交替进行2D离散傅里叶变换和稀疏化操作实现去噪。


<details>
  <summary>Details</summary>
Motivation: 现有网络去噪方法在处理同时存在边剪裁（缺失真实边）和高斯噪声（虚假边）的复杂情况时效果有限，需要一种能够同时过滤噪声边和恢复缺失真实边的鲁棒方法。

Method: IterativeFT方法：对网络邻接矩阵迭代执行前向和逆向2D离散傅里叶变换，在实域和频域表示中应用稀疏化操作，当实域稀疏模式稳定时算法收敛，实现去噪和结构恢复。

Result: 在Kautz、格网、树和二分网络等确定性模型上表现最佳，在格网和Kautz网络上优于对比方法，在树和二分网络上具有竞争力，能有效过滤噪声边并恢复缺失的真实边。

Conclusion: IterativeFT是一种有效的网络去噪方法，特别适用于同时存在边剪裁和高斯噪声的情况，在确定性网络结构识别方面优于现有的实域阈值、频域阈值、降秩重构和局部自适应稀疏化方法。

Abstract: We detail a novel Fourier-based approach (IterativeFT) for identifying deterministic network structure in the presence of both edge pruning and Gaussian noise. This technique involves the iterative execution of forward and inverse 2D discrete Fourier transforms on a target network adjacency matrix. The denoising ability of the method is achieved via the application of a sparsification operation to both the real and frequency domain representations of the adjacency matrix with algorithm convergence achieved when the real domain sparsity pattern stabilizes. To demonstrate the effectiveness of the approach, we apply it to noisy versions of several deterministic models including Kautz, lattice, tree and bipartite networks. For contrast, we also evaluate preferential attachment networks to illustrate the behavior on stochastic graphs. We compare the performance of IterativeFT against simple real domain and frequency domain thresholding, reduced rank reconstruction and locally adaptive network sparsification. Relative to the comparison network denoising approaches, the proposed IterativeFT method provides the best overall performance for lattice and Kuatz networks with competitive performance on tree and bipartite networks. Importantly, the InterativeFT technique is effective at both filtering noisy edges and recovering true edges that are missing from the observed network.

</details>


### [9] [Calibration-Free Induced Magnetic Field Indoor and Outdoor Positioning via Data-Driven Modeling](https://arxiv.org/abs/2602.00817)
*Qiushi Guo,Matthias Tschoepe,Mengxi Liu,Sizhen Bian,Paul Lukowicz*

Main category: eess.SP

TL;DR: 提出基于数据驱动的感应磁场定位框架，使用监督学习直接从磁场测量映射到空间坐标，无需环境特定校准，在室内外实现亚米级定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有磁场定位系统依赖解析场反演、手动校准或环境特定指纹识别，限制了可扩展性和可迁移性。需要一种更灵活、可扩展的定位方法。

Method: 采用数据驱动的感应磁场定位框架，使用监督学习（随机森林回归器）直接从磁场测量映射到空间坐标。引入方向不变特征表示实现旋转无关部署，无需显式环境特定校准。

Result: 在2D定位中实现亚20厘米精度，3D定位中实现亚30厘米精度。跨环境验证显示室内训练的模型无需重新训练即可泛化到室外环境。通过调整发射器间距平衡覆盖范围和精度。

Conclusion: 数据驱动的感应磁场定位是可扩展且可迁移的实际定位解决方案，能够捕捉非线性场相互作用和环境效应，为稳健定位提供新途径。

Abstract: Induced magnetic field (IMF)-based localization offers a robust alternative to wave-based positioning technologies due to its resilience to non-line-of-sight conditions, environmental dynamics, and wireless interference. However, existing magnetic localization systems typically rely on analytical field inversion, manual calibration, or environment-specific fingerprinting, limiting their scalability and transferability. This paper presents a data-driven IMF localization framework that directly maps induced magnetic field measurements to spatial coordinates using supervised learning, eliminating explicit environment-specific calibration. By replacing explicit field modeling with learning-based inference, the proposed approach captures nonlinear field interactions and environmental effects. An orientation-invariant feature representation enables rotation-independent deployment. The system is evaluated across multiple indoor environments and an outdoor deployment. Benchmarking against classical and deep learning baselines shows that a Random Forest regressor achieves sub-20 cm accuracy in 2D and sub-30 cm in 3D localization. Cross-environment validation demonstrates that models trained indoors generalize to outdoor environments without retraining. We further analyze scalability by varying transmitter spacing, showing that coverage and accuracy can be balanced through deployment density. Overall, this work demonstrates that data-driven IMF localization is a scalable and transferable solution for real-world positioning.

</details>


### [10] [mmWave Sensing for Detecting Movement Through Thermoplastic Masks During Radiation Therapy Treatment](https://arxiv.org/abs/2602.00917)
*Ali Kourani,Naveed A. Abbasi,Syeda Narjis Fatima,Katsuyuki Haneda,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 利用毫米波传感技术实现放疗中透过热塑面罩的运动检测，为实时运动跟踪和误差校正奠定基础


<details>
  <summary>Details</summary>
Motivation: 放疗精度依赖于患者固定系统，但热塑面罩无法完全消除细微的自主和非自主运动（如下颌移动、深呼吸、眨眼等）。现有运动跟踪方法存在局限：光学系统需要视线清晰且仅能检测表面运动，X射线跟踪则会引入额外电离辐射。

Method: 研究使用低功率、非电离的毫米波（mmWave）传感进行透面罩运动检测。在28-38 GHz范围内表征热塑面罩材料的射频特性，使用以28 GHz为中心、1 GHz带宽进行运动检测。采用频域系统，在定制消声室中使用喇叭天线，捕捉传输射频波在响应细微头部和面部运动时的幅度和相位变化。

Result: 成功实现了透过热塑面罩的运动检测，验证了毫米波传感在放疗运动跟踪中的可行性。为未来实时透面罩运动跟踪以及与多天线系统和机器学习集成进行误差校正奠定了基础。

Conclusion: 毫米波传感技术为解决放疗中患者细微运动跟踪问题提供了有前景的非电离解决方案，为未来集成实时跟踪和误差校正系统铺平了道路。

Abstract: Precision in radiation therapy relies on immobilization systems that limit patient motion. Thermoplastic masks are commonly used for this purpose, but subtle voluntary and involuntary movements such as jaw shifts, deep breathing, or eye squinting may still compromise treatment accuracy. Existing motion tracking methods are limited: optical systems require a clear line of sight and only detect surface motion, while X-ray-based tracking introduces additional ionizing radiation. This study explores the use of low-power, non-ionizing millimeter-wave (mmWave) sensing for through-mask motion detection. We characterize the RF properties of thermoplastic mask material in the 28-38 GHz range and perform motion detection using a 1 GHz bandwidth centered at 28 GHz. We use a frequency-domain system with horn antennas in a custom-built anechoic chamber to capture changes in the amplitude and phase of transmitted RF waves in response to subtle head and facial movements. These findings lay groundwork for future real-time through-mask motion tracking and future integration with multi-antenna systems and machine learning for error correction during radiotherapy.

</details>


### [11] [Channel Modeling and Experimental Validation of Odor-Based Molecular Communication Systems](https://arxiv.org/abs/2602.01091)
*Ahmet B. Kilic,Fatih E. Bilgen,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 提出有界和无界气味分子通信通道的数学模型，并通过实验验证其准确性


<details>
  <summary>Details</summary>
Motivation: 气味分子通信是实现万物互联愿景的重要技术，但目前缺乏准确描述不同环境中粒子传播的全面通道模型，现有研究缺乏理论建模与实验验证相结合的整体方法

Method: 提出有界和无界OMC通道的数学框架，开发新型实验测试平台，进行广泛性能分析以验证模型准确性

Result: 理论推导与实验数据之间表现出强相关性，为未来端到端OMC系统的设计和分析提供了坚实基础

Conclusion: 通过整合理论建模与实验验证，填补了气味分子通信通道建模的空白，为OMC系统的实际部署提供了可靠的理论和实验基础

Abstract: Odor-based Molecular Communication (OMC) employs odor molecules to convey information, contributing to the realization of the Internet of Everything (IoE) vision. Despite this, the practical deployment of OMC systems is currently limited by the lack of comprehensive channel models that accurately characterize particle propagation in diverse environments. While existing literature explores various aspects of molecular transport, a holistic approach that integrates theoretical modeling with experimental validation for bounded channels remains underdeveloped. In this paper, we address this gap by proposing mathematical frameworks for both bounded and unbounded OMC channels. To verify the accuracy of the proposed models, we develop a novel experimental testbed and conduct an extensive performance analysis. Our results demonstrate a strong correlation between the theoretical derivations and experimental data, providing a robust foundation for the design and analysis of future end-to-end OMC systems.

</details>


### [12] [Digital and Hybrid Precoding and RF Chain Selection Designs for Energy Efficient Multi-User MIMO-OFDM ISAC Systems](https://arxiv.org/abs/2602.01121)
*Po-Chun Kang,Ming-Chun Lee,Tzu-Chien Chiu,Ting-Yao Kuo,Ta-Sung Lee*

Main category: eess.SP

TL;DR: 该论文研究了多用户MIMO-OFDM ISAC系统的能效优化，通过联合预编码和射频链选择，为全数字和混合预编码架构提出能效最大化设计方案。


<details>
  <summary>Details</summary>
Motivation: 现有MIMO-OFDM ISAC研究大多关注性能提升，而忽略了发射功率和射频电路功耗对能效的影响，这一研究空白需要填补。

Method: 提出基于能效最大化的联合预编码和射频链选择优化问题，为全数字和混合预编码架构设计高效优化算法，并分析计算复杂度和收敛性。

Result: 仿真结果表明，相比现有方案，所提方法在ISAC系统的能效-感知权衡方面取得显著改进。

Conclusion: 通过联合优化预编码和射频链激活，能够有效提升MIMO-OFDM ISAC系统的能效，同时满足感知性能要求，为实际系统设计提供重要参考。

Abstract: Using multiple-input multiple-output (MIMO) with orthogonal frequency division multiplexing (OFDM) for integrated sensing and communication (ISAC) has attracted considerable attention in recent years. While most existing works focus on improving MIMO-OFDM ISAC performance, the impact of transmit power and radio-frequency (RF) circuit power consumption on energy efficiency (EE) remains relatively underexplored. To address this gap, this paper investigates joint precoding and RF chain selection for multi-user MIMO-OFDM ISAC systems, and develops energy-efficient designs for both fully digital and hybrid precoding architectures through the joint optimization of precoding and RF-chain activation. Specifically, we first formulate a novel EE maximization problem subject to sensing performance constraints. Then, efficient optimization algorithms are proposed for both architectures, together with analyses of their computational complexity and convergence behavior. Building on the proposed approaches, spectral efficiency-power consumption tradeoff designs are also provided. Simulation results demonstrate that, compared with existing schemes, the proposed approaches achieve significant improvements in the EE-sensing tradeoff for ISAC systems.

</details>


### [13] [Generative AI in Signal Processing Education: An Audio Foundation Model Based Approach](https://arxiv.org/abs/2602.01249)
*Muhammad Salman Khan,Ahmad Ullah,Siddique Latif,Junaid Qadir*

Main category: eess.SP

TL;DR: SPEduAFM是一个专为信号处理教育设计的音频基础模型概念，旨在通过生成式AI技术将传统信号处理原理与创新应用相结合，提升教育体验。


<details>
  <summary>Details</summary>
Motivation: 音频基础模型作为生成式AI的一个专门类别，有潜力通过整合语音增强、去噪、源分离、特征提取等核心应用来革新信号处理教育，将抽象概念转化为实践体验。

Method: 提出SPEduAFM概念框架，通过案例研究展示AFM在教育中的应用，包括自动讲座转录、交互式演示和包容性学习工具，强调动态实时听觉交互促进体验式学习。

Result: 展示了AFM在教育中的多种潜在应用场景，提出了一个将传统信号处理教学与生成式AI创新相结合的前瞻性愿景。

Conclusion: SPEduAFM作为一个前瞻性概念，旨在激发生成式AI在工程教育中的更广泛采用，通过解决伦理、可解释性和定制化等挑战，提升课堂内外的可访问性、参与度和创新性。

Abstract: Audio Foundation Models (AFMs), a specialized category of Generative AI (GenAI), have the potential to transform signal processing (SP) education by integrating core applications such as speech and audio enhancement, denoising, source separation, feature extraction, automatic classification, and real-time signal analysis into learning and research. This paper introduces SPEduAFM, a conceptual AFM tailored for SP education, bridging traditional SP principles with GenAI-driven innovations. Through an envisioned case study, we outline how AFMs can enable a range of applications, including automated lecture transcription, interactive demonstrations, and inclusive learning tools, showcasing their potential to transform abstract concepts into engaging, practical experiences. This paper also addresses challenges such as ethics, explainability, and customization by highlighting dynamic, real-time auditory interactions that foster experiential and authentic learning. By presenting SPEduAFM as a forward-looking vision, we aim to inspire broader adoption of GenAI in engineering education, enhancing accessibility, engagement, and innovation in the classroom and beyond.

</details>


### [14] [Mismatch Analysis and Cooperative Calibration of Array Beam Patterns for ISAC Systems](https://arxiv.org/abs/2602.01293)
*Hui Chen,Mengting Li,Alireza Pourafzal,Huiping Huang,Yu Ge,Sigurd Sandor Petersen,Ming Shen,George C. Alexandropoulos,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出了一种用于ISAC系统的阵列波束图校准方法，通过角度估计误差而非波束图相似性来评估校准质量，并设计了协作校准框架，显著降低了角度估计误差。


<details>
  <summary>Details</summary>
Motivation: ISAC系统中，几何误差和硬件损伤会导致模型失配，从而降低感知性能。现有校准方法主要关注波束图相似性，而非实际的角度估计性能。

Method: 1) 提出基于角度估计误差而非波束图相似性的新性能指标；2) 设计可微分的损失函数；3) 建立协作校准框架，允许多个用户设备基于本地数据迭代优化波束图并协作更新全局校准参数。

Result: 在真实无回波室测量的波束图数据上验证：2D校准场景中角度估计误差从1.01°降至0.11°；3D校准场景中从5.19°降至0.86°。

Conclusion: 所提出的校准方法能有效提升ISAC系统的角度估计精度，通过关注实际感知性能而非波束图相似性，实现了显著的性能改进。

Abstract: Integrated sensing and communication (ISAC) is a key technology for enabling a wide range of applications in future wireless systems. However, the sensing performance is often degraded by model mismatches caused by geometric errors (e.g., position and orientation) and hardware impairments (e.g., mutual coupling and amplifier non-linearity). This paper focuses on the angle estimation performance with antenna arrays and tackles the critical challenge of array beam pattern calibration for ISAC systems. To assess calibration quality from a sensing perspective, a novel performance metric that accounts for angle estimation error, rather than beam pattern similarity, is proposed and incorporated into a differentiable loss function. Additionally, a cooperative calibration framework is introduced, allowing multiple user equipments to iteratively optimize the beam pattern based on the proposed loss functions and local data, and collaboratively update global calibration parameters. The proposed models and algorithms are validated using real-world beam pattern measurements collected in an anechoic chamber. Experimental results show that the angle estimation error can be reduced from {$\textbf{1.01}^\circ$} to $\textbf{0.11}^\circ$ in 2D calibration scenarios, and from $\textbf{5.19}^\circ$ to $\textbf{0.86}^\circ$ in 3D calibration ones.

</details>


### [15] [Approximating Univariate Factored Distributions via Message-Passing Algorithms](https://arxiv.org/abs/2602.01377)
*Zilu Zhao,Dirk Slock*

Main category: eess.SP

TL;DR: 该论文提出了两种结合期望传播(EP)和先前技术的消息传递算法，用于近似单变量因子化分布，特别是高斯混合模型(GMM)的乘积，以解决传统方法中指数级复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 高斯混合模型在通信系统中广泛应用，但多个GMM的乘积会导致组件数量指数增长，使得计算变得不可行。虽然可以通过信念传播(BP)算法进行近似，但期望传播(EP)在处理非可积信念时可能失败，需要新的方法来有效近似单变量因子化分布。

Method: 论文提出了两种方法：1) 基于变量复制和高斯信念传播(VDBP)的算法，通过构建多变量测量模型，然后应用高斯BP将全局推理问题转化为局部问题；2) 结合期望传播(EP)和先前处理非可积信念技术的两种新方法，利用EP的投影操作确保中间函数属于期望的分布族。

Result: 提出的方法能够有效近似单变量因子化概率密度函数，特别是高斯混合模型的乘积，避免了传统方法中组件数量的指数增长问题，同时解决了EP在处理非可积信念时的失败问题。

Conclusion: 通过结合期望传播和先前处理非可积信念的技术，论文成功开发了两种有效的消息传递算法，能够近似单变量因子化分布，为通信系统中的联合估计和检测问题提供了可行的解决方案。

Abstract: Gaussian Mixture Models (GMMs) commonly arise in communication systems, particularly in bilinear joint estimation and detection problems. Although the product of GMMs is still a GMM, as the number of factors increases, the number of components in the resulting product GMM grows exponentially. To obtain a tractable approximation for a univariate factored probability density function (PDF), such as a product of GMMs, we investigate iterative message-passing algorithms. Based on Belief Propagation (BP), we propose a Variable Duplication and Gaussian Belief Propagation (VDBP)-based algorithm. The key idea of VDBP is to construct a multivariate measurement model whose marginal posterior is equal to the given univariate factored PDF. We then apply Gaussian BP (GaBP) to transform the global inference problem into local ones. Expectation propagation (EP) is another branch of message passing algorithms. In addition to converting the global approximation problem into local ones, it features a projection operation that ensures the intermediate functions (messages) belong to a desired family. Due to this projection, EP can be used to approximate the factored PDF directly. However, even if every factor is integrable, the division operation in EP may still cause the algorithm to fail when the mean and variance of a non-integrable belief are required. Therefore, this paper proposes two methods that combine EP with our previously proposed techniques for handling non-integrable beliefs to approximate univariate factored distributions.

</details>


### [16] [Visible Light Positioning With Lamé Curve LEDs: A Generic Approach for Camera Pose Estimation](https://arxiv.org/abs/2602.01577)
*Wenxuan Pan,Yang Yang,Dong Wei,Zhiyu Zhu,Jintao Wang,Huan Wu,Yao Nie*

Main category: eess.SP

TL;DR: 提出LC-VLP算法，利用Lamé曲线统一表示不同LED形状，实现异构LED场景下的相机姿态估计，相比现有方法显著降低定位误差。


<details>
  <summary>Details</summary>
Motivation: 现有基于LED形状特征的可见光定位方法通常局限于单一LED几何形状，在异构LED形状场景中会失效，需要一种通用的解决方案。

Method: 使用Lamé曲线作为LED形状的统一表示，通过可见光通信传输曲线参数，构建LED数据库，将在线定位建模为非线性最小二乘问题，并开发FreePnP算法提供可靠初始化。

Result: 仿真显示LC-VLP在圆形和矩形LED场景中优于现有方法，位置误差降低40%以上，旋转误差降低25%；实验显示平均定位精度小于4厘米。

Conclusion: LC-VLP算法通过Lamé曲线统一表示LED形状，解决了异构LED场景下的相机姿态估计问题，实现了高精度、低成本的室内定位。

Abstract: Camera-based visible light positioning (VLP) is a promising technique for accurate and low-cost indoor camera pose estimation (CPE). To reduce the number of required light-emitting diodes (LEDs), advanced methods commonly exploit LED shape features for positioning. Although interesting, they are typically restricted to a single LED geometry, leading to failure in heterogeneous LED-shape scenarios. To address this challenge, this paper investigates Lamé curves as a unified representation of common LED shapes and proposes a generic VLP algorithm using Lamé curve-shaped LEDs, termed LC-VLP. In the considered system, multiple ceiling-mounted Lamé curve-shaped LEDs periodically broadcast their curve parameters via visible light communication, which are captured by a camera-equipped receiver. Based on the received LED images and curve parameters, the receiver can estimate the camera pose using LC-VLP. Specifically, an LED database is constructed offline to store the curve parameters, while online positioning is formulated as a nonlinear least-squares problem and solved iteratively. To provide a reliable initialization, a correspondence-free perspective-\textit{n}-points (FreeP\textit{n}P) algorithm is further developed, enabling approximate CPE without any pre-calibrated reference points. The performance of LC-VLP is verified by both simulations and experiments. Simulations show that LC-VLP outperforms state-of-the-art methods in both circular- and rectangular-LED scenarios, achieving reductions of over 40% in position error and 25% in rotation error. Experiments further show that LC-VLP can achieve an average position accuracy of less than 4 cm.

</details>


### [17] [Synthesized-Isotropic Narrowband Channel Parameter Extraction from Angle-Resolved Wideband Channel Measurements](https://arxiv.org/abs/2602.01646)
*Minseok Kim,Masato Yomoda*

Main category: eess.SP

TL;DR: 本文重新审视了从角度分辨宽带测量中计算路径增益的技术挑战，重点解决了非正交扫描波束导致的功率估计偏差问题，提出了波束累积校正因子框架。


<details>
  <summary>Details</summary>
Motivation: 在毫米波和太赫兹频段使用天线阵列或机械转向高增益天线进行角度分辨信道探测时，测量响应中嵌入了辐射方向图效应。为了提取天线无关的大尺度信道参数（如路径损耗、延迟扩展和角度扩展），需要对这些效应进行适当补偿。

Method: 首先将合成各向同性窄带功率统一表示为矩阵形式，然后引入波束累积校正因子，包括偏移平均变体以减轻离网角度引起的扇形效应。该框架通过信道模型仿真和154GHz走廊测量进行验证。

Result: 提出的框架能够有效补偿非正交扫描波束导致的功率估计偏差，通过仿真和实际测量验证了方法的有效性。

Conclusion: 本文为解决角度分辨宽带测量中路径增益计算的技术挑战提供了系统框架，特别是针对非正交扫描波束导致的功率估计偏差问题，提出的校正方法能够获得更准确的全向等效功率估计。

Abstract: Angle-resolved channel sounding using antenna arrays or mechanically steered high-gain antennas is widely employed at millimeter-wave and terahertz bands. To extract antenna-independent large-scale channel parameters such as path loss, delay spread, and angular spread, the radiation-pattern effects embedded in the measured responses must be properly compensated. This paper revisits the technical challenges of path-gain calculation from angle-resolved wideband measurements, with emphasis on angular-domain power integration where the scan beams are inherently non-orthogonal and simple power summation leads to biased omni-equivalent power estimates. We first formulate the synthesized-isotropic narrowband power in a unified matrix form and introduce a beam-accumulation correction factor, including an offset-averaged variant to mitigate scalloping due to off-grid angles. The proposed framework is validated through simulations using channel models and 154~GHz corridor measurements.

</details>


### [18] [Resolution-Aliasing Trade-off in Near-Field Localisation](https://arxiv.org/abs/2602.01947)
*Baptiste Sambon,Gilles Monnoyer,Luc Vandendorpe,Claude Oestges*

Main category: eess.SP

TL;DR: 该论文提出了一个统一框架来联合表征近场定位中的分辨率和混叠效应，通过局部啁啾空间频率概念分析阵列几何与采样密度对空间带宽的影响，为XL-MIMO阵列设计提供指导。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统在近场操作下为精确定位提供了新自由度，但密集阵列不切实际。稀疏或分布式阵列可降低硬件复杂度，但亚奈奎斯特空间采样会在定位模糊函数中引入混叠伪影，需要研究分辨率与混叠之间的权衡关系。

Method: 引入局部啁啾空间频率概念，推导阵列几何和采样密度与接收场空间带宽关系的解析表达式。提出两个几何工具：关键天线单元(CAEs)和非贡献区(NCZ)，直观识别各天线对分辨率和/或混叠的贡献。

Result: 分析表明分辨率和混叠并非总是严格耦合，例如增加阵列孔径可提高分辨率而不一定加剧混叠。为设计在分辨率和混叠之间达到最佳平衡的近场阵列提供了实用指导。

Conclusion: 该框架为设计支持高效XL-MIMO部署的近场阵列提供了理论基础，通过理解分辨率和混叠的权衡关系，可优化阵列几何和采样密度，在保持高分辨率的同时控制混叠效应。

Abstract: Extremely Large-scale MIMO (XL-MIMO) systems operating in Near-Field (NF) introduce new degrees of freedom for accurate source localisation, but make dense arrays impractical. Sparse or distributed arrays can reduce hardware complexity while maintaining high resolution, yet sub-Nyquist spatial sampling introduces aliasing artefacts in the localisation ambiguity function. This paper presents a unified framework to jointly characterise resolution and aliasing in NF localisation and study the trade-off between the two. Leveraging the concept of local chirp spatial frequency, we derive analytical expressions linking array geometry and sampling density to the spatial bandwidth of the received field. We introduce two geometric tools--Critical Antenna Elements (CAEs) and the Non-Contributive Zone (NCZ)--to intuitively identify how individual antennas contribute to resolution and/or aliasing. Our analysis reveals that resolution and aliasing are not always strictly coupled, e.g., increasing the array aperture can improve resolution without necessarily aggravating aliasing. These results provide practical guidelines for designing NF arrays that optimally balance resolution and aliasing, supporting efficient XL-MIMO deployment.

</details>


### [19] [Uncertainty-Weighted Multi-Task CNN for Joint DoA and Rain-Rate Estimation Under Rain-Induced Array Distortions](https://arxiv.org/abs/2602.01961)
*Chenyang Yan,Ruonan Yang,Shunqiao Sun,Mats Bengtsson*

Main category: eess.SP

TL;DR: 提出一种基于多任务深度CNN的方法，用于联合估计到达方向(DoA)和降雨率，通过共享特征提取器和任务特定头部，在降雨引起的乘性失真下实现准确估计。


<details>
  <summary>Details</summary>
Motivation: 在降雨引起的乘性失真条件下，传统的DoA估计方法性能会下降。降雨率会影响阵列接收信号的空间相关性，因此需要同时估计DoA和降雨率以提高估计精度。

Method: 基于波前波动模型推导角度相关协方差公式，生成训练数据。将DoA估计建模为离散角度网格上的多标签分类问题，降雨率估计为多分类问题。提出多任务深度CNN架构，包含共享特征提取器和两个任务特定头部，使用不确定性加权目标函数自动平衡两个损失。

Result: 在双源场景的数值实验中，所提网络在中等至高信噪比下比经典基线方法具有更低的DoA均方根误差，并能提供准确的降雨率分类。

Conclusion: 多任务深度学习框架能有效联合估计DoA和降雨率，在降雨引起的乘性失真条件下优于传统方法，为恶劣天气条件下的阵列信号处理提供了新思路。

Abstract: We investigate joint direction-of-arrival (DoA) and rain-rate estimation for a uniform linear array operating under rain-induced multiplicative distortions. Building on a wavefront fluctuation model whose spatial correlation is governed by the rain-rate, we derive an angle-dependent covariance formulation and use it to synthesize training data. DoA estimation is cast as a multi-label classification problem on a discretized angular grid, while rain-rate estimation is formulated as a multi-class classification task. We then propose a multi-task deep CNN with a shared feature extractor and two task-specific heads, trained using an uncertainty-weighted objective to automatically balance the two losses. Numerical results in a two-source scenario show that the proposed network achieves lower DoA RMSE than classical baselines and provides accurate rain-rate classification at moderate-to-high SNRs.

</details>


### [20] [Obstacle Detection at Level Crossings under Adverse Weather Conditions -- A Survey](https://arxiv.org/abs/2602.01974)
*Chenyang Yan,Mats Bengtsson*

Main category: eess.SP

TL;DR: 本文综述了铁路道口障碍物检测的传感器技术与融合策略，重点分析恶劣天气下的性能挑战及多传感器融合解决方案。


<details>
  <summary>Details</summary>
Motivation: 铁路道口事故仍然是现代铁路系统的重大安全隐患，特别是在恶劣天气条件下传感器性能下降时。需要开发更可靠、环境适应性强的检测系统来提升铁路安全。

Method: 1. 综述了各种传感器技术（感应线圈、摄像头、雷达、激光雷达）的工作原理、优缺点及天气影响
2. 分析了针对天气影响的缓解策略，包括信号增强和基于机器学习的去噪方法
3. 系统回顾了多传感器融合方法，包括数据级、特征级和决策级融合架构

Result: 1. 各种传感器在恶劣天气下各有局限性：感应线圈依赖材料、摄像头受能见度影响、雷达和激光雷达分辨率有限
2. 多传感器融合能整合互补信息，提高检测系统的可靠性和容错能力
3. 机器学习方法能有效处理天气引起的信号退化问题

Conclusion: 未来研究方向包括：自适应融合算法、实时处理管道、天气弹性数据集，以支持智能、故障安全的铁路道口检测系统部署。

Abstract: Level crossing accidents remain a significant safety concern in modern railway systems, particularly under adverse weather conditions that degrade sensor performance. This review surveys state-of-the-art sensor technologies and fusion strategies for obstacle detection at railway level crossings, with a focus on robustness, detection accuracy, and environmental resilience. Individual sensors such as inductive loops, cameras, radar, and LiDAR offer complementary strengths but involve trade-offs, including material dependence, reduced visibility, and limited resolution in harsh environments. We analyze each modality's working principles, weather-induced vulnerabilities, and mitigation strategies, including signal enhancement and machine-learning-based denoising. We further review multi-sensor fusion approaches, categorized as data-level, feature-level, and decision-level architectures, that integrate complementary information to improve reliability and fault tolerance. The survey concludes with future research directions, including adaptive fusion algorithms, real-time processing pipelines, and weather-resilient datasets to support the deployment of intelligent, fail-safe detection systems for railway safety.

</details>


### [21] [Silhouette Score Efficient Radio Frequency Fingerprint Feature Extraction](https://arxiv.org/abs/2602.02065)
*Xuan Yang,Dongming Li,Yi Lou,Xianglin Fan*

Main category: eess.SP

TL;DR: 本文建立了射频指纹特征提取的统一理论分析框架，提出了一种基于预编码的通道鲁棒特征提取方法，无需信道估计即可提高轮廓分数。


<details>
  <summary>Details</summary>
Motivation: 射频指纹识别技术易受信道变化影响，现有方法多依赖实验比较而非理论分析，缺乏理论指导阻碍了通道鲁棒特征提取方法的发展。

Method: 1) 使用轮廓分数作为评估指标，通过泰勒级数展开获得各种RFF特征提取方法的理论性能；2) 在认证设备处计算频域接收信号的倒数来减轻信道效应；3) 在确定性信道、独立同分布随机信道和非独立同分布随机信道三种场景下比较不同方法。

Result: 仿真和实验结果表明：轮廓分数是评估分类准确性的有效指标；提出的基于预编码的通道鲁棒RFF特征提取方法在信道变化下实现了最高的轮廓分数和分类准确率。

Conclusion: 建立了射频指纹特征提取的统一理论分析框架，提出的预编码方法显著提升了通道鲁棒性，为通道鲁棒RFF特征提取提供了理论指导。

Abstract: Radio frequency fingerprint (RFF) identification technology, which exploits relatively stable hardware imperfections, is highly susceptible to constantly changing channel effects. Although various channel-robust RFF feature extraction methods have been proposed, they predominantly rely on experimental comparisons rather than theoretical analyses. This limitation hinders the progress of channel-robust RFF feature extraction and impedes the establishment of theoretical guidance for its design. In this paper, we establish a unified theoretical performance analysis framework for different RFF feature extraction methods using the silhouette score as an evaluation metric, and propose a precoding-based channel-robust RFF feature extraction method that enhances the silhouette score without requiring channel estimation. First, we employ the silhouette score as an evaluation metric and obtain the theoretical performance of various RFF feature extraction methods using the Taylor series expansion. Next, we mitigate channel effects by computing the reciprocal of the received signal in the frequency domain at the device under authentication. We then compare these methods across three different scenarios: the deterministic channel scenario, the independent and identically distributed (i.i.d.) stochastic channel scenario, and the non-i.i.d. stochastic channel scenario. Finally, simulation and experimental results demonstrate that the silhouette score is an efficient metric to evaluate classification accuracy. Furthermore, the results indicate that the proposed precoding-based channel-robust RFF feature extraction method achieves the highest silhouette score and classification accuracy under channel variations.

</details>


### [22] [Neurophysiological effects of museum modalities on emotional engagement with real artworks](https://arxiv.org/abs/2602.02086)
*Chen Feng,Sébastien Lugan,Karine Lasaracina,Midori Sugaya,Benoît Macq*

Main category: eess.SP

TL;DR: 数字解说内容（沉浸式投影和显示屏视频）影响艺术观赏时的情感参与风格而非参与量，不同模态产生不同的脑电参与模式


<details>
  <summary>Details</summary>
Motivation: 博物馆越来越多地使用数字内容帮助观众理解艺术品，但人们对这些形式如何影响艺术体验中的情感参与知之甚少，需要研究数字解说内容如何调节艺术观赏时的参与度

Method: 在博物馆现场进行脑电图研究，参与者体验三种模式：直接观看勃鲁盖尔画作、180°沉浸式解说投影、常规显示屏解说视频，使用睁眼基线进行Z标准化对比，提取前额脑电标记（动机取向、内部参与、感知驱动、唤醒）

Result: 不同模态产生特定的参与模式：显示屏解说视频引发高唤醒和快速波段活动，沉浸式投影促进平静、存在导向的专注，原作反映内部调节的参与

Conclusion: 数字解说内容影响参与风格而非参与量，为新的多模态感知方法铺平道路，使博物馆能够优化解说媒体的模态和内容

Abstract: Museums increasingly rely on digital content to support visitors' understanding of artworks, yet little is known about how these formats shape the emotional engagement that underlies meaningful art experiences. This research presents an in-situ EEG study on how digital interpretive content modulate engagement during art viewing. Participants experienced three modalities: direct viewing of a Bruegel painting, a 180° immersive interpretive projection, and a regular, display-based interpretive video. Frontal EEG markers of motivational orientation, internal involvement, perceptual drive, and arousal were extracted using eyes-open baselines and Z-normalized contrasts. Results show modality-specific engagement profiles: display-based interpretive video induced high arousal and fast-band activity, immersive projections promoted calm, presence-oriented absorption, and original artworks reflected internally regulated engagement. These findings, relying on lightweight EEG sensing in an operational cultural environment, suggest that digital interpretive content affects engagement style rather than quantity. This paves the way for new multimodal sensing approaches and enables museums to optimize the modalities and content of their interpretive media.

</details>


### [23] [RIS-Aided Wireless Amodal Sensing for Single-View 3D Reconstruction](https://arxiv.org/abs/2602.02148)
*Yuhan Wang,Haobo Zhang,Qingyu Liu,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 提出了一种基于可重构智能表面(RIS)的无线非模态感知方案，通过RIS增强空间分辨率并绕过障碍物，结合生成学习模型重建完整物体形状，相比传统方案减少至少56.73%的重建误差。


<details>
  <summary>Details</summary>
Motivation: 非模态感知对于现实世界感知应用至关重要，但无线系统由于空间分辨率低导致感知数据稀疏，在复杂遮挡环境中问题更加严重。需要一种能够增强空间分辨率并绕过障碍物的解决方案。

Method: 1) 提出RIS辅助的无线非模态感知方案，利用大规模RIS增强空间分辨率并创建绕过障碍物的反射路径；2) 使用生成学习模型从RIS视角的感知数据重建完整形状；3) 开发误差预测模型学习RIS相位偏移与非模态感知精度之间的映射关系，并基于此优化RIS相位偏移。

Result: 在基准数据集上的实验结果表明，在相同RIS配置数量下，该方法相比传统方案至少减少了56.73%的重建误差。

Conclusion: RIS辅助的无线非模态感知方案通过增强空间分辨率和绕过障碍物，结合生成学习模型和优化的相位偏移策略，显著提高了非模态感知的准确性，为解决无线感知数据稀疏问题提供了有效方案。

Abstract: Amodal sensing is critical for various real-world sensing applications because it can recover the complete shapes of partially occluded objects in complex environments. Among various amodal sensing paradigms, wireless amodal sensing is a potential solution due to its advantages of environmental robustness, privacy preservation, and low cost. However, the sensing data obtained by wireless system is sparse for shape reconstruction because of the low spatial resolution, and this issue is further intensified in complex environments with occlusion. To address this issue, we propose a Reconfigurable Intelligent Surface (RIS)-aided wireless amodal sensing scheme that leverages a large-scale RIS to enhance the spatial resolution and create reflection paths that can bypass the obstacles. A generative learning model is also employed to reconstruct the complete shape based on the sensing data captured from the viewpoint of the RIS. In such a system, it is challenging to optimize the RIS phase shifts because the relationship between RIS phase shifts and amodal sensing accuracy is complex and the closed-form expression is unknown. To tackle this challenge, we develop an error prediction model that learns the mapping from RIS phase shifts to amodal sensing accuracy, and optimizes RIS phase shifts based on this mapping. Experimental results on the benchmark dataset show that our method achieves at least a 56.73% reduction in reconstruction error compared to conventional schemes under the same number of RIS configurations.

</details>


### [24] [Real-Time 2D LiDAR Object Detection Using Three-Frame RGB Scan Encoding](https://arxiv.org/abs/2602.02167)
*Soheil Behnam Roudsari,Alexandre S. Brandão,Felipe N. Martins*

Main category: eess.SP

TL;DR: 提出一种基于2D LiDAR的轻量级物体检测方法，通过堆叠三帧连续扫描作为RGB通道编码时序信息，在嵌入式设备上实现实时高精度检测，无需构建占用网格或RGB摄像头。


<details>
  <summary>Details</summary>
Motivation: 室内服务机器人需要既鲁棒又保护隐私的感知系统，同时能在嵌入式硬件上运行。现有RGB摄像头方案存在隐私问题且计算量大，而传统LiDAR方法通常需要构建占用网格，计算成本较高。

Method: 将三帧连续的2D LiDAR扫描堆叠为RGB通道，形成紧凑的YOLOv8n输入，保留角度结构和运动线索。该方法避免了占用网格构建，直接在嵌入式设备上运行。

Result: 在Webots模拟的160个随机室内场景中，达到98.4% mAP@0.5（0.778 mAP@0.5:0.95），精确率94.9%，召回率94.7%。在树莓派5上平均端到端延迟47.8ms，实现实时运行。

Conclusion: 轻量级时序编码方法能够在嵌入式设备上实现准确、实时的纯LiDAR检测，为室内机器人提供隐私友好且高效的感知方案，尽管目前结果基于模拟环境。

Abstract: Indoor service robots need perception that is robust, more privacy-friendly than RGB video, and feasible on embedded hardware. We present a camera-free 2D LiDAR object detection pipeline that encodes short-term temporal context by stacking three consecutive scans as RGB channels, yielding a compact YOLOv8n input without occupancy-grid construction while preserving angular structure and motion cues. Evaluated in Webots across 160 randomized indoor scenarios with strict scenario-level holdout, the method achieves 98.4% mAP@0.5 (0.778 mAP@0.5:0.95) with 94.9% precision and 94.7% recall on four object classes. On a Raspberry Pi 5, it runs in real time with a mean post-warm-up end-to-end latency of 47.8ms per frame, including scan encoding and postprocessing. Relative to a closely related occupancy-grid LiDAR-YOLO pipeline reported on the same platform, the proposed representation is associated with substantially lower reported end-to-end latency. Although results are simulation-based, they suggest that lightweight temporal encoding can enable accurate and real-time LiDAR-only detection for embedded indoor robotics without capturing RGB appearance.

</details>


### [25] [A Novel ISAC Waveform Based on Orthogonal Delay-Doppler Division Multiplexing with FMCW](https://arxiv.org/abs/2602.02248)
*Kehan Huang,Akram Shafie,Min Qiu,Elias Aboutanios,Jinhong Yuan*

Main category: eess.SP

TL;DR: 提出ODDM-FMCW波形，将正交时延多普勒复用调制与调频连续波结合，用于低PAPR的集成感知与通信系统。


<details>
  <summary>Details</summary>
Motivation: 传统线性FMCW波形在ISAC系统中存在局限性，需要开发既能实现高效通信又能进行精确感知的低PAPR波形。

Method: 1. 提出平方根奈奎斯特滤波FMCW波形；2. 在时延多普勒域嵌入符号生成DD-SRN-FMCW帧；3. 设计DD啁啾压缩接收机；4. 将DD-SRN-FMCW帧叠加到ODDM数据帧上构建ODDM-FMCW波形。

Result: 数值结果显示，ODDM-FMCW波形在感知的均方根误差和通信的误码率方面均表现出优异的ISAC性能。

Conclusion: ODDM-FMCW波形为低PAPR的集成感知与通信系统提供了一种有效的解决方案，在感知精度和通信可靠性方面均表现出色。

Abstract: In this work, we propose the orthogonal delay-Doppler (DD) division multiplexing (ODDM) modulation with frequency modulated continuous wave (FMCW) (ODDM-FMCW) waveform to enable integrated sensing and communication (ISAC) with a low peak-to-average power ratio (PAPR). We first propose a square-root-Nyquist-filtered FMCW (SRN-FMCW) waveform to address limitations of conventional linear FMCW waveforms in ISAC systems. To better integrate with ODDM, we generate SRN-FMCW by embedding symbols in the DD domain, referred to as a DD-SRN-FMCW frame. A DD chirp compression receiver is designed to obtain the channel response efficiently. Next, we construct the proposed ODDM-FMCW waveform for ISAC by superimposing a DD-SRN-FMCW frame onto an ODDM data frame. A comprehensive performance analysis of the ODDM-FMCW waveform is presented, covering peak-to-average power ratio, spectrum, ambiguity function, and Cramer-Rao bound for delay and Doppler estimation. Numerical results show that the proposed ODDM-FMCW waveform delivers excellent ISAC performance in terms of root mean square error for sensing and bit error rate for communications.

</details>


### [26] [Sampling-Free Diffusion Transformers for Low-Complexity MIMO Channel Estimation](https://arxiv.org/abs/2602.02202)
*Zhixiong Chen,Hyundong Shin,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出一种免采样的扩散变换器（SF-DiT-CE）用于低复杂度MIMO信道估计，通过单次前向传播直接预测信道，避免迭代采样


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的信道估计器性能优异但计算复杂度高，因为它们依赖迭代反向采样过程

Method: 利用MIMO信道的角度域稀疏性，训练轻量级扩散变换器（DiT），以最小二乘估计和估计噪声为条件，在单次前向传播中直接从扰动观测和噪声水平预测干净信道

Result: 数值结果表明，该方法在显著降低复杂度的同时，实现了优于最先进基线的估计精度和鲁棒性

Conclusion: SF-DiT-CE通过消除迭代采样，为MIMO信道估计提供了一种高效准确的解决方案，平衡了性能与计算复杂度

Abstract: Diffusion model-based channel estimators have shown impressive performance but suffer from high computational complexity because they rely on iterative reverse sampling. This paper proposes a sampling-free diffusion transformer (DiT) for low-complexity MIMO channel estimation, termed SF-DiT-CE. Exploiting angular-domain sparsity of MIMO channels, we train a lightweight DiT to directly predict the clean channels from their perturbed observations and noise levels. At inference, the least square (LS) estimate and estimation noise condition the DiT to recover the channel in a single forward pass, eliminating iterative sampling. Numerical results demonstrate that our method achieves superior estimation accuracy and robustness with significantly lower complexity than state-of-the-art baselines.

</details>


### [27] [Flexible laboratory setup for DAC experimentation](https://arxiv.org/abs/2602.02312)
*Alfredo Pérez Vega-Leal,Manuel G. Satué*

Main category: eess.SP

TL;DR: 论文回顾了多种DAC技术，并基于商用FPGA系统开发了时间交织Σ-Δ调制DAC原型


<details>
  <summary>Details</summary>
Motivation: 在现代发射机中，速度是主要限制因素，模拟复用技术是一种有前景的解决方案。目标是开发低成本方案来比较不同的数模转换方案。

Method: 回顾了模拟复用技术、高速单DAC、Σ-Δ调制、动态元件匹配等技术，并基于商用FPGA系统开发了时间交织Σ-Δ调制DAC原型

Result: 展示了基于商用FPGA系统的时间交织Σ-Δ调制DAC原型实现

Conclusion: 模拟复用技术在现代发射机中具有应用前景，时间交织Σ-Δ调制DAC原型为比较不同DAC方案提供了低成本解决方案

Abstract: Analog multiplexing appears to be a promising solution for modern transmitters, where speed is the primary limitation. The objective is the development of a low-cost solution to compare different digital to analog (DAC) schemes. In particular, analog multiplexing techniques, high-speed single-DAC, Sigma-delta modulation, Dynamic element matching are considered. The work presents a review of these techniques and shows a prototype of a time interleaved sigma delta modulation based DAC based on a commercially available Field Programmable Gate Array system.

</details>


### [28] [A Track-Before-Detect Trajectory Multi-Bernoulli Filter for Generalised Superpositional Measurements](https://arxiv.org/abs/2602.02365)
*Sion Lynch,Ángel F. García-Fernández,Lee Devlin*

Main category: eess.SP

TL;DR: 提出T-IEMB滤波器用于轨迹估计，采用高斯实现降低计算成本，在非高斯雷达跟踪场景中优于粒子滤波方法


<details>
  <summary>Details</summary>
Motivation: 在轨迹检测前（track-before-detect）应用中，需要估计存活和所有轨迹的集合。现有方法如粒子滤波器计算成本高，需要更高效且性能优越的解决方案来处理广义叠加测量模型。

Method: 提出轨迹信息交换多伯努利（T-IEMB）滤波器，使用广义叠加测量模型，该模型通过叠加隐藏变量映射到测量的条件均值和协方差。同时提出了T-IEMB的高斯实现，通过近似测量模型的条件矩来执行更新，获得计算轻量的滤波解决方案。

Result: 在非高斯雷达跟踪场景的仿真中，两种高斯T-IEMB实现都表现出优越性能：相比最先进的基于粒子滤波的轨迹检测前解决方案，提供了改进的跟踪性能，同时计算成本更低。

Conclusion: T-IEMB滤波器及其高斯实现为轨迹检测前应用提供了一种高效且性能优越的解决方案，能够处理广义叠加测量模型，在保持低计算成本的同时实现更好的跟踪性能。

Abstract: This paper proposes the Trajectory-Information Exchange Multi-Bernoulli (T-IEMB) filter to estimate sets of alive and all trajectories in track-before-detect applications with generalised superpositional measurements. This measurement model has superpositional hidden variables which are mapped to the conditional mean and covariance of the measurement, enabling it to describe a broad range of measurement models. This paper also presents a Gaussian implementation of the T-IEMB filter, which performs the update by approximating the conditional moments of the measurement model, and admits a computationally light filtering solution. Simulation results for a non-Gaussian radar-based tracking scenario demonstrate the performance of two Gaussian T-IEMB implementations, which provide improved tracking performance compared to a state-of-the-art particle filter based solution for track-before-detect, at a reduced computational cost.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [29] [Information Propagation and Encoding in Solids: A Quantitative Approach Towards Mechanical Intelligence](https://arxiv.org/abs/2602.00140)
*Peerasait Prachaseree,Emma Lejeune*

Main category: cs.IT

TL;DR: 该论文提出了一种量化弹性体中信息传播的框架，将力学结构视为信息编码器，并连接信息传输与经典力学现象，为机械智能设计提供可量化指标。


<details>
  <summary>Details</summary>
Motivation: 传统工程系统将机械功能与信息处理分离，而生物系统可利用物理结构进行信息处理。为了探索在机械结构中嵌入信息处理能力，需要建立定量评估框架。

Method: 使用弹性体作为模型系统，应用信息论工具将弹性域视为信息编码器，量化从施加载荷到离散传感器位置的信息传输，并将这些度量与经典力学现象（如圣维南效应和主应力线）联系起来。

Result: 建立了弹性体中信息传播的量化框架，展示了如何通过几何形状和架构材料调节信息传输，使弹性域能够传输或阻断信息。

Conclusion: 这项工作为机械智能提供了可量化的指标和基准任务，支持可比较的机械体现信息处理设计，推进了力学结构作为信息处理媒介的研究。

Abstract: Engineered systems typically separate mechanical function from information processing, whereas biological systems can exploit physical structure as a medium for information processing and computation. Motivated by this contrast, recent work in mechanics has explored embedding information-processing capabilities directly into mechanical structures. However, quantitative frameworks for evaluating such capabilities remain limited. Here we address a foundational question: how does information propagate through a solid body? Using elastic bodies as a model system, we apply information-theoretic tools to treat an elastic domain as an information encoder and quantify how information transmits from applied loads to discrete sensor locations. We further connect these measures to familiar mechanical phenomena, including Saint-Venant's effect and principal stress lines. Moving toward design, we show how geometry and architected materials can tune transmission, enabling elastic domains to either transmit or block information. Overall, this work advances quantifiable metrics and benchmark tasks for mechanical intelligence, supporting comparable designs of mechanically embodied information processing.

</details>


### [30] [Semantic-Aware Command and Control Transmission for Multi-UAVs](https://arxiv.org/abs/2602.00142)
*Boya Li,Xiaonan Liu,Dongzhu Liu,Dusit Niyato,Zhu Han*

Main category: cs.IT

TL;DR: 提出基于语义感知的无人机C&C传输框架，利用语义相似度实现多播传输，通过PPO算法优化资源分配，显著提升传输效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机数量增加和无线数据爆炸式增长，传统的比特导向通信网络已接近香农容量极限，无法满足无人机指挥控制(C&C)传输的超可靠低延迟通信(URLLC)要求。

Method: 1) 利用语义相似度测量每个无人机在连续传输时间间隔内C&C消息的变化，并捕获无人机间C&C消息的相关性，实现多播传输；2) 基于语义相似度和无人机命令重要性设计触发函数量化QoS；3) 开发近端策略优化(PPO)算法，联合确定传输模式（单播/多播/空闲）和基站与无人机间有限资源块的分配。

Result: 实验结果表明，提出的语义感知框架相比比特导向无人机传输，显著提高了传输效率和有效性。

Conclusion: 通过语义感知方法，利用C&C消息的语义相似性实现多播传输，结合PPO算法优化资源分配，能够有效解决有限无线资源下无人机C&C传输的QoS需求问题。

Abstract: Uncrewed aerial vehicles (UAVs) have played an important role in the low-altitude economy and have been used in various applications. However, with the increasing number of UAVs and explosive wireless data, the existing bit-oriented communication network has approached the Shannon capacity, which cannot satisfy the quality of service (QoS) with ultra-reliable low-latency communication (URLLC) requirements for command and control (C\&C) transmission in bit-oriented UAV communication networks. To address this issue, we propose a novel semantic-aware C\&C transmission for multi-UAVs under limited wireless resources. Specifically, we leverage semantic similarity to measure the variation in C\&C messages for each UAV over continuous transmission time intervals (TTIs) and capture the correlation of C\&C messages among UAVs, enabling multicast transmission. Based on the semantic similarity and the importance of UAV commands, we design a trigger function to quantify the QoS of UAVs. Then, to maximize the long-term QoS and exploit multicast opportunities of C\&C messages induced by semantic similarity, we develop a proximal policy optimization (PPO) algorithm to jointly determine the transmission mode (unicast/multicast/idle) and the allocation of limited resource blocks (RBs) between a base station (BS) and UAVs. Experimental results show that our proposed semantic-aware framework significantly increases transmission efficiency and improves effectiveness compared with bit-oriented UAV transmission.

</details>


### [31] [The structure and enumeration of periodic binary sequences with high nonlinear complexity](https://arxiv.org/abs/2602.01134)
*Qin Yuan,Chunlei Li,Xiangyong Zeng*

Main category: cs.IT

TL;DR: 本文研究了非线性复杂度≥3n/4的n周期二进制序列的结构特征，并推导出此类序列的精确计数公式。


<details>
  <summary>Details</summary>
Motivation: 非线性复杂度是评估序列随机性的重要指标，定义为能够生成给定序列的最短反馈移位寄存器的长度。研究高非线性复杂度序列的结构和数量对于密码学和随机序列分析具有重要意义。

Method: 首先对非线性复杂度≥3n/4的n周期二进制序列进行结构特征分析，然后基于这些结构特征推导精确的计数公式。

Result: 获得了非线性复杂度≥3n/4的n周期二进制序列的完整结构特征，并确定了此类序列的精确枚举公式。

Conclusion: 本文成功刻画了高非线性复杂度序列的结构特性，并提供了精确的计数方法，为密码学中随机序列的设计和分析提供了理论支持。

Abstract: Nonlinear complexity, as an important measure for assessing the randomness of sequences, is defined as the length of the shortest feedback shift registers that can generate a given sequence. In this paper, the structure of n-periodic binary sequences with nonlinear complexity larger than or equal to 3n/4 is characterized. Based on their structure, an exact enumeration formula for the number of such periodic sequences is determined.

</details>


### [32] [On the Palindromic/Reverse-Complement Duplication Correcting Codes](https://arxiv.org/abs/2602.01151)
*Yubo Sun,Gennian Ge*

Main category: cs.IT

TL;DR: 该论文研究DNA存储中的纠错码，针对反转互补重复和回文重复两种错误类型，提出了多种编码方案，包括单冗余符号纠错码、Gilbert-Varshamov界分析，以及两种长度为一的反转互补重复纠错码构造。


<details>
  <summary>Details</summary>
Motivation: 受体内DNA存储应用驱动，研究能够纠正重复错误的编码。DNA存储中常见的错误类型包括反转互补重复（插入子串的反转互补副本）和回文重复（仅插入反转副本），需要设计专门的纠错码来处理这些特定错误模式。

Method: 1. 构造单冗余符号的显式编码，可纠正任意数量的反转互补重复或回文重复（要求所有重复长度k≥3⌈log_q n⌉且不相交）；2. 推导Gilbert-Varshamov界，分析纠正任意长度重复错误的最优冗余度上界；3. 针对q≥4，提出两种纠正t个长度为一反转互补重复的显式编码构造，在冗余度和计算复杂度之间提供不同权衡。

Result: 1. 单冗余符号编码能有效纠正不相交的长重复错误；2. 最优冗余度上界为2log_q n + log_q log_q n + O(1)；3. 第一种长度为一重复纠错码冗余度为2t log_q n + O(log_q log_q n)，编码复杂度O(n)，解码复杂度O(n(log_2 n)^4)；第二种改进冗余度为(2t-1)log_q n + O(log_q log_q n)，但编解码复杂度为O(n·poly(log_2 n))。

Conclusion: 该论文为DNA存储中的重复错误纠正提供了系统的编码理论框架，针对不同错误类型和约束条件提出了多种实用编码方案，在冗余度、纠错能力和计算复杂度之间提供了灵活权衡，对DNA存储系统的实际应用具有重要意义。

Abstract: Motivated by applications in in-vivo DNA storage, we study codes for correcting duplications. A reverse-complement duplication of length $k$ is the insertion of the reversed and complemented copy of a substring of length $k$ adjacent to its original position, while a palindromic duplication only inserts the reversed copy without complementation. We first construct an explicit code with a single redundant symbol capable of correcting an arbitrary number of reverse-complement duplications (respectively, palindromic duplications), provided that all duplications have length $k \ge 3\lceil \log_q n \rceil$ and are disjoint. Next, we derive a Gilbert-Varshamov bound for codes that can correct a reverse-complement duplication (respectively, palindromic duplication) of arbitrary length, showing that the optimal redundancy is upper bounded by $2\log_q n + \log_q\log_q n + O(1)$. Finally, for $q \ge 4$, we present two explicit constructions of codes that can correct $t$ length-one reverse-complement duplications. The first construction achieves a redundancy of $2t\log_q n + O(\log_q\log_q n)$ with encoding complexity $O(n)$ and decoding complexity $O\big(n(\log_2 n)^4\big)$. The second construction achieves an improved redundancy of $(2t-1)\log_q n + O(\log_q\log_q n)$, but with encoding and decoding complexities of $O\big(n \cdot \mathrm{poly}(\log_2 n)\big)$.

</details>


### [33] [A class of pseudorandom sequences From Function Fields](https://arxiv.org/abs/2602.01154)
*Xiaofeng Liu,Jun Zhang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 本文利用Weil和Deligne在代数函数域上的指数和界，研究了一类p元序列的周期、线性复杂度、线性复杂度轮廓、r-模式分布、周期相关性和非线性复杂度，推广了先前文献中的序列构造。


<details>
  <summary>Details</summary>
Motivation: 受到Hu等人在循环椭圆函数域上构造伪随机序列（2007）和Xing等人在函数域上构造低相关、大线性跨度二进制序列（2003）的启发，本文旨在利用代数函数域上的指数和理论，推广这些构造并研究更一般的p元序列的密码学性质。

Method: 利用Weil和Deligne在一般代数函数域上推导的指数和界，研究一类推广了[IEEE Trans. Inf. Theory, 49(6), 2003]和[IEEE Trans. Inf. Theory, 53(7), 2007]中构造的p元序列。通过代数函数域的理论工具分析序列的密码学性质。

Result: 对这类p元序列的周期、线性复杂度、线性复杂度轮廓、r-模式分布、周期相关性和非线性复杂度进行了系统分析，得到了这些密码学性质的理论界限和性能评估。

Conclusion: 本文成功地将代数函数域上的指数和理论应用于序列密码学，推广了现有的序列构造方法，并为这类p元序列提供了全面的密码学性质分析，为设计具有良好密码学性质的序列提供了理论依据。

Abstract: Motivated by the constructions of pseudorandom sequences over the cyclic elliptic function fields by Hu \textit{et al.} in \text{[IEEE Trans. Inf. Theory, 53(7), 2007]} and the constructions of low-correlation, large linear span binary sequences from function fields by Xing \textit{et al.} in \text{[IEEE Trans. Inf. Theory, 49(6), 2003]}, we utilize the bound derived by Weil \text{[Basic Number Theory, Grund. der Math. Wiss.,
  Bd 144]} and Deligne \text{[ Lecture Notes in Mathematics, vol. 569 (Springer, Berlin, 1977)]} for the exponential sums over the general algebraic function fields and study the periods, linear complexities, linear complexity profiles, distributions of $r-$patterns, period correlation and nonlinear complexities for a class of $p-$ary sequences that generalize the constructions in \text{[IEEE Trans. Inf. Theory, 49(6), 2003]} and [IEEE Trans. Inf. Theory, 53(7), 2007].

</details>


### [34] [Reducing ORBGRAND Latency via Partial Gaussian Elimination](https://arxiv.org/abs/2602.01174)
*Li Wan,Wenyi Zhang*

Main category: cs.IT

TL;DR: 提出一种基于消除辅助的ORBGRAND解码方案，通过结合最可靠错误位秩和部分高斯消除过滤机制，显著减少需要测试的错误模式数量，降低解码延迟和计算复杂度，同时保持纠错性能。


<details>
  <summary>Details</summary>
Motivation: ORBGRAND虽然通过利用LLR排序实现了GRAND的并行实现，但在不利信道条件下仍然存在高尾延迟问题，限制了其在实时系统中的应用。需要一种方法来减少解码延迟，特别是最坏情况下的延迟。

Method: 提出消除辅助的ORBGRAND方案，将最可靠错误位秩(RMRE)与部分高斯消除过滤机制结合。该方法将共享相同RMRE的错误模式分组并联合验证，一旦识别出有效错误模式，就恢复ORBGRAND搜索。通过利用先前的高斯消除步骤过滤掉不必要的猜测，显著减少需要测试的错误模式数量。

Result: 仿真结果表明，与原始ORBGRAND相比，消除辅助的ORBGRAND过滤掉超过50%的错误模式，相应降低了整体计算复杂度，同时保持块错误率不变。该方法适用于超可靠低延迟通信场景。

Conclusion: 消除辅助的ORBGRAND方案通过智能过滤机制有效减少了解码延迟，特别是最坏情况下的延迟，同时保持纠错性能，为实时通信系统提供了一种可行的低延迟解码解决方案。

Abstract: Guessing Random Additive Noise Decoding (GRAND) is a universal framework for decoding all block codes by testing candidate error patterns (EPs). Ordered Reliability Bits GRAND (ORBGRAND) facilitates parallel implementation of GRAND by exploiting log-likelihood ratio (LLR) rankings but still suffers from high tail latency under unfavorable channel conditions, limiting its use in real-time systems.
  We propose an elimination-aided ORBGRAND scheme that reduces decoding latency by integrating the Rank of the Most Reliable Erroneous (RMRE) bit with a partial Gaussian-elimination (GE) filtering mechanism. The scheme groups and jointly verifies EPs that share the same RMRE, and once a valid EP is identified, the ORBGRAND search is resumed. By leveraging prior GE steps to filter out unnecessary guesses, this approach significantly reduces the number of EPs to be tested, thereby lowering both average and worst-case latency while maintaining error-correction performance.
  Simulation results show that compared to the original ORBGRAND, the elimination-aided ORBGRAND filters out more than 50\% of EPs and correspondingly reduce overall computational complexity, all with no loss in block error rate. This demonstrates that this approach is suitable for ultra-reliable low-latency communication scenarios.

</details>


### [35] [L-Moment-Based LOS and NLOS Channel Characterization via Four-parameter Kappa Distribution for AoA BLE CTE Measurements](https://arxiv.org/abs/2602.01229)
*Hamed Talebian,Aamir Mahmood,Mikael Gidlund*

Main category: cs.IT

TL;DR: 本文通过BLE CTE传输的IQ样本分析，发现LOS和NLOS条件下的统计分布差异显著，提出基于L-矩比的特征分析方法，能更好地区分传播条件并提高AoA估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有BLE方向查找数据集缺乏严格控制的LOS/NLOS配对测量，且常用的平坦衰落模型在室内多径环境中表现不佳。需要更准确的统计模型来区分传播条件，提高AoA估计精度。

Method: 使用商用BLE模块进行配对几何测量，收集132000个标记的CTE数据包。通过稳健预处理去除异常CTE，进行特征假设检验，计算L-矩比并在L-矩比图中分析，最后应用自监督聚类到L-矩统计。

Result: IQ功率特征在LOS和NLOS条件下具有强可分性，所有均值差异均统计显著，92%的特征方差差异显著。NLOS子集表现出更重的尾部和更强的不对称性。Kappa分布拟合提供了更好的拟合优度。

Conclusion: L-矩比分析能有效区分LOS和NLOS传播条件，相比传统矩统计提供更可分的表示，为BLE AoA估计中的传播条件识别提供了更准确的统计框架。

Abstract: Bluetooth Low Energy (BLE) CTE transmissions provide in-phase and quadrature (IQ) samples whose empirical statistics are strongly governed by the propagation regime. in particular, the distributions differ markedly between line-of-sight (LOS) and non-line-of-sight (NLOS) conditions. In NLOS, multipath-induced distortions typically degrade Angle-of-Arrivial (AoA) estimation accuracy. Existing BLE direction finding datasets rarely provide tightly controlled, IQ-level paired LOS and NLOS measurements with rigorous statistical validation, and commonly used flat-fading models can be inadequate for cluttered indoor environments exhibiting heavy-tailed power distributions. To address these limitations, we conduct a paired-geometry BLE AoA measurement campaign using an off-the-shelf module, collecting 132000 labeled CTE packets under matched anchor-tag conditions. A robust preprocessing stage removes anomalous CTEs using combined univariate and multivariate criteria. Feature-wise hypothesis tests on IQ-derived power features confirm strong LOS and NLOS separability. All mean differences are statistically significant; additionally, 92 percent of feature-wise variance differences are significant. We further compute L-moment ratios (LMRs) and analyze them in the L-moment Ratio Diagram (LMRD), showing that NLOS subsets exhibit markedly heavier tails and stronger asymmetry than LOS. Kappa-family distributions fitted from LMRs provide substantially improved dual scored L--moment goodness-of-fit (GoF), Specifically, for NLOS, which is the smallest discrepancy in the LMRD and a near-zero standardized L-kurtosis deviation. As a practice, we apply a self-supervised clustering to L-moment statistics, achieving a more separable representation, compared to product moments.

</details>


### [36] [MDS matrices from skew polynomials with automorphisms and derivations](https://arxiv.org/abs/2602.01383)
*Atif Ahmad Khan,Shakir Ali,Elif Segah Oztas,Abhishek Kesarwani*

Main category: cs.IT

TL;DR: 本文提出了一种使用斜多项式环构造MDS矩阵的新方法，引入了δθ-循环矩阵概念，并构建了准递归MDS矩阵，这些矩阵具有对合性，优于现有构造。


<details>
  <summary>Details</summary>
Motivation: MDS矩阵在编码理论和对称密钥密码学中具有重要作用，但现有构造方法有限。本文旨在利用斜多项式环的代数结构，开发新的MDS矩阵构造方法，特别是要改进现有的准对合构造。

Method: 使用斜多项式环F_q[X;θ,δ]构造MDS矩阵，其中θ是自同构，δ是θ-导子。引入δθ-循环矩阵概念，研究其结构性质，推导这些矩阵成为对合且满足MDS性质的充要条件。在斜多项式环F_q[X;θ]中构造与伴随矩阵相关的准递归MDS矩阵。

Result: 成功构造了δθ-循环矩阵作为经典构造的推广，建立了准递归MDS矩阵，这些矩阵被证明具有对合性，相比文献中已有的准对合构造有严格改进。提供了多个说明性结果和示例。

Conclusion: 本文提出的基于斜多项式环的MDS矩阵构造方法有效且具有优势，特别是准递归MDS矩阵的对合性改进为编码理论和密码学应用提供了更好的工具。

Abstract: Maximum Distance Separable (MDS) matrices play a central role in coding theory and symmetric-key cryptography due to their optimal diffusion properties. In this paper, we present a construction of MDS matrices using skew polynomial rings \( \mathbb{F}_q[X;θ,δ] \), where \( θ\) is an automorphism and \( δ\) is a \( θ\)-derivation on \( \mathbb{F}_q \). We introduce the notion of \( δ_θ \)-circulant matrices and study their structural properties. Necessary and sufficient conditions are derived under which these matrices are involutory and satisfy the MDS property. The resulting $δ_θ$-circulant matrix can be viewed as a generalization of classical constructions obtained in the absence of $θ$-derivations. One of the main contribution of this work is the construction of quasi recursive MDS matrices. In the setting of the skew polynomial ring $\mathbb{F}_q[X;θ]$, we construct quasi recursive MDS matrices associated with companion matrices.
  These matrices are shown to be involutory, yielding a strict improvement over the quasi-involutory constructions previously reported in the literature. Several illustrative results and examples are also provided.

</details>


### [37] [Design of Root Protograph LDPC Codes Simultaneously Achieving Full Diversity and High Coding Gain](https://arxiv.org/abs/2602.01555)
*Inki Kim,Hyuntae Ahn,Yongjune Kim,Hee-Youl Kwak,Dae-Young Yun,Sang-Hyo Kim*

Main category: cs.IT

TL;DR: 提出了一种基于原图的LDPC码设计框架，在块衰落信道中实现全分集，在高斯白噪声信道中实现接近容量的性能


<details>
  <summary>Details</summary>
Motivation: 传统LDPC码设计要么专注于分集性能（块衰落信道），要么专注于容量性能（高斯白噪声信道），缺乏能同时在这两种信道环境下都表现优异的统一设计框架

Method: 1. 使用基于布尔近似的分集演化分析推导广义根校验的结构约束；2. 提出针对双块衰落信道的原图模板；3. 采用密度演化指导的遗传算法优化原图边以获得优异的高斯白噪声信道性能

Result: 设计出的LDPC码在块衰落信道中实现全分集，在高斯白噪声信道中实现接近容量的性能，有效弥合了分集导向和容量导向设计之间的差距

Conclusion: 该框架成功实现了在两种不同信道环境下都具有鲁棒性能的LDPC码设计，为通信系统提供了更通用的编码解决方案

Abstract: This paper presents a novel design framework for protograph-based LDPC codes that simultaneously achieves full diversity in block-fading channels (BFCs) and nearcapacity performance in additive white Gaussian noise channels (AWGNCs). By leveraging a Boolean approximation-based analysis--Diversity Evolution (DivE)--we derive structural constraints for generalized rootchecks that guarantee full diversity. Based on these constraints, we propose a protograph template tailored for two-block BFCs. Furthermore, we employ a genetic algorithm guided by density evolution to optimize the protograph edges within this template for superior AWGNC performance. The resulting codes effectively bridge the gap between diversityoriented and capacity-oriented designs, exhibiting robust performance across both channel environments.

</details>


### [38] [On the Fragility of AI-Based Channel Decoders under Small Channel Perturbations](https://arxiv.org/abs/2602.01582)
*Haoyu Lei,Mohammad Jalali,Chin Wa Lau,Farzan Farnia*

Main category: cs.IT

TL;DR: AI解码器在AWGN信道下性能优于传统BP解码，但对对抗性扰动更敏感，存在鲁棒性代价


<details>
  <summary>Details</summary>
Motivation: 探究AI解码器性能提升的来源及其代价，特别是对信道输出分布变化的鲁棒性问题

Method: 通过对抗性扰动（FGM、投影梯度法、通用对抗扰动）评估AI解码器在分布偏移下的鲁棒性

Result: AI解码器（ECCT、CrossMPT）在对抗性扰动下性能显著下降；对抗扰动在AI解码器间转移性强，但对BP解码器弱；通用扰动比同等范数的随机扰动危害更大

Conclusion: AI解码器的性能提升可能以鲁棒性为代价，对信道分布变化更敏感，揭示了潜在的鲁棒性成本

Abstract: Recent advances in deep learning have led to AI-based error correction decoders that report empirical performance improvements over traditional belief-propagation (BP) decoding on AWGN channels. While such gains are promising, a fundamental question remains: where do these improvements come from, and what cost is paid to achieve them? In this work, we study this question through the lens of robustness to distributional shifts at the channel output. We evaluate both input-dependent adversarial perturbations (FGM and projected gradient methods under $\ell_2$ constraints) and universal adversarial perturbations that apply a single norm-bounded shift to all received vectors. Our results show that recent AI decoders, including ECCT and CrossMPT, could suffer significant performance degradation under such perturbations, despite superior nominal performance under i.i.d. AWGN. Moreover, adversarial perturbations transfer relatively strongly between AI decoders but weakly to BP-based decoders, and universal perturbations are substantially more harmful than random perturbations of equal norm. These numerical findings suggest a potential robustness cost and higher sensitivity to channel distribution underlying recent AI decoding gains.

</details>


### [39] [Spectral-Aligned Pruning for Universal Error-Correcting Code Transformers](https://arxiv.org/abs/2602.01602)
*Sanghyeon Cho,Taewoo Park,Seong-Joon Park,Dae-Young Yun,Hee-Youl Kwak,Sang-Hyo Kim,Yongjune Kim*

Main category: cs.IT

TL;DR: 提出SAP（谱对齐剪枝）框架，通过利用二分图谱实现跨码的结构化剪枝掩码重用，结合LoRA进行码特异性恢复，显著降低FECCT的计算复杂度和内存占用。


<details>
  <summary>Details</summary>
Motivation: 尽管FECCT作为通用信道解码器表现出色，但基于Transformer的架构存在高计算复杂度和大参数规模的问题，阻碍了实际部署。需要一种既能保持性能又能显著降低计算和内存成本的方法。

Method: 提出SAP（谱对齐剪枝）框架：1）利用二分图谱实现跨码的结构化剪枝掩码重用；2）通过参数高效的LoRA（低秩适应）进行码特异性恢复；3）采用内核级结构化剪枝，共享剪枝后的主干网络，仅存储小的码特异性适配器参数。

Result: 实验表明，SAP在不同码型上实现了与专用逐码剪枝相当的译码性能，同时通过结构化剪枝显著降低了计算成本和模型内存占用。

Conclusion: SAP框架成功解决了FECCT部署中的计算复杂度和内存占用问题，通过谱对齐剪枝和LoRA适配实现了高效的跨码结构化剪枝，为通用信道解码器的实际应用提供了可行方案。

Abstract: Recently, the Foundation Error Correction Code Transformer (FECCT) has emerged as a promising universal channel decoder, achieving competitive decoding performance across diverse code families by relying on a single shared model backbone, optionally followed by code-specific retraining. Despite this flexibility, the high computational complexity and large parameter footprint of transformer-based decoders present substantial obstacles to practical deployment. To address these challenges, we investigate structured pruning for FECCT and propose Spectral-Aligned Pruning (SAP), a structure-aware framework that enables cross-code reuse of structured pruning masks across codes by leveraging the spectrum of the corresponding bipartite graph. After pruning, SAP performs per-code recovery via parameter-efficient low-rank adaptation (LoRA), enabling a shared pruned backbone while storing only small code-specific adapter parameters. Experiments across diverse codes show that SAP achieves decoding performance comparable to dedicated per-code pruning, while enabling substantial reductions in computational cost and model memory footprint through kernel-level structured pruning.

</details>


### [40] [Low-Complexity Multi-Agent Continual Learning for Stacked Intelligent Metasurface-Assisted Secure Communications](https://arxiv.org/abs/2602.01653)
*Enyu Shi,Yiyang Zhu,Jiayi Zhang,Ziheng Liu,Jiakang Zheng,Jiancheng An,Derrick Wing Kwan Ng,Bo Ai,Chau Yuen*

Main category: cs.IT

TL;DR: 该论文提出了一种基于堆叠智能超表面(SIM)的多用户MIMO系统物理层安全增强方案，通过波束赋形在电磁域执行，避免了复杂的基带数字预编码，并设计了低复杂度的学习框架优化安全性能。


<details>
  <summary>Details</summary>
Motivation: 未来无线通信安全需求日益增长，传统数字预编码硬件开销大且复杂。堆叠智能超表面(SIM)技术为物理层安全提供了新的可能性，但如何有效集成SIM到多用户MIMO系统中并优化安全性能仍面临挑战。

Method: 提出新型系统架构：每个基站天线传输专用单用户流，多层SIM在电磁域执行波束赋形。设计了流形增强的异构多智能体持续学习(MHACL)框架，结合梯度表示和双尺度策略优化。进一步开发了低复杂度的SIM-MHACL学习模板，将相位协调嵌入乘积流形结构。

Result: 仿真验证表明，所提框架在SIM辅助系统中实现毫秒级每轮训练，显著优于多种基线方案。SIMHACL在保持与MHACL相当加权和保密率的同时，将计算时间减少30%。

Conclusion: SIM技术能有效增强多用户MIMO系统的物理层安全，所提出的学习框架在动态环境中实现了鲁棒性能，同时大幅降低了计算复杂度，为未来无线通信安全提供了高效解决方案。

Abstract: Stacked intelligent metasurfaces (SIMs), composed of multiple layers of reconfigurable transmissive metasurfaces, are gaining prominence as a transformative technology for future wireless communication security. This paper investigates the integration of SIM into multi-user multiple-input multiple-output (MIMO) systems to enhance physical layer security. A novel system architecture is proposed, wherein each base station (BS) antenna transmits a dedicated single-user stream, while a multi-layer SIM executes wave-based beamforming in the electromagnetic domain, thereby avoiding the need for complex baseband digital precoding and significantly reducing hardware overhead. To maximize the weighted sum secrecy rate (WSSR), we formulate a joint precoding optimization problem over BS power allocation and SIM phase shifts, which is high-dimensional and non-convex due to the complexity of the objective function and the coupling among optimization variables. To address this, we propose a manifold-enhanced heterogeneous multi-agent continual learning (MHACL) framework that incorporates gradient representation and dual-scale policy optimization to achieve robust performance in dynamic environments with high demands for secure communication. Furthermore, we develop SIM-MHACL (SIMHACL), a low-complexity learning template that embeds phase coordination into a product manifold structure, reducing the exponential search space to linear complexity while maintaining physical feasibility. Simulation results validate that the proposed framework achieves millisecond-level per-iteratio ntraining in SIM-assisted systems, significantly outperforming various baseline schemes, with SIMHACL achieving comparable WSSR to MHACL while reducing computation time by 30\%.

</details>


### [41] [Decoding Golay Codes and their Related Lattices: A PAC Code Perspective](https://arxiv.org/abs/2602.01657)
*Yujun Ji,Ling Liu,Shanxiang Lyu,Chao Chen,Tao Dai,Baoming Bai*

Main category: cs.IT

TL;DR: 提出了一种基于极化调整卷积码(PAC)的Golay码解码方法，通过Forney立方构造和生成器G*(8,7)/(8,4)，实现了高效的并行列表解码算法，具有接近最大似然的性能。


<details>
  <summary>Details</summary>
Motivation: 现有Golay码解码方法通常需要索引置换和码字删截，过程复杂。本文旨在从PAC码的角度重新审视Golay码，寻找更简单高效的解码方法，同时扩展应用到相关格结构如Leech格。

Method: 利用Forney的Golay码立方构造和生成器G*(8,7)/(8,4)，从PAC码的角度重新构造Golay码，提出了一种无需索引置换和码字删截的并行列表解码算法。

Result: 新方法实现了接近最大似然性能的解码，相比现有方法简化了操作流程。该方法还可高效解码相关格结构，如Leech格Λ24及其主子格H24。

Conclusion: 从PAC码的角度重新构造Golay码提供了一种更简单高效的解码方法，避免了传统方法的复杂性，并可扩展到相关格结构的解码，具有理论和实用价值。

Abstract: In this work, we propose a decoding method of Golay codes from the perspective of Polarization Adjusted Convolutional (PAC) codes. By invoking Forney's cubing construction of Golay codes and their generators $G^*(8,7)/(8,4)$, we found different construction methods of Golay codes from PAC codes, which result in an efficient parallel list decoding algorithm with near-maximum likelihood performance. Compared with existing methods, our method can get rid of index permutation and codeword puncturing. Using the new decoding method, some related lattices, such as Leech lattice $Λ_{24}$ and its principal sublattice $H_{24}$, can be also decoded efficiently.

</details>


### [42] [Performance Guarantees of Cellular Networks with Hardcore Regulation and Scheduling](https://arxiv.org/abs/2602.01802)
*Ke Feng,François Baccelli,Catherine Rosenberg*

Main category: cs.IT

TL;DR: 本文研究蜂窝网络中基站空间硬核调控与调度策略对链路级性能保证的影响，分析调度何时能提供更好的速率保证。


<details>
  <summary>Details</summary>
Motivation: 为通信网络提供性能保证是关键目标，空间调控（如基站间距约束）已被证明对建立可证明的无线链路级保证至关重要。本文旨在研究在蜂窝网络中，空间硬核调控下基站调度如何影响性能保证。

Method: 采用空间网络演算框架，首先为空间调控的蜂窝网络提供总干扰功率的上界，然后识别基站调度比基站始终活跃能提供更好链路级速率保证的机制。以六边形蜂窝网络作为特例进行分析。

Result: 确定了基站调度能提供更好链路级速率保证的机制，为蜂窝网络提供了性能保证的理论分析框架，并分析了六边形蜂窝网络的特例。

Conclusion: 研究结果为需要何种空间调控、何时选择调度策略以及如何降低网络功耗以提供特定目标性能保证提供了见解，有助于优化蜂窝网络设计。

Abstract: Providing performance guarantees is one of the {critical} objectives of {recent and future} communication networks, toward which regulations, {i.e., constraints on key system parameters,} have played an indispensable role. This is the case for large wireless communication networks, where spatial regulations (e.g., constraints on intercell distance) have recently been shown, through a spatial network calculus, to be essential for establishing provable wireless link-level guarantees. In this work, we focus on performance guarantees for {the downlink of} cellular networks where we impose a hardcore (spatial) regulation on base station (BS) locations and evaluate {how BS scheduling (which controls which BSs can transmit at a given time) impacts performance}. Hardcore regulation is the simplest form of spatial regulation that enforces a minimal distance between any pair of transmitters in the network. Within this framework of spatial network calculus, we first provide an upper bound on the power of total interference for a spatially regulated cellular network, and then, identify the regimes where scheduling BSs yields {better} link-level rate guarantees compared to scenarios where base stations are always active. The hexagonal cellular network is analyzed as a special case. The results offer insights into what spatial regulations are needed, when to choose scheduling, and how to potentially reduce the network power consumption {to provide a certain target performance guarantee}.

</details>


### [43] [Zero-Shot Knowledge Base Resizing for Rate-Adaptive Digital Semantic Communication](https://arxiv.org/abs/2602.01829)
*Shumin Yao,Hui Du,Lifeng Xie,Yaping Sun,Hao Chen,Nan Ma,Xiaodong Xu*

Main category: cs.IT

TL;DR: 提出一种零样本知识库调整方法，通过揭示语义层次结构实现VQ-VAE语义通信系统的动态速率适配，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 传统VQ-VAE语义通信系统中，传输速率由固定大小的知识库决定，要改变速率需要为每个不同大小训练和存储单独模型，计算和存储成本过高，无法实现细粒度速率控制。

Method: 三步框架：1）将知识库向量嵌入双曲空间以揭示层次关系；2）使用最小生成树算法构建主语义树；3）通过迭代剪枝最不重要的叶节点实现即时调整。

Result: 该方法的重建质量接近从头训练的知识库，计算成本大幅降低，在极低速率下表现出更好的鲁棒性，传统知识库在此情况下会出现灾难性失败。

Conclusion: 解决了VQ-VAE语义通信系统的根本限制，为灵活、速率自适应的语义通信提供了实用高效路径。

Abstract: Digital semantic communication systems, which often leverage the Vector Quantized Variational Autoencoder (VQ-VAE) framework, are pivotal for future wireless networks. In a VQ-VAE-based semantic communication system, the transmission rate is directly governed by the size of a discrete codebook known as knowledge base (KB). However, the KB size is a fixed hyperparameter, meaning that adapting the rate requires training and storing a separate model for each desired size -- a practice that is too computationally and storage-prohibitive to achieve truly granular rate control. To address this, we introduce a principled, zero-shot KB resizing method that enables on-the-fly rate adaptation without any retraining. Our approach establishes a global importance ranking for all vectors within a single, large parent KB by uncovering its inherent semantic hierarchy. This is achieved via a three-step framework: 1) embedding KB vectors into hyperbolic space to reveal their hierarchical relationships; 2) constructing a master semantic tree using a minimum spanning tree algorithm; 3) enabling instant resizing by iteratively pruning the least important leaf nodes. Extensive simulations demonstrate that our method achieves reconstruction quality nearly identical to that of dedicated KBs trained from scratch, while demanding only a fraction of the computational budget. Moreover, our approach exhibits superior robustness at very low rates, where conventional KBs suffer from catastrophic failure. Our work resolves a fundamental limitation of VQ-VAE-based semantic communication systems, offering a practical and efficient path toward flexible and rate-adaptive semantic communication.

</details>


### [44] [Two-Stage Coded-Sliding Beam Training and QoS-Constrained Sum-Rate Maximization for SIM-Assisted Wireless Communications](https://arxiv.org/abs/2602.02131)
*Qian Zhang,Ju Liu,Yao Ge,Yufei Zhao,Wali Ullah Khan,Zheng Dong,Yong Liang Guan,Chau Yuen*

Main category: cs.IT

TL;DR: 本文提出了一种用于堆叠智能超表面(SIM)辅助通信系统的统一低复杂度算法框架，包括两步码本构建、两阶段编码滑动波束训练和可变解耦块连续上界最小化算法，以解决信道状态信息获取和相位优化难题。


<details>
  <summary>Details</summary>
Motivation: 堆叠智能超表面(SIM)为大规模天线通信提供了经济高效的解决方案，但高效的信道状态信息获取和相位偏移优化仍然是关键挑战。现有方法在计算复杂度和性能之间存在权衡，需要开发低复杂度且高效的算法框架。

Method: 1. 广义两步码本构建(TSCC)：利用二维角度域解耦将平面阵列波束形成器设计转化为两个独立的一维线性阵列设计问题，分别使用Gerchberg-Saxton算法和提出的基于主化最小化的近端距离(PDMM)算法求解。
2. 两阶段编码滑动波束训练(TSCSBT)：第一阶段训练中嵌入纠错码增强抗噪鲁棒性，第二阶段在匹配角度样本周围进行滑动采样以提高角度分辨率。
3. 可变解耦块连续上界最小化(VD-BSUM)算法：通过闭式迭代更新直接求解QoS约束的和速率最大化问题，大幅降低计算复杂度。

Result: 仿真结果表明，所提方法能够实现精确的波束模式实现、改进的波束训练精度和角度分辨率，以及增强的和速率性能。算法在低计算复杂度下取得了优异的性能表现。

Conclusion: 本文提出的统一算法框架有效解决了SIM辅助通信系统中的信道状态信息获取和相位优化挑战，通过创新的角度域解耦、编码波束训练和低复杂度优化算法，为大规模天线通信提供了实用且高效的解决方案。

Abstract: Stacked intelligent metasurfaces (SIM) provide a cost-effective and scalable solution for large-scale antenna communications.However, efficient channel state information acquisition and phase shift optimization remain critical challenges. In this paper, we develop a unified framework of low-complexity algorithms for SIM-assisted communication systems to address these issues. Specifically, we propose a generalized two-step codebook construction (TSCC) method that leverages two-dimensional angular-domain decoupling to transform planar array beamformer design into two independent one-dimensional linear array beamformer design problems, efficiently solved via the Gerchberg-Saxton algorithm and our proposed majorization-minimization-based proximal distance (PDMM) algorithm. We further develop a two-stage coded-sliding beam training (TSCSBT) method for low-overhead and high-accuracy beam training, where error-correcting codes are embedded in the first-stage training to enhance robustness against noise, and sliding sampling is subsequently performed around the matched angular samples to improve angular resolution. The proposed framework is further extended to multi-path user channels. Finally, a variable decoupling-based block successive upper bound minimization (VD-BSUM) algorithm is proposed to directly solve the QoS-constrained sum-rate maximization problem through closed-form iterative updates with substantially reduced computational complexity. Simulation results demonstrate the effectiveness of the proposed methods in achieving precise beam pattern realization, improved beam training accuracy and angular resolution, and enhanced sum-rate performance.

</details>


### [45] [Preemptive Scheduling for Age of Job Minimization in Task-Specific Machine Networks](https://arxiv.org/abs/2602.02435)
*Subhankar Banerjee,Sennur Ulukus*

Main category: cs.IT

TL;DR: 提出基于年龄指标的任务调度策略，包括Whittle指数、最大权重等混合方法，在不同系统规模下各有优势


<details>
  <summary>Details</summary>
Motivation: 在多用户多任务类型的分布式系统中，由于资源限制无法同时服务所有任务，需要设计有效的调度策略来优化任务处理时效性

Method: 引入年龄指标评估调度性能，提出最大权重策略、几何分布下的Whittle指数策略、通用分布下的Whittle指数+最大权重回退策略，以及净收益最大化策略

Result: WIMWF策略在通用分布下表现最佳；系统规模影响策略效果：小系统中最大权重策略优于NGM，大系统中NGM渐近更优；几何分布下Whittle指数策略在所有规模下都最优

Conclusion: 针对不同任务完成时间分布和系统规模，需要采用不同的调度策略来最小化任务年龄，提出的混合策略在通用场景下表现良好

Abstract: We consider a time-slotted job-assignment system consisting of a central server, $N$ task-specific networks of machines, and multiple users. Each network specializes in executing a distinct type of task. Users stochastically generate jobs of various types and forward them to the central server, which routes each job to the appropriate network of machines. Due to resource constraints, the server cannot serve all users' jobs simultaneously, which motivates the design of scheduling policies with possible preemption. To evaluate scheduling performance, we introduce a novel timeliness metric, the age of job, inspired by the well-known metric, the age of information. We study the problem of minimizing the long-term weighted average age of job. We first propose a max-weight policy by minimizing the one-step Lyapunov drift and then derive the Whittle index (WI) policy when the job completion times of the networks of machines follow geometric distributions. For general job completion time distributions, we introduce a Whittle index with max-weight fallback (WIMWF) policy. We also investigate the Net-gain maximization (NGM) policy. Numerically, we show that the proposed WIMWF policy achieves the best performance in the general job completion time setting. We also observe a scaling trend: two different max-weight policies can outperform the NGM policy in small systems, whereas the NGM policy improves as we scale the system size and becomes asymptotically better than max-weight policies. For geometric service times, the WI policy yields the lowest age across all considered system sizes.

</details>


### [46] [Age-Aware Edge-Blind Federated Learning via Over-the-Air Aggregation](https://arxiv.org/abs/2602.02469)
*Ahmed M. Elshazly,Ahmed Arafa*

Main category: cs.IT

TL;DR: 提出一种无需设备端信道状态信息的年龄感知边缘盲空中联邦学习方法，通过多天线MRC检测和AgeTop-k坐标选择，在单OFDM符号内传输模型更新，降低延迟。


<details>
  <summary>Details</summary>
Motivation: 无线联邦学习中，多设备同时发送模型更新面临信道状态信息获取困难、正交子载波有限导致传输延迟增加的问题，需要设计高效的空中计算方案。

Method: 提出年龄感知边缘盲空中联邦学习：1) 设备端无需CSI，PS端使用多天线MRC基于估计的信道增益和检测参数更新；2) 采用AgeTop-k选择算法，优先选择幅度最大且等待时间最长的k个坐标，确保所有选定参数可装入单个OFDM符号。

Result: 1) 更多PS天线显著提高精度和收敛速度；2) 在相对良好信道条件下，AgeTop-k优于随机选择；3) 最优k值取决于信道条件，噪声较大时较小k值更好。

Conclusion: 该方法通过多天线MRC和AgeTop-k坐标选择，有效解决了无线联邦学习中的延迟问题，在信道噪声和压缩误差之间取得了平衡，提高了系统性能。

Abstract: We study federated learning (FL) over wireless fading channels where multiple devices simultaneously send their model updates. We propose an efficient \emph{age-aware edge-blind over-the-air FL} approach that does not require channel state information (CSI) at the devices. Instead, the parameter server (PS) uses multiple antennas and applies maximum-ratio combining (MRC) based on its estimated sum of the channel gains to detect the parameter updates. A key challenge is that the number of orthogonal subcarriers is limited; thus, transmitting many parameters requires multiple Orthogonal Frequency Division Multiplexing (OFDM) symbols, which increases latency. To address this, the PS selects only a small subset of model coordinates each round using \emph{AgeTop-\(k\)}, which first picks the largest-magnitude entries and then chooses the \(k\) coordinates with the longest waiting times since they were last selected. This ensures that all selected parameters fit into a single OFDM symbol, reducing latency. We provide a convergence bound that highlights the advantages of using a higher number of antenna array elements and demonstrates a key trade-off: increasing \(k\) decreases compression error at the cost of increasing the effect of channel noise. Experimental results show that (i) more PS antennas greatly improve accuracy and convergence speed; (ii) AgeTop-\(k\) outperforms random selection under relatively good channel conditions; and (iii) the optimum \(k\) depends on the channel, with smaller \(k\) being better in noisy settings.

</details>


### [47] [Secure Multi-User Linearly-Separable Distributed Computing](https://arxiv.org/abs/2602.02489)
*Amir Masoud Jafarpisheh,Ali Khalesi,Petros Elia*

Main category: cs.IT

TL;DR: 该论文提出了一种在分布式计算框架中实现信息论安全的方法，通过设计满足特定条件的编码方案，确保每个用户只能获取自己请求的函数信息。


<details>
  <summary>Details</summary>
Motivation: 现有的多用户线性可分离分布式计算框架虽然性能接近最优，但其线性特性引发了数据保密性问题。需要设计能够保证信息论安全的方案，确保每个用户无法获取其他用户的信息。

Method: 提出了两个必要且充分的安全准则：(1)每个用户观察到的公共随机性必须恰好跨越α_k-1维子空间；(2)从矩阵D中移除用户观察到的服务器对应列后，矩阵秩至少为K-1。基于这些条件，设计了一个通用方案，通过在E矩阵后附加D的零空间基向量，并精心注入共享随机性来实现安全。

Result: 该方案在有限域情况下能够保证完美的信息论安全，在实数域情况下能够提供明确的互信息界限，通过增加高斯公共随机性的方差可以使互信息任意小。在许多情况下，该方案不会增加额外成本。

Conclusion: 提出的安全分布式计算方案在保持原有性能的同时，解决了线性框架中的数据保密问题，为多用户分布式计算提供了信息论安全保障。

Abstract: The introduction of the new multi-user linearly-separable distributed computing framework, has recently revealed how a parallel treatment of users can yield large parallelization gains with relatively low computation and communication costs. These gains stem from a new approach that converts the computing problem into a sparse matrix factorization problem; a matrix $F$ that describes the users' requests, is decomposed as \(F = DE\), where a \(γ\)-sparse \(E\) defines the task allocation across $N$ servers, and a \(δ\)-sparse \(D\) defines the connectivity between \(N\) servers and \(K\) users as well as the decoding process. While this approach provides near-optimal performance, its linear nature has raised data secrecy concerns.
  We here adopt an information-theoretic secrecy framework, seeking guarantees that each user can learn nothing more than its own requested function. In this context, our main result provides two necessary and sufficient secrecy criteria; (i) for each user \(k\) who observes $α_k$ server responses, the common randomness visible to that user must span a subspace of dimension exactly $α_k-1$,
  and (ii) for each user, removing from \(\mathbf{D}\) the columns corresponding to the servers it observes must leave a matrix of rank at least \(K-1\). With these conditions in place, we design a general scheme -- that applies to finite and non-finite fields alike -- which is based on appending to \(\mathbf{E}\) a basis of \(\mathrm{Null}(\mathbf{D})\) and by carefully injecting shared randomness. In many cases, this entails no additional costs. The scheme, while maintaining performance, guarantees perfect information-theoretic secrecy in the case of finite fields, while in the real case, the conditions yield an explicit mutual-information bound that can be made arbitrarily small by increasing the variance of Gaussian common randomness.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [48] [Frequent Pattern Mining approach to Image Compression](https://arxiv.org/abs/2602.00100)
*Avinash Kadimisetty,C. Oswald,B. Sivalselvan*

Main category: eess.IV

TL;DR: 该论文提出了一种基于频繁模式挖掘的图像压缩方法，通过聚类相似像素并使用聚类标识符进行压缩，相比传统JPEG在压缩率上提升45%，同时保持视觉质量


<details>
  <summary>Details</summary>
Motivation: 传统JPEG压缩中的DCT阶段存在冗余数据处理效率不高的问题，需要更有效的压缩方法来提高压缩率同时保持图像质量

Method: 结合k-means聚类和闭频繁序列挖掘替代传统JPEG的DCT阶段，通过改进的GSP算法优化编码模式基数，提出新的序列频率计算机制减小码表大小

Result: 在基准数据集上测试显示压缩率提升45%，PSNR和SSIM指标显示视觉质量损失可忽略不计，优于现有替代方法

Conclusion: 提出的基于频繁模式挖掘的图像压缩方法在显著提高压缩率的同时保持了良好的视觉质量，为图像压缩提供了有效的新途径

Abstract: The paper focuses on Image Compression, explaining efficient approaches based on Frequent Pattern Mining(FPM). The proposed compression mechanism is based on clustering similar pixels in the image and thus using cluster identifiers in image compression. Redundant data in the image is effectively handled by replacing the DCT phase of conventional JPEG through a mixture of k-means Clustering and Closed Frequent Sequence Mining. To optimize the cardinality of pattern(s) in encoding, efficient pruning techniques have been used through the refinement of Conventional Generalized Sequential Pattern Mining(GSP) algorithm. We have proposed a mechanism for finding the frequency of a sequence which will yield significant reduction in the code table size. The algorithm is tested by compressing benchmark datasets yielding an improvement of 45% in compression ratios, often outperforming the existing alternatives. PSNR and SSIM, which are the image quality metrics, have been tested which show a negligible loss in visual quality.

</details>


### [49] [Radiomics in Medical Imaging: Methods, Applications, and Challenges](https://arxiv.org/abs/2602.00102)
*Fnu Neha,Deepak kumar Shukla*

Main category: eess.IV

TL;DR: 这篇综述对放射组学（Radiomics）进行了端到端分析，探讨了从图像采集到临床应用的整个流程中方法学决策对特征稳定性、模型可靠性和临床转化有效性的影响，并指出了标准化、领域偏移和临床部署等开放挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管放射组学在方法学发展和回顾性研究中取得了鼓舞人心的结果，但仍面临特征不稳定性、可重复性有限、验证偏差和临床转化受限等持续挑战。现有综述大多关注特定应用结果或孤立流程组件，缺乏对整个流程中相互依赖的设计选择如何共同影响稳健性和泛化性的分析。

Method: 提供放射组学流程的端到端分析，审查放射组学特征提取、选择和降维策略；经典机器学习和基于深度学习的方法；集成和混合框架，重点关注验证协议、数据泄漏预防和统计可靠性。强调评估严谨性而非报告的性能指标。

Result: 识别了放射组学在标准化、领域偏移和临床部署方面的开放挑战，并概述了未来方向，包括混合放射组学-人工智能模型、多模态融合、联邦学习和标准化基准测试。

Conclusion: 这篇综述系统分析了放射组学流程中各个环节的相互依赖性，为理解方法学决策如何影响放射组学研究的稳健性和临床转化提供了全面框架，指出了未来研究的关键方向。

Abstract: Radiomics enables quantitative medical image analysis by converting imaging data into structured, high-dimensional feature representations for predictive modeling. Despite methodological developments and encouraging retrospective results, radiomics continue to face persistent challenges related to feature instability, limited reproducibility, validation bias, and restricted clinical translation. Existing reviews largely focus on application-specific outcomes or isolated pipeline components, with limited analysis of how interdependent design choices across acquisition, preprocessing, feature engineering, modeling, and evaluation collectively affect robustness and generalizability. This survey provides an end-to-end analysis of radiomics pipelines, examining how methodological decisions at each stage influence feature stability, model reliability, and translational validity. This paper reviews radiomic feature extraction, selection, and dimensionality reduction strategies; classical machine and deep learning-based modeling approaches; and ensemble and hybrid frameworks, with emphasis on validation protocols, data leakage prevention, and statistical reliability. Clinical applications are discussed with a focus on evaluation rigor rather than reported performance metrics. The survey identifies open challenges in standardization, domain shift, and clinical deployment, and outlines future directions such as hybrid radiomics-artificial intelligence models, multimodal fusion, federated learning, and standardized benchmarking.

</details>


### [50] [Toward a Unified Semantic Loss Model for Deep JSCC-based Transmission of EO Imagery](https://arxiv.org/abs/2602.00136)
*Ti Ti Nguyen,Thanh-Dung Le,Vu Nguyen Ha,Duc-Dung Tran,Hung Nguyen-Kha,Dinh-Hieu Tran,Carlos L. Marcos-Rojas,Juan C. Merlano-Duncan,Symeon Chatzinotas*

Main category: eess.IV

TL;DR: 本文提出一个统一的语义损失框架，用于卫星图像传输中的深度联合信源信道编码，同时考虑重建质量和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 地球观测系统产生的高分辨率图像数据量巨大，而卫星通信系统受限于带宽、功率和动态链路条件，需要有效的传输方案。

Method: 研究深度联合信源信道编码(DJSCC)，从两个互补方面分析语义损失：1)重建中心框架，分析不同压缩比和信道信噪比下的语义退化；2)任务导向框架，将DJSCC与轻量级应用特定模型(如EfficientViT)集成，以下游任务准确性为性能指标。

Result: 基于大量实证分析，提出了一个统一的语义损失框架，能够在一个模型中同时捕捉重建中心和任务导向的性能，揭示了JSCC压缩、信道信噪比和语义质量之间的隐含关系。

Conclusion: 该框架为资源受限卫星链路下设计鲁棒高效的地球观测图像传输系统提供了可行的设计见解。

Abstract: Modern Earth Observation (EO) systems increasingly rely on high-resolution imagery to support critical applications such as environmental monitoring, disaster response, and land-use analysis. Although these applications benefit from detailed visual data, the resulting data volumes impose significant challenges on satellite communication systems constrained by limited bandwidth, power, and dynamic link conditions. To address these limitations, this paper investigates Deep Joint Source-Channel Coding (DJSCC) as an effective source-channel paradigm for the transmission of EO imagery. We focus on two complementary aspects of semantic loss in DJSCC-based systems. First, a reconstruction-centric framework is evaluated by analyzing the semantic degradation of reconstructed images under varying compression ratios and channel signal-to-noise ratios (SNR). Second, a task-oriented framework is developed by integrating DJSCC with lightweight, application-specific models (e.g., EfficientViT), with performance measured using downstream task accuracy rather than pixel-level fidelity. Based on extensive empirical analysis, we propose a unified semantic loss framework that captures both reconstruction-centric and task-oriented performance within a single model. This framework characterizes the implicit relationship between JSCC compression, channel SNR, and semantic quality, offering actionable insights for the design of robust and efficient EO imagery transmission under resource-constrained satellite links.

</details>


### [51] [Visible Singularities Guided Correlation Network for Limited-Angle CT Reconstruction](https://arxiv.org/abs/2602.00184)
*Yiyang Wen,Liu Shi,Zekun Zhou,WenZhe Shan,Qiegen Liu*

Main category: eess.IV

TL;DR: 提出VSGC网络用于有限角度CT重建，通过可见奇异性引导和相关性建模解决方向性伪影问题，在小角度范围表现突出


<details>
  <summary>Details</summary>
Motivation: 有限角度CT(LACT)虽然能减少辐射剂量和扫描时间，但传统重建算法存在固有局限。现有深度学习方法未能充分考虑LACT的核心成像特性：特定方向投影角度缺失导致的方向性伪影和结构信息丢失

Method: 提出可见奇异性引导的相关性网络(VSGC)：1)从LACT图像提取可见奇异性边缘特征，让模型关注这些区域；2)建立可见奇异性边缘特征与图像其他区域的相关性；3)使用具有各向异性约束的多尺度损失函数

Result: 在模拟和真实数据集上的定性和定量验证表明VSGC有效可行。相比其他方法，在小角度范围表现更突出，PSNR提升2.45dB，SSIM提升1.5%

Conclusion: VSGC网络通过可见奇异性引导和相关性建模，有效解决了LACT重建中的方向性伪影问题，在小角度范围重建质量显著提升

Abstract: Limited-angle computed tomography (LACT) offers the advantages of reduced radiation dose and shortened scanning time. Traditional reconstruction algorithms exhibit various inherent limitations in LACT. Currently, most deep learning-based LACT reconstruction methods focus on multi-domain fusion or the introduction of generic priors, failing to fully align with the core imaging characteristics of LACT-such as the directionality of artifacts and directional loss of structural information, which are caused by the absence of projection angles in certain directions. Inspired by the theory of visible and invisible singularities, taking into account the aforementioned core imaging characteristics of LACT, we propose a Visible Singularities Guided Correlation network for LACT reconstruction (VSGC). The design philosophy of VSGC consists of two core steps: First, extract VS edge features from LACT images and focus the model's attention on these VS. Second, establish correlations between the VS edge features and other regions of the image. Additionally, a multi-scale loss function with anisotropic constraint is employed to constrain the model to converge in multiple aspects. Finally, qualitative and quantitative validations are conducted on both simulated and real datasets to verify the effectiveness and feasibility of the proposed design. Particularly, in comparison with alternative methods, VSGC delivers more prominent performance in small angular ranges, with the PSNR improvement of 2.45 dB and the SSIM enhancement of 1.5\%. The code is publicly available at https://github.com/yqx7150/VSGC.

</details>


### [52] [SurfelSoup: Learned Point Cloud Geometry Compression With a Probablistic SurfelTree Representation](https://arxiv.org/abs/2602.00186)
*Tingyu Fan,Ran Gong,Yueyu Hu,Yao Wang*

Main category: eess.IV

TL;DR: SurfelSoup：基于端到端学习的点云几何压缩框架，使用表面结构化基元表示，通过概率表面表示和自适应树结构实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 现有点云压缩方法通常采用体素化表示，在平滑区域存在冗余的点级压缩问题，无法有效利用表面结构的连续性，导致压缩效率不高且重建表面不够平滑。

Method: 提出概率表面表示pSurfel，使用有界广义高斯分布建模局部点占用；构建pSurfelTree层次结构，通过Tree Decision模块自适应终止树细分，实现率失真最优的Surfel粒度选择。

Result: 在MPEG通用测试条件下，相比基于体素的基准方法和MPEG标准G-PCC-GesTM-TriSoup，在几何压缩方面获得一致增益，同时提供视觉上更优的平滑连贯表面重建。

Conclusion: SurfelSoup框架通过表面结构化表示和自适应树结构，有效避免了平滑区域的冗余压缩，实现了紧凑且平滑的表面重建，在点云几何压缩方面表现出优越性能。

Abstract: This paper presents SurfelSoup, an end-to-end learned surface-based framework for point cloud geometry compression, with surface-structured primitives for representation. It proposes a probabilistic surface representation, pSurfel, which models local point occupancies using a bounded generalized Gaussian distribution. In addition, the pSurfels are organized into an octree-like hierarchy, pSurfelTree, with a Tree Decision module that adaptively terminates the tree subdivision for rate-distortion optimal Surfel granularity selection. This formulation avoids redundant point-wise compression in smooth regions and produces compact yet smooth surface reconstructions. Experimental results under the MPEG common test condition show consistent gain on geometry compression over voxel-based baselines and MPEG standard G-PCC-GesTM-TriSoup, while providing visually superior reconstructions with smooth and coherent surface structures.

</details>


### [53] [SCALED : Surrogate-gradient for Codec-Aware Learning of Downsampling in ABR Streaming](https://arxiv.org/abs/2602.00198)
*Esteban Pesnel,Julien Le Tanou,Michael Ropert,Thomas Maugey,Aline Roumy*

Main category: eess.IV

TL;DR: 提出一个使用真实非可微编解码器进行端到端训练的新框架，通过数据驱动的代理梯度实现，相比编解码器无关训练方法在BD-BR(PSNR)上提升5.19%


<details>
  <summary>Details</summary>
Motivation: 传统ABR流媒体处理阶段孤立优化导致端到端率失真性能不佳，现有基于可微代理模型的训练方法无法完全捕捉标准非可微编解码器的行为，缺乏使用标准编解码器训练效率低下的证据

Method: 引入新颖框架，利用从实际压缩误差中推导的数据驱动代理梯度，实现与真实非可微编解码器的端到端训练，促进训练目标与部署性能的对齐

Result: 实验结果显示，相比编解码器无关训练方法，在BD-BR(PSNR)上获得5.19%的改进，在整个率失真凸包上跨多个下采样比率保持一致性

Conclusion: 通过数据驱动代理梯度实现与真实非可微编解码器的端到端训练是可行的，能显著提升ABR流媒体的率失真性能，解决了传统训练方法中的近似偏差问题

Abstract: The rapid growth in video consumption has introduced significant challenges to modern streaming architectures. Over-the-Top (OTT) video delivery now predominantly relies on Adaptive Bitrate (ABR) streaming, which dynamically adjusts bitrate and resolution based on client-side constraints such as display capabilities and network bandwidth. This pipeline typically involves downsampling the original high-resolution content, encoding and transmitting it, followed by decoding and upsampling on the client side. Traditionally, these processing stages have been optimized in isolation, leading to suboptimal end-to-end rate-distortion (R-D) performance. The advent of deep learning has spurred interest in jointly optimizing the ABR pipeline using learned resampling methods. However, training such systems end-to-end remains challenging due to the non-differentiable nature of standard video codecs, which obstructs gradient-based optimization. Recent works have addressed this issue using differentiable proxy models, based either on deep neural networks or hybrid coding schemes with differentiable components such as soft quantization, to approximate the codec behavior. While differentiable proxy codecs have enabled progress in compression-aware learning, they remain approximations that may not fully capture the behavior of standard, non-differentiable codecs. To our knowledge, there is no prior evidence demonstrating the inefficiencies of using standard codecs during training. In this work, we introduce a novel framework that enables end-to-end training with real, non-differentiable codecs by leveraging data-driven surrogate gradients derived from actual compression errors. It facilitates the alignment between training objectives and deployment performance. Experimental results show a 5.19\% improvement in BD-BR (PSNR) compared to codec-agnostic training approaches, consistently across the entire rate-distortion convex hull spanning multiple downsampling ratios.

</details>


### [54] [A Renderer-Enabled Framework for Computing Parameter Estimation Lower Bounds in Plenoptic Imaging Systems](https://arxiv.org/abs/2602.00215)
*Abhinav V. Sambasivan,Liam J. Coulter,Richard G. Paxman,Jarvis D. Haupt*

Main category: eess.IV

TL;DR: 提出一个计算光场成像系统中场景参数估计信息理论下界的通用框架，特别关注被动间接成像问题，使用计算机图形渲染合成前向模型，通过Hammersley-Chapman-Robbins界评估无偏估计器的方差下界。


<details>
  <summary>Details</summary>
Motivation: 评估光场成像系统中场景参数估计的信息理论极限，特别是在被动间接成像问题中，观测数据不包含感兴趣参数的视线信息，需要建立参数估计误差的理论下界。

Method: 使用计算机图形渲染软件合成复杂的前向模型（参数与观测之间的依赖关系），通过Hammersley-Chapman-Robbins界计算无偏估计器的方差下界，并分析不精确渲染对下界的影响。

Result: 在典型目标定位问题上，将计算的下界与最大似然估计器的性能进行比较，表明所提框架计算的下界在多个代表性场景中能够反映真实的基础极限。

Conclusion: 提出的框架能够有效评估光场成像系统中场景参数估计的信息理论极限，为被动间接成像问题提供了参数估计误差的理论下界计算方法，验证了该框架在代表性场景中的有效性。

Abstract: This work focuses on assessing the information-theoretic limits of scene parameter estimation in plenoptic imaging systems. A general framework to compute lower bounds on the parameter estimation error from noisy plenoptic observations is presented, with a particular focus on passive indirect imaging problems, where the observations do not contain line-of-sight information about the parameter(s) of interest. Using computer graphics rendering software to synthesize the often-complicated dependence among parameter(s) of interest and observations, i.e. the forward model, the proposed framework evaluates the Hammersley-Chapman-Robbins bound to establish lower bounds on the variance of any unbiased estimator of the unknown parameters. The effects of inexact rendering of the true forward model on the computed lower bounds are also analyzed, both theoretically and via simulations. Experimental evaluations compare the computed lower bounds with the performance of the Maximum Likelihood Estimator on a canonical object localization problem, showing that the lower bounds computed via the framework proposed here are indicative of the true underlying fundamental limits in several nominally representative scenarios.

</details>


### [55] [Advanced Geometric Correction Algorithms for 3D Medical Reconstruction: Comparison of Computed Tomography and Macroscopic Imaging](https://arxiv.org/abs/2602.00220)
*Tomasz Les,Tomasz Markiewicz,Malgorzata Lorent,Miroslaw Dziekiewicz,Krzysztof Siwek*

Main category: eess.IV

TL;DR: 提出混合两阶段配准框架，从宏观切片重建3D肾脏解剖结构，结合几何约束与深度学习，解决数据稀缺和大变形挑战。


<details>
  <summary>Details</summary>
Motivation: 解决宏观成像中的数据稀缺和高失真问题，传统基于学习的配准方法（如VoxelMorph）由于训练数据有限和大变形超出卷积滤波器捕获范围而难以泛化。

Method: 混合两阶段框架：1) OCM算法进行约束全局对齐（平移、旋转、均匀缩放）；2) 轻量级深度学习细化网络预测相邻切片间的局部变形残差，采用分层分解配准流形设计。

Result: 在40个肾脏的原始数据集上实验，相比单阶段基线方法获得更好结果，通过Hough网格检测保持物理校准，Bezier轮廓平滑实现稳健网格化和体积估计。

Conclusion: 框架将可解释的全局优化与数据高效的深度细化解耦，提高了多模态3D重建的精度、可重复性和解剖真实性，适用于手术规划、形态评估和医学教育。

Abstract: This paper introduces a hybrid two-stage registration framework for reconstructing three-dimensional (3D) kidney anatomy from macroscopic slices, using CT-derived models as the geometric reference standard. The approach addresses the data-scarcity and high-distortion challenges typical of macroscopic imaging, where fully learning-based registration (e.g., VoxelMorph) often fails to generalize due to limited training diversity and large nonrigid deformations that exceed the capture range of unconstrained convolutional filters. In the proposed pipeline, the Optimal Cross-section Matching (OCM) algorithm first performs constrained global alignment: translation, rotation, and uniform scaling to establish anatomically consistent slice initialization. Next, a lightweight deep-learning refinement network, inspired by VoxelMorph, predicts residual local deformations between consecutive slices. The core novelty of this architecture lies in its hierarchical decomposition of the registration manifold. This hybrid OCM+DL design integrates explicit geometric priors with the flexible learning capacity of neural networks, ensuring stable optimization and plausible deformation fields even with few training examples. Experiments on an original dataset of 40 kidneys demonstrated better results compared to single-stage baselines. The pipeline maintains physical calibration via Hough-based grid detection and employs Bezier-based contour smoothing for robust meshing and volume estimation. Although validated on kidney data, the proposed framework generalizes to other soft-tissue organs reconstructed from optical or photographic cross-sections. By decoupling interpretable global optimization from data-efficient deep refinement, the method advances the precision, reproducibility, and anatomical realism of multimodal 3D reconstructions for surgical planning, morphological assessment, and medical education.

</details>


### [56] [Benchmarking Vanilla GAN, DCGAN, and WGAN Architectures for MRI Reconstruction: A Quantitative Analysis](https://arxiv.org/abs/2602.00221)
*Humaira Mehwish,Hina Shakir,Muneeba Rashid,Asarim Aamir,Reema Qaiser Khan*

Main category: eess.IV

TL;DR: 该研究评估了三种GAN模型（Vanilla GAN、DCGAN、WGAN）在MRI重建中的性能，使用膝部、心脏和脑部MRI数据集进行测试，发现DCGAN和WGAN在图像质量和准确性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: MRI是观察内部身体结构的重要成像方式，但需要提高图像质量和诊断准确性。研究旨在评估不同GAN架构在MRI重建中的性能，为临床MRI应用提供可靠的基准。

Method: 使用三种GAN架构：Vanilla GAN、DCGAN和WGAN，在膝部（1000张）、心脏（805张）和脑部（90张）MRI数据集上进行训练和评估。采用SSIM和PSNR作为评估指标，并进行统计验证。

Result: DCGAN表现最佳，SSIM为0.97，PSNR为49.3；WGAN次之，SSIM为0.99，PSNR为43.5；Vanilla GAN最差，SSIM为0.84，PSNR为26。DCGAN和WGAN在图像质量和准确性方面优于Vanilla GAN。

Conclusion: DCGAN和WGAN在MRI重建中表现出色，具有良好的图像质量和准确性。该研究首次在统一预处理流程下建立了跨器官的GAN基准，为未来混合GAN和临床MRI应用提供了可复现的基准。

Abstract: Magnetic Resonance Imaging (MRI) is a crucial imaging modality for viewing internal body structures. This research work analyses the performance of popular GAN models for accurate and precise MRI reconstruction by enhancing image quality and improving diagnostic accuracy. Three GAN architectures considered in this study are Vanilla GAN, Deep Convolutional GAN (DCGAN), and Wasserstein GAN (WGAN). They were trained and evaluated using knee, brain, and cardiac MRI datasets to assess their generalizability across body regions. While the Vanilla GAN operates on the fundamentals of the adversarial network setup, DCGAN advances image synthesis by securing the convolutional layers, giving a superior appearance to the prevalent spatial features. Training instability is resolved in WGAN through the Wasserstein distance to minimize an unstable regime, therefore, ensuring stable convergence and high-quality images. The GAN models were trained and tested using 1000 MR images of an anonymized knee, 805 images of Heart, 90 images of Brain MRI dataset. The Structural Similarity Index (SSIM) for Vanilla GAN is 0.84, DCGAN is 0.97, and WGAN is 0.99. The Peak Signal to Noise Ratio (PSNR) for Vanilla GAN is 26, DCGAN is 49.3, and WGAN is 43.5. The results were further statistically validated. This study shows that DCGAN and WGAN-based frameworks are promising in MR image reconstruction because of good image quality and superior accuracy. With the first cross-organ benchmark of baseline GANs under a common preprocessing pipeline, this work provides a reproducible benchmark for future hybrid GANs and clinical MRI applications.

</details>


### [57] [Recent Advances of End-to-End Video Coding Technologies for AVS Standard Development](https://arxiv.org/abs/2602.00483)
*Xihua Sheng,Xiongzhuang Liang,Chuanbo Tang,Zhirui Zuo,Yifan Bian,Yutao Xie,Zhuoyuan Li,Yuqi Li,Hui Xiang,Li Li,Dong Liu*

Main category: eess.IV

TL;DR: AVS-EEM项目开发了一个面向实际部署的端到端智能视频编码探索模型，在严格复杂度约束下实现了优于传统AVS3参考软件的压缩效率。


<details>
  <summary>Details</summary>
Motivation: 追求更高的视频压缩效率，推动智能视频编码标准化，同时注重实际部署可行性，要求低计算复杂度并符合传统视频编码的通用测试条件。

Method: 建立了AVS端到端智能视频编码探索模型项目，采用系统化的技术框架，包括模型架构设计、训练策略和推理优化，经过两年多的迭代优化和协作努力。

Result: AVS-EEM的最新模型在严格复杂度约束下实现了持续显著的性能提升，压缩效率优于传统的AVS3参考软件。

Conclusion: AVS-EEM项目标志着向可部署智能视频编码标准迈出了重要一步，展示了在保持低计算复杂度的同时实现优越压缩性能的可行性。

Abstract: Video coding standards are essential to enable the interoperability and widespread adoption of efficient video compression technologies. In pursuit of greater video compression efficiency, the AVS video coding working group launched the standardization exploration of end-to-end intelligent video coding, establishing the AVS End-to-End Intelligent Video Coding Exploration Model (AVS-EEM) project. A core design principle of AVS-EEM is its focus on practical deployment, featuring inherently low computational complexity and requiring strict adherence to the common test conditions of conventional video coding. This paper details the development history of AVS-EEM and provides a systematic introduction to its key technical framework, covering model architectures, training strategies, and inference optimizations. These innovations have collectively driven the project's rapid performance evolution, enabling continuous and significant gains under strict complexity constraints. Through over two years of iterative refinement and collaborative effort, the coding performance of AVS-EEM has seen substantial improvement. Experimental results demonstrate that its latest model achieves superior compression efficiency compared to the conventional AVS3 reference software, marking a significant step toward a deployable intelligent video coding standard.

</details>


### [58] [Lightweight Super Resolution-enabled Coding Model for the JPEG Pleno Learning-based Point Cloud Coding Standard](https://arxiv.org/abs/2602.00863)
*André F. R. Guarda,Nuno M. M. Rodrigues,Fernando Pereira*

Main category: eess.IV

TL;DR: 本文提出了一种轻量化的点云几何编码模型，显著降低了JPEG Pleno学习型点云编码标准的复杂度，同时略微提升了压缩效率。


<details>
  <summary>Details</summary>
Motivation: 点云应用需要高效编码方案来处理海量数据，但现有JPEG Pleno学习型点云编码标准复杂度较高，不利于在资源受限环境中广泛采用。

Method: 采用压缩域超分辨率模型方法，并大幅减少潜在通道数量，实现了模型参数约70%的减少。

Result: 模型复杂度显著降低，同时在JPEG Pleno点云编码数据集上实现了轻微的平均压缩性能提升。

Conclusion: 提出的轻量化点云几何编码模型在保持甚至略微提升压缩效率的同时，大幅降低了计算复杂度，有助于学习型点云编码标准在资源受限环境中的推广应用。

Abstract: While point cloud-based applications are gaining traction due to their ability to provide rich and immersive experiences, they critically need efficient coding solutions due to the large volume of data involved, often many millions of points per object. The JPEG Pleno Learning-based Point Cloud Coding standard, as the first learning-based coding standard for static point clouds, has set a foundational framework with very competitive compression performance regarding the relevant conventional and learning-based alternative point cloud coding solutions. This paper proposes a novel lightweight point cloud geometry coding model that significantly reduces the complexity of the standard, which is essential for the broad adoption of this coding standard, particularly in resource-constrained environments, while simultaneously achieving small average compression efficiency benefits. The novel coding model is based on the pioneering adoption of a compressed domain approach for the super-resolution model, in addition to a major reduction of the number of latent channels. A reduction of approximately 70% in the total number of model parameters is achieved while simultaneously offering slight average compression performance gains for the JPEG Pleno Point Cloud coding dataset.

</details>


### [59] [Diagnostic Impact of Cine Clips for Thyroid Nodule Assessment on Ultrasound](https://arxiv.org/abs/2602.00990)
*Jichen Yang,Brian C. Allen,Kirti Magudia,Lisa M. Ho,Chad M. Miller,Maciej A. Mazurowski,Benjamin Wildman-Tobriner*

Main category: eess.IV

TL;DR: 甲状腺超声中cine影像（动态视频）的加入对诊断准确性无显著改善，现有静态图像诊断方法已足够


<details>
  <summary>Details</summary>
Motivation: 甲状腺超声通常结合静态图像和cine影像（视频记录），但cine影像的确切效用和影响尚不清楚。本研究旨在评估cine影像对甲状腺结节评估准确性和一致性的影响。

Method: 纳入50个良性和50个恶性甲状腺结节，由4名专科放射科医生进行3轮阅片研究：前两轮仅评估静态图像，第三轮同时评估静态和cine影像，使用ACR TI-RADS系统评分并比较诊断结果。

Result: 恶性检测的平均灵敏度：静态图像0.65，静态+cine影像0.67（p>0.5）；特异性：静态图像0.20，静态+cine影像0.22（p>0.5）。管理建议相似，阅片者内部一致性保持稳定，TI-RADS总分在cine影像下略高。

Conclusion: 甲状腺超声结节评估中加入cine影像并未显著改变诊断性能，当前不强制要求cine影像的实践指南足以保证准确诊断。

Abstract: Background: Thyroid ultrasound is commonly performed using a combination of static images and cine clips (video recordings). However, the exact utility and impact of cine images remains unknown. This study aimed to evaluate the impact of cine imaging on accuracy and consistency of thyroid nodule assessment, using the American College of Radiology Thyroid Reporting and Data System (ACR TI-RADS). Methods: 50 benign and 50 malignant thyroid nodules with cytopathology results were included. A reader study with 4 specialty-trained radiologists was then conducted over 3 rounds, assessing only static images in the first two rounds and both static and cine images in the third round. TI-RADS scores and the consequent management recommendations were then evaluated by comparing them to the malignancy status of the nodules. Results: Mean sensitivity for malignancy detection was 0.65 for static images and 0.67 with both static and cine images (p>0.5). Specificity was 0.20 for static images and 0.22 with both static and cine images (p>0.5). Management recommendations were similar with and without cine images. Intrareader agreement on feature assignments remained consistent across all rounds, though TI-RADS point totals were slightly higher with cine images. Conclusion: The inclusion of cine imaging for thyroid nodule assessment on ultrasound did not significantly change diagnostic performance. Current practice guidelines, which do not mandate cine imaging, are sufficient for accurate diagnosis.

</details>


### [60] [Coordinate-conditioned Deconvolution for Scalable Spatially Varying High-Throughput Imaging](https://arxiv.org/abs/2602.01065)
*Qianwan Yang,Zhixiong Chen,Jiaqi Zhang,Ruipeng Guo,Guorong Hu,Lei Tian*

Main category: eess.IV

TL;DR: SV-CoDe：一种基于坐标条件卷积的深度学习框架，用于校正紧凑光学系统中的空间变化模糊，实现大视场下的均匀高分辨率重建。


<details>
  <summary>Details</summary>
Motivation: 紧凑光学系统的宽场荧光显微镜存在空间变化的模糊问题，包括场依赖像差、渐晕和传感器截断。现有学习方法使用全局空间变化算子，导致内存和训练成本随图像尺寸急剧增加，难以扩展。

Method: 提出SV-CoDe框架，采用坐标条件卷积局部适应重建核，实现基于补丁的训练，使参数数量与视场大小解耦。通过物理模拟训练，可推广到实际生物样本。

Result: 在模拟和实验测量中均获得最佳图像质量，模型大小减少10倍，训练数据需求减少10倍。在珠状模型、弱散射脑切片和自由运动线虫中均表现出鲁棒泛化能力。

Conclusion: SV-CoDe为紧凑光学系统的空间变化模糊校正提供了可扩展的物理感知解决方案，可广泛应用于生物医学成像领域。

Abstract: Wide-field fluorescence microscopy with compact optics often suffers from spatially varying blur due to field-dependent aberrations, vignetting, and sensor truncation, while finite sensor sampling imposes an inherent trade-off between field of view (FOV) and resolution. Computational Miniaturized Mesoscope (CM2) alleviate the sampling limit by multiplexing multiple sub-views onto a single sensor, but introduce view crosstalk and a highly ill-conditioned inverse problem compounded by spatially variant point spread functions (PSFs). Prior learning-based spatially varying (SV) reconstruction methods typically rely on global SV operators with fixed input sizes, resulting in memory and training costs that scale poorly with image dimensions. We propose SV-CoDe (Spatially Varying Coordinate-conditioned Deconvolution), a scalable deep learning framework that achieves uniform, high-resolution reconstruction across a 6.5 mm FOV. Unlike conventional methods, SV-CoDe employs coordinate-conditioned convolutions to locally adapt reconstruction kernels; this enables patch-based training that decouples parameter count from FOV size. SV-CoDe achieves the best image quality in both simulated and experimental measurements while requiring 10x less model size and 10x less training data than prior baselines. Trained purely on physics-based simulations, the network robustly generalizes to bead phantoms, weakly scattering brain slices, and freely moving C. elegans. SV-CoDe offers a scalable, physics-aware solution for correcting SV blur in compact optical systems and is readily extendable to a broad range of biomedical imaging applications.

</details>


### [61] [Unified ROI-based Image Compression Paradigm with Generalized Gaussian Model](https://arxiv.org/abs/2602.01325)
*Kai Hu,Junfu Tan,Fang Xu,Ramy Samy,Yu Liu*

Main category: eess.IV

TL;DR: 提出基于广义高斯模型(Generalized Gaussian Model, GGM)的ROI图像压缩方法，通过灵活建模潜在变量分布，提升ROI编码性能


<details>
  <summary>Details</summary>
Motivation: ROI图像压缩中比特分配不均导致分布呈现尖峰厚尾特征，现有高斯模型无法准确描述这种分布，导致编码性能损失

Method: 1) 建立统一的率失真优化理论框架；2) 提出广义高斯模型(GGM)灵活建模潜在变量分布；3) 引入可微函数和动态下界稳定优化；4) 使用有限差分法计算梯度

Result: 在COCO2017数据集上，ROI重建和下游任务(分割、目标检测)均达到SOTA；相比经典概率模型，GGM能更精确拟合特征分布，获得更优编码性能

Conclusion: GGM能有效建模ROI压缩中的尖峰厚尾分布，显著提升编码性能，为ROI图像压缩提供了更精确的概率建模方法

Abstract: Region-of-Interest (ROI)-based image compression allocates bits unevenly according to the semantic importance of different regions. Such differentiated coding typically induces a sharp-peaked and heavy-tailed distribution. This distribution characteristic mathematically necessitates a probability model with adaptable shape parameters for accurate description. However, existing methods commonly use a Gaussian model to fit this distribution, resulting in a loss of coding performance. To systematically analyze the impact of this distribution on ROI coding, we develop a unified rate-distortion optimization theoretical paradigm. Building on this paradigm, we propose a novel Generalized Gaussian Model (GGM) to achieve flexible modeling of the latent variables distribution. To support stable optimization of GGM, we introduce effective differentiable functions and further propose a dynamic lower bound to alleviate train-test mismatch. Moreover, finite differences are introduced to solve the gradient computation after GGM fits the distribution. Experiments on COCO2017 demonstrate that our method achieves state-of-the-art in both ROI reconstruction and downstream tasks (e.g., Segmentation, Object Detection). Furthermore, compared to classical probability models, our GGM provides a more precise fit to feature distributions and achieves superior coding performance. The project page is at https://github.com/hukai-tju/ROIGGM.

</details>


### [62] [A texture-based framework for foundational ultrasound models](https://arxiv.org/abs/2602.01444)
*Tal Grutman,Carmel Shinar,Tali Ilovitsh*

Main category: eess.IV

TL;DR: 提出TUSA方法，将自监督学习重新定义为纹理分析问题，专门针对超声图像的物理特性进行优化，相比通用基础模型在多种医学任务上表现更好。


<details>
  <summary>Details</summary>
Motivation: 超声图像具有独特的声学纹理特征，与自然图像统计特性差异很大。现有的基础模型虽然被应用于超声领域，但它们并非为超声物理特性设计，仅是在超声数据上训练，因此在超声应用中表现不佳。需要将超声特定的领域知识整合到学习框架中。

Method: 提出纹理超声语义分析（TUSA）方法，将自监督学习重新定义为纹理分析问题。使用对比学习方法从简单的B模式图像中提取真正的领域特定表示。在开源数据、模拟数据和体内数据的组合上训练TUSA模型。

Result: TUSA模型在多个困难的下游任务上表现出更好的泛化能力：COVID检测（70%准确率）、脊髓血肿（100%）、玻璃体出血（97%）。与定量参数的相关性更强：肝脏脂肪变性（r=0.83）、射血分数（r=0.63）、氧饱和度（r=0.38）。

Conclusion: 通过将超声特定领域知识整合到学习框架中，TUSA方法能够从超声图像中提取更有意义的表示，相比通用基础模型在医学超声任务上表现更优。作者开源了模型权重和训练脚本。

Abstract: Ultrasound is the most widely used medical imaging modality, yet the images it produces are fundamentally unique, arising from tissue-dependent scattering, reflection, and speed-of-sound variations that produce a constrained set of characteristic textures that differ markedly from natural-image statistics. These acoustically driven patterns make ultrasound challenging for algorithms originally designed for natural images. To bridge this gap, the field has increasingly turned to foundation models, hoping to leverage their generalization capabilities. However, these models often falter in ultrasound applications because they are not designed for ultrasound physics, they are merely trained on ultrasound data. Therefore, it is essential to integrate ultrasound-specific domain knowledge into established learning frameworks. We achieve this by reformulating self-supervised learning as a texture-analysis problem, introducing texture ultrasound semantic analysis (TUSA). Using TUSA, models learn to leverage highly scalable contrastive methods to extract true domain-specific representations directly from simple B-mode images. We train a TUSA model on a combination of open-source, simulated, and in vivo data. The latent space is compared to several larger foundation models, demonstrating that our approach gives TUSA models better generalizability for difficult downstream tasks on unique online datasets as well as a clinical eye dataset collected for this study. Our model achieves higher accuracy in detecting COVID (70%), spinal hematoma (100%) and vitreous hemorrhage (97%) and correlates more closely with quantitative parameters like liver steatosis (r = 0.83), ejection fraction (r = 0.63), and oxygen saturation (r = 0.38). We open-source the model weights and training script: https://github.com/talg2324/tusa

</details>


### [63] [MarkCleaner: High-Fidelity Watermark Removal via Imperceptible Micro-Geometric Perturbation](https://arxiv.org/abs/2602.01513)
*Xiaoxi Kong,Jieyu Yuan,Pengdi Chen,Yuanlin Zhang,Chongyi Li,Bin Li*

Main category: eess.IV

TL;DR: MarkCleaner是一个通过微几何扰动去除语义水印的框架，避免传统方法导致的语义漂移，实现高效实时推理


<details>
  <summary>Details</summary>
Motivation: 语义水印对传统图像空间攻击具有强鲁棒性，但研究发现微几何扰动（空间位移）可以通过破坏相位对齐来去除水印，而现有的基于再生的水印去除方法会导致语义漂移

Method: MarkCleaner框架采用微几何扰动监督训练，包含掩码引导编码器学习显式空间表示，以及基于2D高斯泼溅的解码器显式参数化几何扰动同时保持语义内容

Result: 大量实验表明MarkCleaner在水印去除效果和视觉保真度方面均表现优异，同时支持高效的实时推理

Conclusion: 微几何扰动是去除语义水印的有效方法，MarkCleaner框架在保持语义内容的同时实现了高效的水印去除，为水印鲁棒性研究提供了新视角

Abstract: Semantic watermarks exhibit strong robustness against conventional image-space attacks. In this work, we show that such robustness does not survive under micro-geometric perturbations: spatial displacements can remove watermarks by breaking the phase alignment. Motivated by this observation, we introduce MarkCleaner, a watermark removal framework that avoids semantic drift caused by regeneration-based watermark removal. Specifically, MarkCleaner is trained with micro-geometry-perturbed supervision, which encourages the model to separate semantic content from strict spatial alignment and enables robust reconstruction under subtle geometric displacements. The framework adopts a mask-guided encoder that learns explicit spatial representations and a 2D Gaussian Splatting-based decoder that explicitly parameterizes geometric perturbations while preserving semantic content. Extensive experiments demonstrate that MarkCleaner achieves superior performance in both watermark removal effectiveness and visual fidelity, while enabling efficient real-time inference. Our code will be made available upon acceptance.

</details>


### [64] [Hyperspectral Image Fusion with Spectral-Band and Fusion-Scale Agnosticism](https://arxiv.org/abs/2602.01681)
*Yu-Jie Liang,Zihan Cao,Liang-Jian Deng,Yang Yang,Malu Zhang*

Main category: eess.IV

TL;DR: 提出SSA框架，通过Matryoshka Kernel实现光谱通道数无关性，结合INR实现空间尺度无关性，构建通用的MS/HS融合模型，可泛化到未见过的传感器和空间尺度。


<details>
  <summary>Details</summary>
Motivation: 当前多光谱/高光谱图像融合模型通常针对固定光谱波段和空间尺度设计，限制了它们在不同传感器间的可迁移性，需要一种通用的融合框架来解决这一问题。

Method: 提出SSA通用框架：1) 引入Matryoshka Kernel算子，使单个模型能适应任意数量的光谱通道；2) 基于隐式神经表示(INR)建模高光谱信号为连续函数，实现任意空间分辨率的重建。

Result: 大量实验表明，单个SSA模型在保持最先进性能的同时，能很好地泛化到未见过的传感器和空间尺度。

Conclusion: SSA框架通过光谱波段和融合尺度的无关性设计，为构建未来高光谱基础模型铺平了道路，实现了真正通用的MS/HS融合。

Abstract: Current deep learning models for Multispectral and Hyperspectral Image Fusion (MS/HS fusion) are typically designed for fixed spectral bands and spatial scales, which limits their transferability across diverse sensors. To address this, we propose SSA, a universal framework for MS/HS fusion with spectral-band and fusion-scale agnosticism. Specifically, we introduce Matryoshka Kernel (MK), a novel operator that enables a single model to adapt to arbitrary numbers of spectral channels. Meanwhile, we build SSA upon an Implicit Neural Representation (INR) backbone that models the HS signal as a continuous function, enabling reconstruction at arbitrary spatial resolutions. Together, these two forms of agnosticism enable a single MS/HS fusion model that generalizes effectively to unseen sensors and spatial scales. Extensive experiments demonstrate that our single model achieves state-of-the-art performance while generalizing well to unseen sensors and scales, paving the way toward future HS foundation models.

</details>


### [65] [Edge-Aligned Initialization of Kernels for Steered Mixture-of-Experts](https://arxiv.org/abs/2602.02031)
*Martin Determann,Elvira Fleig*

Main category: eess.IV

TL;DR: 提出基于边缘检测的SMoE初始化方法，减少随机优化需求，降低计算成本


<details>
  <summary>Details</summary>
Motivation: SMoE框架在图像建模中表现出色，但依赖每张图像的梯度优化，计算密集且难以扩展，需要更好的初始化策略

Method: 使用Canny边缘检测提取稀疏图像轮廓，确定性地推断核位置和方向，并直接估计专家系数初始值

Result: 在保持良好重建质量的同时，显著减少随机优化需求，降低内存消耗和计算成本

Conclusion: 提出的边缘初始化方案为SMoE提供了高效实用的初始化方法，有助于推动该框架的实际应用

Abstract: Steered Mixture-of-Experts (SMoE) has recently emerged as a powerful framework for spatial-domain image modeling, enabling high-fidelity image representation using a remarkably small number of parameters. Its ability to steer kernel-based experts toward structural image features has led to successful applications in image compression, denoising, super-resolution, and light field processing. However, practical adoption is hindered by the reliance on gradient-based optimization to estimate model parameters on a per-image basis - a process that is computationally intensive and difficult to scale. Initialization strategies for SMoE are an essential component that directly affects convergence and reconstruction quality. In this paper, we propose a novel, edge-based initialization scheme that achieves good reconstruction qualities while reducing the need for stochastic optimization significantly. Through a method that leverages Canny edge detection to extract a sparse set of image contours, kernel positions and orientations are deterministically inferred. A separate approach enables the direct estimation of initial expert coefficients. This initialization reduces both memory consumption and computational cost.

</details>
