<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 12]
- [cs.IT](#cs.IT) [Total: 9]
- [eess.SP](#eess.SP) [Total: 30]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Training-Free Adaptive Quantization for Variable Rate Image Coding for Machines](https://arxiv.org/abs/2511.05836)
*Yui Tatsumi,Ziyue Zeng,Hiroshi Watanabe*

Main category: eess.IV

TL;DR: 提出了一种无需训练的自适应量化步长控制方案，用于图像机器编码(ICM)，通过单一参数实现连续比特率控制，在保持语义重要区域的同时粗量化次要区域。


<details>
  <summary>Details</summary>
Motivation: 现有ICM框架大多使用固定比特率的LIC模型，需要为每个目标比特率单独训练，限制了实际应用。现有的可变比特率方法依赖训练，增加了计算成本和部署复杂性。

Method: 利用通道熵依赖性和超先验网络预测的空间尺度参数，提出无需训练的自适应量化步长控制方案，通过单一参数连续控制比特率。

Result: 实验结果表明该方法有效，相比非自适应可变比特率方法实现了高达11.07%的BD-rate节省。

Conclusion: 该方法解决了ICM中可变比特率控制的挑战，提供了一种灵活且高效的比特率调整方案。

Abstract: Image Coding for Machines (ICM) has become increasingly important with the rapid integration of computer vision into real-world applications. However, most ICM frameworks utilize learned image compression (LIC) models that operate at a fixed rate and require separate training for each target bitrate, which may limit their practical applications. Existing variable rate LIC approaches mitigate this limitation but typically depend on training, increasing computational cost and deployment complexity. Moreover, variable rate control has not been thoroughly explored for ICM. To address these challenges, we propose a training-free, adaptive quantization step size control scheme that enables flexible bitrate adjustment. By leveraging both channel-wise entropy dependencies and spatial scale parameters predicted by the hyperprior network, the proposed method preserves semantically important regions while coarsely quantizing less critical areas. The bitrate can be continuously controlled through a single parameter. Experimental results demonstrate the effectiveness of our proposed method, achieving up to 11.07% BD-rate savings over the non-adaptive variable rate method.

</details>


### [2] [SPASHT: An image-enhancement method for sparse-view MPI SPECT](https://arxiv.org/abs/2511.06203)
*Zezhang Yang,Zitong Yu,Nuri Choi,Janice Tania,Wenxuan Xue,Barry A. Siegel,Abhinav K. Jha*

Main category: eess.IV

TL;DR: SPASHT是一种用于改善稀疏投影心肌灌注SPECT图像质量的算法，通过减少投影视图数量来缩短扫描时间，同时保持缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统心肌灌注SPECT扫描时间长，导致患者不适和运动伪影。减少投影视图可以缩短扫描时间，但会降低图像质量。

Method: 提出SPASHT算法，专门训练用于提高缺陷检测性能，在1/6、1/3和1/2标准投影视图下进行评估。

Result: SPASHT在所有测试的稀疏投影条件下都显著提高了AUC值，人类观察者研究也证实了检测性能的改善。

Conclusion: SPASHT能有效提高稀疏投影MPI SPECT图像质量，值得进一步临床验证。

Abstract: Single-photon emission computed tomography for myocardial perfusion imaging (MPI SPECT) is a widely used diagnostic tool for coronary artery disease. However, the procedure requires considerable scanning time, leading to patient discomfort and the potential for motion-induced artifacts. Reducing the number of projection views while keeping the time per view unchanged provides a mechanism to shorten the scanning time. However, this approach leads to increased sampling artifacts, higher noise, and hence limited image quality. To address these issues, we propose sparseview SPECT image enhancement (SPASHT), inherently training the algorithm to improve performance on defect-detection tasks. We objectively evaluated SPASHT on the clinical task of detecting perfusion defects in a retrospective clinical study using data from patients who underwent MPI SPECT, where the defects were clinically realistic and synthetically inserted. The study was conducted for different numbers of fewer projection views, including 1/6, 1/3, and 1/2 of the typical projection views for MPI SPECT. Performance on the detection task was quantified using area under the receiver operating characteristic curve (AUC). Images obtained with SPASHT yielded significantly improved AUC compared to those obtained with the sparse-view protocol for all the considered numbers of fewer projection views. To further assess performance, a human observer study on the task of detecting perfusion defects was conducted. Results from the human observer study showed improved detection performance with images reconstructed using SPASHT compared to those from the sparse-view protocol. The results provide evidence of the efficacy of SPASHT in improving the quality of sparse-view MPI SPECT images and motivate further clinical validation.

</details>


### [3] [A Visual Perception-Based Tunable Framework and Evaluation Benchmark for H.265/HEVC ROI Encryption](https://arxiv.org/abs/2511.06394)
*Xiang Zhang,Geng Wu,Wenbin Huang,Daoyong Fu,Fei Peng,Zhangjie Fu*

Main category: eess.IV

TL;DR: 提出基于视觉感知的可调框架和评估基准，用于H.265/HEVC ROI选择性加密，解决现有方法灵活性不足和缺乏统一评估体系的问题。


<details>
  <summary>Details</summary>
Motivation: 现有ROI视频加密方法存在灵活性不足和缺乏统一评估系统的问题，需要一种既能保证安全又最小化编码效率影响的隐私保护技术。

Method: 1) 基于视觉感知网络的ROI区域识别模块；2) 三级可调加密策略平衡安全性和实时性；3) 统一的ROI加密评估基准。

Result: 实验结果表明，提出的基准能全面衡量ROI选择性加密性能，相比现有算法，增强和高级加密级别在多个性能指标上表现更优。

Conclusion: 该框架有效满足H.265/HEVC隐私保护需求，为敏感视频内容的安全高效处理提供可靠解决方案。

Abstract: ROI selective encryption, as an efficient privacy protection technique, encrypts only the key regions in the video, thereby ensuring security while minimizing the impact on coding efficiency. However, existing ROI-based video encryption methods suffer from insufficient flexibility and lack of a unified evaluation system. To address these issues, we propose a visual perception-based tunable framework and evaluation benchmark for H.265/HEVC ROI encryption. Our scheme introduces three key contributions: 1) A ROI region recognition module based on visual perception network is proposed to accurately identify the ROI region in videos. 2) A three-level tunable encryption strategy is implemented while balancing security and real-time performance. 3) A unified ROI encryption evaluation benchmark is developed to provide a standardized quantitative platform for subsequent research. This triple strategy provides new solution and significant unified performance evaluation methods for ROI selective encryption field. Experimental results indicate that the proposed benchmark can comprehensively measure the performance of the ROI selective encryption. Compared to existing ROI encryption algorithms, our proposed enhanced and advanced level encryption exhibit superior performance in multiple performance metrics. In general, the proposed framework effectively meets the privacy protection requirements in H.265/HEVC and provides a reliable solution for secure and efficient processing of sensitive video content.

</details>


### [4] [Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression](https://arxiv.org/abs/2511.06424)
*Amit Vaisman,Guy Ohayon,Hila Manor,Michael Elad,Tomer Michaeli*

Main category: eess.IV

TL;DR: Turbo-DDCM是一种高效的零样本扩散压缩方法，通过在每个去噪步骤中组合大量噪声向量，显著减少去噪操作次数，同时保持与最先进技术相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本扩散压缩方法虽然取得了显著进展，但速度缓慢且计算需求高，需要更高效的解决方案。

Method: 基于DDCM压缩方案改进，通过在每个去噪步骤中高效组合大量噪声向量来减少去噪操作次数，并改进了编码协议，还提出了两种变体：优先感知变体和失真控制变体。

Result: Turbo-DDCM运行速度显著快于现有方法，同时保持与最先进技术相当的性能，被定位为有吸引力、实用且灵活的图像压缩方案。

Conclusion: Turbo-DDCM通过减少去噪操作次数和提供灵活的压缩选项，为扩散基压缩方法提供了实用的解决方案。

Abstract: While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme.

</details>


### [5] [Compressive Sensing Photoacoustic Imaging Receiver with Matrix-Vector-Multiplication SAR ADC](https://arxiv.org/abs/2511.06580)
*Huan-Cheng Liao,Shunyao Zhang,Yumin Su,Arvind Govinday,Yiwei Zou,Wei Wang,Vivek Boominathan,Ashok Veeraraghavan,Lei S. Li,Kaiyuan Yang*

Main category: eess.IV

TL;DR: 提出了一种在硬件中嵌入压缩感知的光声成像接收器，通过模拟域压缩实现4-8倍数据率降低，同时保持低损耗的全阵列信息。


<details>
  <summary>Details</summary>
Motivation: 可穿戴光声成像设备在连续健康监测和即时诊断方面前景广阔，但高密度传感器阵列产生的大数据量是实现紧凑、高效能可穿戴系统的主要挑战。

Method: 集成16个模拟前端和4个矩阵向量乘法SAR ADC，在模拟域执行能量和面积高效的压缩。采用两种信号重建方法：基于快速迭代收缩阈值算法的优化方法和基于隐式神经表示的学习方法。

Result: 在65nm CMOS工艺中实现，ADC的SNDR达到57.5dB@20.41MS/s，模拟前端输入参考噪声为3.5nV/sqrt(Hz)。MVM线性度测量显示在广泛的权重和输入幅度范围内R^2>0.999。幻影成像实验验证了在8倍压缩下仍能实现高保真图像重建。

Conclusion: 该接收器每通道功耗5.83mW，支持通用的三元加权测量矩阵，为下一代小型化可穿戴光声成像系统提供了有吸引力的解决方案。

Abstract: Wearable photoacoustic imaging devices hold great promise for continuous health monitoring and point-of-care diagnostics. However, the large data volume generated by high-density transducer arrays presents a major challenge for realizing compact and power-efficient wearable systems. This paper presents a photoacoustic imaging receiver (RX) that embeds compressive sensing directly into the hardware to address this bottleneck. The RX integrates 16 AFEs and four matrix-vector-multiplication (MVM) SAR ADCs that perform energy- and area-efficient analog-domain compression. The architecture achieves a 4-8x reduction in output data rate while preserving low-loss full-array information. The MVM SAR ADC executes passive and accurate MVM using user-defined programmable ternary weights. Two signal reconstruction methods are implemented: (1) an optimization approach using the fast iterative shrinkage-thresholding algorithm, and (2) a learning-based approach employing implicit neural representation. Fabricated in 65 nm CMOS, the chip achieves an ADC's SNDR of 57.5 dB at 20.41 MS/s, with an AFE input-referred noise of 3.5 nV/sqrt(Hz). MVM linearity measurements show R^2 > 0.999 across a wide range of weights and input amplitudes. The system is validated through phantom imaging experiments, demonstrating high-fidelity image reconstruction under up to 8x compression. The RX consumes 5.83 mW/channel and supports a general ternary-weighted measurement matrix, offering a compelling solution for next-generation miniaturized, wearable PA imaging systems.

</details>


### [6] [Hierarchical Spatial-Frequency Aggregation for Spectral Deconvolution Imaging](https://arxiv.org/abs/2511.06751)
*Tao Lv,Daoming Zhou,Chenglong Huang,Chongde Zi,Linsen Chen,Xun Cao*

Main category: eess.IV

TL;DR: 提出HSFAUT方法解决光谱解卷积成像中的场景依赖性问题，通过层次化空间-频谱聚合展开框架和Transformer实现高效高保真重建


<details>
  <summary>Details</summary>
Motivation: 传统计算光谱成像方法存在体积庞大和保真度有限的问题，而基于PSF工程的光谱解卷积方法虽然紧凑，但其复合卷积-积分操作导致系数矩阵场景依赖，阻碍成像先验的有效利用和准确重建

Method: 提出层次化空间-频谱聚合展开框架(HSFAUF)，将非线性过程转化为线性映射；设计空间-频率聚合Transformer(SFAT)在迭代优化中整合空间-频谱先验；最终开发基于Transformer的深度展开方法HSFAUT

Result: 系统模拟和真实实验表明，HSFAUT在内存和计算成本更低的情况下超越现有最优方法，在不同SDI系统上均表现出最优性能

Conclusion: HSFAUT有效解决了SDI中的场景依赖性问题，实现了高效高保真的光谱成像重建，为紧凑型计算光谱成像提供了有力解决方案

Abstract: Computational spectral imaging (CSI) achieves real-time hyperspectral imaging through co-designed optics and algorithms, but typical CSI methods suffer from a bulky footprint and limited fidelity. Therefore, Spectral Deconvolution imaging (SDI) methods based on PSF engineering have been proposed to achieve high-fidelity compact CSI design recently. However, the composite convolution-integration operations of SDI render the normal-equation coefficient matrix scene-dependent, which hampers the efficient exploitation of imaging priors and poses challenges for accurate reconstruction. To tackle the inherent data-dependent operators in SDI, we introduce a Hierarchical Spatial-Spectral Aggregation Unfolding Framework (HSFAUF). By decomposing subproblems and projecting them into the frequency domain, HSFAUF transforms nonlinear processes into linear mappings, thereby enabling efficient solutions. Furthermore, to integrate spatial-spectral priors during iterative refinement, we propose a Spatial-Frequency Aggregation Transformer (SFAT), which explicitly aggregates information across spatial and frequency domains. By integrating SFAT into HSFAUF, we develop a Transformer-based deep unfolding method, \textbf{H}ierarchical \textbf{S}patial-\textbf{F}requency \textbf{A}ggregation \textbf{U}nfolding \textbf{T}ransformer (HSFAUT), to solve the inverse problem of SDI. Systematic simulated and real experiments show that HSFAUT surpasses SOTA methods with cheaper memory and computational costs, while exhibiting optimal performance on different SDI systems.

</details>


### [7] [RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research](https://arxiv.org/abs/2511.06769)
*Ridoy Chandra Shil,Ragib Abid,Tasnia Binte Mamun,Samiul Based Shuvo,Masfique Ahmed Bhuiyan,Jahid Ferdous*

Main category: eess.IV

TL;DR: 介绍了BUET息肉数据集(BPD)，这是一个包含真实临床条件下结肠镜图像的公开数据集，包含息肉图像和无息肉图像，并提供了分类和分割的基准性能结果。


<details>
  <summary>Details</summary>
Motivation: 现有的结肠息肉公共数据集样本量小、图像经过筛选或缺乏真实世界伪影，需要能反映临床实践复杂性的数据集，特别是在资源受限的环境中。

Method: 使用Olympus 170和Pentax i-Scan系列内窥镜在常规临床条件下收集结肠镜图像，包含专家标注的二元掩码，反映了运动模糊、镜面高光、粪便伪影、血液和低光照等挑战。提供了使用VGG16、ResNet50和InceptionV3的分类基准，以及使用UNet变体的分割基准。

Result: 数据集包含来自164名患者的1,288张息肉图像和来自31名患者的1,657张无息肉图像。基准实验显示二元分类最高准确率达90.8%(VGG16)，分割最高Dice分数为0.64(InceptionV4-UNet)。与筛选数据集相比性能较低，反映了真实世界图像的难度。

Conclusion: BPD数据集提供了反映临床实践复杂性的结肠镜图像资源，基准结果表明在真实世界条件下检测息肉具有挑战性，为开发更鲁棒的算法提供了基础。

Abstract: Background and Objective: Colorectal cancer prevention relies on early detection of polyps during colonoscopy. Existing public datasets, such as CVC-ClinicDB and Kvasir-SEG, provide valuable benchmarks but are limited by small sample sizes, curated image selection, or lack of real-world artifacts. There remains a need for datasets that capture the complexity of clinical practice, particularly in resource-constrained settings. Methods: We introduce a dataset, BUET Polyp Dataset (BPD), of colonoscopy images collected using Olympus 170 and Pentax i-Scan series endoscopes under routine clinical conditions. The dataset contains images with corresponding expert-annotated binary masks, reflecting diverse challenges such as motion blur, specular highlights, stool artifacts, blood, and low-light frames. Annotations were manually reviewed by clinical experts to ensure quality. To demonstrate baseline performance, we provide benchmark results for classification using VGG16, ResNet50, and InceptionV3, and for segmentation using UNet variants with VGG16, ResNet34, and InceptionV4 backbones. Results: The dataset comprises 1,288 images with polyps from 164 patients with corresponding ground-truth masks and 1,657 polyp-free images from 31 patients. Benchmarking experiments achieved up to 90.8% accuracy for binary classification (VGG16) and a maximum Dice score of 0.64 with InceptionV4-UNet for segmentation. Performance was lower compared to curated datasets, reflecting the real-world difficulty of images with artifacts and variable quality.

</details>


### [8] [Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT](https://arxiv.org/abs/2511.07047)
*Simone Bendazzoli,Antonios Tzortzakakis,Andreas Abrahamsson,Björn Engelbrekt Wahlin,Örjan Smedby,Maria Holstensson,Rodrigo Moreno*

Main category: eess.IV

TL;DR: 本研究探讨了在基于深度学习的病灶检测模型中添加解剖先验信息的效果，发现解剖先验显著提升了nnDetection框架的性能，但对视觉变换器影响甚微。


<details>
  <summary>Details</summary>
Motivation: 早期癌症检测对改善患者预后至关重要，但准确检测不同大小的多个病灶仍具挑战性。研究旨在探索解剖先验信息对深度学习病灶检测模型的影响。

Method: 使用TotalSegmentator工具生成的器官分割掩码作为辅助输入，为nnDetection和Swin Transformer提供解剖上下文。Swin Transformer采用自监督预训练和监督微调的两阶段训练。在AutoPET和Karolinska淋巴瘤数据集上进行测试。

Result: 解剖先验的加入显著提升了nnDetection框架的检测性能，但对视觉变换器性能几乎没有影响。Swin Transformer相比nnDetection中使用的传统CNN编码器没有明显优势。

Conclusion: 解剖上下文在癌症病灶检测中起着关键作用，特别是在基于CNN的模型中。

Abstract: Early cancer detection is crucial for improving patient outcomes, and 18F FDG PET/CT imaging plays a vital role by combining metabolic and anatomical information. Accurate lesion detection remains challenging due to the need to identify multiple lesions of varying sizes. In this study, we investigate the effect of adding anatomy prior information to deep learning-based lesion detection models. In particular, we add organ segmentation masks from the TotalSegmentator tool as auxiliary inputs to provide anatomical context to nnDetection, which is the state-of-the-art for lesion detection, and Swin Transformer. The latter is trained in two stages that combine self-supervised pre-training and supervised fine-tuning. The method is tested in the AutoPET and Karolinska lymphoma datasets. The results indicate that the inclusion of anatomical priors substantially improves the detection performance within the nnDetection framework, while it has almost no impact on the performance of the vision transformer. Moreover, we observe that Swin Transformer does not offer clear advantages over conventional convolutional neural network (CNN) encoders used in nnDetection. These findings highlight the critical role of the anatomical context in cancer lesion detection, especially in CNN-based models.

</details>


### [9] [TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation](https://arxiv.org/abs/2511.07057)
*Zidong Chen,Fadratul Hafinaz Hassan*

Main category: eess.IV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deploying lightweight medical image segmentation models on edge devices presents two major challenges: 1) efficiently handling the stark contrast between lesion boundaries and background regions, and 2) the sharp drop in accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M parameters). To address these problems, this paper proposes TauFlow, a novel lightweight segmentation model. The core of TauFlow is a dynamic feature response strategy inspired by brain-like mechanisms. This is achieved through two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which dynamically regulates the feature update rate to "slowly" process low-frequency backgrounds and "quickly" respond to high-frequency boundaries; and the STDP Self-Organizing Module, which significantly mitigates feature conflicts between the encoder and decoder, reducing the conflict rate from approximately 35%-40% to 8%-10%.

</details>


### [10] [Validation of Fully-Automated Deep Learning-Based Fibroglandular Tissue Segmentation for Efficient and Reliable Quantitation of Background Parenchymal Enhancement in Breast MRI](https://arxiv.org/abs/2511.07088)
*Yu-Tzu Kuo,Anum S. Kazerouni,Vivian Y. Park,Wesley Surento,Suleeporn Sujichantararat,Daniel S. Hippe,Habib Rahbar,Savannah C. Partridge*

Main category: eess.IV

TL;DR: 比较了基于深度学习的全自动方法和半自动模糊C均值方法在乳腺MRI中量化背景实质增强(BPE)的效果，发现DL方法在分割质量和与定性BPE评估的相关性方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 背景实质增强(BPE)作为乳腺癌风险标志物具有潜力，但临床上通常由放射科医生定性评估。开发定量BPE测量方法可以提供更精确的风险评估。

Method: 使用100名女性的乳腺MRI检查，评估基于深度学习的全自动纤维腺体组织(FGT)分割方法与半自动模糊C均值方法在BPE量化方面的表现，包括分割一致性、定量BPE指标一致性以及与定性BPE的关联性。

Result: 两种方法在定量BPE测量方面表现出良好一致性，但基于深度学习的方法与定性BPE评估的相关性更强，且放射科医生对其分割质量评分更高。

Conclusion: 基于深度学习的FGT分割提高了客观BPE量化的效率，可能改善标准化乳腺癌风险评估。

Abstract: Background parenchymal enhancement (BPE) on breast dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) shows potential as a breast cancer risk marker. Clinically, BPE is qualitatively assessed by radiologists, but quantitative BPE measures offer potential for more precise risk evaluation. This study evaluated an existing open-source, fully-automated deep learning-based (DL-based) method for segmenting fibroglandular tissue (FGT) to quantify BPE and compared it to a semi-automated fuzzy c-means method. Using breast MRI examinations from 100 women, we evaluated segmentation agreement, concordance across quantitative BPE metrics, and associations with qualitative BPE. The quality of FGT segmentations from both methods was scored by a radiologist. While the DL-based and semi-automated methods showed good agreement for quantitative BPE measurements, DL-based measures more strongly correlated with qualitative BPE assessments and DL-based segmentations were scored as higher quality by the radiologist. Our findings suggest that DL-based FGT segmentation enhances efficiency for objective BPE quantification and may improve standardized breast cancer risk assessment.

</details>


### [11] [Task-Adaptive Low-Dose CT Reconstruction](https://arxiv.org/abs/2511.07094)
*Necati Sefercioglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: eess.IV

TL;DR: 提出了一种任务自适应的CT重建框架，通过将预训练的任务网络作为正则化项融入重建损失函数，在保持诊断质量的同时提升解剖细节保留能力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习低剂量CT重建方法虽然在标准图像质量指标上表现优异，但经常无法保留诊断任务所需的关键解剖细节，这限制了其临床应用。

Method: 使用冻结的预训练任务网络作为重建损失函数的正则化项，指导重建训练过程，避免联合训练方法可能导致的重建质量下降问题。

Result: 在肝脏和肝肿瘤分割任务中，任务自适应模型的Dice分数达到0.707，接近全剂量扫描的性能(0.874)，显著优于联合训练方法(0.331)和传统重建方法(0.626)。

Conclusion: 该框架可以通过简单的损失函数修改集成到任何现有的深度学习重建模型中，为临床实践中的任务自适应优化提供了广泛应用前景。

Abstract: Deep learning-based low-dose computed tomography reconstruction methods already achieve high performance on standard image quality metrics like peak signal-to-noise ratio and structural similarity index measure. Yet, they frequently fail to preserve the critical anatomical details needed for diagnostic tasks. This fundamental limitation hinders their clinical applicability despite their high metric scores. We propose a novel task-adaptive reconstruction framework that addresses this gap by incorporating a frozen pre-trained task network as a regularization term in the reconstruction loss function. Unlike existing joint-training approaches that simultaneously optimize both reconstruction and task networks, and risk diverging from satisfactory reconstructions, our method leverages a pre-trained task model to guide reconstruction training while still maintaining diagnostic quality. We validate our framework on a liver and liver tumor segmentation task. Our task-adaptive models achieve Dice scores up to 0.707, approaching the performance of full-dose scans (0.874), and substantially outperforming joint-training approaches (0.331) and traditional reconstruction methods (0.626). Critically, our framework can be integrated into any existing deep learning-based reconstruction model through simple loss function modification, enabling widespread adoption for task-adaptive optimization in clinical practice. Our codes are available at: https://github.com/itu-biai/task_adaptive_ct

</details>


### [12] [CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video](https://arxiv.org/abs/2511.07290)
*Xinyi Wang,Angeliki Katsenou,Junxiao Shen,David Bull*

Main category: eess.IV

TL;DR: CAMP-VQA是一个无需参考的感知视频质量评估框架，利用大型视觉语言模型生成细粒度质量描述，在UGC视频质量评估中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 用户生成内容(UGC)在YouTube、TikTok等平台上的普及使得无需参考的感知视频质量评估变得至关重要。然而，UGC视频的非专业采集和转码特性给NR-VQA带来了挑战，现有模型由于缺乏细粒度伪影类型标注，对压缩内容的主观评分建模有限。

Method: 提出CAMP-VQA框架，利用大型视觉语言模型的语义理解能力，通过质量感知提示机制整合视频元数据（分辨率、帧率、比特率）和帧间变化提取的关键片段，指导BLIP-2预训练方法生成细粒度质量描述。设计统一架构从语义对齐、时间特性和空间特性三个维度建模感知质量。

Result: 在多个UGC数据集上的广泛实验表明，该模型始终优于现有NR-VQA方法，无需昂贵的细粒度人工标注即可提高准确性。在平均排名和线性相关性方面达到最佳性能（SRCC: 0.928, PLCC: 0.938）。

Conclusion: CAMP-VQA通过利用视觉语言模型的语义理解能力，有效解决了UGC视频质量评估中的挑战，为无需细粒度标注的高质量视频质量评估提供了新方法。

Abstract: The prevalence of user-generated content (UGC) on platforms such as YouTube and TikTok has rendered no-reference (NR) perceptual video quality assessment (VQA) vital for optimizing video delivery. Nonetheless, the characteristics of non-professional acquisition and the subsequent transcoding of UGC video on sharing platforms present significant challenges for NR-VQA. Although NR-VQA models attempt to infer mean opinion scores (MOS), their modeling of subjective scores for compressed content remains limited due to the absence of fine-grained perceptual annotations of artifact types. To address these challenges, we propose CAMP-VQA, a novel NR-VQA framework that exploits the semantic understanding capabilities of large vision-language models. Our approach introduces a quality-aware prompting mechanism that integrates video metadata (e.g., resolution, frame rate, bitrate) with key fragments extracted from inter-frame variations to guide the BLIP-2 pretraining approach in generating fine-grained quality captions. A unified architecture has been designed to model perceptual quality across three dimensions: semantic alignment, temporal characteristics, and spatial characteristics. These multimodal features are extracted and fused, then regressed to video quality scores. Extensive experiments on a wide variety of UGC datasets demonstrate that our model consistently outperforms existing NR-VQA methods, achieving improved accuracy without the need for costly manual fine-grained annotations. Our method achieves the best performance in terms of average rank and linear correlation (SRCC: 0.928, PLCC: 0.938) compared to state-of-the-art methods. The source code and trained models, along with a user-friendly demo, are available at: https://github.com/xinyiW915/CAMP-VQA.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [13] [Necessary and Sufficient Conditions for Capacity-Achieving Private Information Retrieval with Adversarial Servers](https://arxiv.org/abs/2511.06003)
*Atsushi Miki,Toshiyasu Matsushima*

Main category: cs.IT

TL;DR: 本文证明了实现容量上限的私有信息检索方案的必要和充分条件，为系统构建最优PIR方案提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然证明了PIR方案的信息理论上界，但缺乏系统构建达到该上界的方法。为了系统构建容量最优的PIR方案，需要明确查询应满足的条件。

Method: 通过理论分析，推导出容量最优PIR方案中查询必须满足的必要和充分条件。

Result: 成功证明了容量最优PIR方案的必要和充分条件，为系统构建此类方案提供了明确指导。

Conclusion: 本文建立的必要和充分条件为系统构建达到信息理论容量上限的PIR方案奠定了理论基础，解决了该领域的关键问题。

Abstract: Private information retrieval (PIR) is a mechanism for efficiently downloading messages while keeping the index of the desired message secret from the servers. PIR schemes have been extended to various scenarios with adversarial servers: PIR schemes where some servers are unresponsive or return noisy responses are called robust PIR and Byzantine PIR, respectively; PIR schemes where some servers collude to reveal the index are called colluding PIR. The information-theoretic upper bound on the download efficiency of these PIR schemes has been proved in previous studies. However, systematic ways to construct PIR schemes that achieve the upper bound are not known. In order to construct a capacity-achieving PIR schemes systematically, it is necessary to clarify the conditions that the queries should satisfy. This paper proves the necessary and sufficient conditions for capacity-achieving PIR schemes.

</details>


### [14] [Differential Space-Time Block Coding for Phase-Unsynchronized Cell-Free MIMO Downlink](https://arxiv.org/abs/2511.06510)
*Marx M. M. Freitas,Giovanni Interdonato,Stefano Buzzi*

Main category: cs.IT

TL;DR: 提出了一种用于无小区大规模MIMO系统的差分空时分组编码方法，无需AP相位同步即可实现性能接近完全同步系统。


<details>
  <summary>Details</summary>
Motivation: 无小区大规模MIMO系统的下行链路性能严重依赖AP间的相位同步，但地理分布的AP实现精确相位同步具有技术挑战性。

Method: 采用差分空时分组编码方法，无需信道状态信息和AP间任何形式的相位同步。

Result: 数值仿真表明，相位失配会显著损害系统性能，而提出的DSTBC方案能有效缓解这些影响。

Conclusion: 所提出的DSTBC方案成功减轻了相位失配的影响，实现了与完全同步系统相当的性能。

Abstract: In the downlink of a cell-free massive multiple-input multiple-output (CF-mMIMO) system, spectral efficiency gains critically rely on joint coherent transmission, as all access points (APs) must align their transmitted signals in phase at the user equipment (UE). Achieving such phase alignment is technically challenging, as it requires tight synchronization among geographically distributed APs. In this paper, we address this issue by introducing a differential space-time block coding (DSTBC) approach that bypasses the need for AP phase synchronization. We first provide analytic bounds to the achievable spectral efficiency of CF-mMIMO with phase-unsynchronized APs. Then, we propose a DSTBC-based transmission scheme specifically tailored to CF-mMIMO, which operates without channel state information and does not require any form of phase synchronization among the APs. We derive a closed-form expression for the resulting signal-to-interference-plus-noise ratio (SINR), enabling quantitative comparisons among different DSTBC schemes. Numerical simulations confirm that phase misalignments can significantly impair system performance. In contrast, the proposed DSTBC scheme successfully mitigates these effects, achieving performance comparable to that of fully synchronized systems.

</details>


### [15] [Events Meet Phase-Shifting Digital Holography: Practical Acquisition, Theory, and Algorithms](https://arxiv.org/abs/2511.06591)
*Ittetsu Uchiyama,Chihiro Tsutake,Keita Takahashi,Toshiaki Fujii*

Main category: cs.IT

TL;DR: 提出了一种基于混合事件视觉传感器的相位移动数字全息术新方法，通过在单次曝光期间进行相位移动，结合模糊全息图和事件数据重建完整复波前。


<details>
  <summary>Details</summary>
Motivation: 传统相位移动数字全息术需要多次曝光，效率较低。本文旨在提高全息图采集效率，同时保持重建质量。

Method: 使用混合事件视觉传感器，在单次曝光期间进行相位移动，记录模糊全息图和对应模糊变化的事件数据，通过分析和优化方法重建完整复波前。

Result: 实验结果表明，该方法在保持与传统相位移动数字全息术相当的重建质量的同时，显著提高了采集效率。

Conclusion: 提出的混合事件视觉传感器相位移动数字全息术方法能够高效地重建高质量全息图像，为数字全息术提供了新的解决方案。

Abstract: We introduce a novel phase-shifting digital holography (PSDH) method leveraging a hybrid event-based vision sensor (EVS). The key idea of our method is the phase shift during a single exposure. The hybrid EVS records a hologram blurred by the phase shift, together with the events corresponding to blur variations. We present analytical and optimization-based methods that theoretically support the reconstruction of full-complex wavefronts from the blurred hologram and events. The experimental results demonstrate that our method achieves a reconstruction quality comparable to that of a conventional PSDH method while enhancing the acquisition efficiency.

</details>


### [16] [The Inaccessible Game](https://arxiv.org/abs/2511.06795)
*Neil D. Lawrence*

Main category: cs.IT

TL;DR: 本文提出了不可访问游戏，这是一个基于四个公理构建的信息论动力系统。前三个公理定义了信息损失，第四个新颖的信息隔离公理假设系统与观测隔离，使其具有观测无关性和可交换性。在隔离公理下，总边际熵守恒，系统展现出结合可逆和不可逆分量的GENERIC类结构。


<details>
  <summary>Details</summary>
Motivation: 构建一个信息论动力系统，通过引入信息隔离公理来确保系统的观测无关性和可交换性，从而研究在总边际熵守恒条件下的最大熵产生过程。

Method: 基于四个公理构建不可访问游戏：前三个公理定义信息损失，第四个信息隔离公理确保系统与观测隔离。在总边际熵守恒条件下分析最大熵产生，并展示系统的GENERIC类结构。

Result: 在信息隔离公理下，系统总边际熵守恒（∑h_i = C），动力系统展现出结合可逆和不可逆分量的GENERIC类结构。

Conclusion: 不可访问游戏提供了一个信息论框架，在信息隔离条件下保持总边际熵守恒，并展现出具有可逆和不可逆分量的GENERIC类动力结构。

Abstract: In this paper we introduce the inaccessible game, an information-theoretic dynamical system constructed from four axioms. The first three axioms are known and define \emph{information loss} in the system. The fourth is a novel \emph{information isolation} axiom that assumes our system is isolated from observation, making it observer-independent and exchangeable. Under this isolation axiom, total marginal entropy is conserved: $\sum_i h_i = C$. We consider maximum entropy production in the game and show that the dynamics exhibit a GENERIC-like structure combining reversible and irreversible components.

</details>


### [17] [Code Equivalence, Point Set Equivalence, and Polynomial Isomorphism](https://arxiv.org/abs/2511.06843)
*Martin Kreuzer*

Main category: cs.IT

TL;DR: 本文证明线性码等价问题等价于射影空间中点集等价问题，并进一步转化为Artinian Gorenstein代数的同构问题和多项式同构问题。


<details>
  <summary>Details</summary>
Motivation: 研究线性码等价问题的计算复杂性，寻找更高效的解决方案。

Method: 将线性码等价问题转化为点集等价问题，然后通过齐次坐标环和规范理想构造Artinian Gorenstein代数，利用其Macaulay逆系统进一步简化为多项式同构问题。

Result: 证明了线性码等价问题与点集等价问题的等价性，并在温和假设下将问题简化为多项式时间可解的多项式同构问题。对于不可分解的等对偶码，进一步简化为三次多项式同构搜索问题。

Conclusion: 线性码等价问题可以有效地简化为多项式同构问题，这为计算编码理论中的等价性问题提供了新的理论框架和算法途径。

Abstract: The linear code equivalence (LCE) problem is shown to be equivalent to the point set equivalence (PSE) problem, i.e., the problem to check whether two sets of points in a projective space over a finite field differ by a linear change of coordinates. For such a point set $\mathbb{X}$, let $R$ be its homogeneous coordinate ring and $\mathfrak{J}_{\mathbb{X}}$ its canonical ideal. Then the LCE problem is shown to be equivalent to an algebra isomorphism problem for the doubling $R/\mathfrak{J}_{\mathbb{X}}$. As this doubling is an Artinian Gorenstein algebra, we can use its Macaulay inverse system to reduce the LCE problem to a Polynomial Isomorphism (PI) problem for homogeneous polynomials. The last step is polynomial time under some mild assumptions about the codes. Moreover, for indecomposable iso-dual codes we can reduce the LCE search problem to the PI search problem of degree 3 by noting that the corresponding point sets are self-associated and arithmetically Gorenstein, so that we can use the isomorphism problem for the Artinian reductions of the coordinate rings and form their Macaulay inverse systems.

</details>


### [18] [Rate-Optimal Streaming Codes Under an Extended Delay Profile for Three-Node Relay Networks With Burst Erasures](https://arxiv.org/abs/2511.06882)
*Zhipeng Li,Wenjie Ma*

Main category: cs.IT

TL;DR: 本文研究三节点中继网络中具有延迟约束T的流码设计，针对突发包擦除信道，提出了扩展延迟分布方法，在更宽松的条件下实现了最优速率。


<details>
  <summary>Details</summary>
Motivation: 现有Singhvi等人的构造在u整除(T-u-v)时达到最优速率，但这一约束过于严格。本文旨在放宽这一约束条件，使流码能在更一般的参数设置下达到最优性能。

Method: 采用扩展延迟分布方法，通过重新设计编码结构来适应更宽松的约束条件，突破了原有构造的限制。

Result: 新方法在约束条件(T-u-v)/(2u-v) ≤ ⌊(T-u-v)/u⌋下实现了最优速率，该条件严格包含了原有的u整除(T-u-v)约束。

Conclusion: 扩展延迟分布方法成功放宽了达到最优速率的约束条件，为三节点中继网络中的流码设计提供了更通用的解决方案。

Abstract: This paper investigates streaming codes for three-node relay networks under burst packet erasures with a delay constraint $T$. In any sliding window of $T+1$ consecutive packets, the source-to-relay and relay-to-destination channels may introduce burst erasures of lengths at most $b_1$ and $b_2$, respectively. Let $u = \max\{b_1, b_2\}$ and $v = \min\{b_1, b_2\}$. Singhvi et al. proposed a construction achieving the optimal rate when $u\mid (T-u-v)$. In this paper, we present an extended delay profile method that attains the optimal rate under a relaxed constraint $\frac{T - u - v}{2u - v} \leq \left\lfloor \frac{T - u - v}{u} \right\rfloor$ and it strictly cover restriction $u\mid (T-u-v)$. %Furthermore, we demonstrate that the optimal rate for streaming codes is not achievable when $0< T-u-v<v$ under the convolutional code framework.

</details>


### [19] [Experimental Validation of Reflective Near-Field Beamfocusing using a b-bit RIS](https://arxiv.org/abs/2511.06994)
*Emil Björnson,Murat Babek Salman*

Main category: cs.IT

TL;DR: 本文首次通过实验验证了使用可重构智能表面(RIS)的反射式近场波束聚焦技术，在28GHz频段使用1024单元1比特RIS进行了室内测量，证明了近场波束聚焦的实用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虽然波束聚焦已被理论证明是大孔径RIS的关键特性，但其实际实现尚未得到探索。本文旨在通过实验验证近场波束聚焦的可行性。

Method: 推导了b比特RIS在近场视距场景下阵列增益的新解析表达式，并通过28GHz频段室内办公环境中的一系列测量进行验证，使用1024单元1比特RIS。

Result: 实验证实近场波束聚焦可以动态实现，并且能够被所提出的解析模型准确预测，尽管存在硬件缺陷和多径传播。

Conclusion: 研究结果表明近场波束聚焦是RIS辅助无线通信中一个鲁棒且实际可行的特性。

Abstract: This paper presents the first experimental validation of reflective near-field beamfocusing using a reconfigurable intelligent surface (RIS). While beamfocusing has been theoretically established as a key feature of large-aperture RISs, its practical realization has remained unexplored. We derive new analytical expressions for the array gain achieved with a $b$-bit RIS in near-field line-of-sight scenarios, characterizing both the finite depth and angular width of the focal region. The theoretical results are validated through a series of measurements in an indoor office environment at 28 GHz using a one-bit 1024-element RIS. The experiments confirm that near-field beamfocusing can be dynamically achieved and accurately predicted by the proposed analytical model, despite the presence of hardware imperfections and multipath propagation. These findings demonstrate that near-field beamfocusing is a robust and practically viable feature of RIS-assisted wireless communications.

</details>


### [20] [A Copula-based Semantics-Structure Minimization Framework for QoS Guaranteed Wireless Communications](https://arxiv.org/abs/2511.07145)
*Xinke Jian,Zhiyuan Ren,Wenchi Cheng*

Main category: cs.IT

TL;DR: 本文为语义通信建立了完整的理论公理基础，提出了四个公理并证明成对秩Copula族是表示最小结构语义的最小充分表示，构建了基于Jensen-Shannon散度的语义失真度量，并建立了样本复杂度边界、率失真边界、端到端服务等级协议定理和语义源信道分离定理。


<details>
  <summary>Details</summary>
Motivation: 当前基于经验的语义通信研究缺乏统一的理论基础，无法提供可量化的服务质量保证，特别是在紧急场景下传输最小结构语义时，这限制了其发展成为可预测的工程科学。

Method: 建立完整的理论公理基础，提出四个公理并证明成对秩Copula族是表示最小结构语义的最小充分表示，构建基于Jensen-Shannon散度的语义失真度量，并建立样本复杂度边界、率失真边界、端到端服务等级协议定理和语义源信道分离定理。

Result: 通过解耦实验验证了所提出的框架，实证表明核心度量严格遵循基础公理，而标准感知度量则无法做到这一点。

Conclusion: 本文为语义通信提供了完整的理论框架，建立了可证明的服务质量保证，推动了语义通信从经验研究向可预测工程科学的转变。

Abstract: Current empirically driven research on semantic communication lacks a unified theoretical foundation, preventing quantifiable Quality of Service guarantees, particularly for transmitting minimal structural semantics in emergency scenarios. This deficiency limits its evolution into a predictable engineering science. To address this, we establish a complete theoretical axiomatic basis for this problem. We propose four axioms and rigorously prove that the family of pairwise rank-Copulas is the minimal sufficient representation for minimal structural semantics. Based on this, we construct a semantic distortion metric, centered on the Jensen-Shannon divergence. We then establish the core theoretical boundaries of the framework: sample complexity bounds; rate-distortion bounds; an end-to-end Service Level Agreements theorem; and a semantic source-channel separation theorem, which provides a provable Quality of Service guarantee. Finally, we validate our framework through decoupled experiments, empirically demonstrating that our core metric strictly adheres to our foundational axioms while standard perceptual metrics fail to do so.

</details>


### [21] [Frequency Diverse (FD)-RIS-Enhanced Covert Communications: Defense Against Wiretapping via Joint Distance-Angle Beamforming](https://arxiv.org/abs/2511.07309)
*Han Xiao,Xiaoyan Hu,Wenjie Wang,Kai-Kit Wong,Kun Yang,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文针对传统RIS辅助隐蔽通信系统的安全盲区问题，提出了一种基于频控RIS的隐蔽通信传输方案，通过联合距离-角度波束赋形能力显著提升隐蔽性能。


<details>
  <summary>Details</summary>
Motivation: 传统RIS辅助隐蔽通信系统存在安全盲区限制，而频控RIS的联合距离-角度波束赋形能力有望解决这些问题。

Method: 开发了FD-RIS信号处理模型，利用时延技术控制谐波信号；构建多看守场景下的隐蔽通信系统；提出迭代算法联合优化时延和调制频率。

Result: 仿真结果表明FD-RIS能显著提升隐蔽性能，特别是在角度重叠场景下，传统RIS性能严重下降时FD-RIS仍能保持良好性能。

Conclusion: FD-RIS在具有挑战性的空间环境下能有效增强隐蔽通信的鲁棒性，为解决传统RIS的安全盲区问题提供了有效方案。

Abstract: In response to the security blind zone challenges faced by traditional reconfigurable intelligent surface (RIS)-aided covert communication (CC) systems, the joint distance-angle beamforming capability of frequency diverse RIS (FD-RIS) shows significant potential for addressing these limitations. Therefore, this paper initially incorporates the FD-RIS into the CC systems and proposes the corresponding CC transmission scheme. Specifically, we first develop the signal processing model of the FD-RIS, which considers effective control of harmonic signals by leveraging the time-delay techniques. The joint distance-angle beamforming capability is then validated through its normalized beampattern. Based on this model, we then construct an FD-RIS-assisted CC system under a multi-warden scenario and derive an approximate closed-form expression for the covert constraints by considering the worst-case eavesdropping conditions and utilizing the logarithmic moment-generating function. An optimization problem is formulated which aims at maximizing the covert user's achievable rate under covert constrains by jointly designing the time delays and modulation frequencies. To tackle this non-convex problem, an iterative algorithm with assured convergence is proposed to effectively solve the time-delay and modulation frequency variables. To evaluate the performance of the proposed scheme, we consider three communication scenarios with varying spatial correlations between the covert user and wardens. Simulation results demonstrate that FD-RIS can significantly improve covert performance, particularly in angular-overlap scenarios where traditional RIS experiences severe degradation. These findings further highlight the effectiveness of FD-RIS in enhancing CC robustness under challenging spatial environments.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [22] [AIRMap - AI-Generated Radio Maps for Wireless Digital Twins](https://arxiv.org/abs/2511.05522)
*Ali Saeizadeh,Miead Tehrani-Moayyed,Davide Villa,J. Gordon Beattie,Pedram Johari,Stefano Basagni,Tommaso Melodia*

Main category: eess.SP

TL;DR: AIRMap是一个基于深度学习的超快速无线电地图估计框架，仅使用2D地形和建筑高度数据，在4毫秒内完成路径增益预测，比GPU加速的射线追踪快7000倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统射线追踪方法计算量大，无法满足动态条件下的实时无线网络仿真和数字孪生应用需求。

Method: 使用单输入U-Net自编码器处理2D地形高程图，在60,000个波士顿地区样本上训练和评估，通过轻量级迁移学习校准减少误差。

Result: 预测路径增益的RMSE低于5 dB，仅用20%现场测量数据进行校准后，中值误差降至约10%，显著优于传统模拟器（误差超过50%）。

Conclusion: AIRMap验证了在无线数字孪生中实现可扩展、准确和实时无线电地图估计的潜力。

Abstract: Accurate, low-latency channel modeling is essential for real-time wireless network simulation and digital-twin applications. Traditional modeling methods like ray tracing are however computationally demanding and unsuited to model dynamic conditions. In this paper, we propose AIRMap, a deep-learning framework for ultra-fast radio-map estimation, along with an automated pipeline for creating the largest radio-map dataset to date. AIRMap uses a single-input U-Net autoencoder that processes only a 2D elevation map of terrain and building heights. Trained and evaluated on 60,000 Boston-area samples, spanning coverage areas from 500 m to 3 km per side, AIRMap predicts path gain with under 5 dB RMSE in 4 ms per inference on an NVIDIA L40S -over 7000x faster than GPU-accelerated ray tracing based radio maps. A lightweight transfer learning calibration using just 20% of field measurements reduces the median error to approximately 10%, significantly outperforming traditional simulators, which exceed 50% error. Integration into the Colosseum emulator and the Sionna SYS platform demonstrate near-zero error in spectral efficiency and block-error rate compared to measurement-based channels. These findings validate AIRMap's potential for scalable, accurate, and real-time radio map estimation in wireless digital twins.

</details>


### [23] [Bridging Accuracy and Explainability in EEG-based Graph Attention Network for Depression Detection](https://arxiv.org/abs/2511.05537)
*Soujanya Hazra,Sanjay Ghosh*

Main category: eess.SP

TL;DR: 提出了一种名为ExPANet的新型图深度学习框架，用于基于EEG区分重度抑郁症患者和健康对照组，该框架在性能上优于现有方法，并具有可解释性优势。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是全球精神疾病的主要原因，及时准确诊断对有效干预至关重要。EEG提供了一种非侵入性且易于获取的方法来检查大脑活动并识别疾病相关模式。

Method: 使用预处理后的EEG数据，提取14个时域、频域、分形和复杂度特征，将电极表示为节点，通过相位锁定值确定边来表示功能连接性，采用改进的图注意力网络分析生成的大脑图。

Result: 该框架在两个不同数据集上相对于当前基于EEG的方法取得了优越性能，并能够评估特征、通道和边的重要性，识别与MDD特别相关的特征、脑区和连接关联。

Conclusion: 研究展示了一种可靠且透明的基于EEG的MDD筛查方法，利用深度学习获得了与临床数据相符的结果。

Abstract: Depression is a major cause of global mental illness and significantly influences suicide rates. Timely and accurate diagnosis is essential for effective intervention. Electroencephalography (EEG) provides a non-invasive and accessible method for examining cerebral activity and identifying disease-associated patterns. We propose a novel graph-based deep learning framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet), for differentiating major depressive disorder (MDD) patients from healthy controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and are segmented into short periods of activity. We extract 14 features from each segment, which include time, frequency, fractal, and complexity domains. Electrodes are represented as nodes, whereas edges are determined by the phase-locking value (PLV) to represent functional connectivity. The generated brain graphs are examined utilizing an adapted graph attention network. This architecture acquires both localized electrode characteristics and comprehensive functional connectivity patterns. The proposed framework attains superior performance relative to current EEG-based approaches across two different datasets. A fundamental advantage of our methodology is its explainability. We evaluated the significance of features, channels, and edges, in addition to intrinsic attention weights. These studies highlight features, cerebral areas, and connectivity associations that are especially relevant to MDD, many of which correspond with clinical data. Our findings demonstrate a reliable and transparent method for EEG-based screening of MDD, using deep learning with clinically relevant results.

</details>


### [24] [Fast Time-Varying mmWave MIMO Channel Estimation and Reconstruction: An Efficient Rank-Aware Matrix Completion Method](https://arxiv.org/abs/2511.05902)
*Tianyu Jiang,Yan Yang,Hongjin Liu,Runyu Han,Bo Ai,Mohsen Guizani*

Main category: eess.SP

TL;DR: 提出一种两阶段秩感知压缩感知框架，用于毫米波MIMO系统中快速时变信道估计，结合低秩矩阵补全和稀疏信道恢复，在动态条件下提高估计精度并降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决毫米波MIMO系统中快速时变信道估计问题，特别是在不完美信道状态信息和用户移动导致的信道秩突变情况下，需要高效的信道重建方法。

Method: 第一阶段使用鲁棒秩一矩阵补全算法进行低秩矩阵补全，建立离散时间自回归模型利用时间秩相关性实现自适应观测矩阵补全；第二阶段开发秩感知块正交匹配追踪算法进行稀疏信道恢复，并引入秩感知测量矩阵设计。

Result: 仿真结果表明，与现有基准算法相比，所提方法在显著降低计算复杂度和训练开销的同时，实现了更优的信道估计性能。

Conclusion: 该两阶段秩感知压缩感知框架能够有效处理毫米波MIMO系统中的快速时变信道估计问题，在动态条件下提供准确的信道重建，同时保持较低的计算复杂度。

Abstract: We address the problem of fast time-varying channel estimation in millimeter-wave (mmWave) MIMO systems with imperfect channel state information (CSI) and facilitate efficient channel reconstruction. Specifically, leveraging the low-rank and sparse characteristics of the mmWave channel matrix, a two-phase rank-aware compressed sensing framework is proposed for efficient channel estimation and reconstruction. In the first phase, a robust rank-one matrix completion (R1MC) algorithm is used to reconstruct part of the observed channel matrix through low-rank matrix completion (LRMC). To address abrupt rank changes caused by user mobility, a discrete-time autoregressive (AR) model is established that leverages temporal rank correlations across consecutive time instances to enable adaptive observation matrix completion, thereby improving estimation accuracy under dynamic conditions. In the second phase, a rank-aware block orthogonal matching pursuit (RA-BOMP) algorithm is developed for sparse channel recovery with low computational complexity. Furthermore, a rank-aware measurement matrix design is introduced to improve angle estimation accuracy. Simulation results demonstrate that, compared with existing benchmark algorithms, the proposed approach achieves superior channel estimation performance while significantly reducing computational complexity and training overhead.

</details>


### [25] [RadioSim Agent: Combining Large Language Models and Deterministic EM Simulators for Interactive Radio Map Analysis](https://arxiv.org/abs/2511.05912)
*Sajjad Hussain,Conor Brennan*

Main category: eess.SP

TL;DR: RadioSim Agent是一个集成大语言模型与电磁模拟器的智能框架，支持交互式无线电地图生成和解释性分析。


<details>
  <summary>Details</summary>
Motivation: 传统电磁模拟器需要专家配置且缺乏交互灵活性，难以满足现代无线系统设计的智能交互需求。

Method: 将射线追踪模型封装为可调用工具，通过LLM解释自然语言目标、管理模拟工作流，并进行视觉分析。

Result: 在城市无人机通信场景中，该代理能自主选择传播机制、执行确定性模拟，并提供路径损耗行为的语义和视觉总结。

Conclusion: RadioSim Agent提供了多模态可解释性和直观用户交互，为下一代无线系统设计中的智能电磁模拟助手铺平了道路。

Abstract: Deterministic electromagnetic (EM) simulators provide accurate radio propagation modeling but often require expert configuration and lack interactive flexibility. We present RadioSim Agent, an agentic framework that integrates large language models (LLMs) with physics-based EM solvers and vision-enabled reasoning to enable interactive and explainable radio map generation. The framework encapsulates ray-tracing models as callable simulation tools, orchestrated by an LLM capable of interpreting natural language objectives, managing simulation workflows, and visually analyzing resulting radio maps. Demonstrations in urban UAV communication scenarios show that the agent autonomously selects appropriate propagation mechanisms, executes deterministic simulations, and provides semantic and visual summaries of pathloss behavior. The results indicate that RadioSim Agent provides multimodal interpretability and intuitive user interaction, paving the way for intelligent EM simulation assistants in next-generation wireless system design.

</details>


### [26] [Near-field Anchor-free Localization using Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2511.05954)
*Srikar Sharma Sadhu,Praful D. Mankar,Santosh Nannuru*

Main category: eess.SP

TL;DR: 提出了一种基于无锚RIS辅助定位的两阶段框架，通过最大化接收信噪比和牛顿细化实现用户设备的精确定位，无需复杂基础设施。


<details>
  <summary>Details</summary>
Motivation: 传统定位方法依赖复杂基础设施和协作锚节点，导致网络负载和能耗增加。利用被动可重构智能表面作为同步参考节点，开发无锚定位解决方案。

Method: 两阶段定位框架：第一阶段通过相关接收的RIS反射信号与基于参考位置视距分量构建的字典获得粗估计；第二阶段使用牛顿细化方法优化粗估计。

Result: 数值结果表明，使用较少参考位置构建的小型字典可实现准确定位，仅需略微增加细化迭代次数。

Conclusion: 所提框架在无需增加RIS控制开销的情况下实现可扩展的无锚定位，为6G网络应用提供了高效解决方案。

Abstract: Near-field localization is expected to play a crucial role in enabling a plethora of applications under the paradigm of 6G networks. The conventional localization methods rely on complex infrastructure for providing cooperative anchor nodes that often contribute to higher network overload and energy consumption. To address this, the passive reconfigurable intelligent surfaces (RISs) can be leveraged as perfectly synced reference nodes for developing anchor-free localization. This work proposes a two-stage framework for localizing user equipment (UE) equipped with multiple antennas. At first, we show that the optimal RIS phase shift matrix maximizing the received signal-to-noise ratio (SNR) for RIS-assisted anchor-free localization is independent of UE location, making the proposed framework scalable without increasing the overhead to control RIS. The proposed two-stage framework first obtains a coarse estimate of UE's location by correlating the received RIS-reflected signal with a dictionary constructed using line-of-sight (LoS) components at a few reference positions. Next, the coarse estimate is refined using Newton's refinement. The numerical results show that the small-sized dictionary, constructed using fewer reference positions, can be employed for accurate localization with a slight increase in the required number of refinement iterations.

</details>


### [27] [Invariants in Eddy Current Testing via Dimensional Analysis](https://arxiv.org/abs/2511.06035)
*Vincenzo Mottola,Alessandro Sardellitti,Filippo Milano,Luigi Ferrigno,Marco Laracca,Antonello Tamburrino*

Main category: eess.SP

TL;DR: 本文提出了一种基于量纲分析的频域涡流检测数据不变变换系统方法，用于在存在不确定参数的情况下准确估计目标参数。


<details>
  <summary>Details</summary>
Motivation: 在无损检测中，经常需要从测量数据中估计部分参数，而忽略其他不确定参数的影响。例如在涡流检测中，可能需要估计板材厚度和电导率，而忽略探头提离距离的变化。

Method: 通过量纲分析和Buckingham π定理推导不变变换，使测量信号独立于一个或多个不确定参数。该方法兼容实时和在线操作。

Result: 实验验证表明，该方法在广泛的参数范围内实现了优异的估计精度，适用于不同厚度、电导率和提离距离的板材配置。

Conclusion: 基于量纲分析的不变变换方法为多参数估计提供了一种系统且有效的解决方案，显著提高了无损检测结果的准确性和可靠性。

Abstract: The Buckingham's $π$, theorem has been recently introduced in the context of Non destructive Testing \& Evaluation (NdT\&E) , giving a theoretical basis for developing simple but effective methods for multi-parameter estimation via dimensional analysis. Dimensional groups, or $π-$groups, allow for the reduction of the number of parameters affecting the dimensionless measured quantities.
  In many real-world applications, the main interest is in estimating only a subset of the variables affecting the measurements. An example is estimating the thickness and electrical conductivity of a plate from Eddy Current Testing data, regardless of the lift-off of the probe, which may be either uncertain and/or variable. Alternatively, one may seek to estimate thickness and lift-off while neglecting the influence of the electrical conductivity, or to estimate the electrical conductivity and the lift-off, neglecting the thickness.
  This is where the concept of invariants becomes crucial. An invariant transformation is a mathematical mapping that makes the measured signal independent of one or more of these uncertain parameters. Invariant transformations provide a way to isolate useful signals from uncertain ones, improving the accuracy and reliability of the NdT results.
  The main contribution of this paper is a systematic method to derive \emph{invariant} transformations for frequency domain Eddy Current Testing data, via dimensional analysis. The proposed method is compatible with real-time and in-line operations.
  After its theoretical foundation is introduced, the method is validated by means of experimental data, with reference to configurations consisting of plates with different thicknesses, electrical conductivity, and lift-off. The experimental validation proves the effectiveness of the method in achieving excellent accuracy on a wide range of parameters of interest.

</details>


### [28] [Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook](https://arxiv.org/abs/2511.06036)
*Hassan Hizeh,Rim Chighri,Muhammad Mahboob Ur Rahman,Mohamed A. Bahloul,Ali Muqaibel,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 本文提出了一个将帕金森病多模态传感与机器人干预相结合的闭环传感器-AI-机器人框架，利用先进AI技术统一这两个独立的研究领域。


<details>
  <summary>Details</summary>
Motivation: 当前帕金森病研究分为两个独立领域：多模态传感监测和机器人干预康复，两者缺乏有效整合。随着AI技术的发展，现在有机会将这两个互补领域统一起来。

Method: 提出闭环传感器-AI-机器人框架，通过多模态传感（IMU、EMG、EEG等）持续指导患者、护理人员和人形机器人之间的交互，利用AI代理（机器人基础模型、LLM推理、强化学习等）实现个性化干预。

Result: 该框架能够实现个性化、可解释和情境感知的干预，为帕金森病患者建立数字孪生，随时间适应以提供智能、以患者为中心的护理。

Conclusion: 通过整合多模态传感和机器人干预，利用先进AI技术构建闭环系统，有望显著改善帕金森病的筛查、监测和管理效果。

Abstract: The current body of research on Parkinson's disease (PD) screening, monitoring, and management has evolved along two largely independent trajectories. The first research community focuses on multimodal sensing of PD-related biomarkers using noninvasive technologies such as inertial measurement units (IMUs), force/pressure insoles, electromyography (EMG), electroencephalography (EEG), speech and acoustic analysis, and RGB/RGB-D motion capture systems. These studies emphasize data acquisition, feature extraction, and machine learning-based classification for PD screening, diagnosis, and disease progression modeling. In parallel, a second research community has concentrated on robotic intervention and rehabilitation, employing socially assistive robots (SARs), robot-assisted rehabilitation (RAR) systems, and virtual reality (VR)-integrated robotic platforms for improving motor and cognitive function, enhancing social engagement, and supporting caregivers. Despite the complementary goals of these two domains, their methodological and technological integration remains limited, with minimal data-level or decision-level coupling between the two. With the advent of advanced artificial intelligence (AI), including large language models (LLMs), agentic AI systems, a unique opportunity now exists to unify these research streams. We envision a closed-loop sensor-AI-robot framework in which multimodal sensing continuously guides the interaction between the patient, caregiver, humanoid robot (and physician) through AI agents that are powered by a multitude of AI models such as robotic and wearables foundation models, LLM-based reasoning, reinforcement learning, and continual learning. Such closed-loop system enables personalized, explainable, and context-aware intervention, forming the basis for digital twin of the PD patient that can adapt over time to deliver intelligent, patient-centered PD care.

</details>


### [29] [Online Learning of Modular Bayesian Deep Receivers: Single-Step Adaptation with Streaming Data](https://arxiv.org/abs/2511.06045)
*Yakov Gusakov,Osvaldo Simeone,Tirza Routtenberg,Nir Shlezinger*

Main category: eess.SP

TL;DR: 提出一种基于贝叶斯跟踪的在线学习框架，用于快速低复杂度适应DNN无线接收器，相比传统梯度下降方法显著降低更新延迟并提高对信道动态的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: DNN接收器在复杂非线性传播环境中具有优势，但面临无线信道快速变化导致预训练静态DNN失效的问题，以及在线SGD学习的高延迟和计算负担挑战。

Method: 将在线学习建模为参数空间的贝叶斯跟踪，实现单步适应而非多轮SGD；采用模块化DNN架构支持并行、在线和局部变分贝叶斯更新。

Result: 在实用通信信道上的仿真表明，该框架能保持低误码率，相比传统梯度下降方法显著降低更新延迟并提高对信道动态的鲁棒性。

Conclusion: 提出的在线学习框架为DNN接收器在动态无线环境中的实际部署提供了有效的解决方案，平衡了性能与计算复杂度。

Abstract: Deep neural network (DNN)-based receivers offer a powerful alternative to classical model-based designs for wireless communication, especially in complex and nonlinear propagation environments. However, their adoption is challenged by the rapid variability of wireless channels, which makes pre-trained static DNN-based receivers ineffective, and by the latency and computational burden of online stochastic gradient descent (SGD)-based learning. In this work, we propose an online learning framework that enables rapid low-complexity adaptation of DNN-based receivers. Our approach is based on two main tenets. First, we cast online learning as Bayesian tracking in parameter space, enabling a single-step adaptation, which deviates from multi-epoch SGD . Second, we focus on modular DNN architectures that enable parallel, online, and localized variational Bayesian updates. Simulations with practical communication channels demonstrate that our proposed online learning framework can maintain a low error rate with markedly reduced update latency and increased robustness to channel dynamics as compared to traditional gradient descent based method.

</details>


### [30] [Positioning Using LEO Satellite Communication Signals Under Orbital Errors](https://arxiv.org/abs/2511.06060)
*Jie Ma,Pinjun Zheng,Xing Liu,Yuchen Zhang,Ali A. Nasir,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 本文研究了在轨道误差下的LEO卫星定位问题，提出了一个两阶段定位方法，包括基于MCRB的加权轨道校准和最小二乘用户定位，能够将定位误差从千米级降低到米级。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星为精确定位提供了有前景的替代方案，但其较低的高度使其更容易受到轨道扰动的影响，从而降低定位精度。

Method: 首先建立了考虑地球非球面性的LEO轨道模型和捕获快慢时多普勒效应及多径传播的宽带通信模型；然后进行MCRB分析评估轨道误差对定位性能的影响；最后提出两阶段定位方法：基于MCRB的加权轨道校准和最小二乘用户定位。

Result: MCRB分析表明轨道误差可导致千米级位置偏差。广泛仿真显示所提出的估计器相对于轨道失配基线显著提高了定位精度，误差在米级范围内。

Conclusion: 所提出的两阶段定位方法能够有效缓解轨道误差对LEO卫星定位的影响，显著提高定位精度。

Abstract: Low Earth orbit (LEO) satellites offer a promising alternative to global navigation satellite systems for precise positioning; however, their relatively low altitudes make them more susceptible to orbital perturbations, which in turn degrade positioning accuracy. In this work, we study LEO-based positioning under orbital errors within a signal-of-opportunity framework. First, we introduce a LEO orbit model that accounts for Earth's non-sphericity and derive a wideband communication model that captures fast- and slow-time Doppler effects and multipath propagation. Subsequently, we perform a misspecified Cramér-Rao bound (MCRB) analysis to evaluate the impact of orbital errors on positioning performance. Then, we propose a two-stage positioning method starting with a (i) MCRB-based weighted orbit calibration, followed by (ii) least-squares user positioning using the corrected orbit. The MCRB analysis indicates that orbital errors can induce kilometer-level position biases. Extensive simulations show that the proposed estimator can considerably enhance the positioning accuracy relative to the orbit-mismatched baseline, yielding errors on the order of a few meters.

</details>


### [31] [Hierarchically Block-Sparse Recovery With Prior Support Information](https://arxiv.org/abs/2511.06173)
*Liyang Lu,Haochen Wu,Wenbo Xu,Zhaocheng Wang,H. Vincent Poor*

Main category: eess.SP

TL;DR: 本文提出了基于先验支撑信息(PSI)的分层压缩感知(HCS)的新恢复边界，设计了HiBOMP-P算法，并推导了基于互不相干性(MIP)的精确恢复条件，证明HCS即使在先验信息与真实支撑集不重叠时也能提供改进的恢复性能。


<details>
  <summary>Details</summary>
Motivation: 现有压缩感知方法严重依赖先验信息与真实支撑集的重叠，当这种重叠不存在时性能会受损。本文旨在开发即使先验信息不准确也能提供改进恢复性能的分层压缩感知方法。

Method: 提出了基于各种形式PSI的详细重建模型，设计了递归形式的分层块正交匹配追踪算法(HiBOMP-P)，推导了基于互不相干性的精确恢复条件，并提出了分层MIP概念和可重构稀疏度水平。

Result: 建立了分层压缩感知的恢复边界，证明了HCS在先验信息与真实支撑集不重叠时仍能提供改进的恢复性能，而现有方法在这种情况下性能会受损。

Conclusion: 分层压缩感知方法在先验信息不准确的情况下仍然具有鲁棒性，相比现有方法提供了更好的恢复性能保障。

Abstract: We provide new recovery bounds for hierarchical compressed sensing (HCS) based on prior support information (PSI). A detailed PSI-enabled reconstruction model is formulated using various forms of PSI. The hierarchical block orthogonal matching pursuit with PSI (HiBOMP-P) algorithm is designed in a recursive form to reliably recover hierarchically block-sparse signals. We derive exact recovery conditions (ERCs) measured by the mutual incoherence property (MIP), wherein hierarchical MIP concepts are proposed, and further develop reconstructible sparsity levels to reveal sufficient conditions for ERCs. Leveraging these MIP analyses, we present several extended insights, including reliable recovery conditions in noisy scenarios and the optimal hierarchical structure for cases where sparsity is not equal to zero. Our results further confirm that HCS offers improved recovery performance even when the prior information does not overlap with the true support set, whereas existing methods heavily rely on this overlap, thereby compromising performance if it is absent.

</details>


### [32] [Meta-Learning-Driven GFlowNets for 3D Directional Modulation in Mobile Wireless Systems](https://arxiv.org/abs/2511.06188)
*Zhihao Tao,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 提出了一种Meta-GFlowNet框架，用于在动态无线环境中快速适应移动用户，通过元学习实现方向通用先验，无需标注数据即可达到更高的安全性能。


<details>
  <summary>Details</summary>
Motivation: 传统GFlowNet方法假设静态环境，限制了在移动无线网络中的适用性。需要解决动态条件下快速适应的问题。

Method: 使用模型无关元学习，通过内部轨迹平衡更新和外部元更新学习方向通用先验，采用从GFlowNet学习奖励和实际系统奖励导出的伪监督一致性目标。

Result: 仿真结果表明，该方法比重新训练的GFlowNets具有更快的适应速度和更高的安全性能。

Conclusion: 该框架为动态无线环境提供了一个高效的生成式AI框架，可扩展到其他移动无线系统如联合感知通信网络。

Abstract: In our prior work we have proposed the use of GFlowNets, a generative AI (GenAI) framework, for designing a secure communication system comprising a time-modulated intelligent reflecting surface (TM-IRS). However, GFlowNet-based approaches assume static environments, limiting their applicability in mobile wireless networks. In this paper, we proposes a novel Meta-GFlowNet framework that achieves rapid adaptation to dynamic conditions using model-agnostic meta-learning. As the communication user is moving, the framework learns a direction-general prior across user directions via inner trajectory-balance updates and outer meta-updates, enabling quick convergence to new user directions. The approach requires no labeled data, employing a pseudo-supervised consistency objective derived from the learned reward by GFlowNet and the actual sum-rate reward of the TM-IRS system. Simulation results show that the proposed method attains faster adaptation and higher secrecy performance than retrained GFlowNets, offering an efficient GenAI framework for dynamic wireless environments. Although the scenario considered here focuses on directional modulation-based physical-layer security, the proposed framework can also be applied to other mobile wireless systems, such as joint sensing-communication networks, that utilize GFlowNets.

</details>


### [33] [Fast Reconstruction of Motion-Corrupted Data with Mobile-GRAPPA: Motion and dB0 Inhomogeneity Correction Leveraging Efficient GRAPPA](https://arxiv.org/abs/2511.06257)
*Yimeng Lin,Nan Wang,Daniel Abraham,Daniel Polak,Xiaozhi Cao,Stephen Cauley,Kawin Setsompop*

Main category: eess.SP

TL;DR: Mobile-GRAPPA是一种k空间"清理"方法，使用局部GRAPPA算子去除运动和dB0相关伪影，使数据能够用标准SENSE重建，解决了Aligned-SENSE计算量过大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有运动导航技术能够快速跟踪主体运动和dB0诱导相位，但将这些高时间分辨率信息准确整合到SENSE（Aligned-SENSE）中计算量过大，难以实际应用。

Method: 通过轻量级多层感知器（MLP）高效训练一系列k空间位置特定的Mobile-GRAPPA核，并将其应用于整个k空间以生成干净数据。

Result: 在高度运动损坏的1毫米全脑GRE和EPTI实验中，Mobile-GRAPPA实现了准确重建且时间开销可忽略，而完整Aligned-SENSE重建时间过长（GRE>10小时，EPTI>10天）。

Conclusion: Mobile-GRAPPA能够以最小计算开销将详细运动和dB0跟踪整合到SENSE中，实现对挑战性数据的快速高质量重建。

Abstract: Advanced motion navigations now enable rapid tracking of subject motion and dB0-induced phase, but accurately incorporating this high-temporal-resolution information into SENSE (Aligned-SENSE) is often computationally prohibitive. We propose "Mobile-GRAPPA", a k-space "cleaning" approach that uses local GRAPPA operators to remove motion and dB0 related corruption so that the resulting data can be reconstructed with standard SENSE. We efficiently train a family of k-space-position-specific Mobile-GRAPPA kernels via a lightweight multilayer perceptron (MLP) and apply them across k-space to generate clean data. In experiments on highly motion-corrupted 1-mm whole-brain GRE (Tacq = 10 min; 1,620 motion/dB0 trackings) and EPTI (Tacq = 2 min; 544 trackings), Mobile-GRAPPA enabled accurate reconstruction with negligible time penalty, whereas full Aligned-SENSE was impractical (reconstruction times > 10 h for GRE and > 10 days for EPTI). These results show that Mobile-GRAPPA incorporates detailed motion and dB0 tracking into SENSE with minimal computational overhead, enabling fast, high-quality reconstructions of challenging data.

</details>


### [34] [Blocker-Aware Beamforming and Dynamic Power Allocation for Multicarrier ISAC-NOMA Systems](https://arxiv.org/abs/2511.06270)
*Abdulahi Abiodun Badrudeen,Nakyung Lee,Adam Dubs,Sunwoo Kim*

Main category: eess.SP

TL;DR: 提出了一种阻塞感知的多载波ISAC-NOMA系统，通过混合波束成形和动态功率分配提升6G网络频谱效率，在阻塞环境下保持稳健性能


<details>
  <summary>Details</summary>
Motivation: 解决环境阻塞导致的性能下降问题，确保在变化的信道条件下系统仍能可靠运行

Method: 采用联合波形设计、信道切换机制和动态功率分配策略，当主LOS链路被阻塞时通过替代NLOS路径重路由通信

Result: 在严重阻塞情况下，系统在15dB SNR时实现了高达400%的感知速率提升，通信速率仅下降20%

Conclusion: 该系统能够适应实际部署环境并优化联合感知-通信性能

Abstract: This paper proposes a blocker-aware multicarrier integrated sensing and communication (ISAC)-non orthogonal multiple access (NOMA) system, leveraging hybrid beamforming and dynamic power allocation to enhance spectrum efficiency in 6G networks. Recognizing the performance degradation caused by environmental blockers, the system introduces a joint waveform design that ensures robust operation under varying channel conditions. A channel switching mechanism is deployed to reroute communication through alternative non-line-of-sight paths when the primary line-of-sight links are obstructed. Moreover, a dynamic power allocation strategy enforces a minimum rate constraint for the weak NOMA user, ensuring consistent quality of service. Extensive simulations over multiple blockage scenarios and signal to noise (SNR) conditions validate the effectiveness of the proposed solution. Notably, under severe blockage, the system achieves up to a 400% sensing rate enhancement at 15 dB SNR, with only a 20% reduction in communication rate. These results corroborate the system's ability to adapt and optimize joint sensing-communication performance in practical deployment environments.

</details>


### [35] [Sum Rate and Worst Case SINR Optimization in Multi HAPS Ground Integrated Networks](https://arxiv.org/abs/2511.06339)
*Shasha Liu,Hayssam Dahrouj,Abla Kammoun,Mohamed-Slim Alouini*

Main category: eess.SP

TL;DR: 本文提出了一种多高空平台系统(HAPS)与地面基站集成的网络架构，通过联合优化用户关联和波束成形来平衡吞吐量和公平性，以解决数字鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 解决全球数字鸿沟问题，通过多HAPS与地面基站协作提升地面用户服务质量，实现数字公平。

Method: 采用广义分配问题(GAP)方法确定用户关联变量，结合基于连续凸近似(SCA)的迭代算法优化波束成形向量，支持分布式实现。

Result: 仿真结果验证了所提算法的性能，证明多HAPS网络能够提升整体网络数字包容性。

Conclusion: 多HAPS网络是实现未来数字服务民主化的关键使能技术，能够有效平衡吞吐量和公平性。

Abstract: Balancing throughput and fairness promises to be a key enabler for achieving large-scale digital inclusion in future vertical heterogeneous networks (VHetNets). In an attempt to address the global digital divide problem, this paper explores a multi-high-altitude platform system (HAPS)-ground integrated network, in which multiple HAPSs collaborate with ground base stations (BSs) to enhance the users' quality of service on the ground to achieve the highly sought-after digital equity. To this end, this paper considers maximizing both the network-wide weighted sum rate function and the worst-case signal-to-interference-plus-noise ratio (SINR) function subject to the same system level constraints. More specifically, the paper tackles the two different optimization problems so as to balance throughput and fairness, by accounting for the individual HAPS payload connectivity constraints, HAPS and BS distinct power limitations, and per-user rate requirements. This paper solves the considered problems using techniques from optimization theory by adopting a generalized assignment problem (GAP)-based methodology to determine the user association variables, jointly with successive convex approximation (SCA)-based iterative algorithms for optimizing the corresponding beamforming vectors. One of the main advantages of the proposed algorithms is their amenability for distributed implementation across the multiple HAPSs and BSs. The simulation results particularly validate the performance of the presented algorithms, demonstrating the capability of multi-HAPS networks to boost-up the overall network digital inclusion toward democratizing future digital services.

</details>


### [36] [Stackelberg Game-Driven Defense for ISAC Against Channel Attacks in Low-Altitude Networks](https://arxiv.org/abs/2511.06359)
*Jiacheng Wang,Changyuan Zhao,Dusit Niyato,Geng Sun,Weijie Yuan,Abbas Jamalipour,Tao Xiang*

Main category: eess.SP

TL;DR: 提出基于Stackelberg博弈的防御框架来应对低空ISAC系统中的信道接入攻击，通过三方博弈建模和逆向归纳算法实现动态策略调整，确保关键低空应用的可靠性能。


<details>
  <summary>Details</summary>
Motivation: 随着经济活动向低空空域扩展，集成感知与通信(ISAC)技术面临信道接入攻击威胁，这会降低性能并威胁安全，需要有效的防御机制。

Method: 首先建模受攻击系统，量化通信和感知性能指标；然后将交互建模为三方Stackelberg博弈，恶意攻击者作为领导者，合法无人机和地面基站作为跟随者；使用逆向归纳算法求解Stackelberg均衡。

Result: 仿真结果表明，所提算法能够收敛到稳定解，并且在性能上优于现有基线方法。

Conclusion: 该防御框架能够有效缓解信道接入攻击，确保关键低空应用的可靠ISAC性能。

Abstract: The increasing saturation of terrestrial resources has driven economic activities into low-altitude airspace. These activities, such as air taxis, rely on low-altitude wireless networks, and one key enabling technology is integrated sensing and communication (ISAC). However, in low-altitude airspace, ISAC is vulnerable to channel-access attacks, thereby degrading performance and threatening safety. To address this, we propose a defense framework based on a Stackelberg game. Specifically, we first model the system under attack, deriving metrics for the communication and the sensing to quantify performance. Then, we formulate the interaction as a three-player game where a malicious attacker acts as the leader, while the legitimate drone and ground base station act as followers. Using a backward induction algorithm, we obtain the Stackelberg equilibrium, allowing the defenders to dynamically adjust their strategies to mitigate the attack. Simulation results verify that the proposed algorithm converges to a stable solution and outperforms existing baselines, ensuring reliable ISAC performance for critical low-altitude applications.

</details>


### [37] [CSIT-Free Multi-Group Multicast Transmission in Overloaded mmWave Systems](https://arxiv.org/abs/2511.06369)
*Wonseok Choi,Jeongjae Lee,Songnam Hong*

Main category: eess.SP

TL;DR: 提出了一种免CSIT的多组多播传输方案，通过确定性预编码和闭式功率分配，在过载毫米波系统中实现低复杂度的干扰消除。


<details>
  <summary>Details</summary>
Motivation: 传统多组多播波束成形需要高计算复杂度和大量反馈开销获取CSIT，同时管理干扰和多播波束成形优化会导致显著的速率损失。

Method: 使用确定性CSIT-free预编码和基于最大最小公平的闭式功率分配，让每个用户能够完全消除组间干扰检测公共多播流。

Result: 仿真结果表明，所提CF-MGM在可达速率和组内用户增加方面优于现有基于CSIT的方法，具有优越性和可扩展性。

Conclusion: CF-MGM方案有效解决了传统多组多播传输中CSIT获取复杂和干扰管理困难的问题，实现了低复杂度高性能的多播传输。

Abstract: In this paper, we investigate the downlink multi-group multicast (MGM) transmission problem in overloaded mmWave systems. In particular, the conventional MGM beamforming requires substantial computational complexity and feedback (or pilot) overhead for acquisition of channel state information at the transmitter (CSIT), while simultaneous interference management and multicast beamforming optimization across multi-group inevitably incurs a significant rate loss. To address this, we propose a CSIT-free MGM (CF-MGM) transmission that eliminates the need for a complex CSIT acquisition. A deterministic CSIT-free precoding and proposed closed-form power allocation based on max-min fairness (MMF) allow each user to detect the common multicast stream completely canceling the inter-group interference with a significantly low complexity. Simulation results demonstrate the superiority and scalability of the proposed CF-MGM for the achievable rate and increase of users in a group outperforming the existing CSIT-based methods.

</details>


### [38] [Near-Field Velocity Estimation and Predictive Beamforming with Modular Linear Array](https://arxiv.org/abs/2511.06383)
*Khalid A. Alshumayri,Mudassir Masood,Ali. A. Nasir*

Main category: eess.SP

TL;DR: 本文推导了在预测波束成形框架下使用模块化线性阵列进行联合速度估计的闭式克拉美-罗界，分析了模块间距对速度估计精度的影响，并研究了速度失配对阵列增益的影响。


<details>
  <summary>Details</summary>
Motivation: 速度估计是近场预测波束成形的关键基础，需要研究模块化线性阵列在预测波束成形框架下的性能界限和优化配置。

Method: 推导了模块化线性阵列在预测波束成形框架下联合速度估计的闭式克拉美-罗界，分析了模块间距对横向和径向速度估计精度的影响，并建立了天线节省与模块间距的闭式关系。

Result: 增大模块间距可扩大有效孔径并降低横向速度的CRB，而径向速度CRB对间距不敏感。横向速度误差比径向速度误差对性能影响更严重。仿真显示预测波束成形与MLA能保持高定位精度。

Conclusion: 模块化线性阵列在预测波束成形中能有效进行目标跟踪，通过优化模块间距可以在保持精度的同时节省天线数量。

Abstract: Velocity estimation is a cornerstone of recently introduced near-field predictive beamforming. This paper derives the closed-form Cramer-Rao bounds (CRBs) for joint velocity estimation using a modular linear array (MLA) within a predictive-beamforming framework. The analysis shows that increasing inter-module separation enlarges the effective aperture and reduces the transverse-velocity CRB, whereas the radial-velocity CRB is largely insensitive to separation. We further obtain a simple closed-form relation linking the achievable antenna savings to the inter-module separation while preserving the same transverse accuracy of a uniform linear array (ULA). We further investigate how velocity mismatch affects array gain and show that transverse-velocity errors cause more severe performance degradation than radial-velocity errors. Simulations show that predictive beamforming with MLAs maintains high localization accuracy for target tracking.

</details>


### [39] [UAV-Assisted Downlink Satellite Covert Communication](https://arxiv.org/abs/2511.06395)
*Hung D. Nguyen,Jeongseok Ha*

Main category: eess.SP

TL;DR: UAV辅助LEO卫星与地面用户间的隐蔽通信，UAV同时服务自身网络并作为友好干扰器增强隐蔽性。通过优化UAV 3D位置、功率分配和卫星发射功率来最大化隐蔽速率。


<details>
  <summary>Details</summary>
Motivation: 解决在被动监视下LEO卫星与地面用户间隐蔽通信的挑战，利用UAV作为友好干扰器来增强隐蔽性。

Method: 推导了看守平均最小检测错误概率的闭式下界，基于此定义隐蔽约束。使用块坐标下降(BCD)和逐次凸近似(SCA)技术提出优化算法，针对特殊情况开发Dinkelbach算法。

Result: 数值结果验证了推导下界的紧致性，并证明了所提算法在配置最优系统参数方面的有效性。

Conclusion: 提出的UAV辅助隐蔽通信框架和优化算法能够有效增强卫星通信的隐蔽性，同时最大化系统隐蔽速率。

Abstract: This paper investigates the use of an unmanned aerial vehicle (UAV) to assist covert communication between a low-Earth orbit (LEO) satellite and a ground user under the surveillance of a passive warden. The UAV simultaneously serves its own ground network and acts as a friendly jammer to enhance the covertness of satellite transmissions. We derive a closed-form lower bound on the warden's average minimum detection error probability which is then used to define the covert constraint. Building on this, we formulate an optimization problem to jointly design the UAV's 3D placement, its power allocation, and the satellite's transmit power to maximize the system's covert rate. To solve the resulting non-convex problem, we propose an algorithm based on the block coordinate descent (BCD) and successive convex approximation (SCA) techniques, and further develop a Dinkelbach's algorithm for a special case. Numerical results validate the tightness of the derived bound and demonstrate the effectiveness of the proposed algorithms in configuring optimal system parameters.

</details>


### [40] [Distributed MIMO Positioning: Fundamental Limit Analysis and User Tracking Framework Design](https://arxiv.org/abs/2511.06440)
*Yingjie Xu,Xuesong Cai,Ali Al-Ameri,Sara Willhammar,Fredrik Tufvesson*

Main category: eess.SP

TL;DR: 本文研究了分布式MIMO系统中用户3D定位能力，提出了考虑实际天线特性的极化模型，建立了基于FIM和PEB的定位理论框架，并开发了结合概率假设密度滤波和PEB感知AP管理的完整定位系统，实现了厘米级跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖理想化的各向同性天线模型，无法准确反映实际天线模式、布局和极化效应，限制了分布式MIMO系统定位精度的提升。

Method: 采用极化模型描述实际天线特性，基于Fisher信息矩阵和位置误差界分析定位性能，提出结合全局概率假设密度滤波和PEB感知AP管理的完整定位框架。

Result: 实验验证显示系统实现了厘米级跟踪精度，PEB感知AP管理策略在显著减少并发活动AP数量的同时保持了鲁棒的跟踪性能。

Conclusion: 所提出的定位框架能够有效利用分布式MIMO系统的空间多样性，在降低系统开销的同时实现高精度3D定位，为实际部署提供了可行方案。

Abstract: This paper presents a comprehensive study on the 3D positioning capabilities of users in distributed multiple-input multiple-output (MIMO) systems. Unlike previous studies that mainly rely on idealized isotropic antenna models, we adopt a polarimetric model that takes advantage of effective aperture distribution functions to characterize realistic antenna patterns, placements, and polarization effects. Based on this model, we analyze the fundamental limits of UE positioning using the Fisher information matrix (FIM) and the position error bound (PEB). The FIM is shown to be expressed as a weighted sum of the information contributions from individual access point (AP)-UE pairs, with each contribution interpreted geometrically across distance, azimuth, and elevation dimensions. The impact of the UE tilt and the spatial distribution of APs on the PEBs is further analyzed. As a further advancement, we propose a complete positioning framework from a UE tracking perspective. By integrating a global probability hypothesis density filter and a PEB-aware AP management strategy, the framework enables accurate tracking while optimizing AP scheduling. Finally, we present a distributed MIMO channel measurement campaign to validate the proposed framework. The results demonstrate a centimeter-level tracking accuracy. In addition, the PEB-aware AP management strategy is shown to maintain robust tracking performance while significantly reducing the number of concurrently active APs, thus lowering the overall system overhead.

</details>


### [41] [Spectrum and Physics-Informed Neural Networks (SaPINNs) for Input-State-Parameter Estimation in Dynamic Systems Subjected to Natural Hazards-Induced Excitation](https://arxiv.org/abs/2511.06621)
*Antonina Kosikova,Apostolos Psaros,Andrew Smyth*

Main category: eess.SP

TL;DR: 提出了SaPINNs方法，结合物理知识和频谱信息来解决自然激励下系统的输入-状态-参数估计问题，在El Centro地震等复杂激励下表现优于传统PINNs。


<details>
  <summary>Details</summary>
Motivation: 解决自然激励下系统辨识的固有不适定问题，特别是在地震、风暴等自然危害中，系统响应具有瞬态、非线性和空间分布特性，传统方法需要额外知识或简化假设。

Method: 将神经网络与系统动力学物理规律相结合，并使用经验频谱作为未知激励的先验，通过Deep Ensemble架构处理预测不确定性。

Result: 在线性和非线性系统上的比较研究表明，该方法优于传统PINNs，频谱信息的引入提供了归纳偏置，能更有效地恢复物理一致的状态和参数估计。

Conclusion: SaPINNs通过整合物理知识和频谱信息，能够在复杂自然激励下实现可靠的系统辨识，为自然危害工程应用提供了有效工具。

Abstract: System identification under unknown external excitation is an inherently ill-posed problem, typically requiring additional knowledge or simplifying assumptions to enable reliable state and parameter estimation. The difficulty of the problem is further amplified in structural systems subjected to natural hazards such as earthquakes or windstorms, where responses are often highly transient, nonlinear, and spatially distributed. To address this challenge, we introduce Spectrum and Physics-Informed Neural Networks (SaPINNs) for efficient input--state--parameter estimation in systems under complex excitations characteristic of natural hazards. The proposed model enhances the neural network with governing physics of the system dynamics and incorporates spectral information of natural hazards by using empirically derived spectra as priors on the unknown excitations. This integration improves inference of unmeasured inputs, system states, and parameters without imposing restrictive assumptions on their dynamics. The performance of the proposed framework is demonstrated through comparative studies on both linear and nonlinear systems under various types of excitation, including the El Centro earthquake, where the seismic spectrum is assumed to be not precisely known. To account for predictive uncertainty, the proposed architecture is embedded within a Deep Ensemble (DEns) networks architecture, providing distributions over possible solutions. The results demonstrate that the proposed approach outperforms conventional PINNs, as the incorporation of spectral information introduces an inductive bias that guides the network more effectively through the solution space and enhances its ability to recover physically consistent state and parameter estimates with realistic uncertainty levels.

</details>


### [42] [Structure-Aware Near-Field Radio Map Recovery via RBF-Assisted Matrix Completion](https://arxiv.org/abs/2511.06710)
*Hao Sun,Xianghao Yu,Junting Chen*

Main category: eess.SP

TL;DR: 提出了一种基于径向基函数插值的结构感知矩阵补全框架，用于XL-MIMO系统中的近场无线电地图构建，通过结合局部变化结构和全局低秩结构显著提高了重建精度。


<details>
  <summary>Details</summary>
Motivation: 近场波前由于球面波传播在角度和距离上表现出强依赖性，导致接收信号强度变化复杂，传统方法难以有效捕捉这种复杂的空间变化结构。

Method: 开发了正则化RBF插值方法，引入逆μ律启发的非均匀采样策略，将RBF插值与基于核范数最小化的矩阵补全相结合，并提出鲁棒的Huberized留一交叉验证方案。

Result: 在变化的采样密度和阴影条件下，相比标准插值和矩阵补全方法，所提方法在归一化均方误差上实现了超过10%的改进。

Conclusion: 通过RBF插值的局部变化结构建模与矩阵补全的全局低秩结构利用相结合，构建了一个结构感知框架，显著提高了近场无线电地图重建的准确性。

Abstract: This paper proposes a novel structure-aware matrix completion framework assisted by radial basis function (RBF) interpolation for near-field radio map construction in extremely large multiple-input multiple-output (XL-MIMO) systems. Unlike the far-field scenario, near-field wavefronts exhibit strong dependencies on both angle and distance due to spherical wave propagation, leading to complicated variations in received signal strength (RSS). To effectively capture the intricate spatial variations structure inherent in near-field environments, a regularized RBF interpolation method is developed to enhance radio map reconstruction accuracy. Leveraging theoretical insights from interpolation error analysis of RBF, an inverse μ-law-inspired nonuniform sampling strategy is introduced to allocate measurements adaptively, emphasizing regions with rapid RSS variations near the transmitter. To further exploit the global low-rank structure in the near-field radio map, we integrate RBF interpolation with nuclear norm minimization (NNM)-based matrix completion. A robust Huberized leave-one-out cross-validation (LOOCV) scheme is then proposed for adaptive selection of the tolerance parameter, facilitating optimal fusion between RBF interpolation and matrix completion. The integration of local variation structure modeling via RBF interpolation and global low-rank structure exploitation via matrix completion yields a structure-aware framework that substantially improves the accuracy of near-field radio map reconstruction. Extensive simulations demonstrate that the proposed approach achieves over 10% improvement in normalized mean squared error (NMSE) compared to standard interpolation and matrix completion methods under varying sampling densities and shadowing conditions.

</details>


### [43] [Learning Performance Optimization for Edge AI System with Time and Energy Constraints](https://arxiv.org/abs/2511.06806)
*Zhiyuan Zhai,Wei Ni,Xin Wang*

Main category: eess.SP

TL;DR: 本文提出了一种Edge AI系统优化方法，通过联合优化数据收集时间和训练轮数，在时间和能量约束下最大化学习性能。


<details>
  <summary>Details</summary>
Motivation: Edge AI系统部署面临高能耗和长时间运行的问题，需要优化系统参数来提升学习性能。

Method: 建立了数据采集、计算和通信过程的时间与能耗模型，进行严格的收敛性分析，并基于一维搜索和交替优化开发低复杂度算法。

Result: 仿真结果验证了收敛分析的准确性，并证明了所提算法在异构设备场景下的有效性。

Conclusion: 该研究为在实际条件下设计能效优化的Edge AI系统提供了有价值的见解。

Abstract: Edge AI, which brings artificial intelligence to the edge of the network for real-time processing and decision-making, has emerged as a transformative technology across various applications. However, the deployment of Edge AI systems faces significant challenges due to high energy consumption and extended operation time.
  In this paper, we consider an Edge AI system which integrates the data acquisition, computation and communication processes, and focus on improving learning performance of this system. We model the time and energy consumption of different processes and perform a rigorous convergence analysis to quantify the impact of key system parameters, such as the amount of collected data and the number of training rounds, on the learning performance. Based on this analysis, we formulate a system-wide optimization problem that seeks to maximize learning performance under given time and energy constraints. We explore both homogeneous and heterogeneous device scenarios, developing low-complexity algorithms based on one-dimensional search and alternating optimization to jointly optimize data collection time and training rounds. Simulation results validate the accuracy of our convergence analysis and demonstrate the effectiveness of the proposed algorithms, providing valuable insights into designing energy-efficient Edge AI systems under real-world conditions.

</details>


### [44] [Joint Access Point Selection and Beamforming Design for Bistatic Backscatter Communication](https://arxiv.org/abs/2511.06866)
*Ahmet Kaplan,Diana P. M. Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: 本文提出了一种用于分布式MIMO系统中双基地反向散射通信的联合接入点角色选择和波束成形技术，旨在增强反向散射信号能量并抑制直接链路干扰，同时开发了相应的信道估计方法和检测器。


<details>
  <summary>Details</summary>
Motivation: 未来物联网网络需要低功耗传感器节点，反向散射通信是一种能效和成本效益高的技术，但面临往返路径损耗和直接链路干扰等挑战，限制了其性能。

Method: 提出联合接入点角色选择和新型波束成形技术，开发了在DLI条件下的信道估计方法，使用估计信道系数的失配检测器，推导了检测器错误概率的闭式表达式，并建模了DLI引起的量化噪声。

Result: 仿真结果表明，所提方法使用1位ADC能有效抑制DLI、减少量化噪声并增强反向散射信号能量，性能可与使用8位ADC的基准场景相媲美。

Conclusion: 该方法显著提升了双基地反向散射通信的性能，在低精度ADC条件下实现了与高精度ADC相当的性能，为物联网网络提供了实用的解决方案。

Abstract: Future Internet-of-Things networks are envisioned to use small and cheap sensor nodes with extremely low power consumption to avoid the extensive use of batteries. To provide connectivity to a massive number of these nodes, backscatter communication (BC) is emerging as an energy- and cost-efficient technology exploiting the reflection of radio frequency signals. However, challenges such as round-trip path loss and direct link interference (DLI) between the carrier emitter and the reader limit its performance. To tackle these limitations, this paper proposes a joint access point role selection and a novel beamforming technique for bistatic BC in a distributed multiple-input multiple- output setup. The proposed approach boosts the received backscattered energy while effectively mitigating DLI, thereby reducing the error probability. We also propose a channel estimation method tailored to operate under DLI conditions and propose a mismatch detector using estimated channel coefficients. Furthermore, we derive a closed-form expression for the probability of error for the detectors and model the quantization noise caused by DLI. Finally, comprehensive simulation results show that the proposed method with 1-bit analog-to-digital converters (ADCs) effectively mitigates DLI, reduces the quantization noise, and enhances backscattered signal energy, achieving performance comparable to the benchmark scenario with 8-bit ADCs.

</details>


### [45] [Radio-Coverage-Aware Path Planning for Cooperative Autonomous Vehicles](https://arxiv.org/abs/2511.06874)
*Giuseppe Baruffa,Luca Rugini,Francesco Binucci,Fabrizio Frescura,Paolo Banelli,Renzo Perfetti*

Main category: eess.SP

TL;DR: 提出了一种改进的路径规划算法，在Dijkstra和A*算法中考虑无线覆盖质量，而不仅仅是行驶距离，以提高自动驾驶车辆在智能交通场景中的通信性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在智能交通场景中需要无线互联网连接来卸载计算机视觉任务，但车辆在移动过程中会穿越不同的无线覆盖区域，影响接入比特率、延迟和切换率。

Method: 修改路径规划算法（Dijkstra和A*）的成本函数，引入多个与无线覆盖相关的成本加权函数，在最佳路径解决方案中同时考虑行驶距离和无线覆盖体验。

Result: 提出的映射算法可以实现低于2%的映射错误概率，路径规划算法在有限距离增加的情况下，显著扩展了自动驾驶车辆的无线覆盖体验。

Conclusion: 通过将无线覆盖质量纳入路径规划成本函数，可以在不显著增加行驶距离的情况下，改善自动驾驶车辆的通信性能。

Abstract: Fleets of autonomous vehicles (AV) often are at the core of intelligent transportation scenarios for smart cities, and may require a wireless Internet connection to offload computer vision tasks to data centers located either in the edge or the cloud section of the network. Cooperation among AVs is successful when the environment is unknown, or changes dynamically, so as to improve coverage and trip time, and minimize the traveled distance. The AVs, while mapping the environment with range-based sensors, move across the wireless coverage areas, with consequences on the achieved access bit rate, latency, and handover rate. In this paper, we propose to modify the cost of path planning algorithms such as Dijkstra and A*, so that not only the traveled distance is considered in the best path solution, but also the radio coverage experience. To this aim, several radio-related cost-weighting functions are introduced and tested, to assess the performance of the proposed techniques with extensive simulations. The proposed mapping algorithm can achieve a mapping error probability below 2%, while the proposed path-planning algorithms extend the experienced radio coverage of the AVs, with limited distance increase with respect to shortest-path existing methods, such as conventional Dijkstra and A* algorithms.

</details>


### [46] [Real-Time Diverse Fiber Sensing Multi-Event Detection using Phase OTDR Measurements](https://arxiv.org/abs/2511.06922)
*Konstantinos Alexoudis,Jasper Müller,Sai Kireet Patri,Vincent A. J. M. Sleiffer,Vishal Chandraprakash Rai,André Sandmann,Sander Jansen,Thomas Bradley,Chigo Okonkwo*

Main category: eess.SP

TL;DR: 开发了一种实验性相位OTDR系统，能够同时检测和分类多种环境事件（如风力引起的光纤移动、车辆移动和音频特征），并实现实时可视化。


<details>
  <summary>Details</summary>
Motivation: 传统OTDR系统在环境事件检测方面存在局限性，需要一种能够同时检测和分类多种环境事件并实现实时可视化的系统。

Method: 采用相位光学时域反射测量（OTDR）技术，通过分析光纤中的相位变化来检测环境事件。

Result: 系统成功实现了对风力引起的光纤移动、车辆移动和音频特征等多种环境事件的同步检测和分类，并提供了实时可视化功能。

Conclusion: 该实验性相位OTDR系统在环境监测领域具有应用潜力，能够提供多事件检测和实时可视化能力。

Abstract: We demonstrate an experimental phase optical time-domain reflectometry (OTDR) system capable of simultaneous detection and classification of various environmental events, such as wind-induced fiber movement, vehicle movement, and audio signatures, with real-time visualization.

</details>


### [47] [MARBLE-Net: Learning to Localize in Multipath Environment with Adaptive Rainbow Beams](https://arxiv.org/abs/2511.06971)
*Qiushi Liang,Yeyue Cai,Jianhua Mo,Meixia Tao*

Main category: eess.SP

TL;DR: MARBLE-Net是一个深度学习框架，通过联合优化频率相关彩虹光束的模拟波束成形参数和神经定位网络，在复杂多径环境中实现高精度目标定位。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)系统在复杂无线环境中面临多径传播的挑战，需要精确高效的目标定位方法。

Method: 将移相器和真时延参数作为可学习权重，通过结构化多阶段训练策略自适应优化感知波束以利用环境特定的多径特性。

Result: 在多径丰富的场景中，MARBLE-Net比固定波束深度学习基准(RaiNet)和传统k-NN方法定位误差减少50%以上，并能有效利用结构化多径实现超越视距条件的性能。

Conclusion: MARBLE-Net证明了通过深度学习联合优化波束成形和定位网络，可以有效利用多径传播特性来提升ISAC系统的定位精度。

Abstract: Integrated sensing and communication (ISAC) systems demand precise and efficient target localization, a task challenged by rich multipath propagation in complex wireless environments. This paper introduces MARBLE-Net (Multipath-Aware Rainbow Beam Learning Network), a deep learning framework that jointly optimizes the analog beamforming parameters of a frequency-dependent rainbow beam and a neural localization network for high-accuracy position estimation. By treating the phase-shifter (PS) and true-time-delay (TTD) parameters as learnable weights, the system adaptively refines its sensing beam to exploit environment-specific multipath characteristics. A structured multi-stage training strategy is proposed to ensure stable convergence and effective end-to-end optimization. Simulation results show that MARBLE-Net outperforms both a fixed-beam deep learning baseline (RaiNet) and a traditional k-nearest neighbors (k-NN) method, reducing localization error by more than 50\% in a multipath-rich scene. Moreover, the results reveal a nuanced interaction with multipath propagation: while confined uni-directional multipath degrades accuracy, structured and directional multipath can be effectively exploited to achieve performance surpassing even line-of-sight (LoS) conditions.

</details>


### [48] [Design Principles of Zero-Shot Self-Supervised Unknown Emitter Detectors](https://arxiv.org/abs/2511.07026)
*Mikhail Krasnov,Ljupcho Milosheski,Mihael Mohorčič,Carolina Fortuna*

Main category: eess.SP

TL;DR: 本文提出了一个全面的未知发射器检测系统评估框架，重点关注数据模态、学习方法和特征学习模块。提出了2D-Constellation数据模态和基于SVD初始化的特征学习方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有未知发射器识别方法依赖标记数据集、不现实假设或缺乏系统评估。需要解决不同消息传输场景下的检测挑战。

Method: 1) 提出2D-Constellation数据模态处理变消息场景；2) 引入可解释KAN网络增强透明度；3) 设计基于SVD的特征学习模块初始化方法；4) 在Deep Clustering、Auto Encoder和Contrastive Learning三种方法上评估所有数据模态和学习模块。

Result: 2D-Constellation数据模态比传统I/Q数据在ROC-AUC、NMI和F1指标上提升达40%；SVD初始化使Deep Clustering方法性能提升达40%。

Conclusion: 所提出的数据模态和特征学习方法显著提升了未知发射器检测性能，为频谱管理和网络安全提供了更有效的解决方案。

Abstract: The proliferation of wireless devices necessitates more robust and reliable emitter detection and identification for critical tasks such as spectrum management and network security. Existing studies exploring methods for unknown emitters identification, however, are typically hindered by their dependence on labeled or proprietary datasets, unrealistic assumptions (e.g. all samples with identical transmitted messages), or deficiency of systematic evaluations across different architectures and design dimensions. In this work, we present a comprehensive evaluation of unknown emitter detection systems across key aspects of the design space, focusing on data modality, learning approaches, and feature learn- ing modules. We demonstrate that prior self-supervised, zero-shot emitter detection approaches commonly use datasets with identical transmitted messages. To address this limitation, we propose a 2D- Constellation data modality for scenarios with varying messages, achieving up to a 40\% performance improvement in ROC-AUC, NMI, and F1 metrics compared to conventional raw I/Q data. Furthermore, we introduce interpretable Kolmogorov--Arnold Net- works (KANs) to enhance model transparency, and a Singular Value Decomposition (SVD)-based initialization procedure for feature learning modules operating on sparse 2D-Constellation data, which improves the performance of Deep Clustering approaches by up to 40\% across the same metrics comparing to the modules without SVD initialization. We evaluate all data modalities and learning modules across three learning approaches: Deep Clustering, Auto Encoder and Contrastive Learning.

</details>


### [49] [Trajectory Design for UAV-Assisted Logistics Collection in Low-Altitude Economy](https://arxiv.org/abs/2511.07178)
*Zhiyuan Zhai,Yuan Gao,Wei Ni,Xiaojun Yuan,Xin Wang*

Main category: eess.SP

TL;DR: 提出结合LKH和DDPG的新算法，用于优化低空经济中无人机物流收集任务的轨迹规划，相比基线方法减少约49%的收集时间。


<details>
  <summary>Details</summary>
Motivation: 低空经济中无人机物流收集任务需要在复杂三维环境中避障飞行，传统在自由空间条件下设计的轨迹规划方法不适用，需要开发能够处理障碍物的高效轨迹规划算法。

Method: 结合Lin-Kernighan-Helsgaun (LKH)算法和Deep Deterministic Policy Gradient (DDPG)方法，LKH确定物品收集的最优顺序，DDPG设计收集点之间的飞行轨迹。

Result: 仿真实验表明，提出的LKH-DDPG算法相比基线方法显著减少了约49%的收集时间。

Conclusion: 该算法在低空经济范式中有效优化了无人机轨迹，提高了物流收集任务的运行效率。

Abstract: Low-altitude economy (LAE) is rapidly emerging as a key driver of innovation, encompassing economic activities taking place in airspace below 500 meters. Unmanned aerial vehicles (UAVs) provide valuable tools for logistics collection within LAE systems, offering the ability to navigate through complex environments, avoid obstacles, and improve operational efficiency. However, logistics collection tasks involve UAVs flying through complex three-dimensional (3D) environments while avoiding obstacles, where traditional UAV trajectory design methods,typically developed under free-space conditions without explicitly accounting for obstacles, are not applicable. This paper presents, we propose a novel algorithm that combines the Lin-Kernighan-Helsgaun (LKH) and Deep Deterministic Policy Gradient (DDPG) methods to minimize the total collection time. Specifically, the LKH algorithm determines the optimal order of item collection, while the DDPG algorithm designs the flight trajectory between collection points. Simulations demonstrate that the proposed LKH-DDPG algorithm significantly reduces collection time by approximately 49 percent compared to baseline approaches, thereby highlighting its effectiveness in optimizing UAV trajectories and enhancing operational efficiency for logistics collection tasks in the LAE paradigm.

</details>


### [50] [Low-Complexity ADMM-Based Multicast Beamforming in Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2511.07310)
*Mahmoud Zaher,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种基于ADMM的框架，用于解决cell-free大规模MIMO网络中的最大最小公平(MMF)和服务质量(QoS)多播波束成形优化问题，该算法通过结合迭代消除策略在ADMM更新中高效获得接近全局最优的秩1波束成形解。


<details>
  <summary>Details</summary>
Motivation: 传统基于半定松弛(SDR)和随机化的方法在系统规模增大时扩展性差，而现有连续凸近似(SCA)方法只能保证收敛到驻点，需要更高效且可扩展的多播波束成形优化方法。

Method: 采用交替方向乘子法(ADMM)框架，结合半定松弛但引入新颖的迭代消除策略，在ADMM更新中高效获得秩1波束成形解。

Result: 数值评估表明，所提出的ADMM方法不仅实现了更优的频谱效率，而且在天线数量和用户设备数量增加时具有良好的扩展性，优于现有的SCA算法。

Conclusion: 该ADMM框架为下一代多播系统提供了一个实用的工具，能够以较低计算复杂度获得接近全局最优的解。

Abstract: The growing demand for efficient delivery of common content to multiple user equipments (UEs) has motivated significant research in physical-layer multicasting. By exploiting the beamforming capabilities of massive MIMO, multicasting provides a spectrum-efficient solution that avoids unnecessary intra-group interference. A key challenge, however, is solving the max-min fair (MMF) and quality-of-service (QoS) multicast beamforming optimization problems, which are NP-hard due to the non-convex structure and the requirement for rank-1 solutions. Traditional approaches based on semidefinite relaxation (SDR) followed by randomization exhibit poor scalability with system size, while state-of-the-art successive convex approximation (SCA) methods only guarantee convergence to stationary points. In this paper, we propose an alternating direction method of multipliers (ADMM)-based framework for MMF and QoS multicast beamforming in cell-free massive MIMO networks. The algorithm leverages SDR but incorporates a novel iterative elimination strategy within the ADMM updates to efficiently obtain near-global optimal rank-1 beamforming solutions with reduced computational complexity compared to standard SDP solvers and randomization methods. Numerical evaluations demonstrate that the proposed ADMM-based procedure not only achieves superior spectral efficiency but also scales favorably with the number of antennas and UEs compared to state-of-the-art SCA-based algorithms, making it a practical tool for next-generation multicast systems.

</details>


### [51] [Enhanced GCD through ORBGRAND-AI: Exploiting Partial and Total Correlation in Noise](https://arxiv.org/abs/2511.07376)
*Jiewei Feng,Ken R. Duffy,Muriel Médard*

Main category: eess.SP

TL;DR: ORBGRAND-AI作为模式生成器集成到猜测码字解码(GCD)中，通过利用信道相关性改进解码性能。直接方法在减少查询模式数量的同时轻微降低BLER，而更精细的方法利用总相关性可额外获得约0.75 dB的BLER改进。


<details>
  <summary>Details</summary>
Motivation: 现有软判决解码器通常假设比特在信道中独立受影响，但ORBGRAND-AI已证明可以利用信道相关性提高解码精度。本研究旨在将ORBGRAND-AI作为模式生成器集成到GCD中，进一步改进解码性能。

Method: 首先采用直接方法将ORBGRAND-AI集成到GCD中，然后开发更精细的方法利用总相关性来优化解码过程。

Result: 直接方法在减少查询模式数量的同时轻微降低BLER；更精细的方法利用总相关性可额外获得约0.75 dB的BLER改进，同时保持减少的查询数量。

Conclusion: 将ORBGRAND-AI作为模式生成器集成到GCD中，特别是通过利用总相关性的精细方法，能够显著改进解码性能，在减少计算复杂度的同时获得更好的BLER性能。

Abstract: There have been significant advances in recent years in the development of forward error correction decoders that can decode codes of any structure, including practical realizations in synthesized circuits and taped out chips. While essentially all soft-decision decoders assume that bits have been impacted independently on the channel, for one of these new approaches it has been established that channel dependencies can be exploited to achieve superior decoding accuracy, resulting in Ordered Reliability Bits Guessing Random Additive Noise Decoding Approximate Independence (ORBGRAND-AI). Building on that capability, here we consider the integration of ORBGRAND-AI as a pattern generator for Guessing Codeword Decoding (GCD). We first establish that a direct approach delivers mildly degraded block error rate (BLER) but with reduced number of queried patterns when compared to ORBGRAND-AI. We then show that with a more nuanced approach it is possible to leverage total correlation to deliver an additional BLER improvement of around 0.75 dB while retaining reduced query numbers.

</details>
