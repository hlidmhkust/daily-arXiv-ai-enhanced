<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 7]
- [eess.SP](#eess.SP) [Total: 14]
- [cs.IT](#cs.IT) [Total: 5]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [USEANet: Ultrasound-Specific Edge-Aware Multi-Branch Network for Lightweight Medical Image Segmentation](https://arxiv.org/abs/2509.08860)
*Jingyi Gao,Di Wu,Baha lhnaini*

Main category: eess.IV

TL;DR: 提出了USEANet网络，针对超声图像分割的独特挑战，通过多分支处理和边缘感知机制，在保持超轻量级计算的同时实现了优异的性能表现


<details>
  <summary>Details</summary>
Motivation: 解决超声图像分割面临的斑点噪声、低对比度和模糊边界等独特挑战，同时满足临床部署对计算效率的高要求

Method: 基于超轻量级PVT-B0主干网络，采用超声特异性多分支处理、边缘感知注意力机制、分层特征聚合和超声感知解码器增强四项关键技术

Result: 在五个超声数据集上显著优于现有方法，仅使用3.64M参数和0.79G FLOPs，在BUSI数据集上达到67.01 IoU

Conclusion: USEANet在保持优异计算效率的同时实现了卓越的分割精度，适合实时临床应用

Abstract: Ultrasound image segmentation faces unique challenges including speckle
noise, low contrast, and ambiguous boundaries, while clinical deployment
demands computationally efficient models. We propose USEANet, an
ultrasound-specific edge-aware multi-branch network that achieves optimal
performance-efficiency balance through four key innovations: (1)
ultrasound-specific multi-branch processing with specialized modules for noise
reduction, edge enhancement, and contrast improvement; (2) edge-aware attention
mechanisms that focus on boundary information with minimal computational
overhead; (3) hierarchical feature aggregation with adaptive weight learning;
and (4) ultrasound-aware decoder enhancement for optimal segmentation
refinement. Built on an ultra-lightweight PVT-B0 backbone, USEANet
significantly outperforms existing methods across five ultrasound datasets
while using only 3.64M parameters and 0.79G FLOPs. Experimental results
demonstrate superior segmentation accuracy with 67.01 IoU on BUSI dataset,
representing substantial improvements over traditional approaches while
maintaining exceptional computational efficiency suitable for real-time
clinical applications. Code is available at
https://github.com/chouheiwa/USEANet.

</details>


### [2] [WarpPINN-fibers: improved cardiac strain estimation from cine-MR with physics-informed neural networks](https://arxiv.org/abs/2509.08872)
*Felipe Álvarez Barrientos,Tomás Banduc,Isabeau Sirven,Francisco Sahli Costabal*

Main category: eess.IV

TL;DR: WarpPINN-fibers是一个基于物理信息神经网络的框架，通过整合纤维信息来准确估计心脏运动和应变，改进了传统方法在纤维力学建模方面的不足。


<details>
  <summary>Details</summary>
Motivation: 心脏收缩运动受纤维分布强烈影响，传统应变分析方法缺乏纤维力学建模，限制了准确解释心脏功能的能力。

Method: 构建物理信息神经网络，损失函数包含三部分：数据相似性损失、近不可压缩性正则化和纤维拉伸惩罚项，通过合成纤维信息控制应变方向。

Result: 在合成幻影实验中改进原有模型并有效控制纤维拉伸，在15名健康志愿者的cine-MRI基准测试中，在标志点追踪和应变曲线预测方面优于其他方法。

Conclusion: 该方法能够通过准确的变形场实现更精确的心脏应变量化，且仅需MRI成像技术，无需更复杂的成像方法。

Abstract: The contractile motion of the heart is strongly determined by the
distribution of the fibers that constitute cardiac tissue. Strain analysis
informed with the orientation of fibers allows to describe several pathologies
that are typically associated with impaired mechanics of the myocardium, such
as cardiovascular disease. Several methods have been developed to estimate
strain-derived metrics from traditional imaging techniques. However, the
physical models underlying these methods do not include fiber mechanics,
restricting their capacity to accurately explain cardiac function. In this
work, we introduce WarpPINN-fibers, a physics-informed neural network framework
to accurately obtain cardiac motion and strains enhanced by fiber information.
We train our neural network to satisfy a hyper-elastic model and promote fiber
contraction with the goal to predict the deformation field of the heart from
cine magnetic resonance images. For this purpose, we build a loss function
composed of three terms: a data-similarity loss between the reference and the
warped template images, a regularizer enforcing near-incompressibility of
cardiac tissue and a fiber-stretch penalization that controls strain in the
direction of synthetically produced fibers. We show that our neural network
improves the former WarpPINN model and effectively controls fiber stretch in a
synthetic phantom experiment. Then, we demonstrate that WarpPINN-fibers
outperforms alternative methodologies in landmark-tracking and strain curve
prediction for a cine-MRI benchmark with a cohort of 15 healthy volunteers. We
expect that our method will enable a more precise quantification of cardiac
strains through accurate deformation fields that are consistent with fiber
physiology, without requiring imaging techniques more sophisticated than MRI.

</details>


### [3] [Generalized User-Oriented Image Semantic Coding Empowered by Large Vision-Language Model](https://arxiv.org/abs/2509.08913)
*Sin-Yu Huang,Vincent W. S. Wong*

Main category: eess.IV

TL;DR: 用户导向的图像语义编码框架，通过文本查询识别用户意图，利用CLIP模型提取相关特征，并使用LLaVA模型评估重建图像与用户查询的相关性，在未见对象上实现更好的结果。


<details>
  <summary>Details</summary>
Motivation: 解决图像语义通信中用户关注特定区域的需求，并涉及到真实应用中可能遇到训练集外图像的泛化问题。

Method: 提出UO-ISC框架，用户通过文本查询指明意图，发送端使用CLIP模型提取与查询相关的图像特征，接收端重建图像，并使用LLaVA模型计算用户意图相关性损失。

Result: 在未见对象上进行零样本推理时，该框架在答案匹配率方面超过了最先进的查询敏感图像语义编码方法。

Conclusion: 该研究成功将用户意图整合到语义编码中，通过大型视觉-语言模型提升了泛化能力，为面向用户需求的语义通信提供了有效解决方案。

Abstract: Semantic communication has shown outstanding performance in preserving the
overall source information in wireless transmission. For semantically rich
content such as images, human users are often interested in specific regions
depending on their intent. Moreover, recent semantic coding models are mostly
trained on specific datasets. However, real-world applications may involve
images out of the distribution of training dataset, which makes generalization
a crucial but largely unexplored problem. To incorporate user's intent into
semantic coding, in this paper, we propose a generalized user-oriented image
semantic coding (UO-ISC) framework, where the user provides a text query
indicating its intent. The transmitter extracts features from the source image
which are relevant to the user's query. The receiver reconstructs an image
based on those features. To enhance the generalization ability, we integrate
contrastive language image pre-training (CLIP) model, which is a pretrained
large vision-language model (VLM), into our proposed UO-ISC framework. To
evaluate the relevance between the reconstructed image and the user's query, we
introduce the user-intent relevance loss, which is computed by using a
pretrained large VLM, large language-and-vision assistant (LLaVA) model. When
performing zero-shot inference on unseen objects, simulation results show that
the proposed UO-ISC framework outperforms the state-of-the-art query-aware
image semantic coding in terms of the answer match rate.

</details>


### [4] [Dynamic Structural Recovery Parameters Enhance Prediction of Visual Outcomes After Macular Hole Surgery](https://arxiv.org/abs/2509.09227)
*Yinzheng Zhao,Zhihao Zhao,Rundong Jiang,Louisa Sackewitz,Quanmin Liang,Mathias Maier,Daniel Zapp,Peter Charbel Issa,Mohammad Ali Nasseri*

Main category: eess.IV

TL;DR: 本文提出了动态结构参数并将其集成到多模态深度学习框架中，用于预测id性全层黄斑潮破裂病人的手术后视力恢复情况，得到了更高的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高对id性全层黄斑潮破裂病人手术后视力恢复预测的准确性，需要提出新的动态结构参数并将其集成到多模态深度学习框架中。

Method: 利用公开的纵向OCT数据集，通过阶段特异分割模型和自动化流程提取各种特征，构建包含动态参数的逻辑回归模型和多模态深度学习模型。

Result: 分割模型准确性高(均值Dice>0.89)，动态恢复率提升了逻辑回归AUC，多模态DL模型表现更优，AUC最高提升0.12。

Conclusion: 集成动态参数的多模态DL模型显著提高了预测准确性，是一种有前景的临床决策支持工具。

Abstract: Purpose: To introduce novel dynamic structural parameters and evaluate their
integration within a multimodal deep learning (DL) framework for predicting
postoperative visual recovery in idiopathic full-thickness macular hole (iFTMH)
patients. Methods: We utilized a publicly available longitudinal OCT dataset at
five stages (preoperative, 2 weeks, 3 months, 6 months, and 12 months). A stage
specific segmentation model delineated related structures, and an automated
pipeline extracted quantitative, composite, qualitative, and dynamic features.
Binary logistic regression models, constructed with and without dynamic
parameters, assessed their incremental predictive value for best-corrected
visual acuity (BCVA). A multimodal DL model combining clinical variables,
OCT-derived features, and raw OCT images was developed and benchmarked against
regression models. Results: The segmentation model achieved high accuracy
across all timepoints (mean Dice > 0.89). Univariate and multivariate analyses
identified base diameter, ellipsoid zone integrity, and macular hole area as
significant BCVA predictors (P < 0.05). Incorporating dynamic recovery rates
consistently improved logistic regression AUC, especially at the 3-month
follow-up. The multimodal DL model outperformed logistic regression, yielding
higher AUCs and overall accuracy at each stage. The difference is as high as
0.12, demonstrating the complementary value of raw image volume and dynamic
parameters. Conclusions: Integrating dynamic parameters into the multimodal DL
model significantly enhances the accuracy of predictions. This fully automated
process therefore represents a promising clinical decision support tool for
personalized postoperative management in macular hole surgery.

</details>


### [5] [Virtual staining for 3D X-ray histology of bone implants](https://arxiv.org/abs/2509.09235)
*Sarah C. Irvine,Christian Lucas,Diana Krüger,Bianca Guedert,Julian Moosmann,Berit Zeller-Plumhoff*

Main category: eess.IV

TL;DR: 本研究将虚拟染色技术扩展到X射线领域，使用改进的CycleGAN网络从同步辐射微CT扫描生成人工染色切片，实现了3D X射线组织学的虚拟染色。


<details>
  <summary>Details</summary>
Motivation: 传统2D组织学需要物理切片和化学染色，而3D X射线组织学虽然无创但缺乏生化特异性。虚拟染色技术可以从无标记图像模拟染色外观，但此前主要应用于光学图像领域。

Method: 使用50多对共配准的微CT和甲苯胺蓝染色组织学图像对，训练针对有限配对数据优化的改进CycleGAN网络。采用像素级监督和灰度一致性约束，通过补丁训练和实时数据增强。

Result: 该方法在SSIM、PSNR和LPIPS指标上均优于Pix2Pix和标准CycleGAN基线，能够生成组织学真实的彩色输出并保持高分辨率结构细节。模型可应用于完整CT体积生成虚拟染色的3D数据集。

Conclusion: 该工作首次将虚拟染色引入3D X射线成像，为生物医学研究提供了可扩展的、化学信息丰富的无标记组织表征途径，但需要更多训练数据和进一步优化以改善植入物降解层等特征的描绘。

Abstract: Three-dimensional X-ray histology techniques offer a non-invasive alternative
to conventional 2D histology, enabling volumetric imaging of biological tissues
without the need for physical sectioning or chemical staining. However, the
inherent greyscale image contrast of X-ray tomography limits its biochemical
specificity compared to traditional histological stains. Within digital
pathology, deep learning-based virtual staining has demonstrated utility in
simulating stained appearances from label-free optical images. In this study,
we extend virtual staining to the X-ray domain by applying cross-modality image
translation to generate artificially stained slices from
synchrotron-radiation-based micro-CT scans. Using over 50 co-registered image
pairs of micro-CT and toluidine blue-stained histology from bone-implant
samples, we trained a modified CycleGAN network tailored for limited paired
data. Whole slide histology images were downsampled to match the voxel size of
the CT data, with on-the-fly data augmentation for patch-based training. The
model incorporates pixelwise supervision and greyscale consistency terms,
producing histologically realistic colour outputs while preserving
high-resolution structural detail. Our method outperformed Pix2Pix and standard
CycleGAN baselines across SSIM, PSNR, and LPIPS metrics. Once trained, the
model can be applied to full CT volumes to generate virtually stained 3D
datasets, enhancing interpretability without additional sample preparation.
While features such as new bone formation were able to be reproduced, some
variability in the depiction of implant degradation layers highlights the need
for further training data and refinement. This work introduces virtual staining
to 3D X-ray imaging and offers a scalable route for chemically informative,
label-free tissue characterisation in biomedical research.

</details>


### [6] [A novel method and dataset for depth-guided image deblurring from smartphone Lidar](https://arxiv.org/abs/2509.09241)
*Antonio Montanaro,Diego Valsesia*

Main category: eess.IV

TL;DR: 提出了一种基于去噪扩散模型的图像去模糊方法，利用LiDAR深度引导且无需配对训练数据，同时创建了首个包含真实模糊图像、LiDAR深度图和清晰真值图像的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏包含真实模糊图像和配对移动LiDAR深度图的数据集，同时也缺乏无需大量配对训练数据就能利用深度引导对真实图像进行去模糊的盲零样本方法。

Method: 基于去噪扩散模型的图像去模糊方法，能够利用LiDAR深度引导，且不需要训练具有配对LiDAR深度图的数据。

Result: 在新数据集上的实验结果表明，LiDAR引导是有效的，所提出的方法在感知质量方面优于最先进的去模糊方法。

Conclusion: 该方法成功解决了LiDAR引导去模糊的数据稀缺问题，证明了深度信息在图像去模糊中的有效性，并为该领域的研究提供了首个真实数据集。

Abstract: Modern smartphones are equipped with Lidar sensors providing depth-sensing
capabilities. Recent works have shown that this complementary sensor allows to
improve various tasks in image processing, including deblurring. However, there
is a current lack of datasets with realistic blurred images and paired mobile
Lidar depth maps to further study the topic. At the same time, there is also a
lack of blind zero-shot methods that can deblur a real image using the depth
guidance without requiring extensive training sets of paired data. In this
paper, we propose an image deblurring method based on denoising diffusion
models that can leverage the Lidar depth guidance and does not require training
data with paired Lidar depth maps. We also present the first dataset with real
blurred images with corresponding Lidar depth maps and sharp ground truth
images, acquired with an Apple iPhone 15 Pro, for the purpose of studying
Lidar-guided deblurring. Experimental results on this novel dataset show that
Lidar guidance is effective and the proposed method outperforms
state-of-the-art deblurring methods in terms of perceptual quality.

</details>


### [7] [In-Loop Filtering Using Learned Look-Up Tables for Video Coding](https://arxiv.org/abs/2509.09494)
*Zhuoyuan Li,Jiacheng Li,Yao Li,Jialin Li,Li Li,Dong Liu,Feng Wu*

Main category: eess.IV

TL;DR: 通过将深度网络过滤结果预先计算并存储在查找表中，提出了一种高效的循环过滤方案，在保持编码效果的同时大幅降低计算复杂度和存储成本。


<details>
  <summary>Details</summary>
Motivation: 神经网络基于循环过滤方案虽然编码效果优异，但带来较高的计算和时间复杂度，或需要专用硬件支持，限制了其普遍应用。

Method: 训练一个参考范围限制的DNN过滤器，将所有可能输入的过滤结果预先计算并存储到LUT中。过滤过程通过查找表和插值完成，避免重载的DNN推理计算。提出多种过滤LUT协作机制、自定义索引机制、跨分量索引机制以及LUT压缩方案。

Result: 在VVC参考软件中实现，在AI和RA配置下平均实现了码率0.82%/2.97%/1.63%和0.85%/4.11%/2.06%的减少。相比DNN基于方案，时间复杂度和存储成本大幅降低。

Conclusion: LUT-ILF++框架提供了一种高效实用的循环过滤解决方案，在保持良好编码效果的同时大幅降低了计算复杂度，为下一代视频编码标准提供了实用的过滤技术选择。

Abstract: In-loop filtering (ILF) is a key technology in video coding standards to
reduce artifacts and enhance visual quality. Recently, neural network-based ILF
schemes have achieved remarkable coding gains, emerging as a powerful candidate
for next-generation video coding standards. However, the use of deep neural
networks (DNN) brings significant computational and time complexity or high
demands for dedicated hardware, making it challenging for general use. To
address this limitation, we study a practical ILF solution by adopting look-up
tables (LUTs). After training a DNN with a restricted reference range for ILF,
all possible inputs are traversed, and the output values of the DNN are cached
into LUTs. During the coding process, the filtering process is performed by
simply retrieving the filtered pixel through locating the input pixels and
interpolating between the cached values, instead of relying on heavy inference
computations. In this paper, we propose a universal LUT-based ILF framework,
termed LUT-ILF++. First, we introduce the cooperation of multiple kinds of
filtering LUTs and propose a series of customized indexing mechanisms to enable
better filtering reference perception with limited storage consumption. Second,
we propose the cross-component indexing mechanism to enable the filtering of
different color components jointly. Third, in order to make our solution
practical for coding uses, we propose the LUT compaction scheme to enable the
LUT pruning, achieving a lower storage cost of the entire solution. The
proposed framework is implemented in the VVC reference software. Experimental
results show that the proposed framework achieves on average 0.82%/2.97%/1.63%
and 0.85%/4.11%/2.06% bitrate reduction for common test sequences, under the AI
and RA configurations, respectively. Compared to DNN-based solutions, our
proposed solution has much lower time complexity and storage cost.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [8] [A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals](https://arxiv.org/abs/2509.08830)
*Seong-A Park,Jong-Eui Chae,Sungdong Kim,Hyung-Chul Lee,Hyun-Lim Yang*

Main category: eess.SP

TL;DR: SNUPHY-M模型通过自监督学习同时分析ECG、PPG和ABP三种生理信号，提取心脏周期的电学、压力和流体特征，在血流动力学监测任务中显著优于监督学习和其他自监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 临床需要监测多种生理信号来管理患者预后，但现有研究多集中于单一信号分析，缺乏适用于实际临床复杂场景的综合分析方法。

Method: 基于自监督学习的掩码表示学习方法，通过恢复三种被掩码的生理信号（ECG、PPG、ABP）来提取反映心脏周期多种物理特征的生理特征。

Result: 在低血压、每搏输出量、收缩压、舒张压和年龄预测等临床下游任务中，SNUPHY-M显著优于监督学习或其他自监督学习模型，特别是在使用无创信号的预测任务中表现突出。

Conclusion: SNUPHY-M是首个将多模态自监督学习应用于心血管分析（涉及ECG、PPG和ABP信号）的模型，能有效支持临床决策，实现精确诊断，对无创早期诊断和血流动力学管理有重要贡献。

Abstract: In clinical settings, monitoring hemodynamics is crucial for managing patient
prognosis, necessitating the integrated analysis of multiple physiological
signals. While recent research has analyzed single signals such as
electrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a
proposal for an approach that encompasses the complex signal analysis required
in actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul
National University hospital PHYsiological signal Masked representation
learning) model extracts physiological features reflecting the electrical,
pressure, and fluid characteristics of the cardiac cycle in the process of
restoring three masked physiological signals based on self-supervised learning
(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing
multiple physical characteristics, the model can extract more enriched features
only using non-invasive signals. We evaluated the model's performance in
clinical downstream tasks such as hypotension, stroke volume, systolic blood
pressure, diastolic blood pressure, and age prediction. Our results showed that
the SNUPHY-M significantly outperformed supervised or SSL models, especially in
prediction tasks using non-invasive signals. To the best of our knowledge,
SNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis
involving ECG, PPG, and ABP signals. This approach effectively supports
clinical decision-making and enables precise diagnostics, contributing
significantly to the early diagnosis and management of hemodynamics without
invasiveness.

</details>


### [9] [Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities](https://arxiv.org/abs/2509.08950)
*Jarvis Haupt,Qin Lu,Yanning Shen,Jia Chen,Yue Dong,Dan McCreary,Mehmet Akçakaya,Georgios B. Giannakis*

Main category: eess.SP

TL;DR: 这篇论文探讨AI在信号处理教育中的应用，重点关注技术限制解决和实践应用，提出了智能教科书的开发概念。


<details>
  <summary>Details</summary>
Motivation: 尽管AI技术取得了重大进展，但还面临着如何公平负责使用以改善全球人类生活的挑战。教育领域是一个有前景的应用方向。

Method: 从两个相互关联的角度出发：识别和解决技术限制，以及在实践中应用AI工具改善教育体验。提供了核心技术问题的入门指南。

Result: 通过开发沉浸式、结构化和可靠的"智能教科书"来展示公平性、包容性、透明性、可解释性和可信赖性等考虑因素。

Conclusion: 该文章为希望推进AI在工程教育中作用的研究人员和教育工作者提供了资源和指南。

Abstract: Powerful artificial intelligence (AI) tools that have emerged in recent years
-- including large language models, automated coding assistants, and advanced
image and speech generation technologies -- are the result of monumental human
achievements. These breakthroughs reflect mastery across multiple technical
disciplines and the resolution of significant technological challenges.
However, some of the most profound challenges may still lie ahead. These
challenges are not purely technical but pertain to the fair and responsible use
of AI in ways that genuinely improve the global human condition. This article
explores one promising application aligned with that vision: the use of AI
tools to facilitate and enhance education, with a specific focus on signal
processing (SP). It presents two interrelated perspectives: identifying and
addressing technical limitations, and applying AI tools in practice to improve
educational experiences. Primers are provided on several core technical issues
that arise when using AI in educational settings, including how to ensure
fairness and inclusivity, handle hallucinated outputs, and achieve efficient
use of resources. These and other considerations -- such as transparency,
explainability, and trustworthiness -- are illustrated through the development
of an immersive, structured, and reliable "smart textbook." The article serves
as a resource for researchers and educators seeking to advance AI's role in
engineering education.

</details>


### [10] [Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography](https://arxiv.org/abs/2509.08973)
*Harshit Agrawal,Ari Hietanen,Simo Särkkä*

Main category: eess.SP

TL;DR: 本研究通过在不同分辨率下应用网络并基于速度和准确性选择最优分辨率，解决了CBCT散射伪影校正中深度学习网络内存占用大的问题，实现了78倍的FLOPs减少和显著的推理时间与GPU内存优化。


<details>
  <summary>Details</summary>
Motivation: 锥束CT扫描中的散射伪影严重降低图像质量，虽然基于深度学习的方法在估计散射方面显示出潜力，但由于网络内存占用大，在移动CBCT系统或边缘设备上的部署仍然受限。

Method: 首先在六个分辨率下比较四种插值方法检查CBCT散射信号的下采样-上采样重建误差，然后在五个图像分辨率上训练最新的SOTA方法，评估FLOPs、推理时间和GPU内存需求的减少。

Result: 减少输入大小和网络参数实现了78倍的FLOPs减少，同时保持可比的MAPE（3.85% vs 4.42%）和MSE（1.34×10⁻² vs 2.01×10⁻²）性能，推理时间和GPU内存使用分别减少16倍和12倍。

Conclusion: 研究强调了降采样在基于深度学习的散射估计中被低估的作用，该方法实现的FLOPs和GPU内存需求大幅减少使得在资源受限环境（如移动CBCT和边缘设备）中进行散射校正成为可能。

Abstract: Purpose: Scatter artifacts drastically degrade the image quality of cone-beam
computed tomography (CBCT) scans. Although deep learning-based methods show
promise in estimating scatter from CBCT measurements, their deployment in
mobile CBCT systems or edge devices is still limited due to the large memory
footprint of the networks. This study addresses the issue by applying networks
at varying resolutions and suggesting an optimal one, based on speed and
accuracy.
  Methods: First, the reconstruction error in down-up sampling of CBCT scatter
signal was examined at six resolutions by comparing four interpolation methods.
Next, a recent state-of-the-art method was trained across five image
resolutions and evaluated for the reductions in floating-point operations
(FLOPs), inference times, and GPU memory requirements.
  Results: Reducing the input size and network parameters achieved a 78-fold
reduction in FLOPs compared to the baseline method, while maintaining comarable
performance in terms of mean-absolute-percentage-error (MAPE) and
mean-square-error (MSE). Specifically, the MAPE decreased to 3.85% compared to
4.42%, and the MSE decreased to 1.34 \times 10^{-2} compared to 2.01 \times
10^{-2}. Inference time and GPU memory usage were reduced by factors of 16 and
12, respectively. Further experiments comparing scatter-corrected
reconstructions on a large, simulated dataset and real CBCT scans from water
and Sedentex CT phantoms clearly demonstrated the robustness of our method.
  Conclusion: This study highlights the underappreciated role of downsampling
in deep learning-based scatter estimation. The substantial reduction in FLOPs
and GPU memory requirements achieved by our method enables scatter correction
in resource-constrained environments, such as mobile CBCT and edge devices.

</details>


### [11] [6G Resilience -- White Paper](https://arxiv.org/abs/2509.09005)
*Hirley Alves,Nurul H. Mahmood,Onel L. A. López,Sumudu Samarakoon,Seppo Yrjölä,Matti Latva-Aho,Markku Juntti,Ari Pouttu,Armin Dekorsy,Arthur Sousa de Sena,Aydin Sezgin,Bho Matthiesen,Chafika Benzaid,Chathuranga Weeraddana,David Hutchison,Dileepa Marasinghe,Doganalp Ergenc,Eduard Jorswieck,Erkki Harjula,Falko Dressler,Harri Saarnisaari,Italo Atzeni,Jaap Van De Beek,Jacek Rak,Konstantin Mikhaylov,Lauri Loven,Madhusanka Liyanage,Marcos Katz,Marja Matinmikko-Blue,Mehdi Rasti,Mika Ylianttila Nhan Nguyen,Pawani Porambage,Petar Popovski,Petri Ahokangas,Premanandana Rajatheva,Robert-Jeron Reifert,Tharaka Hewa,Tommy Svensson*

Main category: eess.SP

TL;DR: 6G应将稳健性作为核心设计目标，通过3R框架（可靠性、稳健性、恢复力）和关键技术提升网络在中断情况下的适应能力。


<details>
  <summary>Details</summary>
Motivation: 6G需要在长期、复杂中断环境中保持稳定运行，并从效果优先转向可持续性认知。

Method: 提出3R框架，重点关注边缘原生设计、开放接口、编程能力，以及AI控制循环、零信任安全和网络优先级技术。

Result: 形成了包含九个商业模式组的技术经济框架，以及相应的管理和标准化建议。

Conclusion: 本白皮书为6G稳健性研究提供了基础框架，并将激励各界参与者共同推动相关发展。

Abstract: 6G must be designed to withstand, adapt to, and evolve amid prolonged,
complex disruptions. Mobile networks' shift from efficiency-first to
sustainability-aware has motivated this white paper to assert that resilience
is a primary design goal, alongside sustainability and efficiency, encompassing
technology, architecture, and economics. We promote resilience by analysing
dependencies between mobile networks and other critical systems, such as
energy, transport, and emergency services, and illustrate how cascading
failures spread through infrastructures. We formalise resilience using the 3R
framework: reliability, robustness, resilience. Subsequently, we translate this
into measurable capabilities: graceful degradation, situational awareness,
rapid reconfiguration, and learning-driven improvement and recovery.
  Architecturally, we promote edge-native and locality-aware designs, open
interfaces, and programmability to enable islanded operations, fallback modes,
and multi-layer diversity (radio, compute, energy, timing). Key enablers
include AI-native control loops with verifiable behaviour, zero-trust security
rooted in hardware and supply-chain integrity, and networking techniques that
prioritise critical traffic, time-sensitive flows, and inter-domain
coordination.
  Resilience also has a techno-economic aspect: open platforms and high-quality
complementors generate ecosystem externalities that enhance resilience while
opening new markets. We identify nine business-model groups and several
patterns aligned with the 3R objectives, and we outline governance and
standardisation. This white paper serves as an initial step and catalyst for 6G
resilience. It aims to inspire researchers, professionals, government
officials, and the public, providing them with the essential components to
understand and shape the development of 6G resilience.

</details>


### [12] [Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data](https://arxiv.org/abs/2509.09018)
*Xueyi Wang,C. J. C.,Lamoth,Elisabeth Wilhelm*

Main category: eess.SP

TL;DR: 提出了AdaST-Sleep模型，结合CNN和RNN进行睡眠评分预测，通过领域分类器实现跨用户泛化，在多个时间窗口设置下优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 睡眠预测可以帮助个人和医疗提供者提前预知并主动处理影响良好休息的因素，从而改善身心健康。

Method: 使用卷积层捕捉多特征间的空间交互，循环神经网络层处理长期时间序列健康数据，集成领域分类器实现跨不同用户的泛化。

Result: 在5种输入窗口和5种预测窗口设置下均优于4个基线模型，最低RMSE为0.282（7天输入窗口+1天预测窗口），即使在多日预测中也保持强劲性能。

Conclusion: 该框架为使用商业可穿戴设备稀疏数据和领域自适应技术提供了鲁棒且适应性强的个性化睡眠预测解决方案。

Abstract: A sleep forecast allows individuals and healthcare providers to anticipate
and proactively address factors influencing restful rest, ultimately improving
mental and physical well-being. This work presents an adaptive spatial and
temporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model
combines convolutional layers to capture spatial feature interactions between
multiple features and recurrent neural network layers to handle longer-term
temporal health-related data. A domain classifier is further integrated to
generalize across different subjects. We conducted several experiments using
five input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes
(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline
models, achieving its lowest RMSE (0.282) with a seven-day input window and a
one-day predicting window. Moreover, the method maintained strong performance
even when forecasting multiple days into the future, demonstrating its
versatility for real-world applications. Visual comparisons reveal that the
model accurately tracks both the overall sleep score level and daily
fluctuations. These findings prove that the proposed framework provides a
robust and adaptable solution for personalized sleep forecasting using sparse
data from commercial wearable devices and domain adaptation techniques.

</details>


### [13] [Improving the Elevational Focusing of Fast Orthogonal Row-Column Electronic Scanning (FORCES) Ultrasound Imaging using Retrospective Transmit Beamforming (RTB)](https://arxiv.org/abs/2509.09056)
*Michael Caulfield,Randy Palamar,Darren Dahunsi,Mohammad Rahim Sobhani,Negar Majidi,Roger Zemp*

Main category: eess.SP

TL;DR: 基于行列数组(RCA)的FORCES成像方案存在载波方向焦点外焦聚性能差的问题，本研究通过引入载波方向回顾性发射波束成型(RTB)技术来改善载波方向的全局焦聚性能


<details>
  <summary>Details</summary>
Motivation: 解决FORCES成像方案因固定载波焦点和大发射孔径导致的载波方向焦点外焦聚性能差的问题

Method: 在FORCES和uFORCES方案中应用载波方向回顾性发射波束成型(RTB)技术，通过纳米线幻子和囊性幻子实验评估性能

Result: RTB技术显著改善了FORCES和uFORCES在焦点外区域的载波方向焦聚性能，在焦点处性能保持相当或有所提升，通过半高宽(FWHM)和对比度噪声比(CNR)指标进行了量化验证

Conclusion: 载波方向RTB技术有效地提升了FORCES成像方案的载波焦聚性能，实现了全局载波焦聚，为行列数组体积成像提供了更优的解决方案

Abstract: Recent developments in Row Column Arrays (RCAs) have presented promising
options for volumetric imaging without the need for the excessive channel
counts of fully wired 2D-arrays. Bias programmable RCAs, also known as Top
Orthogonal to Bottom Electrode (TOBE) Arrays, show further promise in that
imaging schemes, such as Fast Orthogonal Row-Column Electronic Scanning
(FORCES) allow for full transmit and receive focusing everywhere in the image
plane. However, due to its fixed elevational focus and large transmit aperture,
FORCES experiences poor elevational focusing away from the focal point. In this
study we present a modification to the FORCES imaging scheme by applying
Retrospective Transmit Beamforming (RTB) in the elevational direction to allow
for elevational transmit focusing everywhere in the imaging plane. We evaluate
FORCES and uFORCES methods, with and without RTB applied, when imaging both a
cyst and wire phantom. With experiment we show improved elevational focusing
capabilities away from the focal point when RTB is applied to both FORCES and
uFORCES. At the focal point, performance with RTB remains comparable or
improved relative to standard FORCES. This is quantified by the measurement of
Full Width Half Max when imaging the wire phantom, and by the generalized
Contrast to Noise Ratio when imaging the tubular cyst phantom. We also
demonstrate the volumetric imaging capabilities of FORCES RTB with the wire
phantom.

</details>


### [14] [Signed Graph Learning with Hidden Nodes](https://arxiv.org/abs/2509.09120)
*Rong Ye,Xue-Qin Jiang,Hui Feng,Jian Wang,Runhe Qiu*

Main category: eess.SP

TL;DR: 提出了一种考虑隐藏节点的符号图学习方法SGL-HNCS，通过列稀疏正则化约束优化问题来重构符号图拉普拉斯矩阵


<details>
  <summary>Details</summary>
Motivation: 现有符号图学习通常假设所有节点都可见，但在实际应用中往往只有部分节点可观测，其余节点保持隐藏状态，需要解决这一挑战

Method: 基于图信号在符号图上的平滑性假设，将拓扑推断构建为带列稀疏正则化的约束优化问题，使用定制的块坐标下降(BCD)方法求解

Result: 在合成数据和真实数据上的实验结果表明了所提SGL-HNCS方法的有效性

Conclusion: 该方法能够有效处理存在隐藏节点的符号图学习问题，为实际应用提供了可行的解决方案

Abstract: Signed graphs, which are characterized by both positive and negative edge
weights, have recently attracted significant attention in the field of graph
signal processing (GSP). Existing works on signed graph learning typically
assume that all graph nodes are available. However, in some specific
applications, only a subset of nodes can be observed while the remaining nodes
stay hidden. To address this challenge, we propose a novel method for
identifying signed graph that accounts for hidden nodes, termed \textit{signed
graph learning with hidden nodes under column-sparsity regularization}
(SGL-HNCS). Our method is based on the assumption that graph signals are smooth
over signed graphs, i.e., signal values of two nodes connected by positive
(negative) edges are similar (dissimilar). Rooted in this prior assumption, the
topology inference of a signed graph is formulated as a constrained
optimization problem with column-sparsity regularization, where the goal is to
reconstruct the signed graph Laplacian matrix without disregarding the
influence of hidden nodes. We solve the constrained optimization problem using
a tailored block coordinate descent (BCD) approach. Experimental results using
synthetic data and real-world data demonstrate the efficiency of the proposed
SGL-HNCS method.

</details>


### [15] [Sequential Spectral Clustering of Data Sequences](https://arxiv.org/abs/2509.09144)
*G Dhinesh Chandran,Kota Srinivas Reddy,Srikrishna Bhashyam*

Main category: eess.SP

TL;DR: 本文研究数据序列的非参数分组问题，提出了两种新的序列谱聚类算法（SEQ-SPEC和IA-SEQ-SPEC），在保证有限时间停止和指数一致性的同时，实现了更高效的样本量管理和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决在真实分布未知的情况下，通过观察最小样本量来估计数据序列的聚类，以获得给定错误概率下的最优聚类结果。

Method: 提出序列谱聚类算法（SEQ-SPEC）和增量近似序列谱聚类算法（IA-SEQ-SPEC），通过序列采样方式动态地收集样本，直到达到预设的聚类精度要求。

Result: 算法几乎必然在有限时间内停止，并具有指数一致性。模拟实验显示，新算法在合成和实际数据集上都表现更优于固定样本量谱聚类和其他序列聚类算法。IA-SEQ-SPEC计算效率更高且性能接近SEQ-SPEC。

Conclusion: 这是首个在序列框架下进行数据序列谱聚类的研究，提出的算法能够在保证算法性能的同时实现更高效的样本量利用，为序列聚类领域提供了新的解决方案。

Abstract: We study the problem of nonparametric clustering of data sequences, where
each data sequence comprises i.i.d. samples generated from an unknown
distribution. The true clusters are the clusters obtained using the Spectral
clustering algorithm (SPEC) on the pairwise distance between the true
distributions corresponding to the data sequences. Since the true distributions
are unknown, the objective is to estimate the clusters by observing the minimum
number of samples from the data sequences for a given error probability. To
solve this problem, we propose the Sequential Spectral clustering algorithm
(SEQ-SPEC), and show that it stops in finite time almost surely and is
exponentially consistent. We also propose a computationally more efficient
algorithm called the Incremental Approximate Sequential Spectral clustering
algorithm (IA-SEQ-SPEC). Through simulations, we show that both our proposed
algorithms perform better than the fixed sample size SPEC, the Sequential
$K$-Medoids clustering algorithm (SEQ-KMED) and the Sequential Single Linkage
clustering algorithm (SEQ-SLINK). The IA-SEQ-SPEC, while being computationally
efficient, performs close to SEQ-SPEC on both synthetic and real-world
datasets. To the best of our knowledge, this is the first work on spectral
clustering of data sequences under a sequential framework.

</details>


### [16] [JFRFFNet: A Data-Model Co-Driven Graph Signal Denoising Model with Partial Prior Information](https://arxiv.org/abs/2509.09147)
*Ziqi Yan,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出JFRFFNet方法，将联合时-顶点分数傅里叶变换域的维纳滤波模型嵌入神经网络，通过数据驱动方式更新变换阶数对和滤波器系数，仅需部分先验信息即可有效去噪。


<details>
  <summary>Details</summary>
Motivation: 传统滤波方法需要完整的图信号先验信息，要么通过网格搜索确定变换阶数对和计算滤波器系数，要么使用梯度下降策略优化，限制了实际应用。

Method: 采用数据-模型协同驱动的方法，将JFRFT域的维纳滤波模型嵌入神经网络架构，通过数据驱动方式学习最优的变换阶数对和滤波器系数。

Result: 实验表明，JFRFFNet在输出信噪比方面相比现有最先进方法有显著提升。

Conclusion: JFRFFNet方法成功解决了传统方法需要完整先验信息的限制，仅需部分先验信息就能实现有效的时变图信号去噪。

Abstract: Wiener filtering in the joint time-vertex fractional Fourier transform
(JFRFT) domain has shown high effectiveness in denoising time-varying graph
signals. Traditional filtering models use grid search to determine the
transform-order pair and compute filter coefficients, while learnable ones
employ gradient-descent strategies to optimize them; both require complete
prior information of graph signals. To overcome this shortcoming, this letter
proposes a data-model co-driven denoising approach, termed neural-network-aided
joint time-vertex fractional Fourier filtering (JFRFFNet), which embeds the
JFRFT-domain Wiener filter model into a neural network and updates the
transform-order pair and filter coefficients through a data-driven approach.
This design enables effective denoising using only partial prior information.
Experiments demonstrate that JFRFFNet achieves significant improvements in
output signal-to-noise ratio compared with some state-of-the-art methods.

</details>


### [17] [On Sampling of Multiple Correlated Stochastic Signals](https://arxiv.org/abs/2509.09225)
*Lin Jin,Hang Sheng,Hui Feng,Bo Hu*

Main category: eess.SP

TL;DR: 该论文提出了一种利用多通道信号统计相关性的高效采样方法，通过建模为少量不相关潜在源的线性组合，达到了理论最小采样密度。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法独立处理每个通道导致数据冗余，多通道随机信号存在固有统计相关性，需要利用这种相关性实现高效采样。

Method: 将相关通道建模为少量不相关宽平稳潜在源的线性组合，通过潜在源的频谱分割，然后进行时空采样和插值，构建多波段采样方案。

Result: 实验证明该方法在理论采样密度下实现了近乎无损的重建，验证了其效率。

Conclusion: 提出的多波段采样方案达到了理论最小采样密度，有效利用了多通道信号的相关性，实现了高效采样。

Abstract: Multiple stochastic signals possess inherent statistical correlations, yet
conventional sampling methods that process each channel independently result in
data redundancy. To leverage this correlation for efficient sampling, we model
correlated channels as a linear combination of a smaller set of uncorrelated,
wide-sense stationary latent sources. We establish a theoretical lower bound on
the total sampling density for zero mean-square error reconstruction, proving
it equals the ratio of the joint spectral bandwidth of latent sources to the
number of correlated signal channels. We then develop a constructive multi-band
sampling scheme that attains this bound. The proposed method operates via
spectral partitioning of the latent sources, followed by spatio-temporal
sampling and interpolation. Experiments on synthetic and real datasets confirm
that our scheme achieves near-lossless reconstruction precisely at the
theoretical sampling density, validating its efficiency.

</details>


### [18] [Improved Riemannian potato field: an Automatic Artifact Rejection Method for EEG](https://arxiv.org/abs/2509.09264)
*Davoud Hajhassani,Quentin Barthélemy,Jérémie Mattout,Marco Congedo*

Main category: eess.SP

TL;DR: iRPF是一种快速全自动的EEG信号伪影去除方法，在多个指标上显著优于现有技术，处理速度快，适合大规模EEG数据处理和实时应用。


<details>
  <summary>Details</summary>
Motivation: EEG信号中的伪影会严重影响数据质量，现有方法依赖人工超参数调优、对异常值敏感且计算成本高，需要开发自动化解决方案。

Method: 改进的黎曼土豆场(iRPF)方法，是一种基于黎曼几何的快速全自动伪影去除技术。

Result: 在226个EEG记录上测试，iRPF相比其他方法在召回率提升22%，特异性提升102%，精确度提升54%，F1分数提升24%，处理速度达到每epoch 8毫秒。

Conclusion: iRPF为脑机接口和临床神经影像应用提供了强大、数据驱动的伪影去除解决方案，具有显著性能和效率优势。

Abstract: Electroencephalography (EEG) signal cleaning has long been a critical
challenge in the research community. The presence of artifacts can
significantly degrade EEG data quality, complicating analysis and potentially
leading to erroneous interpretations. While various artifact rejection methods
have been proposed, the gold standard remains manual visual inspection by human
experts-a process that is time-consuming, subjective, and impractical for
large-scale EEG studies. Existing techniques are often hindered by a strong
reliance on manual hyperparameter tuning, sensitivity to outliers, and high
computational costs. In this paper, we introduce the improved Riemannian Potato
Field (iRPF), a fast and fully automated method for EEG artifact rejection that
addresses key limitations of current approaches. We evaluate iRPF against
several state-of-the-art artifact rejection methods, using two publicly
available EEG databases, labeled for various artifact types, comprising 226 EEG
recordings. Our results demonstrate that iRPF outperforms all competitors
across multiple metrics, with gains of up to 22% in recall, 102% in
specificity, 54% in precision, and 24% in F1-score, compared to Isolation
Forest, Autoreject, Riemannian Potato, and Riemannian Potato Field,
respectively. Statistical analysis confirmed the significance of these
improvements (p < 0.001) with large effect sizes (Cohen's d > 0.8) in most
comparisons. Additionally, on a typical EEG recording iRPF performs artifact
cleaning in under 8 milliseconds per epoch using a standard laptop,
highlighting its efficiency for large-scale EEG data processing and real-time
applications. iRPF offers a robust and data-driven artifact rejection solution
for high-quality EEG pre-processing in brain-computer interfaces and clinical
neuroimaging applications.

</details>


### [19] [On the Relation of Characteristic Modes of Different Conducting Structures](https://arxiv.org/abs/2509.09282)
*Leonardo Mörlein,Dirk Manteuffel*

Main category: eess.SP

TL;DR: 基于特征模态的形式化方法，用一个结构的特征模态分析其子结构的散射特性，并定义模态变换矩阵来进行基准转换。


<details>
  <summary>Details</summary>
Motivation: 为了在共同的特征模态基础上分析和比较不同的导体结构，提高设计效率和分析准确性。

Method: 推导形式化方法，定义模态变换矩阵来描述两个结构之间特征场和权重系数的映射关系，并进行基准转换。

Result: 证明在这种情况下散射矩阵和微氧矩阵不再是对角矩阵，通过两个实例验证了方法的有效性。

Conclusion: 该形式化方法为天线元件的渐进式设计提供了有用的分析工具，能够在共同基础上进行结构比较和优化。

Abstract: A formalism is derived to analyze the scattering of a conducting structure
based on the characteristic modes of another structure whose surface is a
superset of the first structure. This enables the analysis and comparison of
different structures using a common basis of characteristic modes.
Additionally, it is shown that the scattering matrices and perturbation
matrices are no longer diagonal in these cases. Based on this, a modal
transformation matrix is defined to describe the mapping between the
characteristic fields and the weighting coefficients of the two structures.
This matrix enables the conversion of the perturbation matrices in different
bases. Finally, two examples are provided along with a discussion of some
aspects of the theory. The first example aims to validate and illustrate the
formalism. The second example shows how the formalism can be applied in the
design process of an antenna element that is gradually modified, starting from
a base structure.

</details>


### [20] [Channel Estimation and Analog Precoding for Pixel-based Fluid-Antenna-Assisted Multiuser MIMO-OFDM Systems](https://arxiv.org/abs/2509.09373)
*Huayan Guo,Jichen Zhang,Junhui Rao,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 基于实际原型港径测量，提出了用于像素流体天线系统的稀疏港道恢复框架和两种低复杂度港道估计算法，通过模拟港道预测和模拟预编码显著提升系统性能


<details>
  <summary>Details</summary>
Motivation: 像素流体天线虽能提供更高的多工收益和更快的辐射图切换，但引入了状态非可分离港道响应问题，给港道估计和模拟预编码带来挑战

Method: 提出了一个稀疏港道恢复框架，使用近似可分离港道响应模型和DNN基于天线辐射函数；设计了两种低复杂度港道估计算法（正交匹配追蹶和变分贝叶斯推断）

Result: 模拟结果显示该方法在高信噪比环境下显著优于多个基准方法，尤其是在用户数量较多时

Conclusion: 该研究为像素流体天线系统提供了高效的港道估计和预编码方案，有效解决了状态非可分离港道响应问题，显著提升了多用户MIMO-OFDM系统的性能

Abstract: Pixel-based fluid antennas provide enhanced multiplexing gains and quicker
radiation pattern switching than traditional designs. However, this innovation
introduces challenges for channel estimation and analog precoding due to the
state-non-separable channel response problem. This paper explores a multiuser
MIMO-OFDM system utilizing pixel-based fluid antennas, informed by measurements
from a real-world prototype. We present a sparse channel recovery framework for
uplink channel sounding, employing an approximate separable channel response
model with DNN-based antenna radiation functions. We then propose two
low-complexity channel estimation algorithms that leverage orthogonal matching
pursuit and variational Bayesian inference to accurately recover channel
responses across various scattering cluster angles. These estimations enable
the prediction of composite channels for all fluid antenna states, leading to
an analog precoding scheme that optimally selects switching states for
different antennas. Our simulation results indicate that the proposed approach
significantly outperforms several baseline methods, especially in high
signal-to-noise ratio environments with numerous users.

</details>


### [21] [A Multi-Scale Feature Extraction and Fusion UNet for Pathloss Prediction in UAV-Assisted mmWave Radio Networks](https://arxiv.org/abs/2509.09606)
*Sajjad Hussain*

Main category: eess.SP

TL;DR: 提出基于UNet的深度学习架构，用于无人机毫米波网络路径损耗预测，结合多尺度特征提取和ASPP瓶颈，在准确性和效率上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在跨环境泛化性、噪声输入鲁棒性和无人机高度敏感性方面研究不足，需要更有效的路径损耗预测方案

Method: UNet架构结合多尺度特征提取、卷积特征融合和ASPP瓶颈，从对数距离、LOS掩码和建筑掩码输入预测路径损耗图，并开发了向量化LOS掩码计算算法

Result: 在内部射线追踪数据和RadioMapSeer基准测试中，模型在准确性和效率方面均优于多个最先进基线方法

Conclusion: 所提方法有效解决了路径损耗预测的关键挑战，代码已开源以支持可重复性和未来研究

Abstract: Accurate pathloss prediction is essential for the design and optimization of
UAV-assisted millimeter-wave (mmWave) networks. While deep learning approaches
have shown strong potential, their generalization across diverse environments,
robustness to noisy inputs, and sensitivity to UAV altitude remain
underexplored. To address these challenges, we propose a UNet-based deep
learning architecture that combines multi-scale feature extraction,
convolution-based feature fusion, and an atrous spatial pyramid pooling (ASPP)
bottleneck for efficient context aggregation. The model predicts pathloss maps
from log-distance, line-of-sight (LOS) mask, and building mask inputs. In
addition, we develop a fully vectorized LOS mask computation algorithm that
significantly accelerates pre-processing and enables large-scale dataset
generation. Extensive evaluations on both in-house ray-tracing data and the
RadioMapSeer benchmark demonstrate that the proposed model outperforms several
state-of-the-art baselines in accuracy and efficiency. All source code is
publicly released to support reproducibility and future research.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [22] [Improved Receiver Chain Performance via Error Location Inference](https://arxiv.org/abs/2509.08869)
*Michael Greenwood,Robert Hunter*

Main category: cs.IT

TL;DR: 使用机器学习模型估计字节级删除概率，通过标记删除来提升重应壹梯小大码的编码能力，在不改变设备硬件的情况下实现0.3dB的信道增益


<details>
  <summary>Details</summary>
Motivation: 现代宇航器通信系统依赖于卷积码和Reed-Solomon码的编码组合，需要在不改变硬件和编码标准的前提下提升效能

Method: 在解码端使用机器学习模型来估计接收数据帧中字节级删除的概率，并用这些估计值在RS解码前标记删除

Result: 方法在信号劣化条件下提高了数据恢复能力，实现了0.3分贝的信道增益

Conclusion: 该方法为宇航器通信系统提供了一种无需硬件改造的性能提升方案，通过机器学习模型预测删除来增强错误编码能力

Abstract: Modern spacecraft communication systems rely on concatenated error correction
schemes, typically combining convolutional and Reed-Solomon (RS) codes. This
paper presents a decoder-side method that uses a machine learning model to
estimate the likelihood of byte-level corruption in received data frames. These
estimates are used to mark erasures prior to RS decoding, enhancing its
correction capacity without requiring changes to spacecraft hardware or
encoding standards. The approach enables improved data recovery under degraded
signal conditions at a gain of 0.3 decibels.

</details>


### [23] [Gaussian Copula-Based Outage Performance Analysis of Fluid Antenna Systems: Channel Coefficient- or Envelope-Level Correlation Matrix?](https://arxiv.org/abs/2509.09411)
*Rui Xu,Yinghui Ye,Xiaoli Chu,Guangyue Lu,Farshad Rostami Ghadi,Kai-Kit Wong*

Main category: cs.IT

TL;DR: 本文探讨了在流体天线系统(FAS)中使用颜色相关矩阵替代系数相关矩阵来评估断断性能的优势，并在Nakagami-m衰落下验证了其更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 之前的研究使用Jake模型的通道系数相关矩阵来近似Gaussian copula中的协方差矩阵，但因为多元正态随机变量是通过变换相关颜色生成的，所以需要探索使用颜色相关矩阵是否更准确。

Method: 在完全相关的Nakagami-m衰落环境下，开发了一种生成这种衰落通道的方法，用于Monte Carlo模拟作为理论结果的验证标准。

Result: 模拟结果证实了提出的通道建模方法的有效性，并显示使用颜色相关矩阵具有更高的准确性，特别是在稀疏端口部署和低断断区域。

Conclusion: 使用颜色相关矩阵在评估FAS断断性能时比使用系数相关矩阵更准确，特别在具体应用场景中显示出优势。

Abstract: Gaussian copula has been employed to evaluate the outage performance of Fluid
Antenna Systems (FAS), with the covariance matrix reflecting the dependence
among multivariate normal random variables (RVs). While prior studies
approximate this matrix using the channel coefficient correlation matrix from
Jake's model, this work instead employs the channel envelope correlation
matrix, motivated by the fact that the multivariate normal RVs are generated by
transforming correlated channel envelopes. This raises an open question of
whether using the coefficient- or envelope-level correlation matrix yields
better accuracy in accessing FAS performance. Toward this end, this paper
explores the benefits of using the envelope-level correlation matrix under
fully correlated Nakagami-m fading, and develops a method for generating such
fading channels for Monte Carlo simulations, which serve as a benchmark for
validating the theoretical results. Simulation results confirm the
effectiveness of the proposed channel modeling approach and demonstrate the
superior accuracy of using the envelope-level correlation matrix, particularly
in sparse port deployment and low-outage regime.

</details>


### [24] [Mixture of Semantics Transmission for Generative AI-Enabled Semantic Communication Systems](https://arxiv.org/abs/2509.09499)
*Junjie Ni,Tong Wu,Zhiyong Chen,Yin Xu,Meixia Tao,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出基于生成式AI的语义混合传输策略(MoS)，通过ROI和RONI分区处理实现无线语义通信中带宽资源的优化分配和图像重建


<details>
  <summary>Details</summary>
Motivation: 现有基于生成式AI的语义通信方法在信道资源利用效率方面存在不足，需要在视觉保真度和语义相关性之间取得更好平衡

Method: 在发送端将图像分为感兴趣区域(ROI)和非感兴趣区域(RONI)，分别提取语义信息并分配不同带宽；在接收端使用扩散模型根据接收到的语义信息重建完整图像

Result: 实验结果表明适当的ROI-RONI分配至关重要，MoS在ROI的PSNR和RONI的CLIP分数方面取得了显著的性能提升

Conclusion: MoS策略通过语义混合传输实现了更高效的信道资源利用，在保持语义相关性的同时提升了视觉质量

Abstract: In this paper, we propose a mixture of semantics (MoS) transmission strategy
for wireless semantic communication systems based on generative artificial
intelligence (AI). At the transmitter, we divide an image into regions of
interest (ROI) and reigons of non-interest (RONI) to extract their semantic
information respectively. Semantic information of ROI can be allocated more
bandwidth, while RONI can be represented in a compact form for transmission. At
the receiver, a diffusion model reconstructs the full image using the received
semantic information of ROI and RONI. Compared to existing generative AI-based
methods, MoS enables more efficient use of channel resources by balancing
visual fidelity and semantic relevance. Experimental results demonstrate that
appropriate ROI-RONI allocation is critical. The MoS achieves notable
performance gains in peak signal-to-noise ratio (PSNR) of ROI and CLIP score of
RONI.

</details>


### [25] [Fast Polarisation-Aware Decoder for Non-Binary Polar Codes](https://arxiv.org/abs/2509.09554)
*Joseph Jabbour,Ali Chamas Al-Ghouwayel,Emmanuel Boutillon*

Main category: cs.IT

TL;DR: 提出FSC-PA算法，通过定制化NB-PC解码器内核，显著降低非二进制极化码解码复杂度，在BPSK和CCSK调制下实现60%域加法和30%实数加法减少，性能损失仅0.2dB


<details>
  <summary>Details</summary>
Motivation: 研究低复杂度非二进制极化码解码器，通过分析输入极化水平相同的奇偶校验节点来降低整体解码计算复杂度

Method: 采用快速连续消除-极化感知(FSC-PA)方案，通过离线分析定制每个解码器内核，最小化共享相同输入极化水平的奇偶校验节点的计算负载

Result: 与最先进的扩展最小和算法相比，FSC-PA算法实现了60%的域加法和30%的实数加法总体减少，性能损失仅为0.2dB的轻微退化

Conclusion: FSC-PA方案能有效降低非二进制极化码解码的计算复杂度，在保持接近最优性能的同时显著减少运算量，适用于BPSK和CCSK调制

Abstract: The paper investigates the emerging field of low-complexity non-binary polar
code (NB-PC) decoders. It shows that customizing each kernel of an NB-PC
decoder through offline analysis can significantly reduce the overall decoding
complexity. The proposed decoder, referred to as the Fast Successive
Cancellation-Polarization Aware (FSC-PA) scheme, achieves this by minimizing
the computational load of parity-check nodes that share the same level of input
polarization. The NB polar decoder is developed for both BPSK and CCSK
modulations. Compared to the state-of-the-art extended min-sum algorithm, the
FSC-PA algorithm achieves an overall reduction of 60 percents in field
additions and 30 percents in real additions, while incurring only a negligible
performance loss (less than 0.2 dB degradation).

</details>


### [26] [RSMA-Enhanced Data Collection in RIS-Assisted Intelligent Consumer Transportation Systems](https://arxiv.org/abs/2509.09644)
*Chunjie Wang,Xuhui Zhang,Wenchao Liu,Jinke Ren,Shuqiang Wang,Yanyan Shen,Kejiang Ye,Kim Fung Tsang*

Main category: cs.IT

TL;DR: 提出RIS赋能的智能交通系统数据收集增强框架，通过联合优化RIS相移、功率分配、计算资源和时隙分配，最大化最小处理数据量


<details>
  <summary>Details</summary>
Motivation: 解决智能交通系统中数据收集和处理效率问题，利用RIS技术增强通信性能，提高交通数据处理能力

Method: 采用混合RSMA和TDMA协议，结合交替优化和顺序秩一约束松弛算法，联合优化RIS相移、发射功率、计算资源和时隙分配

Result: 所提算法在多种场景下显著优于基线方案，有效提升了智能交通应用的数据处理性能

Conclusion: 该框架为RIS赋能的智能交通系统提供了有效的数据收集和处理解决方案，具有重要的实际应用价值

Abstract: This paper investigates the data collection enhancement problem in a
reconfigurable intelligent surface (RIS)-empowered intelligent consumer
transportation system (ICTS). We propose a novel framework where a data center
(DC) provides energy to pre-configured roadside unit (RSU) pairs during the
downlink stage. While in the uplink stage, these RSU pairs utilize a hybrid
rate-splitting multiple access (RSMA) and time-division multiple access (TDMA)
protocol to transmit the processed data to the DC, while simultaneously
performing local data processing using the harvested energy. Our objective is
to maximize the minimal processed data volume of the RSU pairs by jointly
optimizing the RIS downlink and uplink phase shifts, the transmit power of the
DC and RSUs, the RSU computation resource allocation, and the time slot
allocation. To address the formulated non-convex problem, we develop an
efficient iterative algorithm integrating alternating optimization and
sequential rank-one constraint relaxation methods. Extensive simulations
demonstrate that the proposed algorithm significantly outperforms baseline
schemes under diverse scenarios, validating its effectiveness in enhancing the
data processing performance for intelligent transportation applications.

</details>
