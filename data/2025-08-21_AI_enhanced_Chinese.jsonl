{"id": "2508.14118", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14118", "abs": "https://arxiv.org/abs/2508.14118", "authors": ["Jason Granstedt", "Prabhat Kc", "Rucha Deshpande", "Victor Garcia", "Aldo Badano"], "title": "Hallucinations in medical devices", "comment": "19 pages, 2 figures", "summary": "Computer methods in medical devices are frequently imperfect and are known to\nproduce errors in clinical or diagnostic tasks. However, when deep learning and\ndata-based approaches yield output that exhibit errors, the devices are\nfrequently said to hallucinate. Drawing from theoretical developments and\nempirical studies in multiple medical device areas, we introduce a practical\nand universal definition that denotes hallucinations as a type of error that is\nplausible and can be either impactful or benign to the task at hand. The\ndefinition aims at facilitating the evaluation of medical devices that suffer\nfrom hallucinations across product areas. Using examples from imaging and\nnon-imaging applications, we explore how the proposed definition relates to\nevaluation methodologies and discuss existing approaches for minimizing the\nprevalence of hallucinations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u533b\u7597\u8bbe\u5907\u4e2d\u5e7b\u89c9\u9519\u8bef\u7684\u5b9e\u7528\u5b9a\u4e49\uff0c\u5c06\u5176\u5b9a\u4e49\u4e3a\u770b\u4f3c\u5408\u7406\u4f46\u53ef\u80fd\u5bf9\u4efb\u52a1\u4ea7\u751f\u5f71\u54cd\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u65e8\u5728\u4fc3\u8fdb\u8de8\u4ea7\u54c1\u9886\u57df\u7684\u533b\u7597\u8bbe\u5907\u8bc4\u4f30\u3002", "motivation": "\u533b\u7597\u8bbe\u5907\u4e2d\u7684\u8ba1\u7b97\u673a\u65b9\u6cd5\u7ecf\u5e38\u4e0d\u5b8c\u7f8e\u5e76\u4ea7\u751f\u9519\u8bef\uff0c\u5f53\u6df1\u5ea6\u5b66\u4e60\u7b49\u65b9\u6cd5\u4ea7\u751f\u9519\u8bef\u8f93\u51fa\u65f6\uff0c\u5e38\u88ab\u79f0\u4e3a\"\u5e7b\u89c9\"\u3002\u9700\u8981\u7edf\u4e00\u7684\u5b9a\u4e49\u6765\u4fc3\u8fdb\u8bc4\u4f30\u3002", "method": "\u57fa\u4e8e\u7406\u8bba\u53d1\u5c55\u548c\u591a\u4e2a\u533b\u7597\u8bbe\u5907\u9886\u57df\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u901a\u7528\u7684\u5e7b\u89c9\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u6210\u50cf\u548c\u975e\u6210\u50cf\u5e94\u7528\u793a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86\u5e7b\u89c9\u4f5c\u4e3a\u770b\u4f3c\u5408\u7406\u9519\u8bef\u7684\u660e\u786e\u5b9a\u4e49\uff0c\u8ba8\u8bba\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b66\uff0c\u5e76\u63a2\u7d22\u4e86\u51cf\u5c11\u5e7b\u89c9\u53d1\u751f\u7387\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b9a\u4e49\u6709\u52a9\u4e8e\u6807\u51c6\u5316\u533b\u7597\u8bbe\u5907\u4e2d\u5e7b\u89c9\u9519\u8bef\u7684\u8bc4\u4f30\uff0c\u4e3a\u4e0d\u540c\u4ea7\u54c1\u9886\u57df\u7684\u8bbe\u5907\u6027\u80fd\u6bd4\u8f83\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2508.14122", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.TO"], "pdf": "https://arxiv.org/pdf/2508.14122", "abs": "https://arxiv.org/abs/2508.14122", "authors": ["Jolanta Mozyrska", "Marcel Beetz", "Luke Melas-Kyriazi", "Vicente Grau", "Abhirup Banerjee", "Alfonso Bueno-Orovio"], "title": "3D Cardiac Anatomy Generation Using Mesh Latent Diffusion Models", "comment": null, "summary": "Diffusion models have recently gained immense interest for their generative\ncapabilities, specifically the high quality and diversity of the synthesized\ndata. However, examples of their applications in 3D medical imaging are still\nscarce, especially in cardiology. Generating diverse realistic cardiac\nanatomies is crucial for applications such as in silico trials,\nelectromechanical computer simulations, or data augmentations for machine\nlearning models. In this work, we investigate the application of Latent\nDiffusion Models (LDMs) for generating 3D meshes of human cardiac anatomies. To\nthis end, we propose a novel LDM architecture -- MeshLDM. We apply the proposed\nmodel on a dataset of 3D meshes of left ventricular cardiac anatomies from\npatients with acute myocardial infarction and evaluate its performance in terms\nof both qualitative and quantitative clinical and 3D mesh reconstruction\nmetrics. The proposed MeshLDM successfully captures characteristics of the\ncardiac shapes at end-diastolic (relaxation) and end-systolic (contraction)\ncardiac phases, generating meshes with a 2.4% difference in population mean\ncompared to the gold standard.", "AI": {"tldr": "\u63d0\u51faMeshLDM\u6a21\u578b\uff0c\u9996\u6b21\u5c06\u6f5c\u5728\u6269\u6563\u6a21\u578b\u5e94\u7528\u4e8e\u751f\u62103D\u5fc3\u810f\u89e3\u5256\u7f51\u683c\uff0c\u5728\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u60a3\u8005\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u751f\u6210\u8d28\u91cf", "motivation": "\u6269\u6563\u6a21\u578b\u57283D\u533b\u5b66\u5f71\u50cf\u7279\u522b\u662f\u5fc3\u810f\u75c5\u5b66\u4e2d\u7684\u5e94\u7528\u4ecd\u8f83\u5c11\uff0c\u751f\u6210\u591a\u6837\u5316\u771f\u5b9e\u5fc3\u810f\u89e3\u5256\u7ed3\u6784\u5bf9\u4e8e\u8ba1\u7b97\u673a\u6a21\u62df\u8bd5\u9a8c\u3001\u7535\u673a\u68b0\u6a21\u62df\u548c\u673a\u5668\u5b66\u4e60\u6570\u636e\u589e\u5f3a\u81f3\u5173\u91cd\u8981", "method": "\u63d0\u51fa\u65b0\u9896\u7684MeshLDM\u67b6\u6784\uff0c\u57fa\u4e8e\u6f5c\u5728\u6269\u6563\u6a21\u578b\u751f\u62103D\u5fc3\u810f\u7f51\u683c\uff0c\u5728\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u60a3\u8005\u7684\u5de6\u5fc3\u5ba43D\u7f51\u683c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30", "result": "\u6a21\u578b\u6210\u529f\u6355\u6349\u8212\u5f20\u671f\u548c\u6536\u7f29\u671f\u5fc3\u810f\u5f62\u72b6\u7279\u5f81\uff0c\u751f\u6210\u7f51\u683c\u4e0e\u91d1\u6807\u51c6\u76f8\u6bd4\u7fa4\u4f53\u5747\u503c\u5dee\u5f02\u4ec5\u4e3a2.4%\uff0c\u5728\u4e34\u5e8a\u548c3D\u91cd\u5efa\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02", "conclusion": "MeshLDM\u662f\u9996\u4e2a\u6210\u529f\u5e94\u7528\u4e8e3D\u5fc3\u810f\u89e3\u5256\u7f51\u683c\u751f\u6210\u7684\u6269\u6563\u6a21\u578b\uff0c\u4e3a\u5fc3\u810f\u75c5\u5b66\u9886\u57df\u7684\u8ba1\u7b97\u673a\u6a21\u62df\u548c\u6570\u636e\u589e\u5f3a\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177"}}
{"id": "2508.14129", "categories": ["eess.IV", "cs.AI", "cs.CV", "68T45", "I.2.10"], "pdf": "https://arxiv.org/pdf/2508.14129", "abs": "https://arxiv.org/abs/2508.14129", "authors": ["Aditya Bagri", "Vasanthakumar Venugopal", "Anandakumar D", "Revathi Ezhumalai", "Kalyan Sivasailam", "Bargava Subramanian", "VarshiniPriya", "Meenakumari K S", "Abi M", "Renita S"], "title": "Fracture Detection and Localisation in Wrist and Hand Radiographs using Detection Transformer Variants", "comment": "18 pages, 21 figures", "summary": "Background: Accurate diagnosis of wrist and hand fractures using radiographs\nis essential in emergency care, but manual interpretation is slow and prone to\nerrors. Transformer-based models show promise in improving medical image\nanalysis, but their application to extremity fractures is limited. This study\naddresses this gap by applying object detection transformers to wrist and hand\nX-rays.\n  Methods: We fine-tuned the RT-DETR and Co-DETR models, pre-trained on COCO,\nusing over 26,000 annotated X-rays from a proprietary clinical dataset. Each\nimage was labeled for fracture presence with bounding boxes. A ResNet-50\nclassifier was trained on cropped regions to refine abnormality classification.\nSupervised contrastive learning was used to enhance embedding quality.\nPerformance was evaluated using AP@50, precision, and recall metrics, with\nadditional testing on real-world X-rays.\n  Results: RT-DETR showed moderate results (AP@50 = 0.39), while Co-DETR\noutperformed it with an AP@50 of 0.615 and faster convergence. The integrated\npipeline achieved 83.1% accuracy, 85.1% precision, and 96.4% recall on\nreal-world X-rays, demonstrating strong generalization across 13 fracture\ntypes. Visual inspection confirmed accurate localization.\n  Conclusion: Our Co-DETR-based pipeline demonstrated high accuracy and\nclinical relevance in wrist and hand fracture detection, offering reliable\nlocalization and differentiation of fracture types. It is scalable, efficient,\nand suitable for real-time deployment in hospital workflows, improving\ndiagnostic speed and reliability in musculoskeletal radiology.", "AI": {"tldr": "\\u8fd9\\u7bc7\\u8bba\\u6587\\u5e94\\u7528Co-DETR\\u53d8\\u6362\\u5668\\u6a21\\u578b\\u8fdb\\u884c\\u624b\\u8150\\u548c\\u624b\\u90e8\\u9aa8\\u6298X\\u5149\\u7247\\u68c0\\u6d4b\\uff0c\\u5b9e\\u73b0\\u4e86\\u9ad8\\u51c6\\u786e\\u5ea6\\u7684\\u9aa8\\u6298\\u5b9a\\u4f4d\\u548c\\u5206\\u7c7b\\uff0c\\u9002\\u5408\\u4e34\\u5e8a\\u90e8\\u7f72\\u3002", "motivation": "\\u624b\\u8150\\u548c\\u624b\\u90e8\\u9aa8\\u6298\\u7684\\u51c6\\u786e\\u8bca\\u65ad\\u5bf9\\u6025\\u8bca\\u91cd\\u8981\\uff0c\\u4f46\\u624b\\u52a8\\u89e3\\u91ca\\u6162\\u901f\\u4e14\\u5bb9\\u6613\\u51fa\\u9519\\u3002\\u53d8\\u6362\\u5668\\u6a21\\u578b\\u5728\\u533b\\u5b66\\u56fe\\u50cf\\u5206\\u6790\\u4e2d\\u5c55\\u73b0\\u6f5c\\u529b\\uff0c\\u4f46\\u5728\\u673a\\u6784\\u9aa8\\u6298\\u68c0\\u6d4b\\u4e2d\\u5e94\\u7528\\u6709\\u9650\\u3002", "method": "\\u4f7f\\u7528\\u8fc7\\u26,000\\u5f20\\u5e26\\u6807\\u6ce8\\u7684X\\u5149\\u7247\\u5bf9RT-DETR\\u548cCo-DETR\\u6a21\\u578b\\u8fdb\\u884c\\u5fae\\u8c03\\uff0c\\u7ed3\\u5408ResNet-50\\u5206\\u7c7b\\u5668\\u8fdb\\u884c\\u533b\\u7597\\u533a\\u57df\\u5206\\u6790\\uff0c\\u91c7\\u7528\\u76d1\\u7763\\u5bf9\\u6bd4\\u5b66\\u4e60\\u63d0\\u5347\\u5d4c\\u5165\\u8d28\\u91cf\\u3002", "result": "Co-DETR\\u8868\\u73b0\\u4f18\\u5f02(AP@50=0.615)\\uff0c\\u96c6\\u6210\\u7ba1\\u7ebf\\u5728\\u5b9e\\u9645X\\u5149\\u7247\\u4e0a\\u8fbe\\u523083.1%\\u51c6\\u786e\\u5ea6\\u300185.1%\\u7cbe\\u786e\\u5ea6\\u548c96.4%\\u56de\\u753b\\u7387\\uff0c\\u80fd\\u591f\\u51c6\\u786e\\u5b9a\\u4f4d13\\u79cd\\u9aa8\\u6298\\u7c7b\\u578b\\u3002", "conclusion": "Co-DETR\\u57fa\\u4e8e\\u7684\\u65b9\\u6848\\u5728\\u624b\\u8150\\u624b\\u90e8\\u9aa8\\u6298\\u68c0\\u6d4b\\u4e2d\\u8868\\u73b0\\u51fa\\u9ad8\\u51c6\\u786e\\u5ea6\\u548c\\u4e34\\u5e8a\\u9002\\u7528\\u6027\\uff0c\\u5177\\u6709\\u53ef\\u6269\\u5c55\\u6027\\u548c\\u9ad8\\u6548\\u6027\\uff0c\\u9002\\u5408\\u5728\\u533b\\u9662\\u5de5\\u4f5c\\u6d41\\u7a0b\\u4e2d\\u5b9e\\u65f6\\u90e8\\u7f72\\uff0c\\u63d0\\u5347\\u9aa8\\u9abc\\u79d1\\u5f71\\u50cf\\u8bca\\u65ad\\u7684\\u901f\\u5ea6\\u548c\\u53ef\\u9760\\u6027\\u3002"}}
{"id": "2508.14133", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14133", "abs": "https://arxiv.org/abs/2508.14133", "authors": ["Karin A. Olthof", "Matteo Fusagli", "Bianca G\u00fcttner", "Tiziano Natali", "Bram Westerink", "Stefanie Speidel", "Theo J. M. Ruers", "Koert F. D. Kuhlmann", "Andrey Zhylka"], "title": "Automated surgical planning with nnU-Net: delineation of the anatomy in hepatobiliary phase MRI", "comment": "14 pages, 5 figures", "summary": "Background: The aim of this study was to develop and evaluate a deep\nlearning-based automated segmentation method for hepatic anatomy (i.e.,\nparenchyma, tumors, portal vein, hepatic vein and biliary tree) from the\nhepatobiliary phase of gadoxetic acid-enhanced MRI. This method should ease the\nclinical workflow of preoperative planning.\n  Methods: Manual segmentation was performed on hepatobiliary phase MRI scans\nfrom 90 consecutive patients who underwent liver surgery between January 2020\nand October 2023. A deep learning network (nnU-Net v1) was trained on 72\npatients with an extra focus on thin structures and topography preservation.\nPerformance was evaluated on an 18-patient test set by comparing automated and\nmanual segmentations using Dice similarity coefficient (DSC). Following\nclinical integration, 10 segmentations (assessment dataset) were generated\nusing the network and manually refined for clinical use to quantify required\nadjustments using DSC.\n  Results: In the test set, DSCs were 0.97+/-0.01 for liver parenchyma,\n0.80+/-0.04 for hepatic vein, 0.79+/-0.07 for biliary tree, 0.77+/-0.17 for\ntumors, and 0.74+/-0.06 for portal vein. Average tumor detection rate was\n76.6+/-24.1%, with a median of one false-positive per patient. The assessment\ndataset showed minor adjustments were required for clinical use of the 3D\nmodels, with high DSCs for parenchyma (1.00+/-0.00), portal vein (0.98+/-0.01)\nand hepatic vein (0.95+/-0.07). Tumor segmentation exhibited greater\nvariability (DSC 0.80+/-0.27). During prospective clinical use, the model\ndetected three additional tumors initially missed by radiologists.\n  Conclusions: The proposed nnU-Net-based segmentation method enables accurate\nand automated delineation of hepatic anatomy. This enables 3D planning to be\napplied efficiently as a standard-of-care for every patient undergoing liver\nsurgery.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8ennU-Net\u7684\u6df1\u5ea6\u5b66\u4e60\u81ea\u52a8\u5206\u5272\u65b9\u6cd5\uff0c\u7528\u4e8e\u9486\u585e\u9178\u589e\u5f3aMRI\u809d\u80c6\u671f\u7684\u809d\u810f\u89e3\u5256\u7ed3\u6784\u5206\u5272\uff0c\u5305\u62ec\u809d\u5b9e\u8d28\u3001\u80bf\u7624\u3001\u95e8\u9759\u8109\u3001\u809d\u9759\u8109\u548c\u80c6\u9053\u6811\uff0c\u4ee5\u7b80\u5316\u672f\u524d\u89c4\u5212\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u7b80\u5316\u809d\u810f\u624b\u672f\u672f\u524d\u89c4\u5212\u7684\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5206\u5272\u65b9\u6cd5\u63d0\u9ad8\u6548\u7387\uff0c\u4f7f3D\u89c4\u5212\u80fd\u591f\u4f5c\u4e3a\u6807\u51c6\u62a4\u7406\u5e94\u7528\u4e8e\u6bcf\u4f4d\u809d\u810f\u624b\u672f\u60a3\u8005\u3002", "method": "\u4f7f\u752890\u4f8b\u60a3\u8005\u7684\u809d\u80c6\u671fMRI\u626b\u63cf\u8fdb\u884c\u624b\u52a8\u5206\u5272\uff0c\u5176\u4e2d72\u4f8b\u7528\u4e8e\u8bad\u7ec3nnU-Net v1\u7f51\u7edc\uff0c\u7279\u522b\u5173\u6ce8\u8584\u7ed3\u6784\u548c\u5730\u5f62\u4fdd\u6301\u3002\u572818\u4f8b\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\uff0c\u4f7f\u7528Dice\u76f8\u4f3c\u7cfb\u6570\u6bd4\u8f83\u81ea\u52a8\u548c\u624b\u52a8\u5206\u5272\u3002", "result": "\u6d4b\u8bd5\u96c6DSC\u7ed3\u679c\uff1a\u809d\u5b9e\u8d280.97\u00b10.01\uff0c\u809d\u9759\u81090.80\u00b10.04\uff0c\u80c6\u9053\u68110.79\u00b10.07\uff0c\u80bf\u76240.77\u00b10.17\uff0c\u95e8\u9759\u81090.74\u00b10.06\u3002\u80bf\u7624\u68c0\u6d4b\u738776.6\u00b124.1%\uff0c\u6bcf\u4f8b\u60a3\u8005\u4e2d\u4f4d\u5047\u9633\u60271\u4e2a\u3002\u4e34\u5e8a\u8bc4\u4f30\u663e\u793a3D\u6a21\u578b\u4ec5\u9700\u5fae\u5c0f\u8c03\u6574\u5373\u53ef\u4f7f\u7528\u3002", "conclusion": "\u57fa\u4e8ennU-Net\u7684\u5206\u5272\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u81ea\u52a8\u63cf\u7ed8\u809d\u810f\u89e3\u5256\u7ed3\u6784\uff0c\u4f7f3D\u89c4\u5212\u80fd\u591f\u9ad8\u6548\u5730\u4f5c\u4e3a\u809d\u810f\u624b\u672f\u60a3\u8005\u7684\u6807\u51c6\u62a4\u7406\u5e94\u7528\uff0c\u5728\u4e34\u5e8a\u4f7f\u7528\u4e2d\u8fd8\u53d1\u73b0\u4e86\u653e\u5c04\u79d1\u533b\u751f\u6700\u521d\u9057\u6f0f\u76843\u4e2a\u989d\u5916\u80bf\u7624\u3002"}}
{"id": "2508.14204", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14204", "abs": "https://arxiv.org/abs/2508.14204", "authors": ["Xingyu Chen", "Jianrong Ding", "Kai Zheng", "Xinmin Fang", "Xinyu Zhang", "Chris Xiaoxuan Lu", "Zhengxiong Li"], "title": "InverTwin: Solving Inverse Problems via Differentiable Radio Frequency Digital Twin", "comment": null, "summary": "Digital twins (DTs), virtual simulated replicas of physical scenes, are\ntransforming various industries. However, their potential in radio frequency\n(RF) sensing applications has been limited by the unidirectional nature of\nconventional RF simulators. In this paper, we present InverTwin, an\noptimization-driven framework that creates RF digital twins by enabling\nbidirectional interaction between virtual and physical realms. InverTwin\novercomes the fundamental differentiability challenges of RF optimization\nproblems through novel design components, including path-space differentiation\nto address discontinuity in complex simulation functions, and a radar surrogate\nmodel to mitigate local non-convexity caused by RF signal periodicity. These\ntechniques enable smooth gradient propagation and robust optimization of the DT\nmodel. Our implementation and experiments demonstrate InverTwin's versatility\nand effectiveness in augmenting both data-driven and model-driven RF sensing\nsystems for DT reconstruction.", "AI": {"tldr": "InverTwin\u662f\u4e00\u4e2a\u4f18\u5316\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u865a\u62df\u548c\u7269\u7406\u9886\u57df\u7684\u53cc\u5411\u4ea4\u4e92\u521b\u5efaRF\u6570\u5b57\u5b6a\u751f\uff0c\u89e3\u51b3\u4e86RF\u4f18\u5316\u7684\u53ef\u5fae\u6027\u6311\u6218\u3002", "motivation": "\u4f20\u7edfRF\u6a21\u62df\u5668\u7684\u5355\u5411\u6027\u9650\u5236\u4e86\u6570\u5b57\u5b6a\u751f\u5728\u5c04\u9891\u4f20\u611f\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b9e\u73b0\u865a\u62df\u4e0e\u7269\u7406\u9886\u57df\u53cc\u5411\u4ea4\u4e92\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8def\u5f84\u7a7a\u95f4\u5fae\u5206\u5904\u7406\u590d\u6742\u6a21\u62df\u51fd\u6570\u7684\u4e0d\u8fde\u7eed\u6027\uff0c\u4f7f\u7528\u96f7\u8fbe\u66ff\u4ee3\u6a21\u578b\u7f13\u89e3RF\u4fe1\u53f7\u5468\u671f\u6027\u5bfc\u81f4\u7684\u5c40\u90e8\u975e\u51f8\u6027\uff0c\u5b9e\u73b0\u5e73\u6ed1\u68af\u5ea6\u4f20\u64ad\u548c\u9c81\u68d2\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eInverTwin\u5728\u589e\u5f3a\u6570\u636e\u9a71\u52a8\u548c\u6a21\u578b\u9a71\u52a8\u7684RF\u4f20\u611f\u7cfb\u7edf\u8fdb\u884c\u6570\u5b57\u5b6a\u751f\u91cd\u5efa\u65b9\u9762\u5177\u6709\u591a\u529f\u80fd\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "InverTwin\u6846\u67b6\u6210\u529f\u514b\u670d\u4e86RF\u4f18\u5316\u95ee\u9898\u7684\u53ef\u5fae\u6027\u6311\u6218\uff0c\u4e3aRF\u6570\u5b57\u5b6a\u751f\u7684\u521b\u5efa\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53cc\u5411\u4ea4\u4e92\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14328", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.14328", "abs": "https://arxiv.org/abs/2508.14328", "authors": ["Jianhang Zhu", "Jie Gong"], "title": "Multi-Source Peak Age of Information Optimization in Mobile Edge Computing Systems", "comment": "16 pages, 10 figures, accepted by IEEE Trans. Networking", "summary": "Age of Information (AoI) is emerging as a novel metric for measuring\ninformation freshness in real-time monitoring systems. For\ncomputation-intensive status data, the information is not revealed until being\nprocessed. We consider a status update problem in a multi-source single-server\nsystem where the sources are scheduled to generate and transmit status data\nwhich are received and processed at the edge server. Generate-at-will sources\nwith both random transmission time and process time are considered, introducing\nthe joint optimization of source scheduling and status sampling on the basis of\ntransmission-computation balancing. We show that a random scheduler is optimal\nfor both non-preemptive and preemptive server settings, and the optimal sampler\ndepends on the scheduling result and its structure remains consistent with the\nsingle-source system, i.e., threshold-based sampler for non-preemptive case and\ntransmission-aware deterministic sampler for preemptive case. Then, the problem\ncan be transformed to jointly optimizing the scheduling frequencies and the\nsampling thresholds/functions, which is non-convex. We proposed an alternation\noptimization algorithm to solve it. Numerical experiments show that the\nproposed algorithm can achieve the optimal in a wide range of settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u6e90\u5355\u670d\u52a1\u5668\u7cfb\u7edf\u4e2d\u8ba1\u7b97\u5bc6\u96c6\u578b\u72b6\u6001\u6570\u636e\u7684AoI\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u968f\u673a\u8c03\u5ea6\u5668\u7684\u6700\u4f18\u6027\u548c\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316\u7684\u8054\u5408\u8c03\u5ea6\u4e0e\u91c7\u6837\u7b97\u6cd5", "motivation": "\u5728\u5b9e\u65f6\u76d1\u63a7\u7cfb\u7edf\u4e2d\uff0c\u8ba1\u7b97\u5bc6\u96c6\u578b\u72b6\u6001\u6570\u636e\u9700\u8981\u4f20\u8f93\u548c\u5904\u7406\u540e\u624d\u80fd\u63ed\u793a\u4fe1\u606f\uff0c\u4f20\u7edfAoI\u5ea6\u91cf\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u8fd9\u79cd\u573a\u666f\u7684\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff0c\u9700\u8981\u8054\u5408\u4f18\u5316\u6e90\u8c03\u5ea6\u548c\u72b6\u6001\u91c7\u6837", "method": "\u8003\u8651\u5177\u6709\u968f\u673a\u4f20\u8f93\u65f6\u95f4\u548c\u5904\u7406\u65f6\u95f4\u7684\u751f\u6210\u5373\u53d1\u6e90\uff0c\u5206\u6790\u975e\u62a2\u5360\u5f0f\u548c\u62a2\u5360\u5f0f\u670d\u52a1\u5668\u8bbe\u7f6e\u4e0b\u7684\u6700\u4f18\u8c03\u5ea6\u5668\u548c\u91c7\u6837\u5668\u7ed3\u6784\uff0c\u63d0\u51fa\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u8c03\u5ea6\u9891\u7387\u548c\u91c7\u6837\u9608\u503c/\u51fd\u6570", "result": "\u8bc1\u660e\u968f\u673a\u8c03\u5ea6\u5668\u5728\u4e24\u79cd\u670d\u52a1\u5668\u8bbe\u7f6e\u4e0b\u90fd\u662f\u6700\u4f18\u7684\uff0c\u6700\u4f18\u91c7\u6837\u5668\u7ed3\u6784\u4fdd\u6301\u4e0e\u5355\u6e90\u7cfb\u7edf\u4e00\u81f4\uff0c\u63d0\u51fa\u7684\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u5728\u5e7f\u6cdb\u8bbe\u7f6e\u4e0b\u80fd\u8fbe\u5230\u6700\u4f18\u6027\u80fd", "conclusion": "\u591a\u6e90\u7cfb\u7edf\u4e2d\u7684AoI\u4f18\u5316\u53ef\u4ee5\u901a\u8fc7\u968f\u673a\u8c03\u5ea6\u548c\u7ed3\u6784\u4e00\u81f4\u7684\u91c7\u6837\u7b56\u7565\u5b9e\u73b0\uff0c\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u975e\u51f8\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898"}}
{"id": "2508.14151", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14151", "abs": "https://arxiv.org/abs/2508.14151", "authors": ["Justin Yiu", "Kushank Arora", "Daniel Steinberg", "Rohit Ghiya"], "title": "A Systematic Study of Deep Learning Models and xAI Methods for Region-of-Interest Detection in MRI Scans", "comment": null, "summary": "Magnetic Resonance Imaging (MRI) is an essential diagnostic tool for\nassessing knee injuries. However, manual interpretation of MRI slices remains\ntime-consuming and prone to inter-observer variability. This study presents a\nsystematic evaluation of various deep learning architectures combined with\nexplainable AI (xAI) techniques for automated region of interest (ROI)\ndetection in knee MRI scans. We investigate both supervised and self-supervised\napproaches, including ResNet50, InceptionV3, Vision Transformers (ViT), and\nmultiple U-Net variants augmented with multi-layer perceptron (MLP)\nclassifiers. To enhance interpretability and clinical relevance, we integrate\nxAI methods such as Grad-CAM and Saliency Maps. Model performance is assessed\nusing AUC for classification and PSNR/SSIM for reconstruction quality, along\nwith qualitative ROI visualizations. Our results demonstrate that ResNet50\nconsistently excels in classification and ROI identification, outperforming\ntransformer-based models under the constraints of the MRNet dataset. While\nhybrid U-Net + MLP approaches show potential for leveraging spatial features in\nreconstruction and interpretability, their classification performance remains\nlower. Grad-CAM consistently provided the most clinically meaningful\nexplanations across architectures. Overall, CNN-based transfer learning emerges\nas the most effective approach for this dataset, while future work with\nlarger-scale pretraining may better unlock the potential of transformer models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u819d\u76d6MRI\u81ea\u52a8\u533a\u57df\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0ResNet50\u5728\u5206\u7c7b\u548cROI\u8bc6\u522b\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u8d85\u8d8a\u4e86\u53d8\u6362\u5668\u6a21\u578b\uff0c\u5e76\u901a\u8fc7Grad-CAM\u63d0\u4f9b\u4e86\u6700\u4e34\u5e8a\u610f\u4e49\u7684\u89e3\u91ca\u3002", "motivation": "MRI\u624b\u5de5\u89e3\u91ca\u8017\u65f6\u4e14\u5b58\u5728\u89c2\u5bdf\u8005\u95f4\u5dee\u5f02\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u533a\u57df\u68c0\u6d4b\u65b9\u6cd5\u6765\u63d0\u9ad8\u8bca\u65ad\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u7814\u7a76\u6d4b\u8bd5\u4e86\u76d1\u7763\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ecResNet50\u3001InceptionV3\u3001Vision Transformers\u548c\u591a\u4e2aU-Net\u53d8\u4f53\uff0c\u5e76\u96c6\u6210Grad-CAM\u548cSaliency Maps\u7b49xAI\u6280\u672f\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "ResNet50\u5728\u5206\u7c7b\u548cROI\u8bc6\u522b\u4e2d\u8868\u73b0\u6700\u4f18\uff08AUC\u8bc4\u4ef7\uff09\uff0c\u8d85\u8d8a\u4e86\u53d8\u6362\u5668\u6a21\u578b\u3002U-Net + MLP\u6df7\u5408\u65b9\u6cd5\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u5206\u7c7b\u6027\u80fd\u8f83\u4f4e\u3002Grad-CAM\u63d0\u4f9b\u4e86\u6700\u4e34\u5e8a\u610f\u4e49\u7684\u89e3\u91ca\u3002", "conclusion": "CNN\u57fa\u4e8e\u8fc7\u7684\u8f6c\u79fb\u5b66\u4e60\u662f\u5728MRNet\u6570\u636e\u96c6\u4e0a\u6700\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u672a\u6765\u9700\u8981\u66f4\u5927\u89c4\u6a21\u7684\u9884\u8bad\u7ec3\u624d\u80fd\u5145\u5206\u53d1\u6325\u53d8\u6362\u5668\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.14438", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14438", "abs": "https://arxiv.org/abs/2508.14438", "authors": ["Akash Prabakar", "Abhishek Shreekant Bhandiwad", "Abijith Jagannath Kamath", "Chandra Sekhar Seelamantula"], "title": "Weakly-Convex Regularization for Magnetic Resonance Image Denoising", "comment": "Presented in ISCS25", "summary": "Regularization for denoising in magnetic resonance imaging (MRI) is typically\nachieved using convex regularization functions. Recently, deep learning\ntechniques have been shown to provide superior denoising performance. However,\nthis comes at the price of lack of explainability, interpretability and\nstability, which are all crucial to MRI. In this work, we present a\nconstructive approach for designing weakly-convex regularization functions for\nMR image denoising. We show that our technique performs on par with\nstate-of-the-art denoisers for diffusion-weighted MR image denoising. Our\ntechnique can be applied to design weakly-convex convolutional neural networks\nwith prototype activation functions that impart interpretability and are\nprovably convergent. We also show that our technique exhibits fewer denoising\nartifacts by demonstrating its effect on brain microstructure modelling.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6784\u5efa\u5f31\u51f8\u6b63\u5219\u5316\u51fd\u6570\u7684\u65b9\u6cd5\u7528\u4e8eMRI\u53bb\u566a\uff0c\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u53bb\u566a\u5668\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3001\u7a33\u5b9a\u6027\u548c\u66f4\u5c11\u7684\u53bb\u566a\u4f2a\u5f71\u3002", "motivation": "\u4f20\u7edfMRI\u53bb\u566a\u4f7f\u7528\u51f8\u6b63\u5219\u5316\u51fd\u6570\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u867d\u7136\u6027\u80fd\u4f18\u8d8a\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u7a33\u5b9a\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u8fd9\u4e9b\u5bf9MRI\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u6784\u9020\u6027\u65b9\u6cd5\u8bbe\u8ba1\u5f31\u51f8\u6b63\u5219\u5316\u51fd\u6570\uff0c\u53ef\u4ee5\u6784\u5efa\u5177\u6709\u539f\u578b\u6fc0\u6d3b\u51fd\u6570\u7684\u5f31\u51f8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u4e9b\u7f51\u7edc\u5177\u6709\u53ef\u89e3\u91ca\u6027\u4e14\u53ef\u8bc1\u660e\u6536\u655b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6269\u6563\u52a0\u6743MR\u56fe\u50cf\u53bb\u566a\u65b9\u9762\u4e0e\u6700\u5148\u8fdb\u7684\u53bb\u566a\u5668\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u66f4\u5c11\u7684\u53bb\u566a\u4f2a\u5f71\uff0c\u5e76\u5728\u8111\u5fae\u7ed3\u6784\u5efa\u6a21\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f31\u51f8\u6b63\u5219\u5316\u65b9\u6cd5\u4e3aMRI\u53bb\u566a\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u4fdd\u6301\u9ad8\u6027\u80fd\u53c8\u5177\u5907\u53ef\u89e3\u91ca\u6027\u548c\u7a33\u5b9a\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u53ef\u9760\u89e3\u91ca\u7684\u533b\u5b66\u6210\u50cf\u5e94\u7528\u3002"}}
{"id": "2508.14386", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.14386", "abs": "https://arxiv.org/abs/2508.14386", "authors": ["Yubo Sun", "Gennian Ge"], "title": "Reconstruction Codes for Deletions and Insertions: Connection, Distinction, and Construction", "comment": null, "summary": "Let $\\mathcal{B}(\\cdot)$ be an error ball function. A set of $q$-ary\nsequences of length $n$ is referred to as an\n\\emph{$(n,q,N;\\mathcal{B})$-reconstruction code} if each sequence\n$\\boldsymbol{x}$ within this set can be uniquely reconstructed from any $N$\ndistinct elements within its error ball $\\mathcal{B}(\\boldsymbol{x})$. The main\nobjective in this area is to determine or establish bounds for the minimum\nredundancy of $(n,q,N;\\mathcal{B})$-reconstruction codes, denoted by\n$\\rho(n,q,N;\\mathcal{B})$. In this paper, we investigate reconstruction codes\nwhere the error ball is either the \\emph{$t$-deletion ball}\n$\\mathcal{D}_t(\\cdot)$ or the \\emph{$t$-insertion ball} $\\mathcal{I}_t(\\cdot)$.\nFirstly, we establish a fundamental connection between reconstruction codes for\ndeletions and insertions. For any positive integers $n,t,q,N$, any\n$(n,q,N;\\mathcal{I}_t)$-reconstruction code is also an\n$(n,q,N;\\mathcal{D}_t)$-reconstruction code. This leads to the inequality\n$\\rho(n,q,N;\\mathcal{D}_t)\\leq \\rho(n,q,N;\\mathcal{I}_t)$. Then, we identify a\nsignificant distinction between reconstruction codes for deletions and\ninsertions when $N=O(n^{t-1})$ and $t\\geq 2$. For deletions, we prove that\n$\\rho(n,q,\\tfrac{2(q-1)^{t-1}}{q^{t-1}(t-1)!}n^{t-1}+O(n^{t-2});\\mathcal{D}_t)=O(1)$,\nwhich disproves a conjecture posed in \\cite{Chrisnata-22-IT}. For insertions,\nwe show that\n$\\rho(n,q,\\tfrac{(q-1)^{t-1}}{(t-1)!}n^{t-1}+O(n^{t-2});\\mathcal{I}_t)=\\log\\log\nn + O(1)$, which extends a key result from \\cite{Ye-23-IT}. Finally, we\nconstruct $(n,q,N;\\mathcal{B})$-reconstruction codes, where $\\mathcal{B}\\in\n\\{\\mathcal{D}_2,\\mathcal{I}_2\\}$, for $N \\in \\{2,3, 4, 5\\}$ and establish\nrespective upper bounds of $3\\log n+O(\\log\\log n)$, $3\\log n+O(1)$, $2\\log\nn+O(\\log\\log n)$ and $\\log n+O(\\log\\log n)$ on the minimum redundancy\n$\\rho(n,q,N;\\mathcal{B})$. This generalizes results previously established in\n\\cite{Sun-23-IT}.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5220\u9664\u548c\u63d2\u5165\u9519\u8bef\u4e0b\u7684\u91cd\u5efa\u7801\uff0c\u5efa\u7acb\u4e86\u5220\u9664\u4e0e\u63d2\u5165\u91cd\u5efa\u7801\u4e4b\u95f4\u7684\u57fa\u672c\u8054\u7cfb\uff0c\u8bc1\u660e\u4e86\u03c1(n,q,N;D_t) \u2264 \u03c1(n,q,N;I_t)\uff0c\u5e76\u53d1\u73b0\u4e86\u5f53N=O(n^{t-1})\u4e14t\u22652\u65f6\u5220\u9664\u4e0e\u63d2\u5165\u91cd\u5efa\u7801\u7684\u91cd\u8981\u533a\u522b\u3002", "motivation": "\u7814\u7a76\u91cd\u5efa\u7801\u7684\u4e3b\u8981\u76ee\u6807\u662f\u786e\u5b9a\u6216\u5efa\u7acb(n,q,N;B)-\u91cd\u5efa\u7801\u7684\u6700\u5c0f\u5197\u4f59\u5ea6\u03c1(n,q,N;B)\u7684\u754c\u9650\uff0c\u5176\u4e2d\u9519\u8bef\u7403\u53ef\u4ee5\u662ft-\u5220\u9664\u7403D_t(\u00b7)\u6216t-\u63d2\u5165\u7403I_t(\u00b7)\u3002", "method": "\u9996\u5148\u5efa\u7acb\u5220\u9664\u548c\u63d2\u5165\u91cd\u5efa\u7801\u4e4b\u95f4\u7684\u57fa\u672c\u8054\u7cfb\uff0c\u7136\u540e\u5206\u522b\u7814\u7a76\u5220\u9664\u548c\u63d2\u5165\u60c5\u51b5\u4e0b\u7684\u5197\u4f59\u5ea6\u754c\u9650\uff0c\u6700\u540e\u6784\u9020\u5177\u4f53\u7684\u91cd\u5efa\u7801\u5e76\u5efa\u7acb\u76f8\u5e94\u7684\u4e0a\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u5220\u9664\u91cd\u5efa\u7801\u7684\u5197\u4f59\u5ea6\u4e3aO(1)\uff0c\u63d2\u5165\u91cd\u5efa\u7801\u7684\u5197\u4f59\u5ea6\u4e3alog log n + O(1)\uff0c\u5e76\u6784\u9020\u4e86N\u2208{2,3,4,5}\u65f6\u7684\u91cd\u5efa\u7801\uff0c\u5206\u522b\u5f97\u5230\u4e863log n+O(log log n)\u30013log n+O(1)\u30012log n+O(log log n)\u548clog n+O(log log n)\u7684\u4e0a\u754c\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u5220\u9664\u548c\u63d2\u5165\u91cd\u5efa\u7801\u4e4b\u95f4\u7684\u91cd\u8981\u5dee\u5f02\uff0c\u63a8\u7ffb\u4e86\u4e4b\u524d\u7684\u731c\u60f3\uff0c\u6269\u5c55\u4e86\u5df2\u6709\u7ed3\u679c\uff0c\u5e76\u4e3a\u7279\u5b9a\u53c2\u6570\u4e0b\u7684\u91cd\u5efa\u7801\u6784\u9020\u63d0\u4f9b\u4e86\u65b0\u7684\u4e0a\u754c\u3002"}}
{"id": "2508.14475", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.14475", "abs": "https://arxiv.org/abs/2508.14475", "authors": ["Xiangfei Sheng", "Xiaofeng Pan", "Zhichao Yang", "Pengfei Chen", "Leida Li"], "title": "Fine-grained Image Quality Assessment for Perceptual Image Restoration", "comment": "9 pages,6 figures", "summary": "Recent years have witnessed remarkable achievements in perceptual image\nrestoration (IR), creating an urgent demand for accurate image quality\nassessment (IQA), which is essential for both performance comparison and\nalgorithm optimization. Unfortunately, the existing IQA metrics exhibit\ninherent weakness for IR task, particularly when distinguishing fine-grained\nquality differences among restored images. To address this dilemma, we\ncontribute the first-of-its-kind fine-grained image quality assessment dataset\nfor image restoration, termed FGRestore, comprising 18,408 restored images\nacross six common IR tasks. Beyond conventional scalar quality scores,\nFGRestore was also annotated with 30,886 fine-grained pairwise preferences.\nBased on FGRestore, a comprehensive benchmark was conducted on the existing IQA\nmetrics, which reveal significant inconsistencies between score-based IQA\nevaluations and the fine-grained restoration quality. Motivated by these\nfindings, we further propose FGResQ, a new IQA model specifically designed for\nimage restoration, which features both coarse-grained score regression and\nfine-grained quality ranking. Extensive experiments and comparisons demonstrate\nthat FGResQ significantly outperforms state-of-the-art IQA metrics. Codes and\nmodel weights have been released in https://pxf0429.github.io/FGResQ/", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u7684\u7ec6\u7c92\u5ea6\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\u6570\u636e\u96c6FGRestore\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u65b0\u7684IQA\u6a21\u578bFGResQ\uff0c\u8be5\u6a21\u578b\u5728\u7c97\u7c92\u5ea6\u8bc4\u5206\u56de\u5f52\u548c\u7ec6\u7c92\u5ea6\u8d28\u91cf\u6392\u5e8f\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30(IQA)\u6307\u6807\u5728\u56fe\u50cf\u6062\u590d(IR)\u4efb\u52a1\u4e2d\u5b58\u5728\u56fa\u6709\u5f31\u70b9\uff0c\u7279\u522b\u662f\u5728\u533a\u5206\u6062\u590d\u56fe\u50cf\u4e4b\u95f4\u7684\u7ec6\u7c92\u5ea6\u8d28\u91cf\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u963b\u788d\u4e86\u6027\u80fd\u6bd4\u8f83\u548c\u7b97\u6cd5\u4f18\u5316\u3002", "method": "1) \u6784\u5efa\u5305\u542b18,408\u5f20\u6062\u590d\u56fe\u50cf\u7684FGRestore\u6570\u636e\u96c6\uff0c\u6db5\u76d66\u79cd\u5e38\u89c1IR\u4efb\u52a1\uff1b2) \u9664\u4e86\u4f20\u7edf\u6807\u91cf\u8d28\u91cf\u5206\u6570\u5916\uff0c\u8fd8\u6807\u6ce8\u4e8630,886\u4e2a\u7ec6\u7c92\u5ea6\u6210\u5bf9\u504f\u597d\uff1b3) \u63d0\u51faFGResQ\u6a21\u578b\uff0c\u540c\u65f6\u8fdb\u884c\u7c97\u7c92\u5ea6\u8bc4\u5206\u56de\u5f52\u548c\u7ec6\u7c92\u5ea6\u8d28\u91cf\u6392\u5e8f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFGResQ\u5728\u56fe\u50cf\u6062\u590d\u8d28\u91cf\u8bc4\u4f30\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdbIQA\u6307\u6807\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u53cd\u6620\u7ec6\u7c92\u5ea6\u6062\u590d\u8d28\u91cf\u5dee\u5f02\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u56fe\u50cf\u6062\u590d\u9886\u57df\u7ec6\u7c92\u5ea6\u8d28\u91cf\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684FGResQ\u6a21\u578b\u4e3a\u89e3\u51b3IR\u4efb\u52a1\u4e2d\u7684IQA\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u548c\u6a21\u578b\u6743\u91cd\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.14458", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14458", "abs": "https://arxiv.org/abs/2508.14458", "authors": ["Jingjing Zhao", "Haowen Song", "Xidong Mu", "Kaiquan Cai", "Yanbo Zhu", "Yuanwei Liu"], "title": "Pinching-Antenna Systems-Enabled Multi-User Communications: Transmission Structures and Beamforming Optimization", "comment": null, "summary": "Pinching-antenna systems (PASS) represent an innovative advancement in\nflexible-antenna technologies, aimed at significantly improving wireless\ncommunications by ensuring reliable line-of-sight connections and dynamic\nantenna array reconfigurations. To employ multi-waveguide PASS in multi-user\ncommunications, three practical transmission structures are proposed, namely\nwaveguide multiplexing (WM), waveguide division (WD), and waveguide switching\n(WS). Based on the proposed structures, the joint baseband signal processing\nand pinching beamforming design is studied for a general multi-group multicast\ncommunication system, with the unicast communication encompassed as a special\ncase. A max-min fairness problem is formulated for each proposed transmission\nstructure, subject to the maximum transmit power constraint. For WM, to solve\nthe highly-coupled and non-convex MMF problem with complex exponential and\nfractional expressions, a penalty dual decomposition (PDD)-based algorithm is\ninvoked for obtaining locally optimal solutions. Specifically, the augmented\nLagrangian relaxation is first applied to alleviate the stringent coupling\nconstraints, which is followed by the block decomposition over the resulting\naugmented Lagrangian function. Then, the proposed PDD-based algorithm is\nextended to solve the MMF problem for both WD and WS. Furthermore, a\nlow-complexity algorithm is proposed for the unicast case employing the WS\nstructure, by simultaneously aligning the signal phases and minimizing the\nlarge-scale path loss at each user. Finally, numerical results reveal that: 1)\nthe MMF performance is significantly improved by employing the PASS compared to\nconventional fixed-position antenna systems; 2) WS and WM are suitable for\nunicast and multicast communications, respectively; 3) the performance gap\nbetween WD and WM can be significantly alleviated when the users are\ngeographically isolated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u57fa\u4e8e\u634f\u5408\u5929\u7ebf\u7cfb\u7edf(PASS)\u7684\u4f20\u8f93\u7ed3\u6784(WM\u3001WD\u3001WS)\uff0c\u7814\u7a76\u4e86\u591a\u7ec4\u591a\u64ad\u901a\u4fe1\u4e2d\u7684\u8054\u5408\u57fa\u5e26\u4fe1\u53f7\u5904\u7406\u548c\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u4f18\u5316\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u7cfb\u7edf\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u521b\u65b0\u7684\u67d4\u6027\u5929\u7ebf\u6280\u672f\u6765\u786e\u4fdd\u53ef\u9760\u7684\u89c6\u8ddd\u8fde\u63a5\u548c\u52a8\u6001\u5929\u7ebf\u9635\u5217\u91cd\u6784\uff0c\u4ee5\u63d0\u9ad8\u591a\u7528\u6237\u901a\u4fe1\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u6ce2\u5bfc\u590d\u7528(WM)\u3001\u6ce2\u5bfc\u5206\u5272(WD)\u548c\u6ce2\u5bfc\u5207\u6362(WS)\u4e09\u79cd\u4f20\u8f93\u7ed3\u6784\uff1b\u9488\u5bf9\u6700\u5927\u6700\u5c0f\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u60e9\u7f5a\u5bf9\u5076\u5206\u89e3(PDD)\u7684\u7b97\u6cd5\uff1b\u4e3a\u5355\u64adWS\u7ed3\u6784\u8bbe\u8ba1\u4e86\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff1a1)PASS\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u7cfb\u7edf\u663e\u8457\u6539\u5584\u4e86MMF\u6027\u80fd\uff1b2)WS\u9002\u7528\u4e8e\u5355\u64ad\u901a\u4fe1\uff0cWM\u9002\u7528\u4e8e\u591a\u64ad\u901a\u4fe1\uff1b3)\u5f53\u7528\u6237\u5730\u7406\u9694\u79bb\u65f6\uff0cWD\u548cWM\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u663e\u8457\u51cf\u5c0f\u3002", "conclusion": "PASS\u6280\u672f\u901a\u8fc7\u52a8\u6001\u5929\u7ebf\u91cd\u6784\u663e\u8457\u63d0\u5347\u4e86\u65e0\u7ebf\u901a\u4fe1\u6027\u80fd\uff0c\u4e0d\u540c\u7684\u4f20\u8f93\u7ed3\u6784\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u901a\u4fe1\u573a\u666f\uff0c\u4e3a\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14507", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.14507", "abs": "https://arxiv.org/abs/2508.14507", "authors": ["Bohao Wang", "Zehua Jiang", "Zhenyu Yang", "Chongwen Huang", "Yongliang Shen", "Siming Jiang", "Chen Zhu", "Zhaohui Yang", "Richeng Jin", "Zhaoyang Zhang", "Sami Muhaidat", "Merouane Debbah"], "title": "DeepTelecom: A Digital-Twin Deep Learning Dataset for Channel and MIMO Applications", "comment": null, "summary": "Domain-specific datasets are the foundation for unleashing artificial\nintelligence (AI)-driven wireless innovation. Yet existing wireless AI corpora\nare slow to produce, offer limited modeling fidelity, and cover only narrow\nscenario types. To address the challenges, we create DeepTelecom, a\nthree-dimension (3D) digital-twin channel dataset. Specifically, a large\nlanguage model (LLM)-assisted pipeline first builds the third level of details\n(LoD3) outdoor and indoor scenes with segmentable material-parameterizable\nsurfaces. Then, DeepTelecom simulates full radio-wave propagation effects based\non Sionna's ray-tracing engine. Leveraging GPU acceleration, DeepTelecom\nstreams ray-path trajectories and real-time signal-strength heat maps, compiles\nthem into high-frame-rate videos, and simultaneously outputs synchronized\nmulti-view images, channel tensors, and multi-scale fading traces. By\nefficiently streaming large-scale, high-fidelity, and multimodal channel data,\nDeepTelecom not only furnishes a unified benchmark for wireless AI research but\nalso supplies the domain-rich training substrate that enables foundation models\nto tightly fuse large model intelligence with future communication systems.", "AI": {"tldr": "DeepTelecom\u662f\u4e00\u4e2a3D\u6570\u5b57\u5b6a\u751f\u4fe1\u9053\u6570\u636e\u96c6\uff0c\u901a\u8fc7LLM\u8f85\u52a9\u6784\u5efa\u9ad8\u7ec6\u8282\u573a\u666f\uff0c\u5229\u7528GPU\u52a0\u901f\u7684\u5c04\u7ebf\u8ffd\u8e2a\u6280\u672f\u751f\u6210\u5927\u89c4\u6a21\u3001\u9ad8\u4fdd\u771f\u3001\u591a\u6a21\u6001\u7684\u65e0\u7ebf\u4fe1\u9053\u6570\u636e\uff0c\u4e3a\u65e0\u7ebfAI\u7814\u7a76\u63d0\u4f9b\u7edf\u4e00\u57fa\u51c6\u548c\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u65e0\u7ebfAI\u6570\u636e\u96c6\u751f\u6210\u7f13\u6162\u3001\u5efa\u6a21\u4fdd\u771f\u5ea6\u6709\u9650\u3001\u573a\u666f\u8986\u76d6\u72ed\u7a84\uff0c\u65e0\u6cd5\u6ee1\u8db3AI\u9a71\u52a8\u7684\u65e0\u7ebf\u521b\u65b0\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u6784\u5efaLoD3\u7ea7\u5ba4\u5185\u5916\u573a\u666f\uff0c\u57fa\u4e8eSionna\u5c04\u7ebf\u8ffd\u8e2a\u5f15\u64ce\u6a21\u62df\u5168\u65e0\u7ebf\u7535\u6ce2\u4f20\u64ad\u6548\u5e94\uff0c\u5229\u7528GPU\u52a0\u901f\u751f\u6210\u5c04\u7ebf\u8def\u5f84\u8f68\u8ff9\u3001\u5b9e\u65f6\u4fe1\u53f7\u5f3a\u5ea6\u70ed\u56fe\u3001\u591a\u89c6\u56fe\u56fe\u50cf\u3001\u4fe1\u9053\u5f20\u91cf\u548c\u591a\u5c3a\u5ea6\u8870\u843d\u8f68\u8ff9\u7b49\u591a\u6a21\u6001\u6570\u636e\u3002", "result": "\u521b\u5efa\u4e86\u80fd\u591f\u9ad8\u6548\u6d41\u5f0f\u4f20\u8f93\u5927\u89c4\u6a21\u3001\u9ad8\u4fdd\u771f\u3001\u591a\u6a21\u6001\u4fe1\u9053\u6570\u636e\u7684DeepTelecom\u6570\u636e\u96c6\uff0c\u652f\u6301\u5b9e\u65f6\u89c6\u9891\u6d41\u548c\u540c\u6b65\u591a\u89c6\u56fe\u8f93\u51fa\u3002", "conclusion": "DeepTelecom\u4e3a\u65e0\u7ebfAI\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u57fa\u51c6\uff0c\u5e76\u4e3a\u57fa\u7840\u6a21\u578b\u5c06\u5927\u6a21\u578b\u667a\u80fd\u4e0e\u672a\u6765\u901a\u4fe1\u7cfb\u7edf\u7d27\u5bc6\u878d\u5408\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u9886\u57df\u8bad\u7ec3\u6570\u636e\u3002"}}
{"id": "2508.14509", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14509", "abs": "https://arxiv.org/abs/2508.14509", "authors": ["Xin Wang", "Xiaopei Zhang", "Xingang Wang"], "title": "Deep Skin Lesion Segmentation with Transformer-CNN Fusion: Toward Intelligent Skin Cancer Analysis", "comment": null, "summary": "This paper proposes a high-precision semantic segmentation method based on an\nimproved TransUNet architecture to address the challenges of complex lesion\nstructures, blurred boundaries, and significant scale variations in skin lesion\nimages. The method integrates a transformer module into the traditional\nencoder-decoder framework to model global semantic information, while retaining\na convolutional branch to preserve local texture and edge features. This\nenhances the model's ability to perceive fine-grained structures. A\nboundary-guided attention mechanism and multi-scale upsampling path are also\ndesigned to improve lesion boundary localization and segmentation consistency.\nTo verify the effectiveness of the approach, a series of experiments were\nconducted, including comparative studies, hyperparameter sensitivity analysis,\ndata augmentation effects, input resolution variation, and training data split\nratio tests. Experimental results show that the proposed model outperforms\nexisting representative methods in mIoU, mDice, and mAcc, demonstrating\nstronger lesion recognition accuracy and robustness. In particular, the model\nachieves better boundary reconstruction and structural recovery in complex\nscenarios, making it well-suited for the key demands of automated segmentation\ntasks in skin lesion analysis.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6539\u8fdbTransUNet\u7684\u9ad8\u7cbe\u5ea6\u76ae\u80a4\u75c5\u53d8\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210Transformer\u6a21\u5757\u548c\u5377\u79ef\u5206\u652f\uff0c\u7ed3\u5408\u8fb9\u754c\u5f15\u5bfc\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u5c3a\u5ea6\u4e0a\u91c7\u6837\uff0c\u6709\u6548\u89e3\u51b3\u75c5\u53d8\u7ed3\u6784\u590d\u6742\u3001\u8fb9\u754c\u6a21\u7cca\u548c\u5c3a\u5ea6\u53d8\u5316\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u76ae\u80a4\u75c5\u53d8\u56fe\u50cf\u5b58\u5728\u590d\u6742\u75c5\u53d8\u7ed3\u6784\u3001\u6a21\u7cca\u8fb9\u754c\u548c\u663e\u8457\u5c3a\u5ea6\u53d8\u5316\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5206\u5272\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u5efa\u6a21\u5168\u5c40\u8bed\u4e49\u4fe1\u606f\u548c\u4fdd\u7559\u5c40\u90e8\u7eb9\u7406\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5728\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6846\u67b6\u4e2d\u96c6\u6210Transformer\u6a21\u5757\u5efa\u6a21\u5168\u5c40\u8bed\u4e49\u4fe1\u606f\uff0c\u4fdd\u7559\u5377\u79ef\u5206\u652f\u4fdd\u6301\u5c40\u90e8\u7eb9\u7406\u548c\u8fb9\u7f18\u7279\u5f81\uff1b\u8bbe\u8ba1\u8fb9\u754c\u5f15\u5bfc\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u5c3a\u5ea6\u4e0a\u91c7\u6837\u8def\u5f84\uff0c\u63d0\u5347\u8fb9\u754c\u5b9a\u4f4d\u548c\u5206\u5272\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728mIoU\u3001mDice\u548cmAcc\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u4ee3\u8868\u6027\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u75c5\u53d8\u8bc6\u522b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u590d\u6742\u573a\u666f\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u8fb9\u754c\u91cd\u5efa\u548c\u7ed3\u6784\u6062\u590d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u76ae\u80a4\u75c5\u53d8\u5206\u6790\u4e2d\u7684\u81ea\u52a8\u5316\u5206\u5272\u4efb\u52a1\u5173\u952e\u9700\u6c42\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u75c5\u53d8\u7ed3\u6784\u7684\u5206\u5272\u95ee\u9898\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14611", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14611", "abs": "https://arxiv.org/abs/2508.14611", "authors": ["Jinkun Yang"], "title": "FPGA Design and Implementation of Fixed-Point Fast Divider Using Goldschmidt Division Algorithm and Mitchell Multiplication Algorithm", "comment": "7 pages,9 figures", "summary": "This paper presents a variable bit-width fixed-point fast divider using\nGoldschmidt division algorithm and Mitchell multiplication algorithm. Described\nusing Verilog HDL and implemented on a Xilinx XC7Z020-2CLG400I FPGA, the\nproposed divider achieves over 99% computational accuracy with a minimum\nlatency of 99.1 ns, which is 31.7 ns faster than existing single-precision\ndividers. Compared with a Goldschmidt divider using a Vedic multiplier, the\nproposed design reduces Slice Registers by 46.68%, Slice LUTs by 4.93%, and\nSlices by 11.85%, with less than 1% accuracy loss and only 24.1 ns additional\ndelay. These results demonstrate an improved balance between computational\nspeed and resource utilization, making the divider well-suited for\nhigh-performance FPGA-based systems with strict resource constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGoldschmidt\u9664\u6cd5\u7b97\u6cd5\u548cMitchell\u4e58\u6cd5\u7b97\u6cd5\u7684\u53ef\u53d8\u4f4d\u5bbd\u5b9a\u70b9\u5feb\u901f\u9664\u6cd5\u5668\uff0c\u5728FPGA\u4e0a\u5b9e\u73b099%\u4ee5\u4e0a\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u5ef6\u8fdf\u964d\u4f4e31.7ns\uff0c\u8d44\u6e90\u4f7f\u7528\u663e\u8457\u51cf\u5c11", "motivation": "\u9488\u5bf9FPGA\u7cfb\u7edf\u4e2d\u9700\u8981\u9ad8\u6027\u80fd\u9664\u6cd5\u8fd0\u7b97\u4f46\u8d44\u6e90\u53d7\u9650\u7684\u95ee\u9898\uff0c\u5bfb\u6c42\u5728\u8ba1\u7b97\u901f\u5ea6\u548c\u8d44\u6e90\u5229\u7528\u7387\u4e4b\u95f4\u66f4\u597d\u7684\u5e73\u8861", "method": "\u91c7\u7528Goldschmidt\u9664\u6cd5\u7b97\u6cd5\u7ed3\u5408Mitchell\u4e58\u6cd5\u7b97\u6cd5\uff0c\u4f7f\u7528Verilog HDL\u8bbe\u8ba1\uff0c\u5728Xilinx XC7Z020-2CLG400I FPGA\u4e0a\u5b9e\u73b0", "result": "\u8fbe\u523099%\u4ee5\u4e0a\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u6700\u5c0f\u5ef6\u8fdf99.1ns\uff08\u6bd4\u73b0\u6709\u5355\u7cbe\u5ea6\u9664\u6cd5\u5668\u5feb31.7ns\uff09\uff0c\u76f8\u6bd4\u4f7f\u7528Vedic\u4e58\u6cd5\u5668\u7684Goldschmidt\u9664\u6cd5\u5668\uff0cSlice\u5bc4\u5b58\u5668\u51cf\u5c1146.68%\uff0cSlice LUTs\u51cf\u5c114.93%\uff0cSlices\u51cf\u5c1111.85%\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e1%\uff0c\u4ec5\u589e\u52a024.1ns\u5ef6\u8fdf", "conclusion": "\u8be5\u8bbe\u8ba1\u5728\u8ba1\u7b97\u901f\u5ea6\u548c\u8d44\u6e90\u5229\u7528\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u975e\u5e38\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u9ad8\u6027\u80fdFPGA\u7cfb\u7edf"}}
{"id": "2508.14575", "categories": ["cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.14575", "abs": "https://arxiv.org/abs/2508.14575", "authors": ["Shuying Gan", "Xijun Wang", "Chao Xu", "Xiang Chen"], "title": "Minimizing Task-Oriented Age of Information for Remote Monitoring with Pre-Identification", "comment": "This work has been submitted to the lEEE for possible publication", "summary": "The emergence of new intelligent applications has fostered the development of\na task-oriented communication paradigm, where a comprehensive, universal, and\npractical metric is crucial for unleashing the potential of this paradigm. To\nthis end, we introduce an innovative metric, the Task-oriented Age of\nInformation (TAoI), to measure whether the content of information is relevant\nto the system task, thereby assisting the system in efficiently completing\ndesignated tasks. We apply TAoI to a wireless monitoring system tasked with\nidentifying targets and transmitting their images for subsequent analysis. To\nminimize TAoI and determine the optimal transmission policy, we formulate the\ndynamic transmission problem as a Semi-Markov Decision Process (SMDP) and\ntransform it into an equivalent Markov Decision Process (MDP). Our analysis\ndemonstrates that the optimal policy is threshold-based with respect to TAoI.\nBuilding on this, we propose a low-complexity relative value iteration\nalgorithm tailored to this threshold structure to derive the optimal\ntransmission policy. Additionally, we introduce a simpler single-threshold\npolicy, which, despite a slight performance degradation, offers faster\nconvergence. Comprehensive experiments and simulations validate the superior\nperformance of our optimal transmission policy compared to two established\nbaseline approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4efb\u52a1\u5bfc\u5411\u4fe1\u606f\u5e74\u9f84(TAoI)\u65b0\u6307\u6807\u6765\u8861\u91cf\u4fe1\u606f\u5185\u5bb9\u4e0e\u7cfb\u7edf\u4efb\u52a1\u7684\u76f8\u5173\u6027\uff0c\u5e94\u7528\u4e8e\u65e0\u7ebf\u76d1\u63a7\u7cfb\u7edf\uff0c\u901a\u8fc7SMDP\u5efa\u6a21\u548c\u9608\u503c\u7b56\u7565\u4f18\u5316\u4f20\u8f93\u6027\u80fd", "motivation": "\u65b0\u5174\u667a\u80fd\u5e94\u7528\u9700\u8981\u9762\u5411\u4efb\u52a1\u7684\u901a\u4fe1\u8303\u5f0f\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u3001\u901a\u7528\u4e14\u5b9e\u7528\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u5145\u5206\u91ca\u653e\u8be5\u8303\u5f0f\u7684\u6f5c\u529b", "method": "\u5f15\u5165TAoI\u6307\u6807\uff0c\u5c06\u52a8\u6001\u4f20\u8f93\u95ee\u9898\u5efa\u6a21\u4e3a\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(SMDP)\u5e76\u8f6c\u5316\u4e3a\u7b49\u6548MDP\uff0c\u63d0\u51fa\u57fa\u4e8e\u9608\u503c\u7ed3\u6784\u7684\u4f4e\u590d\u6742\u5ea6\u76f8\u5bf9\u503c\u8fed\u4ee3\u7b97\u6cd5", "result": "\u5206\u6790\u8868\u660e\u6700\u4f18\u7b56\u7565\u5177\u6709TAoI\u9608\u503c\u7279\u6027\uff0c\u63d0\u51fa\u7684\u6700\u4f18\u4f20\u8f93\u7b56\u7565\u5728\u7efc\u5408\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u4e24\u79cd\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "TAoI\u662f\u6709\u6548\u7684\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\u5ea6\u91cf\u6807\u51c6\uff0c\u9608\u503c\u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u540c\u65f6\u5355\u9608\u503c\u7b56\u7565\u5728\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\u95f4\u63d0\u4f9b\u4e86\u826f\u597d\u6743\u8861"}}
{"id": "2508.14552", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14552", "abs": "https://arxiv.org/abs/2508.14552", "authors": ["Max Kr\u00e4henmann", "Sergio Tascon-Morales", "Fabian Laumer", "Julia E. Vogt", "Ece Ozkan"], "title": "From Slices to Structures: Unsupervised 3D Reconstruction of Female Pelvic Anatomy from Freehand Transvaginal Ultrasound", "comment": null, "summary": "Volumetric ultrasound has the potential to significantly improve diagnostic\naccuracy and clinical decision-making, yet its widespread adoption remains\nlimited by dependence on specialized hardware and restrictive acquisition\nprotocols. In this work, we present a novel unsupervised framework for\nreconstructing 3D anatomical structures from freehand 2D transvaginal\nultrasound (TVS) sweeps, without requiring external tracking or learned pose\nestimators. Our method adapts the principles of Gaussian Splatting to the\ndomain of ultrasound, introducing a slice-aware, differentiable rasterizer\ntailored to the unique physics and geometry of ultrasound imaging. We model\nanatomy as a collection of anisotropic 3D Gaussians and optimize their\nparameters directly from image-level supervision, leveraging sensorless probe\nmotion estimation and domain-specific geometric priors. The result is a\ncompact, flexible, and memory-efficient volumetric representation that captures\nanatomical detail with high spatial fidelity. This work demonstrates that\naccurate 3D reconstruction from 2D ultrasound images can be achieved through\npurely computational means, offering a scalable alternative to conventional 3D\nsystems and enabling new opportunities for AI-assisted analysis and diagnosis.", "AI": {"tldr": "\u57fa\u4e8e\u9ad8\u65af\u62d6\u6d17\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u4ece\u81ea\u7531\u624b2D\u5197\u9053\u8d85\u58f0\u626b\u63cf\u91cd\u5efa3D\u89e3\u5256\u7ed3\u6784\uff0c\u65e0\u9700\u5916\u90e8\u8ddf\u8e2a\u6216\u4f4d\u7f6e\u4f30\u8ba1", "motivation": "\u89e3\u51b3\u4f53\u79ef\u8d85\u58f0\u4f9d\u8d56\u4e13\u95e8\u786c\u4ef6\u548c\u4e25\u683c\u91c7\u96c6\u534f\u8bae\u7684\u9650\u5236\uff0c\u63a8\u5e7f\u4f53\u79ef\u8d85\u58f0\u5728\u8bca\u65ad\u4e2d\u7684\u5e94\u7528", "method": "\u5c06\u9ad8\u65af\u62d6\u6d17\u539f\u7406\u8c03\u9002\u5230\u8d85\u58f0\u9886\u57df\uff0c\u4f7f\u7528\u5207\u7247\u611f\u77e5\u7684\u53ef\u5fae\u5149\u6805\u5316\u5668\uff0c\u5efa\u7acb\u5404\u5411\u5f02\u60273D\u9ad8\u65af\u6a21\u578b\uff0c\u901a\u8fc7\u56fe\u50cf\u7ea7\u76d1\u7763\u4f18\u5316\u53c2\u6570", "result": "\u5b9e\u73b0\u4e86\u7d27\u51d1\u3001\u7075\u6d3b\u3001\u5185\u5b58\u9ad8\u6548\u7684\u4f53\u79ef\u8868\u793a\uff0c\u9ad8\u4fdd\u771f\u5ea6\u6350\u6355\u89e3\u5256\u7ec6\u8282", "conclusion": "\u8bc1\u660e\u4ec5\u901a\u8fc7\u8ba1\u7b97\u65b9\u6cd5\u5373\u53ef\u4ece2D\u8d85\u58f0\u56fe\u50cf\u5b8c\u6210\u51c63D\u91cd\u5efa\uff0c\u4e3aAI\u8f85\u52a9\u8bca\u65ad\u5f00\u542f\u65b0\u53ef\u80fd"}}
{"id": "2508.14637", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14637", "abs": "https://arxiv.org/abs/2508.14637", "authors": ["Jinkun Yang", "Pengbin Xu"], "title": "Design of a Gm-C Dynamic Amplifier with High Linearity and High Temperature and Power Supply Voltage Stability", "comment": "5 pages, 15 figures", "summary": "This paper presents a Gm-C dynamic amplifier with high linearity and high\ntemperature and power supply voltage stability. The main part of the amplifier\nemploys two asymmetric differential pairs to enhance transconductance\nlinearity. The amplifier maintains a nearly constant gain within a differential\ninput range of -40 mV to 40 mV, and achieves a total harmonic distortion (THD)\nof 70.5 dB. The bias part of the amplifier adopts a constant-gm bias circuit,\nwhich improves the temperature and supply voltage stability of the amplifier's\ntransconductance and gain. When the differential input is 1 mV, the power\nsupply voltage fluctuates by $\\pm$10%, and the temperature varies between\n-40$\\mathrm{^\\circ C}$ and 120$\\mathrm{^\\circ C}$, the standard deviation of\nthe gain distribution is 262m, and the distribution range is from 15.1 to 16.3.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u7ebf\u6027\u5ea6\u3001\u9ad8\u6e29\u5ea6\u7a33\u5b9a\u6027\u548c\u7535\u6e90\u7535\u538b\u7a33\u5b9a\u6027\u7684Gm-C\u52a8\u6001\u653e\u5927\u5668\uff0c\u91c7\u7528\u975e\u5bf9\u79f0\u5dee\u5206\u5bf9\u7ed3\u6784\u63d0\u5347\u7ebf\u6027\u5ea6\uff0c\u5728\u00b140mV\u8f93\u5165\u8303\u56f4\u5185\u4fdd\u6301\u6052\u5b9a\u589e\u76ca\uff0cTHD\u8fbe70.5dB\uff0c\u5e76\u901a\u8fc7\u6052\u5b9agm\u504f\u7f6e\u7535\u8def\u5b9e\u73b0\u5728\u6e29\u5ea6\u548c\u7535\u6e90\u7535\u538b\u53d8\u5316\u4e0b\u7684\u7a33\u5b9a\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u653e\u5927\u5668\u5728\u6e29\u5ea6\u53d8\u5316\u548c\u7535\u6e90\u7535\u538b\u6ce2\u52a8\u65f6\u6027\u80fd\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u80fd\u591f\u5728\u5bbd\u6e29\u5ea6\u8303\u56f4(-40\u00b0C\u81f3120\u00b0C)\u548c\u7535\u6e90\u7535\u538b\u6ce2\u52a8(\u00b110%)\u4e0b\u4fdd\u6301\u7a33\u5b9a\u589e\u76ca\u548c\u9ad8\u7ebf\u6027\u5ea6\u7684\u52a8\u6001\u653e\u5927\u5668\u3002", "method": "\u91c7\u7528\u4e24\u4e2a\u975e\u5bf9\u79f0\u5dee\u5206\u5bf9\u7ed3\u6784\u4f5c\u4e3a\u653e\u5927\u5668\u6838\u5fc3\uff0c\u63d0\u5347\u8de8\u5bfc\u7ebf\u6027\u5ea6\uff1b\u4f7f\u7528\u6052\u5b9agm\u504f\u7f6e\u7535\u8def\u6765\u7a33\u5b9a\u8de8\u5bfc\u548c\u589e\u76ca\uff0c\u786e\u4fdd\u5728\u6e29\u5ea6\u548c\u7535\u6e90\u7535\u538b\u53d8\u5316\u65f6\u7684\u6027\u80fd\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u00b140mV\u5dee\u5206\u8f93\u5165\u8303\u56f4\u5185\u4fdd\u6301\u8fd1\u4e4e\u6052\u5b9a\u589e\u76ca\uff0cTHD\u8fbe\u523070.5dB\uff1b\u5728\u6e29\u5ea6-40\u00b0C\u81f3120\u00b0C\u3001\u7535\u6e90\u7535\u538b\u00b110%\u6ce2\u52a8\u6761\u4ef6\u4e0b\uff0c\u589e\u76ca\u6807\u51c6\u5dee\u4e3a262m\uff0c\u589e\u76ca\u5206\u5e03\u8303\u56f4\u4e3a15.1\u81f316.3\uff0c\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Gm-C\u52a8\u6001\u653e\u5927\u5668\u901a\u8fc7\u521b\u65b0\u7684\u975e\u5bf9\u79f0\u5dee\u5206\u5bf9\u7ed3\u6784\u548c\u6052\u5b9agm\u504f\u7f6e\u6280\u672f\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u7ebf\u6027\u5ea6\u548c\u4f18\u5f02\u7684\u6e29\u5ea6/\u7535\u6e90\u7535\u538b\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u5bf9\u6027\u80fd\u7a33\u5b9a\u6027\u8981\u6c42\u4e25\u683c\u7684\u6a21\u62df\u7535\u8def\u5e94\u7528\u3002"}}
{"id": "2508.14573", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2508.14573", "abs": "https://arxiv.org/abs/2508.14573", "authors": ["Yutong Li", "Zhenming Yu", "Liming Cheng", "Jiayu Di", "Liang Lin", "Jingyue Ma", "Tongshuo Zhang", "Yue Zhou", "Haiying Zhao", "Kun Xu"], "title": "Broadband Near-Infrared Compressive Spectral Imaging System with Reflective Structure", "comment": "8 pages, 6 figures", "summary": "Near-infrared (NIR) hyperspectral imaging has become a critical tool in\nmodern analytical science. However, conventional NIR hyperspectral imaging\nsystems face challenges including high cost, bulky instrumentation, and\ninefficient data collection. In this work, we demonstrate a broadband NIR\ncompressive spectral imaging system that is capable of capturing hyperspectral\ndata covering a broad spectral bandwidth ranging from 700 to 1600 nm. By\nsegmenting wavelengths and designing specialized optical components, our design\novercomes hardware spectral limitations to capture broadband data, while the\nreflective optical structure makes the system compact. This approach provides a\nnovel technical solution for NIR hyperspectral imaging.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bbd\u5e26\u8fd1\u7ea2\u5916\u538b\u7f29\u5149\u8c31\u6210\u50cf\u7cfb\u7edf\uff0c\u80fd\u591f\u6355\u83b7700-1600nm\u7684\u5bbd\u5149\u8c31\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7cfb\u7edf\u6210\u672c\u9ad8\u3001\u4f53\u79ef\u5927\u548c\u6570\u636e\u91c7\u96c6\u6548\u7387\u4f4e\u7684\u95ee\u9898", "motivation": "\u4f20\u7edf\u8fd1\u7ea2\u5916\u9ad8\u5149\u8c31\u6210\u50cf\u7cfb\u7edf\u9762\u4e34\u6210\u672c\u9ad8\u3001\u4eea\u5668\u7b28\u91cd\u548c\u6570\u636e\u91c7\u96c6\u6548\u7387\u4f4e\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7d27\u51d1\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u901a\u8fc7\u6ce2\u957f\u5206\u5272\u548c\u8bbe\u8ba1\u4e13\u7528\u5149\u5b66\u5143\u4ef6\u6765\u514b\u670d\u786c\u4ef6\u5149\u8c31\u9650\u5236\uff0c\u91c7\u7528\u53cd\u5c04\u5f0f\u5149\u5b66\u7ed3\u6784\u4f7f\u7cfb\u7edf\u66f4\u52a0\u7d27\u51d1", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u8986\u76d6700-1600nm\u5bbd\u5149\u8c31\u5e26\u5bbd\u7684\u9ad8\u5149\u8c31\u6570\u636e\u6355\u83b7\u80fd\u529b", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8fd1\u7ea2\u5916\u9ad8\u5149\u8c31\u6210\u50cf\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5e94\u7528\u4ef7\u503c"}}
{"id": "2508.14739", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14739", "abs": "https://arxiv.org/abs/2508.14739", "authors": ["Fatih Ayten", "Mehmet C. Ilter", "Akshay Jain", "Ossi Kaltiokallio", "Jukka Talvitie", "Elena Simona Lohan", "Henk Wymeersch", "Mikko Valkama"], "title": "Failure Tolerant Phase-Only Indoor Positioning via Deep Learning", "comment": null, "summary": "High-precision localization turns into a crucial added value and asset for\nnext-generation wireless systems. Carrier phase positioning (CPP) enables\nsub-meter to centimeter-level accuracy and is gaining interest in 5G-Advanced\nstandardization. While CPP typically complements time-of-arrival (ToA)\nmeasurements, recent literature has introduced a phase-only positioning\napproach in a distributed antenna/MIMO system context with minimal bandwidth\nrequirements, using deep learning (DL) when operating under ideal hardware\nassumptions. In more practical scenarios, however, antenna failures can largely\ndegrade the performance. In this paper, we address the challenging phase-only\npositioning task, and propose a new DL-based localization approach harnessing\nthe so-called hyperbola intersection principle, clearly outperforming the\nprevious methods. Additionally, we consider and propose a processing and\nlearning mechanism that is robust to antenna element failures. Our results show\nthat the proposed DL model achieves robust and accurate positioning despite\nantenna impairments, demonstrating the viability of data-driven,\nimpairment-tolerant phase-only positioning mechanisms. Comprehensive set of\nnumerical results demonstrates large improvements in localization accuracy\nagainst the prior art methods.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u53f7\u89d2\u4f4d\u7f6e\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5229\u7528\u53cc\u66f2\u7ebf\u4ea4\u70b9\u539f\u7406\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\uff0c\u5e76\u5177\u6709\u5929\u7ebf\u6545\u969c\u5f3a\u9510\u6027\u3002", "motivation": "\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u662f\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u7684\u5173\u952e\u4ef7\u503c\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u5929\u7ebf\u6545\u969c\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u5929\u7ebf\u5143\u4ef6\u6545\u969c\u4e0b\u4ecd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u53f7\u4f4d\u5b9a\u4f4d\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5229\u7528\u53cc\u66f2\u7ebf\u4ea4\u70b9\u539f\u7406\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5177\u6709\u5929\u7ebf\u5143\u4ef6\u6545\u969c\u5f3a\u9510\u6027\u7684\u5904\u7406\u548c\u5b66\u4e60\u673a\u5236\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u5929\u7ebf\u6545\u969c\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u7a33\u5065\u548c\u51c6\u786e\u7684\u5b9a\u4f4d\uff0c\u5bf9\u6bd4\u73b0\u6709\u6280\u672f\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8bc1\u660e\u4e86\u6570\u636e\u9a71\u52a8\u7684\u3001\u5177\u6709\u6545\u969c\u5bb9\u5fcd\u6027\u7684\u53f7\u4f4d\u5b9a\u4f4d\u673a\u5236\u7684\u53ef\u884c\u6027\uff0c\u4e3a5G-Advanced\u6807\u51c6\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2508.14585", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2508.14585", "abs": "https://arxiv.org/abs/2508.14585", "authors": ["Jingyue Ma", "Zhenming Yu", "Zhengyang Li", "Liang Lin", "Liming Cheng", "Kun Xu"], "title": "Integrated Snapshot Near-infrared Hypersepctral Imaging Framework with Diffractive Optics", "comment": "5 pages, 4 figures, conference", "summary": "We propose an integrated snapshot near-infrared hyperspectral imaging\nframework that combines designed DOE with NIRSA-Net. The results demonstrate\nnear-infrared spectral imaging at 700-1000nm with 10nm resolution while\nachieving improvement of PSNR 1.47dB and SSIM 0.006.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96c6\u6210\u5feb\u7167\u8fd1\u7ea2\u5916\u9ad8\u5149\u8c31\u6210\u50cf\u6846\u67b6\uff0c\u7ed3\u5408\u8bbe\u8ba1\u7684\u884c\u6d41\u5149\u5b66\u5143\u4ef6\u548cNIRSA-Net\u7f51\u7edc\uff0c\u5728700-1000nm\u6ce2\u957f\u8303\u56f4\u5185\u5b9e\u73b010nm\u5206\u8fa8\u7387\u7684\u9ad8\u6027\u80fd\u8c31\u50cf\u6210\u50cf", "motivation": "\u89e3\u51b3\u8fd1\u7ea2\u5916\u9ad8\u5149\u8c31\u6210\u50cf\u4e2d\u7684\u6280\u672f\u6311\u6218\uff0c\u63d0\u9ad8\u6210\u50cf\u8d28\u91cf\u548c\u5206\u8fa8\u7387", "method": "\u91c7\u7528\u8bbe\u8ba1\u7684\u884c\u6d41\u5149\u5b66\u5143\u4ef6(DOE)\u4e0eNIRSA-Net\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u76f8\u7ed3\u5408\u7684\u96c6\u6210\u5feb\u7167\u65b9\u6848", "result": "\u5728700-1000nm\u6ce2\u957f\u8303\u56f4\u5b9e\u73b0\u4e8610nm\u5206\u8fa8\u7387\u7684\u8c31\u50cf\u6210\u50cf\uff0cPSNR\u63d0\u9ad81.47dB\uff0cSSIM\u63d0\u9ad80.006", "conclusion": "\u8be5\u96c6\u6210\u6846\u67b6\u80fd\u591f\u5728\u8fd1\u7ea2\u5916\u533a\u57df\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u9ad8\u6027\u80fd\u7684\u5feb\u7167\u9ad8\u5149\u8c31\u6210\u50cf"}}
{"id": "2508.14753", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14753", "abs": "https://arxiv.org/abs/2508.14753", "authors": ["Ahsan Nazar", "Zhambyl Shaikhanov", "Sennur Ulukus"], "title": "Full-Duplex Beamforming Optimization for Near-Field ISAC", "comment": null, "summary": "Integrated Sensing and Communications (ISAC) is a promising technology for\nfuture wireless networks, enabling simultaneous communication and sensing using\nshared resources. This paper investigates the performance of full-duplex (FD)\ncommunication in near-field ISAC systems, where spherical-wave propagation\nintroduces unique beam-focusing capabilities. We propose a joint optimization\nframework for transmit and receive beamforming at the base station to minimize\ntransmit power while satisfying rate constraints for multi-user downlink\ntransmission, multi-user uplink reception, and multi-target sensing. Our\napproach employs alternating optimization combined with semidefinite relaxation\nand Rayleigh quotient techniques to address the non-convexity of the problem.\nSimulation results demonstrate that FD-enabled near-field ISAC achieves\nsuperior power efficiency compared to half-duplex and far-field benchmarks,\neffectively detecting targets at identical angles while meeting communication\nrequirements.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5168\u53cc\u5de5\u8fd0\u884c\u5728\u8fd1\u573a\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u805a\u7126\u7279\u6027\u63d0\u5347\u529f\u8017\u6548\u7387\u548c\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u662f\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\uff0c\u800c\u8fd1\u573a\u6ce2\u4f20\u64ad\u7684\u7403\u9762\u6ce2\u7279\u6027\u4e3a\u5168\u53cc\u5de5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u805a\u7126\u80fd\u529b\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u6ee1\u8db3\u591a\u7528\u6237\u901a\u4fe1\u548c\u591a\u76ee\u6807\u611f\u77e5\u8981\u6c42\u7684\u540c\u65f6\u6700\u5c0f\u5316\u53d1\u5c04\u529f\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u805a\u5408\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u7ed3\u5408\u534a\u6b63\u5b9a\u677e\u5f1b\u548cRayleigh\u5546\u7b97\u6cd5\u6765\u5904\u7406\u975e\u51f8\u6027\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u57fa\u7ad9\u53d1\u5c04\u548c\u63a5\u6536\u6ce2\u675f\u5f62\u6210\u7684\u805a\u5408\u8bbe\u8ba1\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5168\u53cc\u5de5\u8fd0\u884c\u7684\u8fd1\u573aISAC\u7cfb\u7edf\u5728\u529f\u8017\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u534a\u53cc\u5de5\u548c\u8fdc\u573a\u5bf9\u7167\u7ec4\uff0c\u80fd\u591f\u5728\u6ee1\u8db3\u901a\u4fe1\u8981\u6c42\u7684\u540c\u65f6\u6709\u6548\u68c0\u6d4b\u76f8\u540c\u89d2\u5ea6\u7684\u76ee\u6807\u3002", "conclusion": "\u5168\u53cc\u5de5\u8fd0\u884c\u7684\u8fd1\u573aISAC\u7cfb\u7edf\u901a\u8fc7\u6ce2\u675f\u805a\u7126\u7279\u6027\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u529f\u8017\u6548\u7387\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14681", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14681", "abs": "https://arxiv.org/abs/2508.14681", "authors": ["Hyun-Jic Oh", "Junsik Kim", "Zhiyi Shi", "Yichen Wu", "Yu-An Chen", "Peter K. Sorger", "Hanspeter Pfister", "Won-Ki Jeong"], "title": "Virtual Multiplex Staining for Histological Images using a Marker-wise Conditioned Diffusion Model", "comment": null, "summary": "Multiplex imaging is revolutionizing pathology by enabling the simultaneous\nvisualization of multiple biomarkers within tissue samples, providing\nmolecular-level insights that traditional hematoxylin and eosin (H&E) staining\ncannot provide. However, the complexity and cost of multiplex data acquisition\nhave hindered its widespread adoption. Additionally, most existing large\nrepositories of H&E images lack corresponding multiplex images, limiting\nopportunities for multimodal analysis. To address these challenges, we leverage\nrecent advances in latent diffusion models (LDMs), which excel at modeling\ncomplex data distributions utilizing their powerful priors for fine-tuning to a\ntarget domain. In this paper, we introduce a novel framework for virtual\nmultiplex staining that utilizes pretrained LDM parameters to generate\nmultiplex images from H&E images using a conditional diffusion model. Our\napproach enables marker-by-marker generation by conditioning the diffusion\nmodel on each marker, while sharing the same architecture across all markers.\nTo tackle the challenge of varying pixel value distributions across different\nmarker stains and to improve inference speed, we fine-tune the model for\nsingle-step sampling, enhancing both color contrast fidelity and inference\nefficiency through pixel-level loss functions. We validate our framework on two\npublicly available datasets, notably demonstrating its effectiveness in\ngenerating up to 18 different marker types with improved accuracy, a\nsubstantial increase over the 2-3 marker types achieved in previous approaches.\nThis validation highlights the potential of our framework, pioneering virtual\nmultiplex staining. Finally, this paper bridges the gap between H&E and\nmultiplex imaging, potentially enabling retrospective studies and large-scale\nanalyses of existing H&E image repositories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u6269\u6563\u6a21\u578b\u7684\u865a\u62df\u591a\u91cd\u67d3\u8272\u6846\u67b6\uff0c\u80fd\u591f\u4eceH&E\u56fe\u50cf\u751f\u6210\u591a\u8fbe18\u79cd\u4e0d\u540c\u6807\u8bb0\u7684\u591a\u91cd\u6210\u50cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u591a\u91cd\u6210\u50cf\u6280\u672f\u867d\u7136\u80fd\u63d0\u4f9b\u5206\u5b50\u6c34\u5e73\u7684\u7ec4\u7ec7\u6837\u672c\u4fe1\u606f\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u83b7\u53d6\u590d\u6742\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u540c\u65f6\uff0c\u73b0\u6709\u7684\u5927\u91cfH&E\u56fe\u50cf\u7f3a\u4e4f\u5bf9\u5e94\u7684\u591a\u91cd\u56fe\u50cf\uff0c\u5236\u7ea6\u4e86\u591a\u6a21\u6001\u5206\u6790\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\u53c2\u6570\uff0c\u6784\u5efa\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4eceH&E\u56fe\u50cf\u751f\u6210\u591a\u91cd\u56fe\u50cf\u3002\u91c7\u7528\u9010\u6807\u8bb0\u751f\u6210\u7b56\u7565\uff0c\u901a\u8fc7\u5355\u6b65\u91c7\u6837\u5fae\u8c03\u6a21\u578b\uff0c\u4f7f\u7528\u50cf\u7d20\u7ea7\u635f\u5931\u51fd\u6570\u63d0\u5347\u989c\u8272\u5bf9\u6bd4\u5ea6\u4fdd\u771f\u5ea6\u548c\u63a8\u7406\u6548\u7387\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u591a\u8fbe18\u79cd\u4e0d\u540c\u6807\u8bb0\u7c7b\u578b\uff0c\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff0c\u8fdc\u8d85\u4e4b\u524d\u65b9\u6cd5\u53ea\u80fd\u751f\u62102-3\u79cd\u6807\u8bb0\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5f25\u5408\u4e86H&E\u6210\u50cf\u4e0e\u591a\u91cd\u6210\u50cf\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u56de\u987e\u6027\u7814\u7a76\u548c\u73b0\u6709H&E\u56fe\u50cf\u5e93\u7684\u5927\u89c4\u6a21\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u5f00\u521b\u4e86\u865a\u62df\u591a\u91cd\u67d3\u8272\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.14884", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.14884", "abs": "https://arxiv.org/abs/2508.14884", "authors": ["Brian Kim", "Justin H. Kong", "Terrence J. Moore", "Fikadu T. Dagefu"], "title": "Deep Reinforcement Learning Based Routing for Heterogeneous Multi-Hop Wireless Networks", "comment": null, "summary": "Routing in multi-hop wireless networks is a complex problem, especially in\nheterogeneous networks where multiple wireless communication technologies\ncoexist. Reinforcement learning (RL) methods, such as Q-learning, have been\nintroduced for decentralized routing by allowing nodes to make decisions based\non local observations. However, Q-learning suffers from scalability issues and\npoor generalization due to the difficulty in managing the Q-table in large or\ndynamic network topologies, especially in heterogeneous networks (HetNets) with\ndiverse channel characteristics. Thus, in this paper, we propose a novel deep\nQ-network (DQN)-based routing framework for heterogeneous multi-hop wireless\nnetworks to maximize the end-to-end rate of the route by improving scalability\nand adaptability, where each node uses a deep neural network (DNN) to estimate\nthe Q-values and jointly select the next-hop relay and a communication\ntechnology for transmission. To achieve better performance with the DNN,\nselecting which nodes to exchange information is critical, as it not only\ndefines the state and action spaces but also determines the input to the DNN.\nTo this end, we propose neighbor node selection strategies based on channel\ngain and rate between nodes rather than a simple distance-based approach for an\nimproved set of states and actions for DQN-based routing. During training, the\nmodel experiences diverse network topologies to ensure generalization and\nrobustness, and simulation results show that the proposed neighbor node\nselection outperforms simple distance-based selection. Further, we observe that\nthe DQN-based approach outperforms various benchmark schemes and performs\ncomparably to the optimal approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6Q\u7f51\u7edc(DQN)\u7684\u8def\u7531\u6846\u67b6\uff0c\u7528\u4e8e\u5f02\u6784\u591a\u8df3\u65e0\u7ebf\u7f51\u7edc\uff0c\u901a\u8fc7\u6539\u8fdb\u90bb\u5c45\u8282\u70b9\u9009\u62e9\u7b56\u7565\u6765\u63d0\u5347\u7aef\u5230\u7aef\u901f\u7387\u548c\u7f51\u7edc\u53ef\u6269\u5c55\u6027", "motivation": "\u4f20\u7edfQ\u5b66\u4e60\u5728\u5f02\u6784\u7f51\u7edc\u4e2d\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6216\u52a8\u6001\u62d3\u6251\u7f51\u7edc\u4e2d\u7ba1\u7406Q\u8868\u56f0\u96be", "method": "\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f30\u8ba1Q\u503c\uff0c\u8054\u5408\u9009\u62e9\u4e0b\u4e00\u8df3\u4e2d\u7ee7\u548c\u901a\u4fe1\u6280\u672f\uff1b\u63d0\u51fa\u57fa\u4e8e\u4fe1\u9053\u589e\u76ca\u548c\u901f\u7387\u7684\u90bb\u5c45\u8282\u70b9\u9009\u62e9\u7b56\u7565\uff0c\u800c\u975e\u7b80\u5355\u8ddd\u79bb\u57fa\u51c6", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u90bb\u5c45\u8282\u70b9\u9009\u62e9\u7b56\u7565\u4f18\u4e8e\u7b80\u5355\u8ddd\u79bb\u57fa\u51c6\u65b9\u6cd5\uff0cDQN\u65b9\u6cd5\u5728\u5404\u79cd\u57fa\u51c6\u65b9\u6848\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\u65b9\u6cd5", "conclusion": "DQN-based\u8def\u7531\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f02\u6784\u591a\u8df3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u8def\u7531\u95ee\u9898\uff0c\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u6027\u80fd\u8868\u73b0"}}
{"id": "2508.14708", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14708", "abs": "https://arxiv.org/abs/2508.14708", "authors": ["Robert Graf", "Tanja Lerchl", "Kati Nispel", "Hendrik M\u00f6ller", "Matan Atad", "Julian McGinnis", "Julius Maria Watrinet", "Johannes Paetzold", "Daniel Rueckert", "Jan S. Kirschke"], "title": "Rule-based Key-Point Extraction for MR-Guided Biomechanical Digital Twins of the Spine", "comment": null, "summary": "Digital twins offer a powerful framework for subject-specific simulation and\nclinical decision support, yet their development often hinges on accurate,\nindividualized anatomical modeling. In this work, we present a rule-based\napproach for subpixel-accurate key-point extraction from MRI, adapted from\nprior CT-based methods. Our approach incorporates robust image alignment and\nvertebra-specific orientation estimation to generate anatomically meaningful\nlandmarks that serve as boundary conditions and force application points, like\nmuscle and ligament insertions in biomechanical models. These models enable the\nsimulation of spinal mechanics considering the subject's individual anatomy,\nand thus support the development of tailored approaches in clinical diagnostics\nand treatment planning. By leveraging MR imaging, our method is radiation-free\nand well-suited for large-scale studies and use in underrepresented\npopulations. This work contributes to the digital twin ecosystem by bridging\nthe gap between precise medical image analysis with biomechanical simulation,\nand aligns with key themes in personalized modeling for healthcare.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684MRI\u4e9a\u50cf\u7d20\u7cbe\u5ea6\u5173\u952e\u70b9\u63d0\u53d6\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u4e2a\u6027\u5316\u7684\u810a\u67f1\u751f\u7269\u529b\u5b66\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u652f\u6301\u65e0\u8f90\u5c04\u7684\u4e34\u5e8a\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u9700\u8981\u51c6\u786e\u7684\u4e2a\u6027\u5316\u89e3\u5256\u5efa\u6a21\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56CT\u6210\u50cf\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u57fa\u4e8eMRI\u7684\u65e0\u8f90\u5c04\u65b9\u6cd5\uff0c\u4e3a\u5927\u89c4\u6a21\u7814\u7a76\u548c\u7279\u6b8a\u4eba\u7fa4\u63d0\u4f9b\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u4ece\u5148\u524d\u7684CT\u65b9\u6cd5\u6539\u8fdb\u800c\u6765\uff0c\u5305\u542b\u9c81\u68d2\u7684\u56fe\u50cf\u914d\u51c6\u548c\u690e\u9aa8\u7279\u5f02\u6027\u65b9\u5411\u4f30\u8ba1\uff0c\u751f\u6210\u89e3\u5256\u5b66\u4e0a\u6709\u610f\u4e49\u7684\u5173\u952e\u70b9\u4f5c\u4e3a\u751f\u7269\u529b\u5b66\u6a21\u578b\u7684\u8fb9\u754c\u6761\u4ef6\u548c\u529b\u4f5c\u7528\u70b9\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4eceMRI\u4e2d\u63d0\u53d6\u4e9a\u50cf\u7d20\u7cbe\u5ea6\u7684\u5173\u952e\u70b9\uff0c\u80fd\u591f\u6784\u5efa\u8003\u8651\u4e2a\u4f53\u89e3\u5256\u7ed3\u6784\u7684\u810a\u67f1\u529b\u5b66\u4eff\u771f\u6a21\u578b\uff0c\u652f\u6301\u4e2a\u6027\u5316\u4e34\u5e8a\u65b9\u6cd5\u5f00\u53d1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u586b\u8865\u4e86\u7cbe\u786e\u533b\u5b66\u56fe\u50cf\u5206\u6790\u4e0e\u751f\u7269\u529b\u5b66\u4eff\u771f\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u533b\u7597\u4fdd\u5065\u4e2a\u6027\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u65e0\u8f90\u5c04\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u5927\u89c4\u6a21\u5e94\u7528\u548c\u7279\u6b8a\u4eba\u7fa4\u4f7f\u7528\u3002"}}
