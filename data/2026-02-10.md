<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 38]
- [cs.IT](#cs.IT) [Total: 22]
- [eess.IV](#eess.IV) [Total: 15]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2602.06982)
*Pujitha Mamillapalli,Shikhar Verma,Tiago Koketsu Rodrigues,Abhinav Kumar*

Main category: eess.SP

TL;DR: 提出基于深度确定性策略梯度（DDPG）的RIS辅助HAPS-SAGIN框架，优化波束赋形以抑制跨层干扰，相比传统ZF波束赋形提升吞吐量达11.3%。


<details>
  <summary>Details</summary>
Motivation: 6G天地一体化网络（SAGIN）中，高空平台（HAPS）与地面系统频谱共享导致严重的跨层干扰，特别是HAPS卫星上行与地面下行之间的频率共享受天线后瓣干扰影响。现有零迫（ZF）码书方法在高度动态信道条件下性能有限。

Method: 采用可重构智能表面（RIS）辅助的HAPS-SAGIN框架，结合深度确定性策略梯度（DDPG）算法。DDPG框架优化HAPS波束赋形权重，在干扰源方向形成空间零陷，同时保持对期望信号的鲁棒链路。

Result: 仿真结果表明，DDPG框架在不同RIS配置下均优于传统ZF波束赋形，在4×4 RIS配置下实现高达11.3%的吞吐量提升，验证了其在动态HAPS-SAGIN中增强频谱效率的自适应能力。

Conclusion: 提出的DDPG框架能有效解决HAPS-SAGIN中的跨层干扰问题，通过自适应波束赋形优化显著提升系统性能，为6G天地一体化网络的频谱高效利用提供了有前景的解决方案。

Abstract: Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \(11.3\%\) throughput improvement for a \(4\times4\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.

</details>


### [2] [Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing](https://arxiv.org/abs/2602.06983)
*Alison M. Fernandes,Hermes I. Del Monego,Bruno S. Chang,Anelise Munaretto,Hélder M. Fontes,Rui Campos*

Main category: eess.SP

TL;DR: 提出一种混合深度学习框架，通过多普勒轨迹提取增强特征，结合Inception网络和BiLSTM进行时空特征学习，最后用SVM分类，显著提升了带宽受限Wi-Fi环境中基于CSI的人体活动识别鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限Wi-Fi传感环境中基于CSI的人体活动识别鲁棒性不足的问题，特别是在低带宽场景下现有深度学习方法性能下降明显。

Method: 1. 多普勒轨迹提取阶段：放大运动相关信号特征；2. 混合神经网络架构：Inception网络提取层次空间特征，BiLSTM网络捕捉时间依赖关系；3. SVM作为最终分类层优化决策边界。

Result: 在20、40、80 MHz带宽配置下分别达到89.27%、94.13%、95.30%的准确率，显著优于单独的深度学习基线方法，在低带宽场景中优势尤为明显。

Conclusion: 将多普勒特征工程与混合学习架构相结合，能够有效提升带宽受限无线传感应用中人体活动识别的可靠性。

Abstract: This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture, which integrates Inception networks responsible for hierarchical spatial feature extraction and Bidirectional Long Short-Term Memory (BiLSTM) networks that capture temporal dependencies. A Support Vector Machine (SVM) is then utilized as the final classification layer to optimize decision boundaries. The framework's efficacy was systematically validated using a public dataset across 20, 40, and 80 MHz bandwidth configurations. The model yielded accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), respectively. These results confirm a marked superiority over standalone deep learning baselines, especially in the most constrained low-bandwidth scenarios. This study underscores the utility of combining Doppler-based feature engineering with a hybrid learning architecture for reliable HAR in bandwidth-limited wireless sensing applications.

</details>


### [3] [A Pre-trained EEG-to-MEG Generative Framework for Enhancing BCI Decoding](https://arxiv.org/abs/2602.06990)
*Zhuo Li,Shuqiang Wang*

Main category: eess.SP

TL;DR: 提出首个基于EEG-MEG时空耦合表示的跨模态生成框架，通过EEG信号合成MEG信号，以低成本方式获取MEG数据，提升BCI解码性能。


<details>
  <summary>Details</summary>
Motivation: MEG在脑机接口中具有重要价值，但成本高、便携性差，限制了其实际应用。EEG成本低、便携性好，但信号质量相对较低。需要一种方法能够结合两者优势，克服MEG数据获取的瓶颈。

Method: 1. 使用预训练的EEG模型提取通用神经活动表示；2. 通过空间聚焦映射模块学习MEG的低空间分散特性；3. 通过宽带频谱校准模块学习MEG的高频敏感性；4. 基于这些表示合成MEG信号。

Result: 合成的MEG信号在时频特性和源空间激活模式上与真实MEG高度一致。下游BCI解码实验表明，使用合成MEG不仅能提升配对EEG-MEG数据集的性能，还能提升独立EEG-only数据集的性能。

Conclusion: 该框架为克服BCI中的数据瓶颈开辟了新途径，能够以低成本方式获取高质量的MEG数据，促进脑机接口技术的发展。

Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) play important and complementary roles in non-invasive brain-computer interface (BCI) decoding. However, compared to the low cost and portability of EEG, MEG is more expensive and less portable, which severely limits the practical application of MEG in BCI systems. To overcome this limitation, this study proposes the first cross-modal generation framework based on EEG-MEG spatiotemporal coupled representations to synthesize MEG signals cost-effectively. The framework first extracts general neural activity representations through a pre-trained EEG model. Building upon these representations, the framework effectively learns the lower spatial dispersion and higher high-frequency sensitivity of MEG via the spatial focus mapping module and the broadband spectral calibration module. Experimental results demonstrate that the synthesized MEG signals show high consistency with the real MEG in both time-frequency characteristics and source space activation patterns. More importantly, downstream BCI decoding experiments demonstrate that using synthesized MEG leads to performance enhancements not only on paired EEG-MEG datasets but also on independent EEG-only datasets. Overall, this framework opens a new avenue for overcoming data bottlenecks in BCI.

</details>


### [4] [Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach](https://arxiv.org/abs/2602.06997)
*Anindya Bhattacharjee,Nittya Ananda Biswas,K. A. Shahriar,Adib Rahman*

Main category: eess.SP

TL;DR: 首个将液态神经网络应用于EEG情绪识别的综合框架，结合卷积特征提取、可学习时间常数的液态神经网络和注意力引导融合，在PhyMER数据集上达到95.45%准确率。


<details>
  <summary>Details</summary>
Motivation: 生理信号（特别是EEG）具有非平稳、噪声大和个体依赖性等特点，使得情绪识别面临挑战。需要开发能够有效建模时序动态并融合多模态信息的先进方法。

Method: 提出多模态框架：1）卷积特征提取；2）具有可学习时间常数的液态神经网络；3）注意力引导融合机制；4）专用子网络处理EEG和辅助模态；5）共享自编码器融合模块学习判别性潜在表示。

Result: 在PhyMER数据集7类情绪识别任务中达到95.45%准确率，超越先前报告结果。时间注意力分析提供可解释性洞察，t-SNE可视化显示增强的类别可分性，统计分析证实网络自组织为具有专门功能的快慢神经元组。

Conclusion: 该研究首次成功将液态神经网络应用于EEG情绪识别，提出的框架能有效捕捉复杂情绪特征，提供可解释性洞察，并在性能上取得显著提升，为生理信号情绪识别提供了新方向。

Abstract: Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion to model temporal EEG dynamics with complementary peripheral physiological and personality features. Dedicated subnetworks are used to process EEG features and auxiliary modalities, and a shared autoencoder-based fusion module is used to learn discriminative latent representations before classification. Subject-dependent experiments conducted on the PhyMER dataset across seven emotional classes achieve an accuracy of 95.45%, surpassing previously reported results. Furthermore, temporal attention analysis provides interpretable insights into emotion-specific temporal relevance, and t-SNE visualizations demonstrate enhanced class separability, highlighting the effectiveness of the proposed approach. Finally, statistical analysis of temporal dynamics confirms that the network self-organizes into distinct functional groups with specialized fast and slow neurons, proving it independently tunes learnable time constants and memory dominance to effectively capture complex emotion artifacts.

</details>


### [5] [OTFS-based Integrated Positioning and Communication Systems with Low-Resolution ADCs](https://arxiv.org/abs/2602.07001)
*Yueyi Yang,Zeping Sui,Zilong Liu,Leila Musavian*

Main category: eess.SP

TL;DR: 提出基于OTFS的两阶段IPAC框架，在低分辨率ADC下实现定位与通信集成，通过上行定位估计信道参数，下行利用参数改进波束成形。


<details>
  <summary>Details</summary>
Motivation: 在现实低分辨率ADC约束下，需要设计有效的集成定位与通信系统，利用定位信息提升通信性能，同时评估ADC分辨率对系统的影响。

Method: 采用两阶段OTFS-IPAC框架：上行阶段使用空间平滑-MUSIC算法估计AoA，迭代干扰消除方案估计其他参数；下行阶段利用估计参数改进基站波束成形。

Result: 推导了信道参数和用户位置的CRLB；仿真表明改进上行定位可提升下行BER性能，但低分辨率ADC会导致OTFS-IPAC系统性能显著下降。

Conclusion: 提出的OTFS-IPAC框架在低分辨率ADC下有效，定位精度与通信性能相互促进，但ADC分辨率是系统性能的关键限制因素。

Abstract: This paper proposes a two-phase orthogonal time frequency space (OTFS)-based integrated positioning and communication (IPAC) framework under realistic low-resolution analog-to-digital converters (ADCs). In the uplink phase, the positioning signal is used to estimate channel parameters, which are subsequently used to determine the user's position. The spatial smoothing-multiple signal classification algorithm is introduced to estimate the angle-of-arrival, whereas an iterative interference cancellation scheme is conceived for the remaining parameters' estimation. The corresponding Cramer-Rao lower bounds of channel parameters and user position are also derived. During the downlink communication phase, the estimated parameters are exploited to improve beamforming at the base station. Simulation results evaluate the impact of ADC quantizer resolutions. Specifically, it is shown that enhanced downlink bit error rate performance can be achieved with improved uplink positioning, while the use of low-resolution ADCs induces noticeable performance degradation in the OTFS-IPAC system.

</details>


### [6] [Behavior Score Prediction in Resting-State Functional MRI by Deep State Space Modeling](https://arxiv.org/abs/2602.07131)
*Javier Salazar Cavazos,Maximillian Egan,Krisanne Litinas,Benjamin Hampstead,Scott Peltier*

Main category: eess.SP

TL;DR: 提出基于深度状态空间模型的框架，直接利用BOLD时间序列预测阿尔茨海默病行为评分，相比传统功能连接方法有更好预测性能


<details>
  <summary>Details</summary>
Motivation: 现有阿尔茨海默病早期临床评估主要依赖行为评分，而静息态fMRI研究多使用功能连接矩阵，忽略了功能数据的时间动态特性

Method: 开发深度状态空间建模框架，直接处理BOLD时间序列，学习稀疏的大脑区域集合来预测行为评分，提取包含内在脑活动细微模式的时间特征

Result: 相比传统连接方法有更好的预测性能，识别出最能预测认知障碍的特定大脑区域，为早期阿尔茨海默病病理的神经基质提供新见解

Conclusion: 该方法对阿尔茨海默病风险监测和干预策略的发展具有重要意义，能够更好地捕捉脑活动的时间动态特征

Abstract: Early clinical assessment of Alzheimer's disease relies on behavior scores that measure a subject's language, memory, and cognitive skills. On the medical imaging side, functional magnetic resonance imaging has provided invaluable insights into the neural pathways underlying Alzheimer's disease. While prior studies have used resting-state functional MRI by extracting functional connectivity matrices, these approaches neglect the temporal dynamics inherent in functional data. In this work, we present a deep state space modeling framework that directly leverages the blood-oxygenation-level-dependent time series to learn a sparse collection of brain regions to predict behavior scores. Our model extracts temporal features that encapsulate nuanced patterns of intrinsic brain activity, thereby enhancing predictive performance compared to traditional connectivity methods. We identify specific brain regions that are most predictive of cognitive impairment through experiments on data provided by the Michigan Alzheimer's Disease Research Center, providing new insights into the neural substrates of early Alzheimer's pathology. These findings have important implications for the possible development of risk monitoring and intervention strategies in Alzheimer's disease.

</details>


### [7] [ML-Enabled Deformable Matched Filters for Bandlimitation Compensation in Free-Space Optics](https://arxiv.org/abs/2602.07169)
*Paul Anthony Haigh*

Main category: eess.SP

TL;DR: 提出一种神经网络辅助的可变形匹配滤波框架，用于带宽受限信道下的CAP调制系统，通过学习残差变形来补偿带宽引起的脉冲失真。


<details>
  <summary>Details</summary>
Motivation: 在带宽受限的信道条件下，CAP调制系统会遭受脉冲失真，传统的固定匹配滤波器性能受限。需要一种能够自适应补偿脉冲形状失真的接收机设计，同时避免复杂的决策反馈或增加接收延迟。

Method: 提出神经网络辅助的可变形匹配滤波框架：1）从接收波形中提取16个时域、频域和记忆相关的物理特征；2）使用全连接神经网络将这些特征映射到复数匹配滤波器系数；3）学习对名义匹配滤波器的残差变形；4）采用基于误差向量幅度（EVM）的可微分损失函数进行端到端训练。

Result: 在硬件在环CAP传输系统中的实验结果表明，在严重带宽约束下，所提出的可变形匹配滤波器显著优于传统的固定匹配滤波，且不需要决策反馈或增加接收延迟。

Conclusion: 该神经网络辅助的可变形匹配滤波框架能够有效补偿带宽引起的脉冲失真，提高CAP调制系统在带宽受限信道下的性能，同时保持了接收机的低延迟特性。

Abstract: This paper proposes a neural-network-assisted deformable matched filtering framework for carrier-less amplitude and phase (CAP) modulation operating under bandwidth-limited channel conditions. Instead of replacing the analytically derived CAP matched filter, the proposed receiver learns a residual deformation of the nominal matched filter based on a compact set of physically motivated signal features extracted from the received waveform. A total of 16 time-domain, frequency-domain, and memory-related features are used to provide a low-dimensional representation of bandwidth-induced pulse distortion. These features are mapped by a fully connected neural network to complex-valued matched filter coefficients, enabling adaptive pulse-shape compensation prior to symbol-rate sampling. The network is trained end-to-end using a differentiable loss function based on error vector magnitude (EVM). Experimental results obtained using a hardware-in-the-loop CAP transmission system demonstrate that the proposed deformable matched filter significantly outperforms conventional fixed matched filtering under severe bandwidth constraints, without requiring decision feedback or increasing receiver latency.

</details>


### [8] [Spectrum Coexistence, Network Dimensioning, and Cell-Free Architectures in 5G and 5G-Advanced Wireless Networks](https://arxiv.org/abs/2602.07270)
*Siminfar Samakoush Galougah*

Main category: eess.SP

TL;DR: 本文是一篇关于5G无线网络关键技术和设计挑战的综述，重点关注频谱共存与干扰管理、网络规划、无蜂窝大规模MIMO架构、前传感知用户管理和功率分配策略。


<details>
  <summary>Details</summary>
Motivation: 5G网络引入了新的架构范式、频谱使用模型和优化挑战，需要支持增强移动宽带、大规模机器类通信和超可靠低延迟通信。本文旨在全面概述5G系统的关键技术和设计挑战。

Method: 采用综述研究方法，回顾了代表性的分析方法、基于仿真的方法和优化驱动方法，突出了基本权衡关系。

Result: 提供了5G系统关键技术的全面概述，包括频谱共存与干扰管理、网络规划、无蜂窝大规模MIMO架构、前传感知用户管理和功率分配策略等方面的深入分析。

Conclusion: 本文识别了与5G-Advanced及后续技术相关的开放研究挑战，为未来研究提供了方向。

Abstract: Fifth-generation (5G) wireless networks introduce new architectural paradigms, spectrum usage models, and optimization challenges to support enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communications. This survey provides a comprehensive overview of key technologies and design challenges in 5G systems, with a focus on spectrum coexistence and interference management, network dimensioning and planning, cell-free massive MIMO architectures, fronthaul-aware user management, and power allocation strategies. Representative analytical, simulation-based, and optimization-driven approaches are reviewed, fundamental trade-offs are highlighted, and open research challenges relevant to 5G-Advanced and beyond are identified.

</details>


### [9] [Wireless Context Engineering for Efficient Mobile Agentic AI and Edge General Intelligence](https://arxiv.org/abs/2602.07321)
*Changyuan Zhao,Jiacheng Wang,Yunting Xu,Geng Sun,Dusit Niyato,Zan Li,Abbas Jamalipour,Dong In Kim*

Main category: eess.SP

TL;DR: 将大语言模型中的上下文工程概念扩展到无线系统，提出无线上下文工程框架，在有限推理资源下通过选择性结构化任务相关信息来提升边缘AI性能。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要强大的智能支持感知、通信和自主决策，但边缘部署受延迟、能耗和内存限制，无法无限扩展模型规模。因此需要最大化有限推理输入的有效性，通过过滤冗余观测、聚焦高价值数据来提升性能。

Method: 借鉴大语言模型中的上下文工程范式，将其扩展到无线系统，提出无线上下文通信框架（WCCF），自适应地在推理约束下编排无线上下文。通过案例研究（ISAC启用的波束预测）验证方法有效性。

Result: 无线上下文工程为无线边缘智能提供系统化方法，在不增加模型复杂度的前提下提升性能。案例研究表明，在受限感知预算下，该范式能有效提升波束预测性能。

Conclusion: 无线上下文工程为研究人员提供了管理无线边缘智能上下文的基础视角和实用设计维度，为解决边缘AI部署中的资源约束问题提供了新思路。

Abstract: Future wireless networks demand increasingly powerful intelligence to support sensing, communication, and autonomous decision-making. While scaling laws suggest improving performance by enlarging model capacity, practical edge deployments are fundamentally constrained by latency, energy, and memory, making unlimited model scaling infeasible. This creates a critical need to maximize the utility of limited inference-time inputs by filtering redundant observations and focusing on high-impact data. In large language models and generative artificial intelligence (AI), context engineering has emerged as a key paradigm to guide inference by selectively structuring and injecting task-relevant information. Inspired by this success, we extend context engineering to wireless systems, providing a systematic way to enhance edge AI performance without increasing model complexity. In dynamic environments, for example, beam prediction can benefit from augmenting instantaneous channel measurements with contextual cues such as user mobility trends or environment-aware propagation priors. We formally introduce wireless context engineering and propose a Wireless Context Communication Framework (WCCF) to adaptively orchestrate wireless context under inference-time constraints. This work provides researchers with a foundational perspective and practical design dimensions to manage the wireless context of wireless edge intelligence. An ISAC-enabled beam prediction case study illustrates the effectiveness of the proposed paradigm under constrained sensing budgets.

</details>


### [10] [Pulse Shaping Filter Design for Zak-OTFS](https://arxiv.org/abs/2602.07350)
*Kecheng Zhang,Weijie Yuan,Yonghui Li*

Main category: eess.SP

TL;DR: 论文提出了一种基于Zak变换的正交时频空间(Zak-OTFS)系统，通过设计新的脉冲成形滤波器来改善高移动性通信中的信道估计精度。


<details>
  <summary>Details</summary>
Motivation: Zak-OTFS系统理论上可以通过一个导频符号准确估计信道，但实际中脉冲成形滤波器会导致有效信道响应扩散，限制了信道估计精度。

Method: 首先推导离散时间过采样Zak-OTFS的输入输出关系，分析窗口模糊函数的影响，然后提出在IOTA框架内合成PSWF的新型脉冲成形滤波器设计。

Result: 数值仿真表明，所提出的设计在高信噪比下比传统的根升余弦和矩形窗方案具有更优的信道估计精度和误码率性能。

Conclusion: 通过优化脉冲成形滤波器设计，可以有效抑制信道响应扩散，提升Zak-OTFS系统在高移动性通信中的信道估计性能。

Abstract: The Zak-transform-based Orthogonal Time Frequency Space (Zak-OTFS), offers a robust framework for high-mobility communications by simplifying the input-output (I/O) relation to a twisted convolution. While this structure theoretically enables accurate channel estimation by sampling the response from one pilot symbol, practical implementation is constrained by the spreading of effective channel response induced by pulse shaping filters. To address this, we first derive the I/O relationship for discrete-time oversampled Zak-OTFS, which closely approximates the continuous-time system and facilitates analysis and numerical simulation. We show that every delay-Doppler domain symbol undergoes the same effective channel response under the discrete oversampled Zak-OTFS. We then analyze the impact of window ambiguity functions, and reveal that high sidelobes lead to wide channel spreading and degrade estimation accuracy. Building on this insight, we propose a novel pulse shaping filter design that synthesizes Prolate Spheroidal Wave Functions (PSWFs) within the Isotropic Orthogonal Transform Algorithm (IOTA) framework. Numerical simulations confirm that the proposed design achieves superior channel estimation accuracy and bit error rate (BER) performance compared to conventional root-raised-cosine and rectangular windowing schemes in the high-SNR regime.

</details>


### [11] [Message Passing based Parameter Estimation in Cooperative MIMO-OFDM ISAC Systems](https://arxiv.org/abs/2602.07365)
*Xiaohan Lv,Rang Liu,Yi Chen,Qian Liu,Ming Li*

Main category: eess.SP

TL;DR: 提出一种基于消息传递的协作MIMO-OFDM ISAC系统参数估计框架，联合估计目标位置和速度，通过分层消息传递降低计算复杂度和通信开销。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信网络中，多个基站协作感知共同目标，利用多视角观测和联合信号处理提升感知性能，但现有方法面临高计算复杂度和通信开销的挑战。

Method: 基于几何关系建立信号传播模型，构建因子图表示未知参数，应用和积算法进行联合估计，采用高斯近似的分层消息传递方案，通过参数化消息分布和分层处理降低复杂度。

Result: 仿真结果表明所提消息传递参数估计算法有效，多视角观测和联合信号处理在协作感知中带来显著性能优势，同时显著降低了计算复杂度和基站间通信开销。

Conclusion: 提出的消息传递框架为协作MIMO-OFDM ISAC系统提供了一种高效参数估计方案，在保持感知性能的同时有效解决了计算和通信开销问题。

Abstract: In integrated sensing and communication (ISAC) networks, multiple base stations (BSs) collaboratively sense a common target, leveraging diversity from multiple observation perspectives and joint signal processing to enhance sensing performance. This paper introduces a novel message-passing (MP)-based parameter estimation framework for collaborative MIMO-OFDM ISAC systems, which jointly estimates the target's position and velocity. First, a signal propagation model is established based on geometric relationships, and a factor graph is constructed to represent the unknown parameters. The sum-product algorithm (SPA) is then applied to this factor graph to jointly estimate the multi-dimensional parameter vector. To reduce communication overhead and computational complexity, we employ a hierarchical message-passing scheme with Gaussian approximation. By adopting parameterized message distributions and layered processing, the proposed method significantly reduces both computational complexity and inter-BS communication overhead. Simulation results demonstrate the effectiveness of the proposed MP-based parameter estimation algorithm and highlight the benefits of multi-perspective observations and joint signal processing for cooperative sensing in MIMO-OFDM ISAC systems.

</details>


### [12] [Optimal Low-Dimensional Structures of ISAC Beamforming: Theory and Efficient Algorithms](https://arxiv.org/abs/2602.07502)
*Xiaotong Zhao,Mian Li,Ya-Feng Liu,Qingjiang Shi,Anthony Man-Cho So*

Main category: eess.SP

TL;DR: 该论文证明了ISAC波束成形问题存在低维结构的最优解，提出了基于此的等效重构问题，并开发了低复杂度算法，在大量天线场景下实现高达万倍加速。


<details>
  <summary>Details</summary>
Motivation: ISAC系统中波束成形设计是核心问题，现有方法计算复杂度随基站天线数量快速增长，难以适用于大规模MIMO场景。

Method: 首先证明ISAC波束成形问题存在低维结构的最优解，将问题重构为维度与用户数相关的等效问题；然后开发平衡增广拉格朗日方法求解重构问题。

Result: 当基站天线数远大于用户数时，内点法复杂度降低6个数量级；提出的R-BAL方法在保持最优性的同时，计算复杂度仅随用户数四次方增长，在大规模MIMO场景下实现超过10000倍的加速。

Conclusion: 通过揭示ISAC波束成形问题的低维结构特性，成功开发了适用于大规模MIMO的高效算法，显著降低了计算复杂度，为实际系统部署提供了可行方案。

Abstract: Transmit beamforming design is a fundamental problem in integrated sensing and communication (ISAC) systems. Numerous methods have been proposed to jointly optimize key performance metrics such as the signal-to-interference-plus-noise ratio and Cramér-Rao bound. However, the computational complexity of these methods often grows rapidly with the number of transmit antennas at the base station (BS). To tackle this challenge, we prove a fundamental structural property of the ISAC beamforming problem, i.e., there exists an optimal solution exhibiting a low-dimensional structure. This leads to an equivalent reformulation of the problem with dimension related to the number of users rather than the number of BS antennas, thereby enabling the development of low-complexity algorithms. When applying the interior-point method to the reformulated problem, we achieve up to six orders of magnitude in complexity reduction when the number of antennas exceeds the number of users by an order of magnitude. To further reduce the complexity, we develop a balanced augmented Lagrangian method to solve the reformulated problem. The proposed algorithm maintains optimality while achieving a computational complexity that scales quartically with the number of users. Our simulation results demonstrate that the proposed R-BAL method can achieve a speedup of more than 10000$\times$ over the conventional IPM in massive MIMO scenarios.

</details>


### [13] [Beyond $λ/2$: Can Arbitrary EMVS Arrays Achieve Unambiguous NLOS Localization?](https://arxiv.org/abs/2602.07515)
*Hua Chen,Zhenhao Yu,Tuo Wu,Wei Liu,Maged Elkashlan,Hyundong Shin,Matthew C. Valenti,Robert Schober*

Main category: eess.SP

TL;DR: 该论文提出了一种利用电磁矢量传感器(EMVS)阵列实现超半波长间距的无模糊定位方法，通过PARAFAC模型和相位解缠技术解决空间模糊问题，并结合RIS优化增强NLOS环境下的定位性能。


<details>
  <summary>Details</summary>
Motivation: 传统雷达阵列设计要求阵元间距不超过半波长以避免空间模糊，这限制了阵列孔径和角度分辨率。论文旨在探索在EMVS阵列中，当阵元间距超过半波长时，是否仍能实现无模糊的RIS辅助定位。

Method: 1) 构建基于EMVS观测的三阶PARAFAC模型，利用TALS算法分离空间、极化和传播效应；2) 提出相位解缠方法，利用EMVS六个电磁分量的旋转不变性解决任意阵列几何中的2π相位缠绕问题；3) 结合RIS并通过SDP松弛优化其相位偏移，迭代提升信噪比和抑制空间模糊。

Result: 证明了EMVS阵列在超半波长间距下仍能实现无模糊的2-D DOD、2-D DOA和极化参数联合估计，并自动完成参数配对。RIS优化进一步提高了NLOS环境下的信号功率和定位鲁棒性。

Conclusion: 该研究成功回答了核心问题：通过利用EMVS的多分量结构和PARAFAC建模，结合相位解缠和RIS优化，可以在任意EMVS阵列中实现超半波长间距的无模糊RIS辅助定位，突破了传统阵列设计的限制。

Abstract: Conventional radar array design mandates interelement spacing not exceeding half a wavelength ($λ/2$) to avoid spatial ambiguity, fundamentally limiting array aperture and angular resolution. This paper addresses the fundamental question: Can arbitrary electromagnetic vector sensor (EMVS) arrays achieve unambiguous reconfigurable intelligent surface (RIS)-aided localization when element spacing exceeds $λ/2$? We provide an affirmative answer by exploiting the multi-component structure of EMVS measurements and developing a synergistic estimation and optimization framework for non-line-of-sight (NLOS) bistatic multiple input multiple output (MIMO) radar. A third-order parallel factor (PARAFAC) model is constructed from EMVS observations, enabling natural separation of spatial, polarimetric, and propagation effects via the trilinear alternating least squares (TALS) algorithm. A novel phase-disambiguation procedure leverages rotational invariance across the six electromagnetic components of EMVSs to resolve $2π$ phase wrapping in arbitrary array geometries, allowing unambiguous joint estimation of two-dimensional (2-D) direction of departure (DOD), two-dimensional direction of arrival (DOA), and polarization parameters with automatic pairing. To support localization in NLOS environments and enhance estimation robustness, a reconfigurable intelligent surface (RIS) is incorporated and its phase shifts are optimized via semidefinite programming (SDP) relaxation to maximize received signal power, improving signal-to-noise ratio (SNR) and further suppressing spatial ambiguities through iterative refinement.

</details>


### [14] [Fractional Filtering and Anomaly-Guided Diagnostics: The Local Damage Mode Extractor (LDME) for Early Gear Fault Detection](https://arxiv.org/abs/2602.07527)
*Yaakoub Berrouche*

Main category: eess.SP

TL;DR: LDME是一个无监督的物理信息信号处理框架，通过双路径去噪、多尺度分解、分数域增强和统计异常评分，用于齿轮故障的早期可靠检测。


<details>
  <summary>Details</summary>
Motivation: 复杂传动系统中齿轮故障的早期可靠检测对航空安全和运行可用性至关重要，需要无监督、可解释的故障检测方法。

Method: 三层结构：1) 双路径去噪（DWT+自适应Savitzky-Golay平滑）；2) 多尺度损伤增强（Teager-Kaiser预放大器+Hadamard-Caputo分数算子）；3) 决策融合（谐波感知傅里叶指标+无监督异常检测器）。

Result: 在CWRU轴承数据集、HUMS 2023行星齿轮箱基准和模拟数据集上，LDME能一致区分正常、早期裂纹和扩展裂纹阶段，比HT-TSA提前86个周期检测到主要故障事件，维护建议时间提前18个周期。

Conclusion: LDME提供了一个结构化的物理信息信号处理框架，能够实现无监督、可解释的齿轮故障早期检测，在多个数据集上表现出优越性能，代码开源确保可复现性。

Abstract: Early and reliable detection of gear faults in complex drivetrain systems is critical for aviation safety and operational availability. We present the Local Damage Mode Extractor (LDME), a structured, physics-informed signal processing framework that combines dual-path denoising, multiscale decomposition, fractional-domain enhancement, and statistically principled anomaly scoring to produce interpretable condition indicators without supervision. LDME is organized in three layers: (i) dual-path denoising (DWT with adaptive Savitzky-Golay smoothing) to suppress broadband noise while preserving transient fault structure; (ii) multi-scale damage enhancement using a Teager-Kaiser pre-amplifier followed by a Hadamard-Caputo fractional operator that accentuates non-sinusoidal, low-frequency fault signatures; and (iii) decision fusion, where harmonics-aware Fourier indicators are combined and scored by an unsupervised anomaly detector. Evaluation using the Case Western Reserve University (CWRU) bearing dataset, the HUMS 2023 planetary gearbox benchmark, and a controlled simulated dataset shows that LDME consistently distinguishes nominal, early-crack, and propagated-crack stages under various operating conditions. LDME identifies the primary detection event earlier (198 cycles) than HT-TSA (284 cycles) and advances maintenance recommendation time from 383 to 365 cycles. We discuss its relation to prior art, limitations, and future theoretical directions. All code and experimental configurations are documented for reproducibility.

</details>


### [15] [A Scalable Cloud-Edge Collaborative CKM Construction Framework Enabled by a Foundation Prior Model](https://arxiv.org/abs/2602.07586)
*Sixu Xiao,Yong Zeng,Haotian Rong,Yanqun Tang*

Main category: eess.SP

TL;DR: 提出云边协同框架，通过解耦通用CKM先验与本地观测信息，实现可扩展的信道知识地图构建，降低训练成本并提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 实际部署中CKM观测数据存在噪声和不规则问题，传统端到端算法需要针对每个配置单独训练，成本高昂且难以适应可扩展的边缘部署需求。

Method: 开发云边协同框架，在云端使用无标签数据训练基础模型学习通用CKM先验，推理时边缘节点将共享先验与本地观测相结合。

Result: 在CKMImageNet数据集上的实验表明，该方法在保持竞争性构建精度的同时，显著降低训练成本和数据需求，减轻负迁移，在泛化和部署可扩展性方面具有明显优势。

Conclusion: 该云边协同框架通过知识共享机制，为6G网络中环境感知通信和感知提供了可扩展、成本效益高的CKM构建解决方案。

Abstract: Channel knowledge maps (CKMs) provide a site-specific, location-indexed knowledge base that supports environment-aware communications and sensing in 6G networks. In practical deployments, CKM observations are often noisy and irregular due to coverage-induced sparsity and hardware-induced linear/nonlinear degradations. Conventional end-to-end algorithms couple CKM prior information with task- and device-specific observations, and require labeled data and separate training for each construction configuration, which is expensive and therefore incompatible with scalable edge deployments. Motivated by the trends toward cloud-edge collaboration and the Artificial Intelligence - Radio Access Network (AI-RAN) paradigm, we develop a cloud-edge collaborative framework for scalable CKM construction, which enables knowledge sharing across tasks, devices, and regions by explicitly decoupling a generalizable CKM prior from the information provided by local observations. A foundation model is trained once in the cloud using unlabeled data to learn a generalizable CKM prior. During inference, edge nodes combine the shared prior with local observations. Experiments on the CKMImageNet dataset show that the proposed method achieves competitive construction accuracy while substantially reducing training cost and data requirements, mitigating negative transfer, and offering clear advantages in generalization and deployment scalability.

</details>


### [16] [A Tutorial on 3GPP Rel-19 Channel Modeling for 6G FR3 (7-24 GHz): From Standard Specification to Simulation Implementation](https://arxiv.org/abs/2602.07623)
*Pan Tang,Huixin Xu,Jianhua Zhang,Ximan Liu,Enrui Liu,Haiyang Miao,Xiaodong Sun,Wei Jiang,Guangyi Liu*

Main category: eess.SP

TL;DR: 3GPP Rel-19增强的6G FR3频段信道模型教程，针对7-24GHz频段和极大规模天线阵列特性


<details>
  <summary>Details</summary>
Motivation: 6G网络的FR3频段（7-24GHz）结合了覆盖范围和容量优势，但需要极大规模天线阵列补偿路径损耗。传统3GPP信道模型在该频段面临有效性挑战，需要更新以适应新的传播特性和物理范式转变。

Method: 提供3GPP Rel-19信道模型的综合指南：1）概述3GPP信道建模框架基本原理；2）详细说明Rel-19的具体增强和修改，包括新的郊区宏蜂窝场景、ELAA驱动的近场和空间非平稳性数学建模、大尺度参数重新校准。

Result: 通过大量新测量验证了模型，并引入了显著增强，为研究人员和工程师提供了掌握最新3GPP信道建模方法的指南。

Conclusion: 本教程填补了标准化规范与实际仿真实现之间的差距，为未来6G FR3网络的准确设计和性能评估奠定了坚实基础。

Abstract: The upper-mid band (7-24 GHz), designated as Frequency Range 3 (FR3), has emerged as a definitive ``golden band" for 6G networks, strategically balancing the wide coverage of sub-6 GHz with the high capacity of mmWave. To compensate for the severe path loss inherent to this band, the deployment of Extremely Large Aperture Arrays (ELAA) is indispensable. However, the legacy 3GPP TR 38.901 channel model faces critical validity challenges when applied to 6G FR3, stemming from both the distinct propagation characteristics of this frequency band and the fundamental physical paradigm shift induced by ELAA. In response, 3GPP Release 19 (Rel-19) has validated the model through extensive new measurements and introduced significant enhancements. This tutorial provides a comprehensive guide to the Rel-19 channel model for 6G FR3, bridging the gap between standardization specifications and practical simulation implementation. First, we provide a high-level overview of the fundamental principles of the 3GPP channel modeling framework. Second, we detail the specific enhancements and modifications introduced in Rel-19, including the rationale behind the new Suburban Macro (SMa) scenario, the mathematical modeling of ELAA-driven features such as near-field and spatial non-stationarity, and the recalibration of large-scale parameters. Overall, this tutorial serves as an essential guide for researchers and engineers to master the latest 3GPP channel modeling methodology, laying a solid foundation for the accurate design and performance evaluation of future 6G FR3 networks.

</details>


### [17] [MI-ISAC: Magneto-Inductive Integrated Sensing and Communication in the Reactive Near-Field for RF-Denied Environments](https://arxiv.org/abs/2602.07714)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: MI-ISAC利用磁感应近场准静态耦合，在RF受限环境中实现高精度感知通信一体化，相比传统RF-ISAC在导电介质环境中具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统射频集成感知通信(RF-ISAC)在地下、水下和体内等导电介质环境中效果不佳，电磁波衰减严重，需要新的解决方案。

Method: 提出磁感应ISAC(MI-ISAC)范式，利用磁感应链路的反应近场准静态耦合特性，通过三轴线圈实现联合距离-角度估计，利用耦合梯度而非飞行时间进行高精度测量。

Result: 建立了五个基础结果：三轴线圈可实现可识别联合估计；耦合强度随距离急剧变化，kHz带宽下可达亚毫米精度；耦合梯度比飞行时间分辨率高六个数量级；相比时分基线提供4-10+dB感知增益；MI-MIMO信道具有几何不变性和良好条件数。

Conclusion: MI-ISAC为RF受限环境中的感知通信一体化提供了新范式，具有高精度、几何不变性等优势，为地下、水下和体内应用开辟了新途径。

Abstract: Radio-frequency integrated sensing and communication (RF-ISAC) is ineffective inunderground, underwater, and in-body environments where conductive media attenuate electromagnetic waves by tens of dB per meter. This article presents magneto-inductive ISAC (MI-ISAC), a paradigm that exploits the reactive near-field quasi-static coupling inherent to MI links, enabling a fundamentally different approach to ISAC in these RF-denied environments. Five foundational results are established: (i)~tri-axial coils are necessary and sufficient for identifiable joint range-and-angle estimation; (ii)~coupling strength changes sharply with range, enabling theoretical sub-millimeter accuracy at typical MI distances despite kHz-level bandwidth; (iii)~time-of-flight is ineffective under such narrow bandwidth, but the coupling gradient provides approximately six orders of magnitude finer resolution; (iv)~MI-ISAC can provide 4--10+\,dB sensing gain over time-division baselines; and (v)~the MI-MIMO channel is geometry-invariant and well-conditioned across all orientations. Applications and a research roadmap are discussed.

</details>


### [18] [Joint Simplicial Complex Learning via Binary Linear Programming](https://arxiv.org/abs/2602.07896)
*Varun Sarathchandran,Geert Leus*

Main category: eess.SP

TL;DR: 提出一个联合框架，通过线性约束强制包含属性，将单纯复形学习问题表述为二元线性规划，同时估计边和高阶单纯形。


<details>
  <summary>Details</summary>
Motivation: 从数据中学习高阶网络拓扑是信号处理和机器学习中的基本挑战。单纯复形为建模多向交互提供了原则性框架，但由于包含属性在不同单纯层次之间施加的强耦合，学习其结构具有挑战性。

Method: 提出一个联合单纯复形学习框架，通过线性约束强制包含属性，将问题表述为二元线性规划。目标函数结合所有考虑单纯层次的平滑度度量，允许纳入任意平滑度准则。

Result: 在模拟和真实世界数据上的实验表明，所提出的联合方法优于分层和贪婪基线，同时更忠实地执行高阶结构先验。

Conclusion: 该工作提供了一个有效的联合框架，用于同时学习单纯复形的不同层次结构，解决了高阶网络拓扑学习中的关键挑战。

Abstract: Learning the topology of higher-order networks from data is a fundamental challenge in many signal processing and machine learning applications. Simplicial complexes provide a principled framework for modeling multi-way interactions, yet learning their structure is challenging due to the strong coupling across different simplicial levels imposed by the inclusion property. In this work, we propose a joint framework for simplicial complex learning that enforces the inclusion property through a linear constraint, enabling the formulation of the problem as a binary linear program. The objective function consists of a combination of smoothness measures across all considered simplicial levels, allowing for the incorporation of arbitrary smoothness criteria. This formulation enables the simultaneous estimation of edges and higher-order simplices within a single optimization problem. Experiments on simulated and real-world data demonstrate that the proposed joint approach outperforms hierarchical and greedy baselines, while more faithfully enforcing higher-order structural priors.

</details>


### [19] [End-to-End Secure Connection Probability in MultiLayer Networks with Heterogeneous Rician Fading](https://arxiv.org/abs/2602.07959)
*Hyeonsu Lyu,Yumin Kim,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 提出一种用于非地面网络的多跳中继路由端到端安全连接概率的闭式表达式，该表达式在异构莱斯衰落信道下具有解析可处理性，相比传统方法精度提升一倍。


<details>
  <summary>Details</summary>
Motivation: 非地面网络(NTNs)因其全球覆盖和多跳中继特性，在物理层安全方面面临挑战，特别是窃听者位置和信道未知的情况下，需要可靠的安全连接概率评估方法。

Method: 推导异构莱斯衰落信道下多跳中继路由端到端安全连接概率(SCP)的闭式表达式，该表达式与先前瑞利衰落近似具有相同函数形式但系数不同，为启发式后验系数校准提供理论支持。

Result: 数值实验表明，在大多数情况下该方案估计SCP的误差在1%以内；即使在最坏情况下，精度也比传统方案提高一倍。在实际空天地海一体化网络数据集上的案例研究显示，推导的SCP能准确捕捉实际环境中的安全趋势。

Conclusion: 提出的闭式表达式为异构莱斯衰落信道下的非地面网络安全连接概率提供了准确且可处理的评估框架，验证了先前启发式系数校准方法的有效性，并展示了在实际网络中的适用性。

Abstract: Ensuring physical-layer security in non-terrestrial networks (NTNs) is challenging due to their global coverage and multi-hop relaying across heterogeneous network layers, where the locations and channels of potential eavesdroppers are typically unknown. In this work, we derive a tractable closedform expression of the end-to-end secure connection probability (SCP) of multi-hop relay routes under heterogeneous Rician fading. The resulting formula shares the same functional form as prior Rayleigh-based approximations but for the coefficients, thereby providing analytical support for the effectiveness of heuristic posterior coefficient calibration adopted in prior work. Numerical experiments under various conditions show that the proposed scheme estimates the SCP with an 1%p error in most cases; and doubles the accuracy compared with the conventional scheme even in the worst case. As a case study, we apply the proposed framework to real-world space-air-groundsea integrated network dataset, showing that the derived SCP accurately captures observed security trends in practical settings.

</details>


### [20] [Code-Weight Sphere Decoding](https://arxiv.org/abs/2508.19631)
*Yubeen Jo,Geon Choi,Yongjune Kim,Namyoon Lee*

Main category: eess.SP

TL;DR: 提出一种适用于任意线性分组码的两阶段近最大似然解码框架，包含低复杂度初始解码器和基于码重球面解码的第二阶段，为URLLC系统提供可靠性与复杂度的良好折衷。


<details>
  <summary>Details</summary>
Motivation: URLLC在有限块长下需要高性能纠错码和解码器，现有解码方案在可靠性和复杂度之间存在权衡问题，需要一种能自适应调整计算开销的解决方案。

Method: 提出两阶段解码框架：第一阶段使用低复杂度初始解码器，若CRC校验失败则触发第二阶段——码重球面解码（WSD）。WSD利用预计算的低权重码字构建局部候选球面，迭代优化码字估计。

Result: 仿真表明该解码器在高信噪比下能自适应最小化计算开销，实现近ML性能（尤其对低码率码），在解码可靠性和复杂度间提供优异折衷。

Conclusion: 该两阶段解码框架是下一代URLLC系统的有前景解决方案，能平衡解码可靠性和计算复杂度，特别适合有限块长下的高性能通信需求。

Abstract: Ultra-reliable low-latency communications (URLLC) demand high-performance error-correcting codes and decoders in the finite blocklength regime. This letter introduces a novel two-stage near-maximum likelihood (near-ML) decoding framework applicable to any linear block code. Our approach first employs a low-complexity initial decoder. If this initial stage fails a cyclic redundancy check, it triggers a second stage: the proposed code-weight sphere decoding (WSD). WSD iteratively refines the codeword estimate by exploring a localized sphere of candidates constructed from pre-computed low-weight codewords. This strategy adaptively minimizes computational overhead at high signal-to-noise ratios while achieving near-ML performance, especially for low-rate codes. Extensive simulations demonstrate that our two-stage decoder provides an excellent trade-off between decoding reliability and complexity, establishing it as a promising solution for next-generation URLLC systems.

</details>


### [21] [Adjustment of Cluster-Then-Predict Framework for Multiport Scatterer Load Prediction](https://arxiv.org/abs/2602.08129)
*Hanjun Park,Aleksandr D. Kuznetsov,Ville Viikari*

Main category: eess.SP

TL;DR: 提出两阶段聚类-预测框架用于多端口散射体负载值预测，相比基线在梯度提升方法上实现RMSE降低46%，并引入RUI指标评估多目标权衡。


<details>
  <summary>Details</summary>
Motivation: 多端口散射体中负载值的相互依赖预测具有挑战性，因为存在高维度和阻抗与散射能力之间的复杂依赖关系，但这种预测对通信和测量系统设计至关重要。

Method: 提出两阶段"先聚类后预测"框架：首先对数据进行聚类，然后在每个聚类内进行回归预测。框架适用于多种聚类和回归方法组合。

Result: 在梯度提升方法上实现RMSE降低高达46%，改进在不同聚类和回归方法中表现一致。基于新提出的RUI指标，K-means聚类与KNN回归的组合被确定为最优配置。

Conclusion: 提出的两阶段框架能有效捕捉S参数与负载阻抗之间的函数关系，RUI指标为现实场景中多目标权衡的性能评估提供了有效工具。

Abstract: Predicting interdependent load values in multiport scatterers is challenging due to high dimensionality and complex dependence between impedance and scattering ability, yet this prediction remains crucial for the design of communication and measurement systems. In this paper, we propose a two-stage cluster-then-predict framework for multiple load values prediction task in multiport scatterers. The proposed cluster-then-predict approach effectively captures the underlying functional relation between S-parameters and corresponding load impedances, achieving up to a 46% reduction in Root Mean Square Error (RMSE) compared to the baseline when applied to gradient boosting (GB). This improvement is consistent across various clustering and regression methods. Furthermore, we introduce the Real-world Unified Index (RUI), a metric for quantitative analysis of trade-offs among multiple metrics with conflicting objectives and different scales, suitable for performance assessment in realistic scenarios. Based on RUI, the combination of K-means clustering and k-nearest neighbors (KNN) is identified as the optimal setup for the analyzed multiport scatterer.

</details>


### [22] [AFDM: Evolving OFDM Towards 6G+](https://arxiv.org/abs/2602.08163)
*Hyeon Seok Rou,Vincent Savaux,Zeping Sui,Giuseppe Thadeu Freitas de Abreu,Zilong Liu*

Main category: eess.SP

TL;DR: AFDM作为6G候选波形，在保持与OFDM高度兼容的同时，为高移动性通信和ISAC提供内在鲁棒性


<details>
  <summary>Details</summary>
Motivation: 6G标准化加速推进，业界倾向于采用既能提供新功能又能最大化与现有OFDM兼容性的演进波形，以支持高移动性通信和集成感知与通信

Method: 提出仿射频分复用(AFDM)技术，基于广义分数延迟-分数多普勒信道模型，重用OFDM处理流水线，仅需轻量级数字前后处理

Result: AFDM在射频、物理层和高层都具有高度可重用性，能够应对相位噪声和载波频率偏移等硬件损伤，支持索引调制和物理层安全等高级功能

Conclusion: AFDM为6G及6G+提供了一条低风险、功能丰富且高效的路径，能够实现高保真通信

Abstract: As the standardization of sixth generation (6G) wireless systems accelerates, there is a growing consensus in favor of evolutionary waveforms that offer new features while maximizing compatibility with orthogonal frequency division multiplexing (OFDM), which underpins the 4G and 5G systems. This article presents affine frequency division multiplexing (AFDM) as a premier candidate for 6G, offering intrinsic robustness for both high-mobility communications and integrated sensing and communication (ISAC) in doubly dispersive channels, while maintaining a high degree of synergy with the legacy OFDM. To this end, we provide a comprehensive analysis of AFDM, starting with a generalized fractional-delay-fractional-Doppler (FDFD) channel model that accounts for practical pulse shaping filters and inter-sample coupling. We then detail the AFDM transceiver architecture, demonstrating that it reuses nearly the entire OFDM pipeline and requires only lightweight digital pre- and post-processing. We also analyze the impact of hardware impairments, such as phase noise and carrier frequency offset, and explore advanced functionalities enabled by the chirp-parameter domain, including index modulation and physical-layer security. By evaluating the reusability across the radio-frequency, physical, and higher layers, the article demonstrates that AFDM provides a low-risk, feature-rich, and efficient path toward achieving high-fidelity communications in the later versions of 6G and beyond (6G+).

</details>


### [23] [An Experimental Study on Fine-Grained Bistatic Sensing of UAV Trajectory via Cellular Downlink Signals](https://arxiv.org/abs/2602.08203)
*Chenqing Ji,Jiahong Liu,Qionghui Liu,Yifei Sun,Chao Yu,Rui Wang*

Main category: eess.SP

TL;DR: 提出并演示了一种利用LTE下行信号的双双基地无人机跟踪系统，通过多角度多普勒测量实现高精度轨迹重建


<details>
  <summary>Details</summary>
Motivation: 传统无人机跟踪系统通常需要专用雷达或GPS，成本高且易受干扰。本文旨在利用广泛部署的LTE基站作为照射源，开发低成本、被动式的无人机跟踪方案

Method: 使用两个LTE基站作为照射源，在不同位置部署两个被动接收器。通过检测目标无人机在不同方向上的双基地多普勒频率，估计无人机随时间变化的速度，从而重建其轨迹

Result: 实验表明，当无人机与接收器距离小于30米时，对于90%的复杂轨迹，跟踪误差低于50厘米。这一精度显著优于LTE信号的测距分辨率

Conclusion: 通过多角度双基地多普勒测量，如果接收器部署密度足够，利用LTE信号实现高精度无人机轨迹跟踪是可行的，为低成本被动跟踪提供了新途径

Abstract: In this letter, a dual-bistatic unmanned aerial vehicles (UAVs) tracking system utilizing downlink Long-Term Evolution (LTE) signals is proposed and demonstrated. Particularly, two LTE base stations (BSs) are exploited as illumination sources. Two passive sensing receivers are deployed at different locations to detect the bistatic Doppler frequencies of the target UAV at different directions according to downlink signals transmitted from their corresponding BSs, such that the velocities of the UAV versus time can be estimated. Hence, the trajectories of the target UAV can be reconstructed. Although both the target UAV and the sensing receivers are around 200 meters away from the illuminating BSs, it is demonstrated by experiments that the tracking errors are below 50 centimeters for 90% of the complicated trajectories, when the distances between the UAV and sensing receivers are less than 30 meters. Note this accuracy is significantly better than the ranging resolution of LTE signals, high-accuracy trajectory tracking for UAV might be feasible via multi-angle bistatic Doppler measurements if the receivers are deployed with a sufficient density.

</details>


### [24] [LocDreamer: World Model-Based Learning for Joint Indoor Tracking and Anchor Scheduling](https://arxiv.org/abs/2602.08204)
*Geng Wang,Zhouyou Gu,Shenghong Li,Peng Cheng,Jihong Park,Branka Vucetic,Yonghui Li*

Main category: eess.SP

TL;DR: LocDreamer是一个基于世界模型的框架，用于联合目标跟踪和定位锚点调度，通过生成合成测量数据来想象任意锚点部署，从而提高数据效率并减少能耗


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的方法需要大量标记数据集，且忽视了频谱和能源效率。下一代无线网络中需要准确、资源高效的定位和跟踪服务

Method: 提出LocDreamer框架，学习捕获目标运动和定位环境潜在表示的世界模型，生成合成测量数据来想象任意锚点部署。使用这些数据进行跟踪模型和基于强化学习的锚点调度器的训练，只激活最具信息量的锚点

Result: 在真实室内数据集上的实验表明，LocDreamer显著提高了数据效率和泛化能力，相比传统贝叶斯滤波加随机调度，跟踪精度提升37%，达到直接使用真实数据训练模型86%的精度

Conclusion: LocDreamer通过世界模型生成合成数据，实现了数据高效、能源高效的联合目标跟踪和锚点调度，为下一代无线网络中的定位服务提供了有效解决方案

Abstract: Accurate, resource-efficient localization and tracking enables numerous location-aware services in next-generation wireless networks. However, existing machine learning-based methods often require large labeled datasets while overlooking spectrum and energy efficiencies. To fill this gap, we propose LocDreamer, a world model (WM)-based framework for joint target tracking and scheduling of localization anchors. LocDreamer learns a WM that captures the latent representation of the target motion and localization environment, thereby generating synthetic measurements to imagine arbitrary anchor deployments. These measurements enable imagination-driven training of both the tracking model and the reinforcement learning (RL)-based anchor scheduler that activates only the most informative anchors, which significantly reduce energy and signaling costs while preserving high tracking accuracy. Experiments on a real-world indoor dataset demonstrate that LocDreamer substantially improves data efficiency and generalization, outperforming conventional Bayesian filter with random scheduling by 37% in tracking accuracy, and achieving 86% of the accuracy of same model trained directly on real data.

</details>


### [25] [Riemannian Manifold Optimization for Advanced Wireless Communications: Fundamentals and Applications](https://arxiv.org/abs/2602.08225)
*Siwen Li,Jiacheng Chen,Yunting Xu,Shaofeng Li,Le Yao,Jieling Wang,Dusit Niyato*

Main category: eess.SP

TL;DR: 论文综述了黎曼流形优化在下一代无线通信中的应用，通过将约束问题重构到自然流形上，避免传统欧几里得方法的近似和松弛，提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 下一代无线通信技术（如大规模MIMO、RIS、ISAC、FAS）面临大规模非凸约束优化问题，传统欧几里得方法依赖近似或松弛，导致性能下降和计算成本高昂，需要更有效的优化方法。

Method: 采用黎曼流形优化方法，将约束问题直接在其定义的几何流形上操作，在每个优化步骤中自动满足约束条件，避免近似和松弛，并开发定制化的RMO算法。

Result: 在FAS辅助的NOMA系统安全波束成形案例研究中，RMO方法在性能和计算效率方面均优于传统方法，展示了其在解决无线通信非凸优化问题中的优越性。

Conclusion: 黎曼流形优化为下一代无线通信中的大规模非凸约束优化问题提供了强大解决方案，能够直接处理几何约束，避免传统方法的性能损失和计算负担，具有广阔的应用前景。

Abstract: Next-generation wireless communications promise transformative technologies such as massive multiple-input multiple-output (MIMO), reconfigurable intelligent surfaces (RIS), integrated sensing and communication (ISAC), and fluid antenna systems (FAS). However, deploying these technologies is hindered by large-scale optimization problems with nonconvex constraints. Conventional Euclidean-space methods rely on approximations or relaxations, which degrade performance and incur substantial computational costs. Riemannian manifold optimization (RMO) offers a powerful alternative that directly operates on the manifold defined by the geometric constraints. This approach inherently satisfies the constraints at every optimization step, thereby avoiding the performance degradation and substantial computational costs. In this paper, we first elaborate on the principles of RMO, including the fundamental concepts, tools, and methods, emphasizing its effectiveness for nonconvex problems. We then introduce its applications in advanced wireless communications, showing how constrained problems are reformulated on their natural manifolds and solved using tailored RMO algorithms. Furthermore, we present a case study on secure beamforming in an FAS-assisted non-orthogonal multiple access (NOMA) system, demonstrating RMO's superiority over conventional methods in terms of both performance and computational efficiency.

</details>


### [26] [Towards Optimal Semantic Communications: Reconsidering the Role of Semantic Feature Channels](https://arxiv.org/abs/2602.08260)
*Yongjeong Oh,Jihong Park,Jinho Choi,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 该论文研究了语义通信中语义特征传输的优化，提出了可配置的语义特征信道概念，并开发了编码器-解码器与语义特征信道的联合优化框架。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信研究通常假设语义特征信道是固定的，但实际上该信道可通过传输和接收策略（如功率分配）进行配置。为了提升语义通信性能，需要优化语义特征信道。

Method: 1. 将编码器输出到解码器输入的整个过程建模为语义特征信道；2. 在线性编码器-解码器结构和高斯源假设下，推导最优语义特征信道；3. 提出编码器-解码器与语义特征信道的联合优化框架；4. 提出物理层校准策略实现实时功率控制和信道适应。

Result: 仿真结果表明，所提出的语义特征信道优化在各种通信环境下都能实现优越的任务性能。

Conclusion: 语义特征信道是可配置的，通过联合优化编码器-解码器和语义特征信道，可以显著提升语义通信系统的性能，特别是在动态变化的通信环境中。

Abstract: This paper investigates the optimization of transmitting the encoder outputs, termed semantic features (SFs), in semantic communication (SC). We begin by modeling the entire communication process from the encoder output to the decoder input, encompassing the physical channel and all transceiver operations, as the SF channel, thereby establishing an encoder-SF channel-decoder pipeline. In contrast to prior studies that assume a fixed SF channel, we note that the SF channel is configurable, as its characteristics are shaped by various transmission and reception strategies, such as power allocation. Based on this observation, we formulate the SF channel optimization problem under a mutual information constraint between the SFs and their reconstructions, and analytically derive the optimal SF channel under a linear encoder-decoder structure and Gaussian source assumption. Building upon this theoretical foundation, we propose a joint optimization framework for the encoder-decoder and SF channel, applicable to both analog and digital SCs. To realize the optimized SF channel, we also propose a physical-layer calibration strategy that enables real-time power control and adaptation to varying channel conditions. Simulation results demonstrate that the proposed SF channel optimization achieves superior task performance under various communication environments.

</details>


### [27] [Beam Alignment in Multipath Environments for Integrated Sensing and Communication using Bandit Learning](https://arxiv.org/abs/2602.08380)
*Akanksha Sneh,Shobha Sundar Ram,Sumit J Darak,Aakanksha Tewari*

Main category: eess.SP

TL;DR: 提出结合集成感知与通信(ISAC)的上置信界多臂老虎机算法，通过雷达信息减少波束选择探索时间，提升毫米波通信吞吐量


<details>
  <summary>Details</summary>
Motivation: 传统多臂老虎机算法在毫米波通信中波束数量大时探索时间长，导致整体通信吞吐量差，需要解决这一限制

Method: 将雷达感知信息集成到UCB多臂老虎机算法中，利用雷达检测移动用户来减少候选波束数量，估计准静态场景下的重新对准时间，并通过硬件-软件协同设计和定点分析在SoC上实现

Result: 相比传统仅基于通信的MAB算法，ISAC-based MAB减少了35%的探索时间，吞吐量提升了1.4倍，在包含直接路径、多径、扩展雷达目标和显著静态杂波的复杂传播信道中表现良好

Conclusion: 集成感知与通信能有效提升毫米波波束选择效率，通过雷达信息辅助减少探索时间，显著提高通信吞吐量，硬件加速实现进一步提升了执行效率

Abstract: Prior works have explored multi-armed bandit (MAB) algorithms for the selection of optimal beams for millimeter-wave (mmW) communications between base station and mobile users. However, when the number of beams is large, the existing MAB algorithms are characterized by long exploration times, resulting in poor overall communication throughput. In this work, we propose augmenting the upper confidence bound (UCB) based MAB with integrated sensing and communication (ISAC) to address this limitation. The premise of the work is that the radar and communication functionalities share the same field-of-view and that communication mobile users are detected by the radar as mobile targets. The radar information is used for significantly reducing the number of candidate beams for the UCB, resulting in an overall reduction in the exploration time. Further, the radar information is used to estimate the realignment time in quasi-stationary scenarios. We have realized the MAB and radar signal processing algorithms on the system on chip (SoC) via hardware-software co-design (HSCD) and fixed-point analysis. We demonstrate the significant gain in execution time using accelerators. The simulations consider complex propagation channels involving direct and multipath, with simple and extended radar targets in the presence of significant static clutter. The resulting experiments show that the proposed ISAC-based MAB achieves a 35% reduction in the overall exploration time and 1.4 factor higher throughput as compared to the conventional MAB that is based only on communications.

</details>


### [28] [IEEE 802.11ad-Aided 5-D Sensing with a UAV Swarm in Urban Environment](https://arxiv.org/abs/2602.08396)
*Akanksha Sneh,Shobha Sundar Ram,Kumar Vijay Mishra*

Main category: eess.SP

TL;DR: 提出基于毫米波802.11ad协议的集成感知与通信无人机集群系统，实现五维地面目标感知


<details>
  <summary>Details</summary>
Motivation: 无人机基站支持下一代无线网络，但单无人机存在电池寿命等限制，无人机集群需要解决地面移动用户跟踪和同步问题。传统方法增加传感能力会带来硬件、成本和功耗开销。

Method: 提出集成感知与通信的无人机集群系统，基于毫米波IEEE 802.11ad协议，利用通信信号同时实现感知功能，避免额外传感硬件。

Result: 系统能够在城市环境中实现五维地面目标感知（距离、多普勒速度、方位角、仰角、极化），数值实验验证了基于802.11ad的无人机系统在5-D感知方面的性能。

Conclusion: 集成感知与通信的无人机集群系统能够有效解决地面移动用户跟踪问题，避免额外传感开销，为实际部署提供了可行方案。

Abstract: Aerial base stations mounted on unmanned aerial vehicles (UAVs) support next-generation wireless networks in challenging environments such as urban areas, disaster zones, and remote locations. Further, UAV swarms overcome the challenges of limited battery life and other operational constraints of a single UAV. However, tracking mobile users on the ground by each UAV and the corresponding synchronization between the UAVs is a significant issue that must be addressed before this framework can be deployed in reality. Incorporating additional sensing capabilities to facilitate this additional requirement would introduce significant overhead in terms of hardware, cost, and power to each UAV. Instead, we propose an integrated sensing and communications-enabled swarm UAV system, based on the millimeter-wave IEEE 802.11ad protocol. Further, we show that our proposed system is capable of five-dimensional (5-D) ground target sensing (range, Doppler velocity, azimuth, elevation, and polarization) in an urban environment. Numerical experiments using realistic models demonstrate and validate the performance of 5-D sensing using our proposed 802-11ad-aided UAV system.

</details>


### [29] [Movable Antenna Enabled Reconfigurable Array Topologies for Structured Beam Communications](https://arxiv.org/abs/2602.08409)
*Hongyun Jin,Wenchi Cheng,Jingqing Wang*

Main category: eess.SP

TL;DR: 提出基于可移动天线的结构化波束通信框架，通过可重构阵列拓扑提升6G网络频谱效率


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线的结构化波束方案无法充分利用阵列孔径，限制了拓扑可重构性和对不同通信场景的适应性

Method: 开发基于可移动天线的几何建模框架，构建多种实用阵列拓扑；联合优化阵列拓扑、天线位置和结构化波束成形向量；提出交替优化算法最大化系统频谱效率

Result: 数值结果表明，所提联合设计方案相比传统固定天线方案显著提升了频谱效率

Conclusion: 通过将结构化波束的空间复用自由度与可移动天线的移动自由度相结合，建立了可重构且实用的结构化波束无线通信框架

Abstract: Spatially structured beams have emerged as a promising technology for enhancing spectrum efficiency (SE) in sixth-generation (6G) networks. However, structured beam schemes based on fixed-position antennas (FPAs) fail to fully exploit the array aperture, thereby limiting their topological reconfigurability and adaptability to diverse communication scenarios. To overcome these limitations, this paper proposes a novel structured beam communication framework exploiting movable antennas (MAs) to achieve reconfigurable array topologies. Specifically, we develop an MA-based geometric modeling framework to construct a variety of practical array topologies, thereby enabling the realization of diverse array configurations utilizing a unified hardware platform. Furthermore, we investigate the joint design of the array topology and the structured beamforming vector to efficiently exploit the array aperture and facilitate the multiplexing of orthogonal spatial modes. Accordingly, we formulate the corresponding beam generation and demodulation schemes and derive the channel gains under varying array topologies. We also propose an alternating optimization algorithm to jointly optimize the array topology configuration, the antenna element positions, and the structured beamforming vector, with the aim of maximizing the system SE. Numerical results demonstrate that the proposed joint design significantly enhances the SE compared to conventional FPA schemes. By synergizing the spatial multiplexing degrees of freedom (DoFs) of structured beams with the mobility DoFs of MAs within 2D planar regions, this work establishes a reconfigurable and practical framework for structured beam-based wireless communications.

</details>


### [30] [Reconfigurable Low-Complexity Architecture for High Resolution Doppler Velocity Estimation in Integrated Sensing and Communication System](https://arxiv.org/abs/2602.08415)
*Aakanksha Tewari,Samarth Sharma Bhardwaj,Sumit J Darak,Shobha Sundar Ram*

Main category: eess.SP

TL;DR: 提出一种用于毫米波智能交通ISAC系统的可重构多普勒估计架构，通过硬件软件协同设计实现算法级重构，在FFT粗估计和ESPRIT精估计间动态切换，显著提升速度和资源效率。


<details>
  <summary>Details</summary>
Motivation: 毫米波ISAC系统中，雷达需要长相干处理间隔来获得精细多普勒分辨率以区分移动用户杂波，但这会减少通信时间并降低吞吐量。需要解决多普勒估计精度与系统效率之间的矛盾。

Method: 采用片上系统硬件软件协同设计，提出可重构架构支持算法级重构：在低复杂度FFT粗估计和高复杂度ESPRIT精估计间动态切换。对ESPRIT算法进行改进，大幅提升执行速度并减少资源使用。

Result: 改进的ESPRIT算法执行速度提升6.7倍，内存使用减少79%，乘法器使用减少63%，且精度不受影响。在高信噪比条件下，可切换到更少的慢时间包，进一步将延迟降低2倍，性能无损失。

Conclusion: 提出的可重构多普勒估计架构有效解决了毫米波ISAC系统中多普勒分辨率与通信吞吐量之间的权衡问题，通过算法级重构和ESPRIT优化，在保持精度的同时显著提升了系统效率和资源利用率。

Abstract: In millimeter wave integrated sensing and communication (ISAC) systems for intelligent transportation, radar and communication share spectrum and hardware in a time division manner. Radar rapidly detects and localizes mobile users (MUs), after which communication proceeds through narrow beams identified by radar. Achieving fine Doppler resolution for MU clutter discrimination requires long coherent processing intervals, reducing communication time and throughput. To address this, we propose a reconfigurable architecture for Doppler estimation realized on a system on chip using hardware software codesign. The architecture supports algorithm level reconfiguration, dynamically switching between low-complexity, high-speed FFT-based coarse estimation and high complexity ESPRIT based fine estimation. We introduce modifications to ESPRIT that achieve 6.7 times faster execution while reducing memory and multiplier usage by 79% and 63%, respectively, compared to state of the art approaches, without compromising accuracy. Additionally, the reconfigurable architecture can switch to lower slow time packets under high SNR conditions, improving latency further by 2 times with no loss in performance.

</details>


### [31] [Symbol Rate Maximization in Rolling-Shutter OCC: Design and Implementation Considerations](https://arxiv.org/abs/2602.08474)
*Xinyu Zhang,Alexis A. Dowhuszko,Miguel Rêgo,Pedro Fonseca,Luís Nero Alves,Jyri Hämäläinen,Risto Wichman*

Main category: eess.SP

TL;DR: 该论文提出了一种滚动快门相机的等效数字通信系统模型，将其建模为矩形匹配滤波器，并实验验证了OCC系统在奈奎斯特采样率下的最大符号率，同时通过线性均衡补偿了ISI干扰。


<details>
  <summary>Details</summary>
Motivation: 研究基于滚动快门相机的光学相机通信(OCC)系统的最大数据速率，这类系统利用滚动快门相机的逐行扫描过程来捕捉VLC LED发射器的快速光强变化。

Method: 提出滚动快门相机的等效数字通信系统模型，将其建模为时间宽度等于相机曝光时间的矩形匹配滤波器，然后在相机像素行扫描率下进行采样。基于该模型，实验验证最大符号率，分析VLC发射器与滚动快门OCC接收器之间时间同步不完美导致的ISI，建立等效三抽头信道模型，并使用线性均衡进行补偿。

Result: 仿真和实验结果显示出强相关性，证明所提方法可使OCC系统工作在奈奎斯特采样率（即接收端滚动快门相机的像素行扫描率），并成功补偿了ISI干扰。

Conclusion: 提出的滚动快门相机模型能够准确描述OCC系统性能，使系统工作在最大理论速率（奈奎斯特采样率），并通过线性均衡有效处理同步不完美导致的ISI问题，为OCC系统的性能优化提供了理论基础和实用方法。

Abstract: Optical Camera Communication (OCC) systems can take advantage of the row-by-row scanning process of rolling-shutter cameras to capture the fast variations of light intensity coming from Visible Light Communication (VLC) LED-based transmitters. In order to study the maximum data rate that is feasible in such kind of OCC systems, this paper presents its equivalent digital communication system model in which the rolling-shutter camera is modeled as a rectangular matched-filter whose time width is equal to the exposure time of the camera, followed by a sampling process at the pixel row sweep rate of the camera. Based on the proposed rolling-shutter camera model, the maximum symbol rate that such OCC systems can support is experimentally demonstrated, and the impact of imperfect time synchronization between the VLC transmitter and the rolling-shutter OCC receiver is characterized in the form of Inter-Symbol Interference (ISI). The equivalent three-tap channel model that results from this process is experimentally validated and the generated ISI is compensated with the use of linear equalization in reception. Simulation and experimental results show a strong correlation between them, demonstrating that the proposed approach can be used to make the OCC system work at the Nyquist sampling rate, which is equivalent to the pixel row sweep rate of the rolling-shutter camera used in reception.

</details>


### [32] [Radar Operating Metrics and Network Throughput for Integrated Sensing and Communications in Millimeter-wave Urban Environments](https://arxiv.org/abs/2602.08495)
*Akanksha Sneh,Shobha Sundar Ram*

Main category: eess.SP

TL;DR: 分析毫米波ISAC系统中雷达参数（占空比、波束宽度）对通信吞吐量的影响，使用随机几何框架建模雷达性能指标，并通过蒙特卡洛仿真验证


<details>
  <summary>Details</summary>
Motivation: 下一代智能交通系统需要毫米波集成感知与通信（ISAC）技术，雷达和通信功能共享频谱和硬件资源。关键挑战在于如何优化雷达参数（如占空比和波束宽度）以实现高通信吞吐量，需要建立数学模型来分析雷达性能与通信性能之间的关系。

Method: 采用基于随机几何的数学框架，分析雷达工作指标与雷达、目标和杂波参数的关系，然后利用这些结果研究ISAC系统的网络吞吐量，最后通过蒙特卡洛仿真验证理论结果。

Result: 建立了雷达参数（占空比、波束宽度）与通信吞吐量之间的定量关系模型，验证了通过优化雷达参数可以显著提升ISAC系统的网络性能，蒙特卡洛仿真证实了理论分析的有效性。

Conclusion: 毫米波ISAC系统中雷达参数的选择对通信吞吐量有重要影响，基于随机几何的数学框架能够有效分析雷达性能指标并优化系统设计，为下一代智能交通系统的ISAC技术提供了理论指导。

Abstract: Millimeter wave integrated sensing and communication (ISAC) systems are being researched for next-generation intelligent transportation systems. Here, radar and communication functionalities share a common spectrum and hardware resources in a time-multiplexed manner. The objective of the radar is to first scan the angular search space and detect and localize mobile users/targets in the presence of discrete clutter scatterers. Subsequently, this information is used to direct highly directional beams toward these mobile users for communication service. The choice of radar parameters such as the radar duty cycle and the corresponding beamwidth are critical for realizing high communication throughput. In this work, we use the stochastic geometry-based mathematical framework to analyze the radar operating metrics as a function of diverse radar, target, and clutter parameters and subsequently use these results to study the network throughput of the ISAC system. The results are validated through Monte Carlo simulations.

</details>


### [33] [DNS: Data-driven Nonlinear Smoother for Complex Model-free Process](https://arxiv.org/abs/2602.08560)
*Fredrik Cumlin,Anubhab Ghosh,Saikat Chatterjee*

Main category: eess.SP

TL;DR: 提出数据驱动的非线性平滑器（DNS），用于从含噪声的线性测量序列中估计复杂动态过程的隐藏状态序列，无需动态模型知识，采用无监督学习


<details>
  <summary>Details</summary>
Motivation: 解决复杂动态过程的隐藏状态估计问题，特别是在没有状态转移模型知识的情况下，从仅有的测量数据中学习状态估计

Method: 使用循环架构构建数据驱动的非线性平滑器，提供给定测量序列下隐藏状态序列的闭式后验分布，采用无监督学习方式，仅使用测量数据进行训练

Result: 在多个随机动态过程（包括基准Lorenz系统）的平滑实验中，DNS表现显著优于深度卡尔曼平滑器（DKS）和迭代数据驱动非线性状态估计（iDANSE）平滑器

Conclusion: DNS是一种有效的无模型状态估计方法，能够在没有动态过程先验知识的情况下，仅从测量数据中学习并实现优于现有方法的平滑性能

Abstract: We propose data-driven nonlinear smoother (DNS) to estimate a hidden state sequence of a complex dynamical process from a noisy, linear measurement sequence. The dynamical process is model-free, that is, we do not have any knowledge of the nonlinear dynamics of the complex process. There is no state-transition model (STM) of the process available. The proposed DNS uses a recurrent architecture that helps to provide a closed-form posterior of the hidden state sequence given the measurement sequence. DNS learns in an unsupervised manner, meaning the training dataset consists of only measurement data and no state data. We demonstrate DNS using simulations for smoothing of several stochastic dynamical processes, including a benchmark Lorenz system. Experimental results show that the DNS is significantly better than a deep Kalman smoother (DKS) and an iterative data-driven nonlinear state estimation (iDANSE) smoother.

</details>


### [34] [RFSoC-Based Integrated Navigation and Sensing Using NavIC](https://arxiv.org/abs/2602.08596)
*Riya Sachdeva,Aakanksha Tewari,Sumit J. Darak,Shobha Sundar Ram,Sanat K. Biswas*

Main category: eess.SP

TL;DR: 基于NavIC卫星的被动雷达接收器原型系统，利用地面反射信号进行目标探测，在RFSoC平台上实现延迟-多普勒图生成


<details>
  <summary>Details</summary>
Motivation: 利用现有GNSS基础设施进行二次应用，开发被动雷达系统来探测地面和海上非合作目标，降低雷达系统成本

Method: 在AMD Zynq RFSoC平台上部署双通道接收器原型，分别捕获卫星直射信号和地面反射信号，通过ARM处理器和FPGA处理生成延迟-多普勒图

Result: 成功验证了RFSoC回环配置和AWG信号仿真下的系统性能，能够在不同信噪比条件下生成目标延迟-多普勒图

Conclusion: 该原型系统证明了基于NavIC卫星的被动雷达接收器的可行性，为低成本远程目标探测提供了有效解决方案

Abstract: Prior art has proposed a secondary application for Global Navigation Satellite System (GNSS) infrastructure for remote sensing of ground-based and maritime targets. Here, a passive radar receiver is deployed to detect uncooperative targets on Earth's surface by capturing ground-reflected satellite signals. This work demonstrates a hardware prototype of an L-band Navigation with Indian Constellation (NavIC) satellite-based remote sensing receiver system mounted on an AMD Zynq radio frequency system-on-chip (RFSoC) platform. Two synchronized receiver channels are introduced for capturing the direct signal (DS) from the satellite and ground-reflected signal (GRS) returns from targets. These signals are processed on the ARM processor and field programmable gate array (FPGA) of the RFSoC to generate delay-Doppler maps of the ground-based targets. The performance is first validated in a loop-back configuration of the RFSoC. Next, the DS and GRS signals are emulated by the output from two ports of the Keysight Arbitrary Waveform Generator (AWG) and interfaced with the RFSoC where the signals are subsequently processed to obtain the delay-Doppler maps. The performance is validated for different signal-to-noise ratios (SNR).

</details>


### [35] [Ziv-Zakai Bound for Near-Field Localization and Sensing](https://arxiv.org/abs/2602.08609)
*Nicolò Decarli,Davide Dardari*

Main category: eess.SP

TL;DR: 该论文分析了近场定位与感知中的Ziv-Zakai界(ZZB)，相比传统Cramér-Rao界(CRB)在低信噪比或阈值区域提供了更紧的精度表征，特别关注大规模天线阵列下的距离和角度估计。


<details>
  <summary>Details</summary>
Motivation: 现代无线系统中不断增加的载波频率和天线阵列物理尺寸，推动了在近场条件下进行定位和感知的新研究兴趣。需要更精确的估计精度表征方法，特别是在低信噪比区域。

Method: 利用球面波前和阵列几何结构的信号模型，评估近场定位和感知的Ziv-Zakai界(ZZB)，分析距离和角度估计的精度，研究精度对关键信号和系统参数（如阵列几何、波长、目标位置）的依赖性。

Result: 分析揭示了ZZB的过渡行为，强调了准确近场感知的基本限制和机会。ZZB相比CRB提供了更紧的精度表征，特别是在低信噪比或阈值区域。

Conclusion: 该研究为大规模天线阵列下的近场定位和感知提供了理论基础，揭示了Ziv-Zakai界在表征估计精度方面的优势，并指出了近场感知的基本限制和潜在机会。

Abstract: The increasing carrier frequencies and growing physical dimensions of antenna arrays in modern wireless systems are driving renewed interest in localization and sensing under near-field conditions. In this paper, we analyze the Ziv-Zakai Bound (ZZB) for near-field localization and sensing operated with large antenna arrays, which offers a tighter characterization of estimation accuracy compared to traditional bounds such as the Cramér-Rao Bound (CRB), especially in low signal-to-noise ratio or threshold regions. Leveraging spherical wavefront and array geometry in the signal model, we evaluate the ZZB for distance and angle estimation, investigating the dependence of the accuracy on key signal and system parameters such as array geometry, wavelength, and target position. Our analysis highlights the transition behavior of the ZZB and underscores the fundamental limitations and opportunities for accurate near-field sensing.

</details>


### [36] [Improving Reliability of Hybrid Bit-Semantic Communications for Cellular Networks](https://arxiv.org/abs/2602.08697)
*Nikos G. Evgenidis,Sotiris A. Tegos,Panagiotis D. Diamantoulakis,Ioannis Krikidis,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 该论文研究混合蜂窝网络中语义通信与传统比特通信的可靠性，推导了中断概率闭式表达式，并提出语义利用率指标来优化网络设计。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽能提高频谱和能量效率，但依赖复杂的深度神经网络，在实际部署中存在准确性和实现难度问题。混合网络结合传统比特通信和语义通信，需要研究其可靠性并考虑硬件资源限制。

Method: 推导混合网络中断概率的闭式表达式，提出广义中断概率来计算满足特定用户范围需求的小区半径，引入语义利用率指标来评估语义通信的实际使用情况。

Result: 获得了中断概率的闭式表达式，能够计算达到期望中断阈值的小区半径，并基于语义利用率确定选择语义通信的用户概率和最优小区半径。

Conclusion: 提出的分析表达式和设计指标为混合蜂窝网络提供了理论依据和实用设计指导，仿真验证了理论分析的有效性，有助于实际网络部署。

Abstract: Semantic communications (SemComs) have been considered as a promising solution to reduce the amount of transmitted information, thus paving the way for more energy-and spectrum-efficient wireless networks. Nevertheless, SemComs rely heavily on the utilization of deep neural networks (DNNs) at the transceivers, which limit the accuracy between the original and reconstructed data and are challenging to implement in practice due to increased architecture complexity. Thus, hybrid cellular networks that utilize both conventional bit communications (BitComs) and SemComs have been introduced to bridge the gap between required and existing infrastructure. To facilitate such networks, in this work, we investigate reliability by deriving closed-form expressions for the outage probability of the network. Additionally, we propose a generalized outage probability through which the cell radius that achieves a desired outage threshold for a specific range of users is calculated in closed form. Additionally, to consider the practical limitations caused by the specialized dedicated hardware and the increased memory and computational resources that are required to support SemCom, a semantic utilization metric is proposed. Based on this metric, we express the probability that a specific number of users select SemCom transmission and calculate the optimal cell radius for that number in closed form. Simulation results validate the derived analytical expressions and the characterized design properties of the cell radius found through the proposed metrics, providing useful insights.

</details>


### [37] [Joint Channel Sounding and Source-Channel Coding for MIMO-OFDM Systems: Deep Unified Encoding and Parallel Flow-Matching Decoding](https://arxiv.org/abs/2602.08795)
*Hao Jiang,Xiaojun Yuan,Qinghua Guo*

Main category: eess.SP

TL;DR: 提出DU-PFM框架：统一编码器嵌入源信息，并行流匹配解码器联合估计信道和源，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要明确的导频-数据分离，且扩散式方法推理效率低，需要更高效的联合信道和源估计方案

Method: 1) 深度统一编码器：生成包含足够冗余的码字处理信道和源不确定性；2) 并行流匹配解码器：利用流式生成先验联合估计信道和源；3) 推导贝叶斯克拉美罗下界作为性能基准

Result: 在块衰落MIMO-OFDM信道上的大量仿真表明，DU-PFM方法在信道估计精度和源重建质量上都显著优于现有最先进方法

Conclusion: 提出的DU-PFM框架通过统一编码和高效的并行流匹配解码，实现了更优的联合信道和源估计性能，为无线通信系统提供了有效的解决方案

Abstract: In this work, we propose a deep unified (DU) encoder that embeds source information in a codeword that contains sufficient redundancy to handle both channel and source uncertainties, without enforcing an explicit pilot-data separation. At the receiver, we design a parallel flow-matching (PFM) decoder that leverages flow-based generative priors to jointly estimate the channel and the source, yielding much more efficient inference than the existing diffusion-based approaches. To benchmark performance limits, we derive the Bayesian Cramér-Rao bound (BCRB) for the joint channel and source estimation problem. Extensive simulations over block-fading MIMO-OFDM channels demonstrate that the proposed DU-PFM approach drastically outperforms the state-of-the-art methods in both channel estimation accuracy and source reconstruction quality.

</details>


### [38] [Denoise Stepwise Signals by Diffusion Model Based Approach](https://arxiv.org/abs/2602.08904)
*Xingdi Tong,Chenyu Wen*

Main category: eess.SP

TL;DR: 提出SSDM扩散模型算法，用于单分子检测中阶梯信号的去噪，在信号重建和跃迁点检测方面优于传统方法


<details>
  <summary>Details</summary>
Motivation: 单分子检测中的阶梯信号常被噪声干扰，传统频域滤波效果不佳，HMM方法依赖平稳性假设且非专门用于去噪

Method: 提出SSDM扩散模型，通过前向扩散过程学习阶梯信号统计结构，反向过程重建干净信号，结合多尺度卷积网络和注意力机制

Result: 在广泛信噪比范围内，SSDM在信号水平重建和跃迁点检测方面均优于传统方法，在FRET和纳米孔DNA易位实验数据上验证有效

Conclusion: SSDM为单分子检测和其他离散状态跃迁系统提供通用鲁棒的阶梯信号恢复框架

Abstract: Stepwise signals are ubiquitous in single-molecule detections, where abrupt changes in signal levels typically correspond to molecular conformational changes or state transitions. However, these features are inevitably obscured by noise, leading to uncertainty in estimating both signal levels and transition points. Traditional frequency-domain filtering is ineffective for denoising stepwise signals, as edge-related high-frequency components strongly overlap with noise. Although Hidden Markov Model-based approaches are widely used, they rely on stationarity assumptions and are not specifically designed for signal denoising. Here, we propose a diffusion model-based algorithm for stepwise signal denoising, named the Stepwise Signal Diffusion Model (SSDM). During training, SSDM learns the statistical structure of stepwise signals via a forward diffusion process that progressively adds noise. In the following reverse process, the model reconstructs clean signals from noisy observations, integrating a multi-scale convolutional network with an attention mechanism. Training data are generated by simulating stepwise signals through a Markov process with additive Gaussian noise. Across a broad range of signal-to-noise ratios, SSDM consistently outperforms traditional methods in both signal level reconstruction and transition point detection. Its effectiveness is further demonstrated on experimental data from single-molecule Forster Resonance Energy Transfer and nanopore DNA translocation measurements. Overall, SSDM provides a general and robust framework for recovering stepwise signals in various single-molecule detections and other physical systems exhibiting discrete state transitions.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [39] [Single-shot lossy compression: mutual information bounds](https://arxiv.org/abs/2602.07280)
*Victoria Kostina*

Main category: cs.IT

TL;DR: 论文提出在多种保真度约束下，用互信息上界来逼近最小期望描述长度，并证明当数据信息量不太低时，最小化互信息可作为描述长度优化的合理代理。


<details>
  <summary>Details</summary>
Motivation: 研究如何有效表示随机变量的最小描述长度问题，特别是在实际应用中直接计算最小描述长度往往很困难，需要寻找可计算的代理目标。

Method: 针对三种保真度约束（保证失真、条件超额失真、超额失真），推导出互信息上界来限制最小期望描述长度，并提供这些凸代理的替代特征化，揭示其解的结构。

Result: 证明了在数据信息量不太低的情况下，在适当保真度约束下最小化互信息可以作为最小描述长度的合理代理，并提供了所有三种凸代理的替代特征化。

Conclusion: 该研究为最小描述长度问题提供了实用的互信息代理框架，通过凸优化方法在多种保真度约束下实现了对最小描述长度的有效逼近。

Abstract: For several styles of fidelity constraints -- guaranteed distortion, conditional excess distortion, excess distortion -- we show mutual information upper bounds on the minimum expected description length needed to represent a random variable. Coupled with the corresponding converses, these results attest that as long as the information content in the data is not too low, minimizing the mutual information under an appropriate fidelity constraint serves as a reasonable proxy for the minimum description length of the data. We provide alternative characterizations of all three convex proxies, shedding light on the structure of their solutions.

</details>


### [40] [Network function computation with vector linear target function and security function](https://arxiv.org/abs/2602.07316)
*Min Xu,Qian Chen,Gennian Ge*

Main category: cs.IT

TL;DR: 研究在有窃听者的有向无环网络中安全计算向量线性函数的问题，建立了安全计算容量的上下界，并针对特定网络和函数类型给出了安全向量线性网络码的构造方法。


<details>
  <summary>Details</summary>
Motivation: 在分布式网络中，当存在窃听者可以监听特定线路集合时，如何安全地计算目标函数，同时保护源消息的特定安全函数不被泄露。这扩展了传统安全网络编码到函数计算场景。

Method: 1) 建立两个适用于任意网络拓扑和任意向量线性目标/安全函数的容量上界；2) 当目标函数为有限域上的和时，将现有非安全网络码转换为安全网络码的方法扩展到向量线性安全函数；3) 针对特定网络和向量线性目标函数，刻画构造安全向量线性网络码所需的全局编码矩阵特性。

Result: 1) 建立了两个通用的安全计算容量上界，推广了现有结果，并为有限域上的和函数提供了新的上界；2) 扩展了非安全到安全网络码的转换方法；3) 针对特定网络类型，给出了安全向量线性网络码的构造条件。

Conclusion: 本文为有窃听者的网络中安全计算向量线性函数提供了理论框架，建立了容量上下界，并给出了特定情况下的构造方法，为安全函数计算网络编码的设计提供了理论基础。

Abstract: In this paper, we study the problem of securely computing a function over a network, where both the target function and the security function are vector linear. The network is modeled as a directed acyclic graph. A sink node wishes to compute a function of messages generated by multiple distributed sources, while an eavesdropper can access exactly one wiretap set from a given collection. The eavesdropper must be prevented from obtaining any information about a specified security function of the source messages. The secure computing capacity is the maximum average number of times that the target function can be securely computed with zero error at the sink node with the given collection of wiretap sets and security function for one use of the network. We establish two upper bounds on this capacity, which hold for arbitrary network topologies and for any vector linear target and security functions. These bounds generalize existing results and also lead to a new upper bound when the target function is the sum over a finite field. For the lower bound, when the target function is the sum, we extend an existing method, which transforms a non-secure network code into a secure one, to the case where the security function is vector linear. Furthermore, for a particular class of networks and a vector linear target function, we characterize the required properties of the global encoding matrix to construct a secure vector linear network code.

</details>


### [41] [Multicasting Pinching Antenna Systems With LoS Blockage](https://arxiv.org/abs/2602.07421)
*Muhammad Fainan Hanif,Yuanwei Liu*

Main category: cs.IT

TL;DR: 本文研究夹持天线系统在多播场景下的最优位置分配问题，提出基于MM算法的收敛算法，并比较两种求解方法（CSM和BSM）的性能。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统是一种在高频段有前景的可定制无线接入机制，但在非视距环境下，传统天线系统性能受限，需要研究夹持天线在多播场景下的最优位置分配问题。

Method: 使用minorization-maximization（MM）原理设计收敛算法，通过求解凸代理问题，提出候选搜索方法（CSM）和对分搜索方法（BSM）两种求解方法。

Result: 夹持天线系统在非视距环境下的多播性能优于传统天线系统；当用户和天线数量增加时，BSM具有更好的计算复杂度（例如8个天线和25个用户时，CSM执行时间约为BSM的2.5倍）。

Conclusion: 夹持天线系统在非视距多播场景中具有优势，BSM方法在计算效率上优于CSM，为高频段无线接入提供了有效的解决方案。

Abstract: Pinching-antenna systems (PASS) represent a promising customizable wireless access mechanism in high-frequency bands, enabled by dielectric waveguides and movable dielectric particles, called pinching antennas (PAs). In this work, we study optimal position allocation of PAs in PASS for multicasting in the downlink when a line-of-sight (LoS) link does not necessarily exist between all users and the PAs. The multicasting problem is solved by leveraging minorization-maximization (MM) principle to yield a provably convergent algorithm. In each run of the MM based procedure, we solve a convex surrogate problem using two methods called the candidate search method (CSM) and the bisection search method (BSM). With both BSM and CSM, we not only report superior performance of the multicasting PASS in non-LoS environments compared to conventional antenna systems (CAS), but also determine that BSM yields better overall computational complexity when the number of users and PAs increases. For example, we report that when we have 8 PAs and 25 users, the execution time with the CSM is approximately 2.5 times that with the BSM.

</details>


### [42] [Information Theoretic Modeling of Interspecies Molecular Communication](https://arxiv.org/abs/2602.07474)
*Bitop Maitra,Murat Kuscu,Ozgur B. Akan*

Main category: cs.IT

TL;DR: 提出一个信息论框架来建模植物与昆虫间的挥发性有机化合物分子通信，考虑环境噪声和受体随机响应


<details>
  <summary>Details</summary>
Motivation: 植物和昆虫通过挥发性有机化合物进行化学通信，这种通信发生在有噪声的环境中（风、距离、生物反应），需要理论框架来理解这种跨物种分子通信的信息传递机制

Method: 开发信息论框架，将受体响应建模为多项式分布的概率模型，考虑环境参数如风速、距离和释放分子数量对通信的影响

Result: 数值结果表明通信性能依赖于环境参数，包括风速、距离和释放分子数量，框架为实际生物和环境条件下的VOC通信提供了基础见解

Conclusion: 提出的信息论框架能够有效建模跨物种分子通信，揭示了环境因素对化学信号传递的影响，为理解真实生物环境中的VOC通信提供了理论基础

Abstract: Plants and insects communicate using chemical signals like volatile organic compounds (VOCs). A plant encodes information using different blends of VOCs, which propagate through the air to represent different symbolic information. This communication occurs in a noisy environment, characterized by wind, distance, and complex biological reactions. At the receiver, cross-reactive olfactory receptors produce stochastic binding events whose discretized durations form the receiver observation. In this paper, an information-theoretic framework is developed to model interspecies molecular communication (MC), where receptor responses are modeled probabilistically using a multinomial distribution. Numerical results show that the communication depends on environmental parameters such as wind speed, distance, and the number of released molecules. The proposed framework provides fundamental insights into the VOC-based interspecies communication under realistic biological and environmental conditions.

</details>


### [43] [Transformer-based Hybrid Beamforming with Dynamic Subarray for Near-Space Airship-Borne Communications](https://arxiv.org/abs/2602.07509)
*Ruiqi Wang,Zhen Gao,Keke Ying,Ziwei Wan,Symeon Chatzinotas,Mohamed-Slim Alouini*

Main category: cs.IT

TL;DR: 提出用于近空间飞艇通信的混合波束赋形框架，采用动态子阵列结构和Transformer编码器设计，显著提升频谱效率和能量效率


<details>
  <summary>Details</summary>
Motivation: 针对近空间飞艇通信中能量受限的问题，需要设计高能量效率的大规模MIMO系统，传统固定连接结构难以适应动态信道环境

Method: 提出联合动态混合波束赋形网络(DyHBFNet)，包含三个基于Transformer编码器的组件：模拟波束赋形网络优化模拟矩阵并提供天线选择辅助信息；天线选择网络动态优化天线与射频链连接；数字波束赋形网络采用模型驱动的加权最小均方误差算法优化数字矩阵

Result: 仿真结果表明，该框架相比基线方案显著提升了频谱效率和能量效率，且在非完美信道状态信息下具有鲁棒性能，适合实际部署

Conclusion: 提出的动态混合波束赋形框架为近空间飞艇通信提供了一种高效、可扩展的解决方案，通过动态子阵列结构和Transformer编码器设计实现了性能提升

Abstract: This paper proposes a hybrid beamforming framework for massive multiple-input multiple-output (MIMO) in near-space airship-borne communications. To achieve high energy efficiency (EE) in energy-constraint airships, a dynamic subarray structure is introduced, where each radio frequency chain (RFC) is connected to a disjoint subset of the antennas according to channel state information (CSI). The proposed joint dynamic hybrid beamforming network (DyHBFNet) comprises three key components: 1) An analog beamforming network (ABFNet) that optimizes the analog beamforming matrices and provides auxiliary information for the antenna selection network (ASNet) design, 2) an ASNet that dynamically optimizes the connections between antennas and RFCs, and 3) a digital beamforming network (DBFNet) that optimizes digital beamforming matrices by employing a model-driven weighted minimum mean square error algorithm for improving beamforming performance and convergence speed. The proposed ABFNet, ASNet, and DBFNet are all designed based on advanced Transformer encoders. Simulation results demonstrate that the proposed framework significantly enhances spectral efficiency and EE compared to baseline schemes. Additionally, its robust performance under imperfect CSI makes it a scalable solution for practical implementations.

</details>


### [44] [Expected Recovery Time in DNA-based Distributed Storage Systems](https://arxiv.org/abs/2602.07601)
*Adi Levy,Roni Con,Eitan Yaakobi,Han Mao Kiah*

Main category: cs.IT

TL;DR: 研究DNA分布式存储系统，分析不同纠删码在DNA存储容器故障下的预期恢复时间


<details>
  <summary>Details</summary>
Motivation: DNA存储容器受测序技术限制，每次读取只能随机采样容器中的DNA链，需要研究在这种约束下的分布式存储系统可靠性

Method: 将DNA分布式存储建模为多容器系统，分析多种纠删码的性能，通过推广经典优惠券收集问题来理论分析预期恢复时间

Result: 获得了不同纠删码在DNA存储容器故障下的预期恢复时间分析结果，相关理论分析对优惠券收集问题的推广具有独立价值

Conclusion: 首次系统研究DNA分布式存储系统，为DNA存储的可靠性提供了理论框架和分析工具

Abstract: We initiate the study of DNA-based distributed storage systems, where information is encoded across multiple DNA data storage containers to achieve robustness against container failures. In this setting, data are distributed over $M$ containers, and the objective is to guarantee that the contents of any failed container can be reliably reconstructed from the surviving ones. Unlike classical distributed storage systems, DNA data storage containers are fundamentally constrained by sequencing technology, since each read operation yields the content of a uniformly random sampled strand from the container. Within this framework, we consider several erasure-correcting codes and analyze the expected recovery time of the data stored in a failed container. Our results are obtained by analyzing generalized versions of the classical Coupon Collector's Problem, which may be of independent interest.

</details>


### [45] [Wireless Streamlet: A Spectrum-Aware and Cognitive Consensus Protocol for Edge IoT](https://arxiv.org/abs/2602.07630)
*Taotao Wang,Long Shi,Fang Liu,Qing Yang,Shengli Zhang*

Main category: cs.IT

TL;DR: Wireless Streamlet：针对无线边缘物联网的频谱感知共识协议，通过信道感知领导者选举和编码双链架构，在频谱受限环境中提高可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统BFT协议在频谱拥塞和动态变化的无线边缘物联网网络中效率低下，因为它们对频谱状况不敏感，导致资源利用率低且在时变干扰下进展脆弱。需要设计一种频谱感知的共识协议来适应无线环境。

Method: 基于Streamlet的简化结构，引入信道感知领导者选举机制，利用接收器测量的信道状态信息计算拜占庭鲁棒的连接性评分，从最终历史中确定性选择加权领导者。采用单跳广播介质和确定性TDMA投票调度实现线性每时段空中传输。提出编码双链架构，将仅包含头部的共识链与数据链解耦，使用擦除编码和链上完整性承诺。

Result: 实验表明，在丢包环境中，Wireless Streamlet比代表性基线实现了更高的吞吐量和更低的确认延迟，同时显著减少了每个节点的存储需求，证明了将认知感知集成到共识逻辑中的有效性。

Conclusion: Wireless Streamlet通过频谱感知的共识设计，成功解决了无线边缘物联网中区块链部署的关键挑战，在频谱效率、可靠性和存储优化方面取得了显著改进，为动态无线环境中的去中心化信任提供了可行解决方案。

Abstract: Blockchain offers a decentralized trust framework for the Internet of Things (IoT), yet deploying consensus in spectrum-congested and dynamic wireless edge IoT networks faces fundamental obstacles: traditional BFT protocols are spectrum-ignorant, leading to inefficient resource utilization and fragile progress under time-varying interference. This paper presents \textit{Wireless Streamlet}, a spectrum-aware and cognitive consensus protocol tailored for wireless edge IoT. Building on Streamlet's streamlined structure, we introduce a \textit{Channel-Aware Leader Election (CALE)} mechanism. CALE serves as a verifiable cross-layer cognitive engine that leverages receiver-measured channel state information (CSI) piggybacked in signed votes to derive Byzantine-robust connectivity scores from notarization certificates, and deterministically selects a unique weighted leader per epoch from finalized history, thereby improving proposal dissemination reliability under deep fading. Complementing this cognitive adaptation, Wireless Streamlet exploits the single-hop broadcast medium and a deterministic TDMA voting schedule to achieve linear per-epoch on-air transmissions (slot complexity), ensuring deterministic spectral access. To address the communication-storage trade-off, we further propose a coded dual-chain architecture that decouples header-only consensus (State Chain) from payload data (Data Chain). By employing erasure coding and on-chain integrity commitments, the system minimizes redundant spectrum usage for data retrieval while ensuring availability. Experiments show that Wireless Streamlet achieves higher throughput and lower confirmation latency than representative baselines in lossy environments, while substantially reducing per-node storage, demonstrating the efficacy of integrating cognitive sensing into consensus logic.

</details>


### [46] [Data Compression with Stochastic Codes](https://arxiv.org/abs/2602.07635)
*Gergely Flamich,Deniz Gündüz*

Main category: cs.IT

TL;DR: 本文综述了相对熵编码这一新兴领域，重点介绍了其在有损源编码中作为量化和熵编码替代方案的计算与实践方面。


<details>
  <summary>Details</summary>
Motivation: 机器学习在过去十年对数据压缩产生了重大影响，激发了新的理论和应用问题。相对熵编码作为量化与熵编码的替代方案，在文献中缺乏计算与实践方面的系统概述。

Method: 本文采用综述方法，从三个层面构建相对熵编码的完整图景：提供直观理解、总结当代应用、阐明算法构造的简洁性与优雅性。

Result: 建立了相对熵编码领域的系统框架，填补了文献中计算与实践方面的空白，展示了该领域作为数据压缩研究中简单而令人兴奋的新兴方向。

Conclusion: 相对熵编码是数据压缩研究中一个简单而优雅的新兴领域，具有重要的理论和应用价值，值得进一步探索。

Abstract: Machine learning has had a major impact on data compression over the last decade and inspired many new, exciting theoretical and applied questions.
  This paper describes one such direction -- relative entropy coding -- which focuses on constructing stochastic codes, primarily as an alternative to quantisation and entropy coding in lossy source coding. Our primary aim is to provide a broad overview of the topic, with an emphasis on the computational and practical aspects currently missing from the literature.
  Our goal is threefold: for the curious reader, we aim to provide an intuitive picture of the field and convince them that relative entropy coding is a simple yet exciting emerging field in data compression research. For a reader interested in applied research on lossy data compression, we provide an account of the most salient contemporary applications. Finally, for the reader who has heard of relative entropy coding but has never been quite sure what it is or how the algorithms fit together, we hope to illustrate how simple and elegant the underlying constructions are.

</details>


### [47] [Spectral Graph Analysis for Predicting QoE Fairness Sensitivity in Wireless Communication Networks](https://arxiv.org/abs/2602.07855)
*Xinke Jian,Zhiyuan Ren,Wenchi Cheng*

Main category: cs.IT

TL;DR: 该论文通过谱图理论分析QoE公平性，证明了指数谱上界，揭示了QoE公平性改进在性能阈值以上呈指数衰减，其衰减速率由SLA严格性和网络谱间隙共同决定。


<details>
  <summary>Details</summary>
Motivation: 学术界长期缺乏连接底层拓扑与高层服务公平性的预测方法。QoE公平性评估不仅取决于当前状态，更关键的是其对SLA参数变化的敏感性。需要填补这一理论空白。

Method: 通过谱图理论分析QoE不平衡指数(I)，证明了一个新颖的指数谱上界。该上界首次将服务协议和拓扑瓶颈统一在单一性能边界公式中。

Result: 发现QoE公平性改进在由网络规模和连通性决定的性能阈值以上呈指数衰减行为。衰减速率由SLA严格性(a)和网络谱间隙(cλ₂)中较弱者主导。揭示了清晰的瓶颈效应。

Conclusion: 该理论关系为网络设计中的资源优化提供了瓶颈驱动原则，并支持目标驱动的逆向工程。在各种随机图模型和真实网络拓扑上的大量数值实验验证了分析框架的正确性和普适性。

Abstract: The evaluation of Quality of Experience (QoE) fairness depends not only on its current state but, more critically, on its sensitivity to changes in Service Level Agreement (SLA) parameters. However, the academic community has long lacked a predictive method connecting underlying topology to high-level service fairness. To bridge this gap, this paper analyzes a QoE imbalance index ($I$) through the lens of spectral graph theory.Our core contribution is the proof of a novel exponential spectral upper bound. This bound reveals that the improvement of QoE fairness exhibits an exponential decay behavior only above a performance threshold determined jointly by network size and connectivity. Its core decay rate is dominated by the weaker of two factors: the SLA stringency ($a$) and the network's spectral gap ($cλ_2$). The upper bound unifies the service protocol and the topological bottleneck within a single performance bound formula for the first time.This theoretical relationship also reveals a clear bottleneck effect, where the system's fairness ceiling is determined by the weaker link between service parameters and network structure. This finding provides a bottleneck-driven principle for resource optimization in network design and enables goal-driven reverse engineering. Extensive numerical experiments on various random graph models and real-world network topologies robustly validate the correctness and universality of our analytical framework.

</details>


### [48] [Capacity Scaling Laws for Boundary-Induced Drift-Diffusion Noise Channels](https://arxiv.org/abs/2602.07866)
*Yen-Chi Lee*

Main category: cs.IT

TL;DR: 论文研究了由多维漂移扩散过程首次击中吸收超平面产生的加性噪声信道的高功率容量缩放，发现各向同性高斯信号渐近达到容量，容量预对数因子仅由接收边界维度决定，揭示了信道的几何自由度起源。


<details>
  <summary>Details</summary>
Motivation: 研究边界诱导噪声信道的信息论特性，这类信道由物理传输过程（如粒子扩散到边界）产生，噪声具有非高斯和半重尾特性，需要理解其容量缩放行为和最优信号设计。

Method: 将底层随机传输机制建模为高斯方差混合，引入并分析正态漂移首次击中位置（NDFHL）族作为几何驱动的边界诱导噪声模型。在二阶矩约束下，推导高信噪比下的精确容量展开。

Result: 推导出精确的高信噪比容量展开，上下界在常数级重合，容量间隙消失。各向同性高斯信号对所有固定漂移强度渐近达到容量。预对数因子仅由接收边界维度决定，揭示了信道的几何自由度。发现熵主导的普适性：所有传输过程的物理参数仅通过诱导噪声的微分熵影响容量。

Conclusion: 尽管NDFHL密度没有简单闭式形式，但其熵有限且随漂移消失而连续变化，连接了有限方差区域和奇异无限方差柯西极限。这些结果为边界击中信道在正则和奇异传输区域提供了统一的几何和信息论表征。

Abstract: This paper studies the high-power capacity scaling of additive noise channels whose noise arises from the first-hitting location of a multidimensional drift-diffusion process on an absorbing hyperplane. By identifying the underlying stochastic transport mechanism as a Gaussian variance-mixture, we introduce and analyze the Normally-Drifted First-Hitting Location (NDFHL) family as a geometry-driven model for boundary-induced noise. Under a second-moment constraint, we derive an exact high-SNR capacity expansion and show that the asymptotic upper and lower bounds coincide at the constant level, yielding a vanishing capacity gap. As a consequence, isotropic Gaussian signaling is asymptotically capacity-achieving for all fixed drift strengths, despite the non-Gaussian and semi-heavy-tailed nature of the noise. The pre-log factor is determined solely by the dimension of the receiving boundary, revealing a geometric origin of the channel's degrees of freedom. The refined expansion further uncovers an entropy-dominant universality, whereby all physical parameters of the transport process -- including drift strength, diffusion coefficient, and boundary separation -- affect the capacity only through the differential entropy of the induced noise. Although the NDFHL density does not admit a simple closed form, its entropy is shown to be finite and to vary continuously as the drift vanishes, thereby connecting the finite-variance regime with the singular infinite-variance Cauchy limit. Together, these results provide a unified geometric and information-theoretic characterization of boundary-hitting channels across both regular and singular transport regimes.

</details>


### [49] [Deep learning based Channel Estimation and Beamforming in Movable Antenna Systems](https://arxiv.org/abs/2602.07870)
*Kaijun Feng,Ziwei Wan,Anwen Liao,Wenyan Ma,Lipeng Zhu,Zhenyu Xiao,Zhen Gao,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种用于多用户宽带可移动天线系统的深度学习框架，集成了信道估计、天线位置优化和波束成形，通过两阶段信道估计和Transformer网络实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 可移动天线技术通过天线移动优化信道条件来提升系统性能，但多用户宽带系统中需要解决信道估计、天线位置优化和波束成形的联合优化挑战。

Method: 1) 两阶段信道估计：先通过压缩感知从有限测量重建信道矩阵，再用Swin-Transformer去噪网络提升精度；2) Transformer网络将候选位置的信道状态信息序列映射到最优天线位置；3) 结合模型驱动的加权最小均方误差波束成形方法。

Result: 仿真结果表明，所提方法在各种条件下相比现有方法实现了更优的性能。

Conclusion: 该深度学习框架为可移动天线系统提供了一种高效的信道估计、天线位置优化和波束成形集成解决方案，显著提升了系统性能。

Abstract: Movable antenna (MA) has emerged as a promising technology for future wireless systems. Compared with traditional fixed-position antennas, MA improves system performance by antenna movement to optimize channel conditions. For multiuser wideband MA systems, this paper proposes deep learning-based framework integrating channel estimation (CE), antenna position optimization, and beamforming, with a clear workflow and enhanced efficiency. Specifically, to obtain accurate channel state information (CSI), we design a two-stage CE mechanism: first reconstructing the channel matrix from limited measurements via compressive sensing, then introducing a Swin-Transformer-based denoising network to refine CE accuracy for subsequent optimization. Building on this, we address the joint optimization challenge by proposing a Transformer-based network that intelligently maps CSI sequences of candidate positions to optimal MA positions while combining a model-driven weighted minimum mean square error (WMMSE) beamforming approach to achieve better performance. Simulation results demonstrate that the proposed methods achieve superior performance compared with existing counterparts under various conditions. The codes about this work are available at https://github.com/ZiweiWan/Code-4-DL-MA-CE-BF.

</details>


### [50] [Deep Variable-Length Feedback Codes](https://arxiv.org/abs/2602.07881)
*Yu Ding,Yulin Shao*

Main category: cs.IT

TL;DR: DeepVLF是一种基于深度学习的可变长度反馈编码框架，通过动态调整传输长度显著提升编码性能，在高码率下表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的反馈信道编码存在三个主要限制：固定块长度、高码率下性能下降、无法充分利用反馈的自适应潜力。需要一种更灵活的编码框架来解决这些问题。

Method: 提出DeepVLF编码框架，包含两种互补架构：DeepVLF-R（接收端驱动终止）和DeepVLF-T（发送端控制终止）。两种架构都采用比特分组划分和基于Transformer的编码器-解码器网络，实现细粒度的码率自适应。

Result: 在AWGN和5G-NR衰落信道上的评估表明，DeepVLF显著优于现有学习反馈编码方法：在相同误块率下减少20%-55%的信道使用次数，在高码率下将错误平层降低数个数量级。

Conclusion: DeepVLF框架成功解决了现有学习反馈编码的限制，模型自主学习到类似经典Schalkwijk-Kailath编码的两阶段策略，体现了学习编码的可解释性和信息论对齐性。

Abstract: Deep learning has enabled significant advances in feedback-based channel coding, yet existing learned schemes remain fundamentally limited: they employ fixed block lengths, suffer degraded performance at high rates, and cannot fully exploit the adaptive potential of feedback. This paper introduces Deep Variable-Length Feedback (DeepVLF) coding, a flexible coding framework that dynamically adjusts transmission length via learned feedback. We propose two complementary architectures: DeepVLF-R, where termination is receiver-driven, and DeepVLF-T, where the transmitter controls termination. Both architectures leverage bit-group partitioning and transformer-based encoder-decoder networks to enable fine-grained rate adaptation in response to feedback. Evaluations over AWGN and 5G-NR fading channels demonstrate that DeepVLF substantially outperforms state-of-the-art learned feedback codes. It achieves the same block error rate with 20%-55% fewer channel uses and lowers error floors by orders of magnitude, particularly in high-rate regimes. Encoding dynamics analysis further reveals that the models autonomously learn a two-phase strategy analogous to classical Schalkwijk-Kailath coding: an initial information-carrying phase followed by a noise-cancellation refinement phase. This emergent behavior underscores the interpretability and information-theoretic alignment of the learned codes.

</details>


### [51] [Rich-ARQ: From 1-bit Acknowledgment to Rich Neural Coded Feedback](https://arxiv.org/abs/2602.07886)
*Enhao Chen,Yulin Shao*

Main category: cs.IT

TL;DR: Rich-ARQ：用高维神经编码反馈替代传统1比特ACK/NACK，实现发射端与接收端的协作式物理层信道编码，显著提升性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 传统无线通信中的1比特ACK/NACK反馈机制信息量有限，只是被动确认，无法充分利用反馈信息。需要将被动确认转变为主动协作，通过信息丰富的反馈向量提升通信性能。

Method: 提出Rich-ARQ范式，引入神经编码反馈机制。开发了新型异步反馈编码，消除反馈延迟导致的停滞，动态适应信道波动，并采用轻量级编码器适合设备端部署。构建了首个全栈、标准兼容的软件定义无线电原型，将AI推理与严格无线电时序解耦。

Result: 通过全面的空中实验证明，Rich-ARQ相比传统1比特混合ARQ获得显著的信噪比增益，相比先前基于学习的反馈编码实现显著的延迟降低，将智能反馈从理论推向实际高性能应用。

Conclusion: Rich-ARQ成功将无线通信中的反馈机制从简单的二进制确认转变为高维协作式编码，为下一代网络提供了实用、高性能的智能反馈解决方案，实现了从理论到实践的跨越。

Abstract: This paper reimagines the foundational feedback mechanism in wireless communication, transforming the prevailing 1-bit binary ACK/NACK with a high-dimensional, information-rich vector to transform passive acknowledgment into an active collaboration. We present Rich-ARQ, a paradigm that introduces neural-coded feedback for collaborative physical-layer channel coding between transmitter and receiver. To realize this vision in practice, we develop a novel asynchronous feedback code that eliminates stalling from feedback delays, adapts dynamically to channel fluctuations, and features a lightweight encoder suitable for on-device deployment. We materialize this concept into the first full-stack, standard-compliant software-defined radio prototype, which decouples AI inference from strict radio timing. Comprehensive over-the-air experiments demonstrate that Rich-ARQ achieves significant SNR gains over conventional 1-bit hybrid ARQ and remarkable latency reduction over prior learning-based feedback codes, moving the promise of intelligent feedback from theory to a practical, high-performance reality for next-generation networks.

</details>


### [52] [OFDM Enabled Over-the-Air Computation Systems with Two-Dimensional Fluid Antennas](https://arxiv.org/abs/2602.07953)
*Heyang Xiong,Quanzhong Li,Qi Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于流体天线系统的OFDM空中计算方案，通过优化天线位置和收发器设计来降低计算均方误差。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统能够利用无线信道中的空间自由度，但在频率选择性环境中如何有效利用这些自由度尚未充分研究。本文旨在通过二维流体天线系统增强OFDM空中计算的性能。

Method: 将原始计算均方误差最小化问题分解为发射预编码器优化问题，以及天线位置与接收合并器联合优化问题。后者采用主最小化方法与顺序优化相结合的方法求解。

Result: 数值结果表明，所提出的方案相比固定位置天线方案能够显著降低计算均方误差。

Conclusion: 通过优化流体天线系统的天线位置和收发器设计，可以在频率选择性环境中有效利用空间自由度，显著提升OFDM空中计算系统的性能。

Abstract: Fluid antenna system (FAS) is able to exploit spatial degrees of freedom (DoFs) in wireless channels. In this letter, to exploit spatial DoFs in frequency-selective environments, we investigate an orthogonal frequency division multiplexing enabled over-the-air computation system, where the access point is equipped with a two-dimensional FAS to enhance performance. We solve the computation mean square error (MSE) minimization problem by transforming the original problem into transmit precoders optimization problem and antenna positions optimization along with receive combiners optimization problem. The latter is solved via a majorization-minimization approach combined with sequential optimization. Numerical results confirm that the proposed scheme achieves MSE reduction over the scheme with fixed position antennas.

</details>


### [53] [Tighter Information-Theoretic Generalization Bounds via a Novel Class of Change of Measure Inequalities](https://arxiv.org/abs/2602.07999)
*Yanxiao Liu,Yijun Fan an Deniz Gündüz*

Main category: cs.IT

TL;DR: 提出基于f-散度数据处理不等式的统一框架，得到更紧的测度变换不等式，应用于信息论泛化误差分析，得到新的高概率泛化界


<details>
  <summary>Details</summary>
Motivation: 现有泛化误差分析中的信息论方法存在局限性，需要更强大且灵活的框架来推导更紧的泛化界，并统一处理多种信息度量和应用场景

Method: 基于f-散度的数据处理不等式构建统一框架，推导出涵盖f-散度、Rényi散度和α-互信息等广泛信息度量的测度变换不等式，并将其应用于随机学习算法的泛化误差分析

Result: 获得了比现有方法更紧的高概率信息论泛化界，同时通过简化分析恢复了多个已知最佳结果，框架灵活适应条件互信息、PAC-Bayesian理论和差分隐私等多种设置

Conclusion: 提出的基于数据处理不等式的统一框架简单而强大，能够推导出更紧的测度变换不等式和泛化界，为信息论泛化分析提供了灵活且通用的工具

Abstract: In this paper, we propose a novel class of change of measure inequalities via a unified framework based on the data processing inequality for $f$-divergences, which is surprisingly elementary yet powerful enough to yield tighter inequalities. We provide change of measure inequalities in terms of a broad family of information measures, including $f$-divergences (with Kullback-Leibler divergence and $χ^2$-divergence as special cases), Rényi divergence, and $α$-mutual information (with maximal leakage as a special case). We then embed these inequalities into the analysis of generalization error for stochastic learning algorithms, yielding novel and tighter high-probability information-theoretic generalization bounds, while also recovering several best-known results via simplified analyses. A key advantage of our framework is its flexibility: it readily adapts to a range of settings, including the conditional mutual information framework, PAC-Bayesian theory, and differential privacy mechanisms, for which we derive new generalization bounds.

</details>


### [54] [Term Coding and Dispersion: A Perfect-vs-Rate Complexity Dichotomy for Information Flow](https://arxiv.org/abs/2602.08110)
*Søren Riis*

Main category: cs.IT

TL;DR: 论文提出了"项编码"框架用于离散数学和信息流中的极值问题，通过选择函数符号的解释来最大化满足项方程系统的赋值数量。特别关注"分散"问题，即最大化项映射的像大小，证明最大分散是Θ(n^D)，其中D是相关有向图的猜测数，并给出了计算D的多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 研究离散数学和信息流中的极值问题，特别是如何通过选择函数符号的解释来最大化满足项方程系统的赋值数量。动机在于理解项映射的像大小如何受函数解释的影响，以及相关的计算复杂性。

Method: 提出了"项编码"框架，特别关注"分散"问题。将项映射的像大小与相关有向图的猜测数联系起来，证明了最大分散是Θ(n^D)，其中D是猜测数。开发了多项式时间算法来计算指数D。

Result: 1. 最大分散是Θ(n^D)，D是相关有向图的猜测数；2. 给出了计算D的多项式时间算法；3. 证明了当r≥3时，判断是否存在完美分散（即Disp_n(t)=n^r）是不可判定的；4. 相应的渐近率阈值问题是多项式时间可判定的。

Conclusion: 项编码框架为离散数学和信息流中的极值问题提供了新的视角。分散问题的最大增长率由相关有向图的猜测数决定，虽然计算指数D是高效的，但判断完美分散的存在性在r≥3时是不可判定的，这揭示了问题的计算复杂性层次。

Abstract: We introduce a new framework term coding for extremal problems in discrete mathematics and information flow, where one chooses interpretations of function symbols so as to maximise the number of satisfying assignments of a finite system of term equations.
  We then focus on dispersion, the special case in which the system defines a term map $Θ^\mathcal I:\A^k\to\A^r$ and the objective is the size of its image. Writing $n:=|\A|$, we show that the maximum dispersion is $Θ(n^D)$ for an integer exponent $D$ equal to the guessing number of an associated directed graph, and we give a polynomial-time algorithm to compute $D$. In contrast, deciding whether \emph{perfect dispersion} ever occurs (i.e.\ whether $\Disp_n(\mathbf t)=n^r$ for some finite $n\ge 2$) is undecidable once $r\ge 3$, even though the corresponding asymptotic rate-threshold questions are polynomial-time decidable.

</details>


### [55] [Optimal Transmit Beamforming for MIMO ISAC with Unknown Target and User Locations](https://arxiv.org/abs/2602.08255)
*Yizhuo Wang,Shuowen Zhang*

Main category: cs.IT

TL;DR: 研究MIMO ISAC系统中目标和用户位置均未知且随机时的波束成形设计，基于概率分布信息建立性能指标，推导最优解并揭示位置分布相似性对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在MIMO ISAC系统中，当传感目标和通信用户的位置都未知且随机时，如何利用空间资源设计发射波束成形，使传感和通信都能获得统计上满意的性能是一个难题。同时，研究目标和用户位置分布相似性是否有利于ISAC性能。

Method: 基于概率分布信息建立通信性能指标（期望速率）和传感性能指标（后验克拉美罗界PCRB），然后构建最小化PCRB受期望速率约束的波束成形优化问题，推导最优解。分析最优发射协方差矩阵的秩上界，并研究动态波束成形策略的必要性。

Result: 推导出最优发射协方差矩阵的秩上界为所有可能用户位置的MIMO信道矩阵之和。证明静态波束成形策略足以达到最优性能，无需动态调整。数值结果表明，当目标和用户位置分布相似时，ISAC性能提升，并提供了BS-用户/目标关联策略的有用见解。

Conclusion: 在目标和用户位置均随机未知的MIMO ISAC系统中，基于概率分布信息设计波束成形是可行的，静态波束成形策略已足够，且目标和用户位置分布相似性有利于提升ISAC性能。

Abstract: This paper studies a challenging scenario in a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system where the locations of the sensing target and the communication user are both unknown and random, while only their probability distribution information is known. In this case, how to fully utilize the spatial resources by designing the transmit beamforming such that both sensing and communication can achieve satisfactory performance statistically is a difficult problem, which motivates the study in this paper. Moreover, we aim to reveal if it is desirable to have similar probability distributions for the target and user locations in terms of the ISAC performance. Firstly, based on only probability distribution information, we establish communication and sensing performance metrics via deriving the expected rate or posterior Cramér-Rao bound (PCRB). Then, we formulate the transmit beamforming optimization problem to minimize the PCRB subject to the expected rate constraint, for which the optimal solution is derived. It is unveiled that the rank of the optimal transmit covariance matrix is upper bounded by the summation of MIMO communication channel matrices for all possible user locations. Furthermore, due to the need to cater to multiple target/user locations, we investigate whether dynamically employing different beamforming designs over different time slots improves the performance. It is proven that using a static beamforming strategy is sufficient for achieving the optimal performance. Numerical results validate our analysis, show that ISAC performance improves as the target/user location distributions become similar, and provide useful insights on the BS-user/-target association strategy.

</details>


### [56] [Hierarchical Subcode Ensemble Decoding of Polar Codes](https://arxiv.org/abs/2602.08391)
*Yubeen Jo,Geon Choi,Chanho Park,Namyoon Lee*

Main category: cs.IT

TL;DR: 提出分层子码集成解码(HSCED)框架，通过递归生成分层结构的子码奇偶校验约束，在保证线性覆盖的同时扩展集成规模，显著提升极化码的BP解码性能。


<details>
  <summary>Details</summary>
Motivation: 现有子码集成解码方法缺乏系统性的扩展机制，难以在保持线性覆盖特性的同时增加集成规模，限制了其性能提升潜力。

Method: 采用分层递归方式生成子码奇偶校验约束，构建分层结构的子码集成，确保每个层级都保持线性覆盖特性，从而在控制复杂度的情况下实现大规模集成。

Result: 将HSCED应用于极化码的BP解码，在相同解码延迟约束下，相比标准BP和传统子码集成解码，显著降低了块错误率。

Conclusion: HSCED提供了一种可扩展的子码集成解码框架，能够有效避免陷阱结构，显著提升迭代解码性能，特别适用于极化码等受停止集效应限制的码型。

Abstract: Subcode-ensemble decoders improve iterative decoding by running multiple decoders in parallel over carefully chosen subcodes, increasing the likelihood that at least one decoder avoids the dominant trapping structures. Achieving strong diversity gains, however, requires constructing many subcodes that satisfy a linear covering property-yet existing approaches lack a systematic way to scale the ensemble size while preserving this property. This paper introduces hierarchical subcode ensemble decoding (HSCED), a new ensemble decoding framework that expands the number of constituent decoders while still guaranteeing linear covering. The key idea is to recursively generate subcode parity constraints in a hierarchical structure so that coverage is maintained at every level, enabling large ensembles with controlled complexity. To demonstrate its effectiveness, we apply HSCED to belief propagation (BP) decoding of polar codes, where dense parity-check matrices induce severe stopping-set effects that limit conventional BP. Simulations confirm that HSCED delivers significant block-error-rate improvements over standard BP and conventional subcode-ensemble decoding under the same decoding-latency constraint.

</details>


### [57] [Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes](https://arxiv.org/abs/2602.08501)
*Yubeen Jo,Geon Choi,Yongjune Kim,Namyoon Lee*

Main category: cs.IT

TL;DR: 提出一种两阶段近最大似然解码框架，适用于任何线性分组码，通过低复杂度解码器作为第一级，失败时激活基于多点多码重球面解码的第二级，实现低延迟近ML性能。


<details>
  <summary>Details</summary>
Motivation: URLLC使用短包传输，有限块长效应使得近ML解码很重要，但传统ML解码计算成本过高。需要一种既能达到近ML性能又保持低复杂度的解码方案。

Method: 提出两阶段解码框架：第一阶段使用低复杂度解码器生成候选码字和CRC校验；失败时激活第二阶段MP-WSD解码器，通过预计算低权重码字生成结构化扰动，在欧几里得球面内迭代搜索，逐步缩小搜索范围。

Result: 仿真结果表明，该解码器在短块长、低码率编码下能够达到近ML性能，同时保持低解码延迟。在高信噪比下，第一阶段成功率高，第二级很少激活，平均复杂度低。

Conclusion: 该两阶段解码框架为URLLC提供了一种实用的近ML解码方案，平衡了性能与复杂度，特别适用于短包通信场景。

Abstract: Ultra-reliable low-latency communications (URLLC) operate with short packets, where finite-blocklength effects make near-maximum-likelihood (near-ML) decoding desirable but often too costly. This paper proposes a two-stage near-ML decoding framework that applies to any linear block code. In the first stage, we run a low-complexity decoder to produce a candidate codeword and a cyclic redundancy check. When this stage succeeds, we terminate immediately. When it fails, we invoke a second-stage decoder, termed multipoint code-weight sphere decoding (MP-WSD). The central idea behind {MP-WSD} is to concentrate the ML search where it matters. We pre-compute a set of low-weight codewords and use them to generate structured local perturbations of the current estimate. Starting from the first-stage output, MP-WSD iteratively explores a small Euclidean sphere of candidate codewords formed by adding selected low-weight codewords, tightening the search region as better candidates are found. This design keeps the average complexity low: at high signal-to-noise ratio, the first stage succeeds with high probability and the second stage is rarely activated; when it is activated, the search remains localized. Simulation results show that the proposed decoder attains near-ML performance for short-blocklength, low-rate codes while maintaining low decoding latency.

</details>


### [58] [Reliable one-bit quantization of bandlimited graph data via single-shot noise shaping](https://arxiv.org/abs/2602.08669)
*Johannes Maly,Anna Veselovska*

Main category: cs.IT

TL;DR: 提出一种高效的单次噪声整形方法，用于量化图结构带限数据，在低通滤波下保持信息完整性，支持任意比特级别（包括单比特）量化。


<details>
  <summary>Details</summary>
Motivation: 图数据在自然科学和机器学习中普遍存在，需要量化图结构带限数据，在低比特率下保持低通滤波后的信息完整性。

Method: 提出一种高效的单次噪声整形方法，该方法能够实现最先进的性能，并带有严格的误差界限。

Result: 该方法在量化图结构带限数据方面达到最先进性能，支持任意比特级别量化，包括极端情况下的单比特量化。

Conclusion: 提出的单次噪声整形方法为图结构带限数据提供了一种高效可靠的量化方案，相比现有方法具有更好的灵活性和性能。

Abstract: Graph data are ubiquitous in natural sciences and machine learning. In this paper, we consider the problem of quantizing graph structured, bandlimited data to few bits per entry while preserving its information under low-pass filtering. We propose an efficient single-shot noise shaping method that achieves state-of-the-art performance and comes with rigorous error bounds. In contrast to existing methods it allows reliable quantization to arbitrary bit-levels including the extreme case of using a single bit per data coefficient.

</details>


### [59] [Trellis codes with a good distance profile constructed from expander graphs](https://arxiv.org/abs/2602.08718)
*Yubin Zhu,Zitan Chen*

Main category: cs.IT

TL;DR: 该论文推导了网格码的自由距离和列距离的Singleton型界，证明了网格码在某些时刻的列距离可以超过卷积码，并利用扩展图构造了接近最大距离轮廓卷积码性能的网格码。


<details>
  <summary>Details</summary>
Motivation: 研究网格码的距离特性，探索其相对于卷积码的潜在优势。现有最大距离轮廓卷积码的构造需要字母表大小随输出符号数量指数增长，这在实际应用中存在限制。

Method: 1. 推导网格码的自由距离和列距离的Singleton型界；2. 理论分析网格码与卷积码的距离特性对比；3. 利用扩展图构造恒定字母表大小的网格码。

Result: 1. 网格码在某些时刻的列距离可以超过卷积码；2. 构造的网格码在恒定字母表大小下，其率-距离权衡可以任意接近最大距离轮廓卷积码的性能；3. 相比需要指数增长字母表的卷积码构造，网格码构造更具实用性。

Conclusion: 网格码在距离特性方面具有优势，特别是在恒定字母表大小下能够实现接近最大距离轮廓卷积码的性能，这为实际编码系统提供了更实用的选择。

Abstract: We derive Singleton-type bounds on the free distance and column distances of trellis codes. Our results show that, at a given time instant, the maximum attainable column distance of trellis codes can exceed that of convolutional codes. Moreover, using expander graphs, we construct trellis codes over constant-size alphabets that achieve a rate-distance trade-off arbitrarily close to that of convolutional codes with a maximum distance profile. By comparison, all known constructions of convolutional codes with a maximum distance profile require working over alphabets whose size grows at least exponentially with the number of output symbols per time instant.

</details>


### [60] [Clique-Based Deletion-Correcting Codes via Penalty-Guided Clique Search](https://arxiv.org/abs/2602.08952)
*Aniruddh Pandav,Rajshekhar V Bhat*

Main category: cs.IT

TL;DR: 本文通过最大团问题(MCP)构建d-删除纠错二进制码，采用惩罚引导团搜索(PGCS)算法获得比现有图启发式方法更大的码本，并提出优化的LCS解码器降低解码复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究如何构建高效的d-删除纠错二进制码，现有图启发式方法(如最小度和着色方法)在寻找最大码本方面存在局限，需要更有效的算法来获得更大的码本。

Method: 将删除纠错码构建问题转化为最大团问题(MCP)：顶点表示候选码字，边连接那些最长公共子序列(LCS)距离能保证纠正最多d个删除的码字对。采用惩罚引导团搜索(PGCS)算法，这是一种受动态局部搜索(DLS)启发的轻量级随机团搜索启发式方法。对于分段接收的解码，提出优化的LCS解码器，利用符号计数过滤和提前终止技术。

Result: PGCS算法在块长度n=8-14和删除参数d=1-3时，比现有图启发式方法(最小度和着色方法)产生更大的码本。在某些有限长度情况下，获得的码本大小达到已知最优值，并优于Helberg码等经典构造。优化的LCS解码器显著减少了LCS评估次数，平均解码复杂度远低于基线O(|C|n²)方法。

Conclusion: PGCS算法在构建d-删除纠错二进制码方面优于现有图启发式方法，优化的LCS解码器能有效降低解码复杂度，为删除纠错码的设计和解码提供了实用高效的解决方案。

Abstract: We study the construction of $d$-deletion-correcting binary codes by formulating the problem as a Maximum Clique Problem (MCP). In this formulation, vertices represent candidate codewords and edges connect pairs whose longest common subsequence (LCS) distance guarantees correction of up to $d$ deletions. A valid codebook corresponds to a clique in the resulting graph, and finding the largest codebook is equivalent to identifying a maximum clique. While MCP-based formulations for deletion-correcting codes have previously been explored, we demonstrate that applying Penalty-Guided Clique Search (PGCS), a lightweight stochastic clique-search heuristic inspired by Dynamic Local Search (DLS), consistently yields larger codebooks than existing graph-based heuristics, including minimum-degree and coloring methods, for block lengths $n = 8,9,\dots,14$ and deletion parameters $d = 1,2,3$. In several finite-length regimes, the resulting codebooks match known optimal sizes and outperform classical constructions such as Helberg codes. For decoding under segmented reception, where codeword boundaries are known, we propose an optimized LCS-based decoder that exploits symbol-count filtering and early termination to substantially reduce the number of LCS evaluations while preserving exact decoding guarantees. These optimizations lead to significantly lower average-case decoding complexity than the baseline $O(|C| n^2)$ approach.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [61] [Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss](https://arxiv.org/abs/2602.07022)
*Yucheng Zhou,Hao Li,Jianbing Shen*

Main category: eess.IV

TL;DR: 该论文对使用扩散损失的扩散模型和自回归模型进行了理论分析，提出自回归扩散在条件生成中具有优势，并引入基于最优传输理论的条件精炼方法来解决条件不一致问题。


<details>
  <summary>Details</summary>
Motivation: 最近的研究探索了自回归模型在图像生成中的应用，并将扩散模型与自回归框架结合以通过扩散损失优化图像生成。本文旨在从理论上分析这两种方法，特别关注条件生成中的问题。

Method: 1. 对使用扩散损失的扩散模型和自回归模型进行理论分析比较；2. 提出基于最优传输理论的条件精炼方法，将条件精炼表述为Wasserstein梯度流；3. 通过实验验证方法的有效性。

Result: 理论分析表明：自回归模型中的块去噪优化能有效缓解条件误差并稳定条件分布；自回归条件生成能精炼条件，使条件误差影响呈指数衰减。实验证明该方法优于传统的扩散模型和带扩散损失的自回归模型。

Conclusion: 自回归扩散模型在条件生成方面具有理论优势，结合最优传输理论的条件精炼方法能有效解决条件不一致问题，为图像生成提供了更优的解决方案。

Abstract: Recent studies have explored autoregressive models for image generation, with promising results, and have combined diffusion models with autoregressive frameworks to optimize image generation via diffusion losses. In this study, we present a theoretical analysis of diffusion and autoregressive models with diffusion loss, highlighting the latter's advantages. We present a theoretical comparison of conditional diffusion and autoregressive diffusion with diffusion loss, demonstrating that patch denoising optimization in autoregressive models effectively mitigates condition errors and leads to a stable condition distribution. Our analysis also reveals that autoregressive condition generation refines the condition, causing the condition error influence to decay exponentially. In addition, we introduce a novel condition refinement approach based on Optimal Transport (OT) theory to address ``condition inconsistency''. We theoretically demonstrate that formulating condition refinement as a Wasserstein Gradient Flow ensures convergence toward the ideal condition distribution, effectively mitigating condition inconsistency. Experiments demonstrate the superiority of our method over diffusion and autoregressive models with diffusion loss methods.

</details>


### [62] [Guidestar-Free Adaptive Optics with Asymmetric Apertures](https://arxiv.org/abs/2602.07029)
*Weiyun Jiang,Haiyun Guo,Christopher A. Metzler,Ashok Veeraraghavan*

Main category: eess.IV

TL;DR: 首个无需导星或波前传感器的闭环自适应光学系统，使用非对称孔径和机器学习实现实时波前传感与光学校正


<details>
  <summary>Details</summary>
Motivation: 传统自适应光学系统需要导星和波前传感器，限制了其在自然场景中的应用。本文旨在开发无需导星和波前传感器的实时自适应光学系统，能够在未知遮挡物条件下对自然场景进行光学校正。

Method: 结合三个关键要素：1) 光学路径中的非对称孔径，实现基于相位恢复的波前传感；2) 一对机器学习算法，从自然场景测量中估计点扩散函数并重建相位像差；3) 空间光调制器进行光学校正。在未知遮挡物下的密集自然场景上进行实验验证。

Result: 该方法优于最先进的无导星波前整形方法，使用数量级更少的测量（一个数量级）和计算量（三个数量级）。成功实现了对自然场景的实时光学校正。

Conclusion: 首次展示了无需导星和波前传感器的闭环自适应光学系统，通过非对称孔径和机器学习实现了实时波前传感与校正，为自适应光学在自然场景中的应用开辟了新途径。

Abstract: This work introduces the first closed-loop adaptive optics (AO) system capable of optically correcting aberrations in real-time without a guidestar or a wavefront sensor. Nearly 40 years ago, Cederquist et al. demonstrated that asymmetric apertures enable phase retrieval (PR) algorithms to perform fully computational wavefront sensing, albeit at a high computational cost. More recently, Chimitt et al. extended this approach with machine learning and demonstrated real-time wavefront sensing using only a single (guidestar-based) point-spread-function (PSF) measurement. Inspired by these works, we introduce a guidestar-free AO framework built around asymmetric apertures and machine learning. Our approach combines three key elements: (1) an asymmetric aperture placed in the optical path that enables PR-based wavefront sensing, (2) a pair of machine learning algorithms that estimate the PSF from natural scene measurements and reconstruct phase aberrations, and (3) a spatial light modulator that performs optical correction. We experimentally validate this framework on dense natural scenes imaged through unknown obscurants. Our method outperforms state-of-the-art guidestar-free wavefront shaping methods, using an order of magnitude fewer measurements and three orders of magnitude less computation.

</details>


### [63] [MTS-CSNet: Multiscale Tensor Factorization for Deep Compressive Sensing on RGB Images](https://arxiv.org/abs/2602.07056)
*Mehmet Yamac,Lei Xu,Serkan Kiranyaz,Moncef Gabbouj*

Main category: eess.IV

TL;DR: MTSCSNet提出基于多尺度张量求和分解的压缩感知框架，通过模式线性变换和多尺度求和实现大感受野和跨维度相关性建模，在图像重建上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的压缩感知方法通常使用卷积或块状全连接层学习采样算子，这些方法感受野有限，且对高维数据扩展性差。需要一种能有效建模跨维度相关性、具有大感受野且参数高效的结构化算子。

Method: 提出MTSCSNet框架，基于多尺度张量求和分解。MTS通过模式线性变换和多尺度求和实现高效的多维信号处理。该框架将MTS用作可学习的CS算子进行张量空间的线性降维，其伴随定义初始反投影，然后在重建阶段直接细化估计，形成简单的前馈架构。

Result: 在标准CS基准测试中，MTSCSNet在RGB图像重建上达到最先进性能，相比近期基于扩散的方法获得显著PSNR提升和更快推理速度，同时使用更紧凑的前馈架构。

Conclusion: MTSCSNet通过多尺度张量求和分解提供了一种参数和计算高效的压缩感知框架，能够有效建模跨维度相关性并实现大感受野，在图像重建任务上表现出优越性能。

Abstract: Deep learning based compressive sensing (CS) methods typically learn sampling operators using convolutional or block wise fully connected layers, which limit receptive fields and scale poorly for high dimensional data. We propose MTSCSNet, a CS framework based on Multiscale Tensor Summation (MTS) factorization, a structured operator for efficient multidimensional signal processing. MTS performs mode-wise linear transformations with multiscale summation, enabling large receptive fields and effective modeling of cross-dimensional correlations. In MTSCSNet, MTS is first used as a learnable CS operator that performs linear dimensionality reduction in tensor space, with its adjoint defining the initial back-projection, and is then applied in the reconstruction stage to directly refine this estimate. This results in a simple feed-forward architecture without iterative or proximal optimization, while remaining parameter and computation efficient. Experiments on standard CS benchmarks show that MTSCSNet achieves state-of-the-art reconstruction performance on RGB images, with notable PSNR gains and faster inference, even compared to recent diffusion-based CS methods, while using a significantly more compact feed-forward architecture.

</details>


### [64] [U-Net Based Image Enhancement for Short-time Muon Scattering Tomography](https://arxiv.org/abs/2602.07060)
*Haochen Wang,Pei Yu,Liangwen Chen,Weibo He,Yu Zhang,Yuhong Yu,Xueheng Zhang,Lei Yang,Zhiyu Sun*

Main category: eess.IV

TL;DR: 提出基于U-Net的框架，利用模拟数据训练的深度学习模型来增强低统计量μ子散射断层扫描图像质量，显著提升SSIM并降低LPIPS指标。


<details>
  <summary>Details</summary>
Motivation: μ子散射断层扫描（MST）是一种有前景的非侵入式检测技术，但实际应用中短时间MST因μ子通量有限导致图像质量差，阻碍了其实际部署。

Method: 提出基于U-Net的深度学习框架，使用模拟MST数据生成的最近接近点（PoCA）图像进行训练，然后将训练好的模型应用于实验MST数据以增强图像质量。

Result: 该方法显著提升了图像质量：结构相似性指数从0.7232提高到0.9699，学习感知图像块相似度从0.3604降低到0.0270，有效改善了低统计量MST图像。

Conclusion: 该方法能有效增强低统计量MST图像质量，为短时间MST的实际应用铺平了道路，解决了μ子通量有限导致的图像质量问题。

Abstract: Muon Scattering Tomography (MST) is a promising non-invasive inspection technique, yet the practical application of short-time MST is hindered by poor image quality due to limited muon flux. To address this limitation, we propose a U-Net-based framework trained on Point of Closest Approach (PoCA) images reconstructed with simulation MST data to enhance image quality. When applied to experimental MST data, the framework significantly improves image quality, increasing the Structural Similarity Index Measure (SSIM) from 0.7232 to 0.9699 and decreasing the Learned Perceptual Image Patch Similarity (LPIPS) from 0.3604 to 0.0270. These results demonstrate that our method can effectively enhance low-statistics MST images, thereby paving the way for the practical deployment of short-time MST.

</details>


### [65] [MRI Cross-Modal Synthesis: A Comparative Study of Generative Models for T1-to-T2 Reconstruction](https://arxiv.org/abs/2602.07068)
*Ali Alqutayfi,Sadam Al-Azani*

Main category: eess.IV

TL;DR: 本文比较了三种生成模型（Pix2Pix GAN、CycleGAN、VAE）在T1到T2 MRI图像合成中的表现，发现CycleGAN在PSNR和SSIM指标上最优，Pix2Pix GAN在MSE上最好，VAE则在潜在空间表示方面有优势。


<details>
  <summary>Details</summary>
Motivation: MRI跨模态合成能够减少扫描时间同时保持诊断信息，具有重要临床价值。需要比较不同生成模型在T1到T2 MRI重建任务中的表现，为研究者和临床医生提供选择依据。

Method: 使用BraTS 2020数据集（11,439个训练切片和2,000个测试切片），比较了三种最先进的生成模型：Pix2Pix GAN、CycleGAN和变分自编码器（VAE）。评估指标包括均方误差（MSE）、峰值信噪比（PSNR）和结构相似性指数（SSIM）。

Result: 所有模型都能成功从T1输入合成T2图像。CycleGAN获得最高PSNR（32.28 dB）和SSIM（0.9008），Pix2Pix GAN提供最低MSE（0.005846）。VAE定量性能较低（MSE: 0.006949, PSNR: 24.95 dB, SSIM: 0.6573），但在潜在空间表示和采样能力方面有优势。

Conclusion: 这项比较研究为研究者和临床医生根据特定需求和数据约束选择适当的MRI合成生成模型提供了有价值的见解。不同模型各有优劣，需要根据具体应用场景进行选择。

Abstract: MRI cross-modal synthesis involves generating images from one acquisition protocol using another, offering considerable clinical value by reducing scan time while maintaining diagnostic information. This paper presents a comprehensive comparison of three state-of-the-art generative models for T1-to-T2 MRI reconstruction: Pix2Pix GAN, CycleGAN, and Variational Autoencoder (VAE). Using the BraTS 2020 dataset (11,439 training and 2,000 testing slices), we evaluate these models based on established metrics including Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index (SSIM). Our experiments demonstrate that all models can successfully synthesize T2 images from T1 inputs, with CycleGAN achieving the highest PSNR (32.28 dB) and SSIM (0.9008), while Pix2Pix GAN provides the lowest MSE (0.005846). The VAE, though showing lower quantitative performance (MSE: 0.006949, PSNR: 24.95 dB, SSIM: 0.6573), offers advantages in latent space representation and sampling capabilities. This comparative study provides valuable insights for researchers and clinicians selecting appropriate generative models for MRI synthesis applications based on their specific requirements and data constraints.

</details>


### [66] [Exploring Polarimetric Properties Preservation during Reconstruction of PolSAR images using Complex-valued Convolutional Neural Networks](https://arxiv.org/abs/2602.07094)
*Quentin Gabot,Joana Frontera-Pons,Jérémy Fix,Chengfang Ren,Jean-Philippe Ovarlez*

Main category: eess.IV

TL;DR: 该论文研究了使用复数神经网络处理极化SAR数据，证明复数卷积自编码器能有效压缩和重建数据，同时保持物理特性，优于实数网络。


<details>
  <summary>Details</summary>
Motivation: 极化SAR数据的复数特性需要专门的算法直接处理复数表示，但深度学习社区对此探索不足，许多研究将复数信号转换为实数域后再应用传统实数模型。

Method: 利用复数神经网络，研究复数卷积自编码器的性能，通过Pauli、Krogager、Cameron相干分解和非相干H-α分解来评估物理特性保持能力。

Result: 复数神经网络能有效压缩和重建全极化SAR数据，同时保持基本物理特性，且优于实数对应网络。

Conclusion: 复数神经网络为开发稳健、物理信息丰富的复数生成模型处理SAR数据开辟了道路。

Abstract: The inherently complex-valued nature of Polarimetric SAR data necessitates using specialized algorithms capable of directly processing complex-valued representations. However, this aspect remains underexplored in the deep learning community, with many studies opting to convert complex signals into the real domain before applying conventional real-valued models. In this work, we leverage complex-valued neural networks and investigate the performance of complex-valued Convolutional AutoEncoders. We show that these networks can effectively compress and reconstruct fully polarimetric SAR data while preserving essential physical characteristics, as demonstrated through Pauli, Krogager, and Cameron coherent decompositions, as well as the non-coherent $H-α$ decomposition. Finally, we highlight the advantages of complex-valued neural networks over their real-valued counterparts. These insights pave the way for developing robust, physics-informed, complex-valued generative models for SAR data processing.

</details>


### [67] [DEMIX: Dual-Encoder Latent Masking Framework for Mixed Noise Reduction in Ultrasound Imaging](https://arxiv.org/abs/2602.07163)
*Soumee Guha,Scott T. Acton*

Main category: eess.IV

TL;DR: DEMIX：一种用于超声图像去噪的双编码器框架，通过掩码门控融合机制处理混合噪声和PSF失真


<details>
  <summary>Details</summary>
Motivation: 超声成像在无创医疗诊断中广泛应用，但图像质量受到信号相关斑点噪声、信号无关传感器噪声以及由点扩散函数（PSF）引起的非均匀空间模糊的限制。传统图像恢复方法假设简化的噪声模型，难以有效处理这些复杂退化，需要专门算法在减少退化的同时保留精细结构细节。

Method: 提出DEMIX框架，这是一种受扩散模型启发的双编码器去噪方法，具有前向过程和确定性反向过程。采用掩码门控融合机制，自适应评估不同噪声成分，在潜在空间中解耦这些成分，同时抑制噪声并补偿PSF引起的退化。

Result: 在两个超声数据集和下游分割任务上的广泛实验表明，DEMIX始终优于最先进的基线方法，实现了更好的噪声抑制和结构细节保留。

Conclusion: DEMIX是一种有效的超声图像去噪框架，能够处理混合噪声和PSF失真，在保持结构细节的同时实现优异的去噪性能，代码将公开提供。

Abstract: Ultrasound imaging is widely used in noninvasive medical diagnostics due to its efficiency, portability, and avoidance of ionizing radiation. However, its utility is limited by the quality of the signal. Signal-dependent speckle noise, signal-independent sensor noise, and non-uniform spatial blurring caused by the transducer and modeled by the point spread function (PSF) degrade the image quality. These degradations challenge conventional image restoration methods, which assume simplified noise models, and highlight the need for specialized algorithms capable of effectively reducing the degradations while preserving fine structural details. We propose DEMIX, a novel dual-encoder denoising framework with a masked gated fusion mechanism, for denoising ultrasound images degraded by mixed noise and further degraded by PSF-induced distortions. DEMIX is inspired by diffusion models and is characterized by a forward process and a deterministic reverse process. DEMIX adaptively assesses the different noise components, disentangles them in the latent space, and suppresses these components while compensating for PSF degradations. Extensive experiments on two ultrasound datasets, along with a downstream segmentation task, demonstrate that DEMIX consistently outperforms state-of-the-art baselines, achieving superior noise suppression and preserving structural details. The code will be made publicly available.

</details>


### [68] [Information Theory: An X-ray Microscopy Perspective](https://arxiv.org/abs/2602.07168)
*Charles Wood*

Main category: eess.IV

TL;DR: 该论文将X射线显微镜工作流程视为信息处理系统，使用信息论方法量化各阶段的信息变化，为优化低剂量成像协议提供指导


<details>
  <summary>Details</summary>
Motivation: X射线显微镜成像流程会引入噪声、冗余和信息损失，但缺乏系统性的信息量化方法。需要一种统一框架来理解各处理阶段如何影响最终图像质量，特别是在低剂量或时间受限条件下优化成像协议

Method: 将XRM工作流程建模为信息处理系统，使用熵、互信息和Kullback-Leibler散度等信息论工具，量化采集、去噪、对齐、稀疏角度采样、剂量变化和重建等过程对投影数据和重建体积统计结构的影响

Result: 通过核桃1数据集的案例研究，展示了各处理阶段如何重新分配信息并形成瓶颈。互信息可作为与重建方法无关的保真度指标，支持XRM协议的定量比较和优化

Conclusion: 提出了统一的XRM工作流程信息预算框架，信息论方法为评估和优化成像协议提供了定量工具，特别适用于低剂量或时间受限条件下的成像优化

Abstract: X-ray microscopy (XRM) is commonly used to obtain three-dimensional information on internal microstructure, but the imaging pipeline introduces noise, redundancy and information loss at multiple stages. This paper treats the XRM workflow as an information-processing system acting on a finite information budget. Using entropy, mutual information and Kullback-Leibler divergence, we quantify how acquisition, denoising, alignment, sparse-angle sampling, dose variation and reconstruction reshape the statistical structure of projection data and reconstructed volumes. Case studies based on the Walnut 1 dataset illustrate how these processes redistribute information and impose bottlenecks. We summarise the workflow using a unified information budget and show that mutual information provides a reconstruction-agnostic indicator of fidelity, supporting quantitative comparison and optimisation of XRM protocols, particularly under low-dose or time-constrained conditions

</details>


### [69] [Extracting Root-Causal Brain Activity Driving Psychopathology from Resting State fMRI](https://arxiv.org/abs/2602.07233)
*Eric V. Strobl*

Main category: eess.IV

TL;DR: 提出SOURCE方法，通过双层结构因果模型将症状维度与局部BOLD扰动联系起来，识别根因果脑区而非相关性


<details>
  <summary>Details</summary>
Motivation: 传统神经影像研究将成像模式与诊断标签或综合症状评分相关联，产生模糊的关联，掩盖了潜在机制。需要识别根因果图——引发病理级联的局部BOLD扰动，并将其与特定症状维度联系起来。

Method: 引入双层结构因果模型，通过具有局部直接效应的独立潜在源连接被试间症状结构和被试内静息态fMRI。基于此模型开发SOURCE方法，将可解释的症状轴与一组简约的局部驱动因素联系起来。

Result: 实验表明，SOURCE能够恢复与根因果BOLD驱动因素一致的局部图，相比现有比较方法提高了可解释性和解剖特异性。

Conclusion: SOURCE方法能够识别精神疾病的根因果脑区，将特定症状维度与局部神经驱动因素联系起来，比传统相关性方法更具解释性和特异性。

Abstract: Neuroimaging studies of psychiatric disorders often correlate imaging patterns with diagnostic labels or composite symptom scores, yielding diffuse associations that obscure underlying mechanisms. We instead seek to identify root-causal maps -- localized BOLD disturbances that initiate pathological cascades -- and to link them selectively to symptom dimensions. We introduce a bilevel structural causal model that connects between-subject symptom structure to within-subject resting-state fMRI via independent latent sources with localized direct effects. Based on this model, we develop SOURCE (Symptom-Oriented Uncovering of Root-Causal Elements), a procedure that links interpretable symptom axes to a parsimonious set of localized drivers. Experiments show that SOURCE recovers localized maps consistent with root-causal BOLD drivers and increases interpretability and anatomical specificity relative to existing comparators.

</details>


### [70] [Wavelet-Domain Masked Image Modeling for Color-Consistent HDR Video Reconstruction](https://arxiv.org/abs/2602.07393)
*Yang Zhang,Zhangkai Ni,Wenhan Yang,Hanli Wang*

Main category: eess.IV

TL;DR: WMNet提出了一种基于小波域掩码图像建模的HDR视频重建网络，通过两阶段训练策略和时序一致性模块，显著提升了颜色保真度和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有HDR视频重建方法存在颜色不准确和时间不一致的问题，需要更有效的解决方案来恢复精细的亮度、颜色和细节信息。

Method: 采用两阶段训练：第一阶段在小波域进行自重建预训练，使用掩码图像建模和课程学习；第二阶段微调。引入T-MoE模块自适应融合相邻帧减少闪烁，DMM模块捕获长程依赖确保运动平滑。还重新组织了HDRTV4K-Scene数据集作为新基准。

Result: WMNet在多个评估指标上达到最先进性能，显著改善了颜色保真度、时间一致性和感知质量。

Conclusion: WMNet通过小波域掩码图像建模和创新的时序一致性模块，有效解决了HDR视频重建中的颜色不准确和时间不一致问题，为HDR视频重建提供了新的解决方案。

Abstract: High Dynamic Range (HDR) video reconstruction aims to recover fine brightness, color, and details from Low Dynamic Range (LDR) videos. However, existing methods often suffer from color inaccuracies and temporal inconsistencies. To address these challenges, we propose WMNet, a novel HDR video reconstruction network that leverages Wavelet domain Masked Image Modeling (W-MIM). WMNet adopts a two-phase training strategy: In Phase I, W-MIM performs self-reconstruction pre-training by selectively masking color and detail information in the wavelet domain, enabling the network to develop robust color restoration capabilities. A curriculum learning scheme further refines the reconstruction process. Phase II fine-tunes the model using the pre-trained weights to improve the final reconstruction quality. To improve temporal consistency, we introduce the Temporal Mixture of Experts (T-MoE) module and the Dynamic Memory Module (DMM). T-MoE adaptively fuses adjacent frames to reduce flickering artifacts, while DMM captures long-range dependencies, ensuring smooth motion and preservation of fine details. Additionally, since existing HDR video datasets lack scene-based segmentation, we reorganize HDRTV4K into HDRTV4K-Scene, establishing a new benchmark for HDR video reconstruction. Extensive experiments demonstrate that WMNet achieves state-of-the-art performance across multiple evaluation metrics, significantly improving color fidelity, temporal coherence, and perceptual quality. The code is available at: https://github.com/eezkni/WMNet

</details>


### [71] [Surveillance Facial Image Quality Assessment: A Multi-dimensional Dataset and Lightweight Model](https://arxiv.org/abs/2602.07403)
*Yanwei Jiang,Wei Sun,Yingjie Zhou,Xiangyang Zhu,Yuqin Cao,Jun Jia,Yunhao Li,Sijing Wu,Dandan Zhu,Xingkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 该论文提出了首个针对监控人脸图像的质量评估框架SFIQA，包含多维度质量评估基准SFIQA-Bench和轻量级多任务模型SFIQA-Assessor，解决了监控场景下人脸图像视觉质量与身份保真度的联合评估问题。


<details>
  <summary>Details</summary>
Motivation: 监控人脸图像常因低分辨率、运动模糊、遮挡和光照差等因素导致质量严重下降。现有的人脸图像质量评估方法要么关注视觉质量，要么关注识别性能，无法同时评估对监控应用至关重要的视觉质量和身份保真度。

Method: 1. 构建SFIQA-Bench基准数据集：包含5,004张由三种常用监控摄像头在真实场景中捕获的图像，通过主观实验收集噪声、清晰度、色彩度、对比度、保真度和整体质量六个维度的评分。2. 提出SFIQA-Assessor模型：轻量级多任务FIQA模型，通过跨视角特征交互利用互补的人脸视图，并使用可学习的任务令牌指导多个质量维度的统一回归。

Result: 在提出的数据集上，SFIQA-Assessor相比最先进的通用图像质量评估（IQA）和FIQA方法取得了最佳性能，验证了其在真实监控应用中的有效性。

Conclusion: 该研究填补了监控人脸图像质量评估的空白，提出的SFIQA框架能够同时评估视觉质量和身份保真度，为监控应用提供了更全面的质量评估解决方案。

Abstract: Surveillance facial images are often captured under unconstrained conditions, resulting in severe quality degradation due to factors such as low resolution, motion blur, occlusion, and poor lighting. Although recent face restoration techniques applied to surveillance cameras can significantly enhance visual quality, they often compromise fidelity (i.e., identity-preserving features), which directly conflicts with the primary objective of surveillance images -- reliable identity verification. Existing facial image quality assessment (FIQA) predominantly focus on either visual quality or recognition-oriented evaluation, thereby failing to jointly address visual quality and fidelity, which are critical for surveillance applications. To bridge this gap, we propose the first comprehensive study on surveillance facial image quality assessment (SFIQA), targeting the unique challenges inherent to surveillance scenarios. Specifically, we first construct SFIQA-Bench, a multi-dimensional quality assessment benchmark for surveillance facial images, which consists of 5,004 surveillance facial images captured by three widely deployed surveillance cameras in real-world scenarios. A subjective experiment is conducted to collect six dimensional quality ratings, including noise, sharpness, colorfulness, contrast, fidelity and overall quality, covering the key aspects of SFIQA. Furthermore, we propose SFIQA-Assessor, a lightweight multi-task FIQA model that jointly exploits complementary facial views through cross-view feature interaction, and employs learnable task tokens to guide the unified regression of multiple quality dimensions. The experiment results on the proposed dataset show that our method achieves the best performance compared with the state-of-the-art general image quality assessment (IQA) and FIQA methods, validating its effectiveness for real-world surveillance applications.

</details>


### [72] [DINO-Mix: Distilling Foundational Knowledge with Cross-Domain CutMix for Semi-supervised Class-imbalanced Medical Image Segmentation](https://arxiv.org/abs/2602.07819)
*Xinyu Liu,Guolei Sun*

Main category: eess.IV

TL;DR: DINO-Mix：一种面向类别不平衡医学图像分割的半监督学习新框架，通过引入外部视觉基础模型DINOv3作为无偏语义教师，结合渐进式不平衡感知数据增强，打破传统SSL的确认偏见循环。


<details>
  <summary>Details</summary>
Motivation: 传统半监督学习框架在医学图像分割中存在"内向"问题，仅从目标数据集内部循环利用信息和偏见，在类别不平衡情况下会陷入确认偏见的恶性循环，导致无法识别少数类别。

Method: 提出多层次"外向"框架DINO-Mix：1）基础知识蒸馏(FKD)：引入预训练视觉基础模型DINOv3作为无偏外部语义教师，从其对高语义独特性的稳健理解中蒸馏知识；2）渐进式不平衡感知CutMix(PIC)：在数据内部向外看，创建动态课程，自适应地强制模型关注标记和未标记子集中的少数类别。

Result: 在具有挑战性的半监督类别不平衡医学图像分割基准测试Synapse和AMOS上取得了显著性能提升，成功打破了偏见的恶性循环。

Conclusion: 通过从外部视觉基础模型和内部数据分布两个层面向外看，DINO-Mix框架有效解决了半监督医学图像分割中的类别不平衡问题，为这一领域提供了新的范式。

Abstract: Semi-supervised learning (SSL) has emerged as a critical paradigm for medical image segmentation, mitigating the immense cost of dense annotations. However, prevailing SSL frameworks are fundamentally "inward-looking", recycling information and biases solely from within the target dataset. This design triggers a vicious cycle of confirmation bias under class imbalance, leading to the catastrophic failure to recognize minority classes. To dismantle this systemic issue, we propose a paradigm shift to a multi-level "outward-looking" framework. Our primary innovation is Foundational Knowledge Distillation (FKD), which looks outward beyond the confines of medical imaging by introducing a pre-trained visual foundation model, DINOv3, as an unbiased external semantic teacher. Instead of trusting the student's biased high confidence, our method distills knowledge from DINOv3's robust understanding of high semantic uniqueness, providing a stable, cross-domain supervisory signal that anchors the learning of minority classes. To complement this core strategy, we further look outward within the data by proposing Progressive Imbalance-aware CutMix (PIC), which creates a dynamic curriculum that adaptively forces the model to focus on minority classes in both labeled and unlabeled subsets. This layered strategy forms our framework, DINO-Mix, which breaks the vicious cycle of bias and achieves remarkable performance on challenging semi-supervised class-imbalanced medical image segmentation benchmarks Synapse and AMOS.

</details>


### [73] [A Unified Framework for Multimodal Image Reconstruction and Synthesis using Denoising Diffusion Models](https://arxiv.org/abs/2602.08249)
*Weijie Gan,Xucheng Wang,Tongyao Wang,Wenshang Wang,Chunwei Ying,Yuyang Hu,Yasheng Chen,Hongyu An,Ulugbek S. Kamilov*

Main category: eess.IV

TL;DR: Any2all是一个统一框架，将多模态图像重建和合成任务转化为虚拟修复问题，使用单一无条件扩散模型处理PET/MR/CT脑部数据，在推理时适应不同输入组合。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要针对不同任务训练特定模型，导致训练和部署流程复杂化。多模态成像数据不完整时，需要更统一的方法来处理重建和合成任务。

Method: 将多模态图像重建和合成任务统一表述为虚拟修复问题。训练单一无条件扩散模型于完整多模态数据堆栈，推理时通过"修复"机制从任意可用干净图像或噪声测量中生成所有目标模态。

Result: 在PET/MR/CT脑部数据集上验证，Any2all在多模态重建和合成任务上表现优异，产生具有竞争力的失真性能指标和优于专用方法的感知质量图像。

Conclusion: Any2all框架成功统一了多模态图像处理任务，通过单一模型实现灵活的多模态重建和合成，简化了训练部署流程，同时保持高质量输出。

Abstract: Image reconstruction and image synthesis are important for handling incomplete multimodal imaging data, but existing methods require various task-specific models, complicating training and deployment workflows. We introduce Any2all, a unified framework that addresses this limitation by formulating these disparate tasks as a single virtual inpainting problem. We train a single, unconditional diffusion model on the complete multimodal data stack. This model is then adapted at inference time to ``inpaint'' all target modalities from any combination of inputs of available clean images or noisy measurements. We validated Any2all on a PET/MR/CT brain dataset. Our results show that Any2all can achieve excellent performance on both multimodal reconstruction and synthesis tasks, consistently yielding images with competitive distortion-based performance and superior perceptual quality over specialized methods.

</details>


### [74] [Trajectory Stitching for Solving Inverse Problems with Flow-Based Models](https://arxiv.org/abs/2602.08538)
*Alexander Denker,Moshe Eliasof,Zeljko Kereta,Carola-Bibiane Schönlieb*

Main category: eess.IV

TL;DR: MS-Flow提出了一种新的基于流的生成模型方法，通过将轨迹表示为中间潜在状态序列而非单一初始代码，降低了内存消耗并提高了重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于流的生成模型在解决逆问题时需要反向传播整个生成轨迹，导致高内存成本和数值不稳定性。需要一种更高效的方法来利用流模型作为先验。

Method: MS-Flow将生成轨迹表示为中间潜在状态序列，通过局部强制流动力学和轨迹匹配惩罚耦合各段，交替更新中间潜在状态并确保与观测数据的一致性。

Result: MS-Flow在图像恢复和逆问题（包括修复、超分辨率和计算机断层扫描）上表现出优于现有方法的性能，同时减少了内存消耗。

Conclusion: MS-Flow通过将生成轨迹分解为中间状态序列，提供了一种更高效、更稳定的基于流生成模型解决逆问题的方法，在保持重建质量的同时显著降低了计算成本。

Abstract: Flow-based generative models have emerged as powerful priors for solving inverse problems. One option is to directly optimize the initial latent code (noise), such that the flow output solves the inverse problem. However, this requires backpropagating through the entire generative trajectory, incurring high memory costs and numerical instability. We propose MS-Flow, which represents the trajectory as a sequence of intermediate latent states rather than a single initial code. By enforcing the flow dynamics locally and coupling segments through trajectory-matching penalties, MS-Flow alternates between updating intermediate latent states and enforcing consistency with observed data. This reduces memory consumption while improving reconstruction quality. We demonstrate the effectiveness of MS-Flow over existing methods on image recovery and inverse problems, including inpainting, super-resolution, and computed tomography.

</details>


### [75] [Efficient Brain Extraction of MRI Scans with Mild to Moderate Neuropathology](https://arxiv.org/abs/2602.08764)
*Hjalti Thrastarson,Lotta M. Ellingsen*

Main category: eess.IV

TL;DR: 提出一种基于改进U-net和符号距离变换损失函数的鲁棒性头骨剥离方法，用于T1加权MRI图像处理，在保持大脑外表面一致性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有头骨剥离方法在神经病理存在时经常失败，且大脑掩模边界定义不一致。需要一种能稳定分割大脑外表面（包括脑沟脑脊液）同时排除蛛网膜下腔和脑膜的鲁棒方法。

Method: 使用改进的U-net架构，基于符号距离变换（SDT）的新型损失函数，在银标准地面真值数据上进行训练。

Result: 在保留测试数据上获得平均Dice相似系数0.964±0.006和平均对称表面距离1.4mm±0.2mm；在外部数据集上获得DSC 0.958±0.006和ASSD 1.7±0.2mm，性能与或优于现有最先进方法。

Conclusion: 该方法在头骨剥离任务中表现出色，特别是在大脑外表面一致性保持方面具有优势，已公开在GitHub上供使用。

Abstract: Skull stripping magnetic resonance images (MRI) of the human brain is an important process in many image processing techniques, such as automatic segmentation of brain structures. Numerous methods have been developed to perform this task, however, they often fail in the presence of neuropathology and can be inconsistent in defining the boundary of the brain mask. Here, we propose a novel approach to skull strip T1-weighted images in a robust and efficient manner, aiming to consistently segment the outer surface of the brain, including the sulcal cerebrospinal fluid (CSF), while excluding the full extent of the subarachnoid space and meninges. We train a modified version of the U-net on silver-standard ground truth data using a novel loss function based on the signed-distance transform (SDT). We validate our model both qualitatively and quantitatively using held-out data from the training dataset, as well as an independent external dataset. The brain masks used for evaluation partially or fully include the subarachnoid space, which may introduce bias into the comparison; nonetheless, our model demonstrates strong performance on the held-out test data, achieving a consistent mean Dice similarity coefficient (DSC) of 0.964$\pm$0.006 and an average symmetric surface distance (ASSD) of 1.4mm$\pm$0.2mm. Performance on the external dataset is comparable, with a DSC of 0.958$\pm$0.006 and an ASSD of 1.7$\pm$0.2mm. Our method achieves performance comparable to or better than existing state-of-the-art methods for brain extraction, particularly in its highly consistent preservation of the brain's outer surface. The method is publicly available on GitHub.

</details>
