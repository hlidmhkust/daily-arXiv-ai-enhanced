<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 13]
- [cs.IT](#cs.IT) [Total: 14]
- [eess.SP](#eess.SP) [Total: 33]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [LAYER: A Quantitative Explainable AI Framework for Decoding Tissue-Layer Drivers of Myofascial Low Back Pain](https://arxiv.org/abs/2511.21767)
*Zixue Zeng,Anthony M. Perti,Tong Yu,Grant Kokenberger,Hao-En Lu,Jing Wang,Xin Meng,Zhiyu Sheng,Maryam Satarpour,John M. Cormack,Allison C. Bean,Ryan P. Nussbaum,Emily Landis-Walkenhorst,Kang Kim,Ajay D. Wasan,Jiantao Pu*

Main category: eess.IV

TL;DR: 研究人员开发了LAYER框架，利用可解释AI分析三维超声中的六层组织，发现非肌肉组织对肌筋膜疼痛预测有重要贡献，挑战了传统肌肉中心范式。


<details>
  <summary>Details</summary>
Motivation: 肌筋膜疼痛是慢性腰痛的主要原因，但其组织层面的驱动因素仍不明确，缺乏可靠的影像生物标志物。现有研究主要关注肌肉，而忽视了筋膜、脂肪等起重要生物力学作用的软组织。

Method: 开发了LAYER（分层分析生成可解释相关性组织）框架，这是一个基于解剖学的可解释人工智能框架，分析三维超声中的六层组织，量化它们对肌筋膜疼痛预测的贡献。使用了包含4000多次扫描的最大多模态三维超声队列。

Result: 在B模式成像中，深筋膜膜显示出最高的显著性（0.420）；在B模式和剪切波图像组合中，非肌肉层的集体显著性（0.316）几乎与肌肉（0.317）相当，表明非肌肉组织对疼痛预测有重要贡献。

Conclusion: LAYER建立了一个定量、可解释的框架，将特定层解剖结构与疼痛生理学联系起来，揭示了新的组织靶点，并为软组织影像的可解释分析提供了通用方法，挑战了肌筋膜疼痛研究的传统肌肉中心范式。

Abstract: Myofascial pain (MP) is a leading cause of chronic low back pain, yet its tissue-level drivers remain poorly defined and lack reliable image biomarkers. Existing studies focus predominantly on muscle while neglecting fascia, fat, and other soft tissues that play integral biomechanical roles. We developed an anatomically grounded explainable artificial intelligence (AI) framework, LAYER (Layer-wise Analysis for Yielding Explainable Relevance Tissue), that analyses six tissue layers in three-dimensional (3D) ultrasound and quantifies their contribution to MP prediction. By utilizing the largest multi-model 3D ultrasound cohort consisting of over 4,000 scans, LAYER reveals that non-muscle tissues contribute substantially to pain prediction. In B-mode imaging, the deep fascial membrane (DFM) showed the highest saliency (0.420), while in combined B-mode and shear-wave images, the collective saliency of non-muscle layers (0.316) nearly matches that of muscle (0.317), challenging the conventional muscle-centric paradigm in MP research and potentially affecting the therapy methods. LAYER establishes a quantitative, interpretable framework for linking layer-specific anatomy to pain physiology, uncovering new tissue targets and providing a generalizable approach for explainable analysis of soft-tissue imaging.

</details>


### [2] [Attention-Guided Fair AI Modeling for Skin Cancer Diagnosis](https://arxiv.org/abs/2511.21775)
*Mingcheng Zhu,Mingxuan Liu,Han Yuan,Yilin Ning,Zhiyao Luo,Tingting Zhu,Nan Liu*

Main category: eess.IV

TL;DR: LesionAttn是一种公平性感知的皮肤病AI算法，通过将临床知识融入模型设计，引导注意力到病灶区域，结合帕累托前沿优化平衡公平性和准确性，有效缓解性别偏见。


<details>
  <summary>Details</summary>
Motivation: 皮肤病AI在性别偏见方面研究不足，导致不平等医疗和加剧现有性别差异。虽然肤色相关偏见已有广泛研究，但性别偏见仍待探索。

Method: 开发LesionAttn算法，将临床知识融入模型设计，引导注意力到病灶区域（模仿临床医生的诊断焦点），结合帕累托前沿优化进行双目标模型选择，平衡公平性和预测准确性。

Result: 在两个大规模皮肤病数据集上验证，LesionAttn显著缓解性别偏见同时保持高诊断性能，优于现有偏见缓解算法。

Conclusion: 将临床知识嵌入AI开发可以同时提升模型性能和公平性，促进临床医生与AI开发者之间的跨学科合作。

Abstract: Artificial intelligence (AI) has shown remarkable promise in dermatology, offering accurate and non-invasive diagnosis of skin cancer. While extensive research has addressed skin tone-related bias, gender bias in dermatologic AI remains underexplored, leading to unequal care and reinforcing existing gender disparities. In this study, we developed LesionAttn, a fairness-aware algorithm that integrates clinical knowledge into model design by directing attention toward lesion regions, mirroring the diagnostic focus of clinicians. Combined with Pareto-frontier optimization for dual-objective model selection, LesionAttn balances fairness and predictive accuracy. Validated on two large-scale dermatological datasets, LesionAttn significantly mitigates gender bias while maintaining high diagnostic performance, outperforming existing bias mitigation algorithms. Our study highlights the potential of embedding clinical knowledge into AI development to advance both model performance and fairness, and further to foster interdisciplinary collaboration between clinicians and AI developers.

</details>


### [3] [Comparing SAM 2 and SAM 3 for Zero-Shot Segmentation of 3D Medical Data](https://arxiv.org/abs/2511.21926)
*Satrajit Chakrabarty,Ravi Soni*

Main category: eess.IV

TL;DR: SAM 3在医学图像零样本分割中表现优于SAM 2，特别是在复杂解剖结构和稀疏交互场景下，可作为默认选择


<details>
  <summary>Details</summary>
Motivation: 虽然SAM系列模型在自然图像上表现良好，但在医学数据上的行为特征尚未充分研究。SAM 3引入了新的感知骨干网络、检测器-跟踪器流水线和概念级提示机制，可能改变其在空间提示下的行为，需要评估其能否作为SAM 2的直接替代品

Method: 在16个公共数据集（CT、MRI、3D和动态超声、内窥镜）上对SAM 2和SAM 3进行受控比较，涵盖54个解剖结构、病理和手术器械。提示仅限于第一帧，使用四种模式：单点点击、多点点击、边界框和密集掩码。标准化预处理、提示放置、传播规则和度量计算，以分离提示解释和传播

Result: SAM 3在点击提示初始化方面显著优于SAM 2，在复杂、血管和软组织解剖结构上保持优势，成为更通用的分割器。SAM 2在紧凑、刚性器官和强空间引导下仍具竞争力，但在SAM 3能成功的挑战性目标上经常失败

Conclusion: SAM 3是大多数医学分割任务的更优默认选择，特别是在涉及稀疏用户交互或复杂解剖拓扑的场景中

Abstract: Foundation models for promptable segmentation, including SAM, SAM 2, and the recently released SAM 3, have renewed interest in zero-shot segmentation of medical imaging. Although these models perform strongly on natural images, their behavior on medical data remains insufficiently characterized. While SAM 2 is widely used for annotation in 3D medical workflows, SAM 3 introduces a new perception backbone, detector-tracker pipeline, and concept-level prompting that may alter its behavior under spatial prompts. We present the first controlled comparison of SAM 2 and SAM 3 for zero-shot segmentation of 3D medical volumes and videos under purely visual prompting, with concept mechanisms disabled. We assess whether SAM 3 can serve as an out-of-the-box replacement for SAM 2 without customization. We benchmark both models on 16 public datasets (CT, MRI, 3D and cine ultrasound, endoscopy) covering 54 anatomical structures, pathologies, and surgical instruments. Prompts are restricted to the first frame and use four modes: single-click, multi-click, bounding box, and dense mask. This design standardizes preprocessing, prompt placement, propagation rules, and metric computation to disentangle prompt interpretation from propagation. Prompt-frame analysis shows that SAM 3 provides substantially stronger initialization than SAM 2 for click prompting across most structures. In full-volume analysis, SAM 3 retains this advantage for complex, vascular, and soft-tissue anatomies, emerging as the more versatile general-purpose segmenter. While SAM 2 remains competitive for compact, rigid organs under strong spatial guidance, it frequently fails on challenging targets where SAM 3 succeeds. Overall, our results suggest that SAM 3 is the superior default choice for most medical segmentation tasks, particularly those involving sparse user interaction or complex anatomical topology.

</details>


### [4] [Digital Elevation Model Estimation from RGB Satellite Imagery using Generative Deep Learning](https://arxiv.org/abs/2511.21985)
*Alif Ilham Madani,Riska A. Kuswati,Alex M. Lechner,Muhamad Risqi U. Saputra*

Main category: eess.IV

TL;DR: 使用条件生成对抗网络从免费RGB卫星影像生成数字高程模型，在山区表现良好但低地和居民区仍有局限


<details>
  <summary>Details</summary>
Motivation: 传统DEM生成方法（如LiDAR和摄影测量）需要特定数据，在资源受限地区难以获取。本研究旨在利用免费可得的RGB卫星影像生成DEM，为资源受限地区提供成本效益高的替代方案。

Method: 基于条件生成对抗网络（GAN），使用Landsat卫星影像和NASA SRTM高程数据构建包含12K RGB-DEM对的全球数据集。采用独特预处理流程选择高质量无云区域，并进行两阶段训练：先在完整数据集上训练，然后通过SSIM值筛选高质量样本进行微调。

Result: 在山区表现良好，整体均方根误差为0.4671，平均SSIM得分为0.2065（范围-1到1）。但在低地和居民区存在局限性，显示了模型在不同地形上的泛化挑战。

Conclusion: 该方法为传统DEM生成提供了成本效益高且适应性强的替代方案，强调了在生成建模中细致预处理和迭代优化的重要性，同时指出了在全球多样化地形中泛化的挑战。

Abstract: Digital Elevation Models (DEMs) are vital datasets for geospatial applications such as hydrological modeling and environmental monitoring. However, conventional methods to generate DEM, such as using LiDAR and photogrammetry, require specific types of data that are often inaccessible in resource-constrained settings. To alleviate this problem, this study proposes an approach to generate DEM from freely available RGB satellite imagery using generative deep learning, particularly based on a conditional Generative Adversarial Network (GAN). We first developed a global dataset consisting of 12K RGB-DEM pairs using Landsat satellite imagery and NASA's SRTM digital elevation data, both from the year 2000. A unique preprocessing pipeline was implemented to select high-quality, cloud-free regions and aggregate normalized RGB composites from Landsat imagery. Additionally, the model was trained in a two-stage process, where it was first trained on the complete dataset and then fine-tuned on high-quality samples filtered by Structural Similarity Index Measure (SSIM) values to improve performance on challenging terrains. The results demonstrate promising performance in mountainous regions, achieving an overall mean root-mean-square error (RMSE) of 0.4671 and a mean SSIM score of 0.2065 (scale -1 to 1), while highlighting limitations in lowland and residential areas. This study underscores the importance of meticulous preprocessing and iterative refinement in generative modeling for DEM generation, offering a cost-effective and adaptive alternative to conventional methods while emphasizing the challenge of generalization across diverse terrains worldwide.

</details>


### [5] [When Do Domain-Specific Foundation Models Justify Their Cost? A Systematic Evaluation Across Retinal Imaging Tasks](https://arxiv.org/abs/2511.22001)
*David Isztl,Tahm Spitznagel,Gabor Mark Somfai,Rui Santos*

Main category: eess.IV

TL;DR: 该研究挑战了视网膜疾病分类需要大型领域特定基础模型的假设，证明紧凑的通用模型在大多数任务上表现优异，大型专用模型仅在特定困难任务上值得其计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前视网膜疾病分类广泛采用大型视觉基础模型，但缺乏系统证据证明其参数需求的合理性。研究旨在回答两个关键问题：1）大型领域特定基础模型是否必要，还是紧凑的通用架构就足够？2）专门的视网膜预训练是否值得其计算成本？

Method: 在四个视网膜成像分类任务上基准测试初始化策略：8类OCT分类、3类DME、5类DR和3类青光眼检测。评估12-13种模型配置，包括ViT、Swin Transformers、ConvNeXt和领域特定的RETFound模型，在相同训练条件下比较。

Result: 1）预训练提供普遍益处（5.18-18.41%提升），随任务难度增加；2）紧凑架构（27-29M参数）主导Pareto前沿，SwinV2-tiny在三个数据集上达到top-1性能；3）RETFound（303M）仅在困难的DR分级任务上值得其计算成本（准确率71.15%），其他任务ImageNet预训练已足够（DME准确率99.24%，OCT准确率97.96%）。

Conclusion: 紧凑的通用模型在大多数视网膜分类任务上提供接近最优的性能；专门的基础模型仅在极端类别不平衡下的细粒度区分任务中才值得使用。

Abstract: Large vision foundation models have been widely adopted for retinal disease classification without systematic evidence justifying their parameter requirements. In the present work we address two critical questions: First, are large domain-specific foundation models essential, or do compact general-purpose architectures suffice? Second, does specialized retinal pretraining justify its computational cost? To answer this, we benchmark initialization strategies across four retinal imaging classification tasks spanning Optical Coherence Tomography (OCT) and Color Fundus Photography (CFP) modalities: 8-class OCT classification, 3-class diabetic macular edema (DME), 5-class diabetic retinopathy (DR), and 3-class glaucoma (GL) detection. We evaluate 12-13 model configurations per task, including vision transformers (22.8M-86.6M parameters), Swin Transformers (27.6M-28.3M), ConvNeXt (28.6M), and the domain-specific RETFound models (303M), under identical training conditions. Our results challenge prevailing assumptions: First, we demonstrate that pretraining provides universal benefits (5.18-18.41% improvement), scaling with task difficulty. Second, compact architectures (27-29M) dominate Pareto frontiers; SwinV2-tiny achieves top-1 performance on three datasets. Third, RETFound (303M) justifies its computational cost only for challenging DR grading (accuracy of 71.15%), while ImageNet pretraining proves to be sufficient with all other tasks (DME accuracy: 99.24%, OCT accuracy: 97.96%). CFP tasks show larger pretraining accuracy gains (9.13-18.41%) than OCT (5.18%). Thus, the evidence suggests that compact general-purpose models deliver near-optimal performance for most retinal classification tasks; specialized foundation models warranted only for fine-grained discrimination under extreme class imbalance.

</details>


### [6] [GACELLE: GPU-accelerated tools for model parameter estimation and image reconstruction](https://arxiv.org/abs/2511.22094)
*Kwok-Shing Chan,Hansol Lee,Yixin Ma,Berkin Bilgic,Susie Y. Huang,Hong-Hsi Lee,José P. Marques*

Main category: eess.IV

TL;DR: GACELLE是一个开源的GPU加速qMRI分析框架，通过随机梯度下降和随机采样实现快速参数映射，相比CPU方法加速达451-14,380倍，同时提高参数精度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 定量MRI（qMRI）能提供组织特异性生物标志物，但其参数估计的计算需求巨大，限制了在临床研究中的采用。高空间分辨率图像或多参数拟合需要长时间处理，制约了常规流程应用和方法创新。

Method: GACELLE是一个开源GPU加速框架，提供随机梯度下降优化器和随机采样器。用户只需提供前向信号模型，框架后端管理计算并行化、自动参数更新和内存批处理。随机求解器在CPU和GPU上执行完全向量化的马尔可夫链蒙特卡洛方法。

Result: 基准测试显示：随机梯度下降求解器加速达451倍，随机采样加速达14,380倍，且不损失精度。在三个代表性qMRI模型和图像重建任务中，GACELLE提高了参数精度、增强了测试-重测可重复性、减少了定量图中的噪声。

Conclusion: GACELLE通过结合速度、可用性和灵活性，为医学图像分析提供了通用优化框架，降低了qMRI的计算障碍，为可重复生物标志物开发、大规模成像研究和临床转化铺平了道路。

Abstract: Quantitative MRI (qMRI) offers tissue-specific biomarkers that can be tracked over time or compared across populations; however, its adoption in clinical research is hindered by significant computational demands of parameter estimation. Images acquired at high spatial resolution or requiring fitting multiple parameters often require lengthy processing time, constraining their use in routine pipelines and slowing methodological innovation and clinical translation.
  We present GACELLE, an open source, GPU-accelerated framework for high-throughput qMRI analysis. GACELLE provides a stochastic gradient descent optimiser and a stochastic sampler in MATLAB, enabling fast parameter mapping, improved estimation robustness via spatial regularisation, and uncertainty quantification. GACELLE prioritises accessibility: users only need to provide a forward signal model, while GACELLE's backend manages computational parallelisation, automatic parameter updates, and memory-batching. The stochastic solver performs fully vectorised Markov chain Monte Carlo with identical likelihood on CPU and GPU, ensuring reproducibility across hardware.
  Benchmarking demonstrates up to 451-fold acceleration for the stochastic gradient descent solver and 14,380-fold acceleration for stochastic sampling compared to CPU-based estimation, without compromising accuracy. We demonstrated GACELLE's versatility on three representative qMRI models and on an image reconstruction task. Across these applications, GACELLE improves parameter precision, enhances test-retest reproducibility, and reduces noise in quantitative maps.
  By combining speed, usability and flexibility, GACELLE provides a generalisable optimisation framework for medical image analysis. It lowers the computational barrier for qMRI, paving the way for reproducible biomarker development, large-scale imaging studies, and clinical translation.

</details>


### [7] [ColonAdapter: Geometry Estimation Through Foundation Model Adaptation for Colonoscopy](https://arxiv.org/abs/2511.22250)
*Zhiyi Jiang,Yifu Wang,Xuelian Cheng,Zongyuan Ge*

Main category: eess.IV

TL;DR: ColonAdapter：一种自监督微调框架，用于将几何基础模型适配到结肠镜场景，解决非朗伯表面、移动光源和大面积无纹理区域带来的3D几何估计挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的3D几何基础模型主要在自然场景数据集上训练，在结肠镜临床场景中性能下降，因为结肠镜图像具有高镜面反射、同质纹理等特性，导致几何估计不准确。

Method: 提出ColonAdapter自监督微调框架，利用预训练的几何先验知识并适配临床数据。引入细节恢复模块（DRM）改善低纹理区域性能，几何一致性损失确保尺度一致性，置信度加权光度损失增强临床环境中的训练稳定性。

Result: 在合成和真实数据集上的实验表明，该方法在相机姿态估计、单目深度预测和密集3D点云重建方面达到最先进性能，且不需要真实内参。

Conclusion: ColonAdapter成功将几何基础模型适配到结肠镜场景，克服了临床环境中的特殊挑战，为结肠镜3D几何估计提供了有效的解决方案。

Abstract: Estimating 3D geometry from monocular colonoscopy images is challenging due to non-Lambertian surfaces, moving light sources, and large textureless regions. While recent 3D geometric foundation models eliminate the need for multi-stage pipelines, their performance deteriorates in clinical scenes. These models are primarily trained on natural scene datasets and struggle with specularity and homogeneous textures typical in colonoscopy, leading to inaccurate geometry estimation. In this paper, we present ColonAdapter, a self-supervised fine-tuning framework that adapts geometric foundation models for colonoscopy geometry estimation. Our method leverages pretrained geometric priors while tailoring them to clinical data. To improve performance in low-texture regions and ensure scale consistency, we introduce a Detail Restoration Module (DRM) and a geometry consistency loss. Furthermore, a confidence-weighted photometric loss enhances training stability in clinical environments. Experiments on both synthetic and real datasets demonstrate that our approach achieves state-of-the-art performance in camera pose estimation, monocular depth prediction, and dense 3D point map reconstruction, without requiring ground-truth intrinsic parameters.

</details>


### [8] [Content Adaptive Encoding For Interactive Game Streaming](https://arxiv.org/abs/2511.22327)
*Shakarim Soltanayev,Odysseas Zisimopoulos,Mohammad Ashraful Anam,Man Cheung Kung,Angeliki Katsenou,Yiannis Andreopoulos*

Main category: eess.IV

TL;DR: 提出首个用于交互式游戏流媒体(IGS)的内容自适应编码(CAE)方法，通过CNN基于历史帧编码元数据预测最佳分辨率，在超低延迟约束下实现质量提升。


<details>
  <summary>Details</summary>
Motivation: 交互式游戏流媒体(IGS)对内容自适应编码(CAE)提出特殊挑战：需要超低延迟编码（无前瞻或缓冲）、计算资源极其有限。传统CAE方法在IGS中难以开发和部署。

Method: 训练卷积神经网络(CNN)，基于当前场景中运行窗口的聚合编码块统计信息，从可用选项中推断即将到来的场景的最佳分辨率。使用HEVC编码的紧凑编码元数据。

Result: 在基于HEVC编码的实际IGS设置中：1) 相比默认固定分辨率阶梯，提升2.3 Bjøntegaard Delta-VMAF点；2) 每个场景仅使用单个CPU核心1ms进行推断，无延迟开销。

Conclusion: 首次实现了适用于交互式游戏流媒体的内容自适应编码方案，在满足超低延迟和严格计算约束的同时，显著提升了视频质量。

Abstract: Video-on-demand streaming has benefitted from \textit{content-adaptive encoding} (CAE), i.e., adaptation of resolution and/or quantization parameters for each scene based on convex hull optimization. However, CAE is very challenging to develop and deploy for interactive game streaming (IGS). Commercial IGS services impose ultra-low latency encoding with no lookahead or buffering, and have extremely tight compute constraints for any CAE algorithm execution. We propose the first CAE approach for resolution adaptation in IGS based on compact encoding metadata from past frames. Specifically, we train a convolutional neural network (CNN) to infer the best resolution from the options available for the upcoming scene based on a running window of aggregated coding block statistics from the current scene. By deploying the trained CNN within a practical IGS setup based on HEVC encoding, our proposal: (i) improves over the default fixed-resolution ladder of HEVC by 2.3 Bjøntegaard Delta-VMAF points; (ii) infers using 1ms of a single CPU core per scene, thereby having no latency overhead.

</details>


### [9] [Hard Spatial Gating for Precision-Driven Brain Metastasis Segmentation: Addressing the Over-Segmentation Paradox in Deep Attention Networks](https://arxiv.org/abs/2511.22606)
*Rowzatul Zannath Prerona*

Main category: eess.IV

TL;DR: SG-Net通过硬空间门控机制解决脑转移瘤分割中的过分割问题，显著提升边界精度，减少参数需求


<details>
  <summary>Details</summary>
Motivation: 脑转移瘤MRI分割面临小病灶（5-15mm）和极端类别不平衡（<2%肿瘤体积）的挑战。现有软注意力CNN存在"过分割悖论"：高灵敏度但精度崩溃（<0.23）和边界误差大（>150mm），这对立体定向放射外科规划构成重大风险。

Method: 提出空间门控网络（SG-Net），采用硬空间门控机制。与传统软注意力不同，SG-Net强制执行严格的特征选择，积极抑制背景伪影同时保留肿瘤特征。

Result: 在Brain-Mets-Lung-MRI数据集（n=92）上，SG-Net获得Dice相似系数0.5578±0.0243，显著优于Attention U-Net（p<0.001）和ResU-Net（p<0.001）。边界精度提升3倍，95%Hausdorff距离56.13mm vs 157.52mm，保持稳健召回率（0.79）和更高精度（0.52 vs 0.20）。仅需0.67M参数（比Attention U-Net少8.8倍）。

Conclusion: 硬空间门控是精度驱动病灶检测的稳健解决方案，直接提升放射外科准确性，特别适合资源受限环境部署。

Abstract: Brain metastasis segmentation in MRI remains a formidable challenge due to diminutive lesion sizes (5-15 mm) and extreme class imbalance (less than 2% tumor volume). While soft-attention CNNs are widely used, we identify a critical failure mode termed the "over-segmentation paradox," where models achieve high sensitivity (recall > 0.88) but suffer from catastrophic precision collapse (precision < 0.23) and boundary errors exceeding 150 mm. This imprecision poses significant risks for stereotactic radiosurgery planning. To address this, we introduce the Spatial Gating Network (SG-Net), a precision-first architecture employing hard spatial gating mechanisms. Unlike traditional soft attention, SG-Net enforces strict feature selection to aggressively suppress background artifacts while preserving tumor features. Validated on the Brain-Mets-Lung-MRI dataset (n=92), SG-Net achieves a Dice Similarity Coefficient of 0.5578 +/- 0.0243 (95% CI: 0.45-0.67), statistically outperforming Attention U-Net (p < 0.001) and ResU-Net (p < 0.001). Most critically, SG-Net demonstrates a threefold improvement in boundary precision, achieving a 95% Hausdorff Distance of 56.13 mm compared to 157.52 mm for Attention U-Net, while maintaining robust recall (0.79) and superior precision (0.52 vs. 0.20). Furthermore, SG-Net requires only 0.67M parameters (8.8x fewer than Attention U-Net), facilitating deployment in resource-constrained environments. These findings establish hard spatial gating as a robust solution for precision-driven lesion detection, directly enhancing radiosurgery accuracy.

</details>


### [10] [TokCom-UEP: Semantic Importance-Matched Unequal Error Protection for Resilient Image Transmission](https://arxiv.org/abs/2511.22859)
*Kaizheng Zhang,Zuolin Jin,Zhihang Cheng,Ming Zeng,Li Qiao,Zesong Fei*

Main category: eess.IV

TL;DR: 提出TokCom-UEP框架，通过语义重要性匹配的不等错误保护提升图像传输的鲁棒性，优于传统的等错误保护方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的Token通信框架假设token重要性均匀，采用等错误保护，但压缩后的1D token序列实际上具有异构的语义重要性层次，使得等错误保护方案次优。

Method: 提出TokCom-UEP框架，将无速率不等错误保护编码与token的非均匀语义重要性结合，通过将源token划分为嵌套扩展窗口，为包含关键token的窗口分配更高选择概率，确保其优先恢复。

Result: 仿真结果表明，在低开销条件下，TokCom-UEP在三个核心语义恢复指标和频谱效率方面均优于等错误保护方案。

Conclusion: TokCom-UEP通过语义重要性匹配的不等错误保护，有效提升了6G网络中图像传输的鲁棒性和效率。

Abstract: Based on the provided LaTeX code, here is the metadata for the submission form: Title: TokCom-UEP: Semantic Importance-Matched Unequal Error Protection for Resilient Image Transmission Author(s): Kaizheng Zhang, Zuolin Jin, Zhihang Cheng, Ming Zeng, Li Qiao, Zesong Fei Abstract: Token communication (TokCom), an emerging semantic communication framework powered by Large Multimodal Model (LMM), has become a key paradigm for resilient data transmission in 6G networks. A key limitation of existing TokCom designs lies in the assumption of uniform token importance, which leads to the adoption of equal error protection (EEP). However, compressed one-dimensional (1D) token sequences inherently exhibit heterogeneous semantic importance hierarchies, rendering EEP schemes suboptimal. To address this, this paper proposes TokCom-UEP, a novel semantic importance-matched unequal error protection (UEP) framework designed for resilient image transmission. TokCom-UEP integrates rateless UEP coding with the non-uniform semantic importance of tokens by partitioning source tokens into nested expanding windows, assigning higher selection probabilities to windows containing critical tokens to ensure their prioritized recovery. Simulation results demonstrate that TokCom-UEP outperforms EEP schemes in terms of three core semantic restoration metrics and spectral efficiency under low-overhead conditions.

</details>


### [11] [Two-Dimensional Tomographic Reconstruction From Projections With Unknown Angles and Unknown Spatial Shifts](https://arxiv.org/abs/2511.22890)
*Shreyas Jayant Grampurohit,Satish Mulleti,Ajit Rajwade*

Main category: eess.IV

TL;DR: 提出一种用于二维断层扫描的新方法，能够同时估计未知投影角度和空间位移，改进了现有未知视角断层扫描算法忽略位移的局限性。


<details>
  <summary>Details</summary>
Motivation: 在工业成像和生物医学成像中，投影几何参数（角度和位移）常常未知或部分未知。现有2D未知视角断层扫描算法大多假设投影是居中的，忽略了空间位移问题，这在实际应用中限制了重建质量。

Method: 首先改进现有的基于图拉普拉斯算子的2D未知视角断层扫描算法以包含空间位移，然后将其作为初始化，提出三路交替最小化算法，联合估计2D结构、投影角度和相应的位移。

Result: 在核糖体图像的噪声投影上评估该方法，证明相比忽略位移的基线方法，该方法获得了更优的重建效果。

Conclusion: 提出的方法能够有效处理投影几何参数完全未知的情况，同时估计角度和位移，为工业成像和生物医学成像中的未知几何断层扫描问题提供了更实用的解决方案。

Abstract: In parallel beam computed tomography (CT), an object is reconstructed from a series of projections taken at different angles. However, in some industrial and biomedical imaging applications, the projection geometry is unknown, completely or partially. In this paper, we present a technique for two-dimensional (2D) tomography in which both viewing angles and spatial shifts associated with the projections are unknown. There exists literature on 2D unknown view tomography (UVT), but most existing 2D UVT algorithms assume that the projections are centered; that is, there are no spatial shifts in the projections. To tackle these geometric ambiguities, we first modify an existing graph Laplacian-based algorithm for 2D UVT to incorporate spatial shifts, and then use it as the initialization for the proposed three-way alternating minimization algorithm that jointly estimates the 2D structure, its projection angles, and the corresponding shifts. We evaluate our method on noisy projections of ribosome images and demonstrate that it achieves superior reconstruction compared to the baseline that neglects shifts.

</details>


### [12] [MICCAI STS 2024 Challenge: Semi-Supervised Instance-Level Tooth Segmentation in Panoramic X-ray and CBCT Images](https://arxiv.org/abs/2511.22911)
*Yaqi Wang,Zhi Li,Chengyu Wu,Jun Liu,Yifan Zhang,Jiaxue Ni,Qian Luo,Jialuo Chen,Hongyuan Zhang,Jin Liu,Can Han,Kaiwen Fu,Changkai Ji,Xinxu Cai,Jing Hao,Zhihao Zheng,Shi Xu,Junqiang Chen,Qianni Zhang,Dahong Qian,Shuai Wang,Huiyu Zhou*

Main category: eess.IV

TL;DR: STS 2024挑战赛展示了半监督学习在牙齿分割任务中的显著优势，在数据标注稀缺的情况下，SSL方法相比全监督基线取得了44-61个百分点的性能提升。


<details>
  <summary>Details</summary>
Motivation: 牙齿分割（OPG和CBCT）需要大量实例级标注数据，但人工标注成本高昂，因此需要探索半监督学习来解决数据稀缺问题。

Method: 在MICCAI 2024举办STS挑战赛，提供包含90,000+图像的大规模数据集（2,380 OPG图像和330 CBCT扫描），评估参与者提交的半监督学习方法。

Result: 最佳半监督方法相比全监督nnU-Net基线显著提升：2D OPG赛道Instance Affinity分数提升44+个百分点，3D CBCT赛道Instance Dice分数提升61个百分点。

Conclusion: 半监督学习在标注数据稀缺的复杂医学图像实例分割任务中具有重要价值，最有效的方法结合了SAM等基础模型与多阶段粗到细的优化流程。

Abstract: Orthopantomogram (OPGs) and Cone-Beam Computed Tomography (CBCT) are vital for dentistry, but creating large datasets for automated tooth segmentation is hindered by the labor-intensive process of manual instance-level annotation. This research aimed to benchmark and advance semi-supervised learning (SSL) as a solution for this data scarcity problem. We organized the 2nd Semi-supervised Teeth Segmentation (STS 2024) Challenge at MICCAI 2024. We provided a large-scale dataset comprising over 90,000 2D images and 3D axial slices, which includes 2,380 OPG images and 330 CBCT scans, all featuring detailed instance-level FDI annotations on part of the data. The challenge attracted 114 (OPG) and 106 (CBCT) registered teams. To ensure algorithmic excellence and full transparency, we rigorously evaluated the valid, open-source submissions from the top 10 (OPG) and top 5 (CBCT) teams, respectively. All successful submissions were deep learning-based SSL methods. The winning semi-supervised models demonstrated impressive performance gains over a fully-supervised nnU-Net baseline trained only on the labeled data. For the 2D OPG track, the top method improved the Instance Affinity (IA) score by over 44 percentage points. For the 3D CBCT track, the winning approach boosted the Instance Dice score by 61 percentage points. This challenge confirms the substantial benefit of SSL for complex, instance-level medical image segmentation tasks where labeled data is scarce. The most effective approaches consistently leveraged hybrid semi-supervised frameworks that combined knowledge from foundational models like SAM with multi-stage, coarse-to-fine refinement pipelines. Both the challenge dataset and the participants' submitted code have been made publicly available on GitHub (https://github.com/ricoleehduu/STS-Challenge-2024), ensuring transparency and reproducibility.

</details>


### [13] [Deep Learning for Restoring MPI System Matrices Using Simulated Training Data](https://arxiv.org/abs/2511.23251)
*Artyom Tsanda,Sarah Reiss,Marija Boberg,Tobias Knopp*

Main category: eess.IV

TL;DR: 使用基于物理模拟的系统矩阵训练深度学习模型，可有效解决磁粒子成像中系统矩阵校准的多种恢复任务，并能泛化到真实测量数据。


<details>
  <summary>Details</summary>
Motivation: 磁粒子成像中系统矩阵校准耗时且易受噪声影响，现有深度学习方法缺乏足够的训练数据。本研究旨在评估基于物理模拟的系统矩阵能否用于训练深度学习模型，以解决系统矩阵恢复任务并泛化到真实测量数据。

Method: 使用扩展的单轴各向异性平衡磁化模型生成大规模系统矩阵数据集，涵盖粒子、扫描仪和校准参数，包含2D和3D轨迹，并注入空帧测量的背景噪声。针对去噪、加速校准、上采样和修复等任务，比较深度学习模型与经典非学习基线方法。

Result: 在模拟数据上，去噪任务中DnCNN/RDN/SwinIR比DCT-F基线提高>10 dB PSNR和0.1 SSIM；2D上采样中SMRnet比双三次插值提高20 dB PSNR和0.08 SSIM；3D加速校准中SMRnet在无噪声情况下与三三次插值相当，在噪声下更鲁棒；3D修复中双调和修复在无噪声时更优，但PConvUNet在噪声下保持质量且重建更清晰。

Conclusion: 基于模拟系统矩阵训练的深度学习模型能有效泛化到真实测量数据，缓解了数据稀缺问题，并为超越当前测量能力的新方法开发提供了可能。

Abstract: Magnetic particle imaging reconstructs tracer distributions using a system matrix obtained through time-consuming, noise-prone calibration measurements. Methods for addressing imperfections in measured system matrices increasingly rely on deep neural networks, yet curated training data remain scarce. This study evaluates whether physics-based simulated system matrices can be used to train deep learning models for different system matrix restoration tasks, i.e., denoising, accelerated calibration, upsampling, and inpainting, that generalize to measured data. A large system matrices dataset was generated using an equilibrium magnetization model extended with uniaxial anisotropy. The dataset spans particle, scanner, and calibration parameters for 2D and 3D trajectories, and includes background noise injected from empty-frame measurements. For each restoration task, deep learning models were compared with classical non-learning baseline methods. The models trained solely on simulated system matrices generalized to measured data across all tasks: for denoising, DnCNN/RDN/SwinIR outperformed DCT-F baseline by >10 dB PSNR and up to 0.1 SSIM on simulations and led to perceptually better reconstuctions of real data; for 2D upsampling, SMRnet exceeded bicubic by 20 dB PSNR and 0.08 SSIM at $\times 2$-$\times 4$ which did not transfer qualitatively to real measurements. For 3D accelerated calibration, SMRnet matched tricubic in noiseless cases and was more robust under noise, and for 3D inpainting, biharmonic inpainting was superior when noise-free but degraded with noise, while a PConvUNet maintained quality and yielded less blurry reconstructions. The demonstrated transferability of deep learning models trained on simulations to real measurements mitigates the data-scarcity problem and enables the development of new methods beyond current measurement capabilities.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [14] [Fluid Antenna System-Enabled UAV Communications in the Finite Blocklength Regime](https://arxiv.org/abs/2511.21834)
*Xusheng Zhu,Kai-Kit Wong,Hanjiang Hong,Han Xiao,Hao Xu,Tuo Wu,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文为有限块长体制下的流体天线系统(FAS)无人机中继网络建立了性能分析框架，推导了块错误率的闭式表达式，分析了能量效率优化问题，并揭示了农村与城市环境中不同的最优部署策略。


<details>
  <summary>Details</summary>
Motivation: 研究流体天线系统(FAS)在无人机中继网络中的性能分析，特别是在有限块长体制下，现有研究缺乏对系统可靠性的严格分析，且往往忽略FAS端口选择过程中的时间和能量开销等实际因素。

Method: 采用基于特征值的可处理近似方法来建模空间相关的无人机-用户链路，将独立分集分量建模为Nakagami-m衰落；针对农村(LoS主导)和城市(概率NLoS)场景进行分析；建立高信噪比渐近分析；提出能量效率最大化问题的分层优化算法。

Result: 推导了块错误率(BLER)的闭式表达式，揭示了无人机-用户链路的基本分集阶数；数值结果表明FAS能带来显著功率增益，但操作开销引入了非平凡权衡，导致农村与城市环境中的最优端口数量和无人机部署策略存在根本差异。

Conclusion: 本文为FAS使能的无人机通信提供了基础分析和实用设计指南，强调了在考虑FAS操作开销时，农村和城市环境需要不同的优化策略，为实际系统设计提供了重要见解。

Abstract: This paper develops a comprehensive framework for the performance analysis of fluid antenna system (FAS)-enabled unmanned aerial vehicle (UAV) relaying networks operating in the finite blocklength regime. Our contribution lies in establishing a rigorous methodology for characterizing system reliability under diverse propagation environments. Closed-form expressions for the block error rate (BLER) are derived by employing a tractable eigenvalue-based approximation of the spatially correlated UAV-to-user link, whose underlying independent diversity components are modeled as Nakagami-$m$ fading. This approach addresses both line-of-sight (LoS) dominant rural and probabilistic non-line-of-sight (NLoS) urban scenarios. Furthermore, a high signal-to-noise ratio (SNR) asymptotic analysis is developed, revealing the fundamental diversity order of the UAV-to-user link. Based on this, we further address the practical issue of energy efficiency. A realistic energy efficiency maximization problem is formulated, which explicitly accounts for the time and energy overhead inherent in the FAS port selection process, a factor often omitted in idealized models. An efficient hierarchical algorithm is then proposed to jointly optimize the key system parameters. Extensive numerical results validate the analysis and illustrate that while FASs can yield substantial power gains, the operational overhead introduces a non-trivial trade-off. This trade-off leads to an optimal number of ports and fundamentally different UAV deployment strategies in rural versus urban environments. This work provides both foundational analysis and practical design guidelines for FAS-enabled UAV communications.

</details>


### [15] [Spectrum-Aware IRS Configuration Techniques for Ultrawideband Signals](https://arxiv.org/abs/2511.21927)
*Alessandro Nordio,Alberto Tarable,Francisco J. Escribano*

Main category: cs.IT

TL;DR: 提出两种面向超宽带下行链路的智能反射面配置技术，通过局部优化利用波束分裂效应，相比传统窄带方案和全局优化方法能提升接收信号功率。


<details>
  <summary>Details</summary>
Motivation: 随着无线频谱资源紧张，需要开发更高频段，但高频无线场景存在视距阻塞问题。智能反射面是解决方案之一，但现有技术难以实现大带宽信号重定向，容易受到波束分裂色散效应影响。

Method: 提出两种高效的配置技术：1）基于IRS表面的局部优化；2）利用波束分裂效应并考虑发射信号频谱形状。这些技术专门针对超宽带下行链路场景设计。

Result: 在不同几何设置和信号频谱的仿真中，所提技术相比传统窄带解决方案或对整个IRS表面进行全局优化的技术，能够保证接收端获得更高的信号功率。

Conclusion: 提出的局部优化配置技术能有效应对超宽带场景中的波束分裂效应，提升智能反射面在宽带通信中的性能表现。

Abstract: Intelligent reflecting surfaces (IRS) have become the subject of many current research efforts, as the ongoing wireless spectrum crunch has made the need to open higher frequency bands a priority. IRS are one of the alternatives proposed to overcome the problem of line-of-sight blocking in very high frequency wireless scenarios. The current state-of-the-art shows the difficulty of implementing practical IRS designs able to redirect large signal bandwidths, prone to the so-called beam split (BS) dispersion effect. In this work, we propose two highly efficient configuration techniques, adapted to ultrawideband downlink scenarios, based on localized optimization over the IRS surface. Such techniques exploit the BS effect while taking into account for the shape of the transmitted signal spectrum. Simulations considering different geometrical setups and different signal spectra show how the proposed techniques are able to guarantee an increased signal power at the receiver with respect to classical narrowband-based solutions or techniques that perform a global optimization over the entire IRS surface.

</details>


### [16] [Four classes of optimal p-ary cyclic codes](https://arxiv.org/abs/2511.22086)
*Jinmei Fan,Jingyao Feng,Yuhan Men,Yanhai Zhang*

Main category: cs.IT

TL;DR: 该论文研究了参数为[p^m-1,p^m-2m-2,4]的最优p元循环码，通过弱化码字汉明重量为3的充要条件并分析有限域上特定方程的解，构造了四类最优p元循环码，其中三类是无限的。


<details>
  <summary>Details</summary>
Motivation: 对于奇素数p>3和正整数m，参数为[p^m-1,p^m-2m-2,4]的最优p元循环码研究进展缓慢。现有研究有限，需要新的构造方法来获得更多最优循环码类。

Method: 通过弱化循环码具有汉明重量为3的码字的充要条件，并分析有限域上特定方程的解，构造了由p^m+1/2推导出的四类最优p元循环码。

Result: 提出了四类参数为[p^m-1,p^m-2m-2,4]的最优p元循环码，其中三类是无限的。许多已知的最优五元循环码[5^m-1,5^m-2m-2,4]是本文构造的码的特例。

Conclusion: 本文成功构造了四类最优p元循环码，扩展了最优循环码的理论体系，为编码理论提供了新的构造方法，其中三类无限类具有重要的理论价值。

Abstract: Let p>3 be an odd prime and m be a positive integer. Little progress on the study of optimal p-ary cyclic codes with parameters [p^m-1,p^m-2m-2,4] has been made.In this paper, by weakening the necessary and sufficient conditions on cyclic codes to have codewords of Hamming weight 3 and analyzing the solutions of certain equations over finite fields, four classes of optimal p-ary cyclic codes deduced by p^m+1/2 with parameters [p^m-1,p^m-2m-2,4] are presented.Wherein three classes of optimal p-ary cyclic codes are infinite.Many classes of known optimal quinary cyclic codes with parameters [5^m-1,5^m-2m-2,4] are special cases of the codes constructed in this paper.

</details>


### [17] [Fluid Antenna-Enhanced Flexible Beamforming](https://arxiv.org/abs/2511.22163)
*Jingyuan Xu,Zhentian Zhang,Jian Dang,Hao Jiang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于二维平面流体天线阵列的灵活波束成形框架，将任意波束模式合成转化为稀疏回归问题，并采用定制压缩感知算法和迭代FFT相位恢复方法，相比传统固定阵列显著提高了波束模式重建精度。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统能够在固定物理孔径内提供更高的空间分辨率，对于下一代无线部署具有吸引力。实际通信网络中既需要窄波束也需要宽波束模式，因此通过流体天线实现灵活波束成形成为一个重要且有趣的研究方向。

Method: 建立了一个统一的灵活框架，将任意波束模式合成与流体天线端口选择联系起来。将波束模式重建转化为稀疏回归问题，采用定制压缩感知算法配合快速傅里叶变换高效求解。为确保期望波束的物理一致性相位建模，引入了迭代FFT相位恢复方法，每次迭代仅需一次FFT和一次逆FFT。

Result: 仿真结果表明所提出的灵活波束成形框架有效。与传统固定阵列架构相比，流体天线展现出显著改善的波束模式重建精度，突显了其在未来无线系统中实现高分辨率和自适应波束成形的潜力。

Conclusion: 流体天线系统通过提出的灵活波束成形框架，能够实现更精确的波束模式重建，为下一代无线系统的高分辨率和自适应波束成形提供了有前景的解决方案。

Abstract: Fluid antenna systems encompass a broad class of reconfigurable antenna technologies that offer substantial spatial diversity for various optimization objectives and communication tasks. Their capability to enhance spatial resolution within a fixed physical aperture makes fluid antennas particularly attractive for next-generation wireless deployments. In this work, we focus on the beamforming problem using a two-dimensional planar fluid antenna array. Since both narrow-beam and broad-beam patterns are essential in practical communication networks, enabling flexible beamforming through fluid antennas becomes an important and interesting research direction. We establish a unified and flexible framework that connects arbitrary beam-pattern synthesis with fluid-antenna port selection. The resulting formulation transforms beam-pattern reconstruction into a sparse regression problem, which is addressed using a tailored compressive sensing algorithm designed to operate efficiently with the fast Fourier transform (FFT). Furthermore, to ensure physically consistent phase modeling in the desired beam, we introduce an iterative FFT-based phase retrieval method. Owing to its structure, the proposed phase-refinement procedure exhibits low computational complexity and rapid convergence, requiring only one FFT and one inverse FFT per iteration. Simulation results demonstrate the effectiveness of the proposed flexible beamforming framework. Compared with conventional fixed-array architectures, fluid antennas exhibit significantly improved beam-pattern reconstruction accuracy, highlighting their potential for high-resolution and adaptive beamforming in future wireless systems.

</details>


### [18] [Constructions of block MDS LDPC codes from punctured circulant matrices](https://arxiv.org/abs/2511.22183)
*Hongwei Zhu,Xuantai Wu,Jingjie Lv,Qinshan Zhang,Shu-Tao Xia*

Main category: cs.IT

TL;DR: 本文构造了同时具有块MDS特性和Tanner图中无4环的LDPC码，称为块MDS LDPC码，在二进制域上实现，既增强随机纠错能力又能有效对抗突发错误。


<details>
  <summary>Details</summary>
Motivation: LDPC码在迭代译码中性能优异，接近香农极限；MDS阵列码具有良好代数结构，适合解码大突发错误。但现有码要么有4环问题（如BR码），要么不是MDS阵列码（如Fossorier的准循环LDPC码）。需要构造同时具备块MDS特性和无4环Tanner图的码。

Method: 1. 从穿孔循环置换矩阵生成二进制块MDS码族；2. 从列重大于1的循环矩阵（CM(t)）构造块MDS LDPC码族；3. 提出CM(t)的Moore行列式公式和避免4环的充分条件；4. 指出二进制块MDS CPM-QC LDPC码不存在性。

Result: 相比Li等人（2023）和Xiao等人（2021）的码，在相似码长和码率下，本文的块MDS LDPC码表现出增强的随机纠错能力。同时作为阵列码能有效对抗突发错误。两种构造方法都适用于二进制域。

Conclusion: 成功构造了兼具块MDS特性和无4环Tanner图的二进制LDPC码，在随机错误和突发错误纠正方面都表现优异，为同时需要两种纠错能力的应用场景提供了有效解决方案。

Abstract: Low density parity check (LDPC) codes, initially discovered by Gallager, exhibit excellent performance in iterative decoding, approaching the Shannon limit. MDS array codes, with favorable algebraic structures, are codes suitable for decoding large burst errors. The Blaum-Roth (BR) code, an MDS array code similar to the Reed-Solomon (RS) code but has a parity-check matrix prone to $4$-cycles. Fossorier proposed constructing quasi-cyclic LDPC codes from circulant permutation matrices but are not MDS array codes. This paper aims to construct codes that possess both the block MDS property and have no $4$-cycles in the Tanner graph of their parity-check matrices, namely the so-called block MDS LDPC codes. Non-binary block MDS QC codes were first constructed by [Tauz {\it et al. }IEEE ITW, 2025] using circulant shift matrices. We first generate a family of block MDS codes over $\F_2$ from punctured circulant permutation matrices. Second, we construct a family of block MDS LDPC codes from circulant matrices with column weight $> 1$ (CM$(t)$). Additionally, we present the Moore determinant formula for CM$(t)$s and a sufficient condition to avoid $4$-cycles in CM\((t)\)-QC LDPC codes' Tanner graphs for $t> 1$. We also point out the non-existence of binary block MDS CPM-QC LDPC codes. Compared to the codes constructed in [Li {\it et al. }IEEE TIT, 2023] and [Xiao {\it et al. }IEEE TCOM, 2021], our block MDS LDPC codes show enhanced random-error-correction at a similar code length and rate. Meanwhile, these codes can effectively combat burst errors when considered as array codes. Both of our two types of constructions for block MDS LDPC codes are applicable to the scenario of the binary field.

</details>


### [19] [Maximum Entropy and Bayesian Conditioning Under Extended Space](https://arxiv.org/abs/2511.22375)
*Boning Yu*

Main category: cs.IT

TL;DR: 该论文探讨了贝叶斯条件化与最大熵原理在何种条件下一致，特别关注新信息不在原始概率空间事件中的情况，并回应了Skyrms与Seidenfeld之间的学术争议。


<details>
  <summary>Details</summary>
Motivation: 当新获得的信息不属于原始样本空间定义的概率空间中的事件时，需要扩展概率空间才能使贝叶斯条件化适用。Skyrms(1985)认为在扩展的概率空间上进行贝叶斯条件化与最大熵解一致，而Seidenfeld(1986)则批评这种一致性只在退化概率模型下成立。论文旨在澄清这一理论争议。

Method: 通过理论分析，探讨概率空间扩展的方法，特别是使用结果空间的乘积空间进行扩展。分析Friedman和Shimony(1971)的结果在Skyrms方法中的含义，论证该结果要么是Skyrms方法的良性推论，要么对所有空间扩展方法构成普遍挑战。

Result: 论文提出Friedman和Shimony的结果要么是Skyrms方法的自然结果，要么意味着贝叶斯条件化根本无法处理超出原始结果空间概率空间的信息。接受后者将严重限制贝叶斯方法的适用范围。

Conclusion: 贝叶斯条件化与最大熵原理的一致性争议需要重新审视。要么Skyrms的方法是正确的，Friedman-Shimony结果是其良性推论；要么所有概率空间扩展方法都面临根本性挑战，这将质疑贝叶斯方法处理超出原始空间信息的能力。

Abstract: This paper examines the conditions under which Bayesian conditioning aligns with Maximum Entropy. Specifically, I address cases in which newly learned information does not correspond to an event in the probability space defined on the sample space of outcomes. To facilitate Bayesian conditioning in such cases, one must therefore extend the probability space so that the new information becomes an event in this expanded space. Skyrms (1985) argues that Bayesian conditioning in an extended probability space on a product space of outcomes aligns precisely with the solution from Maximum Entropy. In contrast, Seidenfeld (1986) uses Friedman and Shimony's (1971) result to criticize Skyrms' approach as trivial, suggesting that alignment holds only under a degenerate probability model. Here, I argue that Friedman and Shimony's result must either (1) be a benign consequence of Skyrms' approach, or (2) pose a universal challenge to any method of extending spaces. Accepting (2) would imply that Bayesian conditioning is incapable of accommodating information beyond the probability space defined on the original outcome space.

</details>


### [20] [On the SER Performance of ZF and MMSE Receivers in Pilot-Aided Simultaneous Communication and Localization](https://arxiv.org/abs/2511.22418)
*Shuaishuai Han,Emad Alsusa,Arafat Al-Dweik*

Main category: cs.IT

TL;DR: 本文分析了定位误差对ZF和MMSE均衡器通信性能的影响，推导了紧密近似的SER表达式，揭示了定位误差对不同均衡器的影响差异。


<details>
  <summary>Details</summary>
Motivation: 在无人机通信系统中，定位误差会影响信道矩阵的准确性，进而影响均衡器的性能。需要量化分析定位误差对ZF和MMSE均衡器符号错误率的影响，为系统设计提供指导。

Method: 采用PASCAL系统，无人机向基站发送信号，基站估计位置参数重建信道矩阵。由于信道矩阵与位置参数相关且涉及矩阵求逆，采用Neumann近似和Taylor近似的混合方法推导ZF和MMSE的近似SER表达式。

Result: 1) 所有无人机的定位误差都会影响单个无人机的SER；2) ZF的SER不受距离估计误差影响，而MMSE受影响；3) ZF和MMSE对角度估计误差最敏感；4) ZF对定位误差高度敏感，在显著误差条件下可能比MRC更差。

Conclusion: 定位误差对ZF和MMSE均衡器性能有显著影响，ZF对角度误差特别敏感。在定位精度有限时，MMSE可能比ZF更鲁棒，系统设计需权衡定位精度与均衡器选择。

Abstract: In this paper, a symbol error rate (SER) analysis is provided to evaluate the impact of localization inaccuracy on the communication performance under Zero-Forcing (ZF) and Minimum Mean-Square Error (MMSE) equalizers. Specifically, we adopt a pilot-aided simultaneous communication and localization (PASCAL) system, in which multiple drones actively transmit signals towards the base station (BS). Upon receiving the signal, the BS estimates the drones' location parameters to reconstruct the channel matrix, which is then utilized for ZF and MMSE equalization. As the channel matrix is characterized by the estimated parameters associated with the target's location and the matrix inversion involved in ZF and MMSE further complicates the analysis, obtaining a closed-form SER expression becomes intractable. Thus, a tightly approximated SER expression is respectively derived for ZF and MMSE by using a hybrid approximation method incorporating Neumann approximation and Taylor approximation. Our analysis reveals several important design insights: first, the average SER of drone $k$ for both ZF and MMSE can be affected by the localization errors from all drones including drone $k$; second, the average SER of ZF is unaffected by the estimation inaccuracy of range, whereas the average SER of MMSE is influenced by it; third, ZF and MMSE is the most susceptible to the influence of angle estimation errors compared to the other localization errors; fourth, ZF is highly sensitive to localization errors and may be even worse than maximal ratio combining (MRC) under some conditions of significant estimation errors. Numerical simulation results verify our findings and also validate the accuracy of the analysis across a wide range of system parameters.

</details>


### [21] [TransCoder: A Neural-Enhancement Framework for Channel Codes](https://arxiv.org/abs/2511.22539)
*Anastasiia Kurmukova,Selim F. Yilmaz,Emre Ozfatura,Deniz Gunduz*

Main category: cs.IT

TL;DR: TransCoder是一种基于Transformer架构的神经传输方案，用于增强现有纠错码的性能，在保持与传统解码器相当的计算复杂度下显著降低误块率。


<details>
  <summary>Details</summary>
Motivation: 现有的神经网络解码器虽然能提高纠错码的可靠性，但计算复杂度太高，难以实际部署。需要设计一种既能提升性能又保持实用性的解决方案。

Method: 提出TransCoder框架，采用Transformer架构作为码自适应神经模块，可灵活部署在发射端、接收端或两端。采用迭代解码过程，通过块注意力机制高效处理信道噪声信息和传统解码器更新。

Result: 在多种传统编码（LDPC、BCH、Polar、Turbo）和广泛信道条件下，TransCoder显著改善了误块率性能，计算复杂度与传统解码器相当。特别对长码（块长>64）和低码率场景效果显著。

Conclusion: TransCoder为资源受限的无线设备提供了一种有前景的实用可靠通信解决方案，在保持实用性的同时显著提升了现有纠错码的性能。

Abstract: Reliable communication over noisy channels requires the design of specialized error-correcting codes (ECCs) tailored to specific system requirements. Recently, neural network-based decoders have emerged as promising tools for enhancing ECC reliability, yet their high computational complexity prevents their potential practical deployment. In this paper, we take a different approach and design a neural transmission scheme that employs the transformer architecture in order to improve the reliability of existing ECCs. We call this approach TransCoder, alluding both to its function and architecture. TransCoder operates as a code-adaptive neural module aimed at performance enhancement that can be implemented flexibly at either the transmitter, receiver, or both. The framework employs an iterative decoding procedure, where both noisy information from the channel and updates from the conventional ECC decoder are processed by a neural decoder block, utilizing a block attention mechanism for efficiency. Through extensive simulations with various conventional codes (LDPC, BCH, Polar, and Turbo) and across a wide range of channel conditions, we demonstrate that TransCoder significantly improves block error rate (BLER) performance while maintaining computational complexity comparable to traditional decoders. Notably, our approach is particularly effective for longer codes (block length >64) and at lower code rates, scenarios in which existing neural decoders often struggle (despite their formidable computational complexity). The results establish TransCoder as a promising practical solution for reliable communication among resource-constrained wireless devices.

</details>


### [22] [Maximum Spectral Efficiency With Adaptive MQAM Transmissions Over Terrestrial Coherent FSO Links](https://arxiv.org/abs/2511.22682)
*Himani Verma,Kamal Singh,Ranjan K. Mallik*

Main category: cs.IT

TL;DR: 该论文研究了自由空间光通信中自适应MQAM调制的性能，推导了理论极限并验证了仅使用6种方形MQAM星座即可接近理论极限。


<details>
  <summary>Details</summary>
Motivation: 相干自由空间光通信是下一代无线网络超高速前传和回传的关键技术，MQAM调制格式适合此类链路，但针对地面FSO信道的自适应MQAM传输理论分析仍有限。

Method: 首先推导了在gamma-gamma湍流和指向误差下自适应无约束MQAM的频谱效率极限，然后评估了仅使用6种方形MQAM星座的自适应传输性能。

Result: 仅使用6种方形MQAM星座的自适应传输在广泛信噪比和信道条件下，性能接近理论极限（差距仅0.10-0.12 bits/s/Hz）。

Conclusion: 自适应传输仅需少量MQAM星座即可实现接近理论极限的性能，为实际FSO系统设计提供了高效且实用的解决方案。

Abstract: Coherent free-space optical (FSO) communication is recognized as a key enabler for ultra-high-capacity fronthaul and backhaul links in next-generation wireless networks. Spectrally efficient $M$-ary quadrature amplitude modulation (MQAM) formats are well-suited for these links. However, theoretical analyses of adaptive MQAM transmissions over terrestrial FSO channels remain limited. In this letter, we first derive the spectral efficiency limit of adaptive unconstrained MQAM over gamma-gamma turbulence with pointing error. We then show that adaptive transmissions using only six square MQAM constellations performs close to the theoretical limit (within $0.10$-$0.12$ bits/s/Hz) across a wide range of signal-to-noise ratios and channel conditions.

</details>


### [23] [On Information Theoretic Fairness With A Bounded Point-Wise Statistical Parity Constraint: An Information Geometric Approach](https://arxiv.org/abs/2511.22683)
*Amirreza Zamani,Ayfer Özgür,Mikael Skoglund*

Main category: cs.IT

TL;DR: 该论文研究在点式统计公平性约束下设计公平表示的信息论问题，通过信息几何方法将复杂优化转化为二次规划，提供低复杂度解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究如何在保护敏感属性隐私的同时，从数据中提取有用信息完成任务。传统方法使用互信息约束，本文采用点式统计公平性约束，且假设无法直接访问敏感属性和任务变量。

Method: 设计表示Y最大化I(Y;T)同时满足压缩率约束I(Y;X)≤r和点式统计公平性约束χ²(P_{S|y};P_S)≤ε。利用信息几何方法在ε较小时近似KL散度和互信息，将复杂优化问题转化为二次规划，通过奇异值分解获得低复杂度解。

Result: 当ε较小时，通过局部近似将公平表示设计问题转化为二次优化问题，在特定约束下获得闭式解。对于无法获得闭式解的情况，提供了低计算复杂度的下界估计方法，基于矩阵最大奇异值和奇异向量。

Conclusion: 提出了一种在点式统计公平性约束下设计公平表示的低复杂度方法，通过信息几何近似将复杂信息论问题转化为可解的二次规划，数值实验表明该方法接近最优解。

Abstract: In this paper, we study an information-theoretic problem of designing a fair representation under a bounded point-wise statistical (demographic) parity constraint. More specifically, an agent uses some useful data (database) $X$ to solve a task $T$. Since both $X$ and $T$ are correlated with some latent sensitive attribute or secret $S$, the agent designs a representation $Y$ that satisfies a bounded point-wise statistical parity, that is, such that for all realizations of the representation $y\in\cal Y$, we have $χ^2(P_{S|y};P_S)\leq ε$. In contrast to our previous work, here we use the point-wise measure instead of a bounded mutual information, and we assume that the agent has no direct access to $S$ and $T$; hence, the Markov chains $S - X - Y$ and $T - X - Y$ hold. In this work, we design $Y$ that maximizes the mutual information $I(Y;T)$ about the task while satisfying a bounded compression rate constraint, that is, ensuring that $I(Y;X) \leq r$. Finally, $Y$ satisfies the point-wise bounded statistical parity constraint $χ^2(P_{S|y};P_S)\leq ε$. When $ε$ is small, concepts from information geometry allow us to locally approximate the KL-divergence and mutual information. To design the representation $Y$, we utilize this approximation and show that the main complex fairness design problem can be rewritten as a quadratic optimization problem that has simple closed-form solution under certain constraints. For the cases where the closed-form solution is not obtained we obtain lower bounds with low computational complexity. Here, we provide simple fairness designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix. Finally, in a numerical example we compare our obtained results with the optimal solution.

</details>


### [24] [Leveraging Channel Knowledge Map for Multi-User Hierarchical Beam Training Under Position Uncertainty](https://arxiv.org/abs/2511.22902)
*Xu Shi,Haohan Wang,Yashuai Cao,Hengyu Zhang,Sufang Yang,Jintao Wang*

Main category: cs.IT

TL;DR: 提出一种信道知识地图辅助的波束训练框架，通过分层搜索和位置剪枝策略，在单用户和多用户场景下降低训练开销并提高性能。


<details>
  <summary>Details</summary>
Motivation: 信道知识地图(CKM)虽能提供位置特定的信道信息，但在实际波束训练中面临两大挑战：1) 用户精确位置通常未知，限制了CKM的效用；2) CKM、实时观测和训练策略之间的复杂交互尚未深入研究，导致性能次优。

Method: 单用户场景：提出基于奖励激励的波束潜力分层策略，建模用户位置不确定性，将分层搜索过程建模为剪枝二叉搜索树，通过评估潜在码字的权重和奖励推导最小开销的最优分层搜索策略，并设计低复杂度的两层前瞻方案。多用户场景：开发相关性驱动的位置剪枝训练方案，利用用户间干扰的旁瓣增益提供额外侧信息以减少开销，同时为所有用户分配支持性波束。

Result: 仿真验证了所提方法在推进6G波束训练方面的优越性能，能够有效降低训练开销并提高系统性能。

Conclusion: 提出的CKM辅助波束训练框架通过分层搜索和位置剪枝策略，解决了CKM在实际应用中的位置不确定性和多用户干扰问题，为6G波束训练提供了有效的解决方案。

Abstract: Channel knowledge map (CKM) emerges as a promising framework to acquire location-specific channel information without consuming wireless resources, creating new horizons for advanced wireless network design and optimization. Despite its potential, the practical application of CKM in beam training faces several challenges. On one hand, the user's precise location is typically unavailable prior to beam training, which limits the utility of CKM since its effectiveness relies heavily on accurate input of position data. On the other hand, the intricate interplay among CKM, real-time observations, and training strategies has not been thoroughly studied, leading to suboptimal performance and difficulties in practical implementation. In this paper, we present a framework for CKM-aided beam training that addresses these limitations. For single-user scenario, we propose a reward-motivated beam-potential hierarchical strategy which integrates partial position information and CKM. This strategy models the user equipment (UE) position uncertainty and formulates the hierarchical searching process as a pruned binary search tree. An optimal hierarchical searching strategy with minimal overhead is derived by evaluating the weights and rewards of potential codewords. Furthermore, a low-complexity two-layer lookahead scheme is designed to balance overhead and computational demands. For multi-user scenario, we develop a correlation-driven position-pruning training scheme, where sidelobe gains from inter-user interference are exploited to provide additional side information for overhead reduction, allowing all users to be simultaneously assigned their respective supportive beams. Simulations validate the superior performances of proposed approaches in advancing 6G beam training.

</details>


### [25] [Decoding Trombetti-Zhou codes: a new syndrome-based decoding approach](https://arxiv.org/abs/2511.23202)
*Chunlei Li,Angelica Piccirillo,Olga Polverino,Ferdinando Zullo*

Main category: cs.IT

TL;DR: 本文针对Trombetti-Zhou提出的F_q^n-线性最大秩距离(MRD)码，提出了一种新的基于校验子的解码算法，通过引入F_q^n-生成矩阵和F_q^n-校验矩阵的概念，将解码问题转化为Gabidulin码的解码问题。


<details>
  <summary>Details</summary>
Motivation: Trombetti-Zhou码是F_q^n-线性但不是F_q^{2n}-线性的MRD码，缺乏传统线性码的校验矩阵结构，这限制了基于校验子的解码方法的应用。因此需要为这类F_q^n-线性秩度量码开发新的解码框架。

Method: 1) 为F_q^n-线性秩度量码引入F_q^n-生成矩阵和F_q^n-校验矩阵的概念；2) 为Trombetti-Zhou码构造特定的F_q^n-校验矩阵，使用迹几乎对偶基；3) 将解码问题分为两种情况：当错误秩t < (d-1)/2时，转化为维度大一维的Gabidulin码解码；当t = (d-1)/2时，简化为确定特定矩阵的秩。

Result: 成功为Trombetti-Zhou码开发了基于校验子的解码算法，能够处理秩错误权重t ≤ (d-1)/2的情况，并分析了算法的复杂度。

Conclusion: 本文为Trombetti-Zhou码提供了一种有效的解码方案，通过引入F_q^n-线性结构的新概念，克服了传统线性解码方法不适用的问题，扩展了MRD码的解码理论。

Abstract: In 2019, Trombetti and Zhou introduced a new family of $\mathbb{F}_{q^n}$-linear Maximum Rank Distance (MRD) codes over $\mathbb{F}_{q^{2n}}$. For such codes we propose a new syndrome-based decoding algorithm. It is well known that a syndrome-based decoding approach relies heavily on a parity-check matrix of a linear code. Nonetheless, Trombetti-Zhou codes are not linear over the entire field $\mathbb{F}_{q^{2n}}$, but only over its subfield $\mathbb{F}_{q^{n}}$. Due to this lack of linearity, we introduce the notions of $\mathbb{F}_{q^{n}}$-generator matrix and $\mathbb{F}_{q^{n}}$-parity-check matrix for a generic $\mathbb{F}_{q^{n}}$-linear rank-metric code over $\mathbb{F}_{q^{rn}}$ in analogy with the roles that generator and parity-check matrices play in the context of linear codes. Accordingly, we present an $\mathbb{F}_{q^n}$-generator matrix and $\mathbb{F}_{q^n}$-parity-check matrix for Trombetti-Zhou codes as evaluation codes over an $\mathbb{F}_q$-basis of $\mathbb{F}_{q^{2n}}$. This relies on the choice of a particular basis called \emph{trace almost dual basis}. Subsequently, denoting by $d$ the minimum distance of the code, we show that if the rank weight $t$ of the error vector is strictly smaller than $\frac{d-1}{2}$, the syndrome-based decoding of Trombetti-Zhou codes can be converted to the decoding of Gabidulin codes of dimension one larger. On the other hand, when $t=\frac{d-1}{2}$, we reduce the decoding to determining the rank of a certain matrix. The complexity of the proposed decoding for Trombetti-Zhou codes is also discussed.

</details>


### [26] [Efficient Estimation of Sum-Parameters for Multi-Component Complex Exponential Signals with Theoretical Cramer-Rao Bound Analysis](https://arxiv.org/abs/2511.23318)
*Huiguang Zhang*

Main category: cs.IT

TL;DR: 提出基于低维和参数的新框架，用于多分量复指数信号参数估计，避免传统方法的排列模糊性、计算复杂度和模型阶数选择问题，在长/短样本条件下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统多分量复指数信号参数估计方法面临三大挑战：1) 分量排列模糊性；2) 高维Fisher信息矩阵求逆带来的计算复杂度；3) 模型阶数选择问题。当分量数量较大时，这些问题尤为突出。

Method: 提出基于低维和参数的新框架，包括：振幅和、功率加权频率、相位相关和。这些参数具有明确的物理意义（总信号强度、功率加权平均频率、复合相位信息），且完全避免排列模糊性。开发了高效全局估计方法(EGEM)。

Result: 推导了确定性和随机信号模型下和参数的精确闭式Cramér-Rao界。频率和参数达到与单分量估计器相当的统计效率，同时自动受益于所有信号分量的功率池化。EGEM在宽信噪比范围内实现渐近效率，在长/短样本条件下均显著优于Zoom-Interpolated FFT和Root-MUSIC。2000次蒙特卡洛仿真表明，即使只有250个观测样本，EGEM也能接近理论性能界。

Conclusion: 提出的和参数框架为多分量复指数信号参数估计提供了有效的解决方案，避免了传统方法的局限性，在统计效率和计算复杂度方面均有显著优势，为实际应用提供了可行的理论和方法基础。

Abstract: This paper addresses the challenging problem of parameter estimation for multicomponent complex exponential signals, commonly known as sums of cisoids. Traditional approaches that estimate individual component parameters face significant difficulties when the number of components is large, including permutation ambiguity, computational complexity from high-dimensional Fisher information matrix inversion, and model order selection issues. We introduce a novel framework based on low-dimensional sum-parameters that capture essential global characteristics of the signal ensemble. These parameters include the sum of amplitudes, the power-weighted frequency, and the phase-related sum. These quantities possess clear physical interpretations representing total signal strength, power-weighted average frequency, and composite phase information, while completely avoiding permutation ambiguities. We derive exact closed-form Cramer-Rao bounds for these sum-parameters under both deterministic and stochastic signal models. Our analysis reveals that the frequency sumparameter achieves statistical efficiency comparable to single-component estimators while automatically benefiting from power pooling across all signal components. The proposed Efficient Global Estimation Method (EGEM) demonstrates asymptotic efficiency across a wide range of signal-to-noise ratios, significantly outperforming established techniques such as Zoom-Interpolated FFT and Root-MUSIC in both long- and short-sample regimes. Extensive numerical simulations involving 2000 Monte-Carlo trials confirm that EGEM closely approaches the theoretical performance bounds even with relatively small sample sizes of 250 observations.

</details>


### [27] [Quantum Private Distributed Matrix Multiplication With Degree Tables](https://arxiv.org/abs/2511.23406)
*Mohamed Nomeir,Alptug Aytekin,Lei Hu,Sennur Ulukus*

Main category: cs.IT

TL;DR: 量子资源用于提升私有分布式矩阵乘法(PDMM)速率，通过量子纠缠和量子信道减少所需服务器数量，针对高隐私和低隐私两种场景分别提出量子可行性条件和新编码方案。


<details>
  <summary>Details</summary>
Motivation: 传统PDMM需要大量服务器进行矩阵乘法计算，用户缺乏本地计算能力时需要将矩阵分块发送给多个服务器，同时保护隐私不被任意T个服务器窃取。量子资源（纠缠态和量子信道）有望减少所需服务器数量，提高计算效率。

Method: 1. 在高隐私场景下，针对GASP编码定义量子可行性条件，当条件不满足时：a) 分析最小隐私要求与矩阵维度的关系；b) 开发新的量子编码族。2. 在低隐私场景下，将GASP的可行性条件扩展到CAT和DOG编码，并针对不满足可行性条件的情况提出另一组量子编码方案。

Result: 提出了量子PDMM框架，允许服务器共享纠缠态并通过量子信道响应，用户通过测量量子比特获得矩阵乘法结果。针对不同隐私场景开发了相应的量子可行性条件和编码方案，减少了所需服务器数量。

Conclusion: 量子资源能够有效提升私有分布式矩阵乘法的效率，通过量子纠缠和量子信道可以减少所需服务器数量。针对高隐私和低隐私两种场景分别提出了相应的量子可行性条件和编码方案，为量子分布式计算提供了新的解决方案。

Abstract: In this paper, we explore how quantum resources can be used to increase the rate of private distributed matrix multiplication (PDMM). In PDMM, a user who has two high-dimensional matrices, $A$ and $B$, and lacks the computational capabilities to apply matrix multiplication locally, divides the matrices $A$ and $B$ into $K$ and $L$ sub-blocks, respectively. Then, the user sends them to $N$ servers to apply the required multiplication privately from any $T$ servers. The goal is to reduce the number of servers needed to perform the required matrix multiplication. In the quantum setting, we allow the servers to share an entangled state and respond over quantum channels. Upon receiving the qudits, the user applies measurements to obtain the required multiplication. There are two main regimes in the PDMM literature: The high-privacy regime and the low-privacy regime where $T$ is less than $K$ and $L$.
  First, in the high-privacy regime, the state-of-the-art classical code is called the gap additive secure polynomial (GASP) code. We define a feasibility requirement in the quantum setting for the GASP code such that the highest performance is achieved when it is satisfied. When it is not satisfied, we address two main concerns. The first is to find a relation between the minimum privacy requirement and the dimensions of the two matrices needed for the feasibility condition to be satisfied. Second, we develop a new family of codes that can work in the quantum setting.
  Second, since GASP does not work efficiently in the low-privacy regimes compared to cyclic-addition degree tables (CAT) and discretely optimized GASP (DOG), we show that the feasibility condition developed for GASP can be adopted for both CAT and DOG codes as well. In addition, we propose another set of codes that can be used in the low privacy regime in the quantum setting when the feasibility requirement is not satisfied.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [28] [Internodal Distance Distributions for Static and Mobile Nodes in 2D/3D Wireless Networks](https://arxiv.org/abs/2511.21864)
*Nicholas Vaiopoulos,Alexander Vavoulas,Harilaos G. Sandalidis,Konstantinos K. Delibasis,Dimitris Varoutas*

Main category: eess.SP

TL;DR: 该论文提出了一个统一的解析框架，用于分析2D和3D无线网络中节点间距离分布，节点被限制在同心圆或球形区域内。考虑了四种部署场景，涵盖了静态（均匀）和移动（基于随机路径点）节点的所有组合，并推导了每种场景下节点间距离概率密度函数的闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 无线网络中节点间距离分布的分析对于网络性能评估至关重要，但现有研究通常只考虑特定部署场景。特别是对于节点被限制在同心区域且具有不同移动模式的情况，缺乏统一的分析框架。

Method: 提出了一个统一的解析框架，考虑了四种部署场景：静态-静态、静态-移动、移动-静态和移动-移动节点组合。对于每种场景，推导了节点间距离概率密度函数的闭式表达式，考虑了几何约束和移动引入的空间效应。使用Beta分布近似和蒙特卡洛模拟验证分析结果。

Result: 成功推导了所有四种部署场景下节点间距离概率密度函数的闭式表达式。Beta分布近似和蒙特卡洛模拟验证了分析结果的准确性和有效性，特别是在等半径情况下也得到了解决。

Conclusion: 该研究为2D和3D无线网络中节点间距离分布提供了一个统一的分析框架，能够处理节点被限制在同心区域的各种部署场景，包括静态和移动节点组合，为网络性能分析和优化提供了理论基础。

Abstract: This letter presents a unified analytical framework for internodal distance distributions in 2D and 3D wireless networks, with nodes confined to concentric circular or spherical regions. Four deployment scenarios are considered, covering all combinations of static (uniform) and mobile (random waypoint-based) nodes. For each scenario, closed-form expressions for the internodal distance probability density functions are derived, incorporating both geometric constraints and spatial effects introduced by mobility. Equal-radius cases are also addressed. Beta-distribution approximations and Monte Carlo simulations demonstrate the accuracy and validity of the analytical results.

</details>


### [29] [Joint Estimation of Sea State and Vessel Parameters Using a Mass-Spring-Damper Equivalence Model](https://arxiv.org/abs/2511.21997)
*Ranjeet K. Tiwari,Daniel Sgarioto,Peter Graham,Alexei Skvortsov,Sanjeev Arulampalam,Damith C. Ranasinghe*

Main category: eess.SP

TL;DR: 提出一种无需先验传递函数知识的实时海况与船舶参数联合估计方法，通过伪质量-弹簧-阻尼器建模和平方根容积卡尔曼滤波器实现


<details>
  <summary>Details</summary>
Motivation: 传统海况估计方法依赖准确的波浪-船舶传递函数，但这些函数可能无法获得或会变化。需要一种无需先验传递函数知识的方法来联合估计海况和船舶参数

Method: 使用伪质量-弹簧-阻尼器对波浪-船舶系统建模，建立动态模型；将波浪激励递归建模为时变输入；推导统计一致的过程噪声协方差；实现平方根容积卡尔曼滤波器进行传感器数据融合；推导后验克拉美-罗下界评估性能

Result: 通过大量蒙特卡洛模拟和高保真验证模拟器数据确认，估计的波浪谱与假设完全传递函数知识的方法相匹配

Conclusion: 该方法能够在不依赖先验传递函数知识的情况下有效联合估计海况和船舶参数，性能与传统需要完整传递函数的方法相当

Abstract: Real-time sea state estimation is vital for applications like shipbuilding and maritime safety. Traditional methods rely on accurate wave-vessel transfer functions to estimate wave spectra from onboard sensors. In contrast, our approach jointly estimates sea state and vessel parameters without needing prior transfer function knowledge, which may be unavailable or variable. We model the wave-vessel system using pseudo mass-spring-dampers and develop a dynamic model for the system. This method allows for recursive modeling of wave excitation as a time-varying input, relaxing prior works' assumption of a constant input. We derive statistically consistent process noise covariance and implement a square root cubature Kalman filter for sensor data fusion. Further, we derive the Posterior Cramer-Rao lower bound to evaluate estimator performance. Extensive Monte Carlo simulations and data from a high-fidelity validated simulator confirm that the estimated wave spectrum matches methods assuming complete transfer function knowledge.

</details>


### [30] [CUNEC: A Path Loss Model for Urban Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2511.22041)
*Thomas Choi,Yuning Zhang,Issei Kanno,Masaaki Ito,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 提出CUNEC模型，用于城市非平稳环境下的无蜂窝大规模MIMO路径损耗建模，考虑了空间非平稳性、AP/UE相关性及城市特有传播现象，相比传统模型显著提升精度。


<details>
  <summary>Details</summary>
Motivation: 传统路径损耗模型在密集城市环境中无法捕捉真实传播的复杂性，特别是在无蜂窝大规模MIMO系统中，需要更准确的模型来评估和优化系统性能。

Method: 提出CUNEC模型，通过街道顺序分割AP-UE路径，将路径损耗建模为城市几何的随机函数，并集成空间相关阴影衰落。参数从大规模射线追踪中推导，并在纽约的额外射线追踪和洛杉矶的实际信道测量中进行验证。

Result: 相比传统的alpha-beta模型，CUNEC在考虑的城市传播场景中显著提高了精度。同时发布了包含30,000多个AP位置和128个UE位置的开源数据集。

Conclusion: CUNEC模型为城市非平稳环境下的无蜂窝大规模MIMO系统提供了更准确的路径损耗建模方法，有助于系统评估和优化，开源数据集将支持可重复研究和未来系统开发。

Abstract: Accurate path loss (PL) modeling is essential for evaluating and optimizing cell-free massive MIMO systems, especially in dense urban environments where traditional models fail to capture the complexity of real-world propagation. This paper introduces CUNEC (Cell-free massive MIMO for Urban Non-stationary Environments with Correlations, a novel PL model that accounts for spatial non-stationarity, inter-access point (AP)/user equipment (UE) correlations, and urban-specific propagation phenomena such as corner diffraction and street canyon waveguiding.bCUNEC segments AP-UE paths by street order, models PL as a stochastic function of urban geometry, and integrates spatially correlated shadowing. The parameters are derived from large-scale ray tracing and validated against both additional ray tracing in New York, NY and real-world channel measurements in Los Angeles, CA. Compared to the conventional alpha-beta model, CUNEC significantly improves accuracy in the considered urban propagation scenarios. An open-source dataset comprising over 30,000 AP locations and 128 UE positions is also released to support reproducible research and future system development.

</details>


### [31] [Bistatic Passive Tracking via CSI Power](https://arxiv.org/abs/2511.22144)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Kuangda Chen,Min Xu,Y. Jay Guo*

Main category: eess.SP

TL;DR: PowerSense：基于CSI功率的实时被动跟踪框架，无需相位信息，在ISAC应用中实现0.4米中值跟踪误差，并能提取微多普勒特征


<details>
  <summary>Details</summary>
Motivation: ISAC应用中，由于有限带宽、稀疏天线阵列和双基地收发器部署中的时钟异步性，精确目标跟踪面临挑战。CSI相位虽然携带细粒度信息，但其时变失真需要复杂处理，在跟踪过程中会引入额外干扰。

Method: 提出PowerSense框架，仅依赖CSI功率进行感知：1）通过自共轭操作消除所有CSI相位偏移，得到相位无关的CSI功率；2）应用级联FFT提取延迟、到达角和多普勒特征；3）进行目标检测、异常值去除；4）通过扩展卡尔曼滤波器进行连续轨迹估计；5）利用估计的目标位置提取精细的微多普勒特征。

Result: 使用3.1 GHz LTE和5 GHz WiFi双基地信号（20 MHz带宽）的室内实验表明，无需任何预部署系统校准，实现了0.4米的中值跟踪误差，同时能提取清晰明确的被跟踪目标的微多普勒特征。

Conclusion: PowerSense证明了仅使用CSI功率即可实现精确的实时被动跟踪，避免了相位处理的复杂性，在ISAC应用中具有实际部署价值，能够同时实现轨迹跟踪和微多普勒特征提取。

Abstract: Accurate object tracking in Integrated Sensing and Communication (ISAC) applications remains challenging due to limited signal bandwidth, sparse antenna arrays, and clock asynchronism inherent in bistatic transceiver deployments. This paper proposes PowerSense, a real-time passive tracking framework that operates directly on the power of Channel State Information (CSI). Although CSI phase carries fine-grained information, its time-varying distortions require complex processing, which introduces additional interference during tracking. Instead, this work solely relies on CSI power for accurate sensing. We first remove all CSI phase offsets through a self-conjugate operation, yielding phase-independent CSI power. A cascaded Fast Fourier Transform (FFT) is then applied to extract delay, angle-of-arrival (AoA), and Doppler features, followed by object detection, outlier removal, and continuous trajectory estimation via an Extended Kalman Filter (EKF). To enable fine-grained motion sensing, the estimated target positions are further used to extract refined micro-Doppler signatures. Using 3.1 GHz LTE and 5 GHz WiFi bistatic signals with a 20 MHz bandwidth, our indoor experiments achieve a median tracking error of 0.4 m, without performing any pre-deployment system calibration, while simultaneously extracting clear and unambiguous micro-Doppler signatures of the tracked target.

</details>


### [32] [A Model and Data Dual-driven Approach for Multitargets Detection under Mainlobe Jamming](https://arxiv.org/abs/2511.22201)
*Ruohai Guo,Jiang Zhu,Chengjie Yu,Zhigang Wang,Ning Zhang,Fengzhong Qu,Min Gong*

Main category: eess.SP

TL;DR: 提出基于扩散模型和数据双驱动的DMDD方法，用于多目标估计检测和结构化干扰抑制，在雷达系统中应对主瓣干扰挑战


<details>
  <summary>Details</summary>
Motivation: 现代雷达系统在面对主瓣干扰时，目标检测和参数估计面临重大挑战，需要有效的方法来抑制结构化干扰并准确检测多目标

Method: 采用扩散模型和数据双驱动方法：1) 通过基于分数的扩散过程建模干扰先验，从纯干扰数据学习分数；2) 使用稀疏贝叶斯学习框架建模目标信号的稀疏性，通过EM算法更新超参数；3) 构建单一扩散过程处理干扰，通过直接后验推理估计目标状态

Result: 数值实验证明该方法在结构化干扰场景中的有效性，DMDD算法相比现有方法实现了更优的目标检测性能

Conclusion: 提出的DMDD方法能够有效估计和检测多目标并抑制结构化干扰，无需详细的干扰知识，计算效率高，在雷达主瓣干扰场景中具有优越性能

Abstract: In modern radar systems, target detection and parameter estimation face significant challenges when confronted with mainlobe jamming. This paper presents a Diffusion-based Model and Data Dual-driven (DMDD) approach to estimate and detect multitargets and suppress structured jamming. In DMDD, the jamming prior is modeled through a score-based diffusion process with its score learned from the pure jamming data, enabling posterior sampling without requiring detailed knowledge of jamming. Meanwhile, the target signal is usually sparse in the range space, which can be modeled via a sparse Bayesian learning (SBL) framework, and hyperparameter is updated through the expectation-maximization (EM) algorithm. A single diffusion process is constructed for the jamming, while the state of targets are estimated through direct posterior inference, enhancing computational efficiency. The noise variance is also estimated through EM algorithm. Numerical experiments demonstrate the effectiveness of the proposed method in structured jamming scenarios. The proposed DMDD algorithm achieves superior target detection performance, compared with existing methods.

</details>


### [33] [Foundation Model for Intelligent Wireless Communications](https://arxiv.org/abs/2511.22222)
*Boxun Liu,Xuanyu Liu,Shijian Gao,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: WiFo-2是一个革命性的无线基础模型，采用稀疏专家混合架构，在116亿CSI点的大规模数据集上预训练，在未见配置上实现超越任务特定基线的零样本性能，并在八个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 下一代智能无线系统的发展受到窄域、数据饥渴的AI模型范式限制，需要突破这种约束来提升频谱效率和可靠性。

Method: 采用稀疏专家混合架构，在116亿信道状态信息点的大规模多样化数据集上进行预训练，有效管理异构数据和任务，实现高效推理。

Result: WiFo-2在未见配置上实现零样本性能超越任务特定基线的全样本性能，提供可靠置信度估计，在八个关键下游任务中通过最小微调获得优异表现，硬件原型验证了实际部署可行性。

Conclusion: WiFo-2为AI驱动的无线系统带来了范式转变，通过大规模预训练获得深度可泛化的信道知识，展示了无线基础模型的优越性和实际应用潜力。

Abstract: The evolution toward intelligent next-generation wireless systems promises unprecedented spectral efficiency and reliability but is hindered by a paradigm of narrow and data-hungry AI models. Breaking from this constraint, this work introduces WiFo-2, a revolutionary wireless foundation model that establishes a new state of the art for extensive channel state information (CSI)-based tasks. Uniquely architected as a sparse mixture of experts, WiFo-2 effectively manages heterogeneous data and tasks while enabling highly efficient inference. It is pretrained on a massive and diverse dataset of 11.6 billion CSI points, which enables the acquisition of profound and generalizable channel knowledge. WiFo-2 demonstrates remarkable zero-shot capabilities, not only matching but surpassing the full-shot performance of task-specific baselines on unseen configurations, all while providing reliable confidence estimates. Furthermore, the model achieves exceptional performance on eight key downstream tasks with minimal fine-tuning. A functional hardware prototype demonstrates its real-world deployment feasibility and significant system gains, highlighting WiFo-2's superiority and paving the way for a paradigm shift in AI-based wireless systems.

</details>


### [34] [Pinching-Antenna Systems-Assisted SWIPT: A Rate-Energy Trade-off Perspective](https://arxiv.org/abs/2511.22224)
*Qi Yang,Kai Liu,Jingjing Zhao,Kaiquan Cai,Xidong Mu,Yuanwei Liu*

Main category: eess.SP

TL;DR: 研究PASS辅助SWIPT系统的速率-能量权衡，考虑单用户和多用户场景，提出优化算法和多种多址方案，仿真显示PASS优于传统固定天线系统，TDMA在多用户场景表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究pinching-antenna系统在同时无线信息与能量传输中的性能，探索如何通过天线位置调整优化速率-能量权衡，解决传统固定天线系统的局限性。

Method: 1) 单用户场景：提出两阶段算法，先用SCA方法最小化大尺度路径损耗，再用相位对齐微调；2) 多用户场景：考虑FDMA、TDMA、NOMA三种多址方案，采用ε-约束法将多目标优化转为单目标优化，结合PSO和凸优化方法求解。

Result: 仿真结果表明：i) PASS相比传统固定位置天线系统能实现显著更优的速率-能量区域；ii) 在多用户场景中，利用时隙切换特性的TDMA方案优于NOMA和FDMA。

Conclusion: PASS系统在SWIPT中具有显著优势，通过优化pinching波束成形能有效提升速率-能量权衡性能，TDMA在多用户公平性场景中是最佳选择。

Abstract: This paper investigates the rate-energy trade-off for pinching-antenna systems (PASS)-assisted simultaneous wireless information and power transfer (SWIPT) systems. Both the single information user (IU)/energy user (EU) and multiple IUs/EUs scenarios are considered.1) For the single IU/EU scenario, a pinching beamforming optimization problem is formulated for simultaneously maximizing data rate and harvested energy. To tackle this problem, a two-stage algorithm is proposed. Specifically, the successive convex approximation (SCA) method is first invoked for minimizing the large-scale path loss, which is followed by the fine-tuning method for the phase alignment. 2) For the multiple IUs/EUs scenario, three multiple access schemes are considered, i.e., frequency division multiple access (FDMA), time division multiple access (TDMA), and non-orthogonal multiple access (NOMA). The corresponding multi-objective optimization problem (MOOP) that simultaneously maximizes the minimum data rate and minimum harvested energy is formulated for ensuring users' fairness. To address this problem, we adopt the $ε$-constraint method to first convert the intractable MOOPs to single-objective optimization problems (SOOPs). Then, for the SOOP under each multiple access protocol, the particle swarm optimization (PSO) and convex optimization methods are adopted for solving the pinching beamforming and resource allocation problems, respectively. Simulation results unveil that: i) PASS can achieve a significantly superior rate-energy region compared to conventional fixed-position antenna systems for pinching beamforming; and ii) by exploiting the time-switching feature, TDMA can outperform both NOMA and FDMA for the multiple IUs/EUs scenario.

</details>


### [35] [NOMA Assisted Downlink Power Allocation in Pinching Antenna Systems Using Convolutional Neural Network](https://arxiv.org/abs/2511.22328)
*Saeed Mohammadzadeh,Kanapathippillai Cumanan,Zhiguo Ding*

Main category: eess.SP

TL;DR: 提出基于卷积神经网络的夹持天线辅助NOMA系统优化方法，通过天线布局和功率分配提升系统性能和公平性


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统通过激活介质波导上的小颗粒实现灵活天线架构，但需要解决天线布局和功率分配的联合优化问题，传统方法计算复杂度高

Method: 采用两阶段优化策略：用户感知初始化+梯度优化确定天线位置；最大最小公平功率分配通过准线性规划和二分搜索求解；CNN学习信道条件与最优功率系数的非线性映射

Result: CNN方法在PA辅助NOMA系统中提高了和速率和用户公平性，同时显著降低了计算复杂度，且能泛化到未见网络配置

Conclusion: 提出的CNN框架为PA系统提供了高效、可扩展的NOMA优化方案，平衡了性能、公平性和计算效率

Abstract: In this paper, we consider a flexible-antenna architecture, referred to as a pinching-antenna (PA) system, in which multiple PAs realized by activating small dielectric particles along a dielectric waveguide are jointly employed to serve a single-antenna user. We investigate antenna placement and power allocation optimization in PA-assisted non-orthogonal multiple access (NOMA) systems using a convolutional neural network (CNN). An optimization strategy is developed to determine the PA locations that maximize achievable NOMA performance while satisfying physical and spatial constraints. The proposed method adopts a two-stage structure, combining a user-aware initialization with a gradient-based refinement, enabling near-optimal performance with significantly lower computational cost. A max-min fairness formulation is introduced for power allocation to balance the power budget among users with varying channel strengths, solved efficiently via quasi-linear programming and bisection search. Finally, a CNN-based learning framework is employed to capture the nonlinear mapping between channel conditions and the corresponding optimal power coefficients. This framework can infer near-optimal power allocations for unseen network configurations without retraining, offering scalability and adaptability. Simulation results show that the proposed CNN-based NOMA approach for PA systems improves sum rate and user fairness while reducing computational complexity.

</details>


### [36] [A Bio-Inspired Whisker Sensor toward Underwater Flow Sensing in Darkness and Turbidity](https://arxiv.org/abs/2511.22353)
*Zheyi Hang,Denghan Xiong,Pengo Xie,Huan Hu*

Main category: eess.SP

TL;DR: 该论文提出了一种仿生胡须传感器，用于水下流场感知，解决了现有传感器响应慢、检测阈值高、方向辨别能力有限等问题，通过将高灵敏硅应变计嵌入柔性PDMS基底，实现了高灵敏度、稳定性和简化封装。


<details>
  <summary>Details</summary>
Motivation: 水下流场感知对于无人水下航行器和环境监测至关重要，但现有传感器存在响应性低、检测阈值高、方向辨别能力有限、封装复杂、长期稳定性差等问题，特别是在浑浊和杂乱水域的导航和目标感知中表现不佳。

Method: 采用仿生学方法，模仿海豹胡须结构，将高灵敏硅应变计嵌入柔性PDMS基底中，设计了一种新型胡须传感器，实现了高灵敏度与简化封装的平衡。

Result: 传感器表现出线性力-电阻响应，检测极限为0.27 mN，经过10,000次加载循环后仍保持稳定，偏移漂移小于2%。在水下偶极子测试中显示出频率匹配和清晰的纵向与横向空间响应模式。

Conclusion: 该仿生胡须传感器为UUV平台上的水下流场感知提供了一条稳健且可扩展的技术路径，适用于实际部署环境。

Abstract: Underwater flow sensing is critical for unmanned underwater vehicles (UUVs) and environmental monitoring, yet existing sensors often suffer from low responsiveness, high detection thresholds, limited directional discrimination, complex packaging, and poor long-term stability, especially for navigation and target perception in turbid and cluttered waters. Previous solutions based on traditional strain gauges with limited detection accuracy or doped silicon sensors with limited detection height have shown feasibility but still face challenges in scalability, robustness under harsh aquatic conditions, and calibration complexity. This work presents a bio-inspired whisker sensor that provides a balanced solution by embedding high-gauge-factor silicon strain gauges into a flexible PDMS base, mimicking seal whiskers to offer both high sensitivity and simplified packaging. The device exhibits a linear force-resistance response with a limit of detection of 0.27 mN, maintains stability after 10,000 loading cycles, and shows minimal offset drift of less than 2 percent. It also demonstrates frequency matching in underwater dipole tests with clear longitudinal and transverse spatial response patterns. These results indicate a robust and scalable route for underwater flow sensing on UUV platforms in practical deployments.

</details>


### [37] [Adaptive Dual-Windowing Strategies for Multi-Target Detection in OFDM ISAC](https://arxiv.org/abs/2511.22458)
*Ali Al Khansa,Youssef Bahannis*

Main category: eess.SP

TL;DR: 提出一种基于双窗周期图的OFDM ISAC系统多目标检测算法，通过分辨率优化窗和旁瓣抑制窗的互补使用，结合BSTC和CSTC算法的自适应切换，在保持高性能的同时降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 在OFDM ISAC系统中，多目标检测需要在旁瓣抑制和分辨率之间取得平衡。现有方法通常使用单一固定窗口和预定义检测策略（如低复杂度的BSTC或高性能的CSTC），缺乏自适应调整能力，无法动态平衡检测性能和计算复杂度。

Method: 提出双窗周期图算法：使用两个互补窗口（一个优化分辨率，一个优化旁瓣抑制）。先对两个窗口应用低复杂度BSTC检测算法，通过决策机制比较输出结果。当结果一致时直接使用分辨率优化估计；否则触发高性能CSTC算法解决模糊性。这种自适应方法动态平衡检测性能和复杂度。

Result: 数值结果表明，所提方法在保持高性能的同时显著降低了计算复杂度，特别是在高信噪比条件下效果更明显。算法能够有效解决多目标检测中的旁瓣抑制与分辨率平衡问题。

Conclusion: 该双窗自适应算法成功解决了OFDM ISAC系统中多目标检测的性能与复杂度平衡问题，相比现有固定策略具有更好的适应性和效率，为ISAC系统设计提供了新的解决方案。

Abstract: In Orthogonal Frequency Division Multiplexing (OFDM) Integrated Sensing and Communication (ISAC) systems, a key challenge is balancing sidelobe attenuation and resolution for multi-target detection scenarios. While windowing functions are typically used to manage this trade-off, state-of-the-art methods rely on a single, fixed window followed by a predefined detection strategy (e.g., Binary Successive Target Cancellation (BSTC) (low complexity) or Coherent Successive Target Cancellation (CSTC) (high performance)). This paper proposes a novel dual-window periodogram-based algorithm that leverages two complementary windows: one optimized for resolution and the other for sidelobe suppression. Then, a low-complexity detection algorithm (e.g., BSTC) is applied to both, and a decision mechanism compares the outputs. When results align, the resolution-optimized estimates are directly used; otherwise, high performance algorithm (e.g., CSTC) is triggered to resolve ambiguities. This adaptive approach dynamically balances the detection performance and the complexity, addressing limitations in existing fixed strategies. The Numerical results confirm that the proposed method achieves high performance while reducing the complexity, especially at a high Signal to Noise Ratio (SNR).

</details>


### [38] [Learning to Count Targets from Dual-Window: A CNN Approach for OFDM ISAC](https://arxiv.org/abs/2511.22473)
*Ali Al Khansa*

Main category: eess.SP

TL;DR: 提出一种基于CNN的ISAC-OFDM目标数量估计新方法，通过融合两种互补窗函数处理的距离-多普勒周期图，分别针对分辨率和旁瓣抑制进行优化，提升密集场景下的估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的ISAC-OFDM目标数量估计方法在场景变密集时精度下降，主要受限于经典的分辨率-旁瓣衰减权衡。传统窗函数选择通常是静态的，无法适应不同场景需求。

Method: 提出新的CNN方法，使用两种窗函数处理的距离-多普勒周期图：一种窗针对分辨率优化，另一种针对旁瓣抑制优化。模型学习融合这两种互补视图，自动判断每种视图在何时最有效。

Result: 数值实验表明，相比单窗CNN基线方法，该方法在不同噪声水平和目标密度下都表现出更好的性能，具有更好的扩展性和鲁棒性。

Conclusion: 通过让CNN学习融合互补窗函数处理的距离-多普勒周期图，可以有效解决ISAC-OFDM中的分辨率-旁瓣权衡问题，提升目标数量估计的准确性和鲁棒性。

Abstract: Integrated Sensing and Communication (ISAC) with Orthogonal Frequency Division Multiplexing (OFDM) waveforms is a key enabler for next-generation wireless systems. Recent studies show that Convolutional Neural Networks (CNNs) can estimate the number of targets from two-dimensional (2D) range-Doppler periodogram maps, yet accuracy often degrades as scenes become denser. One significant factor is the classical resolution-sidelobe attenuation trade-off, which limits performance when targets are weak or closely spaced. While windowing is routinely applied to shape this trade-off, the choice is typically static. This paper proposes a new CNN method that uses two windowed range-Doppler periodograms and learns to fuse complementary views: one window optimized for resolution and one window optimized for sidelobe suppression. The design explicitly targets the resolution-sidelobe attenuation trade-off by exposing the model to complementary windowed maps and letting it learn when each is most informative. Numerical experiments show consistent gains over single-window CNN baselines, with better scaling in target density and greater robustness across different noise levels.

</details>


### [39] [Enabling Full-Duplex LEO Satellite Systems with Non-Reciprocal BD-RIS-Assisted Beamforming](https://arxiv.org/abs/2511.22525)
*Ziang Liu,Wonjae Shin,Bruno Clerckx*

Main category: eess.SP

TL;DR: 提出一种采用非互易性对角可重构智能表面(NR-BD-RIS)的全双工LEO卫星系统，通过非互易阻抗网络打破信道互易性，实现多波束同时服务，显著提升上下行链路和速率。


<details>
  <summary>Details</summary>
Motivation: LEO卫星通信面临高速移动带来的波束快速对准挑战，传统大型天线阵列受限于功耗、尺寸和重量约束。未来非地面网络需要高频谱效率，全双工系统成为必要选择。

Method: 提出NR-BD-RIS全双工LEO卫星系统，在RIS阻抗网络中引入非互易元件打破信道互易性。采用时分调度框架，每个时隙同时服务多个上下行地面设备，通过优化问题最大化加权和速率。

Result: 数值结果表明，NR-BD-RIS在单用户和多用户场景下的上下行和速率性能均显著优于传统BD-RIS和对角RIS。此外，NR-BD-RIS需要更少的重新配置频率，更具实际应用可行性。

Conclusion: NR-BD-RIS全双工LEO卫星系统能够有效解决高速移动卫星的波束对准问题，在功率、尺寸和重量约束下实现高频谱效率通信，为未来非地面网络提供实用解决方案。

Abstract: Low Earth orbit (LEO) satellite is a promising technology for providing low-latency, high-data-rate, and wide-coverage communication services. However, the high mobility of LEO satellites necessitates fast and accurate beam steering to continuously serve ground devices. While large antenna arrays can address these challenges, strict constraints on power, size, and weight make such solutions difficult to implement. Furthermore, future non-terrestrial networks (NTNs) require high spectral efficiency, which motivates the adoption of in-band full-duplex (FD) systems. {To overcome these challenges, we propose an FD LEO satellite system, where the non-reciprocal beyond-diagonal reconfigurable intelligent surfaces (NR-BD-RIS) and multiple transmit and receive antennas are attached to the LEO satellite. The NR-BD-RIS reflects the downlink (DL) and uplink (UL) signals by passive beamforming.} By incorporating non-reciprocal components into the impedance network of RIS, the NR-BD-RIS breaks channel reciprocity, facilitating simultaneous support for multiple beam directions. To cover a wide coverage, we propose a time-sharing scheduling framework where, in each time slot, the NR-BD-RIS simultaneously serves multiple DL and multiple UL ground devices. An optimization problem is defined to maximize the weighted sum-rate over the entire scheduling period. Numerical results demonstrate that the proposed NR-BD-RIS significantly performs better than both conventional BD-RIS and diagonal RIS (D-RIS) regarding DL and UL sum-rate performance under both single-user (SU) and multiple-user (MU) cases. Additionally, the NR-BD-RIS requires less frequent reconfiguration compared to other two types of RIS, making it more practical for implementation.

</details>


### [40] [Interference and Multipath Resilient ToA Estimation](https://arxiv.org/abs/2511.22629)
*António Barros,Christoph Studer*

Main category: eess.SP

TL;DR: 提出一种计算高效、抗多径和强干扰的到达时间估计算法，利用多天线结合自适应空间滤波和自动微分技术，无需模型阶数估计即可超分辨首径到达时间


<details>
  <summary>Details</summary>
Motivation: 传统到达时间估计算法在多径传播和强干扰环境下性能受限，需要解决计算复杂度高、模型阶数估计困难等问题

Method: 利用多接收天线，结合自适应空间滤波和自动微分技术，通过计算高效的算法超分辨首径到达时间，无需模型阶数估计

Result: 在射线追踪室内传播信道仿真中，相比传统相关基到达时间估计方法和子空间技术（如JADE），性能显著提升

Conclusion: 该算法在多径和强干扰环境下具有计算高效、性能优越的特点，为到达时间估计提供了新的解决方案

Abstract: We present a computationally-efficient algorithm for time-of-arrival (ToA) estimation that is robust under multipath propagation and strong interference. Our algorithm leverages multiple receive antennas to combine adaptive spatial filtering with autodifferentiation in order to super-resolve the tap of the first-arriving path at low computational complexity and without requiring model-order estimation. We use simulations with ray-traced indoor propagation channels to demonstrate significant performance improvements over conventional correlation-based ToA estimation methods and subspace techniques such as JADE.

</details>


### [41] [Advances in electromagnetic techniques for subsurface infrastructure detection: A comprehensive review of methods, challenges, and innovations](https://arxiv.org/abs/2511.22673)
*Arasti Afrasiabi,Farough Rahimzadeh,Alireza Keshavarzi*

Main category: eess.SP

TL;DR: 这篇综述论文探讨了埋地基础设施非侵入式检测方法的最新进展，重点分析电阻率层析成像、红外热成像和磁力测量技术，以及数据融合方法和数学估计器，旨在提高检测精度和克服各方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 埋地基础设施检测面临传统侵入式方法的局限性，需要开发更高效、准确的非侵入式检测技术。现有单一检测方法各有优缺点，难以全面解决深度估计、目标区分等挑战，因此需要整合多种技术并优化数据处理方法。

Method: 系统综述三种主要非侵入式检测技术：电阻率层析成像（ERT）用于地下成像，红外热成像（IRT）提供热特征信息，磁力测量用于铁磁目标检测。同时分析数据融合技术和数学估计器（如卡尔曼滤波器、粒子滤波器）在噪声抑制和精度提升中的应用。

Result: ERT和IRT在地下成像方面各有优势，磁力测量在铁磁目标检测中效果显著。数据融合技术能有效克服单一方法的局限性，显著提高检测准确性。数学估计器在减少噪声、增强测量精度方面发挥关键作用。

Conclusion: 未来研究应重点优化传感器性能、改进融合算法、探索实时数据处理的混合模型。多技术融合和先进数据处理方法是提高埋地基础设施检测精度的关键方向，具有重要的应用前景。

Abstract: This review paper explores the state-of-the-art in non-intrusive methods for detecting and characterising buried infrastructure, focusing on Electrical Resistivity Tomography (ERT), Infrared Thermography (IRT), and magnetometry, along with data fusion techniques and mathematical estimators. ERT and IRT offer distinct advantages in subsurface imaging, while magnetometry provides omnidirectional measurements ideal for detecting ferrous targets. Despite these benefits, each method has inherent limitations, such as challenges in depth estimation and difficulties in distinguishing between various subsurface objects. The integration of multiple sensing techniques through data fusion approaches has shown significant promise in overcoming these limitations and improving detection accuracy. Additionally, mathematical estimators, including Kalman filters and particle filters, play a crucial role in reducing noise and enhancing the precision of geophysical surveys. This review discusses the strengths, limitations, and future research needs of these techniques, offering a comprehensive understanding of their current and potential applications in buried infrastructure detection. The paper concludes by emphasising the importance of optimising sensor performance, refining fusion algorithms, and exploring hybrid models for real-time data processing in future research.

</details>


### [42] [Rethinking Signaling Design for ISAC: From Pilot-Based to Payload-Based Sensing](https://arxiv.org/abs/2511.22703)
*Yunxin Li,Ying Zhang,Christos Masouros,Sofie Pollin,Fan Liu*

Main category: eess.SP

TL;DR: 本文综述了集成感知与通信(ISAC)信号设计从导频辅助感知向数据载荷方法的范式转变，重点探讨如何在现有5G NR框架内实现这些技术。


<details>
  <summary>Details</summary>
Motivation: ISAC作为6G网络的关键使能技术，其信号设计是演进的核心。现有5G NR结构为ISAC提供了实现基础，但需要探索如何从有限的导频资源扩展到利用整个通信帧进行感知。

Method: 首先复用5G NR中的导频和参考信号进行感知，然后扩展到更先进的数据载荷集成方法，包括新颖的星座整形、调制基和脉冲整形滤波器。通过V2I网络案例研究验证实际可行性。

Result: 展示了从稀疏导频资源到完整通信帧的感知扩展带来的机遇和权衡，强调星座特性和调制选择直接影响感知性能。利用参考信号和载荷回波可以减少信令开销并实现主动波束管理和切换。

Conclusion: ISAC信号设计正在经历从导频辅助到数据载荷方法的范式转变，现有5G NR结构为实现这些技术提供了可行框架，特别是在V2I等实际应用场景中具有显著优势。

Abstract: Integrated Sensing and Communications (ISAC) is emerging as a key enabler for 6G networks, with signaling design at the core of its evolution. This paper reviews the paradigm shift of ISAC signaling designs from pilot-aided sensing to data payload-based approaches, with a particular focus on how these techniques can be realized within existing 5G NR structures. We commence with the reuse of pilots and reference signals that exploit existing 5G New Radio (NR) structures for sensing. Then, we extend to more advanced approaches that integrate the data payload through novel constellation shaping, modulation bases, and pulse shaping filters. We highlight the opportunities and tradeoffs that arise when extending sensing from sparse pilot and reference signal resources to the full communication frame, emphasizing how constellation properties and modulation choices directly determine sensing performance. To illustrate practical feasibility, a case study on sensing-assisted NR Vehicle-to-Infrastructure (V2I) networks demonstrates how exploiting both reference signals and payload echoes can reduce signaling overhead and enable proactive beam management and handover.

</details>


### [43] [FPGA-Enabled Modulo ADC with x100 Dynamic-Range Expansion: Hardware Design and Performance Evaluation](https://arxiv.org/abs/2511.22752)
*Zeyuan Li,Wenyi Yan,Lu Gan,Guoquan Li,Hongqing Liu*

Main category: eess.SP

TL;DR: 本文提出了一种基于FPGA的模数转换器平台，通过折叠输入信号来避免传统ADC的削波问题，实现了超过100倍的动态范围扩展，并在400kHz带宽内保持与传统ADC相当的保真度。


<details>
  <summary>Details</summary>
Motivation: 传统模数转换器（ADC）在捕获高动态范围（HDR）信号时容易因削波而失效，需要一种能够有效处理HDR信号的解决方案。

Method: 采用模数ADC架构，在量化前折叠输入信号，然后通过算法重建原始波形。系统集成了精密模拟前端和200MHz FPGA控制环路，包含多比特更新和数字欠补偿校准，确保稳定的折叠和准确的反馈生成。

Result: 系统在400kHz带宽内实现了超过100倍的动态范围扩展，同时保持了与传统ADC相当的保真度。SoC式实现支持板上实时恢复和最先进重建算法的基准测试。

Conclusion: 该FPGA基模数ADC平台为HDR信号采集和评估提供了一个紧凑实用的框架，通过创新的折叠和重建方法有效解决了传统ADC的动态范围限制问题。

Abstract: Conventional analog-to-digital converters (ADCs) fail to capture high-dynamic-range (HDR) signals due to clipping. Modulo ADCs circumvent this limitation by folding the input prior to quantization and algorithmically reconstructing the original waveform. This work presents a field-programmable gate array (FPGA)-based modulo ADC platform for systematic HDR performance evaluation. The mixed-signal architecture integrates a precision analog front end with a 200-MHz FPGA control loop that incorporates multi-bit updates and digital under-compensation calibration, ensuring stable folding and accurate feedback generation. The system achieves more than a hundred-fold dynamic-range expansion within a 400-kHz bandwidth while maintaining fidelity comparable to that of a conventional ADC. A system-on-chip (SoC)-like implementation enables on-board real-time recovery and supports benchmarking of state-of-the-art reconstruction algorithms, providing a compact and practical framework for HDR signal acquisition and evaluation.

</details>


### [44] [Moduli Selection in Robust Chinese Remainder Theorem: Closed-Form Solutions and Layered Design](https://arxiv.org/abs/2511.22757)
*Wenyi Yan,Lu Gan,Hongqing Liu,Shaoqing Hu*

Main category: eess.SP

TL;DR: 该论文研究了鲁棒中国剩余定理(RCRT)中的模数选择问题，针对带误差的余数恢复，提出了小L(2,3,4)情况下的精确解和斐波那契启发的分层构造，建立了RCRT模数设计的一般理论。


<details>
  <summary>Details</summary>
Motivation: 研究鲁棒中国剩余定理中的模数选择问题，解决在余数存在有界误差的情况下如何选择模数以实现最大鲁棒性，这对于各种信号处理和信息处理应用至关重要。

Method: 1) 针对小L(2,3,4)情况，在动态范围和模数约束下获得最大化鲁棒性边界的精确解；2) 提出斐波那契启发的分层构造(针对L=2)，产生K个鲁棒解码层；3) 分析鲁棒性和范围在层间的演化，并提供闭式表达式估计常见数据和噪声模型下的成功概率。

Result: 获得了小L情况下的精确解，提出了分层构造方法，能够实现误差容忍度和动态范围之间的可预测权衡，并提供了成功概率的闭式估计表达式。

Conclusion: 该框架建立了RCRT模数设计的一般理论，补充了先前的算法工作，强调了鲁棒模数设计在多种信息处理领域的广泛相关性，包括亚奈奎斯特采样、相位解缠、范围估计、模数ADC和基于RNS的深度学习加速器等应用。

Abstract: We study the fundamental problem of \emph{moduli selection} in the Robust Chinese Remainder Theorem (RCRT), where each residue may be perturbed by a bounded error. Consider $L$ moduli of the form $m_i = Γ_i m$ ($1 \le i \le L$), where $Γ_i$ are pairwise coprime integers and $m \in \mathbb{R}^+$ is a common scaling factor. For small $L$ ($L = 2, 3, 4$), we obtain exact solutions that maximize the robustness margin under dynamic-range and modulus-bound constraints. We also introduce a Fibonacci-inspired \emph{layered} construction (for $L = 2$) that produces exactly $K$ robust decoding layers, enabling predictable trade-offs between error tolerance and dynamic range. We further analyze how robustness and range evolve across layers and provide a closed-form expression to estimate the success probability under common data and noise models. The results are promising for various applications, such as sub-Nyquist sampling, phase unwrapping, range estimation, modulo analog-to-digital converters (ADCs), and robust residue-number-system (RNS)-based accelerators for deep learning. Our framework thus establishes a general theory of moduli design for RCRT, complementing prior algorithmic work and underscoring the broad relevance of robust moduli design across diverse information-processing domains.

</details>


### [45] [Embodied Intelligent Wireless (EIW): Synesthesia of Machines Empowered Wireless Communications](https://arxiv.org/abs/2511.22845)
*Xiang Cheng,Weibo Wen,Haotian Zhang,Boxun Liu,Zonghui Yang,Jianan Zhang,Xuesong Cai*

Main category: eess.SP

TL;DR: 论文提出了一种名为"具身智能无线通信"的新范式，将通信节点重新定义为能够主动感知环境、适应变化并与环境共同进化的智能实体，以应对6G及未来通信系统的需求。


<details>
  <summary>Details</summary>
Motivation: 当前基于AI的无线通信设计主要采用静态、模块化的AI替代方案，无法满足未来无线网络对动态环境持续感知、适应和交互的核心需求。需要一种新的通信范式来弥合这一差距。

Method: 提出具身智能无线通信范式，基于观察-决策-行动框架：包括多维观察实现环境全面感知、统一决策模块协调多个无线代理、以及无线代理对环境产生实际影响的行动。还引入了无线世界模型以及自我更新和进化机制作为支撑技术。

Result: 通过仿真展示了所提出的EIW范式及其支撑技术在塑造无线通信节点设计方面的优势，验证了该范式能够使通信系统从被动数据管道转变为智能实体。

Conclusion: EIW范式代表了无线通信设计的根本性转变，将通信节点重新定义为能够与环境持续交互并共同进化的主动智能实体，为6G及未来通信系统的发展提供了新方向。

Abstract: The evolution toward the sixth-generation (6G) and beyond mobile communication systems is marked by a fundamental shift from merely connecting devices to enabling pervasive and embodied intelligence. While recent advances in artificial intelligence (AI)-native wireless communication designs have achieved remarkable progress, the prevailing paradigm remains limited to static, modular AI substitutions. This approach fails to meet the core requirements of future wireless networks: the ability to continuously perceive, adapt to, and interact with the dynamic wireless environment. To bridge this gap, this paper introduces Embodied Intelligent Wireless (EIW), a novel communication paradigm inspired by embodied intelligence, which redefines the communication node as an active, environment-aware, and evolving entity. EIW is built around an observation-decision-action paradigm, comprising: multi-dimensional observations for comprehensive awareness of the environment and system states, a unified decision module for orchestrating multiple wireless agents in an interpretable manner, and actions where wireless agents exert practical effects on both the environment and communication systems. Furthermore, two enabling technologies, wireless world models as well as self-update and self-evolution mechanisms, are introduced to support training efficiency improvement, counterfactual evaluation, and better adaptation. Unlike existing communication systems, EIW envisions future communication systems not as passive data pipelines, but as intelligent entities that continuously interact with and co-evolve alongside their environments. Finally, through simulations, we showcase the advantages of the proposed EIW paradigm and its enabling techniques in shaping the design of wireless communication nodes.

</details>


### [46] [RIS-Assisted Physical Layer Security: Artificial Noise-Driven Optimization and Measurements](https://arxiv.org/abs/2511.22910)
*Ahmet Muaz Aktas,Sefa Kayraklik,Sultangali Arzykulov,Galymzhan Nauryzbayev,Ibrahim Hokelek,Ali Gorcin*

Main category: eess.SP

TL;DR: 本文研究了一种基于人工噪声的RIS辅助安全通信系统，通过分割RIS表面分别引导通信信号给合法用户和人工噪声给窃听者，优化相位偏移和功率分配以最大化保密容量。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)在下一代无线通信网络中具有重要作用，但如何利用RIS增强物理层安全(PLS)仍面临挑战。本文旨在通过人工噪声(AN)驱动的方法，利用RIS同时引导通信信号和人工噪声，以提升系统安全性能。

Method: 1. 将RIS分割为两个部分：一部分配置为将通信信号导向合法用户(Bob)，另一部分配置为将人工噪声导向窃听者(Eve)。2. 开发迭代和基于离散傅里叶变换的算法进行RIS相位偏移优化。3. 优化通信信号和人工噪声之间的功率分配，在限制Eve信道容量的同时最大化保密容量。

Result: 通过仿真和基于软件定义无线电的测试台实验验证，结果表明所提出的PLS框架在保密容量方面有显著提升，证明了AN驱动的RIS辅助PLS在实际部署中的潜力。

Conclusion: 本文提出的AN驱动RIS辅助安全通信系统能够有效提升物理层安全性能，通过智能的RIS分割和优化算法，为下一代无线通信网络的安全部署提供了有前景的解决方案。

Abstract: Reconfigurable intelligent surface (RIS) has emerged as a key enabler for providing signal coverage, energy efficiency, reliable communication, and physical layer security (PLS) in next-generation wireless communication networks. This paper investigates an artificial noise (AN)-driven RIS-assisted secure communication system. The RIS is partitioned into two segments, where the first segment is configured to direct the communication signal (CS) toward the legitimate user (Bob), and the other one is configured to steer the AN toward the eavesdropper (Eve). To this end, iterative and discrete Fourier transform-based algorithms are developed for practical RIS phase shift optimization. The power allocation between the CS and the AN signals is optimized in such a way that the secrecy capacity (SC) is maximized while limiting Eve's channel capacity. The proposed PLS framework is evaluated through both simulations and software defined radio based testbed experiments. The results demonstrate promising improvements in the SC, highlighting the potential of AN-driven RIS-assisted PLS for practical deployments.

</details>


### [47] [EMF-Compliant Power Control in Cell-Free Massive MIMO: Model-Based and Data-Driven Approaches](https://arxiv.org/abs/2511.23357)
*Sergi Liesegang,Stefano Buzzi*

Main category: eess.SP

TL;DR: 该论文研究了在电磁场暴露限制下，用户中心化无蜂窝大规模MIMO系统中的功率控制问题，提出了基于模型和数据驱动的解决方案，以最大化用户最小数据率。


<details>
  <summary>Details</summary>
Motivation: 随着无线数据网络的快速增长，电磁污染问题和电磁场暴露限制的遵守变得越来越重要。论文旨在解决在满足EMF约束条件下，用户中心化无蜂窝大规模MIMO系统中的功率控制问题。

Method: 提出了两种方法：1）基于模型的方法：在下行链路中使用逐次凸优化和对数-求和-指数逼近，在上行链路中使用常规技术；2）数据驱动方法：探索了端到端架构和深度展开技术。

Result: 数值结果表明，基于模型的解决方案能有效满足EMF约束并确保良好性能；数据驱动方法能紧密逼近基于模型方法的性能，但计算复杂度显著降低。

Conclusion: 该论文成功解决了EMF约束下的功率控制问题，提出的基于模型和数据驱动的解决方案在满足EMF限制的同时优化了系统性能，数据驱动方法在保持性能的同时大幅降低了计算复杂度。

Abstract: The impressive growth of wireless data networks has recently led to increased attention to the issue of electromagnetic pollution and the fulfillment of electromagnetic field (EMF) exposure limits. This paper tackles the problem of power control in user-centric cell-free massive multiple-input-multiple-output (CF-mMIMO) systems under EMF constraints. Specifically, the power allocation maximizing the minimum data rate across users is derived for both the uplink and the downlink. To solve such optimization problems, two approaches are proposed, i.e., model-based and data-driven. The proposed model-based solutions for the downlink utilize successive convex optimization and the log-sum-exp approximation for the minimum of a discrete set, whereas ordinary techniques are employed for the uplink. With regard to data-driven solutions, solutions based on both end-to-end architectures and deep unfolding techniques are explored. Extensive numerical results confirm that the proposed model-based solutions effectively fulfill the EMF constraints while ensuring very good performance; moreover, the results show that the proposed data-driven approaches can tightly approximate the performance of model-based solutions but with much lower computational complexity.

</details>


### [48] [RAG-Empowered LLM-Driven Dynamic Radio Resource Management in Open 6G RAN](https://arxiv.org/abs/2511.22933)
*Onur Salan,Burak Çırağ,Onur Sever,İbrahim Hökelek,Ali Görçin,Hakan Ali Çırpan*

Main category: eess.SP

TL;DR: 提出基于检索增强生成（RAG）的大型语言模型（ReLLM）驱动的动态无线资源管理框架，用于O-RAN启发的6G网络，通过双智能体设计优化资源分配和服务质量。


<details>
  <summary>Details</summary>
Motivation: 人工智能在无线通信领域的进展对资源管理具有重要意义，特别是在6G网络和O-RAN架构中，需要更智能、自适应的资源管理方法来满足不同网络切片的服务质量要求。

Method: 采用RAG增强的大型语言模型（ReLLM）框架，包含两个专门智能体：一个负责主动检测SLA违规，通过持续监控和估计切片性能指标；另一个负责在SLA违规概率超过阈值时动态重新分配物理资源块。该框架在基于开源OpenAirInterface仿真器的端到端O-RAN测试平台上实现和验证。

Result: 实验结果表明，ReLLM方法通过减少令牌消耗，在保持低优先级切片接近零丢包率的同时，满足高优先级切片的可接受延迟性能。该设计提高了可靠性和SLA合规性，证实了其在真实O-RAN测试平台中的实用性。

Conclusion: ReLLM驱动的动态无线资源管理框架在O-RAN测试平台上表现出色，减少了不必要的LLM推理调用，提高了计算和能源效率，具有在现实世界O-RAN测试平台和未来6G网络中应用的潜力。

Abstract: Implications of the advancements in the area of artificial intelligence to the wireless communications is extremely significant, especially in terms of resource management. In this paper, a Retrieval-Augmented Generation (RAG)-empowered Large Language Model (ReLLM)-driven dynamic radio resource management framework for Open Radio Access Network (O-RAN) inspired 6G networks is proposed. The introduced methodology leverages the ReLLM framework to interpret both historical and real-time network data, enabling adaptive control of network slices. The ReLLM is founded on two specialized agents, one is responsible for proactively detecting service level agreement (SLA) violations by continuously monitoring and estimating slice-specific performance metrics, and the other one is responsible for dynamically reallocating physical resource blocks when the SLA violation probability exceeds a pre-defined threshold. The primary objective of this dual-agent design is to minimize unnecessary LLM inference calls while satisfying the SLA requirements of the slices, thereby improving computational and energy efficiency. The proposed ReLLM framework is implemented and validated on an end-to-end O-RAN testbed built upon open-source OpenAirInterface emulators. The experimental results demonstrate that the LLM approach with its reduced token consumption feature maintains a near-zero drop ratio for the low-priority slice while simultaneously satisfying acceptable latency performance for the high-priority slice. The ReLLM-driven design improves reliability and SLA compliance, confirming its practicality for real-world O-RAN testbeds and its potential applicability to future 6G networks.

</details>


### [49] [DoA Estimation with Sparse Arrays: Effects of Antenna Element Patterns and Nonidealities](https://arxiv.org/abs/2511.23028)
*Niko Lindvall,Mikko Heino,Robin Rajamäki,Mikko Valkama,Visa Koivunen*

Main category: eess.SP

TL;DR: 研究定向天线单元复杂增益模式和非理想性对波达方向估计的影响，发现稀疏阵列结合定向天线相比均匀全向阵列能显著提升性能，在特定场景下可将平均测向误差降低90%以上。


<details>
  <summary>Details</summary>
Motivation: 研究定向天线单元的复杂增益模式和非理想性对波达方向估计性能的影响，比较稀疏阵列与传统均匀线性阵列在不同天线类型下的表现。

Method: 使用电磁仿真工具精确建模贴片天线和Vivaldi天线单元的电磁行为（包括互耦效应），比较稀疏阵列和经典均匀线性阵列，采用MUSIC算法估计两个信源的波达方向。

Result: 稀疏阵列配置结合定向天线单元能显著提升性能：相比相同数量（8个）的均匀全向阵列，平均测向误差降低90%以上；在固定角度RMSE下，阵列灵敏度提升使单向覆盖距离增加4-15倍；最佳性能来自100°视场的稀疏贴片天线阵列或120°视场的稀疏Vivaldi天线阵列。

Conclusion: 定向天线单元的非理想性和稀疏阵列配置对波达方向估计有重要影响，稀疏阵列结合定向天线能显著提升测向精度和覆盖距离，为实际阵列设计提供了重要指导。

Abstract: This paper studies the effects of directional antenna element complex gain patterns and nonidealities in direction of arrival (DoA) estimation. We compare sparse arrays and classical uniform linear arrays, harnessing EM simulation tools to accurately model the electromagnetic behavior of both patch and Vivaldi antenna element including mutual coupling effects. We show that with sparse array configurations, the performance impacts are significant in terms of DoA estimation accuracy and operable SNR ranges. Specifically, in the scenarios considered, both the usage of directional antenna elements and a sparse array result in over 90% reduction in average direction finding error, compared to a uniform omnidirectional array with the same number of elements (in this case eight), when estimating the directions of two sources using the MUSIC algorithm. For a fixed angular RMSE, the improvements in array sensitivity are shown to yield a 4 to 15-fold increase in one-way coverage distance (assuming free-space path loss). Among the studied options, the best performance was obtained using sparse arrays with either patch or Vivaldi elements for field of views of 100$^\circ$ or 120$^\circ$, respectively.

</details>


### [50] [Harnessing Chaotic Signals for Wireless Information and Power Transfer](https://arxiv.org/abs/2511.23049)
*Priyadarshi Mukherjee,Constantinos Psomas,Ioannis Krikidis*

Main category: eess.SP

TL;DR: 本文探讨混沌信号在无线能量传输和信息能量同传中的应用，提出基于DCSK的接收机架构和波形设计，分析其在6G自持续网络中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着6G通信标准的发展，自持续无线网络成为关键需求。混沌信号因其随机性和对初始条件的高度敏感性，在无线能量传输中表现出优越性能，适合用于为大量无线设备和传感器供电。

Method: 1) 表征多维混沌信号的广义WPT性能，以Lorenz和Henon混沌系统为例；2) 提出基于差分混沌移位键控(DCSK)的WPT接收机架构，优化能量收集；3) 为多天线SWIPT架构设计DCSK发射波形，研究速率-能量权衡。

Result: 实验观察表明混沌信号在WPT性能上优于现有基准方案。提出的DCSK架构和波形设计能够有效提升能量收集效率，并在多天线SWIPT系统中实现更好的速率-能量权衡。

Conclusion: 混沌信号在无线能量传输和同时无线信息能量传输中具有重要应用价值，特别是在6G自持续网络背景下。提出的DCSK架构和波形设计为未来无线通信系统的能量管理提供了创新解决方案。

Abstract: Chaotic dynamical systems have attracted considerable attention due to their inherent randomness and high sensitivity to initial conditions, which makes them ideal for secure wireless communications. Beyond security, these same characteristics also make chaotic signals particularly effective for wireless power transfer (WPT) applications. On the other hand, connectivity along with self-sustainability are the two cornerstones of the upcoming sixth generation (6G) standard for radio communications. Consequently, with the massive increase in wireless devices and sensors, the concept of self-sustainable wireless networks is becoming more relevant. The aspect of WPT to the widely spread wireless devices and simultaneous wireless information and power transfer (SWIPT) among these devices will play a crucial role in the 6G communication systems. In this context, it has been experimentally observed that chaotic signals result in better WPT performance as compared to the existing benchmark schemes. Hence, in this paper, we characterize the generalized WPT performance of the multi-dimensional chaotic signals and present the use case of the Lorenz and the Henon chaotic systems. Moreover, we provide a novel differential chaos shift keying (DCSK)-based WPT receiver architecture ideal for enhanced energy harvesting (EH). Furthermore, we propose DCSK-based transmit waveform designs for multi-antenna SWIPT architectures and investigate the impact of the rate-energy trade-off. Our goal is to explore these aspects of the chaotic signals and discuss their relevance in the context of both WPT and SWIPT.

</details>


### [51] [What If They Took the Shot? A Hierarchical Bayesian Framework for Counterfactual Expected Goals](https://arxiv.org/abs/2511.23072)
*Mikayil Mahmudlu,Oktay Karakuş,Hasan Arkadaş*

Main category: eess.SP

TL;DR: 开发分层贝叶斯框架，结合专家领域知识量化球员在预期进球（xG）估计中的个体效应，解决标准模型将所有球员视为相同终结者的问题。


<details>
  <summary>Details</summary>
Motivation: 标准xG模型将所有球员视为相同的终结者，忽略了球员个体在射门能力上的差异。本研究旨在开发一个能够量化球员特定效应、考虑个体技能差异的模型，为球员评估、招募和战术规划提供更准确的工具。

Method: 使用分层贝叶斯框架，结合贝叶斯逻辑回归和知情先验（使用StatsBomb 2015-16数据和Football Manager 2017评分），稳定球员级估计，特别是对于射门次数少的球员。模型支持反事实分析，通过重新分配相同情境下的射门机会来评估球员差异。

Result: 分层模型相对于弱先验减少了后验不确定性，外部验证表现良好：分层与基线预测相关性R²=0.75，与StatsBomb xG基准的XGBoost模型验证达到R²=0.833。模型识别出可解释的专业化特征（一对一终结、远射、第一触球执行），并发现表现不佳球员的潜在能力（如Immobile和Belotti）。反事实分析显示球员替换的显著不对称效应。

Conclusion: 该研究提供了一个考虑不确定性的工具，用于球员评估、招募和战术规划，并为个体技能和情境因素共同影响表现的领域提供通用方法。框架能够识别球员专业化特征，支持反事实分析，揭示球员替换的非对称效应。

Abstract: This study develops a hierarchical Bayesian framework that integrates expert domain knowledge to quantify player-specific effects in expected goals (xG) estimation, addressing a limitation of standard models that treat all players as identical finishers. Using 9,970 shots from StatsBomb's 2015-16 data and Football Manager 2017 ratings, we combine Bayesian logistic regression with informed priors to stabilise player-level estimates, especially for players with few shots. The hierarchical model reduces posterior uncertainty relative to weak priors and achieves strong external validity: hierarchical and baseline predictions correlate at R2 = 0.75, while an XGBoost benchmark validated against StatsBomb xG reaches R2 = 0.833. The model uncovers interpretable specialisation profiles, including one-on-one finishing (Aguero, Suarez, Belotti, Immobile, Martial), long-range shooting (Pogba), and first-touch execution (Insigne, Salah, Gameiro). It also identifies latent ability in underperforming players such as Immobile and Belotti. The framework supports counterfactual "what-if" analysis by reallocating shots between players under identical contexts. Case studies show that Sansone would generate +2.2 xG from Berardi's chances, driven largely by high-pressure situations, while Vardy-Giroud substitutions reveal strong asymmetry: replacing Vardy with Giroud results in a large decline (about -7 xG), whereas the reverse substitution has only a small effect (about -1 xG). This work provides an uncertainty-aware tool for player evaluation, recruitment, and tactical planning, and offers a general approach for domains where individual skill and contextual factors jointly shape performance.

</details>


### [52] [Physical Layer Security with Artificial Noise in MIMO Pinching-Antenna Systems](https://arxiv.org/abs/2511.23079)
*Pigi P. Papanikolaou,Dimitrios Bozanis,Sotiris A. Tegos,Panagiotis D. Diamantoulakis,Panagiotis Sarigiannidis,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 提出一种用于pinching天线系统的AN辅助波束成形框架，通过联合优化信息波束、AN协方差和PA位置来最大化保密速率，在完美和不完美CSI下均优于基线。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中安全成为关键性能指标，传统MIMO系统存在严重路径损耗且易受附近窃听者攻击，而pinching天线系统通过可重构天线和低损耗介质波导可增强信道条件并动态缓解安全威胁。

Method: 提出AN辅助波束成形框架，联合优化信息波束、AN协方差和PA位置。针对窃听者信道，考虑完美和不完美CSI两种情况。对于不完美CSI，将位置误差通过雅可比矩阵映射到椭球形信道不确定性集合。针对单波导场景推导闭式解，针对多波导多用户场景开发DNN辅助联合优化器。

Result: 数值结果表明，所提方案在单用户和多用户设置下，无论是完美还是不完美CSI，均能持续改进保密速率，优于PAS基线。

Conclusion: 提出的AN辅助波束成形框架有效提升了pinching天线系统的安全性能，通过联合优化波束成形、人工噪声和天线位置，在完美和不完美CSI下均能实现更高的保密速率。

Abstract: As next-generation wireless networks emerge, security is becoming a critical performance metric. However, conventional multiple-input-multiple-output (MIMO) systems often suffer from severe path loss and are vulnerable to nearby eavesdroppers due to their fixed-antenna configurations. Pinching-antenna systems (PASs) offer a promising alternative, leveraging reconfigurable pinching antennas (PAs) positioned along low-loss dielectric waveguides to enhance channel conditions and dynamically mitigate security threats. In this paper, we propose an artificial noise (AN)-aided beamforming framework for the PAS downlink that maximizes the secrecy rate (SR) by jointly optimizing the information beams, the AN covariance, and the PA positions. We examine both perfect and imperfect channel state information (CSI) for the eavesdropper's channel. For the latter, location errors are mapped via a Jacobian into an ellipsoidal channel uncertainty set to accurately formulate the problem. We derive a closed-form solution for the single-waveguide scenario, yielding the optimal PA location and an information/AN power-splitting rule. For multiple waveguides and users, we develop a deep neural network (DNN)-aided joint optimizer that outputs beams, AN, and PA placements. Numerical results demonstrate that the proposed scheme improves SR consistently over PAS baselines in single- and multi-user settings under both perfect and imperfect CSI.

</details>


### [53] [Joint Optimization of Pilot Length, Pilot Assignment, and Power Allocation for Cell-free MIMO Systems with Graph Neural Networks](https://arxiv.org/abs/2511.23128)
*Yao Peng,Tingting Liu,Chenyang Yang*

Main category: eess.SP

TL;DR: 本文提出了一种基于图神经网络（GNN）的深度学习方法，联合优化导频长度、导频分配和功率分配，以最大化用户中心的无小区多天线系统中的净频谱效率（net-SE）。


<details>
  <summary>Details</summary>
Motivation: 在用户中心的无小区多天线系统中，导频污染严重降低了频谱效率。现有方法通常假设固定导频长度来联合优化导频分配和功率分配，但无法平衡导频开销与污染之间的权衡。为了最大化净频谱效率，需要联合优化导频长度、导频分配和功率分配。

Method: 1. 设计尺寸可泛化的图神经网络（GNN）来处理可变导频长度导致的未知尺寸导频分配矩阵问题
2. 引入特征增强技术解决导频分配策略的一对多映射问题
3. 设计污染感知注意力机制提升学习性能
4. 开发双时间尺度GNN框架，分别处理依赖于大尺度和小尺度信道的导频分配和功率分配
5. 设计单时间尺度GNN以减少推理时间

Result: 仿真结果表明，所设计的GNN在净频谱效率、训练复杂度和推理时间方面均优于现有方法，并且能够很好地泛化到不同问题规模和信道条件。

Conclusion: 本文提出的基于GNN的深度学习方法能够有效解决用户中心无小区多天线系统中的导频污染问题，通过联合优化导频长度、导频分配和功率分配，显著提升了净频谱效率，同时具有良好的泛化能力和计算效率。

Abstract: In user-centric cell-free multi-antenna systems, pilot contamination degrades spectral efficiency (SE) severely. To mitigate pilot contamination, existing works jointly optimize pilot assignment and power allocation by assuming fixed pilot length, which fail to balance pilot overhead against the contamination. To maximize net-SE, we jointly optimize pilot length, pilot assignment, and power allocation with deep learning. Since the pilot length is a variable, the size of pilot assignment matrix is unknown during the optimization. To cope with the challenge, we design size-generalizable graph neural networks (GNNs). We prove that pilot assignment policy is a one-to-many mapping, and improperly designed GNNs cannot learn the optimal policy. We tackle this issue by introducing feature enhancement. To improve learning performance, we design a contamination-aware attention mechanism for the GNNs. Given that pilot assignment and power allocation respectively depend on large- and small-scale channels, we develop a dual-timescale GNN framework to explore the potential. To reduce inference time, a single-timescale GNN is also designed. Simulation results show that the designed GNNs outperform existing methods in terms of net-SE, training complexity, and inference time, and can be well generalized across problem scales and channels.

</details>


### [54] [Strategies to Minimize Out-of-Distribution Effects in Data-Driven MRS Quantification](https://arxiv.org/abs/2511.23135)
*Julian P. Merkofer,Antonia Kaiser,Anouk Schrantee,Oliver J. Gurney-Champion,Ruud J. G. van Sloun*

Main category: eess.SP

TL;DR: 本研究系统比较了磁共振波谱代谢物定量中数据驱动与模型驱动策略，重点关注其对分布外效应的鲁棒性，以及准确性、鲁棒性和泛化性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 磁共振波谱代谢物定量需要平衡准确性、鲁棒性和泛化性。传统模型驱动方法面临挑战，而数据驱动方法（特别是深度学习）虽有潜力，但其对分布外效应的鲁棒性尚未得到系统评估。

Method: 设计神经网络用于MRS定量，采用三种训练策略：监督回归、自监督学习和测试时适应，并与模型驱动拟合工具对比。实验结合大规模模拟数据（设计用于探索代谢物浓度外推和信号变异性）和7T 1H单体素活体人脑波谱。

Result: 模拟实验中，监督学习在训练分布相似谱上精度高，但在超出训练分布时性能显著下降；测试时适应对分布外效应更具鲁棒性；自监督学习表现居中。活体实验中，由于域偏移，所有方法（数据驱动和模型驱动）方差较大。重叠代谢物和基线变异性仍是持续挑战。

Conclusion: 数据驱动方法在MRS代谢物定量中可实现强性能，但其可靠性取决于对训练分布和潜在分布外效应的仔细考虑。当目标分布条件无法预知时，测试时适应策略能确保定量、数据和模型之间的一致性，从而建立可靠的数据驱动MRS流程。

Abstract: This study systematically compared data-driven and model-based strategies for metabolite quantification in magnetic resonance spectroscopy (MRS), focusing on resilience to out-of-distribution (OoD) effects and the balance between accuracy, robustness, and generalizability. A neural network designed for MRS quantification was trained using three distinct strategies: supervised regression, self-supervised learning, and test-time adaptation. These were compared against model-based fitting tools. Experiments combined large-scale simulated data, designed to probe metabolite concentration extrapolation and signal variability, with 1H single-voxel 7T in-vivo human brain spectra. In simulations, supervised learning achieved high accuracy for spectra similar to those in the training distribution, but showed marked degradation when extrapolated beyond the training distribution. Test-time adaptation proved more resilient to OoD effects, while self-supervised learning achieved intermediate performance. In-vivo experiments showed larger variance across the methods (data-driven and model-based) due to domain shift. Across all strategies, overlapping metabolites and baseline variability remained persistent challenges. While strong performance can be achieved by data-driven methods for MRS metabolite quantification, their reliability is contingent on careful consideration of the training distribution and potential OoD effects. When such conditions in the target distribution cannot be anticipated, test-time adaptation strategies ensure consistency between the quantification, the data, and the model, enabling reliable data-driven MRS pipelines.

</details>


### [55] [Data-Efficient Motor Condition Monitoring with Time Series Foundation Models](https://arxiv.org/abs/2511.23177)
*Deyu Li,Xinyuan Liao,Shaowei Chen,Shuai Zhao*

Main category: eess.SP

TL;DR: 该论文提出了一种基于时间序列基础模型（MOMENT和Mantis）的电机状态监测框架，通过迁移大规模预训练学到的通用特征，显著减少对标注数据的依赖，在数据稀疏和类别不平衡的情况下仍能保持高诊断精度。


<details>
  <summary>Details</summary>
Motivation: 电机状态监测对系统可靠性至关重要，但现有数据驱动方法面临故障标签稀疏和类别严重不平衡的问题，限制了其在实际应用中的有效性。

Method: 利用两个时间序列基础模型（MOMENT和Mantis）在预训练阶段学到的通用特征，通过迁移学习将广泛的时间表示应用于电机故障诊断，减少对标注数据的依赖。

Result: MOMENT仅使用1%的训练数据就能达到传统深度学习模型近两倍的性能；Mantis在相同数据比例下超越现有最佳基线22%，达到90%的准确率。

Conclusion: 时间序列基础模型在故障诊断中展现出强大的泛化能力和数据效率，为智能电机状态监测提供了可扩展和自适应的新框架思路。

Abstract: Motor condition monitoring is essential for ensuring system reliability and preventing catastrophic failures. However, data-driven diagnostic methods often suffer from sparse fault labels and severe class imbalance, which limit their effectiveness in real-world applications. This paper proposes a motor condition monitoring framework that leverages the general features learned during pre-training of two time series foundation models, MOMENT and Mantis, to address these challenges. By transferring broad temporal representations from large-scale pre-training, the proposed approach significantly reduces dependence on labeled data while maintaining high diagnostic accuracy. Experimental results show that MOMENT achieves nearly twice the performance of conventional deep learning models using only 1\% of the training data, whereas Mantis surpasses state-of-the-art baselines by 22\%, reaching 90\% accuracy with the same data ratio. These results demonstrate the strong generalization and data efficiency of time series foundation models in fault diagnosis, providing new insights into scalable and adaptive frameworks for intelligent motor condition monitoring.

</details>


### [56] [Near-Field Channel Estimation and Joint Angle-Range Recovery in XL-MIMO Systems: A Gridless Super-Resolution Approach](https://arxiv.org/abs/2511.23187)
*Feng Xi,Dehui Yang*

Main category: eess.SP

TL;DR: 提出一种免码本的近场信道估计框架，将问题转化为网格无关的超分辨率问题，通过原子范数最小化实现角度和距离的联合估计。


<details>
  <summary>Details</summary>
Motivation: 现有近场信道估计方法通常需要联合离散化角度和距离参数，导致极坐标域码本过大。需要避免码本构建和二维网格搜索，同时解决基失配问题。

Method: 采用球面波导向矢量的二阶近似，将信道表示为复指数与未知波形的叠加；利用离散啁啾率子空间结构，通过提升技术和正则化原子范数最小化将非凸问题转化为凸优化；最后在精确球面模型下进行梯度非线性最小二乘细化。

Result: 方法能够实现准确的信道重建和用户定位，在稀疏多径场景下，导频开销随阵列规模呈亚线性增长，避免了基失配和穷举二维网格搜索。

Conclusion: 提出了一种创新的网格无关近场信道估计框架，通过利用信道的内在结构特性，实现了高效准确的联合角度-距离估计，为XL-MIMO系统提供了实用的解决方案。

Abstract: Existing near-field channel estimation methods for extremely large-scale MIMO (XL-MIMO) typically discretize angle and range parameters jointly, resulting in large polar-domain codebooks. This paper proposes a novel framework that formulates near-field channel estimation as a gridless super-resolution problem, eliminating the need for explicitly constructed codebooks. By employing a second-order approximation of spherical-wave steering vectors, the near-field channel is represented as a superposition of complex exponentials modulated by unknown waveforms. We demonstrate that these waveforms lie tightly in a common discrete chirp rate (DCR) subspace, with a dimension that scales as $Θ(\sqrt{N})$ for an $N$-element array. By leveraging this structure and applying a lifting technique, we reformulate the non-convex problem as a convex program using regularized atomic norm minimization, which admits an equivalent semidefinite program. From the solution to the convex program, we obtain gridless angle estimates and derive closed-form coarse range estimates, followed by refinement under the exact spherical model using gradient-based nonlinear least squares. The proposed method avoids basis mismatch and exhaustive two-dimensional grid searches while enabling accurate joint angle-range estimation with pilot budgets that scale sublinearly with array size in sparse multipath regimes. Simulations demonstrate accurate channel reconstruction and user localization across representative near-field scenarios.

</details>


### [57] [A Framework for Statistical Geometric Channel Model for ISAC Systems](https://arxiv.org/abs/2511.23201)
*Ali Waqar Azim,Ahmad Bazzi,Theodore S. Rappaport,Marwa Chafii*

Main category: eess.SP

TL;DR: 提出用于双基地系统的几何统计ISAC信道模型框架，将信道分解为目标信道和背景信道，通过混合聚类方法扩展TR38.901标准，在保持通信性能的同时支持感知性能评估。


<details>
  <summary>Details</summary>
Motivation: 为双基地集成感知与通信系统开发一个统一的信道模型框架，能够同时评估通信和感知性能，解决现有标准模型缺乏对感知目标建模能力的问题。

Method: 提出双分量模型：目标信道（包含所有由感知目标产生的多径分量）和背景信道（包含其他传播路径）。采用混合聚类方法扩展TR38.901标准，结合时空一致的确定性聚类和随机聚类，保持信道互易性和绝对时延对齐。

Result: 在UMa、UMi和InF场景下的广泛仿真表明，该模型在保持与TR38.901标准通信性能一致的同时（通过误码率和信道容量验证），能够支持感知性能评估，如目标测距误差和检测概率的ROC曲线分析。

Conclusion: 该框架为双基地ISAC系统提供了一个全面的几何统计信道模型，成功平衡了通信和感知需求，为ISAC系统的性能评估和优化提供了有效工具。

Abstract: This paper proposes a comprehensive framework for a geometry-based statistical model for integrated sensing and communication (ISAC) tailored for bistatic systems. Our dual-component model decomposes the ISAC channel into a target channel encompassing all multipath components produced by a sensing target parameterized by the target's radar cross-section and scattering points, and a background channel comprising all other propagation paths that do not interact with the sensing target. The framework extends TR38.901 via a hybrid clustering approach, integrating spatiotemporally consistent deterministic clusters with stochastic clusters to preserve channel reciprocity and absolute delay alignment for sensing parameter estimation. Extensive simulations across urban macro, urban micro, and indoor factory scenarios demonstrate that the model maintains communication performance parity with the standard TR38.901, validated through bit-error rate analysis obtained via simulated and measured ISAC channels and channel capacity assessment, while enabling sensing performance evaluation, such as target ranging error for localization and receiver operating characteristic curves for detection probability.

</details>


### [58] [Robust HRRP Recognition under Interrupted Sampling Repeater Jamming using a Prior Jamming Information-Guided Network](https://arxiv.org/abs/2511.23256)
*Guozheng Sun,Lei Wang,Yanhao Wang,Jie Wang,Yimin Liu*

Main category: eess.SP

TL;DR: 提出一种基于先验干扰信息的稳健HRRP识别方法，通过点扩散函数建模ISRJ干扰，设计先验引导的特征交互模块和混合损失函数，在不同干扰参数下学习不变特征


<details>
  <summary>Details</summary>
Motivation: 在电子对抗（ECM）环境下，特别是主流的中断采样转发干扰（ISRJ）下，高分辨率距离像（HRRP）会出现严重特征失真，导致雷达自动目标识别（RATR）面临重大挑战

Method: 引入点扩散函数（PSF）作为先验信息来建模ISRJ引起的HRRP失真，设计识别网络，通过先验引导的特征交互模块和混合损失函数来增强模型的判别能力

Result: 模拟和实测数据实验表明，该方法始终优于最先进的方法，在面对未见过的干扰参数时表现出更强的泛化能力

Conclusion: 提出的基于先验干扰信息的稳健HRRP识别方法能有效应对ISRJ干扰，在不同干扰参数下学习不变特征，显著提升识别性能和泛化能力

Abstract: Radar automatic target recognition (RATR) based on high-resolution range profile (HRRP) has attracted increasing attention due to its ability to capture fine-grained structural features. However, recognizing targets under electronic countermeasures (ECM), especially the mainstream interrupted-sampling repeater jamming (ISRJ), remains a significant challenge, as HRRPs often suffer from serious feature distortion. To address this, we propose a robust HRRP recognition method guided by prior jamming information. Specifically, we introduce a point spread function (PSF) as prior information to model the HRRP distortion induced by ISRJ. Based on this, we design a recognition network that leverages this prior through a prior-guided feature interaction module and a hybrid loss function to enhance the model's discriminative capability. With the aid of prior information, the model can learn invariant features within distorted HRRP under different jamming parameters. Both the simulated and measured-data experiments demonstrate that our method consistently outperforms state-of-the-art approaches and exhibits stronger generalization capabilities when facing unseen jamming parameters.

</details>


### [59] [Hierarchical Feature Integration for Multi-Signal Automatic Modulation Recognition](https://arxiv.org/abs/2511.23258)
*Yunpeng Qu,Yazhou Sun,Bingyu Hui,Jian Wang*

Main category: eess.SP

TL;DR: 提出HIFI-YOLO框架，用于多信号联合检测与调制识别，解决实际信道中多信号叠加问题


<details>
  <summary>Details</summary>
Motivation: 现有自动调制识别研究主要关注单一信号识别，忽略了实际信道中多信号叠加现象以及信号检测前置步骤的必要性。考虑到射频信号易受噪声干扰和频谱变化影响，需要开发能同时处理多信号检测与识别的解决方案。

Method: 提出分层特征集成(HIFI)-YOLO框架，通过独特的分层特征集成设计，增强不同模块的特征表示能力。构建了大规模AMR数据集，专门针对多信号共存或重叠的实际传播条件场景，包含多种数字和模拟调制方案。

Result: 在构建的数据集上进行大量实验，证明HIFI-YOLO在多信号检测和调制识别联合方法中表现出优异性能。

Conclusion: HIFI-YOLO框架通过分层特征集成有效提升了多信号环境下的检测与识别性能，为实际无线通信系统中的自动调制识别提供了有效的联合解决方案。

Abstract: Automatic modulation recognition (AMR) is a crucial step in wireless communication systems, which identifies the modulation scheme from detected signals to provide key information for further processing. However, previous work has mainly focused on the identification of a single signal, overlooking the phenomenon of multiple signal superposition in practical channels and the signal detection procedures that must be conducted beforehand. Considering the susceptibility of radio frequency (RF) signals to noise interference and significant spectral variations, we propose a novel Hierarchical Feature Integration (HIFI)-YOLO framework for multi-signal joint detection and modulation recognition. Our HIFI-YOLO framework, with its unique design of hierarchical feature integration, effectively enhances the representation capability of features in different modules, thereby improving detection performance. We construct a large-scale AMR dataset specifically tailored for scenarios of the coexistence or overlapping of multiple signals transmitted through channels with realistic propagation conditions, consisting of diverse digital and analog modulation schemes. Extensive experiments on our dataset demonstrate the excellent performance of HIFI-YOLO in multi-signal detection and modulation recognition as a joint approach.

</details>


### [60] [Compensation of correlated autoregressive clock jitter in arrays of Analog-to-Digital Converters](https://arxiv.org/abs/2511.23351)
*Daniele Gerosa,Lauri Anttila,Thomas Eriksson*

Main category: eess.SP

TL;DR: 提出基于VAR(1)模型和卡尔曼平滑器的ADC阵列时钟抖动联合跟踪与补偿方法


<details>
  <summary>Details</summary>
Motivation: 传统ADC抖动模型将抖动视为独立高斯噪声，忽略了时间相关性和MIMO ADC中的空间互相关性，导致无法有效跟踪和补偿

Method: 将ADC阵列抖动建模为一阶向量自回归过程(VAR(1))，提出基于导频音的卡尔曼平滑器来联合跟踪和补偿交叉相关的定时误差

Result: 仿真显示该方法在不同场景下能显著降低抖动引起的失真

Conclusion: VAR(1)模型和卡尔曼平滑器能有效解决ADC阵列中随机、交叉相关的时钟抖动问题，相比传统标量模型有显著改进

Abstract: In modern communication systems, the fidelity of analog-to-digital converters (ADCs) is limited by sampling clock jitter, i.e., small random timing deviations that undermine ideal sampling. Traditional scalar models often treat jitter as independent Gaussian noise, which makes it essentially untrackable, whereas real ADCs also exhibit temporally correlated (spectrally colored) imperfections. Moreover, spatial cross-correlations between channels in multiple-input multiple-output (MIMO) ADCs are commonly neglected. This paper addresses the joint tracking and compensation of random, cross-correlated timing errors in ADC arrays by modeling jitter as a coupled vector autoregressive process of order one (VAR(1)). We propose a pilot-tone-based Kalman smoother to track and compensate the jitter, and simulations demonstrate substantial reductions in jitter-induced distortion across diverse scenarios.

</details>
