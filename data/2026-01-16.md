<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 3]
- [eess.SP](#eess.SP) [Total: 10]
- [cs.IT](#cs.IT) [Total: 41]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy](https://arxiv.org/abs/2601.10250)
*Raffaella Fiamma Cabini,Deborah Barkauskas,Guangyu Chen,Zhi-Qi Cheng,David E Cicchetti,Judith Drazba,Rodrigo Fernandez-Gonzalez,Raymond Hawkins,Yujia Hu,Jyoti Kini,Charles LeWarne,Xufeng Lin,Sai Preethi Nakkina,John W Peterson,Koert Schreurs,Ayushi Singh,Kumaran Bala Kandan Viswanathan,Inge MN Wortel,Sanjian Zhang,Rolf Krause,Santiago Fernandez Gonzalez,Diego Ulisse Pizzagalli*

Main category: eess.IV

TL;DR: 该论文组织了细胞行为视频分类挑战赛（CBVCC），评估了35种方法，比较了基于跟踪特征、端到端深度学习以及特征融合三种方法在细胞行为视频分类中的表现。


<details>
  <summary>Details</summary>
Motivation: 显微视频中复杂细胞行为的分类对于理解生物过程的动态变化至关重要，但这是计算机视觉的前沿难题，需要能够有效建模无刚性边界物体的形状和运动、从整个图像序列提取层次化时空特征、并处理视场中多个对象的方法。

Method: 组织了细胞行为视频分类挑战赛（CBVCC），基准测试了35种方法，主要分为三类：1）基于跟踪提取特征的分类方法；2）端到端深度学习架构直接从整个视频序列学习时空特征，无需显式细胞跟踪；3）将跟踪特征与图像特征融合的集成方法。

Result: 论文讨论了参赛者取得的结果，并比较了每种方法的潜力和局限性，为促进研究细胞动态的计算机视觉方法发展提供了基础。

Conclusion: 该挑战赛为细胞行为视频分类提供了重要的基准测试，通过系统比较不同方法的优缺点，为未来开发更有效的细胞动态分析计算机视觉方法奠定了基础。

Abstract: The classification of microscopy videos capturing complex cellular behaviors is crucial for understanding and quantifying the dynamics of biological processes over time. However, it remains a frontier in computer vision, requiring approaches that effectively model the shape and motion of objects without rigid boundaries, extract hierarchical spatiotemporal features from entire image sequences rather than static frames, and account for multiple objects within the field of view.
  To this end, we organized the Cell Behavior Video Classification Challenge (CBVCC), benchmarking 35 methods based on three approaches: classification of tracking-derived features, end-to-end deep learning architectures to directly learn spatiotemporal features from the entire video sequence without explicit cell tracking, or ensembling tracking-derived with image-derived features.
  We discuss the results achieved by the participants and compare the potential and limitations of each approach, serving as a basis to foster the development of computer vision methods for studying cellular dynamics.

</details>


### [2] [An effective interactive brain cytoarchitectonic parcellation framework using pretrained foundation model](https://arxiv.org/abs/2601.10412)
*Shiqi Zhang,Fang Xu,Pengcheng Zhou*

Main category: eess.IV

TL;DR: 基于DINOv3视觉Transformer的交互式细胞构筑分区框架，通过多特征融合、轻量解码器和实时用户引导训练，实现高效准确的脑区分割。


<details>
  <summary>Details</summary>
Motivation: 细胞构筑分区是神经科学分析的基础，但现有深度学习方法的性能受限于训练标签稀缺以及染色和成像条件的变化。需要一种能够处理这些挑战的自动化分割方法。

Method: 提出交互式细胞构筑分区框架，包含：(1) 多层级DINOv3特征融合，(2) 轻量级分割解码器，(3) 基于稀疏涂鸦的实时用户引导训练，实现人机协同的快速精化。

Result: 与从头训练nnU-Net相比，使用DINOv3进行迁移学习显著提升了性能。DINOv3提取的特征显示出清晰的解剖对应性，且方法能够有效利用稀疏标签进行脑区分割。

Conclusion: 该研究展示了基础模型驱动的交互式分割在大规模、高效细胞构筑分区中的潜力，为神经科学研究提供了实用的工具。

Abstract: Cytoarchitectonic mapping provides anatomically grounded parcellations of brain structure and forms a foundation for integrative, multi-modal neuroscience analyses. These parcellations are defined based on the shape, density, and spatial arrangement of neuronal cell bodies observed in histological imaging. Recent works have demonstrated the potential of using deep learning models toward fully automatic segmentation of cytoarchitectonic areas in large-scale datasets, but performance is mainly constrained by the scarcity of training labels and the variability of staining and imaging conditions. To address these challenges, we propose an interactive cytoarchitectonic parcellation framework that leverages the strong transferability of the DINOv3 vision transformer. Our framework combines (i) multi-layer DINOv3 feature fusion, (ii) a lightweight segmentation decoder, and (iii) real-time user-guided training from sparse scribbles. This design enables rapid human-in-the-loop refinement while maintaining high segmentation accuracy. Compared with training an nnU-Net from scratch, transfer learning with DINOv3 yields markedly improved performance. We also show that features extracted by DINOv3 exhibit clear anatomical correspondence and demonstrate the method's practical utility for brain region segmentation using sparse labels. These results highlight the potential of foundation-model-driven interactive segmentation for scalable and efficient cytoarchitectonic mapping.

</details>


### [3] [Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming](https://arxiv.org/abs/2601.10607)
*Angeliki Katsenou,Vignesh V. Menon,Guoda Laurinaviciute,Benjamin Bross,Detlev Marpe*

Main category: eess.IV

TL;DR: 本文提出了一种基于帕累托前沿优化的自适应视频流多目标优化框架，用于构建质量单调、内容自适应的VVC码率阶梯，联合优化视频质量、码率和解码时间（作为解码能耗的代理）。


<details>
  <summary>Details</summary>
Motivation: 自适应视频流需要在码率、视频质量和解码复杂度之间取得平衡，以实现高效、内容相关和编解码器相关的自适应流媒体。现有方法往往采用固定阶梯或单一目标优化，无法同时优化多个相互冲突的目标。

Method: 提出了两种策略：联合码率-质量-时间帕累托前沿（JRQT-PF）和联合质量-时间帕累托前沿（JQT-PF）。在自适应流媒体过程中，在质量单调性约束下构建阶梯，确保一致的QoE。使用大规模UHD数据集（Inter-4K）进行实验，使用PSNR、VMAF和XPSNR评估质量，通过解码时间和能耗测量复杂度。

Result: JQT-PF方法相比广泛使用的固定阶梯，在保持相同XPSNR的情况下，平均节省11.76%的码率，同时减少0.29%的平均解码时间。更激进的配置可节省高达27.88%的码率，但复杂度增加。JRQT-PF策略提供更可控的权衡，实现6.38%的码率节省和6.17%的解码时间减少。

Conclusion: 该帕累托前沿优化框架优于现有方法，包括固定阶梯、基于VMAF和XPSNR的动态分辨率选择以及复杂度感知基准。结果表明，带有解码时间约束的PF优化能够实现可持续、高质量的自适应流媒体，适应网络和设备能力。

Abstract: Adaptive video streaming has facilitated improved video streaming over the past years. A balance among coding performance objectives such as bitrate, video quality, and decoding complexity is required to achieve efficient, content- and codec-dependent, adaptive video streaming. This paper proposes a multi-objective Pareto-front (PF) optimization framework to construct quality-monotonic, content-adaptive bitrate ladders Versatile Video Coding (VVC) streaming that jointly optimize video quality, bitrate, and decoding time, which is used as a practical proxy for decoding energy. Two strategies are introduced: the Joint Rate-Quality-Time Pareto Front (JRQT-PF) and the Joint Quality-Time Pareto Front (JQT-PF), each exploring different tradeoff formulations and objective prioritizations. The ladders are constructed under quality monotonicity constraints during adaptive streaming to ensure a consistent Quality of Experience (QoE). Experiments are conducted on a large-scale UHD dataset (Inter-4K), with quality assessed using PSNR, VMAF, and XPSNR, and complexity measured via decoding time and energy consumption. The JQT-PF method achieves 11.76% average bitrate savings while reducing average decoding time by 0.29% to maintain the same XPSNR, compared to a widely-used fixed ladder. More aggressive configurations yield up to 27.88% bitrate savings at the cost of increased complexity. The JRQT-PF strategy, on the other hand, offers more controlled tradeoffs, achieving 6.38 % bitrate savings and 6.17 % decoding time reduction. This framework outperforms existing methods, including fixed ladders, VMAF- and XPSNR-based dynamic resolution selection, and complexity-aware benchmarks. The results confirm that PF optimization with decoding time constraints enables sustainable, high-quality streaming tailored to network and device capabilities.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [4] [Distributed Hypothesis Testing Under A Covertness Constraint](https://arxiv.org/abs/2601.09837)
*Ismaila Salihou Adamou,Michèle Wigger*

Main category: eess.SP

TL;DR: 研究分布式假设检验中的隐蔽性约束问题，在非警报情况下，传感器与决策中心之间的通信需要对外部监控者不可检测。针对部分连接和完全连接的离散无记忆信道，分析了可实现的Stein指数。


<details>
  <summary>Details</summary>
Motivation: 在分布式假设检验中，当存在外部监控者时，需要确保传感器与决策中心之间的通信不被检测到。传统隐蔽通信通常需要共享密钥，本文旨在探索无需共享密钥的隐蔽通信方案，并分析其性能极限。

Method: 针对部分连接的离散无记忆信道(DMC)，推导了Stein指数的闭式表达式，该指数不依赖于具体的信道转移概率。对于完全连接的DMC，提出了可实现的Stein指数方案。所有编码方案都不需要传感器和决策中心共享密钥。

Result: 对于部分连接的DMC，Stein指数等于Shalaby和Papamarcou的无监控者情况下的指数，但传感器可以发送k个无噪声比特(k是观测长度n的亚线性函数)。对于完全连接的DMC，提出的Stein指数可以改善决策中心的局部指数。所有方案的隐蔽性约束以(几乎)指数速度收敛到零。

Conclusion: 本文证明了在分布式假设检验中，无需共享密钥也能实现隐蔽通信，且隐蔽性约束可以指数速度收敛到零。这对于实际隐蔽通信系统设计具有重要意义，特别是对于部分连接的DMC，得到了与具体信道转移概率无关的简洁性能表达式。

Abstract: We study distributed hypothesis testing under a covertness constraint in the non-alert situation, which requires that under the null-hypothesis an external warden be unable to detect whether communication between the sensor and the decision center is taking place. We characterize the achievable Stein exponent of this setup when the channel from the sensor to the decision center is a partially-connected discrete memoryless channel (DMC), i.e., when certain output symbols can only be induced by some of the inputs. The Stein-exponent in this case, does not depend on the specific transition law of the DMC and equals Shalaby and Papamarcou's exponent without a warden but where the sensor can send $k$ noise-free bits to the decision center, for $k$ a function that is sublinear in the observation length $n$. For fully-connected DMCs, we propose an achievable Stein-exponent and show that it can improve over the local exponent at the decision center. All our coding schemes do not require that the sensor and decision center share a common secret key, as commonly assumed in covert communication. Moreover, in our schemes the divergence covertness constraint vanishes (almost) exponentially fast in the obervation length $n$, again, an atypical behaviour for covert communication.

</details>


### [5] [Towards Native Intelligence: 6G-LLM Trained with Reinforcement Learning from NDT Feedback](https://arxiv.org/abs/2601.09992)
*Zhuoran Xiao,Tao Tao,Chenhui Ye,Yunbo Hu,Yijia Feng,Tianyu Jiao,Liyu Cai*

Main category: eess.SP

TL;DR: 提出RLDTF训练范式，利用数字孪生反馈的强化学习来训练6G-LLM，解决现有方法依赖人工标注数据且无法持续自适应的问题。


<details>
  <summary>Details</summary>
Motivation: 6G-LLM作为系统编排器能提升网络灵活性和适应性，但现有构建方法依赖大规模人工标注语料，且离线训练模型缺乏持续自改进能力，难以适应无线通信环境的高度动态需求。

Method: 提出RLDTF训练范式：利用网络数字孪生根据编排结果生成奖励信号，通过强化学习动态引导模型优化决策；引入加权令牌机制提升输出准确性。

Result: 综合实验结果表明，所提框架在编排准确性和解决方案最优性方面显著优于现有最先进基线方法。

Conclusion: RLDTF训练范式有效解决了6G-LLM构建中的数据依赖和自适应限制问题，为网络原生智能的实现提供了可行路径。

Abstract: Owing to its comprehensive understanding of upper-layer application requirements and the capabilities of practical communication systems, the 6G-LLM (6G domain large language model) offers a promising pathway toward realizing network native intelligence. Serving as the system orchestrator, the 6G-LLM drives a paradigm shift that fundamentally departs from existing rule-based approaches, which primarily rely on modular, experience-driven optimization. By contrast, the 6G-LLM substantially enhances network flexibility and adaptability. Nevertheless, current efforts to construct 6G-LLMs are constrained by their reliance on large-scale, meticulously curated, human-authored corpora, which are impractical to obtain in real-world scenarios. Moreover, purely offline-trained models lack the capacity for continual self-improvement, limiting their ability to adapt to the highly dynamic requirements of wireless communication environments. To overcome these limitations, we propose a novel training paradigm termed RLDTF (Reinforcement Learning from Digital Twin Feedback) for 6G-LLMs. This framework leverages network digital twins to generate reward signals based on orchestration outcomes, while employing reinforcement learning to guide the model toward optimal decision-making dynamically. Furthermore, we introduce a weighted token mechanism to improve output accuracy. Comprehensive experimental results demonstrate that our proposed framework significantly outperforms state-of-the-art baselines in orchestration accuracy and solution optimality.

</details>


### [6] [Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks](https://arxiv.org/abs/2601.10013)
*Ce Zheng,Shiyao Ma,Ke Zhang,Chen Sun,Wenqi Zhang*

Main category: eess.SP

TL;DR: 提出基于元数据的联邦学习框架，通过泊松点过程数据划分和聚类用户选择策略，解决数据相关性问题，提升非IID场景下的性能


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习模拟通常依赖不现实的数据划分，且现有用户选择方法忽略了用户间的数据相关性，这限制了联邦学习在真实部署中的性能

Method: 1) 基于齐次泊松点过程(HPPP)的新型数据划分模型，捕捉数据量的异质性和用户数据集间的自然重叠；2) 基于聚类的用户选择策略，利用位置等元数据减少数据相关性，增强训练轮次间的标签多样性

Result: 在FMNIST和CIFAR-10数据集上的实验表明，该框架在非IID场景下显著提升了模型性能、稳定性和收敛速度，在IID设置下保持可比性能，尤其在每轮选择用户数较少时优势更明显

Conclusion: 该元数据驱动的联邦学习框架能有效提升真实部署中的性能，为未来标准化提供指导，特别适用于非IID场景和用户选择受限的情况

Abstract: Federated learning (FL) enables collaborative model training without sharing raw user data, but conventional simulations often rely on unrealistic data partitioning and current user selection methods ignore data correlation among users. To address these challenges, this paper proposes a metadatadriven FL framework. We first introduce a novel data partition model based on a homogeneous Poisson point process (HPPP), capturing both heterogeneity in data quantity and natural overlap among user datasets. Building on this model, we develop a clustering-based user selection strategy that leverages metadata, such as user location, to reduce data correlation and enhance label diversity across training rounds. Extensive experiments on FMNIST and CIFAR-10 demonstrate that the proposed framework improves model performance, stability, and convergence in non-IID scenarios, while maintaining comparable performance under IID settings. Furthermore, the method shows pronounced advantages when the number of selected users per round is small. These findings highlight the framework's potential for enhancing FL performance in realistic deployments and guiding future standardization.

</details>


### [7] [Microwave Linear Analog Computer (MiLAC)-aided Multiuser MISO: Fundamental Limits and Beamforming Design](https://arxiv.org/abs/2601.10060)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文研究了微波线性模拟计算机（MiLAC）辅助的波束成形技术，证明了其在巨型MIMO系统中能实现接近数字波束成形的性能，同时硬件复杂度更低。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信系统向6G演进，巨型MIMO成为关键技术，但面临可扩展性挑战。MiLAC作为一种全模拟域波束成形方法，有望解决传统数字和模拟波束成形的局限性。

Method: 首先严格表征MiLAC可实现的波束成形矩阵集合，证明其灵活性介于数字波束成形和传统移相器模拟波束成形之间。提出混合数字-MiLAC架构，将MiLAC相关约束重构为凸线性矩阵不等式，建立低维子空间特性降低问题维度，并设计WMMSE算法求解。

Result: MiLAC辅助波束成形在巨型MIMO系统中性能接近数字波束成形。相比混合波束成形，在避免符号级数字处理和使用低分辨率DAC的情况下，实现了相当或更优的性能，同时硬件和计算复杂度更低。

Conclusion: MiLAC辅助波束成形是6G巨型MIMO系统的有前景解决方案，在性能和复杂度之间取得了良好平衡，特别适合大规模天线阵列应用。

Abstract: As wireless communication systems evolve toward the 6G era, ultra-massive/gigantic MIMO is envisioned as a key enabling technology. Recently, microwave linear analog computer (MiLAC) has emerged as a promising approach to realize beamforming entirely in the analog domain, thereby alleviating the scalability challenges associated with gigantic MIMO. In this paper, we investigate the fundamental beamforming flexibility and design of lossless and reciprocal MiLAC-aided beamforming for MU-MISO systems. We first provide a rigorous characterization of the set of beamforming matrices achievable by MiLAC. Based on this characterization, we prove that MiLAC-aided beamforming does not generally achieve the full flexibility of digital beamforming, while offering greater flexibility than conventional phase-shifter-based analog beamforming. Furthermore, we propose a hybrid digital-MiLAC architecture and show that it achieves digital beamforming flexibility when the number of radio frequency (RF) chains equals the number of data streams, halving that required by conventional hybrid beamforming. We then formulate the MiLAC-aided sum-rate maximization problem for MU-MISO systems. To solve the problem efficiently, we reformulate the MiLAC-related constraints as a convex linear matrix inequality and establish a low-dimensional subspace property that significantly reduces the problem dimension. Leveraging these results, we propose WMMSE-based algorithms for solving the resulting problem. Simulation results demonstrate that MiLAC-aided beamforming achieves performance close to that of digital beamforming in gigantic MIMO systems. Compared with hybrid beamforming, it achieves comparable or superior performance with lower hardware and computational complexity by avoiding symbol-level digital processing and enabling low-resolution digital-to-analog converters (DACs).

</details>


### [8] [P-norm based Fractional-Order Robust Subband Adaptive Filtering Algorithm for Impulsive Noise and Noisy Input](https://arxiv.org/abs/2601.10074)
*Jianhong Ye,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: 提出了一种结合分数阶随机梯度下降的分数阶NSPN算法，用于在α稳定噪声环境下提高鲁棒性，特别是在0<α≤1的严重脉冲噪声中。


<details>
  <summary>Details</summary>
Motivation: 现有的NSPN算法在1<α≤2的α稳定噪声环境中表现良好，但在0<α≤1的严重脉冲噪声或噪声输入情况下性能显著下降，需要改进算法以应对这些挑战。

Method: 将分数阶随机梯度下降方法整合到MPE框架中，提出分数阶NSPN算法，并分析了步长的收敛范围、分数阶β的理论值域，建立了理论稳态均方偏差模型。

Result: 在不同脉冲噪声环境下的仿真实验证实，提出的FoNSPN算法优于现有的最先进算法。

Conclusion: FoNSPN算法通过引入分数阶方法，有效解决了NSPN在严重脉冲噪声环境下的性能退化问题，提供了更鲁棒的信号处理解决方案。

Abstract: Building upon the mean p-power error (MPE) criterion, the normalized subband p-norm (NSPN) algorithm demonstrates superior robustness in $α$-stable noise environments ($1 < α\leq 2$) through effective utilization of low-order moment hidden in robust loss functions. Nevertheless, its performance degrades significantly when processing noise input or additive noise characterized by $α$-stable processes ($0 < α\leq 1$). To overcome these limitations, we propose a novel fractional-order NSPN (FoNSPN) algorithm that incorporates the fractional-order stochastic gradient descent (FoSGD) method into the MPE framework. Additionally, this paper also analyzes the convergence range of its step-size, the theoretical domain of values for the fractional-order $β$, and establishes the theoretical steady-state mean square deviation (MSD) model. Simulations conducted in diverse impulsive noise environments confirm the superiority of the proposed FoNSPN algorithm against existing state-of-the-art algorithms.

</details>


### [9] [Service Provisioning and Path Planning with Obstacle Avoidance for Low-Altitude Wireless Networks](https://arxiv.org/abs/2601.10179)
*Senning Wan,Bin Li,Hongbin Chen,Lei Liu*

Main category: eess.SP

TL;DR: 本文研究在异构通信网络中，考虑地面障碍物约束下，无人机作为空中基站的3D部署问题，通过联合优化无人机轨迹、波束成形和用户关联来最大化用户满意度。


<details>
  <summary>Details</summary>
Motivation: 异构通信网络中，无人机作为空中基站部署面临地面障碍物、用户数据需求多样化、无人机电池耗尽等约束，需要提供个性化服务并确保服务质量。

Method: 采用块坐标下降法将问题分解为两个子问题：波束成形子问题使用基于二分法的注水算法；轨迹和关联子问题设计基于近端策略优化的深度强化学习算法。

Result: 仿真结果表明，所提方案在收敛速度和整体系统性能上优于基准方案，实现了高效的用户关联和准确的障碍物避让。

Conclusion: 该研究提出了一种有效的3D无人机部署方案，能够在复杂障碍物环境下最大化用户满意度，为异构网络中的无人机通信提供了实用解决方案。

Abstract: This paper investigates the three-dimensional (3D) deployment of uncrewed aerial vehicles (UAVs) as aerial base stations in heterogeneous communication networks under constraints imposed by diverse ground obstacles. Given the diverse data demands of user equipments (UEs), a user satisfaction model is developed to provide personalized services. In particular, when a UE is located within a ground obstacle, the UAV must approach the obstacle boundary to ensure reliable service quality. Considering constraints such as UAV failures due to battery depletion, heterogeneous UEs, and obstacles, we aim to maximize overall user satisfaction by jointly optimizing the 3D trajectories of UAVs, transmit beamforming vectors, and binary association indicators between UAVs and UEs. To address the complexity and dynamics of the problem, a block coordinate descent method is adopted to decompose it into two subproblems. The beamforming subproblem is efficiently addressed via a bisection-based water-filling algorithm. For the trajectory and association subproblem, we design a deep reinforcement learning algorithm based on proximal policy optimization to learn an adaptive control policy. Simulation results demonstrate that the proposed scheme outperforms baseline schemes in terms of convergence speed and overall system performance. Moreover, it achieves efficient association and accurate obstacle avoidance.

</details>


### [10] [BeamCKMDiff: Beam-Aware Channel Knowledge Map Construction via Diffusion Transformer](https://arxiv.org/abs/2601.10207)
*Le Zhao,Yining Wang,Xinyi Wang,Zesong Fei,Yong Zeng*

Main category: eess.SP

TL;DR: BeamCKMDiff：基于扩散变换器的生成框架，无需站点特定采样即可构建高保真信道知识地图，支持任意连续波束赋形向量


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方法依赖稀疏采样测量，仅限于全向地图或离散码本，无法充分利用波束赋形增益。需要一种能够处理任意连续波束赋形向量的高保真CKM构建方法。

Method: 提出BeamCKMDiff生成框架，在扩散变换器(DiT)的噪声预测网络中引入自适应层归一化(adaLN)机制，将连续波束嵌入作为全局控制参数注入，引导生成过程捕捉波束模式与环境几何之间的复杂耦合关系。

Result: 仿真结果表明BeamCKMDiff显著优于现有基线方法，在主瓣和旁瓣的重建精度方面表现优异。

Conclusion: BeamCKMDiff为6G网络提供了一种无需站点特定采样即可构建高保真信道知识地图的有效解决方案，能够支持任意连续波束赋形向量，有望显著提升环境感知网络的性能。

Abstract: Channel knowledge map (CKM) is emerging as a critical enabler for environment-aware 6G networks, offering a site-specific database to significantly reduce pilot overhead. However, existing CKM construction methods typically rely on sparse sampling measurements and are restricted to either omnidirectional maps or discrete codebooks, hindering the exploitation of beamforming gain. To address these limitations, we propose BeamCKMDiff, a generative framework for constructing high-fidelity CKMs conditioned on arbitrary continuous beamforming vectors without site-specific sampling. Specifically, we incorporate a novel adaptive layer normalization (adaLN) mechanism into the noise prediction network of the Diffusion Transformer (DiT). This mechanism injects continuous beam embeddings as {global control parameters}, effectively steering the generative process to capture the complex coupling between beam patterns and environmental geometries. Simulation results demonstrate that BeamCKMDiff significantly outperforms state-of-the-art baselines, achieving superior reconstruction accuracy in capturing main lobes and side lobes.

</details>


### [11] [Sim2Real Deep Transfer for Per-Device CFO Calibration](https://arxiv.org/abs/2601.10264)
*Jingze Zheng,Zhiguo Shi,Shibo He,Chaojie Gu*

Main category: eess.SP

TL;DR: 提出Sim2Real迁移学习框架，通过仿真预训练和轻量级接收器适配，实现跨不同SDR设备的CFO校准，显著提升OFDM系统性能


<details>
  <summary>Details</summary>
Motivation: OFDM系统中的载波频率偏移估计在不同SDR平台间存在性能下降问题，现有基于深度神经网络的方法缺乏设备级适配能力，限制了实际部署

Method: 采用Sim2Real迁移学习框架：1）在包含参数化硬件失真的合成OFDM信号上预训练骨干DNN；2）仅对回归层进行微调，每个目标设备仅需1000个真实帧

Result: 在三种SDR设备（USRP B210、USRP N210、HackRF One）上实验，相比传统CP方法在室内多径条件下实现了30倍的误码率降低

Conclusion: 该框架弥合了仿真与现实的差距，为异构无线系统中的CFO估计提供了成本效益高的部署方案

Abstract: Carrier Frequency Offset (CFO) estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems faces significant performance degradation across heterogeneous software-defined radio (SDR) platforms due to uncalibrated hardware impairments. Existing deep neural network (DNN)-based approaches lack device-level adaptation, limiting their practical deployment. This paper proposes a Sim2Real transfer learning framework for per-device CFO calibration, combining simulation-driven pretraining with lightweight receiver adaptation. A backbone DNN is pre-trained on synthetic OFDM signals incorporating parametric hardware distortions (e.g., phase noise, IQ imbalance), enabling generalized feature learning without costly cross-device data collection. Subsequently, only the regression layers are fine-tuned using $1,000$ real frames per target device, preserving hardware-agnostic knowledge while adapting to device-specific impairments. Experiments across three SDR families (USRP B210, USRP N210, HackRF One) achieve $30\times$ BER reduction compared to conventional CP-based methods under indoor multipath conditions. The framework bridges the simulation-to-reality gap for robust CFO estimation, enabling cost-effective deployment in heterogeneous wireless systems.

</details>


### [12] [Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications](https://arxiv.org/abs/2601.10331)
*Hanyoung Park,Ji-Woong Choi*

Main category: eess.SP

TL;DR: 提出一种用于毫米波通信的盲估计器，无需导频信号即可估计噪声功率、信号功率、SNR和MSE，计算复杂度低


<details>
  <summary>Details</summary>
Motivation: 毫米波信道快速波动导致传统基于导频的估计方法精度下降，现有盲估计算法计算复杂度高，难以用于实时服务

Method: 利用毫米波信道在波束域中的固有稀疏性，使信号和噪声功率分量更易区分，设计无需真实信号知识且计算复杂度低的盲估计器

Result: 提出了能够估计平均噪声功率、信号功率、SNR和MSE的盲估计算法，避免了高计算复杂度问题

Conclusion: 该方法为毫米波通信系统提供了一种高效、低复杂度的盲估计解决方案，增强了系统对动态环境变化的鲁棒性

Abstract: To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that operate without pilot have been considered as potential solutions. However, these algorithms often involve a training phase for machine learning or a large number of iterations, which implies prohibitive computational complexity, making them difficult to employ for real-time services and the system less resilient to dynamic environment variation. In this paper, we propose blind estimators for average noise power, signal power, SNR, and mean-square error (MSE) that do not require knowledge of the ground-truth signal or involve high computational complexity. The proposed algorithm leverages the inherent sparsity of mmWave channel in beamspace domain, which makes the signal and noise power components more distinguishable.

</details>


### [13] [Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis](https://arxiv.org/abs/2601.10576)
*Shaohua Yue,Siyu Miao,Shuhao Zeng,Fenghan Lin,Boya Di*

Main category: eess.SP

TL;DR: 该论文将特征模分析(CMA)引入6G大规模MIMO系统的自由度分析，考虑了天线激励和辐射特性对系统独立数据流数量的影响，并提出基于CMA的遗传算法优化可重构全息表面天线以提升自由度。


<details>
  <summary>Details</summary>
Motivation: 现有MIMO自由度分析主要关注无线信道特性，而忽略了天线激励和辐射特性对系统独立数据流数量的影响。在6G大规模MIMO系统中，天线特性对系统性能至关重要，需要更全面的自由度分析框架。

Method: 1) 使用特征模分析(CMA)建模收发天线激励和辐射特性；2) 建立基于CMA的自由度分析框架并推导可实现自由度；3) 构建天线特征模优化问题以最大化自由度；4) 针对可重构全息表面(RHS)天线案例，提出基于CMA的遗传算法优化天线配置。

Result: 通过改变RHS天线的特征模电场和表面电流分布，系统可实现自由度得到增强。全波仿真验证了理论分析，并表明基于所提算法的RHS重构能够有效提升系统自由度。

Conclusion: 特征模分析为大规模MIMO系统自由度分析提供了更全面的框架，考虑了天线特性对系统性能的影响。通过优化天线特征模配置，可以有效提升系统可实现自由度，为6G通信系统设计提供了新思路。

Abstract: Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communication of a MIMO system. Specifically, we model the excitation and radiation properties of transceiver antennas using CMA to analyze the excitation and radiation properties of antennas. The CMA-based DoF analysis framework is established and the achievable DoF is derived. A characteristic mode optimization problem of antennas is then formulated to maximize the achievable DoF. A case study where the reconfigurable holographic surface (RHS) antennas are deployed at the transceiver is investigated, and a CMA-based genetic algorithm is later proposed to solve the above problem. By changing the characteristic modes electric field and surface current distribution of RHS, the achievable DoF is enhanced. Full-wave simulation verifies the theoretical analysis on the the achievable DoF and shows that, via the reconfiguration of RHS based on the proposed algorithm, the achievable DoF is improved.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [14] [High signal-to-noise ratio asymptotics of entropy-constrained Gaussian channel capacity](https://arxiv.org/abs/2601.09864)
*Adway Girish,Shlomo Shamai,Emre Telatar*

Main category: cs.IT

TL;DR: 研究高斯信道在渐近高信噪比下的输入熵约束容量问题，发现最优分布是离散高斯分布，熵与容量差距随SNR指数衰减


<details>
  <summary>Details</summary>
Motivation: 研究高斯信道在输入熵约束下的容量问题，特别是在高信噪比渐近情况下的最优输入分布特性

Method: 分析高斯信道在高信噪比渐近情况下的容量问题，推导最优输入分布形式

Result: 当SNR趋于无穷时，容量达到分布是支撑在缩放整数格上的离散高斯分布，输入熵与容量差距随SNR指数衰减

Conclusion: 在高信噪比渐近情况下，高斯信道输入熵约束容量问题有离散高斯分布解，熵与容量差距呈指数衰减

Abstract: We study the input-entropy-constrained Gaussian channel capacity problem in the asymptotic high signal-to-noise ratio (SNR) regime. We show that the capacity-achieving distribution as SNR goes to infinity is given by a discrete Gaussian distribution supported on a scaled integer lattice. Further, we show that the gap between the input entropy and the capacity decreases to zero exponentially in SNR, and characterize this exponent.

</details>


### [15] [One-Cold Poisson Channel: A Simple Continuous-Time Channel with Zero Dispersion](https://arxiv.org/abs/2601.09894)
*Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文介绍了一种新型信道模型——单冷泊松信道（OCPC），其中发射机每次选择衰减一个频带。完美OCPC具有容量1、零信道色散和简并的信息谱分布，是唯一已知具有闭式最优非渐近错误概率公式的非平凡无记忆信道。


<details>
  <summary>Details</summary>
Motivation: 研究动机是建立一种极其简单的连续时间无记忆信道模型，该模型具有闭式最优非渐近错误概率公式，可作为信息的基本计量单位（替代比特），并应用于可调谐带阻滤波器的光通信。

Method: 提出单冷泊松信道（OCPC）模型，其中发射机在多个频带中选择一个进行衰减。研究完美OCPC（无限频带数）的特性，分析其容量、信道色散和信息谱分布。研究一般OCPC的非渐近编码和信道仿真。

Result: 完美OCPC具有容量1、零信道色散，信息谱分布为在1处的简并分布。它是唯一已知具有闭式最优非渐近错误概率公式的非平凡（离散或连续时间）无记忆信道。OCPC与完美反馈结合可推广前缀码。

Conclusion: OCPC是一种极其简单的连续时间无记忆信道模型，可作为无限可分的信息基本计量单位（替代比特），在光通信等领域有潜在应用价值，并为非渐近编码理论提供了新的研究工具。

Abstract: We introduce the one-cold Poisson channel (OCPC), where the transmitter chooses one of several frequency bands to attenuate at a time. In particular, the perfect OCPC, where the number of bands is unlimited, is an extremely simple continuous-time memoryless channel. It has a capacity 1, zero channel dispersion, and an information spectrum being the degenerate distribution at 1. It is the only known nontrivial (discrete or continuous-time) memoryless channel with a closed-form formula for its optimal non-asymptotic error probability, making it the simplest channel in this sense. A potential application is optical communication with a tunable band rejection filter. Due to its simplicity, we may use it as a basic currency of information that is infinitely divisible, as an alternative to bits which are not infinitely divisible. OCPC with perfect feedback gives a generalization of prefix codes. We also study non-asymptotic coding and channel simulation results for the general OCPC.

</details>


### [16] [Learning-Augmented Perfectly Secure Collaborative Matrix Multiplication](https://arxiv.org/abs/2601.09916)
*Zixuan He,Mohammad Reza Deylam Salehi,Derya Malak,Photios A. Stavrou*

Main category: cs.IT

TL;DR: 提出了一种用于多方计算中矩阵乘法AᵀB的完美安全协议，保证信息论隐私和正确性，并引入了学习增强扩展以提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 在多方计算中实现矩阵乘法时，需要在保证完美安全性的同时提高计算效率，特别是在大规模矩阵维度下。

Method: 使用稀疏掩码多项式编码子矩阵，结合系数对齐和Beaver式随机性确保完美保密；并引入基于张量分解的本地块乘法学习增强扩展。

Result: 协议在安全阈值下提供均匀随机共享，恢复阈值达到最优；学习增强版本在保持隐私和恢复保证的同时，在矩阵维度增长时提供高达80%的计算效率提升。

Conclusion: 提出的PSMM协议在多方计算中实现了信息论安全的矩阵乘法，并通过学习增强方法在保持安全性的同时显著提高了计算效率。

Abstract: This paper presents a perfectly secure matrix multiplication (PSMM) protocol for multiparty computation (MPC) of $\mathrm{A}^{\top}\mathrm{B}$ over finite fields. The proposed scheme guarantees correctness and information-theoretic privacy against threshold-bounded, semi-honest colluding agents, under explicit local storage constraints. Our scheme encodes submatrices as evaluations of sparse masking polynomials and combines coefficient alignment with Beaver-style randomness to ensure perfect secrecy. We demonstrate that any colluding set of parties below the security threshold observes uniformly random shares, and that the recovery threshold is optimal, matching existing information-theoretic limits. Building on this framework, we introduce a learning-augmented extension that integrates tensor-decomposition-based local block multiplication, capturing both classical and learned low-rank methods. We demonstrate that the proposed learning-based PSMM preserves privacy and recovery guarantees for MPC, while providing scalable computational efficiency gains (up to $80\%$) as the matrix dimensions grow.

</details>


### [17] [Reconstructing Reed-Solomon Codes from Multiple Noisy Channel Outputs](https://arxiv.org/abs/2601.09947)
*Shubhransh Singhvi,Han Mao Kiah,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究序列重构问题中，针对q元离散无记忆对称替换信道，提出基于Reed-Solomon码的高效重构算法，并推导出明确的速率阈值。


<details>
  <summary>Details</summary>
Motivation: Levenshtein在2001年提出的序列重构问题中，发送方传输码字，接收方观察到K个独立的噪声版本。本研究旨在解决当每个输出被q元离散无记忆对称替换信道污染时的高效重构问题。

Method: 针对Reed-Solomon码，将Koetter-Vardy软判决译码算法进行适配，开发出高效的重构算法。对于足够大的分组长度和字母表大小，推导出明确的速率阈值。

Result: 当码率R低于该阈值时，可以以任意小的错误概率重构传输的码字。阈值仅依赖于(p, K)参数。

Conclusion: 成功开发了针对Reed-Solomon码在q元离散无记忆对称替换信道下的高效序列重构算法，并建立了明确的速率阈值理论保证。

Abstract: The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a communication setting in which a sender transmits a codeword and the receiver observes K independent noisy versions of this codeword. In this work, we study the problem of efficient reconstruction when each of the $K$ outputs is corrupted by a $q$-ary discrete memoryless symmetric (DMS) substitution channel with substitution probability $p$. Focusing on Reed-Solomon (RS) codes, we adapt the Koetter-Vardy soft-decision decoding algorithm to obtain an efficient reconstruction algorithm. For sufficiently large blocklength and alphabet size, we derive an explicit rate threshold, depending only on $(p, K)$, such that the transmitted codeword can be reconstructed with arbitrarily small probability of error whenever the code rate $R$ lies below this threshold.

</details>


### [18] [Private Information Retrieval for Graph-based Replication with Minimal Subpacketization](https://arxiv.org/abs/2601.09957)
*Vayur Shanbhag,Prasad Krishnan*

Main category: cs.IT

TL;DR: 提出两种新的基于图复制数据库的最小子分组私有信息检索方案：星图方案和通用图方案，均实现单位子分组（最小化），在特定图类上优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 在基于图复制的私有信息检索系统中，需要在保持高检索率的同时降低子分组复杂度。现有方案在子分组大小和检索率之间存在权衡，需要设计更优的方案。

Method: 1. 针对星图设计专用方案；2. 针对通用图使用独立集分解方法；3. 扩展到多重图情况。

Result: 1. 星图方案在一般星图上比现有低子分组方案有更高检索率；2. 通用图方案在完全图上检索率低于现有方案，但在某些特定图类上可实现更高检索率；3. 多重图扩展方案在完全多重图上比现有方案有更高检索率。

Conclusion: 提出的两种单位子分组方案在不同图类上改进了私有信息检索的性能，星图方案在星图上表现更优，通用图方案通过独立集分解在特定图类上实现优势，多重图扩展进一步提升了完全多重图的性能。

Abstract: We design new minimal-subpacketization schemes for information-theoretic private information retrieval on graph-based replicated databases. In graph-based replication, the system consists of $K$ files replicated across $N$ servers according to a graph with $N$ vertices and $K$ edges. The client wants to retrieve one desired file, while keeping the index of the desired file private from each server via a query-response protocol. We seek PIR protocols that have (a) high rate, which is the ratio of the file-size to the total download cost, and (b) low subpacketization, which acts as a constraint on the size of the files for executing the protocol. We report two new schemes which have unit-subpacketization (which is minimal): (i) for a special class of graphs known as star graphs, and (ii) for general graphs. Our star-graph scheme has a better rate than previously known schemes with low subpacketization for general star graphs. Our scheme for general graphs uses a decomposition of the graph via independent sets. This scheme achieves a rate lower than prior schemes for the complete graph, however it can achieve higher rates than known for some specific graph classes. An extension of our scheme to the case of multigraphs achieves a higher rate than previous schemes for the complete multi-graph.

</details>


### [19] [On the Leaky Private Information Retrieval with Side Information](https://arxiv.org/abs/2601.09960)
*Yingying Huangfu,Tian Bai*

Main category: cs.IT

TL;DR: 本文研究了带侧信息的泄露隐私私有信息检索（L-PIR-SI）问题，通过放宽完美隐私要求来提升通信效率，建立了统一的概率框架量化隐私泄露，并揭示了泄露、侧信息和检索效率之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有的PIR-SI研究主要关注完美隐私保护，但在实际应用中，完全隐私保护往往导致通信效率低下。本文旨在探索在可控信息泄露条件下，如何利用侧信息来提升通信效率，填补了隐私泄露与侧信息结合的研究空白。

Method: 提出了统一的概率框架来构建L-PIR-SI方案，使用参数ε量化隐私泄露（符合差分隐私标准）。通过该框架分析可实现的下载成本，并将结果推广到多种PIR场景。

Result: 建立了泄露、侧信息和检索效率之间的权衡关系。当ε→0时恢复PIR-SI的容量；当无侧信息时退化为已知的泄露-PIR边界。这是首次系统研究这三者之间的权衡关系。

Conclusion: 本文首次系统研究了带侧信息的泄露隐私私有信息检索问题，建立了统一的框架来分析隐私泄露、侧信息和通信效率之间的权衡，为实际应用中平衡隐私保护和效率提供了理论基础。

Abstract: This paper investigates the problem of leaky-private Private Information Retrieval with Side Information (L-PIR-SI), which relaxes the requirement of perfect privacy to achieve improved communication efficiency in the presence of side information. While the capacities of PIR-SI under both $W$-privacy and $(W,S)$-privacy have been partially explored, the impact of controlled information leakage in these settings remains unaddressed. We propose a unified probabilistic framework to construct L-PIR-SI schemes where the privacy leakage is quantified by a parameter $\varepsilon$, consistent with differential privacy standards. We characterize the achievable download costs and show that our results generalize several landmark results in the PIR literature: they recover the capacity of PIR-SI when $\varepsilon \to 0$, and reduce to the known bounds for leaky-PIR when side information is absent. This work provides the first look at the trade-offs between leakage, side information, and retrieval efficiency.

</details>


### [20] [Fundamental Limits of Coded Polynomial Aggregation](https://arxiv.org/abs/2601.10028)
*Xi Zhong,Jörg Kliewer,Mingyue Ji*

Main category: cs.IT

TL;DR: 将编码多项式聚合(CPA)扩展到含掉队者的分布式计算系统，提出基于预设非掉队模式的CPA框架，建立了精确恢复的充要条件，并证明了当非掉队集合足够多时，交集大小阈值是必要且充分的。


<details>
  <summary>Details</summary>
Motivation: 现有CPA方法在含掉队者的分布式系统中效率不足，需要减少所需的worker响应数量，同时保证精确恢复加权聚合结果。

Method: 扩展CPA到含掉队者的分布式计算系统，引入基于预设非掉队模式的CPA框架，建立精确恢复的充要条件，识别交集大小阈值，并提供可行的CPA方案构造方法。

Result: 证明了精确恢复所需worker响应少于基于个体解码的多项式编码计算，可行性由非掉队模式的交集结构决定，建立了交集大小阈值，并证明了当非掉队集合足够多时该阈值是必要且充分的。

Conclusion: 提出的CPA框架能有效减少含掉队者分布式系统中的worker响应需求，通过交集大小阈值提供了实用的可行性判断标准，仿真验证了阈值的紧致性。

Abstract: Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice.

</details>


### [21] [Optimal Proximity Gap for Folded Reed--Solomon Codes via Subspace Designs](https://arxiv.org/abs/2601.10047)
*Fernando Granha Jeronimo,Lenny Liu,Pranav Rajpal*

Main category: cs.IT

TL;DR: 该论文研究了折叠里德-所罗门码的邻近间隙性质，证明了在最优容量范围内存在(δ,ε)-邻近间隙


<details>
  <summary>Details</summary>
Motivation: 研究折叠里德-所罗门码是否能在最优容量范围内展示类似于仿射子空间的(δ,ε)-邻近间隙性质

Method: 利用折叠里德-所罗门码的列表解码算法，将框架扩展到适合的子空间设计码

Result: 肯定地回答了研究问题，证明了折叠里德-所罗门码在最优容量范围内确实存在(δ,ε)-邻近间隙

Conclusion: 折叠里德-所罗门码具有与仿射子空间类似的邻近间隙性质，且该框架可推广到合适的子空间设计码

Abstract: A collection of sets satisfies a $(δ,\varepsilon)$-proximity gap with respect to some property if for every set in the collection, either (i) all members of the set are $δ$-close to the property in (relative) Hamming distance, or (ii) only a small $\varepsilon$-fraction of members are $δ$-close to the property.
  In a seminal work, Ben-Sasson \textit{et al.}\ showed that the collection of affine subspaces exhibits a $(δ,\varepsilon)$-proximity gap with respect to the property of being Reed--Solomon (RS) codewords with $δ$ up to the so-called Johnson bound for list decoding. Their technique relies on the Guruswami--Sudan list decoding algorithm for RS codes, which is guaranteed to work in the Johnson bound regime.
  Folded Reed--Solomon (FRS) codes are known to achieve the optimal list decoding radius $δ$, a regime known as capacity. Moreover, a rich line of list decoding algorithms was developed for FRS codes. It is then natural to ask if FRS codes can be shown to exhibit an analogous $(δ,\varepsilon)$-proximity gap, but up to the so-called optimal capacity regime. We answer this question in the affirmative (and the framework naturally applies more generally to suitable subspace-design codes).
  An additional motivation to understand proximity gaps for FRS codes is the recent results [BCDZ'25] showing that they exhibit properties similar to random linear codes, which were previously shown to be related to properties of RS codes with random evaluation points in [LMS'25], as well as codes over constant-size alphabet based on AEL [JS'25].

</details>


### [22] [Function Correcting Codes for Maximally-Unbalanced Boolean Functions](https://arxiv.org/abs/2601.10135)
*Rajlaxmi Pandey,Shiven Bajpai,Anjana A Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 研究针对最大不平衡布尔函数的最优单错误纠正函数纠正码，分析其距离矩阵结构对AWGN信道下误码性能的影响。


<details>
  <summary>Details</summary>
Motivation: 函数纠正码允许在噪声信道上可靠计算函数而无需完全恢复消息，但现有研究对最优单错误纠正FCC的结构及其对性能影响的理解有限。

Method: 通过关联码字距离矩阵分析最优SEFCC结构，识别不同FCC类别，在AWGN信道上评估软判决和硬判决解码的性能差异。

Result: 不同距离矩阵结构的FCC在数据误码率和函数错误行为上表现显著不同，代码结构的影响强烈依赖于解码策略。

Conclusion: 函数纠正码的性能不仅取决于纠错能力，还受其距离矩阵结构和解码策略的显著影响，这为设计特定应用的FCC提供了重要指导。

Abstract: Function-Correcting Codes (FCCs) enable reliable computation of a function of a $k$-bit message over noisy channels without requiring full message recovery. In this work, we study optimal single-error correcting FCCs (SEFCCs) for maximally-unbalanced Boolean functions, where $k$ denotes the message length and $t$ denotes the error-correction capability. We analyze the structure of optimal SEFCC constructions through their associated codeword distance matrices and identify distinct FCC classes based on this structure. We then examine the impact of these structural differences on error performance by evaluating representative FCCs over the additive white Gaussian noise (AWGN) channel using both soft-decision and hard-decision decoding. The results show that FCCs with different distance-matrix structures can exhibit markedly different Data BER and function error behavior, and that the influence of code structure depends strongly on the decoding strategy.

</details>


### [23] [On Existence of Girth-8 QC-LDPC Code with Large Column Weight: Combining Mirror-sequence with Classification Modulo Ten](https://arxiv.org/abs/2601.10170)
*Guohua Zhang,Xiangya Liu,Jianhua Zhang,Yi Fang*

Main category: cs.IT

TL;DR: 本文在GCD框架下，通过引入镜像序列和新行重组方案，代数构造了列重为7和8、码长极短、围长为8的QC-LDPC码，将连续循环子阵大小的下界提升了约20%。


<details>
  <summary>Details</summary>
Motivation: 构造具有大围长和短码长的准循环LDPC码在信道编码、压缩感知和分布式存储系统中至关重要。现有方法主要依赖搜索，而代数方法构造列重7和8的短码长QC-LDPC码仍面临挑战。

Method: 在先前提出的GCD框架基础上，引入镜像序列概念，采用新的行重组方案，以纯代数方式构造列重为7和8的QC-LDPC码，确保围长为8。

Result: 成功构造出列重7和8、码长极短、围长为8的QC-LDPC码。与现有基准相比，连续循环子阵大小的下界提升了约20%，实际构造的循环子阵大小比新下界还小约25%。

Conclusion: 提出的代数方法有效解决了构造列重7和8的短码长QC-LDPC码问题，显著改善了码构造性能，为相关应用提供了更优的码设计方案。

Abstract: Quasi-cyclic (QC) LDPC codes with large girths play a crucial role in several research and application fields, including channel coding, compressed sensing and distributed storage systems. A major challenge in respect of the code construction is how to obtain such codes with the shortest possible length (or equivalently, the smallest possible circulant size) using algebraic methods instead of search methods. The greatest-common-divisor (GCD) framework we previously proposed has algebraically constructed QC-LDPC codes with column weights of 5 and 6, very short lengths, and a girth of 8. By introducing the concept of a mirror sequence and adopting a new row-regrouping scheme, QC-LDPC codes with column weights of 7 and 8, very short lengths, and a girth of 8 are proposed for arbitrary row weights in this article via an algebraic manner under the GCD framework. Thanks to these novel algebraic methods, the lower bounds (for column weights 7 and 8) on consecutive circulant sizes are both improved by asymptotically about 20%, compared with the existing benchmarks. Furthermore, these new constructions can also offer circulant sizes asymptotically about 25% smaller than the novel bounds.

</details>


### [24] [A Low-Complexity Architecture for Multi-access Coded Caching Systems with Arbitrary User-cache Access Topology](https://arxiv.org/abs/2601.10175)
*Ting Yang,Minquan Cheng,Xinping Yi,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文提出了一种基于图神经网络的通用学习框架，用于解决任意用户-缓存访问拓扑下的多接入编码缓存问题，在保持接近最优传输负载的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有MACC模型依赖于高度结构化的连接设计，无法处理任意用户-缓存访问拓扑。传统DSatur算法虽然性能接近最优，但在大规模图上计算复杂度过高，需要开发更高效的通用解决方案。

Method: 1) 提出基于图的通用框架，将解码冲突建模为冲突图，传输设计简化为图着色问题；2) 开发基于图神经网络的学习框架，高效构建近最优编码多播传输；3) 将索引编码下界扩展到任意访问拓扑，并提出低复杂度贪心近似。

Result: 学习方案在传输负载上接近DSatur算法和下界，同时显著减少计算时间。数值结果表明该方法在不同访问拓扑和用户数量下具有良好的泛化能力。

Conclusion: 提出的学习框架为任意拓扑MACC问题提供了高效解决方案，在保持接近最优性能的同时大幅降低计算复杂度，具有实际应用价值。

Abstract: This paper studies the multi-access coded caching (MACC) problem under arbitrary user-cache access topologies, extending existing models that rely on highly structured and combinatorially designed connectivity. We consider a MACC system consisting of a single server, multiple cache nodes, and multiple user nodes. Each user can access an arbitrary subset of cache nodes to retrieve cached content. The objective is to design a general and low-complexity delivery scheme under fixed cache placement for arbitrary access topologies. We propose a universal graph-based framework for modeling the MACC delivery problem, where decoding conflicts among requested packets are captured by a conflict graph and the delivery design is reduced to a graph coloring problem. In this formulation, a lower transmission load corresponds to using fewer colors. The classical greedy coloring algorithm DSatur achieves a transmission load close to the index-coding converse bound, providing a tight benchmark, but its computational complexity becomes prohibitive for large-scale graphs. To overcome this limitation, we develop a learning-based framework using graph neural networks that efficiently constructs near-optimal coded multicast transmissions and generalizes across diverse access topologies and varying numbers of users. In addition, we extend the index-coding converse bound for uncoded cache placement to arbitrary access topologies and propose a low-complexity greedy approximation. Numerical results demonstrate that the proposed learning-based scheme achieves transmission loads close to those of DSatur and the converse bound while significantly reducing computational time.

</details>


### [25] [Error-Correcting Codes for the Sum Channel](https://arxiv.org/abs/2601.10256)
*Lyan Abboud,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出了一种新的信道模型——求和信道，用于分布式存储和DNA数据存储，构建了能纠正两个删除的编码方案，并证明了其冗余度接近最优。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机源于分布式存储和DNA数据存储应用中的实际需求。在这些场景中，数据通常以矩阵形式存储，需要设计能够有效纠正删除错误的编码方案，同时保持较低的冗余度。

Method: 论文引入了求和信道模型，该模型将ℓ行二进制矩阵作为输入，输出(ℓ+1)行矩阵，其中前ℓ行等于输入，最后一行是前ℓ行的奇偶校验行。作者构建了能够纠正两个删除的编码方案，其冗余度为2⌈log₂log₂n⌉ + O(ℓ²)。对于ℓ=2的情况，建立了⌈log₂log₂n⌉ + O(1)的上界。此外，还提出了纠正单个替换错误的编码方案，冗余度为⌈log₂(ℓ+1)⌉。

Result: 1. 构建了能够纠正两个删除的编码方案，冗余度为2⌈log₂log₂n⌉ + O(ℓ²)
2. 当ℓ=2时，证明了编码方案的冗余度上界为⌈log₂log₂n⌉ + O(1)，表明所提方案在因子2范围内是最优的
3. 提出了纠正单个替换错误的编码方案，冗余度为⌈log₂(ℓ+1)⌉，并证明该方案与最优解仅相差1比特

Conclusion: 论文成功引入了求和信道模型，并为其设计了高效的纠错编码方案。所提出的两删除纠正编码在冗余度上接近理论最优，而单替换纠正编码几乎达到最优性能。这些结果为分布式存储和DNA数据存储应用提供了实用的编码解决方案。

Abstract: We introduce the sum channel, a new channel model motivated by applications in distributed storage and DNA data storage. In the error-free case, it takes as input an $\ell$-row binary matrix and outputs an $(\ell+1)$-row matrix whose first $\ell$ rows equal the input and whose last row is their parity (sum) row. We construct a two-deletion-correcting code with redundancy $2\lceil\log_2\log_2 n\rceil + O(\ell^2)$ for $\ell$-row inputs. When $\ell=2$, we establish an upper bound of $\lceil\log_2\log_2 n\rceil + O(1)$, implying that our redundancy is optimal up to a factor of 2. We also present a code correcting a single substitution with $\lceil \log_2(\ell+1)\rceil$ redundant bits and prove that it is within one bit of optimality.

</details>


### [26] [Transmission Mask Analysis for Range-Doppler Sensing in Half-Duplex ISAC](https://arxiv.org/abs/2601.10259)
*Dikai Liu,Yifeng Xiong,Marco Lops,Fan Liu,Jianhua Zhang*

Main category: cs.IT

TL;DR: 分析半双工ISAC中MASM周期性传输掩码的期望距离-多普勒响应，证明距离旁瓣具有多普勒不变性，并揭示不同动态场景下最优掩码设计原则


<details>
  <summary>Details</summary>
Motivation: 研究半双工集成感知与通信（ISAC）中掩码调制（MASM）的周期性传输掩码设计，分析其对距离-多普勒响应的影响，为优化感知性能提供理论指导

Method: 推导周期性掩码的期望距离-多普勒响应闭式解，分析距离旁瓣的多普勒不变性，研究不同动态场景下最优掩码设计：在中等动态场景使用循环差集（特别是Singer CDS），在高度动态场景分析掩码自相关函数与多普勒旁瓣能量的凹函数关系

Result: 距离旁瓣具有多普勒不变性，将距离旁瓣最优性扩展到二维设置；对于距离主瓣，周期性掩码产生稀疏多普勒旁瓣：在中等动态场景中循环差集（特别是Singer CDS）是minimax最优的，在高度动态场景中多普勒旁瓣能量是掩码自相关的凹函数，揭示了与主瓣波动不可避免的权衡

Conclusion: 周期性掩码设计在半双工ISAC中具有重要理论价值，距离旁瓣的多普勒不变性扩展了最优性分析维度，不同动态场景需要不同的最优掩码设计策略，为实际系统设计提供了理论依据

Abstract: In this paper, we analyze the periodic transmission masks for MASked Modulation (MASM) in half-duplex integrated sensing and communication (ISAC), and derive their closed-form expected range-Doppler response $\mathbb{E}\{r(k,l,ν)\}$. We show that range sidelobes ($k\neq l$) are Doppler-invariant, extending the range-sidelobe optimality to the 2-D setting. For the range mainlobe ($k=l$), periodic masking yields sparse Doppler sidelobes: Cyclic difference sets (CDSs) (in particular Singer CDSs) are minimax-optimal in a moderately dynamic regime, while in a highly dynamic regime the Doppler-sidelobe energy is a concave function of the mask autocorrelation, revealing an inevitable tradeoff with mainlobe fluctuation.

</details>


### [27] [Algebraic Properties of PAC Codes](https://arxiv.org/abs/2601.10262)
*Vlad-Florin Dragoi,Mohammad Rowshan*

Main category: cs.IT

TL;DR: 该论文分析了极化调整卷积码，定义了广义多项式极化码类，推导了其结构特性如对偶性和最小距离，并得出了最小重量码字数量和单项式子码维数方面的结构限制。


<details>
  <summary>Details</summary>
Motivation: 研究极化调整卷积码（PAC码）和反向PAC码的代数结构，通过极化码和Reed-Muller码的代数表示来深入理解这些码类的性质。

Method: 使用极化码和Reed-Muller码的代数表示方法，定义广义多项式极化码类，并推导其结构特性，包括对偶性、最小距离等代数性质。

Result: 建立了广义多项式极化码的数学框架，推导了其结构性质如对偶性和最小距离，并得出了关于最小重量码字数量和单项式子码维数的结构限制。

Conclusion: 广义多项式极化码为分析PAC码和反向PAC码提供了统一的代数框架，其结构特性的推导有助于深入理解这些码类的性能极限和设计原则。

Abstract: We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code.

</details>


### [28] [On the Capacity of Noisy Frequency-based Channels](https://arxiv.org/abs/2601.10329)
*Yuval Gerzon,Ilan Shomorony,Nir Weinberger*

Main category: cs.IT

TL;DR: 研究基于频率的信道在噪声下的容量，针对DNA数据存储中的短分子机制，信息编码在项目类型的频率而非顺序中。建立了容量上界（逆界）和下界（可达界），并应用于DNA存储信道量化噪声导致的存储比特数损失。


<details>
  <summary>Details</summary>
Motivation: 研究受DNA数据存储中短分子机制启发的基于频率的信道容量问题。在短分子机制中，信息通过项目类型的频率而非顺序编码。虽然无噪声频率信道的容量已有研究，但识别噪声的影响尚未完全表征，需要量化噪声对信道容量的影响。

Method: 1. 通过随机退化和数据处理不等式建立容量上界（逆界）；2. 基于多项采样过程的泊松化建立可达界，分析由此产生的向量泊松信道与符号间干扰；3. 改进Feinstein界中信息密度的集中不等式；4. 明确表征识别噪声导致的互信息加性损失。

Result: 建立了噪声频率信道的容量上下界，明确量化了识别噪声导致的互信息加性损失。将结果应用于DNA存储信道，量化了噪声在可靠存储比特总数缩放中的损失影响。

Conclusion: 该研究为基于频率的信道在噪声下的容量提供了理论分析框架，特别适用于DNA数据存储中的短分子机制。通过建立容量上下界并量化噪声损失，为实际系统设计提供了理论指导。

Abstract: We investigate the capacity of noisy frequency-based channels, motivated by DNA data storage in the short-molecule regime, where information is encoded in the frequency of items types rather than their order. The channel output is a histogram formed by random sampling of items, followed by noisy item identification. While the capacity of the noiseless frequency-based channel has been previously addressed, the effect of identification noise has not been fully characterized. We present a converse bound on the channel capacity that follows from stochastic degradation and the data processing inequality. We then establish an achievable bound, which is based on a Poissonization of the multinomial sampling process, and an analysis of the resulting vector Poisson channel with inter-symbol interference. This analysis refines concentration inequalities for the information density used in Feinstein bound, and explicitly characterizes an additive loss in the mutual information due to identification noise. We apply our results to a DNA storage channel in the short-molecule regime, and quantify the resulting loss in the scaling of the total number of reliably stored bits.

</details>


### [29] [Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems](https://arxiv.org/abs/2601.10391)
*Liujia Yao,Changsheng You,Zixuan Huang,Chao Zhou,Zhaohui Yang,Xiaoyang Li*

Main category: cs.IT

TL;DR: 提出一种针对用户分布优化的XL-MIMO反馈码本设计，通过联合优化角度-距离采样和比特分配，显著降低反馈开销并提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有XL-MIMO码本设计（如极域码本）未充分考虑实际用户分布，导致反馈开销过大。需要设计更高效的反馈码本以适应实际用户分布特征。

Method: 1. 针对用户均匀分布场景，建立和速率最大化问题，联合优化角度-距离采样和比特分配；2. 利用Voronoi分区证明均匀角度采样最优；3. 针对距离采样，推导接收功率下界，提出几何采样作为高质量次优解；4. 扩展至非均匀用户分布，采用交替采样方法；5. 进行理论分析，研究比特分配随阵列尺寸变化的规律。

Result: 1. 理论分析表明：随着阵列尺寸增大，最优比特分配逐渐偏向距离采样而非角度采样；2. 数值结果显示：所提码本在各种系统配置下均表现出优越的速率性能和鲁棒性，相比基准方案（包括广泛使用的极域码本）获得显著性能增益。

Conclusion: 提出的用户分布感知码本设计能有效降低XL-MIMO FDD系统的反馈开销，通过优化角度-距离采样和比特分配，显著提升系统性能，为实际部署提供了高效解决方案。

Abstract: In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to user distribution. To this end, we first consider a typical scenario where users are uniformly distributed within a specific polar-region, based on which a sum-rate maximization problem is formulated to jointly optimize angle-range samples and bit allocation among angle/range feedback. This problem is challenging to solve due to the lack of a closed-form expression for the received power in terms of angle and range samples. By leveraging a Voronoi partitioning approach, we show that uniform angle sampling is optimal for received power maximization. For more challenging range sampling design, we obtain a tight lower-bound on the received power and show that geometric sampling, where the ratio between adjacent samples is constant, can maximize the lower bound and thus serves as a high-quality suboptimal solution. We then extend the proposed framework to accommodate more general non-uniform user distribution via an alternating sampling method. Furthermore, theoretical analysis reveals that as the array size increases, the optimal allocation of feedback bits increasingly favors range samples at the expense of angle samples. Finally, numerical results validate the superior rate performance and robustness of the proposed codebook design under various system setups, achieving significant gains over benchmark schemes, including the widely used polar-domain codebook.

</details>


### [30] [Convertible Codes for Data and Device Heterogeneity](https://arxiv.org/abs/2601.10341)
*Anina Gruica,Benjamin Jany,Stanislav Kruglik*

Main category: cs.IT

TL;DR: 该论文研究分布式存储系统中的可转换码，旨在同时处理数据异构性和设备异构性，通过Reed-Muller码实现高效的数据转换。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统面临两个关键挑战：数据异构性（由非均匀访问需求引起）和设备异构性（由时变节点可靠性引起）。现有方法通常只解决其中一个问题，需要一种能同时处理这两种异构性的解决方案。

Method: 研究可转换码，能够在合并机制下以最小成本将一种编码转换为另一种编码。推导线性码转换的读写成本一般下界，重点关注Reed-Muller码，并构建显式的转换程序。

Result: 首次实现了同时处理数据异构性和设备异构性的分布式数据存储方案，为Reed-Muller码提供了显式转换程序，并建立了线性码转换的读写成本理论下界。

Conclusion: 可转换码为分布式存储系统提供了一种有效处理双重异构性的框架，Reed-Muller码的转换程序实现了数据异构性和设备异构性的首次结合，为实际系统设计提供了理论基础。

Abstract: Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which efficiently handle data heterogeneity, addressing the former issue, and construct explicit conversion procedures that, for the first time, combine both forms of heterogeneity for distributed data storage.

</details>


### [31] [Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement](https://arxiv.org/abs/2601.10676)
*Lei Hu,Mohamed Nomeir,Alptug Aytekin,Sennur Ulukus*

Main category: cs.IT

TL;DR: 量子分布式存储系统：利用量子通信和纠缠优化存储-修复带宽权衡，在某些条件下可同时最小化存储和带宽


<details>
  <summary>Details</summary>
Motivation: 研究量子资源在分布式存储系统中的应用潜力，探索如何通过量子通信和纠缠来突破经典存储系统的存储-修复带宽权衡限制

Method: 在(n,k,d)分布式存储系统中引入量子通信：当节点失效时，d个辅助节点通过量子信道向新节点传输信息，新节点通过测量接收到的量子态生成存储；利用幸存节点间的量子纠缠优化系统

Result: 完全刻画了存储与修复带宽之间的基本权衡关系；相比经典系统，量子纠缠显著改善了最优存储-带宽权衡，特别是在最小存储再生点；当d≥2k-2时，存在一个操作点可同时最小化存储和修复带宽

Conclusion: 量子通信和纠缠为分布式存储系统带来了根本性的新机制，打破了经典设置中的权衡关系，展示了量子增强在存储系统优化中的巨大潜力

Abstract: This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The newcomer then generates its storage by performing appropriate measurements on the received quantum states. In this setting, we fully characterize the fundamental tradeoff between storage and repair bandwidth (total communication cost). Compared to classical systems, the optimal storage--bandwidth tradeoff can be significantly improved with the enhancement of quantum entanglement shared only among the surviving nodes, particularly at the minimum-storage regenerating point. Remarkably, we show that when $d \geq 2k-2$, there exists an operating point at which \textit{both storage and repair bandwidth are simultaneously minimized}. This phenomenon breaks the tradeoff in the classical setting and reveals a fundamentally new regime enabled by quantum communication.

</details>


### [32] [A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10353)
*Bowen Zheng,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出基于L-half-sum disjoint packing的MISO编码缓存方案，在保持线性子分组(F=K)的同时显著降低子分组复杂度，仅轻微牺牲sum-DoF性能。


<details>
  <summary>Details</summary>
Motivation: 现有MISO编码缓存方案虽然能实现最大sum-DoF，但子分组复杂度随用户数指数增长，限制了实际应用。需要设计在保持良好性能的同时降低子分组复杂度的方案。

Method: 基于拉丁方框架，将MAPDA设计问题转化为L-half-sum disjoint packing构造问题。通过构建L-HSDP结构，生成具有线性子分组(F=K)的MISO编码缓存方案。

Result: 提出的L-HSDP方案相比指数子分组方案显著降低了子分组复杂度，仅轻微牺牲sum-DoF；相比现有线性子分组方案，同时实现了更高的sum-DoF和更低的子分组复杂度。

Conclusion: 通过L-HSDP构造的MISO编码缓存方案在子分组复杂度和系统性能之间取得了良好平衡，为实际系统部署提供了可行的解决方案。

Abstract: In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for general parameters $L$, $M$, and $N$, their subpacketizations increase exponentially with the number of users. We aim to design a MISO coded caching scheme that achieves a large sum-DoF with low subpacketization $F$. An interesting combinatorial structure, called the multiple-antenna placement delivery array (MAPDA), can be used to generate MISO coded caching schemes under these two strategies; moreover, all existing schemes with these strategies can be represented by the corresponding MAPDAs. In this paper, we study the case with $F=K$ (i.e., $F$ grows linearly with $K$) by investigating MAPDAs. Specifically, based on the framework of Latin squares, we transform the design of MAPDA with $F=K$ into the construction of a combinatorial structure called the $L$-half-sum disjoint packing (HSDP). It is worth noting that a $1$-HSDP is exactly the concept of NHSDP, which is used to generate the shared-link coded caching scheme with $F=K$. By constructing $L$-HSDPs, we obtain a class of new schemes with $F=K$. Finally, theoretical and numerical analyses show that our $L$-HSDP schemes significantly reduce subpacketization compared to existing schemes with exponential subpacketization, while only slightly sacrificing sum-DoF, and achieve both a higher sum-DoF and lower subpacketization than the existing schemes with linear subpacketization.

</details>


### [33] [Generalized Weight Structure of Polar Codes: Selected Template Polynomials](https://arxiv.org/abs/2601.10362)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 该论文提出了一个计算极化码汉明权重的通用代数框架，通过规范二元形式表达权重，推导出生成低中权重谱的结构模板，并结合LTA群作用得到明确的多重性公式。


<details>
  <summary>Details</summary>
Motivation: 极化码可以视为递减单项式码，具有由下三角仿射（LTA）群支配的丰富代数结构。然而，需要系统的方法来计算由单项式之和生成的码字的汉明权重，并表征权重谱。

Method: 开发通用框架计算由单项式之和生成的码字的汉明权重，以规范二元形式表达这些权重，推导出关键结构模板（不相交和、嵌套块、互补翻转），这些模板生成低和中权重谱。结合LTA群作用，得到明确的多重性公式。

Result: 获得了统一的代数方法来表征和枚举码字，能够明确计算汉明权重并推导出权重谱的多重性公式。

Conclusion: 该框架为极化码的权重分析提供了系统的代数方法，通过结合结构模板和LTA群作用，实现了对码字权重的完整表征和枚举。

Abstract: Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords.

</details>


### [34] [A Hybrid Reliability--Weight Framework for Construction of Polar Codes](https://arxiv.org/abs/2601.10376)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 提出一种结合可靠性和权重的混合比特信道排序方法，用于构造Polar码，在短到中等码长下改善最小距离谱特性


<details>
  <summary>Details</summary>
Motivation: 传统Polar码构造基于可靠性排序，能保证容量可达但短到中等码长时可能产生较差的最小权重谱。需要结合代数结果来改善最小距离特性

Method: 定义混合比特信道排序，结合可靠性（Bhattacharyya因子）和权重贡献（最小权重码字轨道枚举）。证明该方法在递减单项式码类中最小化截断SC/ML联合界代理

Result: 混合构造在短到中等码长下在最小距离、多重性和联合界近似方面实现可靠性构造和权重优化之间的权衡，渐近影响随码长增加而消失

Conclusion: 混合比特信道排序方法有效结合可靠性和最小距离特性，为短到中等长度Polar码设计提供改进方案，同时保持渐近最优性

Abstract: Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices.

</details>


### [35] [Multiaccess Coded Caching with Heterogeneous Retrieval Costs](https://arxiv.org/abs/2601.10394)
*Wenbo Huang,Minquan Cheng,Kai Wan,Xiaojun Li,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出基于叠加编码的代价感知多接入编码缓存框架，通过优化缓存放置最小化系统总代价（缓存访问代价+广播代价）


<details>
  <summary>Details</summary>
Motivation: 现有MACC研究假设用户从连接的缓存节点获取内容无通信代价，但实际中用户从不同缓存节点获取内容代价不同，服务器传输内容也有代价，需要设计代价感知的系统

Method: 提出基于叠加编码的新编码缓存框架，将Cheng等人的MACC方案分层；推导代价感知优化问题优化缓存放置；利用最优解的稀疏性提出复杂度降低的结构感知算法

Result: 仿真结果表明，在异构检索代价场景下，所提方案始终优于Cheng等人的方案

Conclusion: 提出的代价感知MACC框架能有效最小化系统总代价，在异构代价场景下性能优越

Abstract: The multiaccess coded caching (MACC) system, as formulated by Hachem {\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communication cost. In practice, each user retrieves content from its $L$ different connected cache nodes at varying costs. Additionally, the server also incurs certain costs to transmit the content to the users. In this paper, we focus on a cost-aware MACC system and aim to minimize the total system cost, which includes cache-access costs and broadcast costs. Firstly, we propose a novel coded caching framework based on superposition coding, where the MACC schemes of Cheng \textit{et al.} are layered. Then, a cost-aware optimization problem is derived that optimizes cache placement and minimizes system cost. By identifying a sparsity property of the optimal solution, we propose a structure-aware algorithm with reduced complexity. Simulation results demonstrate that our proposed scheme consistently outperforms the scheme of Cheng {\it et al.} in scenarios with heterogeneous retrieval costs.

</details>


### [36] [Placement Delivery Array for Cache-Aided MIMO Systems](https://arxiv.org/abs/2601.10422)
*Yifei Huang,Kai Wan,Minquan Cheng,Jinyan Wang,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出MIMO-PDA统一结构，实现最大和自由度与低子分组化的缓存辅助MIMO网络编码缓存方案


<details>
  <summary>Details</summary>
Motivation: 在缓存辅助MIMO网络中，需要同时实现最大和自由度与低子分组化的编码缓存方案。现有方案往往在子分组化方面存在不足，需要设计更高效的方案。

Method: 引入MIMO放置交付数组(MIMO-PDA)统一组合结构，分析其组合特性，推导和自由度上界，并提出两种新颖的MIMO-PDA构造方法。

Result: 推导出和自由度上界min{KG, Gt+G⌈L/G⌉}，两种构造均达到最大和自由度，第一种在严格参数约束下实现线性子分组化，第二种在更宽松约束下实现有序指数级子分组化。

Conclusion: 提出的MIMO-PDA框架有效平衡了和自由度与子分组化的权衡，第二种构造在保持最大和自由度的同时，相比现有方案指数级降低了子分组化。

Abstract: We consider a $(G,L,K,M,N)$ cache-aided multiple-input multiple-output (MIMO) network, where a server equipped with $L$ antennas and a library of $N$ equal-size files communicates with $K$ users, each equipped with $G$ antennas and a cache of size $M$ files, over a wireless interference channel. Each user requests an arbitrary file from the library. The goal is to design coded caching schemes that simultaneously achieve the maximum sum degrees of freedom (sum-DoF) and low subpacketization. In this paper, we first introduce a unified combinatorial structure, termed the MIMO placement delivery array (MIMO-PDA), which characterizes uncoded placement and one-shot zero-forcing delivery. By analyzing the combinatorial properties of MIMO-PDAs, we derive a sum-DoF upper bound of $\min\{KG, Gt+G\lceil L/G \rceil\}$, where $t=KM/N$, which coincides with the optimal DoF characterization in prior work by Tehrani \emph{et al.}. Based on this upper bound, we present two novel constructions of MIMO-PDAs that achieve the maximum sum-DoF. The first construction achieves linear subpacketization under stringent parameter constraints, while the second achieves ordered exponential subpacketization under substantially milder constraints. Theoretical analysis and numerical comparisons demonstrate that the second construction exponentially reduces subpacketization compared to existing schemes while preserving the maximum sum-DoF.

</details>


### [37] [Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting](https://arxiv.org/abs/2601.10452)
*Zhouxiang Zhao,Zhaohui Yang,Mingzhe Chen,Chen Zhu,Xin Tong,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 该论文研究资源受限的可见光通信概率语义通信系统中的能效最大化问题，通过联合优化传输波束成形、直流偏置、公共速率分配和语义压缩比，提出基于SCA和Dinkelbach方法的交替优化算法。


<details>
  <summary>Details</summary>
Motivation: 可见光通信作为未来无线通信的关键技术，具有独特的物理层优势，但其与语义通信等高层技术的结合仍未被充分探索。在资源受限的VLC概率语义通信系统中，存在语义压缩带来的计算开销和知识库同步需求，需要解决能效优化问题。

Method: 采用速率分割多址接入技术同时传输知识和信息数据，建立能效最大化优化问题，联合优化传输波束成形、直流偏置、公共速率分配和语义压缩比。开发基于逐次凸逼近和Dinkelbach方法的交替优化算法来解决该非凸优化问题。

Result: 仿真结果表明所提方法的有效性，能够优化VLC概率语义通信系统的能效，平衡通信和计算成本，实现资源受限环境下的高效语义通信。

Conclusion: 该研究为VLC与语义通信的融合提供了有效的能效优化方案，通过联合优化多个系统参数，解决了资源受限环境下的概率语义通信能效问题，对未来无线通信系统的发展具有重要意义。

Abstract: Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, light-emitting diode (LED) transmitters perform semantic compression to reduce data size, which incurs additional computation overhead. The compressed semantic information is transmitted to the users for semantic inference using a shared knowledge base that requires periodic updates to ensure synchronization. In the PSCom system, the knowledge base is represented by probabilistic graphs. To enable simultaneous transmission of both knowledge and information data, rate splitting multiple access (RSMA) is employed. The optimization problem focuses on maximizing energy efficiency by jointly optimizing transmit beamforming, direct current (DC) bias, common rate allocation, and semantic compression ratio, while accounting for both communication and computation costs. To solve this problem, an alternating optimization algorithm based on successive convex approximation (SCA) and Dinkelbach method is developed. Simulation results demonstrate the effectiveness of the proposed approach.

</details>


### [38] [Joint Source-Channel Coding for ISAC: Distortion Tradeoffs and Separation Theorems](https://arxiv.org/abs/2601.10470)
*Gefei Peng,Youlong Wu*

Main category: cs.IT

TL;DR: 本文研究了ISAC系统中的联合信源信道编码框架，证明了分离信源信道编码在此设置下能达到联合最优性，并建立了信道容量、通信与感知失真以及估计成本之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信系统能够同时实现高效通信和环境感知，但需要表征感知与通信之间的性能权衡关系。本文旨在从信息论角度建立ISAC系统中信道容量、通信与感知失真以及估计成本之间的权衡关系。

Method: 采用联合信源信道编码框架，系统包含具有信道状态估计器和联合信源信道编码器的发射机、状态相关无记忆信道以及具有联合信源信道解码器的接收机。从信息论角度分析性能权衡，并通过二进制设置的示例验证理论结果。

Result: 证明了分离信源信道编码在此设置下能达到联合最优性，建立了信道容量、通信与感知失真以及估计成本之间的权衡关系。通过二进制设置的示例验证了理论结果。

Conclusion: 在ISAC系统的联合信源信道编码框架下，分离信源信道编码能够达到联合最优性，为系统设计提供了理论基础。研究建立了信道容量、通信与感知失真以及估计成本之间的权衡关系，有助于指导实际ISAC系统的优化设计。

Abstract: Integrated Sensing and Communication (ISAC) systems have garnered significant attention due to their capability to simultaneously achieve efficient communication and environmental sensing. A core objective in this field is characterizing the performance tradeoff between sensing and communication. In this paper, we consider a joint source-channel coding (JSCC) framework for the ISAC system that consists of a transmitter with a channel state estimator and a joint source-channel encoder, a state-dependent memoryless channel, and a receiver with a joint source-channel decoder. From an information-theoretic perspective, we establish the tradeoff relationships among channel capacity, distortions in both communication and sensing processes, and the estimation cost. We prove that the separate source and channel coding can achieve joint optimality in this setting. An illustrative example of a binary setting is also provided to validate our theoretical results.

</details>


### [39] [A Construction Framework of Coded Caching Scheme for Multi-Access MIMO Systems via Knapsack Problem](https://arxiv.org/abs/2601.10484)
*Siying Luo,Youlong Wu,Mingming Zhang,Minquan Cheng,Dianhua Wu*

Main category: cs.IT

TL;DR: 该论文研究了具有组合拓扑的多接入多输入单输出网络中的编码缓存问题，提出了一种基于0-1背包问题的多天线放置交付阵列设计方法，在提高和自由度同时降低子分组复杂度。


<details>
  <summary>Details</summary>
Motivation: 在多接入MISO网络中，现有编码缓存方案难以同时实现高和自由度与低子分组复杂度。组合拓扑结构使得缓存设计变得复杂，需要一种能平衡性能与复杂度的新方法。

Method: 将多天线放置交付阵列设计建模为0-1背包问题，通过优化框架将复杂的组合缓存结构转化为可处理的优化问题，生成高效的缓存放置和灵活的传输策略。

Result: 在组合拓扑网络中，所提方案比现有方案获得更高的和自由度；在相同缓存大小约束下，子分组水平与现有线性子分组方案相当；特定条件下能达到理论最大和自由度并进一步降低子分组。

Conclusion: 提出的基于优化框架的MAPDA设计方法能有效解决多接入MISO网络的编码缓存问题，在提高和自由度的同时控制子分组复杂度，为组合拓扑网络提供了高效的缓存方案。

Abstract: This paper investigates the coded caching problem in a multi-access multiple-input single-output (MAMISO) network with the combinatorial topology. The considered system consists of a server containing $N$ files, $Λ$ cache nodes, and $K$ cache-less users, where each user can access a unique subset of $r$ cache nodes. The server is equipped with $L$ transmit antennas. Our objective is to design a caching scheme that simultaneously achieves a high sum Degree of Freedom (sum-DoF) and low subpacketization complexity. To address this challenge, we formulate the design of multi-antenna placement delivery arrays (MAPDA) as a $0$--$1$ knapsack problem to maximize the achievable DoF, thereby transforming the complex combinatorial caching structure into a tractable optimization framework that yields efficient cache placement and flexible delivery strategies. Theoretical and numerical analyses demonstrate that: for networks with combinatorial topologies, the proposed scheme achieves a higher sum-DoF than existing schemes. Under identical cache size constraints, the subpacketization level remains comparable to existing linear subpacketization schemes. Moreover, under specific system conditions, the proposed scheme attains the theoretical maximum sum-DoF of $\min\{L+KM/N, K\}$ while achieving further reductions subpacketization. For particular combinatorial structures, we further derive optimized constructions that achieve even higher sum-DoF with lower subpacketization. ```

</details>


### [40] [Coded Caching for Combinatorial Multi-Access Hotplug Networks from $t$-Designs](https://arxiv.org/abs/2601.10503)
*Dhruv Pratap Singh,Anjana A. Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 提出了一种基于t设计的组合多接入热插拔编码缓存方案，在特定内存区间优于现有方案


<details>
  <summary>Details</summary>
Motivation: 研究组合多接入网络中的热插拔编码缓存问题，扩展现有模型，允许用户访问多个缓存，同时在传输阶段只有部分缓存在线

Method: 将热插拔放置交付数组框架扩展到组合多接入设置，提出基于t设计的编码缓存方案，通过适当参数选择消除冗余组播传输

Result: 方案实现了灵活子分组化的一系列速率-内存权衡，数值比较显示在特定内存区间优于现有热插拔编码缓存方案

Conclusion: 提出的t设计方案为组合多接入热插拔编码缓存提供了有效的解决方案，在性能上优于现有方法

Abstract: We study hotplug coded caching in combinatorial multi-access networks, which generalizes existing hotplug coded caching models by allowing users to access multiple caches, while only a subset of caches is online during the delivery phase. We first generalize the Hotplug Placement Delivery Array (HpPDA) framework to the combinatorial multi-access setting. Based on this generalized framework, we propose a t-design-based coded caching scheme for combinatorial multi-access networks. We characterize a class of design parameters under which every active user has access to a sufficient number of coded subfiles to decode its requested file, and show that appropriate parameter choices allow for the elimination of redundant multicast transmissions. As a result, the proposed scheme achieves a family of rate memory trade offs with flexible subpacketization. We present numerical comparisons illustrating that the proposed t-scheme outperforms existing hotplug coded caching schemes in certain memory regimes.

</details>


### [41] [A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Latin Rectangle](https://arxiv.org/abs/2601.10505)
*Yongcheng Yang,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出基于非半和拉丁矩形(NHSLR)的新型编码缓存方案，将子分组化从F=K扩展到F=O(K)，实现线性可扩展的子分组化并降低传输负载。


<details>
  <summary>Details</summary>
Motivation: 现有编码缓存方案面临子分组化与传输负载的权衡问题：指数/多项式子分组化方案复杂，而线性子分组化方案传输负载过高。需要设计同时实现低子分组化和低传输负载的方案。

Method: 提出非半和拉丁矩形(NHSLR)这一新型组合结构，扩展了Cheng等人提出的非半和不相交打包(NHSDP)框架。通过构造NHSLR，将线性编码缓存方案从F=K扩展到F=O(K)的更广泛场景。

Result: 获得了一类新的编码缓存方案，实现了线性可扩展的子分组化，同时相比NHSDP方案进一步降低了传输负载。理论和数值分析表明，该方案不仅比现有线性子分组化方案传输负载更低，而且接近某些指数子分组化方案的性能。

Conclusion: NHSLR结构为编码缓存方案设计提供了新框架，在子分组化和传输负载之间取得了更好的平衡，为解决编码缓存中的关键挑战提供了有效方法。

Abstract: Coded caching is recognized as an effective method for alleviating network congestion during peak periods by leveraging local caching and coded multicasting gains. The key challenge in designing coded caching schemes lies in simultaneously achieving low subpacketization and low transmission load. Most existing schemes require exponential or polynomial subpacketization levels, while some linear subpacketization schemes often result in excessive transmission load. Recently, Cheng et al. proposed a construction framework for linear coded caching schemes called Non-Half-Sum Disjoint Packing (NHSDP), where the subpacketization equals the number of users $K$. This paper introduces a novel combinatorial structure, termed the Non-Half-Sum Latin Rectangle (NHSLR), which extends the framework of linear coded caching schemes from $F=K$ (i.e., the construction via NHSDP) to a broader scenario with $F=\mathcal{O}(K)$. By constructing NHSLR, we have obtained a new class of coded caching schemes that achieves linearly scalable subpacketization, while further reducing the transmission load compared with the NHSDP scheme. Theoretical and numerical analyses demonstrate that the proposed schemes not only achieves lower transmission load than existing linear subpacketization schemes but also approaches the performance of certain exponential subpacketization schemes.

</details>


### [42] [A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10510)
*Mengyuan Li,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出一种基于CMA-NHSDP组合结构的多接入编码缓存方案，在保持线性子分组化(F=K)的同时降低传输负载


<details>
  <summary>Details</summary>
Motivation: 现有多接入编码缓存方案存在矛盾：具有指数级子分组化的方案传输性能好但复杂度高，而线性/多项式子分组化的方案传输负载较高。需要设计在保持线性子分组化的同时降低传输负载的方案。

Method: 将NHSDP（非半和不相交包装）结构扩展到多接入系统，提出CMA-NHSDP（循环多接入非半和不相交包装）组合结构，基于此构造新的多接入编码缓存方案。

Result: 理论分析和数值比较表明，所提方案在线性子分组化下比现有方案传输负载更低，在某些情况下甚至优于具有指数级子分组化的方案。

Conclusion: CMA-NHSDP结构为多接入编码缓存系统提供了一种有效的设计框架，在保持低复杂度的同时改善了传输性能。

Abstract: We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incur higher transmission loads. We aim to design a multi-access coded caching scheme with linear subpacketization $F$ while maintaining low transmission load. Recently, Cheng et al. proposed a construction framework for coded caching schemes with linear subpacketization (i.e., $F=K$) called non-half-sum disjoint packing (NHSDP). Inspired by this structure, we introduce a novel combinatorial structure named cyclic multi-access non-half-sum disjoint packing (CMA-NHSDP) by extending NHSDP to MACC system. By constructing CMA-NHSDP, we obtain a new class of multi-access coded caching schemes. Theoretical and numerical analyses show that our scheme achieves lower transmission loads than some existing schemes with linear subpacketization. Moreover, the proposed schemes achieves lower transmission load compared to existing schemes with exponential subpacketization in some case.

</details>


### [43] [On the suboptimality of linear codes for binary distributed hypothesis testing](https://arxiv.org/abs/2601.10526)
*Adway Girish,Robinson D. H. Cung,Emre Telatar*

Main category: cs.IT

TL;DR: 研究二元分布式假设检验问题，两个代理观察相关二元向量，以相同速率向中央决策者发送压缩信息。分析线性压缩方案，证明截断在某些情况下是最佳线性方案，但线性编码总体上是次优的。


<details>
  <summary>Details</summary>
Motivation: 研究分布式假设检验中的信息压缩问题，特别关注线性压缩方案在相关二元向量检测中的性能，探索在通信速率受限条件下如何有效压缩观测信息。

Method: 采用线性压缩方案，分析截断方法作为特殊线性编码的性能。在两种特定情况下证明截断是最佳线性方案：1）检验相反符号但相同幅度的相关性；2）检验独立性或反对独立性。通过数值证据支持截断在检验任何相反符号相关性时都是最佳线性编码的猜想。

Result: 证明截断在两种情况下是最佳线性方案，数值证据支持截断在检验相反符号相关性时是最佳线性编码的猜想。对于检验反对独立性，计算了经典随机编码指数，显示截断（以及任何线性编码）严格次优。

Conclusion: 线性压缩方案在某些特定假设检验场景中表现良好（截断是最佳方案），但在更一般的检验反对独立性问题上，线性编码严格次优于经典随机编码方法。

Abstract: We study a binary distributed hypothesis testing problem where two agents observe correlated binary vectors and communicate compressed information at the same rate to a central decision maker. In particular, we study linear compression schemes and show that simple truncation is the best linear scheme in two cases: (1) testing opposite signs of the same magnitude of correlation, and (2) testing for or against independence. We conjecture, supported by numerical evidence, that truncation is the best linear code for testing any correlations of opposite signs. Further, for testing against independence, we also compute classical random coding exponents and show that truncation, and consequently any linear code, is strictly suboptimal.

</details>


### [44] [Network Integrated Sensing and Communication](https://arxiv.org/abs/2601.10538)
*Edward Andrews,Lawrence Ong,Duy T. Ngo,Yao Liu,Min Li*

Main category: cs.IT

TL;DR: 本文研究了网络级ISAC系统，分析了中继网络中通信路由与感知覆盖之间的基本权衡，为6G异构网络设计提供了理论指导。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究主要集中在链路级设计，但面向大规模部署需要理解网络级性能。本文旨在研究网络ISAC模型中通信路由与感知覆盖之间的基本权衡关系。

Method: 提出一个新颖的优化框架，捕捉多节点路由和感知覆盖之间的相互作用。针对一维路径网络提供完整的感知-吞吐量区域解析表征，并扩展到一般网络拓扑，证明感知-吞吐量Pareto边界是分段线性的。

Result: 揭示了感知覆盖与通信路由之间的基本权衡关系，为6G异构网络设计提供了关键见解。对于一维路径网络给出了完整的感知-吞吐量区域解析解，对于一般网络拓扑证明了Pareto边界的分段线性特性。

Conclusion: 本文建立了网络级ISAC性能分析的理论框架，揭示了通信路由与感知覆盖之间的基本权衡，为未来6G异构网络的优化设计提供了重要指导。

Abstract: Integrated sensing and communication (ISAC) is a cornerstone technology for 6G networks, offering unified support for high-rate communication and high-accuracy sensing. While existing literature extensively covers link-level designs, the transition toward large-scale deployment necessitates a fundamental understanding of network-level performance. This paper investigates a network ISAC model where a source node communicates with a destination via a relay network, while intermediate nodes concurrently perform cooperative sensing over specific spatial regions. We formulate a novel optimization framework that captures the interplay between multi-node routing and sensing coverage. For a one-dimensional path network, we provide an analytical characterization of the complete sensing-throughput region. Extending this to general network topologies, we establish that the sensing-throughput Pareto boundary is piecewise linear and provide physical interpretations for each segment. Our results reveal the fundamental trade-offs between sensing coverage and communication routing, offering key insights for the design of future 6G heterogeneous networks.

</details>


### [45] [Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity](https://arxiv.org/abs/2601.10540)
*Yajuan Liu,Tolga M. Duman*

Main category: cs.IT

TL;DR: 本文研究了能纠正多个(t₁,t₂)-DI错误突发的纠错码构造，建立了不同错误类型间的等价关系，推导了码率上下界，并提出了低复杂度构造方法。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储和文档同步等实际应用中会出现同时包含插入、删除和替换的突发错误，需要能够纠正这类错误的信道编码。

Method: 1) 建立两个(t₁,t₂)-DI突发、两个(t₂,t₁)-DI突发、以及一个(t₁,t₂)-DI和一个(t₂,t₁)-DI突发之间的等价关系；2) 推导两个(t₁,t₂)-DI突发纠错码的码率上下界；3) 提出两个(t₁,t₂)-DI突发纠错码的具体构造方法。

Result: 提出的构造方法相比基于综合征压缩技术的编码具有显著更低的计算复杂度，且码率上下界可自然扩展到多个突发错误的情况。

Conclusion: 本文为纠正多个(t₁,t₂)-DI突发错误提供了理论基础和实用构造，在保持纠错能力的同时降低了计算复杂度，适用于DNA数据存储等实际应用场景。

Abstract: Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity.

</details>


### [46] [Sparse Signal Recovery from Random Measurements](https://arxiv.org/abs/2601.10569)
*Siu-Wing Cheng,Man Ting Wong*

Main category: cs.IT

TL;DR: 提出一种无需优化或解线性系统的简单方法，通过Θ(log n)个随机感知矩阵在O(kn log n)时间内恢复稀疏信号，其中k=Θ(s log n)，s为信号非零坐标数


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知方法需要解决优化问题或线性系统，计算复杂度高。本文旨在开发一种更简单、更快速的方法来恢复稀疏信号，避免复杂的优化过程。

Method: 使用Θ(log n)个随机感知矩阵，每个大小为k×n，其中k=Θ(s log n)。通过简单的算法直接确定未知向量z，无需解决任何优化问题或线性系统。方法还适应于确定信号的支持集（非零坐标位置）。

Result: 方法时间复杂度为O(kn log n)，远低于传统优化方法。在二进制信号上实验表明，该方法与基于优化的方法相比具有竞争力。

Conclusion: 提出了一种简单高效的压缩感知信号恢复方法，避免了复杂的优化过程，在计算效率和实现简单性方面具有优势，特别适用于稀疏信号恢复。

Abstract: Given the compressed sensing measurements of an unknown vector $z \in \mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $Θ(\log n)$ random sensing matrices in $\mathbb{R}^{k \times n}$ and runs in $O(kn\log n)$ time, where $k = Θ(s\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimization-based methods on binary signals.

</details>


### [47] [Fundamental Limits of Multi-User Distributed Computing of Linearly Separable Functions](https://arxiv.org/abs/2601.10603)
*K. K. Krishnan Namboodiri,Elizabath Peter,Derya Malak,Petros Elia*

Main category: cs.IT

TL;DR: 该论文研究了多用户分布式计算中线性可分函数的基本极限，提出了在通信与计算权衡下的最优分布式计算方案。


<details>
  <summary>Details</summary>
Motivation: 研究多用户分布式计算中线性可分函数的基本性能极限，解决通信与计算之间的根本权衡问题。在分布式计算系统中，每个服务器计算能力有限（最多计算M个子函数），通信能力也有限（最多向Δ个用户传输数据），需要设计高效的任务分配和传输方案来降低通信成本。

Method: 提出了一个联合设计任务分配和传输的分布式计算方案。对于给定的K（基子函数数量）、L（用户数量）、M（每个服务器计算能力）、Δ（每个服务器通信能力），在实数域中使用新颖的反向证明方法验证方案的最优性，在有限域中使用基于计数参数的反向证明来表征方案性能。

Result: 证明了所提出的分布式计算方案在各种条件下在实数域中达到最优性能，并在有限域中完整表征了方案的性能表现。

Conclusion: 该工作建立了多用户分布式计算线性可分函数的基本极限，提出的联合设计方案在通信与计算权衡下实现了最优性能，为分布式计算系统的设计提供了理论基础。

Abstract: This work establishes the fundamental limits of the classical problem of multi-user distributed computing of linearly separable functions. In particular, we consider a distributed computing setting involving $L$ users, each requesting a linearly separable function over $K$ basis subfunctions from a master node, who is assisted by $N$ distributed servers. At the core of this problem lies a fundamental tradeoff between communication and computation: each server can compute up to $M$ subfunctions, and each server can communicate linear combinations of their locally computed subfunctions outputs to at most $Δ$ users. The objective is to design a distributed computing scheme that reduces the communication cost (total amount of data from servers to users), and towards this, for any given $K$, $L$, $M$, and $Δ$, we propose a distributed computing scheme that jointly designs the task assignment and transmissions, and shows that the scheme achieves optimal performance in the real field under various conditions using a novel converse. We also characterize the performance of the scheme in the finite field using another converse based on counting arguments.

</details>


### [48] [Basis-Spline Assisted Coded Computing: Strategies and Error Bounds](https://arxiv.org/abs/2601.10616)
*Rimpi Borah,J. Harshan,V. Lalitha*

Main category: cs.IT

TL;DR: 提出基于三次B样条插值的编码计算框架，相比现有Berrut近似编码计算方法，在处理非多项式函数时能显著提升精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有Berrut近似编码计算方法在处理非多项式函数时，由于Berrut插值具有全局支撑特性，当延迟节点数量较多时精度会显著下降。需要一种更稳定的编码计算方法来应对这一挑战。

Method: 提出基于三次B样条插值的编码计算框架，利用B样条的局部支撑和平滑特性，在服务器端进行函数评估，并在主节点使用B样条重构函数值，从而增强稳定性和精度。

Result: 建立了将B样条插值集成到编码计算中的系统方法，推导了关于服务器数量和延迟节点数量的近似误差理论界。比较分析表明，该方法在各种非多项式函数上显著优于基于Berrut的方法。

Conclusion: 基于三次B样条插值的编码计算框架能有效解决Berrut方法在延迟节点较多时的精度下降问题，为分布式计算中非多项式函数的可靠计算提供了更优的解决方案。

Abstract: Coded computing has become a key framework for reliable distributed computation over decentralized networks, effectively mitigating the impact of stragglers. Although there exists a wide range of coded computing methods to handle both polynomial and non-polynomial functions, computing methods for the latter class have received traction due its inherent challenges in reconstructing non-polynomial functions using a finite number of evaluations. Among them, the state-of-the-art method is Berrut Approximated coded computing, wherein Berrut interpolants, are used for approximating the non-polynomial function. However, since Berrut interpolants have global support characteristics, such methods are known to offer degraded accuracy when the number of stragglers is large. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master node using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error in terms of the number of servers and stragglers. Comparative analysis demonstrates that our framework significantly outperforms Berrut-based methods for various non-polynomial functions.

</details>


### [49] [Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval](https://arxiv.org/abs/2601.10643)
*Chandan Anand,Jayesh Seshadri,Prasad Krishnan,Gowtham R. Kurri*

Main category: cs.IT

TL;DR: 本文证明了Chandan等人提出的WPIR方案在特定条件下的最优性，并在不满足阈值约束时提供了反例，表明可以获得比之前报道更高的速率。


<details>
  <summary>Details</summary>
Motivation: Chandan等人最近提出了新的弱私有信息检索(WPIR)方案，并给出了在互信息泄漏和最大泄漏度量下的速率-隐私权衡表达式。然而，这些权衡是否在各自类别中是最优的尚不清楚。

Method: 通过数学证明和构造反例的方法，分析Chandan等人提出的Sun-Jafar型和Banawan-Ulukus型WPIR方案的最优性条件。

Result: 证明了在非共谋复制存储设置下，Sun-Jafar型方案的速率-隐私权衡是最优的；在满足阈值约束条件下，Banawan-Ulukus型MDS-WPIR和Sun-Jafar型T-共谋WPIR方案也是类别最优的；当不满足阈值约束时，构造了反例表明可以获得更高的速率。

Conclusion: 本文确定了Chandan等人提出的WPIR方案的最优性条件，为弱私有信息检索的理论发展提供了重要结果，并指出了在特定参数范围下存在改进空间。

Abstract: Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR schemes, under the mutual information leakage and maximal leakage metrics. Explicit achievable trade-offs for the same were also presented, which were shown to be competitive or better than prior WPIR schemes. However, the class-wise optimality of the reported trade-offs were unknown. In this work, we show that the explicit rate-privacy trade-offs reported for the Sun-Jafar-type schemes by Chandan et al. are optimal for the non-colluding and replicated setting. Furthermore, we prove the class-wise optimality for Banawan-Ulukus-type MDS-WPIR and Sun-Jafar-type $T$-colluding WPIR schemes, under threshold-constraints on the system parameters. When these threshold-constraints do not hold, we present counter-examples which show that even higher rates than those reported before can be achieved.

</details>


### [50] [One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity](https://arxiv.org/abs/2601.10648)
*Joseph Rowan,Buu Phan,Ashish Khisti*

Main category: cs.IT

TL;DR: 研究单次联合信源信道编码，其中源编码一次后通过独立信道广播给K个解码器，要求至少一个解码器能在最大失真约束下恢复源信号。发现使用不相交码本可获得码本分集增益，不同于共享码本时的信道分集增益。


<details>
  <summary>Details</summary>
Motivation: 研究多解码器广播场景下的单次联合信源信道编码问题，探索如何通过码本设计来提升至少一个解码器成功恢复源信号的概率，特别是在独立信道条件下。

Method: 提出使用不相交码本的编码方案，推导一阶和二阶可达界（通过改进的泊松匹配引理）。进一步提出混合编码方案，将解码器分组以平衡码本分集和信道分集。

Result: 在二进制对称信道上的数值结果表明，混合方法（部分解码器共享码本，部分使用不相交码本）优于完全共享或完全不相交码本的策略。

Conclusion: 在单次联合信源信道编码的多解码器广播中，码本分集增益是独立于信道分集的重要机制，混合编码方案能有效平衡两种分集，提升系统性能。

Abstract: We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint.

</details>


### [51] [Synchronizing Probabilities in Model-Driven Lossless Compression](https://arxiv.org/abs/2601.10678)
*Aviv Adler,Jennifer Tang*

Main category: cs.IT

TL;DR: PMATIC是一种容忍预测不匹配的概率匹配区间编码算法，可作为模型驱动压缩工具中算术编码的替代方案，在保持压缩性能的同时增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在基于神经网络的概率预测压缩中，压缩器和解压器必须具有完全匹配的预测概率，但硬件、软件或计算顺序的微小差异会导致预测不匹配，进而引发级联解码失败。

Method: 提出了概率匹配区间编码（PMATIC），这是一种模型无关的算法，能够容忍有界的预测不匹配，同时保持低开销。PMATIC与预测概率兼容，可作为模型驱动压缩工具中算术编码的直接替代方案。

Result: 理论分析证明了PMATIC的正确性和性能边界，在文本数据上的实验验证表明，当与先进的预测模型结合时，PMATIC对预测不匹配具有鲁棒性，同时压缩率优于标准的现代压缩工具。

Conclusion: PMATIC为解决模型驱动压缩中的预测不匹配问题提供了有效的解决方案，能够在保持压缩性能的同时增强系统的鲁棒性，为基于神经网络的压缩算法提供了更可靠的编码框架。

Abstract: It is well-known in the field of lossless data compression that probabilistic next-symbol prediction can be used to compress sequences of symbols. Deep neural networks are able to capture rich dependencies in data, offering a powerful means of estimating these probabilities and hence an avenue towards more effective compression algorithms. However, both compressor and decompressor must have exactly matching predictions; even small non-deterministic differences (which often happen with learned models due to hardware, software, or computation order) can lead to cascading decoding failures. In this paper, we formalize the problem of prediction mismatch in model-driven compression, and introduce Probability Matching Interval Coding (PMATIC), a model-agnostic algorithm that tolerates bounded prediction mismatch with low overhead. PMATIC works with the predicted probabilities, making it compatible as a drop-in replacement for the arithmetic encoder in model-driven compression tools. We show theoretical correctness and performance bounds for PMATIC, and validate these results on text data. These results confirm that, when paired an advanced prediction model, PMATIC is robust to prediction mismatch while achieving compression rates that out-perform standard modern compression tools.

</details>


### [52] [Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes](https://arxiv.org/abs/2601.10682)
*Pin-Hsun Lin,Hadi Aghaee,Christian Deppe,Eduard A. Jorswieck,Holger Boche*

Main category: cs.IT

TL;DR: 基于极化码在二进制输入加性高斯白噪声信道上的二选一不经意传输协议，利用极化变换的自同构实现完美接收者隐私和渐进发送者隐私


<details>
  <summary>Details</summary>
Motivation: 在二进制输入加性高斯白噪声信道上实现安全的不经意传输协议，同时保证接收者和发送者的隐私安全

Method: 使用极化码，通过极化变换的自同构连接两个解码器视图，公开从对应的自同构群中随机选择编码器，在选定的坏比特信道上故意注入随机性

Result: 在任何有限块长下实现完美接收者隐私，通过信道极化结合隐私放大获得渐进发送者隐私，推导了松弛的可靠性准则并评估了有限块长性能

Conclusion: 该方案成功实现了基于极化码的二选一不经意传输协议，通过极化变换自同构的结构特性推导并优化了可实现的有限块长OT速率

Abstract: We develop a one-out-of-two-oblivious transfer protocol over the binary-input additive white Gaussian noise channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect receiver privacy at any finite blocklength, since the public encoder distribution is independent of the receiver's choice bit. Sender privacy is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness on selected bad bit-channels, we derive a relaxed reliability criterion and evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength OT rate.

</details>


### [53] [Improved Constructions of Reed-Solomon Codes with Optimal Repair Bandwidth](https://arxiv.org/abs/2601.10685)
*Jing Qiu,Weijun Fang,Shu-Tao Xia,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 改进的RS-MSR码构造，消除了素数模s同余1的条件，显著降低了子分组化程度，扩展了参数范围


<details>
  <summary>Details</summary>
Motivation: 现有RS-MSR码构造要求素数p_i ≡ 1 (mod s)，限制了参数选择和增加了子分组化程度，需要更灵活的构造方法

Method: 提出改进的RS-MSR码构造，消除p_i ≡ 1 (mod s)的约束条件，使用更一般的素数选择

Result: 子分组化程度降低φ(s)^n倍，扩展了可行的参数范围，提供了更灵活的RS-MSR码构造

Conclusion: 成功构建了更高效的RS-MSR码，显著降低了存储开销，为分布式存储系统提供了更好的修复带宽优化方案

Abstract: Maximum-distance-separable (MDS) codes are widely used in distributed storage, yet naive repair of a single erasure in an $[n,k]$ MDS code downloads the entire contents of $k$ nodes. Minimum Storage Regenerating (MSR) codes (Dimakis et al., 2010) minimize repair bandwidth by contacting $d>k$ helpers and downloading only a fraction of data from each. Guruswami and Wootters first proposed a linear repair scheme for Reed-Solomon (RS) codes, showing that they can be repaired with lower bandwidth than the naive approach. The existence of RS codes achieving the MSR point (RS-MSR codes) nevertheless remained open until the breakthrough construction of Tamo, Barg, and Ye, which yields RS-MSR codes with subpacketization $\ell = s \prod_{i=1}^n p_i$, where $p_i$ are distinct primes satisfying $p_i \equiv 1 \pmod{s}$ and $s=d+1-k$.
  In this paper, we present an improved construction of RS-MSR codes by eliminating the congruence condition $p_i \equiv 1 \pmod{s}$. Consequently, our construction reduces the subpacketization by a multiplicative factor of $φ(s)^n$ ( $φ(\cdot)$ is Euler's totient function) and broadens the range of feasible parameters for RS-MSR codes.

</details>


### [54] [Perfect Secret Key Generation for a class of Hypergraphical Sources](https://arxiv.org/abs/2601.10697)
*Manuj Mukherjee,Sagnik Chatterjee,Alhad Sethi*

Main category: cs.IT

TL;DR: 本文扩展了PIN模型到超图，提出了两种完美密钥生成方案：一种针对完全t-均匀超图，另一种针对3-均匀超图，通过星超图包装和哈密顿包装实现容量最优。


<details>
  <summary>Details</summary>
Motivation: Nitinawarat和Narayan提出的PIN模型基于图论，利用生成树包装率实现完美密钥生成。本文旨在将这一框架扩展到超图，利用超图的组合特性设计类似的完美密钥生成方案。

Method: 1. 针对完全t-均匀超图：利用星超图包装完全t-均匀超图，设计每个星图生成$\binom{m-2}{t-2}$比特完美密钥的方案。2. 针对3-均匀超图：首先设计投影为环的3-均匀星超图的2比特完美密钥生成方案，然后通过星图包装和哈密顿包装扩展到一般3-均匀超图。

Result: 1. 完全t-均匀超图的方案达到容量最优。2. 3-均匀超图的方案对某些超图类别达到容量最优。

Conclusion: 成功将PIN模型扩展到超图，利用超图的组合特性设计了完美密钥生成方案，对完全t-均匀超图和某些3-均匀超图实现了容量最优。

Abstract: Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph.
  Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs.

</details>
