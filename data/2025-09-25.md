<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 3]
- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 42]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor Segmentation](https://arxiv.org/abs/2509.19353)
*Yuxiao Yi,Qingyao Zhuang,Zhi-Qin John Xu*

Main category: eess.IV

TL;DR: 提出了一种集成nnU-Net、Swin UNETR和HFF-Net的方法用于儿科脑肿瘤分割，通过可调初始化尺度、迁移学习和频域分解等技术优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 儿科脑肿瘤分割面临罕见性和异质性挑战，但对临床诊断和治疗规划至关重要。

Method: 集成三种网络：nnU-Net（可调初始化尺度控制复杂度）、Swin UNETR（从BraTS 2021预训练模型迁移学习）、HFF-Net（频域分解分离低频轮廓和高频纹理）。最终集成模型结合三个网络的输出。

Result: 在BraTS-PED 2025挑战中取得Dice分数：ET 72.3%、NET 95.6%、CC 68.9%、ED 89.5%、TC 92.3%、WT 92.3%。

Conclusion: 提出的集成方法在儿科脑肿瘤分割任务中表现出色，验证了多模型集成和针对性技术改进的有效性。

Abstract: Pediatric brain tumor segmentation presents unique challenges due to the
rarity and heterogeneity of these malignancies, yet remains critical for
clinical diagnosis and treatment planning. We propose an ensemble approach
integrating nnU-Net, Swin UNETR, and HFF-Net for the BraTS-PED 2025 challenge.
Our method incorporates three key extensions: adjustable initialization scales
for optimal nnU-Net complexity control, transfer learning from BraTS 2021
pre-trained models to enhance Swin UNETR's generalization on pediatric dataset,
and frequency domain decomposition for HFF-Net to separate low-frequency tissue
contours from high-frequency texture details. Our final ensemble combines
nnU-Net ($\gamma=0.7$), fine-tuned Swin UNETR, and HFF-Net, achieving Dice
scores of 72.3% (ET), 95.6% (NET), 68.9% (CC), 89.5% (ED), 92.3% (TC), and
92.3% (WT), respectively.

</details>


### [2] [BALANCE: Bitrate-Adaptive Limit-Aware Netcast Content Enhancement Utilizing QUBO and Quantum Annealing](https://arxiv.org/abs/2509.19616)
*Animesh Rajpurohit,Michael Kelley,Wei Wang,Krishna Murthy Kattiyan Ramamoorthy*

Main category: eess.IV

TL;DR: BALANCE是一种基于量子框架的视频流优化方法，通过智能预选视频片段和使用VMAF指标来提升数据限制下的用户体验质量。


<details>
  <summary>Details</summary>
Motivation: 在数据上限约束日益严格的时代，如何在用户定义的数据限制内优化视频流质量是一个重要挑战。

Method: 使用量子框架，通过视觉复杂度和预期数据消耗智能预选视频片段，采用VMAF指标，将比特率分配问题建模为QUBO问题，比较松弛变量方法和动态惩罚方法。

Result: 与传统比特率阶梯相比，在相同数据约束下显著提升了QoE；动态惩罚方法在数据限制增加时始终优于松弛变量方法，提供更有效和最优的解决方案。

Conclusion: 这种新的量子方法显著提升了数据受限用户的流媒体满意度。

Abstract: In an era of increasing data cap constraints, optimizing video streaming
quality while adhering to user-defined data caps remains a significant
challenge. This paper introduces Bitrate-Adaptive Limit-Aware Netcast Content
Enhancement (BALANCE), a novel Quantum framework aimed at addressing this
issue. BALANCE intelligently pre-selects video segments based on visual
complexity and anticipated data consumption, utilizing the Video Multimethod
Assessment Fusion (VMAF) metric to enhance Quality of Experience (QoE). We
compare our method against traditional bitrate ladders used in Adaptive Bitrate
(ABR) streaming, demonstrating a notable improvement in QoE under equivalent
data constraints. We compare the Slack variable approach with the Dynamic
Penalization Approach (DPA) by framing the bitrate allocation problem through
Quadratic Unconstrained Binary Optimization (QUBO) to effectively enforce data
limits. Our results indicate that the DPA consistently outperforms the Slack
Variable Method, delivering more valid and optimal solutions as data limits
increase. This new quantum approach significantly enhances streaming
satisfaction for users with limited data plans.

</details>


### [3] [Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms](https://arxiv.org/abs/2509.20001)
*Babak Naderi,Ross Cutler*

Main category: eess.IV

TL;DR: 本文提出了一种检测远程桌面用户的方法，并比较了两个主流众包平台在真实测试条件下的易受攻击性和缓解措施。


<details>
  <summary>Details</summary>
Motivation: 主观视频质量评估（VQA）是衡量通信、流媒体和UGC管道中最终用户体验的黄金标准。众包提供了准确、可靠、快速且廉价的评估，但存在不可靠提交的问题，如工人忽略指令或利用奖励机制。最近测试显示，视频元数据的复杂利用和远程桌面（RD）连接的使用增加，都会导致结果偏差。

Method: 提出客观和主观检测器来识别远程桌面用户，并在真实测试条件和任务设计下比较两个主流众包平台的易受攻击性和缓解措施。

Result: 未在摘要中明确说明具体结果。

Conclusion: 需要开发有效的检测和缓解方法来应对众包平台中的远程桌面用户问题，以确保主观视频质量评估的准确性和可靠性。

Abstract: Subjective video quality assessment (VQA) is the gold standard for measuring
end-user experience across communication, streaming, and UGC pipelines. Beyond
high-validity lab studies, crowdsourcing offers accurate, reliable, faster, and
cheaper evaluation-but suffers from unreliable submissions by workers who
ignore instructions or game rewards. Recent tests reveal sophisticated exploits
of video metadata and rising use of remote-desktop (RD) connections, both of
which bias results. We propose objective and subjective detectors for RD users
and compare two mainstream crowdsourcing platforms on their susceptibility and
mitigation under realistic test conditions and task designs.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [4] [Analyzing α-divergence in Gaussian Rate-Distortion-Perception Theory](https://arxiv.org/abs/2509.19572)
*Martha V. Sourla,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.IT

TL;DR: 本文研究了高斯源在均方误差失真和α散度感知度量下的信息率失真感知函数估计问题，提出了参数化解决方案，并建立了与现有结果的联系。


<details>
  <summary>Details</summary>
Motivation: 研究信息率失真感知函数对于目标导向的有损压缩和语义信息重建具有重要意义，特别是在高斯源和特定感知度量下的理论分析。

Method: 假设联合高斯RDPF形成凸优化问题，推导出参数化上界解，将最优参数求解转化为寻找α度简化指数多项式的根，并使用二分法进行数值计算。

Result: 成功建立了参数化解决方案，验证了分析结果与数值结果的一致性，并建立了与现有理论结果的连接。

Conclusion: 提出的方法有效解决了高斯源在特定失真和感知度量下的RDPF估计问题，为相关应用提供了理论基础和计算工具。

Abstract: The problem of estimating the information rate distortion perception function
(RDPF), which is a relevant information-theoretic quantity in goal-oriented
lossy compression and semantic information reconstruction, is investigated
here. Specifically, we study the RDPF tradeoff for Gaussian sources subject to
a mean-squared error (MSE) distortion and a perception measure that belongs to
the family of {\alpha} divergences. Assuming a jointly Gaussian RDPF, which
forms a convex optimization problem, we characterize an upper bound for which
we find a parametric solution. We show that evaluating the optimal parameters
of this parametric solution is equivalent to finding the roots of a reduced
exponential polynomial of degree {\alpha}. Additionally, we determine which
disjoint sets contain each root, which enables us to evaluate them numerically
using the well-known bisection method. Finally, we validate our analytical
findings with numerical results and establish connections with existing
results.

</details>


### [5] [Efficient $\varepsilon$-approximate minimum-entropy couplings](https://arxiv.org/abs/2509.19598)
*Spencer Compton*

Main category: cs.IT

TL;DR: 本文提出了一种针对最小熵耦合问题的多项式时间近似方案（PTAS），能够在常数m的情况下，以n^O(poly(1/ε)·exp(m))的时间复杂度实现H(ALG) ≤ H(OPT) + ε的近似保证。


<details>
  <summary>Details</summary>
Motivation: 最小熵耦合问题是NP难问题，之前最好的多项式时间算法只能达到常数加性误差（m=2时c≈0.53，一般m时c≈1.22）。主要开放问题是该问题是否APX难，或者是否存在PTAS。

Method: 设计了一种算法，通过利用问题的结构特性，在常数m的情况下实现了多项式时间近似方案。算法的时间复杂度为n^O(poly(1/ε)·exp(m))。

Result: 证明了对于常数m，最小熵耦合问题存在PTAS，这是该问题近似算法研究的重要突破。

Conclusion: 这项工作解决了最小熵耦合问题近似复杂度的主要开放问题，表明对于常数m该问题不是APX难的，存在高效的近似方案。

Abstract: Given $m \ge 2$ discrete probability distributions over $n$ states each, the
minimum-entropy coupling is the minimum-entropy joint distribution whose
marginals are the same as the input distributions. Computing the
minimum-entropy coupling is NP-hard, but there has been significant progress in
designing approximation algorithms; prior to this work, the best known
polynomial-time algorithms attain guarantees of the form $H(\operatorname{ALG})
\le H(\operatorname{OPT}) + c$, where $c \approx 0.53$ for $m=2$, and $c
\approx 1.22$ for general $m$ [CKQGK '23].
  A main open question is whether this task is APX-hard, or whether there
exists a polynomial-time approximation scheme (PTAS). In this work, we design
an algorithm that produces a coupling with entropy $H(\operatorname{ALG}) \le
H(\operatorname{OPT}) + \varepsilon$ in running time
$n^{O(\operatorname{poly}(1/\varepsilon) \cdot \operatorname{exp}(m) )}$:
showing a PTAS exists for constant $m$.

</details>


### [6] [Agentic AI for Low-Altitude Semantic Wireless Networks: An Energy Efficient Design](https://arxiv.org/abs/2509.19791)
*Zhouxiang Zhao,Ran Yi,Yihan Cang,Boyang Jin,Zhaohui Yang,Mingzhe Chen,Chongwen Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 该论文提出了一种基于智能AI的低空语义无线网络框架，通过优化无人机位置、语义压缩比、传输功率等关键变量，解决无人机自主系统中的能效问题，以最小化系统总能耗。


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助自主系统中的能源效率问题，提高任务续航能力，特别是在低空语义无线网络环境中。

Method: 构建了一个系统级能耗最小化问题，综合考虑无人机位置、语义压缩比、传输功率等变量，并开发了一种低复杂度算法，通过二维搜索获得全局最优解。

Result: 仿真结果表明，所提出的设计相比传统基线方法能显著降低总能耗。

Conclusion: 提出的智能AI驱动的低空语义无线网络框架能有效优化无人机系统的能效，为无人机自主系统的长期运行提供了可行的解决方案。

Abstract: This letter addresses the energy efficiency issue in unmanned aerial vehicle
(UAV)-assisted autonomous systems. We propose a framework for an agentic
artificial intelligence (AI)-powered low-altitude semantic wireless network,
that intelligently orchestrates a sense-communicate-decide-control workflow. A
system-wide energy consumption minimization problem is formulated to enhance
mission endurance. This problem holistically optimizes key operational
variables, including UAV's location, semantic compression ratio, transmit power
of the UAV and a mobile base station, and binary decision for AI inference task
offloading, under stringent latency and quality-of-service constraints. To
tackle the formulated mixed-integer non-convex problem, we develop a
low-complexity algorithm which can obtain the globally optimal solution with
two-dimensional search. Simulation results validate the effectiveness of our
proposed design, demonstrating significant reductions in total energy
consumption compared to conventional baseline approaches.

</details>


### [7] [Understanding the ratio of the partition sum to its Bethe approximation via double covers](https://arxiv.org/abs/2509.19910)
*Pascal O. Vontobel*

Main category: cs.IT

TL;DR: 本文探讨了图模型中配分函数与其Bethe近似之间的比值关系，特别是配分函数与二阶Bethe近似的比值平方与配分函数与Bethe近似的比值之间的近似关系。


<details>
  <summary>Details</summary>
Motivation: 观察到在图模型中，配分函数与其Bethe近似的比值通常接近配分函数与其二阶Bethe近似的比值的平方，这一现象值得深入研究，因为后者通常更容易分析和量化。

Method: 对观察到的两个比值之间的关系进行理论论证，并对两类对数超模图模型中的这些比值进行分析。

Result: 提供了对观察到的比值关系的理论依据，并对特定类别的图模型进行了比值分析。

Conclusion: 研究结果支持了观察到的比值关系，并为理解图模型中配分函数近似提供了新的理论视角。

Abstract: For various classes of graphical models it has been observed that the ratio
of the partition sum to its Bethe approximation is often close to being the
square of the ratio of the partition sum to its degree-2 Bethe approximation.
This is of relevance because the latter ratio can often better be analyzed
and/or quantified than the former ratio. In this paper, we give some
justifications for the observed relationship between these two ratios and then
analyze these ratios for two classes of log-supermodular graphical models.

</details>


### [8] [Constrained Higher-Order Binary Optimization for Wireless Communications Systems Using Ising Machines](https://arxiv.org/abs/2509.20092)
*Gan Zheng,Ioannis Krikidis*

Main category: cs.IT

TL;DR: 本文提出了一种基于Ising机器的算法，用于解决无线通信系统中具有不等式约束的大规模高阶二进制优化问题，通过增强拉格朗日方法和泰勒展开将高阶多项式近似为二次型，实现了无需辅助变量的迭代求解。


<details>
  <summary>Details</summary>
Motivation: 传统QUBO方法在无线通信资源优化中应用受限，因为实际问题通常包含高阶多项式项和严格不等式约束，需要开发能够处理这些复杂性的新方法。

Method: 采用增强拉格朗日方法处理约束，使用泰勒展开将高阶多项式近似为二次型，在每个迭代步骤中求解单个QUBO问题，无需引入辅助变量。

Result: 在同时无线信息和能量传输系统的相位优化案例中，仿真结果表明所提算法性能令人满意，优于启发式基准方案。

Conclusion: 该算法成功克服了QUBO在无线通信应用中的瓶颈，为利用Ising机器解决复杂资源优化问题提供了有效途径。

Abstract: This paper develops an algorithmic solution using Ising machines to solve
large-scale higher-order binary optimization (HOBO) problems with inequality
constraints for resource optimization in wireless communications systems.
Quadratic unconstrained binary optimization (QUBO) aims to solve a special
category of these problems widely encountered in engineering and science. To
solve QUBO instances, specialized Ising machines have been designed, while
sophisticated quantum annealing algorithm and quantum-inspired classical
heuristics have been developed. However, the application of QUBO in wireless
communications has limited practical interest mainly due to the complexity of
resource optimization problems which are often characterized by high-order
polynomial terms and strict inequality constraints. To overcome these
bottlenecks and take advantage of recent advancements in Ising machines, in
this paper, we propose an iterative algorithmic solution to solve HOBO
problems, which is based on the augmented Lagrangian method to handle
constraints. Specifically, Taylor expansion is employed to approximate
higher-order polynomials to quadratic ones in the augmented Lagrangian
function, which enables the solution of a single QUBO problem at each iteration
without auxiliary variables. As an illustrative case study, we consider the
problem of phase optimization in a simultaneous wireless information and power
transfer system, where a reconfigurable intelligent surface with 1-bit phase
resolution is used to facilitate information/energy transfer. Simulation
results verify that the proposed algorithm achieves satisfactory performance
and outperforms heuristic benchmark schemes.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [9] [Raspberry Pi Pico as a Radio Transmitter](https://arxiv.org/abs/2509.19304)
*M. Andrecut*

Main category: eess.SP

TL;DR: 将树莓派Pico微控制器通过廉价现成电子元件和开源软件转变为无线电发射器的简单方法


<details>
  <summary>Details</summary>
Motivation: 探索树莓派Pico作为无线电发射器的潜力，揭示这种看似无害的改造在极端情况下可能带来的安全风险

Method: 使用廉价现成的电子元件和开源软件对树莓派Pico微控制器进行改造

Result: 成功将树莓派Pico转变为无线电发射器，能够建立大量本地隐蔽无线电通信通道

Conclusion: 这种简单的改造方法虽然看似无害，但在安全方面存在潜在风险，需要引起重视

Abstract: In this paper we discuss several surprisingly simple methods for transforming
the Raspberry Pi Pico (RP2) microcontroller into a radio transmitter, by using
only cheap off the shelf electronic components, and open source software. While
initially this transformation may look as a harmless curiosity, in some extreme
cases it can also pose security risks, since it can be used to open a large
number of local stealth radio communication channels.

</details>


### [10] [A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks](https://arxiv.org/abs/2509.19306)
*Jingyi Wang,Zhongyuan Zhao,Qingtian Wang,Zexu Li,Yue Wang,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该论文提出了一种基于在线学习的优化方法，用于在异构无线网络中优化联邦微调，通过动态切换LoRA模块来应对设备异构性和传输不可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 边缘智能需要低延迟和普适服务，但无线网络中的设备异构性和资源约束对联邦微调性能构成威胁。

Method: 提出基于切换的联邦微调框架，设备动态切换LoRA模块；推导推理风险差距上界；将非凸混合整数规划问题分解为模型切换、发射功率控制和带宽分配子问题；开发具有多项式计算复杂度的在线优化算法。

Result: 在SST-2和QNLI数据集上的仿真结果显示，在测试准确率和能效方面获得了性能提升。

Conclusion: 所提出的在线优化方法能有效提升异构无线网络中联邦微调的性能和效率。

Abstract: Edge intelligence has emerged as a promising strategy to deliver low-latency
and ubiquitous services for mobile devices. Recent advances in fine-tuning
mechanisms of foundation models have enabled edge intelligence by integrating
low-rank adaptation (LoRA) with federated learning. However, in wireless
networks, the device heterogeneity and resource constraints on edge devices
pose great threats to the performance of federated fine-tuning. To tackle these
issues, we propose to optimize federated fine-tuning in heterogenous wireless
networks via online learning. First, the framework of switching-based federated
fine-tuning in wireless networks is provided. The edge devices switches to LoRA
modules dynamically for federated fine-tuning with base station to jointly
mitigate the impact of device heterogeneity and transmission unreliability.
Second, a tractable upper bound on the inference risk gap is derived based on
theoretical analysis. To improve the generalization capability, we formulate a
non-convex mixed-integer programming problem with long-term constraints, and
decouple it into model switching, transmit power control, and bandwidth
allocation subproblems. An online optimization algorithm is developed to solve
the problems with polynomial computational complexity. Finally, the simulation
results on the SST-2 and QNLI data sets demonstrate the performance gains in
test accuracy and energy efficiency.

</details>


### [11] [Bandwidth of Gamma-Distribution-Shaped Functions via Lambert W Function](https://arxiv.org/abs/2509.19307)
*Anthony LoPrete,Johannes Burge*

Main category: eess.SP

TL;DR: 本文推导并提出了伽马分布函数的半高全宽（FWHM）的解析表达式，使用Lambert W函数计算伽马分布概率密度函数的逆函数，并比较了伽马形状函数的高斯近似。


<details>
  <summary>Details</summary>
Motivation: 伽马形状函数的半高全宽（FWHM）是表征单峰函数带宽的有用量，但目前缺乏其闭式表达式的广泛可用性。

Method: 使用Lambert W函数计算伽马分布概率密度函数（PDF）的逆函数，从而推导出伽马分布在任意比例最大值处的宽度的精确解析表达式。

Result: 成功推导出伽马分布FWHM的精确解析表达式，并提供了伽马形状函数的倍频带宽表达式。

Conclusion: 本文提供了伽马形状函数FWHM的闭式表达式，填补了现有文献的空白，并对高斯近似进行了比较分析。

Abstract: The full width at half maximum (FWHM) is a useful quantity for characterizing
the bandwidth of unimodal functions. However, a closed-form expression for the
FWHM of gamma-shaped functions-i.e. functions that are shaped like the gamma
distribution probability density function (PDF)-is not widely available. Here,
we derive and present just such an expression. To do so, we use the Lambert W
function to compute the inverse of the gamma PDF. We use this inverse to derive
an exact analytic expression for the width of a gamma distribution at an
arbitrary proportion of the maximum, from which the FWHM follows trivially. (An
expression for the octave bandwidth of gamma-shaped functions is also
provided.) The FWHM is then compared to the Gaussian approximation of
gamma-shaped functions. A few other related issues are discussed.

</details>


### [12] [Graph-Based Spatio-temporal Attention and Multi-Scale Fusion for Clinically Interpretable, High-Fidelity Fetal ECG Extraction](https://arxiv.org/abs/2509.19308)
*Chang Wang,Ming Zhu,Shahram Latifi,Buddhadeb Dawn,Shengjie Zhai*

Main category: eess.SP

TL;DR: FHNet是一个深度学习框架，结合图神经网络和多尺度增强变换器，用于从腹部心电图中提取干净的胎儿心电图信号，在低信噪比条件下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病是最常见的新生儿异常，需要早期检测来改善预后。但胎儿心电图信号在腹部心电图中常被母体心电图和噪声掩盖，传统方法在低信噪比条件下效果不佳。

Method: 提出FetalHealthNet（FHNet）框架，整合图神经网络和多尺度增强变换器，动态建模导联间的时空相关性，提取干净的胎儿心电图信号。

Result: 在基准数据集上，FHNet持续优于LSTM模型、标准变换器和最先进模型，R²>0.99，RMSE=0.015，即使在严重噪声条件下也表现优异。可解释性分析显示具有生理意义的时空和导联贡献。

Conclusion: FHNet展示了AI驱动建模在推进胎儿监测和实现早期先天性心脏病筛查方面的潜力，强调了新一代生物医学信号处理的变革性影响。

Abstract: Congenital Heart Disease (CHD) is the most common neonatal anomaly,
highlighting the urgent need for early detection to improve outcomes. Yet,
fetal ECG (fECG) signals in abdominal ECG (aECG) are often masked by maternal
ECG and noise, challenging conventional methods under low signal-to-noise ratio
(SNR) conditions. We propose FetalHealthNet (FHNet), a deep learning framework
that integrates Graph Neural Networks with a multi-scale enhanced transformer
to dynamically model spatiotemporal inter-lead correlations and extract clean
fECG signals. On benchmark aECG datasets, FHNet consistently outperforms long
short-term memory (LSTM) models, standard transformers, and state-of-the-art
models, achieving R2>0.99 and RMSE = 0.015 even under severe noise.
Interpretability analyses highlight physiologically meaningful temporal and
lead contributions, supporting model transparency and clinical trust. FHNet
illustrates the potential of AI-driven modeling to advance fetal monitoring and
enable early CHD screening, underscoring the transformative impact of
next-generation biomedical signal processing.

</details>


### [13] [A Novel Two-Dimensional Wigner Distribution Framework via the Quadratic Phase Fourier Transform with a Non-Separable Kernel](https://arxiv.org/abs/2509.19310)
*Mukul Chauhan,Waseem Z. Lone,Amit K. Verma*

Main category: eess.SP

TL;DR: 本文提出了一种新的时频分布——二维非可分离二次相位Wigner分布(2D-NSQPWD)，基于二维非可分离二次相位傅里叶变换框架，能够有效捕捉复杂非可分离信号结构，并在二维线性调频信号处理中表现出优越的交叉项抑制和信号定位性能。


<details>
  <summary>Details</summary>
Motivation: 传统Wigner分布在处理复杂非可分离信号结构时存在局限性，需要开发更有效的时频分析工具来捕捉这类信号的特性。

Method: 通过用NSQPFT核替换经典傅里叶核，构建了2D-NSQPWD分布，并严格证明了其时间频率平移不变性、边缘行为、共轭对称性、卷积关系和Moyal恒等式等关键性质。

Result: 在单分量、双分量和三分量二维线性调频信号上的应用表明，该分布具有优越的交叉项抑制能力和信号定位性能。

Conclusion: 2D-NSQPWD为复杂非可分离信号的时频分析提供了一种有效的工具，在信号处理领域具有重要应用价值。

Abstract: This paper introduces a novel time-frequency distribution, referred to as the
Two-Dimensional Non-Separable Quadratic Phase Wigner Distribution (2D-NSQPWD),
formulated within the framework of the Two-Dimensional Non-Separable Quadratic
Phase Fourier Transform (2D-NSQPFT). By replacing the classical Fourier kernel
with the NSQPFT kernel, the proposed distribution generalizes the classical
Wigner distribution and effectively captures complex, non-separable signal
structures. We rigorously establish several key properties of the 2D-NSQPWD,
including time and frequency shift invariance, marginal behavior, conjugate
symmetry, convolution relations, and Moyal's identity. Furthermore, the
connection between the 2D-NSQPWD and the two-dimensional short-time Fourier
transform (2D-STFT) is explored. The distribution's effectiveness is
demonstrated through its application to single-, bi-, and tri-component
two-dimensional linear frequency modulated (2D-LFM) signals, where it shows
superior performance in cross-term suppression and signal localization.

</details>


### [14] [E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion](https://arxiv.org/abs/2509.19312)
*Minghui Wu,Zhen Gao*

Main category: eess.SP

TL;DR: 提出一个端到端的上行-下行CSI融合预编码网络，联合建模下行CSI参考信号设计、CSI反馈和基站预编码，通过融合上行SRS信息和下行反馈来提升大规模MIMO系统的频谱效率。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统虽然能提供高频谱效率，但高维下行信道状态信息(CSI)使得实时信道获取和预编码变得复杂，需要更高效的解决方案。

Method: 基于MAXIM架构的投影网络处理上行SRS信号，输出投影矩阵用于设计下行CSI-RS；UE压缩反馈CSI观测值；BS端有两个互补分支分别基于下行反馈和上行SRS生成候选预编码器，最后通过融合网络结合得到最终预编码器。所有模块采用三阶段训练策略，以频谱效率为导向进行优化。

Result: 仿真结果显示，该方法有效利用SRS信息和UE反馈，相比传统基线方法取得了显著更好的性能。

Conclusion: 提出的端到端融合预编码网络能够有效结合上行和下行信道信息，为大规模MIMO系统中的信道获取和预编码问题提供了有效的解决方案。

Abstract: Massive multiple-input multiple-output (MIMO) promises high spectral
efficiency but also leads to high-dimensional downlink channel state
information (CSI), which complicates real-time channel acquisition and
precoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI
fusion precoding network that jointly models downlink CSI reference signal
(CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single
E2E neural architecture. Concretely, a projection network built on the MAXIM
architecture takes uplink sounding reference signals (SRS) as input and outputs
frequency-, beam-, and port-domain projection matrices for designing downlink
CSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS
observations and feeds back a compact representation. At the base station (BS),
two complementary branches produce candidate precoders: one is a feedback-only
precoding network driven by quantized downlink observations, and the other is
an SRS-only precoding network driven by uplink SRS. These candidate precoders
are subsequently combined by a fusion precoding network to yield the final
transmit precoder. All the modules are trained with a
spectral-efficiency-oriented loss under a three-stage schedule. Simulation
results show that the proposed approach effectively harnesses both SRS-derived
information and UE feedback, achieving markedly better performance than
conventional baselines.

</details>


### [15] [STL-FFT-STFT-TCN-LSTM: An Effective Wave Height High Accuracy Prediction Model Fusing Time-Frequency Domain Features](https://arxiv.org/abs/2509.19313)
*Huipeng Liu,Zhichao Zhu,Yuan Zhou,Changlu Li*

Main category: eess.SP

TL;DR: 本文提出了一种结合STL-FFT-STFT-TCN-LSTM的混合模型，用于精确预测有效波高，解决了波浪能信号的非线性、突变、多尺度周期性等挑战，在极端波高捕捉和噪声抑制方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统能源消耗加剧且环境影响显著，波浪能因其高能量密度、稳定性、分布广泛和环境友好性而成为有前景的可再生能源。精确预测有效波高是开发的关键，但波浪能信号存在强非线性、突变、多尺度周期性、数据稀疏和高频噪声干扰等问题，物理模型计算成本极高。

Method: 提出STL-FFT-STFT-TCN-LSTM混合模型，利用季节性趋势分解（STL）、快速傅里叶变换（FFT）、短时傅里叶变换（STFT）、时间卷积网络（TCN）和长短期记忆网络（LSTM）技术，优化多尺度特征融合，捕捉极端波高，处理高频噪声和周期信号问题。

Result: 使用NOAA Station 41008和41047的2019-2022小时数据进行实验，与其它单模型和混合模型相比，该模型在捕捉极端波高和抑制高频噪声方面预测精度显著更高，MAE降低15.8%-40.5%，SMAPE降低8.3%-20.3%，R增加1.31%-2.9%。消融实验验证了各组件步骤的必要性。

Conclusion: STL-FFT-STFT-TCN-LSTM模型在多尺度特征融合方面具有优越性，能够高效准确地预测有效波高，为波浪能开发提供了可靠的技术支持。

Abstract: As the consumption of traditional energy sources intensifies and their
adverse environmental impacts become more pronounced, wave energy stands out as
a highly promising member of the renewable energy family due to its high energy
density, stability, widespread distribution, and environmental friendliness.
The key to its development lies in the precise prediction of Significant Wave
Height (WVHT). However, wave energy signals exhibit strong nonlinearity, abrupt
changes, multi-scale periodicity, data sparsity, and high-frequency noise
interference; additionally, physical models for wave energy prediction incur
extremely high computational costs. To address these challenges, this study
proposes a hybrid model combining STL-FFT-STFT-TCN-LSTM. This model exploits
the Seasonal-Trend Decomposition Procedure based on Loess (STL), Fast Fourier
Transform (FFT), Short-Time Fourier Transform (STFT), Temporal Convolutional
Network (TCN), and Long Short-Term Memory (LSTM) technologies. The model aims
to optimize multi-scale feature fusion, capture extreme wave heights, and
address issues related to high-frequency noise and periodic signals, thereby
achieving efficient and accurate prediction of significant wave height.
Experiments were conducted using hourly data from NOAA Station 41008 and 41047
spanning 2019 to 2022. The results showed that compared with other single
models and hybrid models, the STL-FFT-STFT-TCN-LSTM model achieved
significantly higher prediction accuracy in capturing extreme wave heights and
suppressing high-frequency noise, with MAE reduced by 15.8\%-40.5\%, SMAPE
reduced by 8.3\%-20.3\%, and R increased by 1.31\%-2.9\%; in ablation
experiments, the model also demonstrated the indispensability of each component
step, validating its superiority in multi-scale feature fusion.

</details>


### [16] [Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning](https://arxiv.org/abs/2509.19315)
*Yiqiao Chen,Zijian Huang,Zhenghui Feng*

Main category: eess.SP

TL;DR: 提出一种多模态深度学习框架，结合ECG和IEGM信号，用于儿科心律失常的自动分类，在Leipzig Heart Center数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 儿科心律失常是导致残疾和心源性猝死的主要风险因素，但由于类别不平衡、少样本类别和复杂信号特征，其自动分类面临挑战，限制了早期筛查和临床干预的效率与可靠性。

Method: 提出多模态端到端深度学习框架，包括双分支卷积编码器（ECG和IEGM）、语义注意力机制用于跨模态特征对齐、轻量级Transformer编码器用于全局依赖建模，以及新的对比损失函数AGCACL来增强类内紧凑性和类间可分离性。

Result: 在Leipzig Heart Center儿科/先天性ECG+IEGM数据集上，该方法取得了97.76%的Top-1准确率、94.08%宏精度、91.97%宏召回率、92.97%宏F1和92.36%宏F2，相比最强基线分别提升了13.64、15.96、19.82和19.44个百分点。

Conclusion: 该框架显著提高了少数心律失常类别的可检测性和鲁棒性，为儿科和先天性心脏病人群的心律筛查、术前评估和术后随访提供了潜在的临床价值。

Abstract: Pediatric arrhythmias are a major risk factor for disability and sudden
cardiac death, yet their automated classification remains challenging due to
class imbalance, few-shot categories, and complex signal characteristics, which
severely limit the efficiency and reliability of early screening and clinical
intervention. To address this problem, we propose a multimodal end-to-end deep
learning framework that combines dual-branch convolutional encoders for ECG and
IEGM, semantic attention for cross-modal feature alignment, and a lightweight
Transformer encoder for global dependency modeling. In addition, we introduce a
new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive
Loss (AGCACL) to enhance intra-class compactness and inter-class separability
through class prototypes and a global similarity matrix. To the best of our
knowledge, this is the first systematic study based on the Leipzig Heart Center
pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and
reproducible preprocessing pipeline. Experimental results demonstrate that the
proposed method achieves the overall best performance on this dataset,
including 97.76\% Top-1 Accuracy, 94.08\% Macro Precision, 91.97\% Macro
Recall, 92.97\% Macro F1, and 92.36\% Macro F2, with improvements of +13.64,
+15.96, +19.82, and +19.44 percentage points over the strongest baseline in
Macro Precision/Recall/F1/F2, respectively. These findings indicate that the
framework significantly improves the detectability and robustness for minority
arrhythmia classes, offering potential clinical value for rhythm screening,
pre-procedural assessment, and postoperative follow-up in pediatric and
congenital heart disease populations.

</details>


### [17] [Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks](https://arxiv.org/abs/2509.19340)
*Ying Ju,Mingdong Li,Haoyu Wang,Lei Liu,Youyang Qu,Mianxiong Dong,Victor C. M. Leung,Chau Yuen*

Main category: eess.SP

TL;DR: 提出了一种流体天线辅助的移动边缘计算卸载框架，通过信息瓶颈度量增强的信道压缩感知和博弈论辅助的分层双决斗多智能体算法，有效解决了信道估计和联合优化问题，显著降低了系统延迟。


<details>
  <summary>Details</summary>
Motivation: 流体天线能够动态调整端口位置，提供空间分集和频谱效率优势，特别适用于移动边缘计算系统。但面临信道估计复杂性和联合优化非凸性两大挑战。

Method: 1. IBM-CCS：将信息相关性融入感知过程，有效捕获流体天线信道关键特征；2. HiTDMA：基于博弈论的分层双决斗多智能体算法，通过分层结构解耦用户侧和基站侧的优化任务，利用博弈论降低功率控制变量维度。

Result: 数值结果表明，所提方案显著降低系统延迟，提升卸载性能，优于基准方法。IBM-CCS在不同端口密度下表现出优越的准确性和鲁棒性。

Conclusion: 该框架成功解决了流体天线辅助MEC系统中的关键挑战，为高效通信提供了有效解决方案，在非完美信道状态信息下仍能保持良好性能。

Abstract: With the emergence of fluid antenna (FA) in wireless communications, the
capability to dynamically adjust port positions offers substantial benefits in
spatial diversity and spectrum efficiency, which are particularly valuable for
mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC
offloading framework to minimize system delay. This framework faces two severe
challenges, which are the complexity of channel estimation due to dynamic port
configuration and the inherent non-convexity of the joint optimization problem.
Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed
Sensing (IBM-CCS), which advances FA channel estimation by integrating
information relevance into the sensing process and capturing key features of FA
channels effectively. Secondly, to address the non-convex and high-dimensional
optimization problem in FA-assisted MEC systems, which includes FA port
selection, beamforming, power control, and resource allocation, we propose a
game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA)
based offloading scheme, where the hierarchical structure effectively decouples
and coordinates the optimization tasks between the user side and the base
station side. Crucially, the game theory effectively reduces the dimensionality
of power control variables, allowing deep reinforcement learning (DRL) agents
to achieve improved optimization efficiency. Numerical results confirm that the
proposed scheme significantly reduces system delay and enhances offloading
performance, outperforming benchmarks. Additionally, the IBM-CCS channel
estimation demonstrates superior accuracy and robustness under varying port
densities, contributing to efficient communication under imperfect CSI.

</details>


### [18] [Electric Vehicle Identification from Behind Smart Meter Data](https://arxiv.org/abs/2509.19316)
*Ammar Kamoona,Hui Song,Ali Moradi Amani,Mahdi Jalili,Xinghuo Yu,Peter McTaggart*

Main category: eess.SP

TL;DR: 本文提出了一种基于异常检测的无监督学习方法，用于从智能电表低频数据中识别电动汽车充电负荷，无需先验的EV充电配置文件知识。


<details>
  <summary>Details</summary>
Motivation: 当电动汽车在电表后充电时，充电负荷被视为用户总负荷的一部分，而非由配电网运营商单独测量。配电网运营商需要了解其网络中的EV存在情况，以更好地规划和管理配电网。

Method: 采用基于异常检测技术的无监督学习方法和深度时间卷积编码解码网络，仅需非EV用户的实际功耗数据。

Result: 该方法应用于澳大利亚维多利亚州家庭的智能电表后功耗数据，TAE网络在识别有EV的家庭方面表现出优越性能。

Conclusion: 所提出的无监督方法能够有效识别电表后的EV充电负荷，为配电网运营商提供重要决策支持。

Abstract: Electric vehicle (EV) charging loads identification from behind smart meter
recordings is an indispensable aspect that enables effective decision-making
for energy distributors to reach an informed and intelligent decision about the
power grid's reliability. When EV charging happens behind the meter (BTM), the
charging occurs on the customer side of the meter, which measures the overall
electricity consumption. In other words, the charging of the EV is considered
part of the customer's load and not separately measured by the Distribution
Network Operators (DNOs). DNOs require complete knowledge about the EV presence
in their network. Identifying the EV charging demand is essential to better
plan and manage the distribution grid. Unlike supervised methods, this paper
addresses the problem of EV charging load identification in a non-nonintrusive
manner from low-frequency smart meter using an unsupervised learning approach
based on anomaly detection technique. Our approach does not require prior
knowledge of EV charging profiles. It only requires real power consumption data
of non-EV users, which are abundant in practice. We propose a deep temporal
convolution encoding decoding (TAE) network. The TAE is applied to power
consumption from smart BTM from Victorian households in Australia, and the TAE
shows superior performance in identifying households with EVs.

</details>


### [19] [A Measurement Report Data-Driven Framework for Localized Statistical Channel Modeling](https://arxiv.org/abs/2509.19342)
*Xinyu Qin,Ye Xue,Qi Yan,Shutao Zhang,Bingsheng Peng,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: 提出了一种基于测量报告数据的局部统计信道建模框架，通过超图神经网络解决MR数据位置缺失问题，并联合优化网格划分和信道APS估计来提高复杂环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的局部统计信道建模方法严重依赖高成本的驱动测试数据，空间覆盖有限。利用低成本、广泛收集的MR数据可以克服这些限制。

Method: 框架包含两个模块：1）MR定位模块使用基于超图神经网络的半监督方法处理位置缺失问题；2）联合网格构建和信道APS估计模块通过聚类和改进的稀疏恢复算法交替优化网格划分和APS估计。

Result: 在真实MR数据集上的实验表明，该框架在定位和信道建模方面具有优越的性能和鲁棒性。

Conclusion: 所提出的MR数据驱动框架为数字孪生辅助网络优化提供了一种高效、低成本的局部统计信道建模解决方案。

Abstract: Localized statistical channel modeling (LSCM) is crucial for effective
performance evaluation in digital twin-assisted network optimization. Solely
relying on the multi-beam reference signal receiving power (RSRP), LSCM aims to
model the localized statistical propagation environment by estimating the
channel angular power spectrum (APS). However, existing methods rely heavily on
drive test data with high collection costs and limited spatial coverage. In
this paper, we propose a measurement report (MR) data-driven framework for
LSCM, exploiting the low-cost and extensive collection of MR data. The
framework comprises two novel modules. The MR localization module addresses the
issue of missing locations in MR data by introducing a semi-supervised method
based on hypergraph neural networks, which exploits multi-modal information via
distance-aware hypergraph modeling and hypergraph convolution for location
extraction. To enhance the computational efficiency and solution robustness,
LSCM operates at the grid level. Compared to independently constructing
geographically uniform grids and estimating channel APS, the joint grid
construction and channel APS estimation module enhances robustness in complex
environments with spatially non-uniform data by exploiting their correlation.
This module alternately optimizes grid partitioning and APS estimation using
clustering and improved sparse recovery for the ill-conditioned measurement
matrix and incomplete observations. Through comprehensive experiments on a
real-world MR dataset, we demonstrate the superior performance and robustness
of our framework in localization and channel modeling.

</details>


### [20] [Scensory: Automated Real-Time Fungal Identification and Spatial Mapping](https://arxiv.org/abs/2509.19318)
*Yanbaihui Liu,Erica Babusci,Claudia K. Gunsch,Boyuan Chen*

Main category: eess.SP

TL;DR: Scensory是一个机器人驱动的嗅觉系统，使用低成本VOC传感器阵列和深度学习同时识别真菌种类并定位其空间来源。


<details>
  <summary>Details</summary>
Motivation: 现有室内真菌检测方法速度慢、成本高且缺乏空间分辨率，不适合实时监测和大规模部署。

Method: 利用时间VOC动态编码化学和空间特征，通过神经网络架构解码机器人自动收集的数据，提供被动多阵列和主动单阵列两种操作模式。

Result: 在五种真菌物种上达到89.85%的种类检测准确率和87.31%的定位准确率，每个预测仅需3-7秒传感器输入。

Conclusion: 该方法实现了实时、空间感知的真菌监测，建立了可扩展且经济实惠的自主环境感知框架。

Abstract: Indoor fungal contamination poses significant risks to public health, yet
existing detection methods are slow, costly, and lack spatial resolution.
Conventional approaches rely on laboratory analysis or high-concentration
sampling, making them unsuitable for real-time monitoring and scalable
deployment. We introduce \textbf{\textit{Scensory}}, a robot-enabled olfactory
system that simultaneously identifies fungal species and localizes their
spatial origin using affordable volatile organic compound (VOC) sensor arrays
and deep learning. Our key idea is that temporal VOC dynamics encode both
chemical and spatial signatures, which we decode through neural architectures
trained on robot-automated data collection. We demonstrate two operational
modes: a passive multi-array configuration for environmental monitoring, and a
mobile single-array configuration for active source tracking. Across five
fungal species, our system achieves up to 89.85\% accuracy in species detection
and 87.31\% accuracy in localization under ambient conditions, where each
prediction only takes 3--7\,s sensor inputs. Additionally, by computationally
analyzing model behavior, we can uncover key biochemical signatures without
additional laboratory experiments. Our approach enables real-time, spatially
aware fungal monitoring and establishes a scalable and affordable framework for
autonomous environmental sensing.

</details>


### [21] [Neural Network Based Framework for Passive Intermodulation Cancellation in MIMO Systems](https://arxiv.org/abs/2509.19382)
*Xiaolong Li,Zhi-qin John Xu,Peiting You,Yifei Zhu*

Main category: eess.SP

TL;DR: 提出了一种轻量级深度学习框架，利用深度可分离卷积和空洞卷积来有效抑制MIMO-OFDM系统中的无源互调干扰，在实验中获得29dB的平均功率误差改善，仅需11k可训练参数。


<details>
  <summary>Details</summary>
Motivation: 5G及后续通信系统中，无源互调已成为MIMO-OFDM系统自干扰的关键来源。传统消除方法依赖复杂的非线性模型，存在可扩展性有限和计算成本高的问题。

Method: 采用深度可分离卷积和空洞卷积来高效捕捉天线和子载波间的非线性依赖关系，同时使用循环学习率调度和梯度裁剪来增强收敛性。

Result: 在受控MIMO实验设置中，该方法有效抑制了三阶无源互调失真，实现了高达29dB的平均功率误差改善，仅使用11k可训练参数。

Conclusion: 紧凑的神经网络架构在可扩展干扰抑制方面具有巨大潜力，为未来无线通信系统提供了高效解决方案。

Abstract: Passive intermodulation (PIM) has emerged as a critical source of
self-interference in modern MIMO-OFDM systems, especially under the stringent
requirements of 5G and beyond. Conventional cancellation methods often rely on
complex nonlinear models with limited scalability and high computational cost.
In this work, we propose a lightweight deep learning framework for PIM
cancellation that leverages depthwise separable convolutions and dilated
convolutions to efficiently capture nonlinear dependencies across antennas and
subcarriers. To further enhance convergence, we adopt a cyclic learning rate
schedule and gradient clipping. In a controlled MIMO experimental setup, the
method effectively suppresses third-order passive intermodulation (PIM)
distortion, achieving up to 29dB of average power error (APE) with only 11k
trainable parameters. These results highlight the potential of compact neural
architectures for scalable interference mitigation in future wireless
communication systems.

</details>


### [22] [Human Activity Recognition Based on Electrocardiogram Data Only](https://arxiv.org/abs/2509.19328)
*Sina Montazeri,Waltenegus Dargie,Yunhe Feng,Kewei Sha*

Main category: eess.SP

TL;DR: 本文首次证明仅使用心电图（ECG）即可在六种不同活动中实现稳健的活动识别，超越了以往工作的范畴。


<details>
  <summary>Details</summary>
Motivation: 传统活动识别依赖惯性测量单元（IMU），但IMU资源密集且需要校准。虽然ECG方法已被探索，但通常作为IMU的补充或仅限于广泛分类。

Method: 设计并评估了三种新的深度学习模型：带有Squeeze-and-Excitation块的CNN分类器、带有扩张卷积的ResNet分类器，以及结合卷积特征提取和注意力机制的CNNTransformer混合模型。

Result: 在54名受试者的六种活动数据上测试，所有三种模型对已见受试者的准确率超过94%，CNNTransformer混合模型对未见受试者的准确率达到72%。

Conclusion: 本研究首次成功实现了仅基于ECG的多项身体活动分类，为开发能够同时进行心脏监测和活动识别的下一代可穿戴设备提供了重要潜力。

Abstract: Human activity recognition is critical for applications such as early
intervention and health analytics. Traditional activity recognition relies on
inertial measurement units (IMUs), which are resource intensive and require
calibration. Although electrocardiogram (ECG)-based methods have been explored,
these have typically served as supplements to IMUs or have been limited to
broad categorical classification such as fall detection or active vs. inactive
in daily activities. In this paper, we advance the field by demonstrating, for
the first time, robust recognition of activity only with ECG in six distinct
activities, which is beyond the scope of previous work. We design and evaluate
three new deep learning models, including a CNN classifier with
Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet
classifier with dilated convolutions for multiscale temporal dependency
capture, and a novel CNNTransformer hybrid combining convolutional feature
extraction with attention mechanisms for long-range temporal relationship
modeling. Tested on data from 54 subjects for six activities, all three models
achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid
reaching the best accuracy of 72% for unseen subjects, a result that can be
further improved by increasing the training population. This study demonstrates
the first successful ECG-only activity classification in multiple physical
activities, offering significant potential for developing next-generation
wearables capable of simultaneous cardiac monitoring and activity recognition
without additional motion sensors.

</details>


### [23] [Impact of RHIs and ipSIC on Active RIS-NOMA Systems with Low-Precision ADCs](https://arxiv.org/abs/2509.19383)
*Qianqian Li,Hua Li,Shiya Hao,Lintao Li,Xiaoming Dai*

Main category: eess.SP

TL;DR: 该研究评估了采用低精度ADC的主动可重构智能表面辅助非正交多址系统的性能，推导了考虑残余硬件损伤和不完美连续干扰消除的中断概率分析近似，并分析了高信噪比下的渐近性能、系统吞吐量和分集阶数。


<details>
  <summary>Details</summary>
Motivation: 研究主动可重构智能表面在非正交多址系统中的应用潜力，特别是在使用低精度ADC时如何克服性能限制，探索通过优化功率和反射单元数量来提升系统性能的方法。

Method: 采用理论分析方法推导中断概率的解析近似，考虑残余硬件损伤和不完美连续干扰消除的影响，并通过仿真验证主动RIS-NOMA系统相对于被动RIS-NOMA系统的性能优势。

Result: 仿真结果表明，量化ARIS-NOMA系统在中断概率和吞吐量方面优于被动PRIS-NOMA系统，且随着反射单元数量的增加，两种系统的中断性能均有显著改善。低精度ADC的负面影响可以通过优化发射功率和增加反射单元数量来有效缓解。

Conclusion: 主动可重构智能表面辅助的非正交多址系统在使用低精度ADC时仍能保持良好性能，通过适当的系统参数优化可以实现比被动系统更优的性能表现，为未来通信系统设计提供了有价值的参考。

Abstract: This study evaluates the performance of an active reconfigurable intelligent
surface (ARIS)-assisted non-orthogonal multiple access (NOMA) system employing
low-precision analog-to-digital converters (ADCs). Analytical approximations
for the outage probability (OP) are derived, considering residual hardware
impairments (RHIs) and imperfect successive interference cancellation (ipSIC).
Additionally, we analyze the asymptotic OP, system throughput, and diversity
order at high signal-to-noise ratios (SNRs). Simulation results demonstrate
that the proposed quantized ARIS-NOMA system outperforms its passive
counterpart (PRIS-NOMA), achieving lower OP and higher throughput with reduced
transmit power requirements and fewer reflecting elements. Moreover, the outage
performance of both quantized ARIS-NOMA and PRIS-NOMA systems demonstrates
significant improvement as the number of reflecting elements increases. The
negative impacts of low-precision ADCs can be effectively mitigated by
optimizing transmit power and scaling the number of reflecting elements.

</details>


### [24] [LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition](https://arxiv.org/abs/2509.19330)
*Zejun Liu,Yunshan Chen,Chengxi Xie,Huan Liu*

Main category: eess.SP

TL;DR: 本文介绍了LibEMER，一个用于EEG多模态情感识别的开源评估框架，旨在解决该领域缺乏开源实现、标准化基准和深入讨论的问题。


<details>
  <summary>Details</summary>
Motivation: EEG多模态情感识别领域存在三个关键问题：缺乏开源实现、缺乏标准化透明基准、缺乏对主要挑战和研究方向的深入讨论。

Method: 开发了LibEMER框架，提供可复现的PyTorch实现、标准化数据预处理、模型实现和实验设置协议。

Result: 该框架在三个广泛使用的公共数据集和两个学习任务上实现了无偏性能评估。

Conclusion: LibEMER为EEG多模态情感识别研究提供了统一的评估平台，有助于推动该领域的公平比较和进一步发展。

Abstract: EEG-based multimodal emotion recognition(EMER) has gained significant
attention and witnessed notable advancements, the inherent complexity of human
neural systems has motivated substantial efforts toward multimodal approaches.
However, this field currently suffers from three critical limitations: (i) the
absence of open-source implementations. (ii) the lack of standardized and
transparent benchmarks for fair performance analysis. (iii) in-depth discussion
regarding main challenges and promising research directions is a notable
scarcity. To address these challenges, we introduce LibEMER, a unified
evaluation framework that provides fully reproducible PyTorch implementations
of curated deep learning methods alongside standardized protocols for data
preprocessing, model realization, and experimental setups. This framework
enables unbiased performance assessment on three widely-used public datasets
across two learning tasks. The open-source library is publicly accessible at:
https://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384

</details>


### [25] [Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention](https://arxiv.org/abs/2509.19331)
*Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin*

Main category: eess.SP

TL;DR: 提出了全息Transformer，将波干涉原理融入自注意力机制，通过相对相位调制交互并相干叠加值，确保幅度和相位的一致性，在复数信号处理中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大多数深度学习模型将注意力视为实值相关性，忽略了复数信号中同时包含幅度和相位的干涉效应。

Method: 引入全息注意力机制，通过相对相位调制交互，相干叠加值；采用双头解码器同时重构输入和预测任务输出，防止相位崩溃。

Result: 在PolSAR图像分类和无线信道预测实验中表现出强性能，获得高分类精度和F1分数，低回归误差，对相位扰动具有更强的鲁棒性。

Conclusion: 在注意力中强制物理一致性可带来复数学习中的泛化改进，为相干信号建模提供了统一的物理基础框架。

Abstract: Complex-valued signals encode both amplitude and phase, yet most deep models
treat attention as real-valued correlation, overlooking interference effects.
We introduce the Holographic Transformer, a physics-inspired architecture that
incorporates wave interference principles into self-attention. Holographic
attention modulates interactions by relative phase and coherently superimposes
values, ensuring consistency between amplitude and phase. A dual-headed decoder
simultaneously reconstructs the input and predicts task outputs, preventing
phase collapse when losses prioritize magnitude over phase. We demonstrate that
holographic attention implements a discrete interference operator and maintains
phase consistency under linear mixing. Experiments on PolSAR image
classification and wireless channel prediction show strong performance,
achieving high classification accuracy and F1 scores, low regression error, and
increased robustness to phase perturbations. These results highlight that
enforcing physical consistency in attention leads to generalizable improvements
in complex-valued learning and provides a unified, physics-based framework for
coherent signal modeling. The code is available at
https://github.com/EonHao/Holographic-Transformers.

</details>


### [26] [A Spatio-Temporal Feature Fusion EEG Virtual Channel Signal Generation Network and Its Application in Anxiety Assessment](https://arxiv.org/abs/2509.19334)
*Shangqing Yuan,Wenshuang Zhai,Shengwen Guo*

Main category: eess.SP

TL;DR: 本研究提出了一种基于时空特征融合的EEG虚拟通道信号生成网络，用于解决便携式EEG设备通道有限的问题，通过4个额叶通道生成13个脑区的虚拟EEG信号，显著提升了焦虑分类性能。


<details>
  <summary>Details</summary>
Motivation: 便携式EEG设备存在通道数量有限、信息采集不足的问题，限制了其在脑电信号分析和应用中的效果。

Method: 采用二维卷积神经网络架构，包含并行的时间域和空间域特征提取模块，以及特征融合模块，基于PRED+CT数据库的119名受试者多通道EEG信号进行验证。

Result: 生成的虚拟通道EEG信号与原始真实信号的平均相关系数为0.6724，平均绝对误差为3.9470；结合虚拟信号进行焦虑分类时，显著提升了支持向量机的分类性能。

Conclusion: 该网络生成的虚拟EEG信号与真实信号具有高度一致性，能有效缓解便携式EEG设备信息获取不足的问题，并增强机器学习算法在焦虑分类中的表现。

Abstract: To address the issue of limited channels and insufficient information
collection in portable EEG devices, this study explores an EEG virtual channel
signal generation network using a novel spatio-temporal feature fusion
strategy. Based on the EEG signals from four frontal lobe channels, the network
aims to generate virtual channel EEG signals for other 13 important brain
regions. The architecture of the network is a two-dimensional convolutional
neural network and it includes a parallel module for temporal and spatial
domain feature extraction, followed by a feature fusion module. The public
PRED+CT database, which includes multi-channel EEG signals from 119 subjects,
was selected to verify the constructed network. The results showed that the
average correlation coefficient between the generated virtual channel EEG
signals and the original real signals was 0.6724, with an average absolute
error of 3.9470. Furthermore, the 13 virtual channel EEG signals were combined
with the original EEG signals of four brain regions and then used for anxiety
classification with a support vector machine. The results indicate that the
virtual EEG signals generated by the constructed network not only have a high
degree of consistency with the real channel EEG signals but also significantly
enhance the performance of machine learning algorithms for anxiety
classification. This study effectively alleviates the problem of insufficient
information acquisition by portable EEG devices with few channels.

</details>


### [27] [CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for Integrated Sensing and Communication Systems](https://arxiv.org/abs/2509.19335)
*Xudong Zhang,Jingbo Tan,Zhizhen Ren,Jintao Wang,Yihua Ma,Jian Song*

Main category: eess.SP

TL;DR: CSIYOLO是一个基于CSI的散射体定位框架，仅使用单个基站-用户设备对的CSI估计，无需修改波形或硬件，可实现高精度散射体定位。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC散射感知方法依赖波形硬件修改或传统信号处理方案，与现有通信系统兼容性差且感知精度有限。

Method: 提出基于锚点的散射参数检测方法（受YOLO架构启发），将散射参数提取建模为图像检测问题，然后推导CSI定位算法确定散射体位置，并设计了可扩展网络结构和噪声注入训练策略。

Result: 实验表明该方法在不同散射体数量和估计误差下，能以相对较低复杂度显著优于现有方法的定位精度。

Conclusion: CSIYOLO框架仅基于估计的CSI运行，无需修改波形或信号处理流程，可作为插件无缝集成到现有通信系统中。

Abstract: ISAC is regarded as a promising technology for next-generation communication
systems, enabling simultaneous data transmission and target sensing. Among
various tasks in ISAC, scatter sensing plays a crucial role in exploiting the
full potential of ISAC and supporting applications such as autonomous driving
and low-altitude economy. However, most existing methods rely on either
waveform and hardware modifications or traditional signal processing schemes,
leading to poor compatibility with current communication systems and limited
sensing accuracy. To address these challenges, we propose CSIYOLO, a framework
that performs scatter localization only using estimated CSI from a single base
station-user equipment pair. This framework comprises two main components:
anchor-based scatter parameter detection and CSI-based scatter localization.
First, by formulating scatter parameter extraction as an image detection
problem, we propose an anchor-based scatter parameter detection method inspired
by You Only Look Once architectures. After that, a CSI-based localization
algorithm is derived to determine scatter locations with extracted parameters.
Moreover, to improve localization accuracy and implementation efficiency, we
design an extendable network structure with task-oriented optimizations,
enabling multi-scale anchor detection and better adaptation to CSI
characteristics. A noise injection training strategy is further designed to
enhance robustness against channel estimation errors. Since the proposed
framework operates solely on estimated CSI without modifying waveforms or
signal processing pipelines, it can be seamlessly integrated into existing
communication systems as a plugin. Experiments show that our proposed method
can significantly outperform existing methods in scatter localization accuracy
with relatively low complexities under varying numbers of scatters and
estimation errors.

</details>


### [28] [Low-Cost Sensor Fusion Framework for Organic Substance Classification and Quality Control Using Classification Methods](https://arxiv.org/abs/2509.19367)
*Borhan Uddin Chowdhury,Damian Valles,Md Raf E Ul Shougat*

Main category: eess.SP

TL;DR: 基于Arduino Mega 2560微控制器平台开发的多传感器融合框架，用于有机物质的快速无损分类和质量控制，通过机器学习模型实现93-94%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、非破坏性的有机物质分类和质量控制方法，利用商业环境传感器和气体传感器构建实用的检测平台。

Method: 使用Arduino Mega 2560微控制器配备三个商业传感器收集数据，通过相关性分析进行特征选择，采用PCA/LDA降维，训练SVM、决策树、随机森林、ANN和集成投票分类器等多种机器学习模型。

Result: 最优模型（调优随机森林、集成分类器和ANN）在测试集上达到93-94%的准确率，证明了该低成本多传感器平台的有效性。

Conclusion: 基于Arduino的低成本多传感器平台结合先进的机器学习和相关性驱动的特征工程，能够可靠地识别有机化合物并进行质量控制。

Abstract: We present a sensor-fusion framework for rapid, non-destructive
classification and quality control of organic substances, built on a standard
Arduino Mega 2560 microcontroller platform equipped with three commercial
environmental and gas sensors. All data used in this study were generated
in-house: sensor outputs for ten distinct classes - including fresh and expired
samples of apple juice, onion, garlic, and ginger, as well as cinnamon and
cardamom - were systematically collected and labeled using this hardware setup,
resulting in a unique, application-specific dataset. Correlation analysis was
employed as part of the preprocessing pipeline for feature selection. After
preprocessing and dimensionality reduction (PCA/LDA), multiple supervised
learning models - including Support Vector Machine (SVM), Decision Tree (DT),
and Random Forest (RF), each with hyperparameter tuning, as well as an
Artificial Neural Network (ANN) and an ensemble voting classifier - were
trained and cross-validated on the collected dataset. The best-performing
models, including tuned Random Forest, ensemble, and ANN, achieved test
accuracies in the 93 to 94 percent range. These results demonstrate that
low-cost, multisensory platforms based on the Arduino Mega 2560, combined with
advanced machine learning and correlation-driven feature engineering, enable
reliable identification and quality control of organic compounds.

</details>


### [29] [Short-Term Regional Electricity Demand Forecasting in Argentina Using LSTM Networks](https://arxiv.org/abs/2509.19374)
*Oscar A. Oviedo*

Main category: eess.SP

TL;DR: 开发基于LSTM的深度学习模型预测阿根廷科尔多瓦短期小时电力需求，整合历史数据和外部变量，实现高精度预测（MAPE 3.20%，R² 0.95）。


<details>
  <summary>Details</summary>
Motivation: 为电网运营商提供优化的规划和控制策略，应对不同需求场景下的电力调度挑战。

Method: 使用LSTM网络结合历史消费数据、气候因素、时间周期和人口统计等外生变量，进行模型设计和超参数优化，并辅以随机森林回归的可解释性分析和峰值时间预测评估。

Result: 模型预测精度高，MAPE为3.20%，决定系数0.95；在预测日需求极值时间方面，超过三分之二的测试日达到精确小时准确度，90%以上案例误差在1小时内。

Conclusion: 该框架不仅预测准确，且具有操作相关性，为电网管理提供了有价值的见解。

Abstract: This study presents the development and optimization of a deep learning model
based on Long Short-Term Memory (LSTM) networks to predict short-term hourly
electricity demand in C\'ordoba, Argentina. Integrating historical consumption
data with exogenous variables (climatic factors, temporal cycles, and
demographic statistics), the model achieved high predictive precision, with a
mean absolute percentage error of 3.20\% and a determination coefficient of
0.95. The inclusion of periodic temporal encodings and weather variables proved
crucial to capture seasonal patterns and extreme consumption events, enhancing
the robustness and generalizability of the model. In addition to the design and
hyperparameter optimization of the LSTM architecture, two complementary
analyses were carried out: (i) an interpretability study using Random Forest
regression to quantify the relative importance of exogenous drivers, and (ii)
an evaluation of model performance in predicting the timing of daily demand
maxima and minima, achieving exact-hour accuracy in more than two-thirds of the
test days and within abs(1) hour in over 90\% of cases. Together, these results
highlight both the predictive accuracy and operational relevance of the
proposed framework, providing valuable insights for grid operators seeking
optimized planning and control strategies under diverse demand scenarios.

</details>


### [30] [Data-Driven Reconstruction of Significant Wave Heights from Sparse Observations](https://arxiv.org/abs/2509.19384)
*Hongyuan Shi,Yilin Zhai,Ping Dong,Zaijin You,Chao Zhan,Qing Wang*

Main category: eess.SP

TL;DR: AUWave是一个混合深度学习框架，用于从稀疏浮标观测数据重建高分辨率区域有效波高场，通过多尺度U-Net和注意力机制提升重建精度。


<details>
  <summary>Details</summary>
Motivation: 从稀疏不均匀的浮标观测数据重建高分辨率波浪场是海洋监测和风险评估的核心挑战，现有方法在稀疏采样条件下性能有限。

Method: 提出AUWave混合深度学习框架，结合站点序列编码器(MLP)和带瓶颈自注意力层的多尺度U-Net，通过贝叶斯超参数搜索优化模型参数。

Result: 在夏威夷区域的NDBC浮标观测和ERA5再分析数据上，AUWave达到最小验证损失0.043285，在数据较丰富配置下显著优于基线方法。

Conclusion: AUWave为数据同化提供了可扩展的高分辨率先验，误差分析和站点消融实验为观测网络设计提供了实用指导。

Abstract: Reconstructing high-resolution regional significant wave height fields from
sparse and uneven buoy observations remains a core challenge for ocean
monitoring and risk-aware operations. We introduce AUWave, a hybrid deep
learning framework that fuses a station-wise sequence encoder (MLP) with a
multi-scale U-Net enhanced by a bottleneck self-attention layer to recover
32$\times$32 regional SWH fields. A systematic Bayesian hyperparameter search
with Optuna identifies the learning rate as the dominant driver of
generalization, followed by the scheduler decay and the latent dimension. Using
NDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave
attains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE
distribution. Spatial errors are lowest near observation sites and increase
with distance, reflecting identifiability limits under sparse sampling.
Sensitivity experiments show that AUWave consistently outperforms a
representative baseline in data-richer configurations, while the baseline is
only marginally competitive in the most underdetermined single-buoy cases. The
architecture's multi-scale and attention components translate into accuracy
gains when minimal but non-trivial spatial anchoring is available. Error maps
and buoy ablations reveal key anchor stations whose removal disproportionately
degrades performance, offering actionable guidance for network design. AUWave
provides a scalable pathway for gap filling, high-resolution priors for data
assimilation, and contingency reconstruction.

</details>


### [31] [A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application](https://arxiv.org/abs/2509.19385)
*Benjamin J. Choi,Griffin Milsap,Clara A. Scholl,Francesco Tenore,Mattson Ogg*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合专家（MoE）框架的新型EEG信号去噪算法，专门针对高噪声环境下的EMG伪影去除问题，在EEGdenoiseNet数据集上取得了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于神经网络的EEG去噪方法在高噪声环境下表现不佳，需要开发更有效的EMG伪影去除算法来改善神经接口的信号质量。

Method: 采用混合专家（MoE）框架，结合三个新的统计洞察：EMG伪影可分类、窄SNR范围专家专业化、基于相关性的目标函数。使用CNN和RNN神经网络构建MoE去噪模型。

Result: 在EEGdenoiseNet数据集（67名受试者）上测试，MoE模型在整体性能上与SOTA方法相当，在高噪声环境下表现出更优的下界性能。

Conclusion: MoE框架在EMG伪影去除方面显示出潜力，特别是在高噪声环境下，有望推动更有效的神经接口发展。

Abstract: Effective control of neural interfaces is limited by poor signal quality.
While neural network-based electroencephalography (EEG) denoising methods for
electromyogenic (EMG) artifacts have improved in recent years, current
state-of-the-art (SOTA) models perform suboptimally in settings with high
noise. To address the shortcomings of current machine learning (ML)-based
denoising algorithms, we present a signal filtration algorithm driven by a new
mixture-of-experts (MoE) framework. Our algorithm leverages three new
statistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can
be partitioned into quantifiable subtypes to aid downstream MoE classification,
(2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can
achieve performance increases through specialization, and (3) correlation-based
objective functions, in conjunction with rescaling algorithms, can enable
faster convergence in a neural network-based denoising context. We empirically
demonstrate these three insights into EMG artifact removal and use our findings
to create a new downstream MoE denoising algorithm consisting of convolutional
(CNN) and recurrent (RNN) neural networks. We tested all results on a major
benchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our
MoE denoising model achieved competitive overall performance with SOTA ML
denoising algorithms and superior lower bound performance in high noise
settings. These preliminary results highlight the promise of our MoE framework
for enabling advances in EMG artifact removal for EEG processing, especially in
high noise settings. Further research and development will be necessary to
assess our MoE framework on a wider range of real-world test cases and explore
its downstream potential to unlock more effective neural interfaces.

</details>


### [32] [Hybrid Pipeline SWD Detection in Long-Term EEG Signals](https://arxiv.org/abs/2509.19387)
*Antonio Quintero Rincon,Nicolas Masino,Veronica Marsico,Hadj Batatia*

Main category: eess.SP

TL;DR: 提出了一种轻量级混合管道，结合分析特征和浅层人工神经网络，用于在长期单极脑电图中准确检测棘慢波放电（SWD），实现了高敏感性和特异性。


<details>
  <summary>Details</summary>
Motivation: 棘慢波放电（SWD）是失神癫痫的脑电图标志，但在多日记录中手动识别SWD仍然劳动密集且容易出错，需要自动化解决方案。

Method: 使用双边移动平均滤波器抑制正常背景活动的高频成分，然后计算残差信号的均值和标准差作为特征向量，输入单隐藏层人工神经网络进行分类。

Result: 在12名患者的780个通道上评估，正确检测出384个事件（敏感性98%），特异性96.2%，总体准确率97.2%。

Conclusion: 正态分布描述符与小型神经网络结合为扩展脑电图记录中的自动化SWD筛查提供了有效且计算成本低的解决方案。

Abstract: Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of
absence epilepsy, yet their manual identification in multi-day recordings
remains labour-intensive and error-prone. We present a lightweight hybrid
pipeline that couples analytical features with a shallow artificial neural
network (ANN) for accurate, patient-specific SWD detection in long-term,
monopolar EEG. A two-sided moving-average (MA) filter first suppresses the
high-frequency components of normal background activity. The residual signal is
then summarised by the mean and the standard deviation of its normally
distributed samples, yielding a compact, two-dimensional feature vector for
every 20s window. These features are fed to a single-hidden-layer ANN trained
via back-propagation to classify each window as SWD or non-SWD. The method was
evaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392
annotated SWD events. It correctly detected 384 events (sensitivity: 98%) while
achieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because
feature extraction is analytic, and the classifier is small, the pipeline runs
in real-time and requires no manual threshold tuning. These results indicate
that normal-distribution descriptors combined with a modest ANN provide an
effective and computationally inexpensive solution for automated SWD screening
in extended EEG recordings.

</details>


### [33] [Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG](https://arxiv.org/abs/2509.19397)
*Jiarui Jin,Xiaocheng Fang,Haoyu Wang,Jun Li,Che Liu,Donglin Xie,Hongyan Li,Shenda Hong*

Main category: eess.SP

TL;DR: SelfMIS是一个用于从单导联心电图检测心肌梗死的潜在空间对齐学习框架，通过自切割策略将多导联与单导联心电图在潜在空间直接对齐，提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 单导联心电图检测心肌梗死具有挑战性，因为空间信息有限。现有生成方法在信号层面优化，但存在潜在空间差距，影响诊断效果。需要探索潜在空间对齐是否能帮助解决这一问题。

Method: 提出SelfMIS框架，摒弃手动数据增强，采用自切割策略将多导联心电图与其对应的单导联片段配对，并在潜在空间直接对齐。这种设计将学习目标从追求变换不变性转向丰富单导联表示。

Result: SelfMIS在九种心肌梗死类型上均优于基线模型，同时保持更简单的架构和更低的计算开销。

Conclusion: 直接潜在空间对齐能有效提升单导联心电图的心肌梗死检测性能，证明了该方法的有效性。

Abstract: Myocardial infarction is a critical manifestation of coronary artery disease,
yet detecting it from single-lead electrocardiogram (ECG) remains challenging
due to limited spatial information. An intuitive idea is to convert single-lead
into multiple-lead ECG for classification by pre-trained models, but generative
methods optimized at the signal level in most cases leave a large latent space
gap, ultimately degrading diagnostic performance. This naturally raises the
question of whether latent space alignment could help. However, most prior ECG
alignment methods focus on learning transformation invariance, which mismatches
the goal of single-lead detection. To address this issue, we propose SelfMIS, a
simple yet effective alignment learning framework to improve myocardial
infarction detection from single-lead ECG. Discarding manual data
augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead
ECG with their corresponding single-lead segments and directly align them in
the latent space. This design shifts the learning objective from pursuing
transformation invariance to enriching the single-lead representation,
explicitly driving the single-lead ECG encoder to learn a representation
capable of inferring global cardiac context from the local signal.
Experimentally, SelfMIS achieves superior performance over baseline models
across nine myocardial infarction types while maintaining a simpler
architecture and lower computational overhead, thereby substantiating the
efficacy of direct latent space alignment. Our code and checkpoint will be
publicly available after acceptance.

</details>


### [34] [SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs](https://arxiv.org/abs/2509.19401)
*Jiazhen Hong,Geoff Mackellar,Soheila Ghane*

Main category: eess.SP

TL;DR: SpellerSSL框架结合自监督学习和P300聚合，解决了EEG P300拼写器BCI的低信噪比、泛化性差和校准耗时的问题，在公开数据集上达到94%的字符识别率和21.86 bits/min的信息传输率。


<details>
  <summary>Details</summary>
Motivation: 解决EEG P300拼写器BCI面临的三个主要挑战：低信噪比、泛化性差和校准时间过长。

Method: 提出SpellerSSL框架，包含P300聚合策略增强信噪比，使用定制1D U-Net骨干网络在跨域和域内EEG数据上进行自监督预训练，然后通过轻量级ERP-Head分类器进行微调。

Result: 在II-B公开数据集上，域内自监督学习达到94%的字符识别率（仅需7次重复），最高ITR为21.86 bits/min，同时将所需校准数据量减少60%。

Conclusion: 这是首个将自监督学习应用于P300拼写器的研究，展示了其在提高BCI效率和泛化性方面的潜力，为P300拼写器BCI的EEG基础模型铺平了道路。

Abstract: Electroencephalogram (EEG)-based P300 speller brain-computer interfaces
(BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor
generalization, and time-consuming calibration. We propose SpellerSSL, a
framework that combines self-supervised learning (SSL) with P300 aggregation to
address these issues. First, we introduce an aggregation strategy to enhance
SNR. Second, to achieve generalization in training, we employ a customized 1D
U-Net backbone and pretrain the model on both cross-domain and in-domain EEG
data. The pretrained model is subsequently fine-tuned with a lightweight
ERP-Head classifier for P300 detection, which adapts the learned
representations to subject-specific data. Our evaluations on calibration time
demonstrate that combining the aggregation strategy with SSL significantly
reduces the calibration burden per subject and improves robustness across
subjects. Experimental results show that SSL learns effective EEG
representations in both in-domain and cross-domain, with in-domain achieving a
state-of-the-art character recognition rate of 94% with only 7 repetitions and
the highest information transfer rate (ITR) of 21.86 bits/min on the public
II-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the
required calibration size by 60% while maintaining a comparable character
recognition rate. To the best of our knowledge, this is the first study to
apply SSL to P300 spellers, highlighting its potential to improve both
efficiency and generalization in speller BCIs and paving the way toward an EEG
foundation model for P300 speller BCIs.

</details>


### [35] [Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces](https://arxiv.org/abs/2509.19403)
*Sheng-Bin Duan,Jian-Long Hao,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Zeng-Guang Hou*

Main category: eess.SP

TL;DR: 该研究提出了一种基于双阶段对齐和自监督的在线自适应算法，用于解决脑机接口系统中个体脑电信号差异的问题，实现无需校准的快速操作。


<details>
  <summary>Details</summary>
Motivation: 个体脑电信号的差异阻碍了基于脑电图的脑机接口系统的在线应用，需要一种能够快速适应新用户的方法。

Method: 采用双阶段对齐方法：先在EEG数据空间进行欧几里得对齐，然后在表示空间更新批量归一化统计量。同时设计自监督损失函数，使用解码器生成的软伪标签作为未知真实标签的代理，并通过香农熵进行校准。

Result: 在五个公共数据集和七个解码器上的实验表明，该算法可以无缝集成到不同BCI范式和架构中。每次迭代仅使用单个在线试验更新解码器，在稳态视觉诱发电位和运动想象任务上分别获得4.9%和3.6%的平均准确率提升。

Conclusion: 该算法支持快速校准操作，在脑机接口应用中具有巨大潜力，能够有效解决个体差异问题。

Abstract: Individual differences in brain activity hinder the online application of
electroencephalogram (EEG)-based brain computer interface (BCI) systems. To
overcome this limitation, this study proposes an online adaptation algorithm
for unseen subjects via dual-stage alignment and self-supervision. The
alignment process begins by applying Euclidean alignment in the EEG data space
and then updates batch normalization statistics in the representation space.
Moreover, a self-supervised loss is designed to update the decoder. The loss is
computed by soft pseudo-labels derived from the decoder as a proxy for the
unknown ground truth, and is calibrated by Shannon entropy to facilitate
self-supervised training. Experiments across five public datasets and seven
decoders show the proposed algorithm can be integrated seamlessly regardless of
BCI paradigm and decoder architecture. In each iteration, the decoder is
updated with a single online trial, which yields average accuracy gains of 4.9%
on steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.
These results support fast-calibration operation and show that the proposed
algorithm has great potential for BCI applications.

</details>


### [36] [Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design](https://arxiv.org/abs/2509.19551)
*Jérôme Leclère,Thyagaraja Marathe,Tyler G. R. Reid*

Main category: eess.SP

TL;DR: 本文分析了低地球轨道(LEO)卫星导航系统Pulsar的特性，通过与GPS对比研究其信号参数差异，并探讨这些差异对接收机设计的影响和优化策略。


<details>
  <summary>Details</summary>
Motivation: 随着LEO星座如Pulsar在定位导航授时(PNT)领域的重要性日益增加，需要深入理解其独特的信号特性和对接收机设计的新要求。

Method: 使用GNSS模拟器分析Pulsar卫星的轨道参数，包括卫星过境时间、仰角、多普勒频移、多普勒变化率、距离和可见卫星数等，并与GPS进行对比分析。

Result: 研究发现LEO系统具有更强的信号、更快的动态特性、更短的首次定位时间，但也带来了更大的多普勒范围和更高的多普勒变化率等挑战。

Conclusion: 基于参数分析，提出了接收机设计优化策略，包括改进捕获算法、应用预测和优先级技术，可显著减少捕获时间并降低功耗。

Abstract: The landscape of global navigation satellite systems (GNSS) is expanding with
the emergence of low Earth orbit (LEO) constellations such as Pulsar, which are
expected to play a key role in the future of positioning, navigation, and
timing (PNT). LEO-based systems provide advantages including stronger signals
for greater robustness, faster dynamics that aid convergence and multipath
mitigation, and shorter time to first fix (TTFF) enabled by high data rates.
These benefits, however, come with changes in signal behavior and constellation
geometry that require careful consideration in receiver design. This paper
investigates Pulsar properties using a GNSS simulator, analyzing parameters
such as satellite pass duration, elevation, Doppler shift, Doppler rate, range,
and number of satellites in view. Comparisons with GPS highlight the
differences introduced by LEO operation. The analysis examines temporal
evolution, statistical distributions, and maximum and minimum values. Beyond
these statistical insights, the study explores interdependencies between
parameters and differences across satellites, providing additional perspective.
Evaluations are performed at multiple latitudes to ensure a worldwide
perspective, and the impact of applying different elevation masks is discussed
where relevant. Building on these findings, the paper assesses Pulsar's impact
on receiver design from two standpoints: design considerations, addressing
expanded Doppler ranges, higher Doppler rates, and unique constellation
structure; and design optimizations, exploiting parameter analyses and
interdependencies (e.g., Doppler rate vs Doppler) to refine acquisition
strategies and applying prediction and prioritization techniques to avoid
unnecessary computations. Together, these optimizations can reduce acquisition
time and lower receiver power consumption.

</details>


### [37] [DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation](https://arxiv.org/abs/2509.19594)
*Mohammadhossein Karimi,Yuanzhe Gong,Tho Le-Ngoc*

Main category: eess.SP

TL;DR: 提出一种基于深度学习的近场零陷控制波束聚焦框架，用于超大规模MIMO系统中的多用户干扰抑制。


<details>
  <summary>Details</summary>
Motivation: 解决超大规模MIMO系统中多用户干扰问题，实现实时、可扩展的波束聚焦和干扰抑制。

Method: 采用双估计器架构，包含两个全连接深度神经网络，分别预测NCBF权重的相位和幅度分量，使用期望用户和干扰用户的位置信息。模型通过LCMV波束形成算法生成的大数据集进行训练。

Result: DNN模型预测精度高，相位估计测试误差为0.067弧度，幅度估计为0.206 dB。全波仿真显示DNN预测与LCMV方案在波束模式上高度一致，平均MUI抑制达到36.7 dB，所有测试案例中干扰抑制均超过17.5 dB。

Conclusion: 该方法为未来近场多用户无线通信提供了一种有前景的解决方案，能够实现可扩展的实时波束聚焦和有效干扰抑制。

Abstract: This paper proposes a deep learning-based framework for near-field nulling
control beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate
multi-user interference (MUI). A dual-estimator architecture comprising two
fully connected deep neural networks (FCDNNs) is developed to separately
predict the phase and magnitude components of NCBF weights, using locations of
both desired and interfering users. The models are trained on a large dataset
generated via a Linearly Constrained Minimum Variance (LCMV) beamforming
algorithm to accommodate diverse user configurations, including both collinear
and non-collinear scenarios. Illustrative results demonstrate that the proposed
DNN models achieve high prediction accuracy, with test errors of only 0.067
radians for phase estimation and 0.206 dB for magnitude estimation. Full-wave
simulations incorporating realistic element radiation patterns and
inter-element coupling confirm the close agreement between the beam patterns
produced by the DNN-predicted and LCMV-based NCBF schemes under practical
deployment conditions. An average MUI suppression of 36.7 dB is achieved, with
interference mitigation exceeding 17.5 dB across all tested cases. The proposed
approach enables scalable and real-time beam focusing with effective
interference suppression, offering a promising solution for future near-field
multi-user wireless communications.

</details>


### [38] [Non-locally averaged pruned reassigned spectrograms: a tool for glottal pulse visualization and analysis](https://arxiv.org/abs/2509.19686)
*Gabriel J. Griswold,Mark A. Griswold*

Main category: eess.SP

TL;DR: 提出了一种改进的重分配谱图方法NAPReS，通过堆叠、求和和修剪大量声门脉冲来简化说话人声门脉冲模式的观察，在高噪声环境下比传统LPC方法更具可重复性。


<details>
  <summary>Details</summary>
Motivation: 传统重分配谱图在精确共振峰测量和说话人区分方面有优势，但无法以易于理解和可重复的方式可视化大量数据。

Method: 基于Fulop和Fitz的技术开发了NAPReS方法，通过非局部平均修剪重分配谱图来展示声门脉冲模式特征，并采用高斯混合模型进行共振峰拟合。

Result: NAPReS能够以易于理解和量化的方式显示大量数据，使低幅度循环结构的观察更加容易，在高噪声情况下比传统LPC拟合更具可重复性。

Conclusion: NAPReS方法为声门脉冲模式分析提供了更有效的可视化工具，在高噪声环境下表现出更好的性能，为共振峰分析提供了新的可能性。

Abstract: Reassigned spectrograms have shown advantages in precise formant measuring
and inter-speaker differentiation. However, reassigned spectrograms suffer from
their inability to visualize larger amounts of data in an easily comprehensible
and reproducible manner. Utilizing the techniques and tools developed by Fulop
and Fitz, a variation of the reassigned spectrogram is proposed. Non-locally
Averaged Pruned Reassigned Spectrograms (NAPReS) provide a simplified view into
the characteristics of a speaker's glottal pulsation patterns throughout the
centroid of a vowel through the stacking, summing, and pruning of large numbers
of glottal pulses. In this exploratory study, NAPReS has been shown to display
a large amount of data in an easily comprehensible and quantifiable manner,
while also making the observation of low-amplitude cyclical structures more
accessible. NAPReS also allows for alternative formant fitting methods such as
Gaussian mixture modeling. In this study, NAPReS with GMM was compared against
conventional LPC fitting of formant values and was shown to be more
reproducible than conventional LPC fitting in high-noise situations.

</details>


### [39] [Timeliness-Aware Joint Source and Channel Coding for Adaptive Image Transmission](https://arxiv.org/abs/2509.19754)
*Xiaolei Yang,Zijing Wang,Zhijin Qin,Xiaoming Tao*

Main category: eess.SP

TL;DR: 提出了一种基于信息价值(VoI)的自适应联合源信道编码(JSCC)方法，用于时间敏感应用中的图像传输，同时考虑重建质量和时效性。


<details>
  <summary>Details</summary>
Motivation: 现有无线系统带宽有限，难以同时满足高保真和低延迟的图像传输需求。语义通信通过传输目标导向的语义信息有望突破性能瓶颈。

Method: 设计了自适应码长的JSCC图像传输框架，构建VoI最大化问题，并提出基于深度强化学习的算法来优化传输码长。

Result: 实验结果表明，该方法在重建质量和时效性方面显著优于基线方案，特别是在低信噪比条件下表现优异。

Conclusion: 该方法为时间敏感无线网络中高效鲁棒的图像传输提供了有前景的解决方案。

Abstract: Accurate and timely image transmission is critical for emerging
time-sensitive applications such as remote sensing in satellite-assisted
Internet of Things. However, the bandwidth limitation poses a significant
challenge in existing wireless systems, making it difficult to fulfill the
requirements of both high-fidelity and low-latency image transmission. Semantic
communication is expected to break through the performance bottleneck by
focusing on the transmission of goal-oriented semantic information rather than
raw data. In this paper, we employ a new timeliness metric named the value of
information (VoI) and propose an adaptive joint source and channel coding
(JSCC) method for image transmission that simultaneously considers both
reconstruction quality and timeliness. Specifically, we first design a JSCC
framework for image transmission with adaptive code length. Next, we formulate
a VoI maximization problem by optimizing the transmission code length of the
adaptive JSCC under the reconstruction quality constraint. Then, a deep
reinforcement learning-based algorithm is proposed to solve the optimization
problem efficiently. Experimental results show that the proposed method
significantly outperforms baseline schemes in terms of reconstruction quality
and timeliness, particularly in low signal-to-noise ratio conditions, offering
a promising solution for efficient and robust image transmission in
time-sensitive wireless networks.

</details>


### [40] [Electromagnetics-Compliant Optimization of Dynamic Metasurface Antennas for Bistatic Sensing](https://arxiv.org/abs/2509.19801)
*Ioannis Gavras,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一种考虑物理约束的动态超表面天线（DMA）优化方法，用于双基地传感中的波束成形设计，通过低复杂度算法在存在不确定性的情况下实现高定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有DMA研究大多依赖理想化模型，忽略了超材料固有的结构约束和物理特性（如互耦效应和波导传播损耗），这限制了实际应用中的性能。

Method: 1. 提出考虑互耦和波导损耗的DMA物理一致性模型；2. 开发可处理的DMA响应近似方法；3. 构建鲁棒波束成形优化问题，最小化最坏情况位置误差；4. 设计两种低复杂度波束成形方法，基于新型波束码本进行离线搜索。

Result: 蒙特卡洛仿真验证了所提方法的准确性，表明精确建模互耦效应对保持高定位性能至关重要。在存在定位和同步不确定性的情况下，所提设计能达到与全数字和模拟对应方案相当的精度，同时满足DMA结构约束。

Conclusion: 物理一致性建模是DMA性能优化的关键，所提出的低复杂度设计方法在实际约束下能有效平衡性能和计算复杂度，为下一代无线系统中的DMA应用提供了实用解决方案。

Abstract: Dynamic Metasurface Antennas (DMAs) are recently attracting considerable
research interests due to their potential to enable low-cost, reconfigurable,
and highly scalable antenna array architectures for next generation wireless
systems. However, most of the existing literature relies on idealized models
for the DMA operation, often overlooking critical structural and physical
constraints inherent to their constituent metamaterials. In this paper,
leveraging a recently proposed model for this antenna architecture
incorporating physically consistent modeling of mutual coupling and waveguide
propagation losses, we optimize DMA-based transmission for bistatic sensing. A
tractable approximation for the DMA response is first presented, which enables
efficient optimization of the dynamically reconfigurable Lorentzian-constrained
responses of the array's metamaterials. In particular, we formulate a robust
beamforming optimization problem with the objective to minimize the worst-case
position error bound, in the presence of spatial uncertainties for the
environment's scatterers as well as synchronization uncertainties at the analog
combining multi-antenna receiver. To address the resulting high computational
complexity due to the possibly excessive number of metamaterial-based antennas
and their operation constraints, two low complexity beamforming design
approaches are presented that perform offline searching over a novel beam
codebook. The accuracy of all presented DMA designs is assessed by means of
Monte Carlo simulations for various system parameters, confirming that
accurately modeling mutual coupling is essential for maintaining increased
localization performance. It is also shown that, even under positioning and
synchronization uncertainties, the proposed designs yield accuracy comparable
to their fully digital and analog counterparts, while adhering to the
structural DMA constraints.

</details>


### [41] [Generalized Nonnegative Structured Kruskal Tensor Regression](https://arxiv.org/abs/2509.19900)
*Xinjue Wang,Esa Ollila,Sergiy A. Vorobyov,Ammar Mian*

Main category: eess.SP

TL;DR: 本文提出了广义非负结构化Kruskal张量回归(NS-KTR)，这是一个通过模态特定混合正则化和非负约束来增强可解释性和性能的新型张量回归框架。


<details>
  <summary>Details</summary>
Motivation: 处理多维张量数据中的结构异质性，同时适应线性和逻辑回归公式，以处理不同类型的响应变量。

Method: 集成融合LASSO、总变差和岭正则化器，每个都针对特定张量模态定制，并开发了基于交替方向乘子法(ADMM)的高效参数估计算法。

Result: 在合成信号和真实高光谱数据集上的综合实验表明，NS-KTR始终优于传统的张量回归方法。

Conclusion: 该框架能够在保持张量维度间不同结构特征的同时确保物理可解释性，特别适用于信号处理和高光谱图像分析应用。

Abstract: This paper introduces Generalized Nonnegative Structured Kruskal Tensor
Regression (NS-KTR), a novel tensor regression framework that enhances
interpretability and performance through mode-specific hybrid regularization
and nonnegativity constraints. Our approach accommodates both linear and
logistic regression formulations for diverse response variables while
addressing the structural heterogeneity inherent in multidimensional tensor
data. We integrate fused LASSO, total variation, and ridge regularizers, each
tailored to specific tensor modes, and develop an efficient alternating
direction method of multipliers (ADMM) based algorithm for parameter
estimation. Comprehensive experiments on synthetic signals and real
hyperspectral datasets demonstrate that NS-KTR consistently outperforms
conventional tensor regression methods. The framework's ability to preserve
distinct structural characteristics across tensor dimensions while ensuring
physical interpretability makes it especially suitable for applications in
signal processing and hyperspectral image analysis.

</details>


### [42] [Rotatable Antenna Enabled Spectrum Sharing: Joint Antenna Orientation and Beamforming Design](https://arxiv.org/abs/2509.19912)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Wen Chen,Yanze Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 该论文研究了可旋转天线在MISO干扰信道中的应用，通过联合优化发射波束成形和天线方向来最大化加权和速率，提出了交替优化框架和离散方向选择算法。


<details>
  <summary>Details</summary>
Motivation: 传统天线阵列通过增加元件数量来改善性能会导致硬件和功耗成本过高，而可旋转天线通过机械或电子方式调整元件方向，为空间灵活性提供了新的自由度，可以在不扩大阵列规模的情况下改善链路对齐和干扰抑制。

Method: 提出了交替优化框架，结合加权最小均方误差波束成形和Frank-Wolfe方向更新；针对有限分辨率执行器，构建了球面斐波那契码本并设计了基于交叉熵方法的离散方向选择算法；还研究了最大比传输和迫零波束成形方案下的方向优化。

Result: 仿真结果表明，将可旋转天线与传统波束成形结合显著提高了加权和速率，且增益随元件方向性的增强而增加；在离散方向控制下，提出的交叉熵方法算法始终优于最近投影基线方法。

Conclusion: 可旋转天线为无线通信系统提供了一种有效的空间灵活性增强方法，通过联合优化波束成形和天线方向可以显著提升系统性能，特别是在干扰信道环境下。

Abstract: Conventional antenna arrays rely primarily on digital beamforming for spatial
control. While adding more elements can narrow beamwidth and suppress
interference, such scaling incurs prohibitive hardware and power costs.
Rotatable antennas (RAs), which allow mechanical or electronic adjustment of
element orientations, introduce a new degree of freedom to exploit spatial
flexibility without enlarging the array. By dynamically optimizing
orientations, RAs can substantially improve desired link alignment and
interference suppression. This paper investigates RA-enabled multiple-input
single-output (MISO) interference channels under co-channel spectrum sharing
and formulates a weighted sum-rate maximization problem that jointly optimizes
transmit beamforming and antenna orientations. To tackle this nonconvex
problem, we develop an alternating optimization (AO) framework that integrates
weighted minimum mean-square error (WMMSE)-based beamforming with
Frank-Wolfe-based orientation updates. To reduce complexity, we further study
orientation optimization under maximum-ratio transmission (MRT) and
zero-forcing (ZF) beamforming schemes. For finite-resolution actuators, we
construct spherical Fibonacci codebooks and design a cross-entropy method
(CEM)-based algorithm for discrete orientation selection. Simulations show that
integrating RAs with conventional beamforming markedly increases weighted
sum-rate, with gains rising with element directivity. Under discrete
orientation control, the proposed CEM algorithm consistently outperforms the
nearest-projection baseline.

</details>


### [43] [On the Invariance of Cross-Correlation Peak Positions Under Monotonic Signal Transformations, with Application to Fast Time Difference Estimation](https://arxiv.org/abs/2509.19974)
*Natsuki Ueno,Ryotaro Sato,Nobutaka Ono*

Main category: eess.SP

TL;DR: 提出关于互相关峰值位置不变性的定理，为比传统FFT方法更快的时差估计方法提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 传统基于FFT的时差估计方法计算复杂度较高，需要寻找更高效的替代方案。

Method: 利用互相关峰值位置在输入信号任意单调变换下保持不变的性质，设计基于低比特整数量化信号的互相关函数估计算法，仅需整数运算。

Result: 数值实验表明，所提方法比传统FFT方法处理时间更短。

Conclusion: 该方法通过理论定理和整数运算实现了比FFT更快的时差估计，具有计算效率优势。

Abstract: We present a theorem concerning the invariance of cross-correlation peak
positions, which provides a foundation for a new method for time difference
estimation that is potentially faster than the conventional fast Fourier
transform (FFT) approach for real/complex sequences. This theoretical result
shows that the peak position of the cross-correlation function between two
shifted discrete-time signals remains unchanged under arbitrary monotonic
transformations of the input signals. By exploiting this property, we design an
efficient estimation algorithm based on the cross-correlation function between
signals quantized into low-bit integers. The proposed method requires only
integer arithmetic instead of real-valued operations, and further computational
efficiency can be achieved through number-theoretic algorithms. Numerical
experiments demonstrate that the proposed method achieves a shorter processing
time than conventional FFT-based approaches.

</details>


### [44] [Near-field Spatial-domain Channel Extrapolation for XL-MIMO Systems](https://arxiv.org/abs/2509.20026)
*Jiayi Lu,Jiayi Zhang,Hao Lei,Huahua Xiao,Bo Ai,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 提出了一个用于多子载波XL-MIMO系统的自适应近场信道外推框架，通过选择天线子集和开发网格/离网算法来提高精度并降低复杂度。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统需要低复杂度的精确CSI获取，现有方法忽略了近场球面波前或过度依赖稀疏先验，导致性能下降。

Method: 开发了基于天线子集选择的网格和离网算法，引入交叉验证方案降低复杂度，提出相干最小化随机模式确保鲁棒外推。

Result: 数值结果表明所提算法在外推精度和可达速率上显著优于现有方法，同时保持低计算复杂度。

Conclusion: 提出的CV比率在精度和效率之间提供了灵活权衡，相应的离网算法以传统网格方法的复杂度实现了高精度。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are
pivotal to next-generation wireless communications, where dynamic RF chain
architectures offer enhanced performance. However, efficient precoding in such
systems requires accurate channel state information (CSI) obtained with low
complexity. To address this challenge, spatial-domain channel extrapolation has
attracted growing interest. Existing methods often overlook near-field
spherical wavefronts or rely heavily on sparsity priors, leading to performance
degradation. In this paper, we propose an adaptive near-field channel
extrapolation framework for multi-subcarrier XL-MIMO systems, leveraging a
strategically selected subset of antennas. Subsequently, we develop both
on-grid and off-grid algorithms, where the latter refines the former's
estimates for improved accuracy. To further reduce complexity, a
cross-validation (CV)-based scheme is introduced. Additionally, we analytically
formulate the mutual coherence of the sensing matrix and propose a
coherence-minimizing-based random pattern to ensure robust extrapolation.
Numerical results validate that the proposed algorithms significantly
outperform existing methods in both extrapolation accuracy and achievable rate,
while maintaining low computational complexity. In particular, our proposed CV
ratio offers a flexible trade-off between accuracy and efficiency, and the
corresponding off-grid algorithm achieves high accuracy with complexity
comparable to conventional on-grid methods.

</details>


### [45] [Multi-Stage CD-Kennedy Receiver for QPSK Modulated CV-QKD in Turbulent Channels](https://arxiv.org/abs/2509.20030)
*Renzhi Yuan,Zhixing Wang,Shouye Miao,Mufei Zhao,Haifeng Yao,Bin Cao,Mugen Peng*

Main category: eess.SP

TL;DR: 本文探讨了在多阶段CD-Kennedy量子接收器在湍流信道中增强QPSK调制CV-QKD协议安全密钥率的可能性，提出了三种不同类型的接收器，并证明其在误码率和安全密钥率方面优于经典相干接收器。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发协议因高密钥率和与现有光通信基础设施兼容性好而受到关注，但在卫星对地光通信链路中必须克服大气湍流的影响。量子接收器在湍流信道中的潜在应用尚未充分探索。

Method: 推导了多阶段CD-Kennedy接收器在湍流信道中检测QPSK信号的误码概率，提出了三种具有不同位移选择的接收器类型，并推导了使用该接收器和后选择策略的QPSK调制CV-QKD协议在湍流信道中的安全密钥率。

Result: 数值结果表明，多阶段CD-Kennedy接收器在湍流信道中的误码率和安全密钥率性能均优于经典相干接收器，且Type-II接收器在误码率性能方面能容忍更差的信道条件。

Conclusion: 多阶段CD-Kennedy量子接收器能够有效提升CV-QKD协议在湍流信道中的性能，为卫星对地量子通信提供了有前景的技术方案。

Abstract: Continuous variable-quantum key distribution (CV-QKD) protocols attract
increasing attentions in recent years because they enjoy high secret key rate
(SKR) and good compatibility with existing optical communication
infrastructure. Classical coherent receivers are widely employed in coherent
states based CV-QKD protocols, whose detection performance is bounded by the
standard quantum limit (SQL). Recently, quantum receivers based on displacement
operators are experimentally demonstrated with detection performance
outperforming the SQL in various practical conditions. However, potential
applications of quantum receivers in CV-QKD protocols under turbulent channels
are still not well explored, while practical CV-QKD protocols must survive from
the atmospheric turbulence in satellite-to-ground optical communication links.
In this paper, we consider the possibility of using a quantum receiver called
multi-stage CD-Kennedy receiver to enhance the SKR performance of a quadrature
phase shift keying (QPSK) modulated CV-QKD protocol in turbulent channels. We
first derive the error probability of the multi-stage CD-Kennedy receiver for
detecting QPSK signals in turbulent channels and further propose three types of
multi-stage CD-Kennedy receiver with different displacement choices, i.e., the
Type-I, Type-II, and Type-III receivers. Then we derive the SKR of a QPSK
modulated CV-QKD protocol using the multi-stage CD-Kennedy receiver and
post-selection strategy in turbulent channels. Numerical results show that the
multi-stage CD-Kennedy receiver can outperform the classical coherent receiver
in turbulent channels in terms of both error probability and SKR performance
and the Type-II receiver can tolerate worse channel conditions compared with
Type-I and Type-III receivers in terms of error probability performance.

</details>


### [46] [Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional](https://arxiv.org/abs/2509.20034)
*Etienne Lasalle,Barbara Pascal*

Main category: eess.SP

TL;DR: 本文提出了一种联合估计有效再生数和空间连通性结构的方法，以解决COVID-19疫情期间由于感染数据质量差而导致的监测挑战。


<details>
  <summary>Details</summary>
Motivation: 在流行病爆发期间，决策者需要准确可靠的工具来监测病原体传播。有效再生数是量化流行强度的关键指标，但COVID-19大流行监测面临前所未有的挑战，主要是全球报告的感染数据质量较差。当同时监测不同地区的疫情时，利用数据的空间结构可以显著提高再生数估计的准确性和鲁棒性，但这需要良好的空间结构估计。

Method: 提出了一种联合估计再生数和连通性结构的程序。该方法通过精心设计的合成数据进行了密集数值模拟评估，并在真实的COVID-19时空感染数据上进行了验证。

Result: 该方法能够同时估计有效再生数和空间连通性结构，提高了在数据质量不佳情况下的监测准确性。

Conclusion: 提出的联合估计方法为解决流行病监测中的空间结构估计问题提供了有效解决方案，特别是在数据质量较差的现实情况下表现出良好的性能。

Abstract: During an epidemic outbreak, decision makers crucially need accurate and
robust tools to monitor the pathogen propagation. The effective reproduction
number, defined as the expected number of secondary infections stemming from
one contaminated individual, is a state-of-the-art indicator quantifying the
epidemic intensity. Numerous estimators have been developed to precisely track
the reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance
raised unprecedented challenges due to the poor quality of worldwide reported
infection counts. When monitoring the epidemic in different territories
simultaneously, leveraging the spatial structure of data significantly enhances
both the accuracy and robustness of reproduction number estimates. However,
this requires a good estimate of the spatial structure. To tackle this major
limitation, the present work proposes a joint estimator of the reproduction
number and connectivity structure. The procedure is assessed through intensive
numerical simulations on carefully designed synthetic data and illustrated on
real COVID-19 spatiotemporal infection counts.

</details>


### [47] [A dual bistatic optical forward transceiver configuration for determining the position of an acoustic communication source detected by optical communication fibers](https://arxiv.org/abs/2509.20046)
*Knut H. Grythe,Jan Erik Håkegård*

Main category: eess.SP

TL;DR: 该论文提出了一种基于双光纤布局的水声通信系统，利用双向配置和双基地雷达原理实现声源定位，通过到达时间差(TDOA)估计位置，虽然定位精度低于传统DAS但为集成通信定位提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 传统分布式声学传感(DAS)在双向配置中缺乏内置的声源定位功能，而水下通信场景中声源定位具有重要价值，需要开发集成通信和定位的系统。

Method: 采用双光纤布局，两端配备光学发射器和接收器，基于双基地雷达原理利用传播延迟差异估计声源位置，使用到达时间差(TDOA)和交叉模糊函数作为最大似然估计器。

Result: 推导了Cramér-Rao Bound理论定位精度极限，分析表明增加声学带宽和载波频率可提高空间分辨率，仿真结果验证了方法在不同系统条件下的性能。

Conclusion: 该方法为集成通信和定位提供了可行方案，但实际应用中仍需解决关键技术挑战，如光学功率损耗等参数优化问题。

Abstract: Optical fibers have long been employed as sensors in a wide range of
commercial systems. Distributed Acoustic Sensing (DAS) extends this concept by
enabling the detection and localization of acoustic sources along the fiber,
using backscattered light from small segments to achieve spatial resolution on
the order of meters. Recently, DAS has also been explored as a component in
underwater acoustic communication systems. Emerging interest in bidirectional
configurations where both transmitter and receiver are placed at opposite ends
of the fiber has opened new possibilities. However, in such setups, source
localization is not inherently integrated into the signal decoding process. For
scenarios where source positioning is valuable, we propose an approach inspired
by bi-static radar principles. This configuration utilizes acoustic signals
received at both ends of the fiber to estimate source position based on
propagation delay differences. Although the localization accuracy is lower than
that of DAS due to reduced sampling rates, the method offers a viable
alternative for integrated communication and positioning. We present the system
topology and configuration for a dual-fiber layout, each end equipped with
optical transmitters and receivers. The position estimation is derived from the
time difference of arrival (TDOA) between the two receivers. The Cram\'er-Rao
Bound is derived to characterize the theoretical limits of localization
accuracy, highlighting dependencies on system parameters such as optical power
loss. Our analysis shows that increased acoustic bandwidth and higher carrier
frequencies enhance spatial resolution. We formulate the Cross Ambiguity
Function as a maximum likelihood estimator for TDOA and provide simulation
results illustrating its performance under varying system conditions. Finally,
we discuss key challenges that must be addressed for practical implementation.

</details>


### [48] [Joint Ex-Post Location Calibration and Radio Map Construction under Biased Positioning Errors](https://arxiv.org/abs/2509.20059)
*Koki Kanzaki,Koya Sato*

Main category: eess.SP

TL;DR: 提出了一种针对定位误差环境的高精度无线电地图构建方法，通过建模定位误差和空间相关性，在无线电地图构建中进行事后校准。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图构建方法大多假设定位信息无噪声，但实际设备定位系统（如GNSS）会产生数米到数十米的误差，忽略这些误差会显著降低地图精度。

Method: 引入一个新颖框架，将定位误差和无线电传播的空间相关性建模为边际对数似然函数中的可调参数，实现定位不确定性的事后校准。

Result: 基于实际人类移动数据的数值结果表明，该方法能将RMSE退化限制在约0.25-0.29 dB，而基线方法的性能损失超过1 dB。

Conclusion: 该方法能有效处理定位误差问题，在存在定位误差的情况下仍能保持较高的无线电地图精度。

Abstract: This paper proposes a high-accuracy radio map construction method tailored
for environments where location information is affected by bursty errors. Radio
maps are an effective tool for visualizing wireless environments. Although
extensive research has been conducted on accurate radio map construction, most
existing approaches assume noise-free location information during sensing. In
practice, however, positioning errors ranging from a few to several tens of
meters can arise due to device-based positioning systems (e.g., GNSS). Ignoring
such errors during inference can lead to significant degradation in radio map
accuracy. This study highlights that these errors often tend to be biased when
using mobile devices as sensors. We introduce a novel framework that models
these errors together with spatial correlation in radio propagation by
embedding them as tunable parameters in the marginal log-likelihood function.
This enables ex-post calibration of location uncertainty during radio map
construction. Numerical results based on practical human mobility data
demonstrate that the proposed method can limit RMSE degradation to
approximately 0.25-0.29 dB, compared with Gaussian process regression using
noise-free location data, whereas baseline methods suffer performance losses
exceeding 1 dB.

</details>


### [49] [Reciprocal Beyond-Diagonal Reconfigurable Intelligent Surface (BD-RIS): Scattering Matrix Design via Manifold Optimization](https://arxiv.org/abs/2509.20246)
*Marko Fidanovski,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 本文研究了基于对角可重构智能表面（BD-RIS）的和速率最大化问题，通过强制对称性约束实现低复杂度物理实现，提出了一种流形优化框架，在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: BD-RIS技术因其低成本和高性能信号处理能力，能够增强无线系统在恶劣城市环境中的鲁棒性、可达到速率和能量效率。本文旨在通过设计对称散射矩阵来实现和速率最大化，同时确保物理实现的可行性。

Method: 采用流形优化框架，在目标函数中添加惩罚项来保证对称性约束，并通过将解投影到可行散射矩阵集合上来进一步强制互易性。

Result: 仿真结果表明，所提出的方法在和速率最大化方面优于当前最先进的方法。

Conclusion: 通过强制对称性约束的BD-RIS设计能够有效实现和速率最大化，同时保证低复杂度的物理实现可行性。

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) are emerging as
a transformative technology in wireless communications, enabling enhanced
performance and quality of service (QoS) of wireless systems in harsh urban
environments due to their relatively low cost and advanced signal processing
capabilities. Generally, BD-RIS systems are employed to improve robustness,
increase achievable rates, and enhance energy efficiency of wireless systems in
both direct and indirect ways. The direct way is to produce a favorable
propagation environment via the design of optimized scattering matrices, while
the indirect way is to reap additional improvements via the design of
multiple-input multiple-output (MIMO) beamformers that further exploit the
latter "engineered" medium. In this article, the problem of sum-rate
maximization via BD-RIS is examined, with a focus on feasibility, namely
low-complexity physical implementation, by enforcing reciprocity in the BD-RIS
design. We begin by outlining the system model and formulating an optimization
problem that aims to enhance the system's sum-rate by designing a symmetric
scattering matrix. In particular, the approach leverages a manifold
optimization framework, where a penalty term is added to the objective function
to ensure that the symmetry constraint is upheld, with reciprocity further
enforced by projecting the obtained solution onto a set of feasible scattering
matrices. Simulation results demonstrate the effectiveness of the proposed
method in outperforming current state-of-the-art (SotA) approaches in terms of
sum-rate maximization.

</details>


### [50] [Geometric Port Selection in CUMA Systems](https://arxiv.org/abs/2509.20299)
*Chenguang Rao,Kai-Kit Wong,Mohd Hamza Naim Shaikh,Hanjiang Hong,Hyundong Shin,Yangyang Zhang*

Main category: eess.SP

TL;DR: 本文提出两种自适应单射频端口选择方案（EOHS和PCA），用于改进紧凑超大规模天线阵列技术，在保持低复杂度的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统CUMA技术的临时端口选择策略存在优化空间，需要开发更高效的端口选择机制来提升系统性能。

Method: 提出两种方案：EOHS方案动态选择最大化瞬时信号累积的投影方向；PCA方案基于主成分分析将端口划分与信道向量的主要统计方向对齐。

Result: 仿真结果表明EOHS和PCA方案在各种用户密度、端口数量和FAS孔径尺寸下均优于传统CUMA，PCA能以较低计算成本实现接近EOHS的性能。

Conclusion: 所提方案能有效扩展到大规模用户场景，为下一代多址接入系统提供了有吸引力的复杂度-性能权衡。

Abstract: Compact ultra-massive antenna-array (CUMA) is a novel multiple access
technology built on the fluid antenna system (FAS) concept, offering an
improved scheme over fluid antenna multiple access (FAMA) that can support
massive connectivity on the same physical channel without the need of precoding
and interference cancellation. By employing a simple port-selection mechanism
that leverages random channel superposition, CUMA can suppress inter-user
interference while keeping hardware costs low. Nevertheless, its ad-hoc
port-selection strategy leaves considerable room for optimization. In this
work, we revisit CUMA and propose two adaptive single-RF port-selection schemes
that retain its simplicity while significantly enhancing performance. The first
one, referred to as exact optimal half-space (EOHS), dynamically selects the
projection direction that maximizes the instantaneous signal build-up across
active ports. To reduce complexity while preserving most of the gains, we
furthermore introduce a principal component analysis (PCA)-based scheme, which
aligns port partitioning with the dominant statistical direction of per-port
channel vectors. This method yields a closed-form low-complexity solution,
complemented by a tractable analytical framework that provides a closed-form
expression for the signal-to-interference ratio (SIR) probability density
function (PDF). Simulation results corroborate the analysis, demonstrating that
both EOHS and PCA consistently outperform conventional CUMA across diverse user
densities, port counts, and FAS aperture sizes. Notably, PCA achieves
performance close to EOHS at a fraction of the computational cost. The proposed
schemes scale effectively to large-user regimes, offering a compelling
complexity-performance trade-off for next-generation multiple access systems.

</details>
