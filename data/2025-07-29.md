<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 18]
- [eess.SP](#eess.SP) [Total: 23]
- [eess.IV](#eess.IV) [Total: 10]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Polar Coding and Linear Decoding](https://arxiv.org/abs/2507.19695)
*Geraldo A. Barbosa*

Main category: cs.IT

TL;DR: 本文探讨了Polar编码的线性解码方法，适用于小损失或少量比特翻转的情况，并与Arikan的概率解码方法进行了对比。


<details>
  <summary>Details</summary>
Motivation: 研究Polar编码在信道传输中的线性解码方法，以简化解码过程并提高效率。

Method: 采用线性方程直接解码接收信号，适用于小损失或少量比特翻转的情况；对于中等损失，采用重复传输策略。

Result: 通过数值示例展示了线性解码的有效性，并提供了Mathematica代码供用户直接尝试。

Conclusion: 线性解码为Polar编码提供了一种高效且直接的解码方法，适用于特定场景，并具有实际应用的潜力。

Abstract: Polar encoding, described by Arikan in IEEE Transactions on Information
Theory, Vol. 55, No. 7, July 2009, was a milestone for telecommunications. A
Polar code distributes information among high and low-capacity channels,
showing the possibility of achieving perfect channel capacity. The
high-capacity channels allow almost noiseless transmission of data. When these
channels are not high noise, reliability is achieved in the signal
transmission. It starts to compete against codes such a Low-Density
Parity-Check (LDPC) codes. Polar code can be also considered error correcting,
based on the redundancy inherent in its structure. This feature makes polar
encoding also applicable to digital quantum-resistant cryptography protocols.
This work explores linear decoding at a first or single trial in the case of
small losses or small number of bit-flipping, and repeated transmission for
medium level losses. This is distinct from Arikans successive probabilistic
decoding by application of probabilistic rules. Linear decoding is done
directly from solving the linear equations connecting the codewords x and the
received signals y after transmission via noisy channels. Numerical examples
will be shown. Along with this work, programming in Mathematica language was
used. Codes are available for copy-and-paste for Mathematica users to
immediately try the described formalism.

</details>


### [2] [Efficient Computation of Marton's Error Exponent via Constraint Decoupling](https://arxiv.org/abs/2507.19816)
*Jiachuan Ye,Shitong Wu,Lingyi Chen,Wenyi Zhang,Huihui Wu,Hao Wu*

Main category: cs.IT

TL;DR: 本文提出了一种复合最大化方法，有效计算Marton误差指数及其逆函数，通过约束解耦和交替最大化算法显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: Marton误差指数是理论最优的误差概率衰减率，但其非凸优化问题导致计算方法不足，现有方法计算成本高。

Method: 采用约束解耦技术，将问题分解为可通过交替最大化算法高效求解的子问题，固定一个参数后子问题变为凸优化。

Result: 数值实验表明，该算法在简单源和Ahlswede反例中优于现有方法，计算效率显著提升。

Conclusion: 提出的方法解决了Marton误差指数的计算难题，具有全局收敛性和高效性。

Abstract: The error exponent in lossy source coding characterizes the asymptotic decay
rate of error probability with respect to blocklength. The Marton's error
exponent provides the theoretically optimal bound on this rate. However,
computation methods of the Marton's error exponent remain underdeveloped due to
its formulation as a non-convex optimization problem with limited efficient
solvers. While a recent grid search algorithm can compute its inverse function,
it incurs prohibitive computational costs from two-dimensional brute-force
parameter grid searches. This paper proposes a composite maximization approach
that effectively handles both Marton's error exponent and its inverse function.
Through a constraint decoupling technique, the resulting problem formulations
admit efficient solvers driven by an alternating maximization algorithm. By
fixing one parameter via a one-dimensional line search, the remaining
subproblem becomes convex and can be efficiently solved by alternating variable
updates, thereby significantly reducing search complexity. Therefore, the
global convergence of the algorithm can be guaranteed. Numerical experiments
for simple sources and the Ahlswede's counterexample, demonstrates the superior
efficiency of our algorithm in contrast to existing methods.

</details>


### [3] [Neural Estimation of the Information Bottleneck Based on a Mapping Approach](https://arxiv.org/abs/2507.19832)
*Lingyi Chen,Shitong Wu,Sicheng Xu,Huihui Wu,Wenyi Zhang*

Main category: cs.IT

TL;DR: 论文提出了一种基于神经网络的IB问题解决方案，通过新公式简化优化变量，理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 信息瓶颈（IB）方法在机器学习中广泛应用，但传统方法可能复杂，需要更高效的数据驱动解决方案。

Method: 利用IB功能的结构和映射方法，提出仅需优化单个变量的新公式，适用于神经网络估计。

Result: 理论分析证明神经网络估计器渐近解决IB问题，合成和MNIST数据集实验验证其有效性。

Conclusion: 提出的神经网络估计器为IB问题提供了高效且可扩展的解决方案。

Abstract: The information bottleneck (IB) method is a technique designed to extract
meaningful information related to one random variable from another random
variable, and has found extensive applications in machine learning problems. In
this paper, neural network based estimation of the IB problem solution is
studied, through the lens of a novel formulation of the IB problem. Via
exploiting the inherent structure of the IB functional and leveraging the
mapping approach, the proposed formulation of the IB problem involves only a
single variable to be optimized, and subsequently is readily amenable to
data-driven estimators based on neural networks. A theoretical analysis is
conducted to guarantee that the neural estimator asymptotically solves the IB
problem, and the numerical experiments on both synthetic and MNIST datasets
demonstrate the effectiveness of the neural estimator.

</details>


### [4] [An Efficient Alternating Minimization Algorithm for Computing Quantum Rate-Distortion Function](https://arxiv.org/abs/2507.19920)
*Lingyi Chen,Deheng Yuan,Wenyi Zhang,Hao Wu,Huihui Wu*

Main category: cs.IT

TL;DR: 提出了一种基于拉格朗日分析的交替最小化算法，用于计算纠缠辅助量子率失真函数，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 纠缠辅助量子率失真函数在量子信息理论中具有核心作用，但现有方法效率不足。

Method: 通过交替最小化算法动态更新拉格朗日乘子，避免多维非线性方程或多元优化问题。

Result: 数值实验验证了算法的准确性和效率优于现有方法。

Conclusion: 该算法解决了原始问题而非其拉格朗日松弛，具有高效性和实用性。

Abstract: We consider the computation of the entanglement-assisted quantum
rate-distortion function, which plays a central role in quantum information
theory. We propose an efficient alternating minimization algorithm based on the
Lagrangian analysis. Instead of fixing the multiplier corresponding to the
distortion constraint, we update the multiplier in each iteration. Hence the
algorithm solves the original problem itself, rather than the Lagrangian
relaxation of it. Moreover, all the other variables are iterated in closed form
without solving multi-dimensional nonlinear equations or multivariate
optimization problems. Numerical experiments show the accuracy of our proposed
algorithm and its improved efficiency over existing methods.

</details>


### [5] [Adaptive Learned Belief Propagation for Decoding Error-Correcting Codes](https://arxiv.org/abs/2507.19941)
*Alireza Tasdighi,Mansoor Yousefi*

Main category: cs.IT

TL;DR: 本文提出了一种自适应加权置信传播（WBP）解码器，通过动态调整权重显著提升解码性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态WBP解码器在解码线性分组码时性能有限，希望通过动态权重优化提升解码效果。

Method: 提出两种自适应WBP解码器：并行WBP（离散权重搜索）和两阶段解码器（神经网络动态确定权重）。

Result: 在BCH、极化和QC-LDPC码中，自适应WBP的误码率比静态WBP低一个数量级；在非线性光纤信道中，编码增益达0.8 dB。

Conclusion: 自适应WBP在保持解码复杂度的同时显著提升性能，适用于多种信道和编码场景。

Abstract: Weighted belief propagation (WBP) for the decoding of linear block codes is
considered. In WBP, the Tanner graph of the code is unrolled with respect to
the iterations of the belief propagation decoder. Then, weights are assigned to
the edges of the resulting recurrent network and optimized offline using a
training dataset. The main contribution of this paper is an adaptive WBP where
the weights of the decoder are determined for each received word. Two variants
of this decoder are investigated. In the parallel WBP decoders, the weights
take values in a discrete set. A number of WBP decoders are run in parallel to
search for the best sequence of weights in real time. In the two-stage decoder,
a small neural network is used to dynamically determine the weights of the WBP
decoder for each received word. The proposed adaptive decoders demonstrate
significant improvements over the static counterparts in two applications. In
the first application, Bose-Chaudhuri-Hocquenghem, polar and quasi-cyclic
low-density parity-check (QC-LDPC) codes are used over an additive white
Gaussian noise channel. The results indicate that the adaptive WBP achieves bit
error rates (BERs) up to an order of magnitude less than the BERs of the static
WBP at about the same decoding complexity, depending on the code, its rate, and
the signal-to-noise ratio. The second application is a concatenated code
designed for a long-haul nonlinear optical fiber channel where the inner code
is a QC-LDPC code and the outer code is a spatially coupled LDPC code. In this
case, the inner code is decoded using an adaptive WBP, while the outer code is
decoded using the sliding window decoder and static belief propagation. The
results show that the adaptive WBP provides a coding gain of 0.8 dB compared to
the neural normalized min-sum decoder, with about the same computational
complexity and decoding latency.

</details>


### [6] [Performance Analysis of Spatiotemporal 2-D Polar Codes for Massive MIMO with MMSE Receivers](https://arxiv.org/abs/2507.19986)
*Yaqi Li,Xiaohu You,Jiamin Li,Chen Ji,Bin Sheng*

Main category: cs.IT

TL;DR: 提出了一种新型的时空二维极化编码方案，用于大规模MIMO系统，以解决5G到6G演进中URLLC的低延迟和高可靠性需求。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G演进，URLLC对性能要求更加严格，传统极化码在短码长下性能下降，亟需一种新的编码方案。

Method: 提出了一种时空二维极化编码方案，结合MMSE接收机，利用大规模MIMO的空间自由度，通过高斯近似方法分析极化行为。

Result: 仿真结果表明，与传统时域极化码相比，该方案显著降低延迟并保证可靠性，或在相同延迟下提高可靠性。

Conclusion: 该方案为未来6G URLLC场景提供了一种容量接近且延迟高效的编码解决方案。

Abstract: With the evolution from 5G to 6G, ultra-reliable low-latency communication
(URLLC) faces increasingly stringent performance requirements. Lower latency
constraints demand shorter channel coding lengths, which can severely degrade
decoding performance. The massive multiple-input multiple-output (MIMO) system
is considered a crucial technology to address this challenge due to its
abundant spatial degrees of freedom (DoF). While polar codes are theoretically
capacity-achieving in the limit of infinite code length, their practical
applicability is limited by significant decoding latency. In this paper, we
establish a unified theoretical framework and propose a novel spatiotemporal
two-dimensional (2-D) polar coding scheme for massive MIMO systems employing
minimum mean square error (MMSE) receivers. The polar transform is jointly
applied over both spatial and temporal dimensions to fully exploit the large
spatial DoF. By leveraging the near-deterministic
signal-to-interference-plus-noise ratio (SINR) property of MMSE detection, the
spatial domain is modeled as a set of parallel Gaussian sub-channels. Within
this framework, we perform a theoretical analysis of the 2-D polarization
behavior using the Gaussian approximation method, and the capacity-achieving
property of the proposed scheme is proved under finite blocklength constraints
and large spatial DoF. Simulation results further demonstrate that, compared to
traditional time-domain polar codes, the proposed 2-D scheme can significantly
reduce latency while guaranteeing reliability, or alternatively improve
reliability under the same latency constraint -- offering a capacity-achieving
and latency-efficient channel coding solution for massive MIMO systems in
future 6G URLLC scenarios.

</details>


### [7] [Rotatable RIS Assisted Physical Layer Multicasting](https://arxiv.org/abs/2507.20113)
*Ji Wang,Jiayu Tian,Lijuan Qin,Kunrui Cao,Hongbo Xu,Xingwang Li,Tony. Q. S. Quek*

Main category: cs.IT

TL;DR: 本文提出了一种可旋转RIS辅助的物理层多播系统框架，通过联合优化基站波束成形、RIS相位偏移和方向，最大化最小多播速率总和。


<details>
  <summary>Details</summary>
Motivation: 传统RIS系统在非旋转或单播设置中无法动态调整方向以优化用户组信号对齐，导致弱用户公平性和速率受限。

Method: 采用交替优化方法，结合凸优化（波束成形/相位偏移）、穷举搜索和粒子群优化（PSO）进行方向优化，并利用Majorization-Minimization算法迭代求解子问题。

Result: 仿真结果显示，该框架比非旋转RIS基线实现了24.1%（穷举搜索）和20.0%（PSO）的速率提升，PSO性能接近穷举搜索上限。

Conclusion: 可旋转RIS在物理层多播和方向优化中表现出显著优势，提升了用户公平性和通信速率。

Abstract: Reconfigurable Intelligent Surfaces (RIS) dynamically control signal
propagation to enhance wireless communications. This paper presents a novel
framework for rotatable RIS assisted physical-layer multicast systems, aiming
to maximize the sum of minimum multicast rates via joint optimization of base
station beamforming, RIS phase shifts, and orientation. Unlike unicast or
non-rotatable setups, the rotatable RIS adapts orientation to align signals
with user groups, improving fairness and rates for weak users. An alternating
optimization approach combines convex optimization for beamforming/phase shifts
with exhaustive search and particle swarm optimization (PSO) for orientation.
Majorization-Minimization-based algorithms solve subproblems iteratively.
Simulation results show the framework achieves 24.1% rate improvement via
exhaustive search and 20.0% via PSO over the non-rotatable RIS baseline, with
PSO performance close to the exhaustive search upper bound, highlighting the
benefits of physical-layer multicast and orientation optimization.

</details>


### [8] [An Optimal Transport-Based Method for Computing LM Rate and Its Convergence Analysis](https://arxiv.org/abs/2507.20129)
*Shitong Wu,Wenhao Ye,Xinwei Li,Lingyi Chen,Wenyi Zhang,Huihui Wu,Hao Wu*

Main category: cs.IT

TL;DR: 论文提出了一种基于最优传输问题的Sinkhorn算法，用于高效计算LM率，解决了传统方法在高维输入字母表下的计算难题。


<details>
  <summary>Details</summary>
Motivation: LM率作为失配容量的紧下界，其计算复杂度高，传统数值方法在大规模输入字母表下效率低下。

Method: 将LM率计算重新表述为带约束的最优传输问题，并基于Sinkhorn算法设计新算法。

Result: 算法具有次线性收敛速度，数值实验验证了其高效性和可行性。

Conclusion: 提出的算法为LM率计算提供了高效解决方案，适用于大规模通信场景。

Abstract: The mismatch capacity characterizes the highest information rate of the
channel under a prescribed decoding metric and serves as a critical performance
indicator in numerous practical communication scenarios. Compared to the
commonly used Generalized Mutual Information (GMI), the Lower bound on the
Mismatch capacity (LM rate) generally provides a tighter lower bound on the
mismatch capacity. However, the efficient computation of the LM rate is
significantly more challenging than that of the GMI, particularly as the size
of the channel input alphabet increases. This growth in complexity renders
standard numerical methods (e.g., interior point methods) computationally
intensive and, in some cases, impractical. In this work, we reformulate the
computation of the LM rate as a special instance of the optimal transport (OT)
problem with an additional constraint. Building on this formulation, we develop
a novel numerical algorithm based on the Sinkhorn algorithm, which is well
known for its efficiency in solving entropy regularized optimization problems.
We further provide the convergence analysis of the proposed algorithm,
revealing that the algorithm has a sub-linear convergence rate. Numerical
experiments demonstrate the feasibility and efficiency of the proposed
algorithm for the computation of the LM rate.

</details>


### [9] [Sparse Regression Codes for Secret Key Agreement: Achieving Strong Secrecy and Near-Optimal Rates for Gaussian Sources](https://arxiv.org/abs/2507.20157)
*Emmanouil M. Athanasakos,Hariprasad Manjunath*

Main category: cs.IT

TL;DR: 本文提出了一种基于稀疏回归码（SPARCs）的高斯源秘密密钥协议方案，展示了其接近最优的密钥速率和强保密性。


<details>
  <summary>Details</summary>
Motivation: 利用SPARCs在率失真和Wyner-Ziv编码中的最优性，构建高效且安全的密钥生成协议。

Method: 通过SPARCs的嵌套结构，设计完整的密钥协议方案，并进行端到端分析。

Result: 方案实现了接近最优的密钥速率，并揭示了密钥速率与公共通信开销之间的权衡。

Conclusion: SPARCs为安全密钥生成提供了低复杂度且理论可靠的框架。

Abstract: Secret key agreement from correlated physical layer observations is a
cornerstone of information-theoretic security. This paper proposes and
rigorously analyzes a complete, constructive protocol for secret key agreement
from Gaussian sources using Sparse Regression Codes (SPARCs). Our protocol
systematically leverages the known optimality of SPARCs for both
rate-distortion and Wyner-Ziv (WZ) coding, facilitated by their inherent nested
structure. The primary contribution of this work is a comprehensive end-to-end
analysis demonstrating that the proposed scheme achieves near-optimal secret
key rates with strong secrecy guarantees, as quantified by a vanishing
variational distance. We explicitly characterize the gap to the optimal rate,
revealing a fundamental trade-off between the key rate and the required public
communication overhead, which is governed by a tunable quantization parameter.
Furthermore, we uncover a non-trivial constrained optimization for this
parameter, showing that practical constraints on the SPARC code parameters
induce a peak in the achievable secret key rate. This work establishes SPARCs
as a viable and theoretically sound framework for secure key generation,
providing a compelling low-complexity alternative to existing schemes and
offering new insights into the practical design of such protocols.

</details>


### [10] [Stochastic Channel Models for Satellite Mega-Constellations](https://arxiv.org/abs/2507.20255)
*Brendon McBain,Yi Hong,Emanuele Viterbo*

Main category: cs.IT

TL;DR: 提出了一种用于快速移动的LEO卫星与地面用户通信的通用卫星信道模型，基于非齐次二项点过程（NBPP）建模卫星位置和方向，推导了功率增益、传播延迟和多普勒频移的概率分布，并分析了散射函数和全局信道参数。


<details>
  <summary>Details</summary>
Motivation: 为大规模星座中的LEO卫星与地面用户通信提供一个通用的信道模型，以解决快速移动卫星的信道特性建模问题。

Method: 使用非齐次二项点过程（NBPP）建模卫星位置和方向，推导功率增益、传播延迟和多普勒频移的分布，并分析散射函数和全局信道参数。

Result: 模型推导的信道统计和全局参数与Starlink星座的实际轨道模拟结果高度吻合。

Conclusion: 提出的信道模型能够有效描述大规模星座中LEO卫星与地面用户通信的信道特性，为实际系统设计提供了理论基础。

Abstract: A general satellite channel model is proposed for communications between a
rapidly moving low Earth orbit (LEO) satellite in a mega-constellation and a
stationary user on Earth. The channel uses a non-homogeneous binomial point
process (NBPP) for modelling the satellite positions, marked with an
ascending/descending binary random variable for modelling the satellite
directions. Using the marked NBPP, we derive the probability distributions of
power gain, propagation delay, and Doppler shift, resulting in a stochastic
signal propagation model for the mega-constellation geometry in isolation of
other effects. This forms the basis for our proposed channel model as a
randomly time-varying channel. The scattering function of this channel is
derived to characterise how the received power is spread in the delay-Doppler
domain. Global channel parameters such as path loss and channel spread are
analysed in terms of the scattering function. The channel statistics and the
global channel parameters closely match realistic orbit simulations of the
Starlink constellation.

</details>


### [11] [Ensemble Average Analysis of Non-Adaptive Group Testing with Sparse Pooling Graphs](https://arxiv.org/abs/2507.20281)
*Emna Ben Yacoub,Gianluigi Liva,Enrico Paolini,Marco Chiani*

Main category: cs.IT

TL;DR: 论文分析了非自适应群组测试中稀疏池化图的假警报（FA）和漏检（MD）概率，通过组合正交匹配追踪和明确缺陷检测算法，在无噪声、非定量环境下进行。


<details>
  <summary>Details</summary>
Motivation: 研究稀疏池化图在非自适应群组测试中的性能表现，特别是FA和MD概率。

Method: 采用组合分析方法，基于规定的度分布计算池化图集合的平均FA/MD概率。

Result: 数值实验验证了分析方法的准确性，表明该方法可用于表征基于稀疏池化图的非自适应群组测试方案性能。

Conclusion: 提出的技术能有效分析稀疏池化图在非自适应群组测试中的性能，为相关应用提供了理论支持。

Abstract: A combinatorial analysis of the false alarm (FA) and misdetection (MD)
probabilities of non-adaptive group testing with sparse pooling graphs is
developed. The analysis targets the combinatorial orthogonal matching pursuit
and definite defective detection algorithms in the noiseless, non-quantitative
setting. The approach follows an ensemble average perspective, where average
FA/MD probabilities are computed for pooling graph ensembles with prescribed
degree distributions. The accuracy of the analysis is demonstrated through
numerical examples, showing that the proposed technique can be used to
characterize the performance of non-adaptive group testing schemes based on
sparse pooling graphs.

</details>


### [12] [Rethinking Multi-User Communication in Semantic Domain: Enhanced OMDMA by Shuffle-Based Orthogonalization and Diffusion Denoising](https://arxiv.org/abs/2507.20477)
*Maojun Zhang,Guangxu Zhu,Xiaoming Chen,Kaibin Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于随机置换的JSCC特征向量正交化框架，解决了语义通信中的用户间干扰问题，无需用户特定模型，提升了性能和隐私。


<details>
  <summary>Details</summary>
Motivation: 语义通信中用户间干扰严重降低语义信息质量，传统方法性能不佳。

Method: 采用随机置换的JSCC特征向量正交化，结合扩散模型和协作波束成形策略。

Result: 显著优于现有多用户语义通信框架，提升了语义保真度和抗干扰能力。

Conclusion: 该框架简化设计，增强隐私，适用于语义相关数据场景。

Abstract: Inter-user interference remains a critical bottleneck in wireless
communication systems, particularly in the emerging paradigm of semantic
communication (SemCom). Compared to traditional systems, inter-user
interference in SemCom severely degrades key semantic information, often
causing worse performance than Gaussian noise under the same power level. To
address this challenge, inspired by the recently proposed concept of Orthogonal
Model Division Multiple Access (OMDMA) that leverages semantic orthogonality
rooted in the personalized joint source and channel (JSCC) models to
distinguish users, we propose a novel, scalable framework that eliminates the
need for user-specific JSCC models as did in original OMDMA. Our key innovation
lies in shuffle-based orthogonalization, where randomly permuting the positions
of JSCC feature vectors transforms inter-user interference into Gaussian-like
noise. By assigning each user a unique shuffling pattern, the interference is
treated as channel noise, enabling effective mitigation using diffusion models
(DMs). This approach not only simplifies system design by requiring a single
universal JSCC model but also enhances privacy, as shuffling patterns act as
implicit private keys. Additionally, we extend the framework to scenarios
involving semantically correlated data. By grouping users based on semantic
similarity, a cooperative beamforming strategy is introduced to exploit
redundancy in correlated data, further improving system performance. Extensive
simulations demonstrate that the proposed method outperforms state-of-the-art
multi-user SemCom frameworks, achieving superior semantic fidelity, robustness
to interference, and scalability-all without requiring additional training
overhead.

</details>


### [13] [Cooperative Jamming Detection Using Low-Rank Structure of Received Signal Matrix](https://arxiv.org/abs/2507.20504)
*Amir Mehrabian,Georges Kaddoum*

Main category: cs.IT

TL;DR: 本文提出了一种基于接收信号矩阵低秩结构的协作干扰检测方法，利用似然比测试设计了多种场景下的检测器，并通过仿真验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 无线通信因其开放性和共享媒介特性易受恶意干扰攻击，检测干扰是实施抗干扰策略的首要步骤。

Method: 利用接收信号矩阵的低秩结构，采用似然比测试设计检测器，适用于不同友好节点和干扰节点数量及噪声统计信息的场景。

Result: 仿真结果表明，所提出的检测器在协作感知网络中表现出色，干扰检测准确且鲁棒。

Conclusion: 该方法为无线通信中的干扰检测提供了高效解决方案，适用于多种实际场景。

Abstract: Wireless communication can be simply subjected to malicious attacks due to
its open nature and shared medium. Detecting jamming attacks is the first and
necessary step to adopt the anti-jamming strategies. This paper presents novel
cooperative jamming detection methods that use the low-rank structure of the
received signal matrix. We employed the likelihood ratio test to propose
detectors for various scenarios. We regarded several scenarios with different
numbers of friendly and jamming nodes and different levels of available
statistical information on noise. We also provided an analytical examination of
the false alarm performance of one of the proposed detectors, which can be used
to adjust the detection threshold. We discussed the synthetic signal generation
and the Monte Carlo (MC)-based threshold setting method, where knowledge of the
distribution of the jamming-free signal, as well as several parameters such as
noise variance and channel state information (CSI), is required to accurately
generate synthetic signals for threshold estimation. Extensive simulations
reveal that the proposed detectors outperform several existing methods,
offering robust and accurate jamming detection in a collaborative network of
sensing nodes.

</details>


### [14] [Construction of non-generalized Reed-Solomon MDS codes based on systematic generator matrix](https://arxiv.org/abs/2507.20559)
*Shengwei Liu,Hongwei Liu,Bocong Chen*

Main category: cs.IT

TL;DR: 本文证明了两种广义扭曲Reed-Solomon（GTRS）码是非GRS码，并为一类GTRS码提供了系统生成矩阵。此外，受GTRS码的系统生成矩阵启发，还提出了一种非GRS MDS码的构造方法。


<details>
  <summary>Details</summary>
Motivation: 研究非GRS的MDS码，扩展MDS码的构造方法，特别是通过广义扭曲Reed-Solomon（GTRS）码的形式。

Method: 通过证明两种GTRS码是非GRS码，并构造其系统生成矩阵；进一步提出非GRS MDS码的构造方法。

Result: 证明了两种GTRS码是非GRS码，并提供了一类GTRS码的系统生成矩阵；提出了一种新的非GRS MDS码构造方法。

Conclusion: GTRS码为非GRS的MDS码提供了新的构造途径，扩展了MDS码的理论和应用范围。

Abstract: Maximum distance separable (MDS) codes are considered optimal because the
minimum distance cannot be improved for a given length and code size. The most
prominent MDS codes are likely the generalized Reed-Solomon (GRS) codes. In
1989, Roth and Lempel constructed a type of MDS code that is not a GRS code
(referred to as non-GRS). In 2017, Beelen et al. introduced twisted
Reed-Solomon (TRS) codes and demonstrated that many MDS TRS codes are indeed
non-GRS. Following this, the definition of TRS codes was generalized to the
most comprehensive form, which we refer to as generalized twisted Reed-Solomon
(GTRS) codes. In this paper, we prove that two families of GTRS codes are
non-GRS and provide a systematic generator matrix for a class of GTRS codes.
Inspired by the form of the systematic generator matrix for GTRS codes,we also
present a construction of non-GRS MDS codes.

</details>


### [15] [A note on the Artstein-Avidan-Milman's generalized Legendre transforms](https://arxiv.org/abs/2507.20577)
*Frank Nielsen*

Main category: cs.IT

TL;DR: 论文证明了广义勒让德变换对应于仿射变形函数的普通勒让德变换，并从信息几何的角度进行了解释。


<details>
  <summary>Details</summary>
Motivation: 研究广义勒让德变换与普通勒让德变换之间的关系，探索其在信息几何中的应用。

Method: 通过数学证明，展示广义勒让德变换如何对应于仿射变形函数的普通勒让德变换。

Result: 广义凸共轭实际上是仿射变形函数的凸共轭。

Conclusion: 研究结果为广义勒让德变换提供了新的理解，并展示了其在信息几何中的潜在应用。

Abstract: Artstein-Avidan and Milman [Annals of mathematics (2009), (169):661-674]
characterized invertible reverse-ordering transforms on the space of
lower-semi-continuous extended real-valued convex functions as affine
deformations of the ordinary Legendre transform. In this note, we prove that
all those generalized Legendre transforms on functions correspond to the
ordinary Legendre transform on dually corresponding affine-deformed functions.
That is, generalized convex conjugates are convex conjugates of affine-deformed
functions. We conclude this note by sketching how this result can be
interpreted from the lens of information geometry.

</details>


### [16] [The Coverage Depth Problem in DNA Storage Over Small Alphabets](https://arxiv.org/abs/2507.20639)
*Matteo Bertuzzo,Alberto Ravagnani,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究在小有限域上定义的码在DNA数据存储中的覆盖深度问题，提供闭式解并与理论界限比较。


<details>
  <summary>Details</summary>
Motivation: 解决在基域不够大时无法使用MDS码的问题，探索小有限域上码的性能。

Method: 应用概率论、对偶理论和组合数学技术，分析不同码族的期望读取次数。

Result: 提供了多种码族的闭式解，并与渐近理论界限进行了比较。

Conclusion: 在小有限域上定义的码在覆盖深度问题中表现良好，为实际应用提供了理论支持。

Abstract: The coverage depth problem in DNA data storage is about minimizing the
expected number of reads until all data is recovered. When they exist, MDS
codes offer the best performance in this context. This paper focuses on the
scenario where the base field is not large enough to allow the existence of MDS
codes. We investigate the performance for the coverage depth problem of codes
defined over a small finite field, providing closed formulas for the expected
number of reads for various code families. We also compare the results with the
theoretical bounds in asymptotic regimes. The techniques we apply range from
probability, to duality theory and combinatorics.

</details>


### [17] [The Random Variables of the DNA Coverage Depth Problem](https://arxiv.org/abs/2507.20645)
*Şeyma Bodur,Stefano Lia,Hiram H. López,Rati Ludhani,Alberto Ravagnani,Lisa Seccia*

Main category: cs.IT

TL;DR: 本文研究了DNA数据存储系统中的随机访问覆盖深度问题，旨在最小化恢复信息链所需的读取次数。通过分析线性编码的性能和几何编码构造，优化了参数，并深入研究了覆盖深度问题的全分布。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储系统因其高密度和持久性而备受关注，但高效数据检索依赖于覆盖深度。本文旨在优化这一性能指标，提升数据恢复效率。

Method: 研究采用线性编码和基于平衡准弧的几何编码构造，分析其渐近性能并优化参数。同时，探讨覆盖深度问题的全分布特性。

Result: 通过两种独立证明验证了近期提出的编码构造的渐近性能，并优化了几何编码的参数。全分布分析揭示了传统期望值无法区分的编码行为差异。

Conclusion: 本文通过理论分析和优化，为DNA数据存储系统的随机访问覆盖深度问题提供了新的见解和方法，提升了数据恢复的效率和准确性。

Abstract: DNA data storage systems encode digital data into DNA strands, enabling dense
and durable storage. Efficient data retrieval depends on coverage depth, a key
performance metric. We study the random access coverage depth problem and focus
on minimizing the expected number of reads needed to recover information
strands encoded via a linear code. We compute the asymptotic performance of a
recently proposed code construction, establishing and refining a conjecture in
the field by giving two independent proofs. We also analyze a geometric code
construction based on balanced quasi-arcs and optimize its parameters. Finally,
we investigate the full distribution of the random variables that arise in the
coverage depth problem, of which the traditionally studied expectation is just
the first moment. This allows us to distinguish between code constructions
that, at first glance, may appear to behave identically.

</details>


### [18] [Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL](https://arxiv.org/abs/2507.20966)
*Hussein A. Ammar,Raviraj Adve,Shahram Shahbazpanahi,Gary Boudreau,Israfil Bahceci*

Main category: cs.IT

TL;DR: 本文提出了一种基于深度强化学习（DRL）的解决方案，用于预测和管理用户移动时的接入点切换（HO），以减少频繁切换带来的开销。


<details>
  <summary>Details</summary>
Motivation: 在用户中心的无蜂窝大规模MIMO网络中，用户移动性导致频繁的接入点切换，增加了资源分配和释放的开销。

Method: 采用Soft Actor-Critic算法，结合连续动作空间表示，训练深度神经网络作为切换策略，并提出了一种新的奖励函数以平衡速率和切换开销。

Result: 仿真结果表明，该方法比离散空间方法更具扩展性，且能自动学习在特定时间集中切换以减少开销，响应时间小于0.4毫秒。

Conclusion: 基于DRL的连续动作空间方法能有效管理移动用户的接入点切换，减少开销并实现实时操作。

Abstract: In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user
mobility necessitates updating the set of serving access points to maintain the
user-centric clustering. Such updates are typically performed through handoff
(HO) operations; however, frequent HOs lead to overheads associated with the
allocation and release of resources. This paper presents a deep reinforcement
learning (DRL)-based solution to predict and manage these connections for
mobile users. Our solution employs the Soft Actor-Critic algorithm, with
continuous action space representation, to train a deep neural network to serve
as the HO policy. We present a novel proposition for a reward function that
integrates a HO penalty in order to balance the attainable rate and the
associated overhead related to HOs. We develop two variants of our system; the
first one uses mobility direction-assisted (DA) observations that are based on
the user movement pattern, while the second one uses history-assisted (HA)
observations that are based on the history of the large-scale fading (LSF).
Simulation results show that our DRL-based continuous action space approach is
more scalable than discrete space counterpart, and that our derived HO policy
automatically learns to gather HOs in specific time slots to minimize the
overhead of initiating HOs. Our solution can also operate in real time with a
response time less than 0.4 ms.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [19] [Multipath Interference Suppression in Indirect Time-of-Flight Imaging via a Novel Compressed Sensing Framework](https://arxiv.org/abs/2507.19546)
*Yansong Du,Yutong Deng,Yuting Zhou,Feiyu Jiao,Bangyao Wang,Zhancong Xu,Zhaoxiang Jiang,Xun Guan*

Main category: eess.SP

TL;DR: 提出一种新型压缩感知方法，提升间接飞行时间（iToF）系统的深度重建精度和多目标分离能力，无需硬件改动。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖硬件修改或复杂调制，而新方法通过单频调制和多相位偏移实现高效重建。

Method: 利用多相位偏移和窄占空比连续波构建感知矩阵，结合K-Means聚类优化稀疏恢复。

Result: 实验表明，新方法在重建精度和鲁棒性上优于传统方法。

Conclusion: 该方法无需硬件改动即可显著提升iToF系统性能。

Abstract: We propose a novel compressed sensing method to improve the depth
reconstruction accuracy and multi-target separation capability of indirect
Time-of-Flight (iToF) systems. Unlike traditional approaches that rely on
hardware modifications, complex modulation, or cumbersome data-driven
reconstruction, our method operates with a single modulation frequency and
constructs the sensing matrix using multiple phase shifts and narrow-duty-cycle
continuous waves. During matrix construction, we further account for pixel-wise
range variation caused by lens distortion, making the sensing matrix better
aligned with actual modulation response characteristics. To enhance sparse
recovery, we apply K-Means clustering to the distance response dictionary and
constrain atom selection within each cluster during the OMP process, which
effectively reduces the search space and improves solution stability.
Experimental results demonstrate that the proposed method outperforms
traditional approaches in both reconstruction accuracy and robustness, without
requiring any additional hardware changes.

</details>


### [20] [Coverage Probability and Average Rate Analysis of Hybrid Cellular and Cell-free Network](https://arxiv.org/abs/2507.19763)
*Zhuoyin Dai,Jingran Xu,Xiaoli Xu,Ruoguang Li,Yong Zeng,Jiangbin Lyu*

Main category: eess.SP

TL;DR: 本文提出了一种基于随机几何的混合蜂窝和无小区网络模型，分析了信号和干扰的分布及其耦合关系，并推导了覆盖概率和平均可实现速率。


<details>
  <summary>Details</summary>
Motivation: 尽管无小区无线网络在性能分析和优化方面取得了进展，但大规模部署AP是否能够经济高效地提升通信容量仍是一个开放问题。混合蜂窝和无小区网络（HCCNs）作为一种实用解决方案，值得进一步探索其性能极限。

Method: 采用共轭波束成形设计，利用矩匹配分析聚合信号，并通过推导干扰分量的拉普拉斯变换及其高阶导数来表征覆盖概率。

Result: 通过干扰耦合分析，推导了混合网络在信道衰落下的平均可实现速率。

Conclusion: 混合蜂窝和无小区网络为无小区网络的发展提供了可行的解决方案，其性能分析为未来网络部署提供了理论支持。

Abstract: Cell-free wireless networks deploy distributed access points (APs) to
simultaneously serve user equipments (UEs) across the service region and are
regarded as one of the most promising network architectural paradigms. Despite
recent advances in the performance analysis and optimization of cellfree
wireless networks, it remains an open question whether large-scale deployment
of APs in existing wireless networks can cost-effectively achieve communication
capacity growth. Besides, the realization of a cell-free network is considered
to be a gradual long-term evolutionary process in which cell-free APs will be
incrementally introduced into existing cellular networks, and form a hybrid
communication network with the existing cellular base stations (BSs). Such a
collaboration will bridge the gap between the established cellular network and
the innovative cellfree network. Therefore, hybrid cellular and cell-free
networks (HCCNs) emerge as a practical and feasible solution for advancing
cell-free network development, and it is worthwhile to further explore its
performance limits. This paper presents a stochastic geometry-based hybrid
cellular and cell-free network model to analyze the distributions of signal and
interference and reveal their mutual coupling. Specifically, in order to
benefit the UEs from both the cellular BSs and the cell-free APs, a conjugate
beamforming design is employed, and the aggregated signal is analyzed using
moment matching. Then, the coverage probability of the hybrid network is
characterized by deriving the Laplace transforms and their higher-order
derivatives of interference components. Furthermore, the average achievable
rate of the hybrid network over channel fading is derived based on the
interference coupling analysis.

</details>


### [21] [Radar and Acoustic Sensor Fusion using a Transformer Encoder for Robust Drone Detection and Classification](https://arxiv.org/abs/2507.19785)
*Gevindu Ganganath,Pasindu Sankalpa,Samal Punsara,Demitha Pasindu,Chamira U. S. Edussooriya,Ranga Rodrigo,Udaya S. K. P. Miriya Thanthrige*

Main category: eess.SP

TL;DR: 提出了一种结合雷达和声学传感的多模态方法，用于无人机的检测和分类，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 无人机应用广泛，但安全问题突出，需要可靠的检测和分类机制。

Method: 结合雷达和声学传感，直接使用原始声学信号，采用变压器编码器架构融合传感器数据。

Result: 在户外实验中，该方法表现优于现有技术。

Conclusion: 多模态方法在无人机检测和分类中具有优越性。

Abstract: The use of drones in a wide range of applications is steadily increasing.
However, this has also raised critical security concerns such as unauthorized
drone intrusions into restricted zones. Therefore, robust and accurate drone
detection and classification mechanisms are required despite significant
challenges due to small size of drones, low-altitude flight, and environmental
noise. In this letter, we propose a multi-modal approach combining radar and
acoustic sensing for detecting and classifying drones. We employ radar due to
its long-range capabilities, and robustness to different weather conditions. We
utilize raw acoustic signals without converting them to other domains such as
spectrograms or Mel-frequency cepstral coefficients. This enables us to use
fewer number of parameters compared to the stateof-the-art approaches.
Furthermore, we explore the effectiveness of the transformer encoder
architecture in fusing these sensors. Experimental results obtained in outdoor
settings verify the superior performance of the proposed approach compared to
the state-of-the-art methods.

</details>


### [22] [Channel Estimation in Massive MIMO Systems with Orthogonal Delay-Doppler Division Multiplexing](https://arxiv.org/abs/2507.19812)
*Dezhi Wang,Chongwen Huang,Xiaojun Yuan,Sami Muhaidat,Lei Liu,Xiaoming Chen,Zhaoyang Zhang,Chau Yuen,Mérouane Debbah*

Main category: eess.SP

TL;DR: 本文提出了一种基于MAMP的低复杂度信道估计算法，用于大规模MIMO-ODDM系统，显著提升了信道估计精度。


<details>
  <summary>Details</summary>
Motivation: 高移动性环境下，大规模MIMO-ODDM系统的信道估计面临天线阵列庞大和复杂度高的挑战。

Method: 建立有效信道模型，利用MAMP方法估计多径信道的增益、延迟和多普勒效应，并通过DFT方法估计信道角度。

Result: 数值结果表明，所提算法在无限天线数量下接近贝叶斯最优结果，归一化均方误差比现有算法提升约30%。

Conclusion: 所提算法为高移动性环境下的大规模MIMO-ODDM系统提供了高效且精确的信道估计解决方案。

Abstract: Orthogonal delay-Doppler division multiplexing~(ODDM) modulation has recently
been regarded as a promising technology to provide reliable communications in
high-mobility situations. Accurate and low-complexity channel estimation is one
of the most critical challenges for massive multiple input multiple
output~(MIMO) ODDM systems, mainly due to the extremely large antenna arrays
and high-mobility environments. To overcome these challenges, this paper
addresses the issue of channel estimation in downlink massive MIMO-ODDM systems
and proposes a low-complexity algorithm based on memory approximate message
passing~(MAMP) to estimate the channel state information~(CSI). Specifically,
we first establish the effective channel model of the massive MIMO-ODDM
systems, where the magnitudes of the elements in the equivalent channel vector
follow a Bernoulli-Gaussian distribution. Further, as the number of antennas
grows, the elements in the equivalent coefficient matrix tend to become
completely random. Leveraging these characteristics, we utilize the MAMP method
to determine the gains, delays, and Doppler effects of the multi-path channel,
while the channel angles are estimated through the discrete Fourier transform
method. Finally, numerical results show that the proposed channel estimation
algorithm approaches the Bayesian optimal results when the number of antennas
tends to infinity and improves the channel estimation accuracy by about 30%
compared with the existing algorithms in terms of the normalized mean square
error.

</details>


### [23] [Feature Engineering for Wireless Communications and Networking: Concepts, Methodologies, and Applications](https://arxiv.org/abs/2507.19837)
*Jiacheng Wang,Changyuan Zhao,Zehui Xiong,Tao Xiang,Dusit Niyato,Xianbin Wang,Shiwen Mao,Dong In Kim*

Main category: eess.SP

TL;DR: 本文全面研究了AI驱动的无线通信中的特征工程技术，重点分析了其基本原理、方法及其在低空ISAC网络中的应用，并提出了一种基于生成AI的框架，用于在恶意攻击下重建信号特征频谱。


<details>
  <summary>Details</summary>
Motivation: 随着AI在无线通信中的应用日益广泛，特征工程技术在将原始数据转化为适合AI模型的结构化表示中扮演关键角色，尤其是在低空ISAC网络中。

Method: 论文首先分析了特征工程的基本原理和方法，随后探讨了其在无线通信系统中的应用，并提出了一个生成AI框架，用于在恶意攻击下重建信号频谱。

Result: 案例研究表明，该框架能有效重建信号频谱，平均结构相似性指数提高了4%。

Conclusion: 该研究为AI驱动的无线通信系统提供了有效的特征工程解决方案，尤其在低空ISAC网络中表现出色。

Abstract: AI-enabled wireless communications have attracted tremendous research
interest in recent years, particularly with the rise of novel paradigms such as
low-altitude integrated sensing and communication (ISAC) networks. Within these
systems, feature engineering plays a pivotal role by transforming raw wireless
data into structured representations suitable for AI models. Hence, this paper
offers a comprehensive investigation of feature engineering techniques in
AI-driven wireless communications. Specifically, we begin with a detailed
analysis of fundamental principles and methodologies of feature engineering.
Next, we present its applications in wireless communication systems, with
special emphasis on ISAC networks. Finally, we introduce a generative AI-based
framework, which can reconstruct signal feature spectrum under malicious
attacks in low-altitude ISAC networks. The case study shows that it can
effectively reconstruct the signal spectrum, achieving an average structural
similarity index improvement of 4%, thereby supporting downstream sensing and
communication applications.

</details>


### [24] [Toward Dual-Functional LAWN: Control-Aware System Design for Aerodynamics-Aided UAV Formations](https://arxiv.org/abs/2507.19910)
*Jun Wu,Weijie Yuan,Qingqing Cheng,Haijia Jin*

Main category: eess.SP

TL;DR: 论文提出了一种基于ATC扩散LMS算法的分布式节能无人机编队框架，用于低空无线网络中的集成感知与通信，优化了能量消耗并提升了控制性能。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信（ISAC）是下一代通信系统的关键技术，研究旨在通过优化无人机编队设计，提升低空无线网络的能量效率和飞行续航能力。

Method: 采用ATC扩散LMS算法进行局部位置估计更新，并通过邻居间的协作信息交换优化气动结构；提出两步法解决非凸问题，结合SCA和SDR技术设计双功能波束成形方案。

Result: 仿真结果表明，'V'形编队是最节能的配置，所提设计在控制性能上优于基准方案。

Conclusion: 论文提出的框架显著提升了无人机编队的能量效率和感知通信性能，为低空无线网络的优化提供了有效解决方案。

Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal
technology for advancing low-altitude wireless networks (LAWNs), serving as a
critical enabler for next-generation communication systems. This paper
investigates the system design for energy-saving unmanned aerial vehicle (UAV)
formations in dual-functional LAWNs, where a ground base station (GBS)
simultaneously wirelessly controls multiple UAV formations and performs sensing
tasks. To enhance flight endurance, we exploit the aerodynamic upwash effects
and propose a distributed energy-saving formation framework based on the
adapt-then-combine (ATC) diffusion least mean square (LMS) algorithm.
Specifically, each UAV updates the local position estimate by invoking the LMS
algorithm, followed by refining it through cooperative information exchange
with neighbors. This enables an optimized aerodynamic structure that minimizes
the formation's overall energy consumption. To ensure control stability and
fairness, we formulate a maximum linear quadratic regulator (LQR) minimization
problem, which is subject to both the available power budget and the required
sensing beam pattern gain. To address this non-convex problem, we develop a
two-step approach by first deriving a closed-form expression of LQR as a
function of arbitrary beamformers. Subsequently, an efficient iterative
algorithm that integrates successive convex approximation (SCA) and
semidefinite relaxation (SDR) techniques is proposed to obtain a sub-optimal
dual-functional beamforming solution. Extensive simulation results confirm that
the 'V'-shaped formation is the most energy-efficient configuration and
demonstrate the superiority of our proposed design over benchmark schemes in
improving control performance.

</details>


### [25] [Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems](https://arxiv.org/abs/2507.19936)
*Zhongnian Li,Chao Zheng,Jian Xiao,Ji Wang,Gongpu Wang,Ming Zeng,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的两阶段框架（CP-Mamba），用于近场稀疏超大MIMO-OFDM系统中的联合信道估计与定位，通过定位阶段预测用户坐标以提升信道估计精度。


<details>
  <summary>Details</summary>
Motivation: 研究近场稀疏超大MIMO-OFDM系统中信道估计与定位的协同增益，以提升系统性能。

Method: 提出两阶段框架：定位阶段预测用户坐标，信道估计阶段利用坐标信息。采用U形Mamba架构（CP-Mamba）结合Mamba模型与U形卷积网络优势。

Result: 数值仿真表明，CP-Mamba优于现有基线方法，稀疏阵列在信道估计和定位精度上显著优于紧凑阵列。

Conclusion: CP-Mamba框架有效提升了联合信道估计与定位的精度，稀疏阵列表现更优。

Abstract: This paper investigates joint channel estimation and positioning in
near-field sparse extra-large multiple-input multiple-output (XL-MIMO)
orthogonal frequency division multiplexing (OFDM) systems. To achieve
cooperative gains between channel estimation and positioning, we propose a deep
learning-based two-stage framework comprising positioning and channel
estimation. In the positioning stage, the user's coordinates are predicted and
utilized in the channel estimation stage, thereby enhancing the accuracy of
channel estimation. Within this framework, we propose a U-shaped Mamba
architecture for channel estimation and positioning, termed as CP-Mamba. This
network integrates the strengths of the Mamba model with the structural
advantages of U-shaped convolutional networks, enabling effective capture of
local spatial features and long-range temporal dependencies of the channel.
Numerical simulation results demonstrate that the proposed two-stage approach
with CP-Mamba architecture outperforms existing baseline methods. Moreover,
sparse arrays (SA) exhibit significantly superior performance in both channel
estimation and positioning accuracy compared to conventional compact arrays.

</details>


### [26] [Dependability Theory-based Statistical QoS Provisioning of Fluid Antenna Systems](https://arxiv.org/abs/2507.19984)
*Irfan Muhammad,Priyadarshi Mukherjee,Wee Kiat New,Hirley Alves,Ioannis Krikidis,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 本文提出了一种基于可靠性理论的框架，用于在有限块长度（FBL）约束下为流体天线系统（FAS）提供统计服务质量（QoS）保障，并定义了新的可靠性指标和能效指标。


<details>
  <summary>Details</summary>
Motivation: 现有研究常忽略信道衰落的时变特性及其对关键任务操作的影响，因此需要一种新的框架来量化FAS的可靠性。

Method: 推导了N端口FAS在Nakagami-m衰落信道下的电平穿越率（LCR）和平均衰落持续时间（AFD）的闭式表达式，定义了任务可靠性和首次故障平均时间（MTTFF）等指标，并扩展了经典有效容量（EC）概念。

Result: 通过仿真揭示了端口数量、QoS指数、信噪比和任务持续时间之间的关键权衡关系。

Conclusion: 研究结果为超可靠、低延迟和高能效的工业物联网（IIoT）系统设计提供了重要参考。

Abstract: Fluid antenna systems (FAS) have recently emerged as a promising technology
for next-generation wireless networks, offering real-time spatial
reconfiguration to enhance reliability, throughput, and energy efficiency.
Nevertheless, existing studies often overlook the temporal dynamics of channel
fading and their implications for mission-critical operations. In this paper,
we propose a dependability-theoretic framework for statistical
quality-of-service (QoS) provisioning of FAS under finite blocklength (FBL)
constraints. Specifically, we derive new closed-form expressions for the
level-crossing rate (LCR) and average fade duration (AFD) of an $N$-port FAS
over Nakagami-$m$ fading channels. Leveraging these second-order statistics, we
define two key dependability metrics such as mission reliability and mean
time-to-first-failure (MTTFF), to quantify the probability of uninterrupted
operation over a defined mission duration. We further extend the classical
effective capacity (EC) concept to incorporate mission reliability in the FBL
regime, yielding a mission EC (mEC). To capture energy efficiency under bursty
traffic and latency constraints, we also develop the mission effective energy
efficiency (mEEE) metric and formulate its maximization as a non-convex
fractional optimization problem. This problem is then solved via a modified
Dinkelbach's method with an embedded line search. Extensive simulations uncover
critical trade-offs among port count, QoS exponent, signal-to-noise ratio, and
mission duration, offering insights for the design of ultra-reliable,
low-latency, and energy-efficient industrial internet-of-things (IIoT) systems.

</details>


### [27] [DOA Estimation via Optimal Weighted Low-Rank Matrix Completion](https://arxiv.org/abs/2507.19996)
*Saeed Razavikia,Mohammad Bokaei,Arash Amini,Stefano Rini,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种基于加权提升结构低秩矩阵补全的非均匀稀疏线性传感器阵列方向估计新方法，单快照样本下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决非均匀稀疏线性传感器阵列在单快照样本下的方向估计问题，提升低噪声条件下的性能。

Method: 通过加权提升结构低秩矩阵补全，包括样本提升、权重矩阵设计、噪声消除和方向估计四个步骤。

Result: 数值评估显示，该方法在低噪声条件下比非加权方法和原子范数最小化方法性能更优，归一化均方误差降低约10 dB。

Conclusion: 该方法在样本复杂度和性能上均表现优异，适用于非均匀稀疏阵列的方向估计。

Abstract: This paper presents a novel method for estimating the direction of arrival
(DOA) for a non-uniform and sparse linear sensor array using the weighted
lifted structure low-rank matrix completion. The proposed method uses a single
snapshot sample in which a single array of data is observed. The method is
rooted in a weighted lifted-structured low-rank matrix recovery framework. The
method involves four key steps: (i) lifting the antenna samples to form a
low-rank stature, then (ii) designing left and right weight matrices to reflect
the sample informativeness, (iii) estimating a noise-free uniform array output
through completion of the weighted lifted samples, and (iv) obtaining the DOAs
from the restored uniform linear array samples.
  We study the complexity of steps (i) to (iii) above, where we analyze the
required sample for the array interpolation of step (iii) for DOA estimation.
We demonstrate that the proposed choice of weight matrices achieves a
near-optimal sample complexity. This complexity aligns with the problem's
degree of freedom, equivalent to the number of DOAs adjusted for logarithmic
factors. Numerical evaluations show the proposed method's superiority against
the non-weighted counterpart and atomic norm minimization-based methods.
Notably, our proposed method significantly improves, with approximately a 10 dB
reduction in normalized mean-squared error over the non-weighted method at
low-noise conditions.

</details>


### [28] [NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis](https://arxiv.org/abs/2507.20189)
*Chengkai Wang,Di Wu,Yunsheng Liao,Wenyao Zheng,Ziyi Zeng,Xurong Gao,Hemmings Wu,Zhoule Zhu,Jie Yang,Lihua Zhong,Weiwei Cheng,Yun-Hsuan Chen,Mohamad Sawan*

Main category: eess.SP

TL;DR: NeuroCLIP是一种结合EEG和fNIRS数据的深度学习框架，用于提高甲基苯丙胺依赖的客观评估和治疗效果监测。


<details>
  <summary>Details</summary>
Motivation: 甲基苯丙胺依赖的评估和治疗效果监测常依赖主观报告或单模态神经影像数据，存在局限性和不确定性。

Method: 提出NeuroCLIP框架，通过渐进学习策略整合EEG和fNIRS数据，生成更可靠的生物标志物。

Result: NeuroCLIP显著提高了甲基苯丙胺依赖者与健康对照的区分能力，并能客观评估rTMS治疗效果。

Conclusion: NeuroCLIP提供了一种更可靠的多模态生物标志物，对成瘾神经科学研究和临床评估具有重要价值。

Abstract: Methamphetamine dependence poses a significant global health challenge, yet
its assessment and the evaluation of treatments like repetitive transcranial
magnetic stimulation (rTMS) frequently depend on subjective self-reports, which
may introduce uncertainties. While objective neuroimaging modalities such as
electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS)
offer alternatives, their individual limitations and the reliance on
conventional, often hand-crafted, feature extraction can compromise the
reliability of derived biomarkers. To overcome these limitations, we propose
NeuroCLIP, a novel deep learning framework integrating simultaneously recorded
EEG and fNIRS data through a progressive learning strategy. This approach
offers a robust and trustworthy biomarker for methamphetamine addiction.
Validation experiments show that NeuroCLIP significantly improves
discriminative capabilities among the methamphetamine-dependent individuals and
healthy controls compared to models using either EEG or only fNIRS alone.
Furthermore, the proposed framework facilitates objective, brain-based
evaluation of rTMS treatment efficacy, demonstrating measurable shifts in
neural patterns towards healthy control profiles after treatment. Critically,
we establish the trustworthiness of the multimodal data-driven biomarker by
showing its strong correlation with psychometrically validated craving scores.
These findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP
offers enhanced robustness and reliability over single-modality approaches,
providing a valuable tool for addiction neuroscience research and potentially
improving clinical assessments.

</details>


### [29] [Information-Preserving CSI Feedback: Invertible Networks with Endogenous Quantization and Channel Error Mitigation](https://arxiv.org/abs/2507.20283)
*Haotian Tian,Lixiang Lian,Jiaqi Cao,Sijie Ji*

Main category: eess.SP

TL;DR: 本文提出了InvCSINet，一种基于可逆神经网络（INN）的CSI反馈框架，通过信息保留压缩和重建解决了传统深度学习方法中的信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的CSI反馈方法存在信息丢失和重建精度下降的问题，因此需要一种信息保留的压缩和重建方法。

Method: 提出InvCSINet框架，利用INN的双射特性实现信息保留压缩和重建，并集成了自适应量化模块、可微分比特通道失真模块和信息补偿模块。

Result: 仿真结果表明，该方案在CSI恢复性能和鲁棒性方面表现优越，且架构轻量。

Conclusion: InvCSINet通过信息保留和补偿机制，显著提升了CSI反馈的完整性和准确性。

Abstract: Deep learning has emerged as a promising solution for efficient channel state
information (CSI) feedback in frequency division duplex (FDD) massive MIMO
systems. Conventional deep learning-based methods typically rely on a deep
autoencoder to compress the CSI, which leads to irreversible information loss
and degrades reconstruction accuracy. This paper introduces InvCSINet, an
information-preserving CSI feedback framework based on invertible neural
networks (INNs). By leveraging the bijective nature of INNs, the model ensures
information-preserving compression and reconstruction with shared model
parameters. To address practical challenges such as quantization and
channel-induced errors, we endogenously integrate an adaptive quantization
module, a differentiable bit-channel distortion module and an information
compensation module into the INN architecture. This design enables the network
to learn and compensate the information loss during CSI compression,
quantization, and noisy transmission, thereby preserving the CSI integrity
throughout the feedback process. Simulation results validate the effectiveness
of the proposed scheme, demonstrating superior CSI recovery performance and
robustness to practical impairments with a lightweight architecture.

</details>


### [30] [Reliability of Wi-Fi, LTE, and 5G-Based UAV RC Links in ISM Bands: Uplink Interference Asymmetry Analysis and HARQ Design](https://arxiv.org/abs/2507.20392)
*Donggu Lee,Sung Joon Maeng,Ozgur Ozdemir,Mani Bharathi Pandian,Ismail Guvenc*

Main category: eess.SP

TL;DR: 论文研究了无人机（UAV）在ISM频段中的遥控（RC）链路干扰问题，发现空中干扰比地面更严重，并提出多种HARQ机制以改善下行链路吞吐量。


<details>
  <summary>Details</summary>
Motivation: 无人机遥控链路在ISM频段易受干扰，尤其是空中干扰更严重，影响链路质量。

Method: 通过测量实验和评估不同HARQ机制（如Type-I、Type-III等）来研究干扰对吞吐量的影响。

Result: 测量结果显示空中干扰比地面高16.66 dB，不对称干扰导致上行链路ACK/NACK丢失，影响下行吞吐量。

Conclusion: 不对称上行干扰显著影响下行链路性能，需采用合适的HARQ机制以优化吞吐量。

Abstract: Command and control of uncrewed aerial vehicles (UAVs) is often realized
through air-to-ground (A2G) remote control (RC) links that operate in ISM
bands. While wireless fidelity (Wi-Fi) technology is commonly used for UAV RC
links, ISM-based long-term evolution (LTE) and fifth-generation (5G)
technologies have also been recently considered for the same purpose. A major
problem for UAV RC links in the ISM bands is that other types of interference
sources, such as legacy Wi-Fi and Bluetooth transmissions, may degrade the link
quality. Such interference problems are a higher concern for the UAV in the air
than the RC unit on the ground due to the UAV being in line-of-sight (LoS) with
a larger number of interference sources. To obtain empirical evidence of the
asymmetric interference conditions in downlink (DL) and uplink (UL), we first
conducted a measurement campaign using a helikite platform in urban and rural
areas at NC State University. The results from this measurement campaign show
that the aggregate interference can be up to 16.66 dB at higher altitudes up to
170 m, compared with the interference observed at a ground receiver. As a
result of this asymmetric UL interference, lost hybrid automatic repeat request
(HARQ) indicators (ACK/NACK) in the UL may degrade the DL throughput. To
investigate this, we study various HARQ mechanisms, including HARQ Type-I with
no combining, HARQ Type-I with chase combining, HARQ Type-III with incremental
redundancy, and burst transmission with chase combining. To evaluate the impact
of asymmetric UL interference on throughput performance, we consider three
steps of evaluation process: 1) standalone physical DL shared channel (PDSCH)
throughput evaluation with perfect ACK/NACK assumption; 2) standalone physical
UL control channel (PUCCH) decoding reliability evaluation; and 3) PDSCH DL
throughput evaluation with asymmetric UL ACK/NACK transmission.

</details>


### [31] [A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification](https://arxiv.org/abs/2507.20408)
*Samiul Based Shuvo,Taufiq Hasan*

Main category: eess.SP

TL;DR: 提出了一种混合CNN-Transformer框架，用于儿科呼吸疾病分类，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 儿科呼吸音分类研究不足，尤其是6岁以下儿童，需要专门的方法。

Method: 采用多阶段混合CNN-Transformer框架，结合CNN特征提取和注意力机制，处理数据不平衡问题。

Result: 在二元和多元分类任务中分别达到0.9039和0.8448的分数，优于之前最佳模型。

Conclusion: 该方法为资源有限地区的儿科呼吸疾病诊断提供了可行方案。

Abstract: Automated analysis of lung sound auscultation is essential for monitoring
respiratory health, especially in regions facing a shortage of skilled
healthcare workers. While respiratory sound classification has been widely
studied in adults, its ap plication in pediatric populations, particularly in
children aged <6 years, remains an underexplored area. The developmental
changes in pediatric lungs considerably alter the acoustic proper ties of
respiratory sounds, necessitating specialized classification approaches
tailored to this age group. To address this, we propose a multistage hybrid
CNN-Transformer framework that combines CNN-extracted features with an
attention-based architecture to classify pediatric respiratory diseases using
scalogram images from both full recordings and individual breath events. Our
model achieved an overall score of 0.9039 in binary event classifi cation and
0.8448 in multiclass event classification by employing class-wise focal loss to
address data imbalance. At the recording level, the model attained scores of
0.720 for ternary and 0.571 for multiclass classification. These scores
outperform the previous best models by 3.81% and 5.94%, respectively. This
approach offers a promising solution for scalable pediatric respiratory disease
diagnosis, especially in resource-limited settings.

</details>


### [32] [Energy-Efficient Secure Communications via Joint Optimization of UAV Trajectory and Movable-Antenna Array Beamforming](https://arxiv.org/abs/2507.20489)
*Sanghyeok Kim,Jinu Gong,Joonhyuk Kang*

Main category: eess.SP

TL;DR: 论文研究无人机搭载可移动天线阵列提升无线通信系统安全性，提出联合优化无人机轨迹和天线波束成形的框架，以提高保密能效。


<details>
  <summary>Details</summary>
Motivation: 探索无人机和可移动天线阵列在无线通信安全中的潜力，解决物理层安全问题。

Method: 提出联合优化无人机轨迹和可移动天线波束成形的框架，利用空间自由度形成高方向性波束和深零陷。

Result: 数值结果表明，所提方法显著提高了保密能效，得益于可移动天线架构的空间灵活性。

Conclusion: 可移动天线阵列与无人机轨迹优化结合，能有效增强无线通信系统的物理层安全性。

Abstract: This paper investigates the potential of unmanned aerial vehicles (UAVs)
equipped with movable-antenna (MA) arrays to strengthen security in wireless
communication systems. We propose a novel framework that jointly optimizes the
UAV trajectory and the reconfigurable beamforming of the MA array to maximize
secrecy energy efficiency, while ensuring reliable communication with
legitimate users. By exploiting the spatial degrees of freedom enabled by the
MA array, the system can form highly directional beams and deep nulls, thereby
significantly improving physical layer security. Numerical results demonstrate
that the proposed approach achieves superior secrecy energy efficiency,
attributed to the enhanced spatial flexibility provided by the movable antenna
architecture.

</details>


### [33] [Real-Time Distributed Optical Fiber Vibration Recognition via Extreme Lightweight Model and Cross-Domain Distillation](https://arxiv.org/abs/2507.20587)
*Zhongyao Luo,Hao Wu,Zhao Ge,Ming Tang*

Main category: eess.SP

TL;DR: 该论文提出了一种FPGA加速的轻量级模型和知识蒸馏框架，解决了分布式光纤振动传感系统在动态条件下识别精度下降和实时数据处理的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 分布式光纤振动传感系统在大规模监测和入侵事件识别中具有潜力，但动态条件下的识别精度下降和实时数据处理的计算瓶颈阻碍了其实际部署。

Method: 采用FPGA加速的三层深度可分离卷积网络（仅4141参数）和基于物理先验的跨域知识蒸馏框架，嵌入频域信息以提升模型泛化能力。

Result: 模型处理速度达0.019 ms/样本（覆盖12.5 m光纤），支持168.68 km光纤的实时处理；识别精度从未知环境下的51.93%提升至95.72%。

Conclusion: 该方法结合可解释信号处理与深度学习，为DVS系统提供了实时处理和边缘计算的参考架构，并揭示了DOFS技术中更高效、鲁棒和可解释AI系统的新方向。

Abstract: Distributed optical fiber vibration sensing (DVS) systems offer a promising
solution for large-scale monitoring and intrusion event recognition. However,
their practical deployment remains hindered by two major challenges:
degradation of recognition accuracy in dynamic conditions, and the
computational bottleneck of real-time processing for mass sensing data. This
paper presents a new solution to these challenges, through a FPGA-accelerated
extreme lightweight model along with a newly proposed knowledge distillation
framework. The proposed three-layer depthwise separable convolution network
contains only 4141 parameters, which is the most compact architecture in this
field to date, and achieves a maximum processing speed of 0.019 ms for each
sample covering a 12.5 m fiber length over 0.256 s. This performance
corresponds to real-time processing capabilities for sensing fibers extending
up to 168.68 km. To improve generalizability under changing environments, the
proposed cross-domain distillation framework guided by physical priors is used
here to embed frequency-domain insights into the time-domain model. This allows
for time-frequency representation learning without increasing complexity and
boosts recognition accuracy from 51.93% to 95.72% under unseen environmental
conditions. The proposed methodology provides key advancements including a
framework combining interpretable signal processing technique with deep
learning and a reference architecture for real-time processing and
edge-computing in DVS systems, and more general distributed optical fiber
sensing (DOFS) area. It mitigates the trade-off between sensing range and
real-time capability, bridging the gap between theoretical capabilities and
practical deployment requirements. Furthermore, this work reveals a new
direction for building more efficient, robust and explainable artificial
intelligence systems for DOFS technologies.

</details>


### [34] [RFI and Jamming Detection in Antenna Arrays with an LSTM Autoencoder](https://arxiv.org/abs/2507.20648)
*Christos Ntemkas,Antonios Argyriou*

Main category: eess.SP

TL;DR: 论文提出了一种利用天线阵列数据和深度学习检测射频干扰（RFI）及恶意干扰的新方法，无需先验知识即可高效检测。


<details>
  <summary>Details</summary>
Motivation: 射频干扰和恶意干扰是无线通信中的重大问题，传统方法依赖统计模型或AI算法，但需要输入基带数据或时频表示。本文旨在利用天线阵列数据，提出更高效的检测方法。

Method: 结合傅里叶成像空间定位干扰源，并采用深度LSTM自编码器检测异常（RFI和干扰）。

Result: 在不同功率水平的RFI/干扰和信号下，检测器表现出高性能，且无需干扰信号的先验知识。

Conclusion: 该方法为无线通信中的干扰检测提供了高效且无需先验知识的解决方案。

Abstract: Radio frequency interference (RFI) and malicious jammers are a significant
problem in our wireless world. Detecting RFI or jamming is typically performed
with model-based statistical detection or AI-empowered algorithms that use an
input baseband data or time-frequency representations like spectrograms. In
this work we depart from the previous approaches and we leverage data in
antenna array systems. We use Fourier imaging to localize spatially the sources
and then deploy a deep LSTM autoencoder that detects RFI and jamming as
anomalies. Our results for different power levels of the RFI/jamming sources,
and the signal of interest, reveal that our detector offers high performance
without needing any pre-existing knowledge regarding the RFI or jamming signal.

</details>


### [35] [Angle-distance decomposition based on deep learning for active sonar detection](https://arxiv.org/abs/2507.20651)
*Jichao Zhang,Xiao-Lei Zhang,Kunde Yang*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的主动声纳目标检测方法，通过分解角度和距离估计任务，结合迁移学习和模拟数据，解决了复杂水下环境中的噪声和干扰问题。


<details>
  <summary>Details</summary>
Motivation: 传统信号处理方法在复杂水下环境中面临噪声、混响和干扰的挑战，需要更有效的解决方案。

Method: 使用深度学习模型分别预测目标的角度和距离，并通过迁移学习和模拟数据解决数据不足的问题。

Result: 实验证明该方法在挑战性条件下具有有效且鲁棒的检测性能。

Conclusion: 基于深度学习的方法在主动声纳目标检测中表现出色，尤其在数据有限的情况下，迁移学习和模拟数据是有效的解决方案。

Abstract: Underwater target detection using active sonar constitutes a critical
research area in marine sciences and engineering. However, traditional signal
processing methods face significant challenges in complex underwater
environments due to noise, reverberation, and interference. To address these
issues, this paper presents a deep learning-based active sonar target detection
method that decomposes the detection process into separate angle and distance
estimation tasks. Active sonar target detection employs deep learning models to
predict target distance and angle, with the final target position determined by
integrating these estimates. Limited underwater acoustic data hinders effective
model training, but transfer learning and simulation offer practical solutions
to this challenge. Experimental results verify that the method achieves
effective and robust performance under challenging conditions.

</details>


### [36] [The micro-Doppler Attack Against AI-based Human Activity Classification from Wireless Signals](https://arxiv.org/abs/2507.20657)
*Margarita Loupa,Antonios Argyriou,Yanwei Liu*

Main category: eess.SP

TL;DR: 论文提出了一种针对基于无线OFDM信号的人类活动分类系统的微多普勒攻击，通过人为改变波形降低分类准确性。


<details>
  <summary>Details</summary>
Motivation: 研究无线信号被动收集的人类活动分类系统的安全性，揭示其潜在的脆弱性。

Method: 通过插入人工变化到OFDM波形中，改变其微多普勒特征，并研究两种时间尺度下的攻击变体。

Result: 使用深度卷积神经网络的HAC准确性可降至10%以下。

Conclusion: 微多普勒攻击能有效破坏HAC系统的准确性，暴露其安全漏洞。

Abstract: A subset of Human Activity Classification (HAC) systems are based on AI
algorithms that use passively collected wireless signals. This paper presents
the micro-Doppler attack targeting HAC from wireless orthogonal frequency
division multiplexing (OFDM) signals. The attack is executed by inserting
artificial variations in a transmitted OFDM waveform to alter its micro-Doppler
signature when it reflects off a human target. We investigate two variants of
our scheme that manipulate the waveform at different time scales resulting in
altered receiver spectrograms. HAC accuracy with a deep convolutional neural
network (CNN) can be reduced to less than 10%.

</details>


### [37] [A Nonlinear Spectral Approach for Radar-Based Heartbeat Estimation via Autocorrelation of Higher Harmonics](https://arxiv.org/abs/2507.20664)
*Kohei Shimomura,Chi-Hsuan Lee,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出一种非线性信号处理方法，通过利用心跳信号的高阶谐波周期性，提高雷达心跳间隔估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过选择性频率滤波或跟踪单个谐波，难以有效处理呼吸谐波和噪声，导致估计不准确。

Method: 采用非线性相关处理增强频谱的全局周期性结构，包括平滑和二阶导数操作抑制噪声，并通过局部自相关计算突出谐波频率。

Result: 实验表明，该方法将均方根误差降低20%，相关系数提高0.20。

Conclusion: 非线性方法能有效抑制噪声和呼吸谐波，提高心跳间隔估计的鲁棒性。

Abstract: This study presents a nonlinear signal processing method for accurate
radar-based heartbeat interval estimation by exploiting the periodicity of
higher-order harmonics inherent in heartbeat signals. Unlike conventional
approaches that employ selective frequency filtering or track individual
harmonics, the proposed method enhances the global periodic structure of the
spectrum via nonlinear correlation processing. Specifically, smoothing and
second-derivative operations are first applied to the radar displacement signal
to suppress noise and accentuate higher-order heartbeat harmonics. Rather than
isolating specific frequency components, we compute localized autocorrelations
of the Fourier spectrum around the harmonic frequencies. The incoherent
summation of these autocorrelations yields a pseudo-spectrum in which the
fundamental heartbeat periodicity is distinctly emphasized. This nonlinear
approach mitigates the effects of respiratory harmonics and noise, enabling
robust interbeat interval estimation. Experiments with radar measurements from
five participants demonstrate that the proposed method reduces root-mean-square
error by 20% and improves the correlation coefficient by 0.20 relative to
conventional techniques.

</details>


### [38] [DT-Aided Resource Management in Spectrum Sharing Integrated Satellite-Terrestrial Networks](https://arxiv.org/abs/2507.20789)
*Hung Nguyen-Kha,Vu Nguyen Ha,Ti Ti Nguyen,Eva Lagunas,Symeon Chatzinotas,Joel Grotz*

Main category: eess.SP

TL;DR: 提出了一种基于数字孪生的卫星-地面网络资源管理框架，通过联合优化带宽分配、流量引导和资源分配，以减少拥塞。


<details>
  <summary>Details</summary>
Motivation: 解决卫星与地面网络共存时的频谱共享挑战，如系统间干扰和低轨卫星移动问题。

Method: 采用时间变化的数字孪生框架，结合3D地图，通过两阶段算法（基于SCA和压缩感知）解决MINLP问题。

Result: 数值结果显示，该方法在队列长度最小化方面优于基准方法。

Conclusion: 提出的框架能有效管理卫星-地面网络的资源，减少拥塞。

Abstract: The integrated satellite-terrestrial networks (ISTNs) through spectrum
sharing have emerged as a promising solution to improve spectral efficiency and
meet increasing wireless demand. However, this coexistence introduces
significant challenges, including inter-system interference (ISI) and the low
Earth orbit satellite (LSat) movements. To capture the actual environment for
resource management, we propose a time-varying digital twin (DT)-aided
framework for ISTNs incorporating 3D map that enables joint optimization of
bandwidth (BW) allocation, traffic steering, and resource allocation, and aims
to minimize congestion. The problem is formulated as a mixed-integer nonlinear
programming (MINLP), addressed through a two-phase algorithm based on
successive convex approximation (SCA) and compressed sensing approaches.
Numerical results demonstrate the proposed method's superior performance in
queue length minimization compared to benchmarks.

</details>


### [39] [Chirp-Permuted AFDM: A New Degree of Freedom for Next-Generation Versatile Waveform Design](https://arxiv.org/abs/2507.20825)
*Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 提出了一种新型多载波波形CP-AFDM，通过在传统AFDM的啁啾子载波上引入啁啾置换域，提升了多普勒域的分辨率和峰值旁瓣比，同时保持了AFDM的核心特性。


<details>
  <summary>Details</summary>
Motivation: 为满足6G应用对可靠性和感知能力的需求，开发一种既能保持AFDM核心特性又能提升性能的新型波形。

Method: 在AFDM的基础上引入啁啾置换域，通过信号模型和数值模拟分析其性能。

Result: CP-AFDM在保持AFDM特性的同时，提升了多普勒域的分辨率和峰值旁瓣比，并展示了两种多功能应用。

Conclusion: CP-AFDM是一种适用于6G的高性能波形，具有多功能应用潜力。

Abstract: We present a novel multicarrier waveform, termed chirp-permuted affine
frequency division multiplexing (CP-AFDM), which introduces a unique
chirp-permutation domain on top of the chirp subcarriers of the conventional
AFDM. Rigorous analysis of the signal model and waveform properties, supported
by numerical simulations, demonstrates that the proposed CP-AFDM preserves all
core characteristics of affine frequency division multiplexing (AFDM) -
including robustness to doubly-dispersive channels, peak-to-average power ratio
(PAPR), and full delay-Doppler representation - while further enhancing
ambiguity function resolution and peak-to-sidelobe ratio (PSLR) in the Doppler
domain. These improvements establish CP-AFDM as a highly attractive candidate
for emerging sixth generation (6G) use cases demanding both reliability and
sensing-awareness. Moreover, by exploiting the vast degree of freedom in the
chirp-permutation domain, two exemplary multifunctional applications are
introduced: an index modulation (IM) technique over the permutation domain
which achieves significant spectral efficiency gains, and a physical-layer
security scheme that ensures practically perfect security through
permutation-based keying, without requiring additional transmit energy or
signaling overhead.

</details>


### [40] [Interference Analysis and Successive Interference Cancellation for Multistatic OFDM-based ISAC Systems](https://arxiv.org/abs/2507.20942)
*Taewon Jeong,Lucas Giroto,Umut Utku Erdem,Christian Karle,Jiyeon Choi,Thomas Zwick,Benjamin Nuss*

Main category: eess.SP

TL;DR: 多静态集成感知与通信（ISAC）系统通过分布式收发器提升覆盖范围和感知精度，但面临共存节点间的干扰问题。本文分析了干扰影响，提出了一种低复杂度干扰消除方法，并通过仿真和实测验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多静态ISAC系统因共存节点的干扰问题影响感知和通信性能，需研究干扰分类及消除方法以提升系统性能。

Method: 分类干扰类型，提出基于单静态雷达图像信干噪比（SINR）的低复杂度逐次干扰消除方法，并通过仿真和实测验证。

Result: 提出的方法在多种SINR条件下降低了误码率（BER），改善了误差向量幅度（EVM）和雷达图像SINR。

Conclusion: 低复杂度的干扰消除方法能有效提升多静态ISAC系统的性能，适用于实际应用。

Abstract: Multistatic integrated sensing and communications (ISAC) systems, which use
distributed transmitters and receivers, offer enhanced spatial coverage and
sensing accuracy compared to stand-alone ISAC configurations. However, these
systems face challenges due to interference between co-existing ISAC nodes,
especially during simultaneous operation. In this paper, we analyze the impact
of this mutual interference arising from the co-existence in a multistatic ISAC
scenario, where a mono- and a bistatic ISAC system share the same spectral
resources. We first classify differenct types of interference in the power
domain. Then, we discuss how the interference can affect both sensing and
communications in terms of bit error rate (BER), error vector magnitude (EVM),
and radar image under varied transmit power and RCS configurations through
simulations. Along with interfernce analysis, we propose a low-complexity
successive interference cancellation method that adaptively cancels either the
monostatic reflection or the bistatic line-of-sight signal based on a
monostatic radar image signal-to-interference-plus-noise ratio (SINR). The
proposed framework is evaluated with both simulations and proof-of-concept
measurements using an ISAC testbed with a radar echo generator for object
emulation. The results have shown that the proposed method reduces BER and
improves EVM as well as radar image SINR across a wide range of SINR
conditions. These results demonstrate that accurate component-wise cancellation
can be achieved with low computational overhead, making the method suitable for
practical applications.

</details>


### [41] [Analytical Modeling of Batteryless IoT Sensors Powered by Ambient Energy Harvesting](https://arxiv.org/abs/2507.20952)
*Jimmy Fernandez Landivar,Andrea Zanella,Ihsane Gryech,Sofie Pollin,Hazem Sallouha*

Main category: eess.SP

TL;DR: 提出了一种用于无电池物联网传感器节点的能量动态数学模型，涵盖能量收集和消耗阶段，并通过实验验证了模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 为无电池物联网设备提供精确的能量动态分析，以支持智能电源管理。

Method: 开发了一个综合数学模型，明确包含电源管理任务，并在三种不同光照条件下通过原型验证。

Result: 实验结果显示分析结果与实测超级电容器电压曲线高度吻合。

Conclusion: 该模型能准确预测无电池物联网设备的行为，适用于多种环境条件。

Abstract: This paper presents a comprehensive mathematical model to characterize the
energy dynamics of batteryless IoT sensor nodes powered entirely by ambient
energy harvesting. The model captures both the energy harvesting and
consumption phases, explicitly incorporating power management tasks to enable
precise estimation of device behavior across diverse environmental conditions.
The proposed model is applicable to a wide range of IoT devices and supports
intelligent power management units designed to maximize harvested energy under
fluctuating environmental conditions. We validated our model against a
prototype batteryless IoT node, conducting experiments under three distinct
illumination scenarios. Results show a strong correlation between analytical
and measured supercapacitor voltage profiles, confirming the proposed model's
accuracy.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [42] [SLENet: A Novel Multiscale CNN-Based Network for Detecting the Rats Estrous Cycle](https://arxiv.org/abs/2507.19566)
*Qinyang Wang,Hoileong Lee,Xiaodi Pu,Yuanming Lai,Yiming Ma*

Main category: eess.IV

TL;DR: 提出了一种基于EfficientNet改进的分类网络SLENet，用于自动识别大鼠动情周期，准确率达96.31%，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 大鼠动情周期对实验结果有显著影响，但人工识别成本高、耗时长且主观性强，需自动化解决方案。

Method: 基于EfficientNet改进，引入SECA机制替代SE模块，并添加Non-local注意力机制，增强长距离依赖捕捉能力。

Result: 在2655张显微图像数据集上测试，SLENet准确率达96.31%，优于基线模型（94.2%）。

Conclusion: SLENet为优化大鼠实验设计提供了实用工具，但未来需结合多模态输入以提升适用性。

Abstract: In clinical medicine, rats are commonly used as experimental subjects.
However, their estrous cycle significantly impacts their biological responses,
leading to differences in experimental results. Therefore, accurately
determining the estrous cycle is crucial for minimizing interference. Manually
identifying the estrous cycle in rats presents several challenges, including
high costs, long training periods, and subjectivity. To address these issues,
this paper proposes a classification network-Spatial Long-distance EfficientNet
(SLENet). This network is designed based on EfficientNet, specifically
modifying the Mobile Inverted Bottleneck Convolution (MBConv) module by
introducing a novel Spatial Efficient Channel Attention (SECA) mechanism to
replace the original Squeeze Excitation (SE) module. Additionally, a Non-local
attention mechanism is incorporated after the last convolutional layer to
enhance the network's ability to capture long-range dependencies. The dataset
used 2,655 microscopic images of rat vaginal epithelial cells, with 531 images
in the test set. Experimental results indicate that SLENet achieved an accuracy
of 96.31%, outperforming baseline EfficientNet model (94.2%). This finding
provide practical value for optimizing experimental design in rat-based studies
such as reproductive and pharmacological research, but this study is limited to
microscopy image data, without considering other factors like temporal
patterns, thus, incorporating multi-modal input is necessary for future
application.

</details>


### [43] [Multisession Longitudinal Dynamic MRI Incorporating Patient-Specific Prior Image Information Across Time](https://arxiv.org/abs/2507.19636)
*Jingjia Chen,Hersh Chandarana,Daniel K. Sodickson,Li Feng*

Main category: eess.IV

TL;DR: 提出了一种纵向动态MRI方法，利用患者先前的图像信息提高重建质量，减少扫描时间。


<details>
  <summary>Details</summary>
Motivation: 现有MRI重建方法独立处理每次成像会话，未利用纵向信息。

Method: 通过多会话时间分辨4D GRASP数据集拼接，采用低秩子空间重建算法。

Result: 纵向重建在图像质量上优于单会话重建，且能保留会话间变化。

Conclusion: 该方法为纵向MRI应用提供了高效且一致的成像新范式。

Abstract: Serial Magnetic Resonance Imaging (MRI) exams are often performed in clinical
practice, offering shared anatomical and motion information across imaging
sessions. However, existing reconstruction methods process each session
independently without leveraging this valuable longitudinal information. In
this work, we propose a novel concept of longitudinal dynamic MRI, which
incorporates patient-specific prior images to exploit temporal correlations
across sessions. This framework enables progressive acceleration of data
acquisition and reduction of scan time as more imaging sessions become
available. The concept is demonstrated using the 4D Golden-angle RAdial Sparse
Parallel (GRASP) MRI, a state-of-the-art dynamic imaging technique.
Longitudinal reconstruction is performed by concatenating multi-session
time-resolved 4D GRASP datasets into an extended dynamic series, followed by a
low-rank subspace-based reconstruction algorithm. A series of experiments were
conducted to evaluate the feasibility and performance of the proposed method.
Results show that longitudinal 4D GRASP reconstruction consistently outperforms
standard single-session reconstruction in image quality, while preserving
inter-session variations. The approach demonstrated robustness to changes in
anatomy, imaging intervals, and body contour, highlighting its potential for
improving imaging efficiency and consistency in longitudinal MRI applications.
More generally, this work suggests a new context-aware imaging paradigm in
which the more we see a patient, the faster we can image.

</details>


### [44] [A Metabolic-Imaging Integrated Model for Prognostic Prediction in Colorectal Liver Metastases](https://arxiv.org/abs/2507.19734)
*Qinlong Li,Pu Sun,Guanlin Zhu,Tianjiao Liang,Honggang QI*

Main category: eess.IV

TL;DR: 该研究开发了一种基于术前临床参数和影像特征的机器学习模型，用于预测结直肠肝转移（CRLM）术后复发风险，3个月预测模型表现最佳（AUC 0.723），并避免了数据泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 传统临床模型在CRLM预后评估中准确性不足，需要更可靠的预测工具。

Method: 使用术前基线临床参数和CT影像的放射组学特征，构建机器学习模型，预测术后3、6、12个月的复发风险。

Result: 3个月复发预测模型在交叉验证中AUC为0.723，决策曲线分析显示其临床实用性优于“全治疗”或“不治疗”策略。

Conclusion: 研究成功开发了具有临床实用性的早期复发预测模型，并强调了数据泄漏风险及解决方案，提升了模型的可靠性和转化价值。

Abstract: Prognostic evaluation in patients with colorectal liver metastases (CRLM)
remains challenging due to suboptimal accuracy of conventional clinical models.
This study developed and validated a robust machine learning model for
predicting postoperative recurrence risk. Preliminary ensemble models achieved
exceptionally high performance (AUC $>$ 0.98) but incorporated postoperative
features, introducing data leakage risks. To enhance clinical applicability, we
restricted input variables to preoperative baseline clinical parameters and
radiomic features from contrast-enhanced CT imaging, specifically targeting
recurrence prediction at 3, 6, and 12 months postoperatively. The 3-month
recurrence prediction model demonstrated optimal performance with an AUC of
0.723 in cross-validation. Decision curve analysis revealed that across
threshold probabilities of 0.55-0.95, the model consistently provided greater
net benefit than "treat-all" or "treat-none" strategies, supporting its utility
in postoperative surveillance and therapeutic decision-making. This study
successfully developed a robust predictive model for early CRLM recurrence with
confirmed clinical utility. Importantly, it highlights the critical risk of
data leakage in clinical prognostic modeling and proposes a rigorous framework
to mitigate this issue, enhancing model reliability and translational value in
real-world settings.

</details>


### [45] [SpecBPP: A Self-Supervised Learning Approach for Hyperspectral Representation and Soil Organic Carbon Estimation](https://arxiv.org/abs/2507.19781)
*Daniel La'ah Ayuba,Jean-Yves Guillemaut,Belen Marti-Cardona,Oscar Mendez Maldonado*

Main category: eess.IV

TL;DR: 提出了一种名为SpecBPP的自监督学习框架，通过预测光谱带的顺序来学习HSI表示，显著提升了土壤有机碳估计的性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在视觉和语言领域取得了成功，但在高光谱图像（HSI）中尚未充分探索。HSI的光谱带顺序结构提供了独特的学习机会。

Method: 提出SpecBPP框架，通过恢复打乱的光谱段顺序来学习全局光谱理解，并采用渐进式训练策略管理排列空间的复杂性。

Result: 在EnMAP卫星数据的土壤有机碳估计任务中，SpecBPP取得了最佳性能（R²=0.9456，RMSE=1.1053%，RPD=4.19），超越了其他自监督和监督基线。

Conclusion: 光谱顺序预测是HSI理解的有效预训练任务，为遥感及其他领域的科学表示学习开辟了新途径。

Abstract: Self-supervised learning has revolutionized representation learning in vision
and language, but remains underexplored for hyperspectral imagery (HSI), where
the sequential structure of spectral bands offers unique opportunities. In this
work, we propose Spectral Band Permutation Prediction (SpecBPP), a novel
self-supervised learning framework that leverages the inherent spectral
continuity in HSI. Instead of reconstructing masked bands, SpecBPP challenges a
model to recover the correct order of shuffled spectral segments, encouraging
global spectral understanding. We implement a curriculum-based training
strategy that progressively increases permutation difficulty to manage the
factorial complexity of the permutation space. Applied to Soil Organic Carbon
(SOC) estimation using EnMAP satellite data, our method achieves
state-of-the-art results, outperforming both masked autoencoder (MAE) and
joint-embedding predictive (JEPA) baselines. Fine-tuned on limited labeled
samples, our model yields an $R^2$ of 0.9456, RMSE of 1.1053%, and RPD of 4.19,
significantly surpassing traditional and self-supervised benchmarks. Our
results demonstrate that spectral order prediction is a powerful pretext task
for hyperspectral understanding, opening new avenues for scientific
representation learning in remote sensing and beyond.

</details>


### [46] [Hybrid Deep Learning and Handcrafted Feature Fusion for Mammographic Breast Cancer Classification](https://arxiv.org/abs/2507.19843)
*Maximilian Tschuchnig,Michael Gadermayr,Khalifa Djemal*

Main category: eess.IV

TL;DR: 提出了一种结合ResNet-50、手工特征和Transformer嵌入的混合框架，用于乳腺癌分类，性能优于单一方法。


<details>
  <summary>Details</summary>
Motivation: 由于良性和恶性组织之间的细微差异，乳腺癌自动分类仍具挑战性，需结合多种特征提升性能。

Method: 使用ResNet-50提取深度特征，结合手工描述符和DINOv2的Transformer嵌入，在CBIS-DDSM数据集上进行实验。

Result: 混合方法AUC达79.6%，召回率80.5%，F1分数67.4%，优于单一方法。

Conclusion: 混合特征融合方法性能接近SOTA，兼具简单性和计算效率，适合临床决策支持。

Abstract: Automated breast cancer classification from mammography remains a significant
challenge due to subtle distinctions between benign and malignant tissue. In
this work, we present a hybrid framework combining deep convolutional features
from a ResNet-50 backbone with handcrafted descriptors and transformer-based
embeddings. Using the CBIS-DDSM dataset, we benchmark our ResNet-50 baseline
(AUC: 78.1%) and demonstrate that fusing handcrafted features with deep
ResNet-50 and DINOv2 features improves AUC to 79.6% (setup d1), with a peak
recall of 80.5% (setup d1) and highest F1 score of 67.4% (setup d1). Our
experiments show that handcrafted features not only complement deep
representations but also enhance performance beyond transformer-based
embeddings. This hybrid fusion approach achieves results comparable to
state-of-the-art methods while maintaining architectural simplicity and
computational efficiency, making it a practical and effective solution for
clinical decision support.

</details>


### [47] [Taming Domain Shift in Multi-source CT-Scan Classification via Input-Space Standardization](https://arxiv.org/abs/2507.19858)
*Chia-Ming Lee,Bo-Cheng Qiu,Ting-Yao Chen,Ming-Han Sun,Fang-Ying Lin,Jung-Tse Tsai,I-An Tsai,Yu-Fan Lin,Chih-Chung Hsu*

Main category: eess.IV

TL;DR: 该研究分析了SSFL++和KDS预处理管道如何通过输入空间标准化平衡局部可区分性和跨源泛化能力，证明其能有效减少域偏移并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 多源CT扫描分类中存在域偏移问题，影响跨源泛化能力，现有预处理方法的机制尚不明确。

Method: 采用SSFL++和KDS进行空间和时间标准化，将不同输入映射到一致的目标空间。

Result: 实验验证了该方法在不同架构中的一致性改进，并在竞赛中获得第一名。

Conclusion: 输入空间标准化是解决多机构医学影像域偏移的鲁棒且实用的解决方案。

Abstract: Multi-source CT-scan classification suffers from domain shifts that impair
cross-source generalization. While preprocessing pipelines combining
Spatial-Slice Feature Learning (SSFL++) and Kernel-Density-based Slice Sampling
(KDS) have shown empirical success, the mechanisms underlying their domain
robustness remain underexplored. This study analyzes how this input-space
standardization manages the trade-off between local discriminability and
cross-source generalization. The SSFL++ and KDS pipeline performs spatial and
temporal standardization to reduce inter-source variance, effectively mapping
disparate inputs into a consistent target space. This preemptive alignment
mitigates domain shift and simplifies the learning task for network
optimization. Experimental validation demonstrates consistent improvements
across architectures, proving the benefits stem from the preprocessing itself.
The approach's effectiveness was validated by securing first place in a
competitive challenge, supporting input-space standardization as a robust and
practical solution for multi-institutional medical imaging.

</details>


### [48] [SkinDualGen: Prompt-Driven Diffusion for Simultaneous Image-Mask Generation in Skin Lesions](https://arxiv.org/abs/2507.19970)
*Zhaobin Xu*

Main category: eess.IV

TL;DR: 提出了一种利用Stable Diffusion-2.0生成高质量合成皮肤病变图像和分割掩码的方法，显著提升了分类和分割任务的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析在疾病早期诊断中至关重要，但数据稀缺和类别不平衡问题限制了深度学习模型的性能。

Method: 通过领域特定的LoRA微调和多目标损失函数的联合优化，使模型能一步生成临床相关图像和分割掩码。

Result: 生成的图像质量接近真实图像，混合数据集显著提升了分类和分割模型的性能（准确率和F1分数提高8%-15%）。

Conclusion: 该方法为医学影像数据的挑战提供了可扩展的解决方案，提升了罕见疾病诊断的准确性和可靠性。

Abstract: Medical image analysis plays a pivotal role in the early diagnosis of
diseases such as skin lesions. However, the scarcity of data and the class
imbalance significantly hinder the performance of deep learning models. We
propose a novel method that leverages the pretrained Stable Diffusion-2.0 model
to generate high-quality synthetic skin lesion images and corresponding
segmentation masks. This approach augments training datasets for classification
and segmentation tasks. We adapt Stable Diffusion-2.0 through domain-specific
Low-Rank Adaptation (LoRA) fine-tuning and joint optimization of
multi-objective loss functions, enabling the model to simultaneously generate
clinically relevant images and segmentation masks conditioned on textual
descriptions in a single step. Experimental results show that the generated
images, validated by FID scores, closely resemble real images in quality. A
hybrid dataset combining real and synthetic data markedly enhances the
performance of classification and segmentation models, achieving substantial
improvements in accuracy and F1-score of 8% to 15%, with additional positive
gains in other key metrics such as the Dice coefficient and IoU. Our approach
offers a scalable solution to address the challenges of medical imaging data,
contributing to improved accuracy and reliability in diagnosing rare diseases.

</details>


### [49] [On Uncertainty Prediction for Deep-Learning-based Particle Image Velocimetry](https://arxiv.org/abs/2507.20102)
*Wei Wang,Jeremiah Hu,Jia Ai,Yong Lee*

Main category: eess.IV

TL;DR: 本文探讨了深度学习在PIV中的不确定性量化方法，比较了UNN、MM和MT三种方法，发现UNN表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习显著提升了PIV的精度和效率，但其不确定性量化仍是一个被忽视的关键挑战。

Method: 研究了三种不确定性量化方法：UNN、MM和MT，并在多个数据集上进行了评估。

Result: 三种方法在轻度扰动下表现良好，其中UNN方法表现最优，提供了准确的不确定性估计。

Conclusion: 本研究为PIV中的不确定性量化提供了全面框架，对未来的研究和实际应用具有指导意义。

Abstract: Particle Image Velocimetry (PIV) is a widely used technique for flow
measurement that traditionally relies on cross-correlation to track the
displacement. Recent advances in deep learning-based methods have significantly
improved the accuracy and efficiency of PIV measurements. However, despite its
importance, reliable uncertainty quantification for deep learning-based PIV
remains a critical and largely overlooked challenge. This paper explores three
methods for quantifying uncertainty in deep learning-based PIV: the Uncertainty
neural network (UNN), Multiple models (MM), and Multiple transforms (MT). We
evaluate the three methods across multiple datasets. The results show that all
three methods perform well under mild perturbations. Among the three evaluation
metrics, the UNN method consistently achieves the best performance, providing
accurate uncertainty estimates and demonstrating strong potential for
uncertainty quantification in deep learning-based PIV. This study provides a
comprehensive framework for uncertainty quantification in PIV, offering
insights for future research and practical implementation.

</details>


### [50] [Implicit Spatiotemporal Bandwidth Enhancement Filter by Sine-activated Deep Learning Model for Fast 3D Photoacoustic Tomography](https://arxiv.org/abs/2507.20575)
*I Gede Eka Sulistyawan,Takuro Ishii,Riku Suzuki,Yoshifumi Saijo*

Main category: eess.IV

TL;DR: 论文提出了一种基于正弦激活的深度学习模型，用于恢复稀疏和带宽受限的3D光声断层扫描数据，通过简化训练策略和模拟数据，提高了图像质量和带宽恢复能力。


<details>
  <summary>Details</summary>
Motivation: 解决3D光声断层扫描中因传感器稀疏和带宽受限导致的图像质量下降问题。

Method: 引入正弦激活的深度学习模型，直接处理传感器级光声射频数据，采用模拟随机球形吸收体的简化训练策略。

Result: 模型在多种测试中表现良好，显著提高了高频内容恢复和图像对比度，同时保持了结构相似性。

Conclusion: 正弦激活模型有效提升了3D光声断层扫描的图像质量和实用性，适用于自由移动目标的快速成像。

Abstract: 3D photoacoustic tomography (3D-PAT) using high-frequency hemispherical
transducers offers near-omnidirectional reception and enhanced sensitivity to
the finer structural details encoded in the high-frequency components of the
broadband photoacoustic (PA) signal. However, practical constraints such as
limited number of channels with bandlimited sampling rate often result in
sparse and bandlimited sensors that degrade image quality. To address this, we
revisit the 2D deep learning (DL) approach applied directly to sensor-wise PA
radio-frequency (PARF) data. Specifically, we introduce sine activation into
the DL model to restore the broadband nature of PARF signals given the observed
band-limited and high-frequency PARF data. Given the scarcity of 3D training
data, we employ simplified training strategies by simulating random spherical
absorbers. This combination of sine-activated model and randomized training is
designed to emphasize bandwidth learning over dataset memorization. Our model
was evaluated on a leaf skeleton phantom, a micro-CT-verified 3D spiral phantom
and in-vivo human palm vasculature. The results showed that the proposed
training mechanism on sine-activated model was well-generalized across the
different tests by effectively increasing the sensor density and recovering the
spatiotemporal bandwidth. Qualitatively, the sine-activated model uniquely
enhanced high-frequency content that produces clearer vascular structure with
fewer artefacts. Quantitatively, the sine-activated model exhibits full
bandwidth at -12 dB spectrum and significantly higher contrast-to-noise ratio
with minimal loss of structural similarity index. Lastly, we optimized our
approach to enable fast enhanced 3D-PAT at 2 volumes-per-second for better
practical imaging of a free-moving targets.

</details>


### [51] [Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural Network](https://arxiv.org/abs/2507.20765)
*Davide Piccinini,Diego Valsesia,Enrico Magli*

Main category: eess.IV

TL;DR: 论文提出了一种轻量级的神经网络设计DPSR，用于实时提升卫星上高光谱图像的空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像的空间分辨率有限，提升分辨率有助于下游任务；同时需要在卫星上部署轻量级实时超分辨率方法。

Method: 设计了DPSR神经网络，通过逐行处理图像并利用因果记忆机制，减少内存和计算需求。

Result: DPSR在低功耗硬件上实现实时性能，超分辨率质量优于或媲美更复杂的方法。

Conclusion: DPSR是一种高效、轻量级的超分辨率方法，适用于卫星上的实时处理。

Abstract: Hyperspectral imagers on satellites obtain the fine spectral signatures
essential for distinguishing one material from another at the expense of
limited spatial resolution. Enhancing the latter is thus a desirable
preprocessing step in order to further improve the detection capabilities
offered by hyperspectral images on downstream tasks. At the same time, there is
a growing interest towards deploying inference methods directly onboard of
satellites, which calls for lightweight image super-resolution methods that can
be run on the payload in real time. In this paper, we present a novel neural
network design, called Deep Pushbroom Super-Resolution (DPSR) that matches the
pushbroom acquisition of hyperspectral sensors by processing an image line by
line in the along-track direction with a causal memory mechanism to exploit
previously acquired lines. This design greatly limits memory requirements and
computational complexity, achieving onboard real-time performance, i.e., the
ability to super-resolve a line in the time it takes to acquire the next one,
on low-power hardware. Experiments show that the quality of the super-resolved
images is competitive or even outperforms state-of-the-art methods that are
significantly more complex.

</details>
