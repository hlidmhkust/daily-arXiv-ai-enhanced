<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 5]
- [eess.IV](#eess.IV) [Total: 21]
- [eess.SP](#eess.SP) [Total: 6]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [A Convergent Primal-Dual Algorithm for Computing Rate-Distortion-Perception Functions](https://arxiv.org/abs/2508.13486)
*Chunhui Chen,Linyi Chen,Xueyan Niu,Hao Wu*

Main category: cs.IT

TL;DR: 这篇论文提出了一种新的理论框架和算法，用于计算率相式-失真度-感知估计（RDP）函数，解决了现有方法缺乏理论保证的问题，并首次证明了O(1/n)的严格收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有的数值方法在处理复杂的感知约束时缺乏理论保证，导致非凸性和计算不可行性问题。需要一种具有严格收敛性证明的方法来解决RDP函数计算问题。

Method: 采用了一种新的理论框架，通过改写建模问题来改进优化过程。关键思想是放宽对重建分布的约束，并以重建分布本身的替代优化方法进行替代。基于此形式，发展了一种新题的原始-对偶算法。

Result: 首次证明了RDP函数计算的O(1/n)收敛速度。该方法不仅填补了现有文献中的理论空白，而且在代表性设置中达到了竞争性的实验性能。实验结果证明了该算法的高效性和准确性。

Conclusion: 这项研究为RDP约束压缩系统的更可靠和可解释性优化奠定了基础。提出的理论框架和算法有效解决了复杂感知约束下的计算挑战，为该领域的后续研究提供了重要支撑。

Abstract: Recent advances in Rate-Distortion-Perception (RDP) theory highlight the
importance of balancing compression level, reconstruction quality, and
perceptual fidelity. While previous work has explored numerical approaches to
approximate the information RDP function, the lack of theoretical guarantees
remains a major limitation, especially in the presence of complex perceptual
constraints that introduce non-convexity and computational intractability.
Inspired by our previous constrained Blahut-Arimoto algorithm for solving the
rate-distortion function, in this paper, we present a new theoretical framework
for computing the information RDP function by relaxing the constraint on the
reconstruction distribution and replacing it with an alternative optimization
approach over the reconstruction distribution itself. This reformulation
significantly simplifies the optimization and enables a rigorous proof of
convergence. Based on this formulation, we develop a novel primal-dual
algorithm with provable convergence guarantees. Our analysis establishes, for
the first time, a rigorous convergence rate of $O(1/n)$ for the computation of
RDP functions. The proposed method not only bridges a key theoretical gap in
the existing literature but also achieves competitive empirical performance in
representative settings. These results lay the groundwork for more reliable and
interpretable optimization in RDP-constrained compression systems. Experimental
results demonstrate the efficiency and accuracy of the proposed algorithm.

</details>


### [2] [On optimal quantum LRCs from the Hermitian construction and $t$-designs](https://arxiv.org/abs/2508.13553)
*Yang Li,Shitao Li,Huimin Lao,Gaojun Luo,San Ling*

Main category: cs.IT

TL;DR: 通过Hermitian构造推导了量子本地可恢复码的四个界限，构建了多个新的NMDS码家族，并获得了三个明确的最优量子本地可恢复码家族


<details>
  <summary>Details</summary>
Motivation: 解决Luo等人在2025年提出的开放问题，为大规模量子数据存储提供更好的量子本地可恢复码，并推进量子LDPC码的研究

Method: 采用Hermitian构造方法，构建具有灵活维数的NMDS码，这些码支持2设计和3设计，然后通过获得Hermitian对偶包含的经典本地可恢复码来得到量子本地可恢复码

Result: 推导了量子本地可恢复码的四个新界限，构建了三个明确的最优量子本地可恢复码家族，这些码的参数比通过CSS构造获得的已知码更加灵活新颖

Conclusion: 该工作不仅解决了一个重要的开放问题，而且为量子信息处理领域提供了参数更优、更灵活的量子本地可恢复码，构建的经典码本身也在四个不同界限下达到最优

Abstract: In a recent work, quantum locally recoverable codes (qLRCs) have been
introduced for their potential application in large-scale quantum data storage
and implication for quantum LDPC codes. This work focuses on the bounds and
constructions of qLRCs derived from the Hermitian construction, which solves an
open problem proposed by Luo $et~al.$ (IEEE Trans. Inf. Theory, 71 (3):
1794-1802, 2025). We present four bounds for qLRCs and give comparisons in
terms of their asymptotic formulas. We construct several new infinite families
of NMDS codes, with general and flexible dimensions, that support t-designs for
$t\in \{2,3\}$, and apply them to obtain Hermitian dual-containing classical
LRCs (cLRCs). As a result, we derive three explicit families of optimal qLRCs.
Compared to the known qLRCs obtained by the CSS construction, our optimal qLRCs
offer new and more flexible parameters. It is also worth noting that the
constructed cLRCs themselves are interesting as they are optimal with respect
to four distinct bounds for cLRCs.

</details>


### [3] [Power and Rate Allocations for Positive-rate Covert Communications in Block-Fading Channels](https://arxiv.org/abs/2508.13555)
*Yubo Zhang,Hassan ZivariFard,Xiaodong Wang*

Main category: cs.IT

TL;DR: 该论文研究瑞利块衰落信道中的无密钥隐蔽通信，提出了功率分配和速率分配两种问题，分别针对非因果和因果CSI知识情况设计了不同的优化方法。


<details>
  <summary>Details</summary>
Motivation: 在无线通信中实现隐蔽通信，特别是在瑞利块衰落信道环境下，当收发双方具有信道状态信息(CSI)而监听者只有统计信息时，如何优化功率和速率分配来最大化隐蔽通信性能。

Method: 对于非因果CSI情况，提出了三步法解决功率和速率分配问题；对于因果CSI情况，将功率分配问题建模为MDP并使用DDQN方法求解，速率分配问题则通过训练好的DDQN近似解决。

Result: 仿真结果表明所提出的功率和速率分配方法有效，并对不同分配方案进行了全面的性能比较。

Conclusion: 该研究为瑞利衰落信道中的隐蔽通信提供了有效的功率和速率分配策略，特别是在不同CSI知识场景下都能实现良好的隐蔽通信性能。

Abstract: We aim to achieve keyless covert communication with a positive-rate in
Rayleigh block-fading channels. Specifically, the transmitter and the
legitimate receiver are assumed to have either causal or non-causal knowledge
of the \ac{CSI} for both the legitimate and the warden channels, while the
warden only knows the statistical distribution of the \ac{CSI}. Two problem
formulations are considered in this work: (a) Power allocation: maximizing the
sum covert rate subject to a maximum power constraint, and (b) Rate allocation:
minimizing the power consumption subject to a minimum covert rate constraint.
Both problems are formulated based on recent information theoretical results on
covert communication over state-dependent channels. When the \ac{CSI} of each
fading block is known non-causally, we propose a novel three-step method to
solve both the power and rate allocation problems. In the case where the
\ac{CSI} is known causally, the power allocation problem can be formulated as
\ac{MDP} and be solved using a \ac{DDQN} approach. Although the rate allocation
problem under causal \ac{CSI} does not directly conform to an \ac{MDP}
structure, it can be approximately solved using the \ac{DDQN} trained for power
allocation. Simulation results demonstrate the effectiveness of the proposed
power and rate allocation methods and provide comprehensive performance
comparisons across different allocation schemes.

</details>


### [4] [Repeater Swarm-Assisted Cellular Systems: Interaction Stability and Performance Analysis](https://arxiv.org/abs/2508.13593)
*Jianan Bai,Anubhab Chowdhury,Anders Hansson,Erik G. Larsson*

Main category: cs.IT

TL;DR: 大规模MIMO系统中部署无线中继器群来改善覆盖，解决中继器间互相作用导致的正向反馈问题，并优化系统性能。


<details>
  <summary>Details</summary>
Motivation: 使用成本低廉、即插即用的全双工中继器群来提升细胞大规模MIMO系统的覆盖能力，但需要解决中继器间互相作用导致的系统不稳定问题和噪声注入影响。

Method: 推导了广义奇瑞利稳定性判据，开发了迭代优化算法来聚合优化中继器增益、用户发射功率和接收结合权重，以最大化加权和速率并确保系统稳定性。

Result: 数值结果证实中继器能够在sub-6 GHz和毫米波段显著提升系统性能，但需要沟通基站与中继器间的视线链路来充分发挥其优势。

Conclusion: 无线中继器群是改善大规模MIMO系统覆盖的有效手段，通过稳定性分析和聚合优化可以充分发挥其潜力，但部署时需注意中继器与基站间的链路质量。

Abstract: We consider a cellular massive MIMO system where swarms of wireless repeaters
are deployed to improve coverage. These repeaters are full-duplex relays with
small form factors that receive and instantaneously retransmit signals. They
can be deployed in a plug-and-play manner at low cost, while being transparent
to the network--conceptually they are active channel scatterers with
amplification capabilities. Two fundamental questions need to be addressed in
repeater deployments: (I) How can we prevent destructive effects of positive
feedback caused by inter-repeater interaction (i.e., each repeater receives and
amplifies signals from others)? (ii) How much performance improvement can be
achieved given that repeaters also inject noise and may introduce more
interference? To answer these questions, we first derive a generalized Nyquist
stability criterion for the repeater swarm system, and provide an easy-to-check
stability condition. Then, we study the uplink performance and develop an
efficient iterative algorithm that jointly optimizes the repeater gains, user
transmit powers, and receive combining weights to maximize the weighted sum
rate while ensuring system stability. Numerical results corroborate our
theoretical findings and show that the repeaters can significantly improve the
system performance, both in sub-6 GHz and millimeter-wave bands. The results
also warrant careful deployment to fully realize the benefits of repeaters, for
example, by ensuring a high probability of line-of-sight links between
repeaters and the base station.

</details>


### [5] [Joint Beamforming Design for RIS-Empowered NOMA-ISAC Systems](https://arxiv.org/abs/2508.13842)
*Chunjie Wang,Xuhui Zhang,Jinke Ren,Wenchao Liu,Shuqiang Wang,Yanyan Shen,Kejiang Ye,Chengzhong Xu,Dusit Niyato*

Main category: cs.IT

TL;DR: 本文提出了一种基于NOMA技术的RIS辅助ISAC系统联合通信与感知波束成形设计，通过交替优化算法最大化用户和速率，仿真结果显示优于基线算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决集成感知与通信系统中同时服务多用户和感知多目标的需求，利用RIS和NOMA技术提升系统性能。

Method: 采用交替优化框架，联合优化双功能基站的主动波束成形、RIS反射系数和雷达接收滤波器，在多种约束条件下最大化用户和速率。

Result: 仿真结果表明，所提出的算法在RIS赋能的NOMA-ISAC系统中优于基线算法，展现出显著优势。

Conclusion: 该研究为RIS辅助的ISAC系统提供了一种有效的联合优化方法，证明了NOMA技术在提升系统性能方面的潜力。

Abstract: This paper investigates a reconfigurable intelligent surface (RIS)-assisted
integrated sensing and communication (ISAC) system and proposes a joint
communication and sensing beamforming design based on non-orthogonal multiple
access (NOMA) technology. The system employs a dual-functional base station
(DFBS) to simultaneously serve multiple users and sense multiple targets with
the aid of RIS. To maximize the sum-rate of users, we jointly optimize the
DFBS's active beamforming, the RIS's reflection coefficients, and the radar
receive filters. The optimization is performed under constraints including the
radar signal-to-noise ratio thresholds, the user
signal-to-interference-plus-noise ratio requirements, the phase shifts of the
RIS, the total transmit power, the receive filters, and the successive
interference cancellation decoding order. To tackle the complex
interdependencies and non-convex nature of the optimization problem, we
introduce an effective iterative algorithm based on the alternating
optimization framework. Simulation results demonstrate that the proposed
algorithm outperforms baseline algorithms, highlighting its distinct advantages
in the considered RIS-empowered NOMA-ISAC systems.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [6] [Sex-Specific Vascular Score: A Novel Perfusion Biomarker from Supervoxel Analysis of 3D pCASL MRI](https://arxiv.org/abs/2508.13173)
*Sneha Noble,Neelam Sinha,Vaanathi Sundareshan,Thomas Gregor Issac*

Main category: eess.IV

TL;DR: 基于3D pCASL MRI的血管健康评估框架，通过超像素聚类和卷积神经网络识别性别特异的腥血模式，准确率达95%，为神经退血性疾病的早期识别提供个性化干预方案。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于插洞性血管健康在神经退血性疾病中的关键作用，特别是性别特异的腥血模式对疾病故变的影响。传统方法缺乏精确的性别特异血管评估工具，而3D pCASL MRI技术为这一研究提供了新的机会。

Method: 采用186名认知健康参与者的3D pCASL MRI数据，通过超像素聚类将大脑分割为空间连续的均匀腥血区域，提取平均腥血流值。训练自定制卷积神经网络进行性别分类，并系统分析男女群体内的区域性腥血流变化和年龄相关效应。

Result: 卷积神经网络在性别分类任务中达到95%的高准确率，显示了大脑中存在突出的性别特异腥血模式。研究还识别了男女群体内的区域性腥血流变化和年龄相关效应，为血管健康评估提供了重要参考。

Conclusion: 该研究提出的血管风险评分框架能够提升对正常大脑腥血和老化过程的理解，并为阵达恨病等神经退血性疾病的早期识别和个性化干预提供了有力的工具。该方法在预防性医学和个性化健康管理中具有重要的应用潜力。

Abstract: We propose a novel framework that leverages 3D pseudo-continuous arterial
spin labeling (3D pCASL) MRI to compute sex-specific vascular scores that
quantify cerebrovascular health and potential disease susceptibility. The brain
is parcellated into spatially contiguous regions of homogeneous perfusion using
supervoxel clustering, capturing both microvascular and macrovascular
contributions. Mean cerebral blood flow (CBF) values are extracted from 186
cognitively healthy participants and used to train a custom convolutional
neural network, achieving 95 percent accuracy in sex classification. This
highlights robust, sex-specific perfusion patterns across the brain.
Additionally, regional CBF variations and age-related effects are
systematically evaluated within male and female cohorts. The proposed vascular
risk-scoring framework enhances understanding of normative brain perfusion and
aging, and may facilitate early detection and personalized interventions for
neurodegenerative diseases such as Alzheimer's.

</details>


### [7] [Colon Polyps Detection from Colonoscopy Images Using Deep Learning](https://arxiv.org/abs/2508.13188)
*Md Al Amin,Bikash Kumar Paul*

Main category: eess.IV

TL;DR: 使用YOLOv5深度学习模型在结肠镜图像中进行息肉棉肠息肉棉检测，YOLOv5l版本表现最佳，mAP达到85.1%，为直肠癌穿前症的早期识别提供了有效工具。


<details>
  <summary>Details</summary>
Motivation: 直肠癌是全球癌症相关死亡的主要原因之一，息肉棉是其前驱病变。早期检测对改善患者预后至关重要。本研究意在探索深度学习物体检测技术在结肠镜图像中识别息肉棉的应用。

Method: 采用Kvasir-SEG数据集，进行大量数据增帿，并将数据分为训练集(80%)、验证集(训练集的20%)和测试集(20%)。评估了YOLOv5架构的三个变体(YOLOv5s、YOLOv5m、YOLOv5l)。

Result: YOLOv5l在所有变体中表现最佳，达到平均精度(mAP)85.1%，最高平均交并比(IoU)为0.86。

Conclusion: YOLOv5l在结肠息肉棉定位方面显示出优秀的检测性能，为提高直肠癌筛查的准确性提供了有前景的工具。

Abstract: Colon polyps are precursors to colorectal cancer, a leading cause of
cancer-related mortality worldwide. Early detection is critical for improving
patient outcomes. This study investigates the application of deep
learning-based object detection for early polyp identification using
colonoscopy images. We utilize the Kvasir-SEG dataset, applying extensive data
augmentation and splitting the data into training (80\%), validation (20\% of
training), and testing (20\%) sets. Three variants of the YOLOv5 architecture
(YOLOv5s, YOLOv5m, YOLOv5l) are evaluated. Experimental results show that
YOLOv5l outperforms the other variants, achieving a mean average precision
(mAP) of 85.1\%, with the highest average Intersection over Union (IoU) of
0.86. These findings demonstrate that YOLOv5l provides superior detection
performance for colon polyp localization, offering a promising tool for
enhancing colorectal cancer screening accuracy.

</details>


### [8] [Benchmarking GPT-5 for Zero-Shot Multimodal Medical Reasoning in Radiology and Radiation Oncology](https://arxiv.org/abs/2508.13192)
*Mingzhe Hu,Zach Eidex,Shansong Wang,Mojtaba Safari,Qiang Li,Xiaofeng Yang*

Main category: eess.IV

TL;DR: GPT-5在放射学、放射肿瘤学和医学物理学的多模态任务中相比GPT-4o有显著性能提升，在医学影像推理和数值问题解决方面表现优异


<details>
  <summary>Details</summary>
Motivation: 评估GPT-5等大型多模态模型在安全关键的医学领域（放射学、放射肿瘤学、医学物理学）中的实际应用价值，验证最新技术进步是否能转化为这些领域的可测量增益

Method: 采用零样本评估方法，在三个代表性任务上对比GPT-5及其变体（GPT-5-mini、GPT-5-nano）与GPT-4o的性能：1）VQA-RAD放射学视觉问答基准；2）SLAKE多语言跨模态理解数据集；3）医学物理委员会考试风格的150道多选题数据集

Result: GPT-5在所有数据集上获得最高准确率，相比GPT-4o提升显著：胸部纵隔区域+20.00%，肺部问题+13.60%，脑组织解读+11.44%。在物理委员会考试中达到90.7%准确率（136/150），超过人类通过阈值，而GPT-4o仅为78.0%

Conclusion: GPT-5在医学影像推理和领域特定数值问题解决方面相比GPT-4o提供了一致且显著的性能改进，展示了其在增强医学影像和治疗物理学专家工作流程方面的潜力

Abstract: Radiology, radiation oncology, and medical physics require decision-making
that integrates medical images, textual reports, and quantitative data under
high-stakes conditions. With the introduction of GPT-5, it is critical to
assess whether recent advances in large multimodal models translate into
measurable gains in these safety-critical domains. We present a targeted
zero-shot evaluation of GPT-5 and its smaller variants (GPT-5-mini, GPT-5-nano)
against GPT-4o across three representative tasks. We present a targeted
zero-shot evaluation of GPT-5 and its smaller variants (GPT-5-mini, GPT-5-nano)
against GPT-4o across three representative tasks: (1) VQA-RAD, a benchmark for
visual question answering in radiology; (2) SLAKE, a semantically annotated,
multilingual VQA dataset testing cross-modal grounding; and (3) a curated
Medical Physics Board Examination-style dataset of 150 multiple-choice
questions spanning treatment planning, dosimetry, imaging, and quality
assurance. Across all datasets, GPT-5 achieved the highest accuracy, with
substantial gains over GPT-4o up to +20.00% in challenging anatomical regions
such as the chest-mediastinal, +13.60% in lung-focused questions, and +11.44%
in brain-tissue interpretation. On the board-style physics questions, GPT-5
attained 90.7% accuracy (136/150), exceeding the estimated human passing
threshold, while GPT-4o trailed at 78.0%. These results demonstrate that GPT-5
delivers consistent and often pronounced performance improvements over GPT-4o
in both image-grounded reasoning and domain-specific numerical problem-solving,
highlighting its potential to augment expert workflows in medical imaging and
therapeutic physics.

</details>


### [9] [PediDemi -- A Pediatric Demyelinating Lesion Segmentation Dataset](https://arxiv.org/abs/2508.13239)
*Maria Popa,Gabriela Adriana Visa*

Main category: eess.IV

TL;DR: 首个公开的儿科脱骨骼病变数据集，包含13名患者的MRI扫描和病变资料，用于脱骨骼病变分割研究


<details>
  <summary>Details</summary>
Motivation: 目前缺乏公开的儿科脱骨骼病变数据集，特别是多硫性硫柱病以外的其他脱骨骼病变，影响了相关研究的进展

Method: 收集13名儿科脱骨骼病变患者的MRI扫描数据，包括3名ADEM患者，提供病变分割掩码和详细的病人元数据，并使用现有MS数据集训练的最新分割模型评估数据集质量

Result: 建立了首个公开的儿科脱骨骼病变数据集，为脱骨骼病变分割研究提供了重要资源，证明了多样化数据集的重要性

Conclusion: 该研究填补了儿科脱骨骼病变数据集的空白，为进一步研究提供了价值，并强调了多样化数据对医学图像分析的关键作用

Abstract: Demyelinating disorders of the central nervous system may have multiple
causes, the most common are infections, autoimmune responses, genetic or
vascular etiology. Demyelination lesions are characterized by areas were the
myelin sheath of the nerve fibers are broken or destroyed. Among autoimmune
disorders, Multiple Sclerosis (MS) is the most well-known Among these
disorders, Multiple Sclerosis (MS) is the most well-known and aggressive form.
Acute Disseminated Encephalomyelitis (ADEM) is another type of demyelinating
disease, typically with a better prognosis. Magnetic Resonance Imaging (MRI) is
widely used for diagnosing and monitoring disease progression by detecting
lesions. While both adults and children can be affected, there is a significant
lack of publicly available datasets for pediatric cases and demyelinating
disorders beyond MS. This study introduces, for the first time, a publicly
available pediatric dataset for demyelinating lesion segmentation. The dataset
comprises MRI scans from 13 pediatric patients diagnosed with demyelinating
disorders, including 3 with ADEM. In addition to lesion segmentation masks, the
dataset includes extensive patient metadata, such as diagnosis, treatment,
personal medical background, and laboratory results. To assess the quality of
the dataset and demonstrate its relevance, we evaluate a state-of-the-art
lesion segmentation model trained on an existing MS dataset. The results
underscore the importance of diverse datasets

</details>


### [10] [Automated Cervical Cancer Detection through Visual Inspection with Acetic Acid in Resource-Poor Settings with Lightweight Deep Learning Models Deployed on an Android Device](https://arxiv.org/abs/2508.13253)
*Leander Melroy Maben,Keerthana Prasad,Shyamala Guruvare,Vidya Kudva,P C Siddalingaswamy*

Main category: eess.IV

TL;DR: 使用轻量级深度学习算法自动化乳腰癌VIA细胞学检查，通过EfficientDet-Lite3检测关键区域和MobileNet-V2分类，在Android设备上实现高效执行。


<details>
  <summary>Details</summary>
Motivation: 解决低资源地区乳腰癌筛查的主观性问题，通过AI自动化VIA检测来消除主观性差异，让较低培训水平的医务人员也能执行筛查任务。

Method: 采用EfficientDet-Lite3作为关键区域检测器，结合MobileNet-V2基础的分类模型，部署在Android设备上，支持离线运行。

Result: 分类模型在测试集上达到准确率92.31%，敏感度98.24%，特异性88.37%的高性能指标。

Conclusion: 该轻量级AI系统为低资源地区提供了一种充满前景的自动化乳腰癌筛查方案，无需高级医疗设备或网络连接。

Abstract: Cervical cancer is among the most commonly occurring cancer among women and
claims a huge number of lives in low and middle-income countries despite being
relatively easy to treat. Several studies have shown that public screening
programs can bring down cervical cancer incidence and mortality rates
significantly. While several screening tests are available, visual inspection
with acetic acid (VIA) presents itself as the most viable option for
low-resource settings due to the affordability and simplicity of performing the
test. VIA requires a trained medical professional to interpret the test and is
subjective in nature. Automating VIA using AI eliminates subjectivity and would
allow shifting of the task to less trained health workers. Task shifting with
AI would help further expedite screening programs in low-resource settings. In
our work, we propose a lightweight deep learning algorithm that includes
EfficientDet-Lite3 as the Region of Interest (ROI) detector and a MobileNet- V2
based model for classification. These models would be deployed on an
android-based device that can operate remotely and provide almost instant
results without the requirement of highly-trained medical professionals, labs,
sophisticated infrastructure, or internet connectivity. The classification
model gives an accuracy of 92.31%, a sensitivity of 98.24%, and a specificity
of 88.37% on the test dataset and presents itself as a promising automated
low-resource screening approach.

</details>


### [11] [InnerGS: Internal Scenes Rendering via Factorized 3D Gaussian Splatting](https://arxiv.org/abs/2508.13287)
*Shuxin Liang,Yihan Xiao,Wenlu Tang*

Main category: eess.IV

TL;DR: 通过3D高斯散点技术直接建模内部结构，从稀疏切片数据重建平滑详细的内部场景


<details>
  <summary>Details</summary>
Motivation: 现有技术主要关注外部表面建模，而对于需深度理解物体内部结构的应用至关重要

Method: 通过内部3D高斯分布直接建模连续体积密度，无需相机位姬，即插即用

Result: 能够有效重建平滑且详细的内部结构

Conclusion: 该方法为内部场景重建提供了高效的解决方案，兼容任何数据模态，并提供了CUDA实现

Abstract: 3D Gaussian Splatting (3DGS) has recently gained popularity for efficient
scene rendering by representing scenes as explicit sets of anisotropic 3D
Gaussians. However, most existing work focuses primarily on modeling external
surfaces. In this work, we target the reconstruction of internal scenes, which
is crucial for applications that require a deep understanding of an object's
interior. By directly modeling a continuous volumetric density through the
inner 3D Gaussian distribution, our model effectively reconstructs smooth and
detailed internal structures from sparse sliced data. Our approach eliminates
the need for camera poses, is plug-and-play, and is inherently compatible with
any data modalities. We provide cuda implementation at:
https://github.com/Shuxin-Liang/InnerGS.

</details>


### [12] [Susceptibility Distortion Correction of Diffusion MRI with a single Phase-Encoding Direction](https://arxiv.org/abs/2508.13340)
*Sedigheh Dargahi,Sylvain Bouix,Christian Desrosier*

Main category: eess.IV

TL;DR: 深度学习方法仅需单次采集即可等效缩正碳化锌扭曲效应，提供了替代传统topup方法的实用方案


<details>
  <summary>Details</summary>
Motivation: 传统碳化锌扭曲缩正方法(topup)需要同时获取blip-up和blip-down图像对，而实际中很多往期数据只有单个相位编码方向，限制了其应用范围

Method: 提出基于深度学习的方法，仅使用单次采集的数据(或blip-up或blip-down)即可进行碳化锌扭曲缩正

Result: 实验结果显示，该方法达到了与topup相似的性能水平

Conclusion: 该深度学习方法作为一种高效且实用的替代方案，在碳化锌扭曲缩正方面具有强大潜力

Abstract: Diffusion MRI (dMRI) is a valuable tool to map brain microstructure and
connectivity by analyzing water molecule diffusion in tissue. However,
acquiring dMRI data requires to capture multiple 3D brain volumes in a short
time, often leading to trade-offs in image quality. One challenging artifact is
susceptibility-induced distortion, which introduces significant geometric and
intensity deformations. Traditional correction methods, such as topup, rely on
having access to blip-up and blip-down image pairs, limiting their
applicability to retrospective data acquired with a single phase encoding
direction. In this work, we propose a deep learning-based approach to correct
susceptibility distortions using only a single acquisition (either blip-up or
blip-down), eliminating the need for paired acquisitions. Experimental results
show that our method achieves performance comparable to topup, demonstrating
its potential as an efficient and practical alternative for susceptibility
distortion correction in dMRI.

</details>


### [13] [Towards Understanding and Harnessing the Transferability of Prognostic Knowledge in Computational Pathology](https://arxiv.org/abs/2508.13482)
*Pei Liu,Luping Ji,Jiaxiang Gou,Xiangxiang Zeng*

Main category: eess.IV

TL;DR: 该研究提出了第一个系统性的疾病预后知识转移研究(Path-PKT)，解决传统疾病特异模型在稀有肝癌和知识共享方面的局限性。通过大规模多疾病数据集和新的MoE-PKT方法，实现了不同疾病间预后知识的有效转移。


<details>
  <summary>Details</summary>
Motivation: 传统的WSI预后模型是疾病特异的，每种疾病需要独立开发模型，无法利用其他疾病的预后知识。这种方式在稀有肝癌(样本有限)和知识共享方面存在明显局限性。

Method: 研究包括三部分：(1)构建包含13种肝癌的大规模数据集UNI2-h-DSS；(2)设计实验分析知识转移的影响因素；(3)提出新的MoE-PKT方法，通过路由机制利用其他肝癌的通用预后知识。

Result: 研究证明了预后知识在不同肝癌间具有转移性，并通过MoE-PKT方法实现了有效的知识利用。特别是在稀有肝癌上，源模型的知识转移显著提升了预后性能。

Conclusion: 该研究为WSI基于肝癌预后的知识转移研究奠定了坚实基础，解决了传统疾病特异模型在稀有肝癌处理和知识共享方面的核心挑战，为跨疾病预后分析开启了新方向。

Abstract: Whole-Slide Image (WSI) is an important tool for evaluating the prognosis of
cancer patients. Present WSI-based prognosis studies generally follow a
conventional paradigm -- cancer-specific model development -- where one cancer
disease corresponds to one model and this model cannot make use of the
prognostic knowledge from others. Despite its notable success in recent years,
this paradigm has inherent limitations and has always been struggling with
practical requirements: (i) scaling to the rare tumor diseases with very
limited samples and (ii) benefiting from the generalizable prognostic knowledge
in other cancers. To this end, this paper presents the first systematic study
on Prognostic Knowledge Transfer in Pathology, called Path-PKT. It comprises
three main parts. (1) We curate a large dataset (UNI2-h-DSS) with 13 cancers
and use it to evaluate the transferability of prognostic knowledge between
different cancers computationally. (2) We design experiments to understand what
factors affect knowledge transfer and what causes positive transfers. (3)
Motivated by empirical findings, we propose a new baseline approach (MoE-PKT)
with a routing mechanism to utilize the generalizable prognostic knowledge in
other cancers. Finally, we show the transferability of source models to rare
tumor diseases. This study could lay solid foundations for the study of
knowledge transfer in WSI-based cancer prognosis. Source code is available at
https://github.com/liupei101/Path-PKT.

</details>


### [14] [State of Abdominal CT Datasets: A Critical Review of Bias, Clinical Relevance, and Real-world Applicability](https://arxiv.org/abs/2508.13626)
*Saeide Danaei,Zahra Dehghanian,Elahe Meftah,Nariman Naderi,Seyed Amir Ahmad Safavi-Naini,Faeze Khorasanizade,Hamid R. Rabiee*

Main category: eess.IV

TL;DR: 对46个公开腹部CT数据集的系统综述显示存在严重的数据冗余（59.1%病例重复）和地域偏见（75.3%来自欧美），高风险的领域偏移和选择偏见可能影响AI模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 评估公开腹部CT数据集在临床AI应用中的适用性，识别现有数据集的局限性，特别是对资源有限医疗环境的泛化问题。

Method: 系统性地审查了46个公开腹部CT数据集（共50,256项研究），对其中19个≥100病例的数据集进行了偏见评估。

Result: 发现59.1%的病例重复使用，75.3%数据来自北美和欧洲，63%存在领域偏移风险，57%存在选择偏见。

Conclusion: 提出多机构合作、标准化协议和多样化患者群体纳入等策略，以开发更公平和临床稳健的腹部影像AI模型。

Abstract: This systematic review critically evaluates publicly available abdominal CT
datasets and their suitability for artificial intelligence (AI) applications in
clinical settings. We examined 46 publicly available abdominal CT datasets
(50,256 studies). Across all 46 datasets, we found substantial redundancy
(59.1\% case reuse) and a Western/geographic skew (75.3\% from North America
and Europe). A bias assessment was performed on the 19 datasets with >=100
cases; within this subset, the most prevalent high-risk categories were domain
shift (63\%) and selection bias (57\%), both of which may undermine model
generalizability across diverse healthcare environments -- particularly in
resource-limited settings. To address these challenges, we propose targeted
strategies for dataset improvement, including multi-institutional
collaboration, adoption of standardized protocols, and deliberate inclusion of
diverse patient populations and imaging technologies. These efforts are crucial
in supporting the development of more equitable and clinically robust AI models
for abdominal imaging.

</details>


### [15] [subCellSAM: Zero-Shot (Sub-)Cellular Segmentation for Hit Validation in Drug Discovery](https://arxiv.org/abs/2508.13701)
*Jacob Hanimann,Daniel Siegismund,Mario Wieser,Stephan Steigele*

Main category: eess.IV

TL;DR: 一种无需细调的零样本分割基础模型方法，通过上下文学习和自动提示机制，在生物医药高速语射屏幕中实现准确的核、细胞和子细胞结构分割


<details>
  <summary>Details</summary>
Motivation: 解决传统图像分析和深度学习方法在生物医药高通量屏幕中需要大量手动参数调整或领域特定模型细调的问题

Method: 采用三步分割流程（核、细胞、子细胞），通过上下文学习策略应用分割基础模型，使用增长面具和前景/背景点来编码形态学和拓扑学优先知识的自动提示机制

Result: 在标准细胞分割测试集和产业相关命中验证实验中，方法能够准确分割生物学相关结构而无需数据集特定调整

Conclusion: 该方法为生物医药发现中的高通量屏幕提供了一种无需手动调整的高效分割解决方案，显著提高了分析效率和准确性

Abstract: High-throughput screening using automated microscopes is a key driver in
biopharma drug discovery, enabling the parallel evaluation of thousands of drug
candidates for diseases such as cancer. Traditional image analysis and deep
learning approaches have been employed to analyze these complex, large-scale
datasets, with cell segmentation serving as a critical step for extracting
relevant structures. However, both strategies typically require extensive
manual parameter tuning or domain-specific model fine-tuning. We present a
novel method that applies a segmentation foundation model in a zero-shot
setting (i.e., without fine-tuning), guided by an in-context learning strategy.
Our approach employs a three-step process for nuclei, cell, and subcellular
segmentation, introducing a self-prompting mechanism that encodes morphological
and topological priors using growing masks and strategically placed
foreground/background points. We validate our method on both standard cell
segmentation benchmarks and industry-relevant hit validation assays,
demonstrating that it accurately segments biologically relevant structures
without the need for dataset-specific tuning.

</details>


### [16] [Optimizing Region of Interest Selection for Effective Embedding in Video Steganography Based on Genetic Algorithms](https://arxiv.org/abs/2508.13710)
*Nizheen A. Ali,Ramadhan J. Mstafa*

Main category: eess.IV

TL;DR: 使用遗传算法识别视频关键区域，通过AES加密数据后嵌入视频，实现高嵌入容量和保持高视频质量的视频隐写术


<details>
  <summary>Details</summary>
Motivation: 网络数据传输安全和隐私保护需求增长，需要在保持视频质量的前提下实现高效的数据隐藏技术

Method: 采用遗传算法(GA)识别视频中的关键区域(ROI)，使用AES标准加密秘密数据，然后将数据嵌入到视频覆盖中(最多占视频的10%)

Result: 嵌入容量高效率好，PSNR值在64-75 dB之间，嵌入数据与原始视频几乎无法区分，编码解码速度快，适合实时应用

Conclusion: 该方法通过GA算法和AES加密的结合，实现了高效、高安全性的视频隐写术，在保持视频质量的同时确保了数据隐藏的可靠性

Abstract: With the widespread use of the internet, there is an increasing need to
ensure the security and privacy of transmitted data. This has led to an
intensified focus on the study of video steganography, which is a technique
that hides data within a video cover to avoid detection. The effectiveness of
any steganography method depends on its ability to embed data without altering
the original video quality while maintaining high efficiency. This paper
proposes a new method to video steganography, which involves utilizing a
Genetic Algorithm (GA) for identifying the Region of Interest (ROI) in the
cover video. The ROI is the area in the video that is the most suitable for
data embedding. The secret data is encrypted using the Advanced Encryption
Standard (AES), which is a widely accepted encryption standard, before being
embedded into the cover video, utilizing up to 10% of the cover video. This
process ensures the security and confidentiality of the embedded data. The
performance metrics for assessing the proposed method are the Peak Signal to
Noise Ratio (PSNR) and the encoding and decoding time. The results show that
the proposed method has a high embedding capacity and efficiency, with a PSNR
ranging between 64 and 75 dBs, which indicates that the embedded data is almost
indistinguishable from the original video. Additionally, the method can encode
and decode data quickly, making it efficient for real time applications.

</details>


### [17] [Deep Biomechanically-Guided Interpolation for Keypoint-Based Brain Shift Registration](https://arxiv.org/abs/2508.13762)
*Tiago Assis,Ines P. Machado,Benjamin Zwick,Nuno C. Garcia,Reuben Dorent*

Main category: eess.IV

TL;DR: 一种基于深度学习的生物力学导向的脑部变形插值方法，通过生物力学模拟数据训练3D U-Net，从稀疏关键点估计密集变形场，在脑夜导航中提高射线定位精度


<details>
  <summary>Details</summary>
Motivation: 在脑夜导航中，准确补偿脑部移位对保持定位精度至关重要。现有的关键点注册方法依赖简单几何插值器，忽略了组织生物力学特性，导致密集变形场不准确

Method: 首先使用生物力学模拟生成大量合成脑部变形数据集，然后训练殊差3D U-Net网络，将标准插值估计精炼为生物力学导向的变形场

Result: 在大量模拟变形场上的实验表明，该方法显著超过传统插值方法，将均方误差降低了一半，同时在推理时间上增加的计算开销可以忽略不计

Conclusion: 该深度学习框架能够从稀疏匹配关键点生成物理可行的密集脑部变形场，为脑夜导航提供了更准确的变形补偿方案

Abstract: Accurate compensation of brain shift is critical for maintaining the
reliability of neuronavigation during neurosurgery. While keypoint-based
registration methods offer robustness to large deformations and topological
changes, they typically rely on simple geometric interpolators that ignore
tissue biomechanics to create dense displacement fields. In this work, we
propose a novel deep learning framework that estimates dense, physically
plausible brain deformations from sparse matched keypoints. We first generate a
large dataset of synthetic brain deformations using biomechanical simulations.
Then, a residual 3D U-Net is trained to refine standard interpolation estimates
into biomechanically guided deformations. Experiments on a large set of
simulated displacement fields demonstrate that our method significantly
outperforms classical interpolators, reducing by half the mean square error
while introducing negligible computational overhead at inference time. Code
available at:
\href{https://github.com/tiago-assis/Deep-Biomechanical-Interpolator}{https://github.com/tiago-assis/Deep-Biomechanical-Interpolator}.

</details>


### [18] [Comparing Conditional Diffusion Models for Synthesizing Contrast-Enhanced Breast MRI from Pre-Contrast Images](https://arxiv.org/abs/2508.13776)
*Sebastian Ibarra,Javier del Riego,Alessandro Catanese,Julian Cuba,Julian Cardona,Nataly Leon,Jonathan Infante,Karim Lekadir,Oliver Diaz,Richard Osuala*

Main category: eess.IV

TL;DR: 使用去噪扩散概率模型从预对比MRI合成动态对比增强MRI，减少对造影剂的依赖，在22种模型变体中发现基于减影图像的模型表现最佳，肿瘤感知损失和分割掩码条件能提升病灶保真度。


<details>
  <summary>Details</summary>
Motivation: 动态对比增强MRI对乳腺癌诊断至关重要，但依赖造影剂存在安全性问题、禁忌症、成本增加和工作流程复杂性，需要开发无造影剂的替代方案。

Method: 提出预对比条件去噪扩散概率模型，包括22种生成模型变体，引入肿瘤感知损失函数和显式肿瘤分割掩码条件，在单乳和全乳设置下进行实验。

Result: 基于减影图像的模型在五个评估指标上一致优于后对比基线模型，肿瘤感知损失和分割掩码输入能改善评估指标，读者研究确认合成图像的高真实感。

Conclusion: 生成式对比增强技术显示出临床潜力，但肿瘤定位输入在筛查环境中不一定可用，该方法为减少造影剂使用提供了有前景的解决方案。

Abstract: Dynamic contrast-enhanced (DCE) MRI is essential for breast cancer diagnosis
and treatment. However, its reliance on contrast agents introduces safety
concerns, contraindications, increased cost, and workflow complexity. To this
end, we present pre-contrast conditioned denoising diffusion probabilistic
models to synthesize DCE-MRI, introducing, evaluating, and comparing a total of
22 generative model variants in both single-breast and full breast settings.
Towards enhancing lesion fidelity, we introduce both tumor-aware loss functions
and explicit tumor segmentation mask conditioning. Using a public multicenter
dataset and comparing to respective pre-contrast baselines, we observe that
subtraction image-based models consistently outperform post-contrast-based
models across five complementary evaluation metrics. Apart from assessing the
entire image, we also separately evaluate the region of interest, where both
tumor-aware losses and segmentation mask inputs improve evaluation metrics. The
latter notably enhance qualitative results capturing contrast uptake, albeit
assuming access to tumor localization inputs that are not guaranteed to be
available in screening settings. A reader study involving 2 radiologists and 4
MRI technologists confirms the high realism of the synthetic images, indicating
an emerging clinical potential of generative contrast-enhancement. We share our
codebase at https://github.com/sebastibar/conditional-diffusion-breast-MRI.

</details>


### [19] [Direct vascular territory segmentation on cerebral digital subtraction angiography](https://arxiv.org/abs/2508.13821)
*P. Matthijs van der Sluijs,Lotte Strong,Frank G. te Nijenhuis,Sandra Cornelissen,Pieter Jan van Doormaal,Geert Lycklama a Nijeholt,Wim van Zwam,Ad van Es,Diederik Dippel,Aad van der Lugt,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: eess.IV

TL;DR: 使用深度学习nnUNet模型在脑部DSA影像中预测血管分布区域，精度显著超过传统地图注册方法


<details>
  <summary>Details</summary>
Motivation: DSA影像主要可视化血管，软组织观察不清，需要预测隐藏的血管分布区域以支持医生进行脉冻中风治疗

Method: 使用nnUNet深度学习模型，在1224份脉冻中风患者的DSA影像上训练，手动分割内颈动脉和大脑中动脉血管领域

Result: 深度学习模型DSC指标显著更高(0.96 vs 0.82)，ASD更低(13.8 vs 47.3)，外部测试成功率更高(85% vs 66%)，均p<0.001

Conclusion: 深度学习方法在DSA血管分布区域分割上显示出优秀的准确性和质量，有潜力应用于其他解剖结构可视化，代码已开源

Abstract: X-ray digital subtraction angiography (DSA) is frequently used when
evaluating minimally invasive medical interventions. DSA predominantly
visualizes vessels, and soft tissue anatomy is less visible or invisible in
DSA. Visualization of cerebral anatomy could aid physicians during treatment.
This study aimed to develop and evaluate a deep learning model to predict
vascular territories that are not explicitly visible in DSA imaging acquired
during ischemic stroke treatment. We trained an nnUNet model with manually
segmented intracranial carotid artery and middle cerebral artery vessel
territories on minimal intensity projection DSA acquired during ischemic stroke
treatment. We compared the model to a traditional atlas registration model
using the Dice similarity coefficient (DSC) and average surface distance (ASD).
Additionally, we qualitatively assessed the success rate in both models using
an external test. The segmentation model was trained on 1224 acquisitions from
361 patients with ischemic stroke. The segmentation model had a significantly
higher DSC (0.96 vs 0.82, p<0.001) and lower ASD compared to the atlas model
(13.8 vs 47.3, p<0.001). The success rate of the segmentation model (85%) was
higher compared to the atlas registration model (66%) in the external test set.
A deep learning method for the segmentation of vascular territories without
explicit borders on cerebral DSA demonstrated superior accuracy and quality
compared to the traditional atlas-based method. This approach has the potential
to be applied to other anatomical structures for enhanced visualization during
X-ray guided medical procedures. The code is publicly available at
https://github.com/RuishengSu/autoTICI.

</details>


### [20] [Improving Deep Learning for Accelerated MRI With Data Filtering](https://arxiv.org/abs/2508.13822)
*Kang Lin,Anselm Krainovic,Kun Wang,Reinhard Heckel*

Main category: eess.IV

TL;DR: 该研究探讨了数据筛选策略对加速MRI重建中深度学习模型性能的影响，通过构建大规模多样化数据集和测试集，发现适当的数据过滤能带来稳定但有限的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习MRI重建研究主要关注网络架构改进，而忽略了训练数据质量的影响。本研究旨在探索数据筛选策略如何提升MRI重建性能。

Method: 收集了来自18个公开来源的110万张图像的原始k空间数据，构建了包含48个测试集的多样化评估集。提出并研究了不同的数据过滤策略来增强现有最先进神经网络在加速MRI重建中的表现。

Result: 实验表明，过滤训练数据能带来一致但有限的性能提升。这种性能提升在不同训练集大小和加速倍数下都具有鲁棒性，特别是在未过滤训练集中分布内数据比例较低时，过滤效果更为明显。

Conclusion: 数据筛选是提升MRI重建性能的有效策略，特别是在训练数据分布不均匀时，适当的过滤能够显著改善模型表现。

Abstract: Deep neural networks achieve state-of-the-art results for accelerated MRI
reconstruction. Most research on deep learning based imaging focuses on
improving neural network architectures trained and evaluated on fixed and
homogeneous training and evaluation data. In this work, we investigate data
curation strategies for improving MRI reconstruction. We assemble a large
dataset of raw k-space data from 18 public sources consisting of 1.1M images
and construct a diverse evaluation set comprising 48 test sets, capturing
variations in anatomy, contrast, number of coils, and other key factors. We
propose and study different data filtering strategies to enhance performance of
current state-of-the-art neural networks for accelerated MRI reconstruction.
Our experiments show that filtering the training data leads to consistent,
albeit modest, performance gains. These performance gains are robust across
different training set sizes and accelerations, and we find that filtering is
particularly beneficial when the proportion of in-distribution data in the
unfiltered training set is low.

</details>


### [21] [Latent Interpolation Learning Using Diffusion Models for Cardiac Volume Reconstruction](https://arxiv.org/abs/2508.13826)
*Niklas Bubeck,Suprosanna Shit,Chen Chen,Can Zhao,Pengfei Guo,Dong Yang,Georg Zitzlsberger,Daguang Xu,Bernhard Kainz,Daniel Rueckert,Jiazhen Pan*

Main category: eess.IV

TL;DR: 提出CaLID框架，通过潜空间扩散模型实现高效的3D心脏重建，免需辅助输入且计算效率提升24倍


<details>
  <summary>Details</summary>
Motivation: 解决传统2D CMR成像切片稀疏导致体积信息不完整的问题，免除对预定义插值方案和辅助语义输入的依赖

Method: 基于扩散模型的数据驱动插值方案，在潜空间进行高效运算，支持2D+T时空动态建模

Result: 在体积评估和分割任务中达到SOTA性能，重建质量和效率都有显著提升

Conclusion: CaLID框架为心血管成像提供了稳健且临床实用的解决方案，推进了空间和时空心脏重建技术的发展

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a critical tool for diagnosing
and managing cardiovascular disease, yet its utility is often limited by the
sparse acquisition of 2D short-axis slices, resulting in incomplete volumetric
information. Accurate 3D reconstruction from these sparse slices is essential
for comprehensive cardiac assessment, but existing methods face challenges,
including reliance on predefined interpolation schemes (e.g., linear or
spherical), computational inefficiency, and dependence on additional semantic
inputs such as segmentation labels or motion data. To address these
limitations, we propose a novel \textbf{Ca}rdiac \textbf{L}atent
\textbf{I}nterpolation \textbf{D}iffusion (CaLID) framework that introduces
three key innovations. First, we present a data-driven interpolation scheme
based on diffusion models, which can capture complex, non-linear relationships
between sparse slices and improves reconstruction accuracy. Second, we design a
computationally efficient method that operates in the latent space and speeds
up 3D whole-heart upsampling time by a factor of 24, reducing computational
overhead compared to previous methods. Third, with only sparse 2D CMR images as
input, our method achieves SOTA performance against baseline methods,
eliminating the need for auxiliary input such as morphological guidance, thus
simplifying workflows. We further extend our method to 2D+T data, enabling the
effective modeling of spatiotemporal dynamics and ensuring temporal coherence.
Extensive volumetric evaluations and downstream segmentation tasks demonstrate
that CaLID achieves superior reconstruction quality and efficiency. By
addressing the fundamental limitations of existing approaches, our framework
advances the state of the art for spatio and spatiotemporal whole-heart
reconstruction, offering a robust and clinically practical solution for
cardiovascular imaging.

</details>


### [22] [A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler](https://arxiv.org/abs/2508.13875)
*Wenxuan Zhang,Shuai Li,Xinyi Wang,Yu Sun,Hongyu Kang,Pui Yuk Chryste Wan,Yong-Ping Zheng,Sai-Kit Lam*

Main category: eess.IV

TL;DR: 这篇论文提出了一种基于泡小波YOLO网络的AI系统，能够在经颈夜立体超声数据中实时自动分割脑底势圈的血管，以解决依赖操作者经验的问题。


<details>
  <summary>Details</summary>
Motivation: 经颈夜立体超声(TCCD)在脑血管评估中具有无放射、价格便宜和易获得等优势，但其可靠性依赖于操作者的专业知识和技能，限制了普及应用。需要一种能够减少人为干预的自动化解决方案。

Method: 提出了一种新的泡小波YOLO网络(AAW-YOLO)，将泡小波变换与泡小波反渣柱结合到YOLOv8框架中，以提高对TCCD数据的处理能力。采集了738帧注释数据和3,419个标记血管实例进行模型训练和评估。

Result: 系统在同侧和对侧脑底势圈血管分割中表现优异：平均Dice指数0.901、IoU 0.823、精度0.882、召回率0.926、mAP 0.953，每帧推理速度14.199ms，能够满足实时应用需求。

Conclusion: 该AI驱动系统为TCCD基础的脑血管筛查提供了实用解决方案，有效减少了对操作者经验的依赖，在常规临床工作流程和资源有限环境中具有应用潜力。

Abstract: The Circle of Willis (CoW), vital for ensuring consistent blood flow to the
brain, is closely linked to ischemic stroke. Accurate assessment of the CoW is
important for identifying individuals at risk and guiding appropriate clinical
management. Among existing imaging methods, Transcranial Color-coded Doppler
(TCCD) offers unique advantages due to its radiation-free nature,
affordability, and accessibility. However, reliable TCCD assessments depend
heavily on operator expertise for identifying anatomical landmarks and
performing accurate angle correction, which limits its widespread adoption. To
address this challenge, we propose an AI-powered, real-time CoW
auto-segmentation system capable of efficiently capturing cerebral arteries. No
prior studies have explored AI-driven cerebrovascular segmentation using TCCD.
In this work, we introduce a novel Attention-Augmented Wavelet YOLO (AAW-YOLO)
network tailored for TCCD data, designed to provide real-time guidance for
brain vessel segmentation in the CoW. We prospectively collected TCCD data
comprising 738 annotated frames and 3,419 labeled artery instances to establish
a high-quality dataset for model training and evaluation. The proposed AAW-YOLO
demonstrated strong performance in segmenting both ipsilateral and
contralateral CoW vessels, achieving an average Dice score of 0.901, IoU of
0.823, precision of 0.882, recall of 0.926, and mAP of 0.953, with a per-frame
inference speed of 14.199 ms. This system offers a practical solution to reduce
reliance on operator experience in TCCD-based cerebrovascular screening, with
potential applications in routine clinical workflows and resource-constrained
settings. Future research will explore bilateral modeling and larger-scale
validation.

</details>


### [23] [Learning to See Through Flare](https://arxiv.org/abs/2508.13907)
*Xiaopeng Peng,Heath Gemar,Erin Fleet,Kyle Novak,Abbie Watnik,Grover Swartzlander*

Main category: eess.IV

TL;DR: NeuSee是一个计算成像框架，通过联合学习衍射光学元件和频率空间Mamba-GAN网络，实现全可见光谱范围内的高保真传感器保护和激光抑制。


<details>
  <summary>Details</summary>
Motivation: 机器视觉系统容易受到激光耀斑的影响，强烈的激光照射会导致传感器过饱和或永久损坏，需要开发有效的保护方法。

Method: 联合学习衍射光学元件的神经表示和频率空间Mamba-GAN网络进行图像恢复，采用对抗性端到端训练，利用异构数据和模型并行化进行分布式计算。

Result: 系统能够抑制高达传感器饱和阈值10^6倍的峰值激光辐照度，在恢复图像质量方面比其他学习方法提升10.1%，首次实现全光谱成像和激光抑制。

Conclusion: NeuSee是第一个能够在全可见光谱范围内提供高保真传感器保护的计算成像框架，有效解决了激光耀斑对机器视觉系统的威胁。

Abstract: Machine vision systems are susceptible to laser flare, where unwanted intense
laser illumination blinds and distorts its perception of the environment
through oversaturation or permanent damage to sensor pixels. We introduce
NeuSee, the first computational imaging framework for high-fidelity sensor
protection across the full visible spectrum. It jointly learns a neural
representation of a diffractive optical element (DOE) and a frequency-space
Mamba-GAN network for image restoration. NeuSee system is adversarially trained
end-to-end on 100K unique images to suppress the peak laser irradiance as high
as $10^6$ times the sensor saturation threshold $I_{\textrm{sat}}$, the point
at which camera sensors may experience damage without the DOE. Our system
leverages heterogeneous data and model parallelism for distributed computing,
integrating hyperspectral information and multiple neural networks for
realistic simulation and image restoration. NeuSee takes into account
open-world scenes with dynamically varying laser wavelengths, intensities, and
positions, as well as lens flare effects, unknown ambient lighting conditions,
and sensor noises. It outperforms other learned DOEs, achieving full-spectrum
imaging and laser suppression for the first time, with a 10.1\% improvement in
restored image quality.

</details>


### [24] [MMIS-Net for Retinal Fluid Segmentation and Detection](https://arxiv.org/abs/2508.13936)
*Nchongmaje Ndipenocha,Alina Mirona,Kezhi Wanga,Yongmin Li*

Main category: eess.IV

TL;DR: 提出了MMIS-Net多模态医学图像分割网络，通过相似性融合块和一热标签空间处理多数据集训练，在RETOUCH挑战赛中获得最佳性能


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法大多在单一数据源上训练测试，忽略了其他可用标注数据的协同潜力，需要利用多个小型医学图像数据集来提升在未见数据上的性能

Method: 提出MMIS-Net算法，包含相似性融合块进行监督和像素级相似性知识选择，创建一热标签空间处理类别定义不一致和标签矛盾问题，在10个数据集上训练单一模型

Result: 在RETOUCH挑战赛隐藏测试集上超越大型基础模型和其他先进算法，获得最佳平均Dice分数0.83和绝对体积差异0.035，流体检测任务AUC达到1

Conclusion: 相似性融合块和一热标签空间的有效结合解决了多数据集训练中的监督和标签不一致问题，证明了模型在处理多模态多器官医学图像分割任务中的优越性

Abstract: Purpose: Deep learning methods have shown promising results in the
segmentation, and detection of diseases in medical images. However, most
methods are trained and tested on data from a single source, modality, organ,
or disease type, overlooking the combined potential of other available
annotated data. Numerous small annotated medical image datasets from various
modalities, organs, and diseases are publicly available. In this work, we aim
to leverage the synergistic potential of these datasets to improve performance
on unseen data. Approach: To this end, we propose a novel algorithm called
MMIS-Net (MultiModal Medical Image Segmentation Network), which features
Similarity Fusion blocks that utilize supervision and pixel-wise similarity
knowledge selection for feature map fusion. Additionally, to address
inconsistent class definitions and label contradictions, we created a one-hot
label space to handle classes absent in one dataset but annotated in another.
MMIS-Net was trained on 10 datasets encompassing 19 organs across 2 modalities
to build a single model. Results: The algorithm was evaluated on the RETOUCH
grand challenge hidden test set, outperforming large foundation models for
medical image segmentation and other state-of-the-art algorithms. We achieved
the best mean Dice score of 0.83 and an absolute volume difference of 0.035 for
the fluids segmentation task, as well as a perfect Area Under the Curve of 1
for the fluid detection task. Conclusion: The quantitative results highlight
the effectiveness of our proposed model due to the incorporation of Similarity
Fusion blocks into the network's backbone for supervision and similarity
knowledge selection, and the use of a one-hot label space to address label
class inconsistencies and contradictions.

</details>


### [25] [Real-Time, Population-Based Reconstruction of 3D Bone Models via Very-Low-Dose Protocols](https://arxiv.org/abs/2508.13947)
*Yiqun Lin,Haoran Sun,Yongqing Li,Rabia Aslam,Lung Fung Tse,Tiange Cheng,Chun Sing Chui,Wing Fung Yau,Victorine R. Le Meur,Meruyert Amangeldy,Kiho Cho,Yinyu Ye,James Zou,Wei Zhao,Xiaomeng Li*

Main category: eess.IV

TL;DR: SSR-KD是一个快速准确的AI框架，能够在30秒内从双平面X光片重建高质量骨骼模型，平均误差小于1.0mm，消除了对CT和人工工作的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统基于CT的骨骼建模方法存在灵活性低、辐射剂量高、手动分割耗时等问题，限制了其在术中的应用。需要一种快速、低辐射的替代方案。

Method: 提出了半监督重建与知识蒸馏（SSR-KD）框架，利用双平面X光片进行骨骼模型重建，结合知识蒸馏技术提高重建精度。

Result: 在30秒内完成重建，平均误差小于1.0mm。专家在高位胫骨截骨模拟中验证了重建模型与CT标注模型具有相当的临床适用性。

Conclusion: 该方法加速了重建过程，减少了辐射暴露，实现了术中引导，显著提高了骨骼模型的实用性，为骨科应用提供了变革性解决方案。

Abstract: Patient-specific bone models are essential for designing surgical guides and
preoperative planning, as they enable the visualization of intricate anatomical
structures. However, traditional CT-based approaches for creating bone models
are limited to preoperative use due to the low flexibility and high radiation
exposure of CT and time-consuming manual delineation. Here, we introduce
Semi-Supervised Reconstruction with Knowledge Distillation (SSR-KD), a fast and
accurate AI framework to reconstruct high-quality bone models from biplanar
X-rays in 30 seconds, with an average error under 1.0 mm, eliminating the
dependence on CT and manual work. Additionally, high tibial osteotomy
simulation was performed by experts on reconstructed bone models, demonstrating
that bone models reconstructed from biplanar X-rays have comparable clinical
applicability to those annotated from CT. Overall, our approach accelerates the
process, reduces radiation exposure, enables intraoperative guidance, and
significantly improves the practicality of bone models, offering transformative
applications in orthopedics.

</details>


### [26] [UNICON: UNIfied CONtinual Learning for Medical Foundational Models](https://arxiv.org/abs/2508.14024)
*Mohammad Areeb Qazi,Munachiso S Nwadike,Ibrahim Almakky,Mohammad Yaqub,Numan Saeed*

Main category: eess.IV

TL;DR: UNICON是一个统一的持续学习框架，使医学基础模型能够无缝适应不同领域、任务和模态，无需为每个新任务重新训练，避免了灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域数据稀缺，为每个领域、模态或任务预训练基础模型具有挑战性。持续学习可以通过顺序微调模型来整合新知识，而无需每个训练阶段都使用大型数据集。

Method: 提出UNICON框架，统一处理领域、任务和模态的变化，使基础模型能够动态扩展到不同成像模态、解剖区域和临床目标，避免灾难性遗忘和任务干扰。

Result: 将胸部CT基础模型从分类任务扩展到预后和分割任务，在两个附加任务上都显示出改进的性能。持续整合PET扫描后，Dice分数比相应基线提高了5%。

Conclusion: 基础模型并不固有地受限于其初始训练范围，而是可以进化发展，这为医学影像通用AI模型铺平了道路。

Abstract: Foundational models are trained on extensive datasets to capture the general
trends of a domain. However, in medical imaging, the scarcity of data makes
pre-training for every domain, modality, or task challenging. Continual
learning offers a solution by fine-tuning a model sequentially on different
domains or tasks, enabling it to integrate new knowledge without requiring
large datasets for each training phase. In this paper, we propose UNIfied
CONtinual Learning for Medical Foundational Models (UNICON), a framework that
enables the seamless adaptation of foundation models to diverse domains, tasks,
and modalities. Unlike conventional adaptation methods that treat these changes
in isolation, UNICON provides a unified, perpetually expandable framework.
Through careful integration, we show that foundation models can dynamically
expand across imaging modalities, anatomical regions, and clinical objectives
without catastrophic forgetting or task interference. Empirically, we validate
our approach by adapting a chest CT foundation model initially trained for
classification to a prognosis and segmentation task. Our results show improved
performance across both additional tasks. Furthermore, we continually
incorporated PET scans and achieved a 5\% improvement in Dice score compared to
respective baselines. These findings establish that foundation models are not
inherently constrained to their initial training scope but can evolve, paving
the way toward generalist AI models for medical imaging.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [27] [CKM-Assisted Physical-Layer Security for Resilience Against Unknown Eavesdropping Location](https://arxiv.org/abs/2508.13681)
*Ladan Khaloopour,Matthias Hollick,Vahid Jamali*

Main category: eess.SP

TL;DR: 利用频道知识地图(CKM)在mmWave系统中通过多束编码和资源分配来提高物理层安全性，无需假设偷听者位置或频道状态


<details>
  <summary>Details</summary>
Motivation: 解决传统物理层安全方案依赖偷听者位置和频道状态信息的限制，利用CKM提供的频道知识来实现更高效的安全通信

Method: 采用高方向性mmWave传输，将机密消息在多个束上进行聚合编码，通过CKM推导时间和功率分配算法

Result: 算法能够在偷听者位置最坏情况下最大化绝对保密速率

Conclusion: CKM为无线通信安全提供了一种不依赖偷听者信息的新方案，通过数据驱动的方式显著提升了物理层安全性能

Abstract: Channel Knowledge Map (CKM) is an emerging data-driven toolbox that captures
our awareness of the wireless channel and enables efficient communication and
resource allocation beyond the state of the art. In this work, we consider CKM
for improving physical-layer security (PLS) in the presence of a passive
eavesdropper (Eve), without making any assumptions about Eve's location or
channel state information (CSI). We employ highly directional mmWave
transmissions, with the confidential message jointly encoded across multiple
beams. By exploiting CKM, we derive an algorithm for time and power allocation
among the beams that maximizes the absolute secrecy rate under the worst-case
scenario for Eve's location.

</details>


### [28] [Airy beams for near-field communications: Fundamentals, potentials, and limitations](https://arxiv.org/abs/2508.13714)
*Donatella Darsena,Francesco Verde,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 这篇论文研究了近场区域中艾里光束的特性和应用，对比了艾里光束与高斯光束在非视线传播中的性能差异，证明了艾里光束在某些NLoS通道中具有更优的传播性能


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，近场区域的扩大为光束形成和控制提供了新的自由度，而艾里光束在近场区域具有自动加速、自戒恢和无行展等优异特性，有潜力提升非视线传播性能

Method: 首先分析连续孔径场分布辐射自加速光束的基本原理，然后研究有限能量和孔径截断对艾里光束生成的挑战，分析其自由空间传播特性，重点研究非视线场景下的传播行为，并与高斯光束进行对比分析

Result: 理论和数值结果显示，如果艾里光束的关键特性（沿抛物线轨迹自加速和无行展传播）能够大体保持，那么在某些非视线通道中其性能可能要优于高斯光束。在存在障碍物时，这需要传输孔径中有清晰视线路径的部分充分大

Conclusion: 艾里光束在下一代无线网络的近场区域传播中具有重要潜力，特别是在非视线传播场景下可能提供更优的性能。但需要充分大的视线路径孔径来保持其关键特性，以发挥其在复杂传播环境中的优势

Abstract: In next-generation wireless networks, the combination of electrically large
radiating apertures and high-frequency transmission extends the radiating
near-field region around the transmitter. In this region, unlike in the far
field, the wavefront is nonplanar, which provides additional degrees of freedom
to shape and steer the transmitted beam in a desired manner. In this paper, we
focus on Airy beams, which may exhibit several highly desirable properties in
the near-field region. Ideally, these beams follow self-accelerating (curved)
trajectories, demonstrate resilience to perturbations through self-healing, and
maintain a consistent intensity profile across all planes perpendicular to the
propagation direction, making them effectively diffraction-free. Specifically,
we first present the underlying principles of self-accelerating beams radiated
by continuous aperture field distributions. We then address several challenges
regarding the generation of Airy beams, including their exponential decay due
to finite energy constraints and spatial truncation of the aperture. Moreover,
we examine their free-space propagation characteristics. The second part of the
paper focuses on the propagation behavior of Airy beams in non-line-of-sight
(NLoS) scenarios. A comparison is also presented between Airy beams and
Gaussian beams. Our theoretical and numerical results show that Airy beams may
offer a performance advantage over Gaussian beams in certain NLoS channels,
provided that their key properties are largely preserved, specifically,
self-acceleration along a parabolic trajectory and diffraction-free
propagation. In the presence of an obstacle, this requires that the portion of
the transmit aperture with a clear line-of-sight to the receiver is
sufficiently large.

</details>


### [29] [Joint AP Selection and Power Allocation for Unicast-Multicast Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13771)
*Mustafa S. Abbas,Zahra Mobini,Hien Quoc Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文研究了支持单播和多播传输的无蜂窝大规模MIMO系统，推导了频谱效率的闭式表达式，提出了基于加速投影梯度的联合AP选择和功率分配优化算法，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着物联网等无线系统的发展，联合单播和多播传输变得越来越重要。现有研究缺乏对无蜂窝大规模MIMO系统中同时支持这两种传输类型的优化方案。

Method: 推导了零迫近和最大比预编码下的频谱效率闭式表达式，将非凸优化问题重构为可处理形式，开发了基于加速投影梯度的算法和基于逐次凸近似的基准算法。

Result: 仿真结果表明，所提出的联合优化方法在各种系统设置和预编码策略下显著提升了加权和频谱效率，APG算法在保持竞争力的同时大幅降低了复杂度。

Conclusion: 该研究为大规模实际部署提供了高效的联合优化方案，APG算法特别适合大规模系统，在性能和复杂度之间取得了良好平衡。

Abstract: Joint unicast and multicast transmissions are becoming increasingly important
in practical wireless systems, such as Internet of Things networks. This paper
investigates a cell-free massive multiple-input multiple-output system that
simultaneously supports both transmission types, with multicast serving
multiple groups. Exact closed-form expressions for the achievable downlink
spectral efficiency (SE) of both unicast and multicast users are derived for
zero-forcing and maximum ratio precoding designs. Accordingly, a weighted sum
SE (SSE) maximization problem is formulated to jointly optimize the access
point (AP) selection and power allocation. The optimization framework accounts
for practical constraints, including the maximum transmit power per AP,
fronthaul capacity limitations between APs and the central processing unit, and
quality-of-service requirements for all users. The resulting non-convex
optimization problem is reformulated into a tractable structure, and an
accelerated projected gradient (APG)-based algorithm is developed to
efficiently obtain near-optimal solutions. As a performance benchmark, a
successive convex approximation (SCA)-based algorithm is also implemented.
Simulation results demonstrate that the proposed joint optimization approach
significantly enhances the SSE across various system setups and precoding
strategies. In particular, the APG-based algorithm achieves substantial
complexity reduction while maintaining competitive performance, making it
well-suited for large-scale practical deployments.

</details>


### [30] [Robust Optimization for Movable Antenna-aided Cell-Free ISAC with Time Synchronization Errors](https://arxiv.org/abs/2508.13818)
*Yue Xiu,Yang Zhao,Ran Yang,Wanting Lyu,Dusit Niyato,Dong In Kim,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 提出基于可移动天线的CF-ISAC架构，利用空间分集增强通信速率、保持感知精度并减少时间同步误差的影响，通过流形优化和元强化学习算法实现鲁棒优化。


<details>
  <summary>Details</summary>
Motivation: 无细胞集成感知与通信系统在6G网络中具有广阔前景，但现有同步技术限制导致时间同步误差成为重要挑战，需要解决这一问题以充分发挥系统潜力。

Method: 提出MA辅助的CF-ISAC架构，建立最坏情况感知精度优化问题，推导CRLB下界，采用流形优化解决感知精度问题，并提出MA-MetaRL算法联合优化波束成形和天线位置。

Result: 仿真结果表明所提鲁棒优化算法显著提高检测精度，对时间同步误差具有强鲁棒性，相比传统固定天线技术获得更高系统容量。

Conclusion: 基于可移动天线的CF-ISAC架构能有效提升系统性能，验证了其在应对时间同步误差挑战方面的有效性，为6G网络发展提供了有前景的技术方案。

Abstract: The cell-free integrated sensing and communication (CF-ISAC) system, which
effectively mitigates intra-cell interference and provides precise sensing
accuracy, is a promising technology for future 6G networks. However, to fully
capitalize on the potential of CF-ISAC, accurate time synchronization (TS)
between access points (APs) is critical. Due to the limitations of current
synchronization technologies, TS errors have become a significant challenge in
the development of the CF-ISAC system. In this paper, we propose a novel
CF-ISAC architecture based on movable antennas (MAs), which exploits spatial
diversity to enhance communication rates, maintain sensing accuracy, and reduce
the impact of TS errors. We formulate a worst-case sensing accuracy
optimization problem for TS errors to address this challenge, deriving the
worst-case Cram\'er-Rao lower bound (CRLB). Subsequently, we develop a joint
optimization framework for AP beamforming and MA positions to satisfy
communication rate constraints while improving sensing accuracy. A robust
optimization framework is designed for the highly complex and non-convex
problem. Specifically, we employ manifold optimization (MO) to solve the
worst-case sensing accuracy optimization problem. Then, we propose an
MA-enabled meta-reinforcement learning (MA-MetaRL) to design optimization
variables while satisfying constraints on MA positions, communication rate, and
transmit power, thereby improving sensing accuracy. The simulation results
demonstrate that the proposed robust optimization algorithm significantly
improves the accuracy of the detection and is strong against TS errors.
Moreover, compared to conventional fixed position antenna (FPA) technologies,
the proposed MA-aided CF-ISAC architecture achieves higher system capacity,
thus validating its effectiveness.

</details>


### [31] [Distributed Distortion-Aware Robust Optimization for Movable Antenna-aided Cell-Free ISAC Systems](https://arxiv.org/abs/2508.13839)
*Yue Xiu,Yang Zhao,Ran Yang,Zheng Dong,Wanting Lyu,Zeyuan Zhang,Dusit Niyato,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 提出了一种基于可移动天线的无蜂窝集成感知通信系统，通过分布式失真感知鲁棒优化框架和SACGNN算法，有效缓解功率放大器非线性失真对通信和感知性能的影响


<details>
  <summary>Details</summary>
Motivation: 6G无蜂窝集成感知通信架构面临功率放大器非线性失真的严重挑战，这种硬件损伤会同时降低通信和感知性能，需要新的解决方案来提升系统鲁棒性

Method: 采用三阶无记忆多项式建模功率放大器非线性，构建分布式失真感知最坏情况鲁棒优化框架，结合逐次凸逼近估计失真系数，并开发MA-enabled自注意力卷积图神经网络算法联合优化波束成形和天线位置

Result: 仿真结果表明该方法在失真条件下显著改善了通信-感知权衡，在鲁棒性和容量方面优于固定位置天线基线

Conclusion: 可移动天线辅助的无蜂窝集成感知通信系统具有明显优势，能够有效应对硬件损伤带来的挑战，为6G系统部署提供了可行的解决方案

Abstract: The cell-free integrated sensing and communication (CF-ISAC) architecture is
a promising enabler for 6G, offering spectrum efficiency and ubiquitous
coverage. However, real deployments suffer from hardware impairments,
especially nonlinear distortion from power amplifiers (PAs), which degrades
both communication and sensing. To address this, we propose a movable antenna
(MA)-aided CF-ISAC system that mitigates distortion and enhances robustness.
The PAs nonlinearities are modeled by a third-order memoryless polynomial,
where the third-order distortion coefficients (3RDCs) vary across access points
(APs) due to hardware differences, aging, and environmental conditions. We
design a distributed distortion-aware worst-case robust optimization framework
that explicitly incorporates uncertainty in 3RDCs. First, we analyze the
worst-case impact of PA distortion on both the Cramer-Rao lower bound (CRLB)
and communication rate. Then, to address the resulting non-convexity, we apply
successive convex approximation (SCA) for estimating the 3RDCs. With these, we
jointly optimize beamforming and MA positions under transmit power and sensing
constraints. To efficiently solve this highly non-convex problem, we develop an
MA-enabled self-attention convolutional graph neural network (SACGNN)
algorithm. Simulations demonstrate that our method substantially enhances the
communication-sensing trade-off under distortion and outperforms fixed-position
antenna baselines in terms of robustness and capacity, thereby highlighting the
advantages of MA-aided CF-ISAC systems.

</details>


### [32] [Evaluating Particle Filtering for RSS-Based Target Localization under Varying Noise Levels and Sensor Geometries](https://arxiv.org/abs/2508.13937)
*Halim Lee,Jongmin Park,Kwansik Park*

Main category: eess.SP

TL;DR: 这篇论文系统性分析了基于粒子滤波的RSS目标定位算法，在不同传感器配置和噪声条件下较传统三角测量方法提高了定位精度


<details>
  <summary>Details</summary>
Motivation: RSS测量在目标定位中具有成本低、功耗小、部署简单的优势，但粒子滤波在不同传感器布局和噪声条件下的性能缺乏系统研究

Method: 设计和评估了一种用于静止目标定位的粒子滤波算法，与传统RSS三角测量方法在不同传感器配置和噪声条件下进行对比

Result: 模拟结果显示，粒子滤波比三角测量方法提供更准确的目标定位，尤其在传感器布局不利和高RSS噪声场景下优势更为明显

Conclusion: 粒子滤波算法在RSS基础的目标定位任务中表现优异，特别适用于具有挑战性的环境条件，为实际应用提供了更可靠的定位解决方案

Abstract: Target localization is a critical task in various applications, such as
search and rescue, surveillance, and wireless sensor networks. When a target
emits a radio frequency (RF) signal, spatially distributed sensors can collect
signal measurements to estimate the target's location. Among various
measurement modalities, received signal strength (RSS) is particularly
attractive due to its low cost, low power consumption, and ease of deployment.
While particle filtering has previously been applied to RSS-based target
localization, few studies have systematically analyzed its performance under
varying sensor geometries and RSS noise levels. This paper addresses this gap
by designing and evaluating a particle filtering algorithm for localizing a
stationary target. The proposed method is compared with a conventional
RSS-based trilateration approach across different sensor configurations and
noise conditions. Simulation results indicate that particle filtering provides
more accurate target localization than trilateration, particularly in scenarios
with unfavorable sensor geometries and high RSS noise.

</details>
