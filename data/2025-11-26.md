<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 14]
- [eess.SP](#eess.SP) [Total: 17]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [The Quality of Information: A Weighted Entropy Approach to Near-Optimal Mastermind](https://arxiv.org/abs/2511.19446)
*Serkan Gür*

Main category: cs.IT

TL;DR: 本文提出了一种基于加权熵启发式的Mastermind游戏求解方法，通过遗传算法优化权重模式，实现了接近理论最优的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统的Mastermind游戏求解方法在性能上存在局限，需要开发更有效的信息理论策略来接近理论最优解。

Method: 应用基于Belis-Guias框架的加权熵启发式，为每种可能的反馈类型分配上下文相关的效用值，并使用遗传算法优化权重模式。

Result: 固定权重向量实现平均4.3565次猜测（最多5次），阶段加权启发式达到平均4.3488次猜测（最多6次），接近4.3403的理论最优值。

Conclusion: 该方法在保持经典一步前瞻启发式计算效率的同时，通过原则性的信息估值显著提升了性能，接近理论最优解。

Abstract: This paper presents a novel class of information-theoretic strategies for solving the game of Mastermind, achieving state-of-the-art performance among known heuristic methods. The core contribution is the application of a weighted entropy heuristic, based on the Belis-Guias, u framework, which assigns context-dependent utility values to each of the possible feedback types. A genetic algorithm optimization approach discovers interpretable weight patterns that reflect strategic game dynamics. First, I demonstrate that a single, fixed vector of optimized weights achieves a remarkable 4.3565 average guesses with a maximum of 5. Building upon this, I introduce a stage-weighted heuristic with distinct utility vectors for each turn, achieving 4.3488 average guesses with a maximum of 6, approaching the theoretical optimum of 4.3403 by less than 0.2%. The method retains the computational efficiency of classical one-step-ahead heuristics while significantly improving performance through principled information valuation. A complete implementation and all optimized parameters are provided for full reproducibility.

</details>


### [2] [The Semiotic Channel Principle: Measuring the Capacity for Meaning in LLM Communication](https://arxiv.org/abs/2511.19550)
*Davide Picca*

Main category: cs.IT

TL;DR: 提出了一个分析大型语言模型（LLMs）的符号学框架，将LLMs概念化为随机符号引擎，其输出需要人类进行主动、不对称的解读。通过信息论工具形式化表达丰富性（符号广度）与解读稳定性（可解读性）之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有分析往往关注模型内部机制，而本文转向关注可观察的文本产物，为理解、评估和设计LLM介导的通信提供严谨且可操作的工具包。

Method: 引入生成复杂度参数λ来建模广度与可解读性之间的权衡，定义符号通道并设定意义传输的容量约束，操作上定义为通过优化λ实现的最大可解读性。

Result: 展示了该框架在四个关键应用中的实用性：模型分析、提示/上下文设计优化、基于模糊性的风险分析以及自适应符号系统。

Conclusion: 这种基于容量的符号学方法为理解、评估和设计LLM介导的通信提供了严谨且可操作的工具包。

Abstract: This paper proposes a novel semiotic framework for analyzing Large Language Models (LLMs), conceptualizing them as stochastic semiotic engines whose outputs demand active, asymmetric human interpretation. We formalize the trade-off between expressive richness (semiotic breadth) and interpretive stability (decipherability) using information-theoretic tools. Breadth is quantified as source entropy, and decipherability as the mutual information between messages and human interpretations. We introduce a generative complexity parameter (lambda) that governs this trade-off, as both breadth and decipherability are functions of lambda. The core trade-off is modeled as an emergent property of their distinct responses to $λ$. We define a semiotic channel, parameterized by audience and context, and posit a capacity constraint on meaning transmission, operationally defined as the maximum decipherability by optimizing lambda. This reframing shifts analysis from opaque model internals to observable textual artifacts, enabling empirical measurement of breadth and decipherability. We demonstrate the framework's utility across four key applications: (i) model profiling; (ii) optimizing prompt/context design; (iii) risk analysis based on ambiguity; and (iv) adaptive semiotic systems. We conclude that this capacity-based semiotic approach offers a rigorous, actionable toolkit for understanding, evaluating, and designing LLM-mediated communication.

</details>


### [3] [One-Shot Coding and Applications](https://arxiv.org/abs/2511.19556)
*Yanxiao Liu*

Main category: cs.IT

TL;DR: 本文扩展了泊松函数表示法的应用范围，使其能处理更复杂的信息论场景，这些场景原本无法直接应用该方法。


<details>
  <summary>Details</summary>
Motivation: 研究单次信息论中的可实现性部分，旨在推导出能够涵盖现有渐近结果的单次可实现性结果。

Method: 扩展泊松函数表示法，开发适用于复杂场景的改进版本。

Result: 成功将泊松函数表示法应用于更多复杂的信息论问题。

Conclusion: 泊松函数表示法可以扩展到更复杂的信息论场景，为单次信息理论提供统一的编码方案。

Abstract: One-shot information theory addresses scenarios in source coding and channel coding where the signal blocklength is assumed to be 1. In this case, each source and channel can be used only once, and the sources and channels are arbitrary and not required to be memoryless or ergodic. We study the achievability part of one-shot information theory, i.e., we consider explicit coding schemes in the oneshot scenario. The objective is to derive one-shot achievability results that can imply existing (first-order and second-order) asymptotic results when applied to memoryless sources and channels, or applied to systems with memory that behave ergodically.
  Poisson functional representation was first proposed as a one-shot channel simulation technique by Li and El Gamal [118] for proving a strong functional representation lemma. It was later extended to the Poisson matching lemma by Li and Anantharam [117], which provided a unified one-shot coding scheme for a broad class of information-theoretic problems. The main contribution of this thesis is to extend the applicability of Poisson functional representation to various more complicated scenarios, where the original version cannot be applied directly and further extensions must be developed.

</details>


### [4] [A Hybrid Dominant-Interferer Approximation for SINR Coverage in Poisson Cellular Networks](https://arxiv.org/abs/2511.19568)
*Sunder Ram Krishnan,Junaid Farooq,Kumar Vijay Mishra,Xingchen Liu,S. Unnikrishna Pillai,Theodore S. Rappaport*

Main category: cs.IT

TL;DR: 提出了一种混合近似框架，结合蒙特卡洛采样和拉普拉斯函数表示，用于改进蜂窝网络中的无线电传播和干扰建模。


<details>
  <summary>Details</summary>
Motivation: 随机几何和概率干扰模型在蜂窝网络建模中存在局限性：随机几何涉及复杂积分和特殊函数，概率模型仅适用于有限参数选择且表达式复杂。

Method: 结合蒙特卡洛采样主导干扰源和拉普拉斯函数表示残余远场干扰，形成主导加尾部的模块化结构。

Result: 该方法提供了数值稳定、路径损耗无关的估计器，适用于噪声受限和干扰受限场景，并推导了理论误差界限。

Conclusion: 所提出的混合框架在随机几何和概率建模基准测试中表现良好，为蜂窝网络干扰建模提供了更实用的解决方案。

Abstract: Accurate radio propagation and interference modeling is essential for the design and analysis of modern cellular networks. Stochastic geometry offers a rigorous framework by treating base station locations as a Poisson point process and enabling coverage characterization through spatial averaging, but its expressions often involve nested integrals and special functions that limit general applicability. Probabilistic interference models seek closed-form characterizations through moment-based approximations, yet these expressions remain tractable only for restricted parameter choices and become unwieldy when interference moments lack closed-form representations. This work introduces a hybrid approximation framework that addresses these challenges by combining Monte Carlo sampling of a small set of dominant interferers with a Laplace functional representation of the residual far-field interference. The resulting dominant-plus-tail structure provides a modular, numerically stable, and path-loss-agnostic estimator suitable for both noise-limited and interference-limited regimes. We further derive theoretical error bounds that decrease with the number of dominant interferers and validate the approach against established stochastic geometry and probabilistic modeling benchmarks.

</details>


### [5] [Computer-aided Characterization of Fundamental Limits of Coded Caching with Linear Coding](https://arxiv.org/abs/2511.19639)
*Niccolò Brembilla,Yinbin Ma,Pietro Belotti,Federico Malucelli,Daniela Tuninetti*

Main category: cs.IT

TL;DR: 本文提出了一个高效的计算机辅助框架，用于在线性编码约束下表征编码缓存系统的基本极限。该框架考虑了对可表示多拟阵有效的非香农型不等式，并利用编码缓存的对称结构和问题特定约束来降低线性规划的复杂度。


<details>
  <summary>Details</summary>
Motivation: 受Tian以及Cao和Xu先前工作的启发，本文旨在在线性编码约束下更精确地表征编码缓存系统的基本性能极限，特别是通过考虑非香农型不等式来获得更紧的逆界。

Method: 提出一个计算机辅助框架，考虑对可表示多拟阵有效的非香农型不等式，利用编码缓存的对称结构和问题特定约束来降低线性规划复杂度，从而推导更紧的逆界。

Result: 推导的逆界比先前已知的解析方法更紧，并证明了在线性编码放置和传输约束下某些可实现内存-负载权衡点的最优性。

Conclusion: 结果表明，结合最小公共信息构造的小型结构化需求子集可能足以在线性编码下表征最优权衡关系。

Abstract: Inspired by prior work by Tian and by Cao and Xu, this paper presents an efficient computer-aided framework to characterize the fundamental limits of coded caching systems under the constraint of linear coding. The proposed framework considers non-Shannon-type inequalities which are valid for representable polymatroids (and hence for linear codes), and leverages symmetric structure and problem-specific constraints of coded caching to reduce the complexity of the linear program. The derived converse bounds are tighter compared to previous known analytic methods, and prove the optimality of some achievable memory-load tradeoff points under the constraint of linear coding placement and delivery. These results seem to indicate that small, structured demand subsets combined with minimal common information constructions may be sufficient to characterize optimal tradeoffs under linear coding.

</details>


### [6] [Joint Satellite Power Consumption and Handover Optimization for LEO Constellations](https://arxiv.org/abs/2511.19745)
*Yassine Afif,Mohammed Almekhlafi,Antoine Lesage-Landry,Gunes Karabulut Kurt*

Main category: cs.IT

TL;DR: 本文提出了一种LEO卫星通信系统中考虑切换频率的功率分配优化方法，通过联合优化发射功率、用户-卫星关联和切换惩罚，在保证用户吞吐量的同时控制切换频率。


<details>
  <summary>Details</summary>
Motivation: LEO卫星通信系统中频繁的切换会导致额外的信令开销和功耗，随着星座规模增大，这成为显著负担。需要优化传输速率同时控制切换频率。

Method: 将功率分配问题建模为混合整数凹线性规划(MICP)，联合考虑总发射功率、用户-卫星关联和切换惩罚，使用现成求解器求解。

Result: 蒙特卡洛仿真表明，该方法能有效控制切换频率同时保持高用户吞吐量，用户速率提升约40%且切换频率不会不成比例增加。

Conclusion: 所提出的切换感知优化策略在显著提升用户速率的同时有效控制了切换频率，证明了该方法的有效性。

Abstract: In satellite constellation-based communication systems, continuous user coverage requires frequent handoffs due to the dynamic topology induced by the Low Earth Orbit (LEO) satellites. Each handoff between a satellite and ground users introduces additional signaling and power consumption, which can become a significant burden as the size of the constellation continues to increase. This work focuses on the optimization of the total transmission rate in a LEO-to-user system, by jointly considering the total transmitted power, user-satellite associations, and power consumption, the latter being handled through a penalty on handoff events. We consider a system where LEO satellites serve users located in remote areas with no terrestrial connectivity, and formulate the power allocation problem as a mixed-integer concave linear program (MICP) subject to power and association constraints. Our approach can be solved with off-the-shelf solvers and is benchmarked against a naive baseline where users associate to their closest visible satellite. Extensive Monte Carlo simulations demonstrate the effectiveness of the proposed method in controlling the handoff frequency while maintaining high user throughput. These performance gains highlight the effectiveness of our handover-aware optimization strategy, which ensures that user rates improve significantly, by about 40%, without incurring a disproportionate rise in the handoff frequency.

</details>


### [7] [Two-Step Decoding of Binary $2\times2$ Sum-Rank-Metric Codes](https://arxiv.org/abs/2511.19812)
*Hao Wu,Bocong Chen,Guanghui Zhang,Hongwei Liu*

Main category: cs.IT

TL;DR: 本文解决了Chen-Cheng-Qi提出的开放问题，证明二元和秩度量码的解码可以完全简化为对组成汉明度量码的解码，无需额外的距离条件限制。


<details>
  <summary>Details</summary>
Motivation: 解决Chen-Cheng-Qi在2025年提出的开放问题：是否可以将二元和秩度量码的解码完全简化为对组成汉明度量码的解码，而不需要额外的距离条件$d_1\ge\tfrac{2}{3}d_{\mathrm{sr}}$。

Method: 提出了一个简单的两步解码过程：首先唯一解码$C_2$，然后对$C_1$应用单次错误/擦除解码。

Result: 证明限制性假设$d_1\ge\tfrac{2}{3}d_{\mathrm{sr}}$在理论上是不必要的，解码器能够实现唯一解码达到$\lfloor (d_{\mathrm{sr}}-1)/2\rfloor$，总体复杂度为$T_2+T_1$。

Conclusion: 这种简化在黑板模型中是最优的，任何和秩解码器都必须固有地解码组成汉明码。对于在$\F_4$上的BCH或Goppa实例化，解码器在$O(\ell^2)$时间内运行。

Abstract: We resolve an open problem posed by Chen--Cheng--Qi (IEEE Trans.\ Inf.\ Theory, 2025): can decoding of binary sum-rank-metric codes $\SR(C_1,C_2)$ with $2\times2$ matrix blocks be reduced entirely to decoding the constituent Hamming-metric codes $C_1$ and $C_2$ without the additional requirement $d_1\ge\tfrac{2}{3}d_{\mathrm{sr}}$ that underlies their fast decoder? We answer this in the affirmative by exhibiting a simple two-step procedure: first uniquely decode $C_2$, then apply a single error/erasure decoding of $C_1$.This shows that the restrictive hypothesis $d_1\ge\tfrac{2}{3}d_{\mathrm{sr}}$ is theoretically unnecessary.The resulting decoder achieves unique decoding up to $\lfloor (d_{\mathrm{sr}}-1)/2\rfloor$ with overall cost $T_2+T_1$, where $T_2$ and $T_1$ are the complexities of the Hamming decoders for $C_2$ and $C_1$, respectively. We further show that this reduction is asymptotically optimal in a black-box model, as any sum-rank decoder must inherently decode the constituent Hamming codes.For BCH or Goppa instantiations over $\F_4$, the decoder runs in $O(\ell^2)$ time.

</details>


### [8] [Towards Edge General Intelligence: Knowledge Distillation for Mobile Agentic AI](https://arxiv.org/abs/2511.19947)
*Yuxuan Wu,Linghan Ma,Ruichen Zhang,Yinqiu Liu,Dusit Niyato,Shunpu Tang,Zehui Xiong,Zhu Han,Zhaohui Yang,Kaibin Huang,Zhaoyang Zhang,Kai-Kit Wong*

Main category: cs.IT

TL;DR: 该调查探讨了知识蒸馏(KD)在边缘通用智能(EGI)中的应用，KD作为在资源受限的边缘设备上部署智能代理的关键使能技术，特别关注无线通信和移动网络中的KD技术。


<details>
  <summary>Details</summary>
Motivation: 在移动边缘计算中部署智能代理面临计算、能源和存储资源有限的挑战，需要高效的技术来支持动态、资源受限环境中的自主智能操作。

Method: 调查了专门为无线通信设计的KD技术，包括信道感知自蒸馏、跨模型CSI反馈蒸馏和鲁棒调制/分类蒸馏，以及适合边缘部署的新型架构如Mamba、RWKV和跨架构蒸馏。

Result: KD驱动的架构能够在视觉、语音和多模态任务中实现EGI，增强了边缘设备的泛化能力。

Conclusion: 该调查为研究人员在EGI时代探索KD驱动的移动代理AI框架提供了全面参考，并指出了KD在EGI中的关键挑战和未来方向。

Abstract: Edge General Intelligence (EGI) represents a paradigm shift in mobile edge computing, where intelligent agents operate autonomously in dynamic, resource-constrained environments. However, the deployment of advanced agentic AI models on mobile and edge devices faces significant challenges due to limited computation, energy, and storage resources. To address these constraints, this survey investigates the integration of Knowledge Distillation (KD) into EGI, positioning KD as a key enabler for efficient, communication-aware, and scalable intelligence at the wireless edge. In particular, we emphasize KD techniques specifically designed for wireless communication and mobile networking, such as channel-aware self-distillation, cross-model Channel State Information (CSI) feedback distillation, and robust modulation/classification distillation. Furthermore, we review novel architectures natively suited for KD and edge deployment, such as Mamba, RWKV (Receptance, Weight, Key, Value) and Cross-Architecture distillation, which enhance generalization capabilities. Subsequently, we examine diverse applications in which KD-driven architectures enable EGI across vision, speech, and multimodal tasks. Finally, we highlight the key challenges and future directions for KD in EGI. This survey aims to provide a comprehensive reference for researchers exploring KD-driven frameworks for mobile agentic AI in the era of EGI.

</details>


### [9] [Explainable Deep Learning for Secrecy Energy-Efficiency Maximization in Ambient Backscatter Multi-User NOMA Systems](https://arxiv.org/abs/2511.20108)
*Miled Alam,Abdul Karim Gizzini,Laurent Clavier*

Main category: cs.IT

TL;DR: 本文研究了多用户下行NOMA系统中，在存在被动窃听者的情况下，多个环境反向散射通信辅助的保密能效优化问题。


<details>
  <summary>Details</summary>
Motivation: 研究NOMA系统在环境反向散射通信辅助下的保密能效，解决在存在窃听者情况下的安全通信和能效平衡问题。

Method: 对于两个反向散射设备的情况推导闭式解；对于更多设备提出网格搜索基准方法和粒子群优化算法；设计前馈神经网络预测器近似最优解。

Result: AmBC显著提升保密能效，在高噪声环境下相比传统NOMA提升达615%；FNN模型达到95%以上准确率且降低复杂度；SHAP分析显示主导复合信道特征最具影响力。

Conclusion: 可解释人工智能在构建可信赖的能效安全AmBC-NOMA系统方面具有潜力，适用于下一代物联网应用。

Abstract: In this paper, we investigate the secrecy energy-efficiency (SEE) of a multi-user downlink non-orthogonal multiple access (NOMA) system assisted by multiple ambient backscatter communications (AmBC) in the presence of a passive eavesdropper. We analyze both the trade-off and the ratio between the achievable secrecy sum-rate and total power consumption. In the special case of two backscatter devices (BDs), we derive closed-form solutions for the optimal reflection coefficients and power allocation by exploiting the structure of the SEE objective and the Pareto boundary of the feasible set. When more than two BDs are present, the problem becomes analytically intractable. To address this, we propose two efficient optimization techniques: (i) an exhaustive grid-based benchmark method, and (ii) a scalable particle swarm optimization algorithm. Furthermore, we design a deep learning-based predictor using a feedforward neural network (FNN), which closely approximates the optimal solutions. Numerical results show that the inclusion of AmBC significantly improves SEE, with gains up to 615% compared to conventional NOMA in high-noise regimes. Additionally, the FNN model achieves more than 95% accuracy compared to the optimal baseline, while reducing complexity. Finally, we employ SHAP (SHapley Additive exPlanations) to interpret the learned model, revealing that the most influential features correspond to the dominant composite channel components, in accordance with the theoretical system model. This demonstrates the potential of explainable artificial intelligence to build trust in energy-efficient and secure AmBC-NOMA systems for next-generation internet of things applications.

</details>


### [10] [On hierarchical secure aggregation against relay and user collusion](https://arxiv.org/abs/2511.20117)
*Min Xu,Xuejiao Han,Kai Wan,Gennian Ge*

Main category: cs.IT

TL;DR: 该论文研究了同质网络中的分层安全聚合（HSA），针对中继和用户共谋的情况，建立了通信负载的基本限制，并设计了通信最优的聚合方案。


<details>
  <summary>Details</summary>
Motivation: 安全聚合是联邦学习中保护隐私的基础技术，但现有方法在分层网络结构中面临中继和用户共谋的安全威胁，需要设计更安全高效的聚合方案。

Method: 采用两阶段通信框架：用户向中继发送掩码数据，中继处理并转发编译消息给服务器进行精确求和恢复。使用网络函数计算方法构建通信最优方案。

Result: 建立了通信负载的基本限制，推导了共谋弹性的可达阈值，在共谋中继和用户数量低于临界阈值时构建了通信最优方案，并证明了循环网络中所需密钥大小的下界可达性。

Conclusion: 通过建立HSA与网络函数计算之间的联系，推进了安全聚合在通信效率和信息论安全性方面的理论极限。

Abstract: Secure aggregation (SA) is fundamental to privacy preservation in federated learning (FL), enabling model aggregation while preventing disclosure of individual user updates. This paper addresses hierarchical secure aggregation (HSA) against relay and user collusion in homogeneous networks, where each user connects to $n$ relays and each relay serves $m$ users. In the two-phase communication framework, users transmit masked data to relays, which then process and forward compiled messages to the server for exact sum recovery. The primary objective is to devise a transmission scheme such that the server can finish the aggregation task, while any group of $T_h$ colluding relays and $T_u$ colluding users cannot reveal any information about the data owned by the non-colluding users. In this study, we establish fundamental limits on the communication load, defined as the ratio of transmitted information size to original data size, for each user-relay link and each relay-server link. Achievable thresholds for collusion resilience are also derived. When the number of colluding relays and users falls below certain critical thresholds, we construct communication-optimal schemes using methods from network function computation. A limitation of these schemes is their reliance on large random keys. To address this, we derive a lower bound on the required key size and prove its achievability in cyclic networks, where users are connected to relays in a cyclic wrap-around manner. By establishing a connection between HSA and network function computation, this work advances the theoretical limits of communication efficiency and information-theoretic security in secure aggregation.

</details>


### [11] [General Multi-User Distributed Computing](https://arxiv.org/abs/2511.20127)
*Ali Khalesi*

Main category: cs.IT

TL;DR: 提出了一个统一的学习和信息理论框架GMUDC，用于多用户分布式计算和推理，通过联合优化计算、通信和精度来满足异构目标函数需求。


<details>
  <summary>Details</summary>
Motivation: 解决分布式系统中用户需求异构目标函数时的计算、通信和精度联合优化问题，特别是在航空、卫星和边缘智能网络等对能效和数据效率要求严格的场景。

Method: 引入GMUDC模型，采用对偶分析：淬火设计考虑固定子函数分配和网络拓扑，退火设计捕获从给定集合中均匀随机抽取分配和链接时的平均性能。

Result: 建立了计算负载、通信负载和重构失真之间的基本权衡关系，揭示了泛化能力与网络拓扑和资源分配之间的谱覆盖对偶性。

Conclusion: 该框架为可扩展和资源最优的分布式和联邦学习系统提供了信息-能量基础，在能效和数据效率至关重要的场景中具有直接应用价值。

Abstract: This work develops a unified {learning- and information-theoretic} framework for distributed computation and inference across multiple users and servers. The proposed \emph{General Multi-User Distributed Computing (GMUDC)} model characterizes how computation, communication, and accuracy can be jointly optimized when users demand heterogeneous target functions that are arbitrary transformations of shared real-valued subfunctions. Without any separability assumption, and requiring only that each target function lies in a reproducing-kernel Hilbert space associated with a shift-invariant kernel, the framework remains valid for arbitrary connectivity and task-assignment topologies. A dual analysis is introduced: the \emph{quenched design} considers fixed assignments of subfunctions and network topology, while the \emph{annealed design} captures the averaged performance when assignments and links are drawn uniformly at random from a given ensemble. These formulations reveal the fundamental limits governing the trade-offs among computing load, communication load, and reconstruction distortion under computational and communication budgets~$Γ$ and~$Δ$. The analysis establishes a spectral-coverage duality linking generalization capability with network topology and resource allocation, leading to provably efficient and topology-aware distributed designs. The resulting principles provide an \emph{information-energy foundation} for scalable and resource-optimal distributed and federated learning systems, with direct applications to aeronautical, satellite, and edge-intelligent networks where energy and data efficiency are critical.

</details>


### [12] [CSI Prediction Frameworks for Enhanced 5G Link Adaptation: Performance-Complexity Trade-offs](https://arxiv.org/abs/2511.20160)
*Francisco Díaz-Ruiz,Francisco J. Martín-Vega,Jose A. Cortés,Gerardo Gómez,Mari Carmen Aguayo*

Main category: cs.IT

TL;DR: 本文提出并评估了两种适用于TDD和FDD系统的CSI预测框架，在有效SINR域进行操作以降低复杂度。比较了经典维纳滤波器和基于GRU、LSTM、DNN的深度学习框架，发现维纳滤波器在计算复杂度更低的情况下性能接近GRU，但GRU在不同信道场景下具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 信道状态信息(CSI)对于高效链路自适应至关重要，但信道老化、用户移动性和反馈延迟等挑战显著影响自适应调制编码(AMC)的性能。

Method: 提出了两种CSI预测框架，在有效SINR域进行操作以降低复杂度。比较了经典维纳滤波器和基于GRU、LSTM、DNN的深度学习框架，评估了预测精度(MSE)、系统性能和实现复杂度(FLOPs)。

Result: 仿真结果显示，维纳滤波器在MSE和吞吐量方面性能接近GRU，且计算复杂度更低，前提是信道的二阶统计特性可用。但GRU模型在不同信道场景下表现出更好的泛化能力。

Conclusion: 基于学习的解决方案更适合TDD系统（基站处理计算），而经典方法的低复杂度使其成为FDD设置的优选（预测在功率受限的用户设备进行）。

Abstract: Accurate and timely channel state information (CSI) is fundamental for efficient link adaptation. However, challenges such as channel aging, user mobility, and feedback delays significantly impact the performance of adaptive modulation and coding (AMC). This paper proposes and evaluates two CSI prediction frameworks applicable to both time division duplexing (TDD) and frequency division duplexing (FDD) systems. The proposed methods operate in the effective signal to interference plus noise ratio (SINR) domain to reduce complexity while preserving predictive accuracy. A comparative analysis is conducted between a classical Wiener filter and state-of-the-art deep learning frameworks based on gated recurrent units (GRUs), long short-term memory (LSTM) networks, and a delayed deep neural network (DNN). The evaluation considers the accuracy of the prediction in terms of mean squared error (MSE), the performance of the system, and the complexity of the implementation regarding floating point operations (FLOPs). Furthermore, we investigate the generalizability of both approaches under various propagation conditions. The simulation results show that the Wiener filter performs close to GRU in terms of MSE and throughput with lower computational complexity, provided that the second-order statistics of the channel are available. However, the GRU model exhibits enhanced generalization across different channel scenarios. These findings suggest that while learningbased solutions are well-suited for TDD systems where the base station (BS) handles the computation, the lower complexity of classical methods makes them a preferable choice for FDD setups, where prediction occurs at the power-constrained user equipment (UE).

</details>


### [13] [Unified Block Signal Processing Framework for LPWANs: Sequence Index Modulation Spreading](https://arxiv.org/abs/2511.20364)
*Wenkun Wen,Tierui Min,Long Yuan,Minghua Xia*

Main category: cs.IT

TL;DR: 提出了一个用于LPWAN的广义块信号传输统一框架，解决传统逐符号方法的局限性，支持准正交多用户分离和块同步，适用于FSK和CSS等应用。


<details>
  <summary>Details</summary>
Motivation: 低功耗广域网需要高接收灵敏度和高效物理层信号处理，传统逐符号方法存在局限性，需要更高效的传输框架。

Method: 构建包含信号块向量、块内结构生成器和信号基矩阵的统一框架，利用循环移位扩频序列形成准正交码字，支持块相关匹配解调。

Result: 实现了可靠的异步多用户分离，建立了块同步概念基础，为FSK和CSS提供了灵活系统化实现方案。

Conclusion: 该框架推进了下一代LPWAN的可扩展高效物理层设计，为块信号传输提供了统一理论基础。

Abstract: Low-power wide-area networks (LPWANs) demand high receiver sensitivity and efficient physical-layer signal processing. This paper introduces a unified framework for generalized block signal transmission in LPWANs, addressing the limitations of conventional symbol-by-symbol approaches. The framework comprises three key components: the signal block vector, the intra-block structure generator, and the signal basis matrix, and leverages quasi-orthogonal codewords formed through cyclically shifted spreading sequences. The resulting quasi-orthogonality enables reliable multi-user separation, particularly under asynchronous access. The framework establishes a conceptual foundation for block synchronization and provides a unified demodulation structure based on block correlation matching. It further supports flexible and systematic implementation, as demonstrated through applications to frequency-shift keying and chirp spread spectrum. This work advances scalable and efficient physical-layer design for next-generation LPWANs.

</details>


### [14] [Dimension-counting bounds for equi-isoclinic subspaces](https://arxiv.org/abs/2511.20642)
*Joseph W. Iverson,Kaysie Rose O*

Main category: cs.IT

TL;DR: 本文在最优子空间填充和等斜子空间理论中做出了四个贡献：新的块相干性下界、偶维等斜子空间精确计数、等斜子空间数量新上界，以及在特定维度下该上界可达性的证明。


<details>
  <summary>Details</summary>
Motivation: 研究最优子空间填充和等斜子空间的理论问题，旨在改进相关参数的下界和上界，并精确计数特定情况下的等斜子空间数量。

Method: 主要基于维度计数方法进行证明，通过数学分析推导各种界限和计数结果。

Result: 获得了块相干性的新下界、偶维等斜子空间的精确计数、等斜子空间数量的新上界，并证明了在特定维度下该上界在复数域对所有r可达，在实数域对r=2^k可达。

Conclusion: 维度计数方法在最优子空间填充和等斜子空间理论中具有重要作用，能够有效推导各种界限和精确计数结果，为相关理论研究提供了新的工具和视角。

Abstract: We make four contributions to the theory of optimal subspace packings and equi-isoclinic subspaces: (1) a new lower bound for block coherence, (2) an exact count of equi-isoclinic subspaces of even dimension $r$ in $\mathbb{R}^{2r+1}$ with parameter $α\neq \tfrac{1}{2}$, (3) a new upper bound for the number of $r$-dimensional equi-isoclinic subspaces in $\mathbb{R}^d$ or $\mathbb{C}^d$, and (4) a proof that when $d=2r$, a further refinement of this bound is attained for every $r$ in the complex case and every $r=2^k$ in the real case. For each of these contributions, the proof ultimately relies on a dimension count.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [15] [Latent-space metrics for Complex-Valued VAE out-of-distribution detection under radar clutter](https://arxiv.org/abs/2511.19805)
*Y. A. Rouzoumka,E. Terreaux,C. Morisseau,J. -P. Ovarlez,C. Ren*

Main category: eess.SP

TL;DR: 研究复杂值变分自编码器(CVAE)在复杂雷达环境中的离群分布检测，提出了多种检测指标并与经典检测器进行性能比较


<details>
  <summary>Details</summary>
Motivation: 在复杂雷达环境中进行离群分布检测，需要更有效的检测方法

Method: 使用复杂值变分自编码器，提出重构误差、基于潜在空间的马氏距离和KL散度等多种检测指标，并与ANMF-Tyler检测器进行对比

Result: 在合成和实验雷达数据上分析了所有检测器的性能，展示了各检测器的优势和弱点

Conclusion: 不同检测器在复杂雷达环境中的离群分布检测各有优缺点，需要根据具体场景选择合适的方法

Abstract: We investigate complex-valued Variational AutoEncoders (CVAE) for radar Out-Of-Distribution (OOD) detection in complex radar environments. We proposed several detection metrics: the reconstruction error of CVAE (CVAE-MSE), the latent-based scores (Mahalanobis, Kullback-Leibler divergence (KLD)), and compared their performance against the classical ANMF-Tyler detector (ANMF-FP). The performance of all these detectors is analyzed on synthetic and experimental radar data, showing the advantages and the weaknesses of each detector.

</details>


### [16] [White-Box Modeling of V2X Link Performance Using Stabilized Symbolic Regression](https://arxiv.org/abs/2511.19809)
*Rahul Gulia,Feyisayo Favour Popoola,Ashish Sheikh*

Main category: eess.SP

TL;DR: 提出一种稳定的符号回归框架，用于推导紧凑、可解析解释的块错误率预测表达式，在保持高精度的同时提供可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如深度神经网络）在车联网无线网络中预测块错误率时虽然精度高，但缺乏可解释性且计算成本大，限制了在实时资源受限环境中的应用。

Method: 使用稳定的符号回归框架，基于真实车联网仿真数据训练，捕捉关键系统参数的非线性依赖关系，包括信噪比、相对速度、调制编码方案等。

Result: 最终符号表达式仅包含158个节点，在测试集上达到决定系数R²=0.8684和均方误差2.08×10⁻²，优于传统固定形式回归，与神经网络精度相当但完全可解释。

Conclusion: 所提出的稳定符号回归框架结合了预测性能、物理保真度和计算效率，为实时车联网通信系统设计、自适应资源分配和快速场景评估提供了强大工具。

Abstract: Reliable modeling of block error rate in vehicle-to-everything wireless networks is critical for designing robust communication systems under dynamic mobility and diverse channel conditions. Traditional machine learning approaches, such as deep neural networks, achieve high predictive accuracy but lack interpretability and impose significant computational costs, limiting their applicability in real-time, resource-constrained environments. In this work, we propose a stabilized symbolic regression framework to derive compact, analytically interpretable expressions for block error rate prediction. Trained on realistic vehicle-to-everything simulation data, the symbolic regression framework for vehicle-to-everything model accurately captures nonlinear dependencies on key system parameters, including signal-to-noise ratio, relative velocity, modulation and coding schemes, number of demodulation reference signal symbols, and environmental factors (line of sight/non-line of sight). Our final symbolic expression comprises only 158 nodes, enabling ultra-fast inference suitable for embedded deployment. On the test set, the symbolic regression framework for vehicle-to-everything model achieves a coefficient of determination $R^2 = 0.8684$ and mean squared error $= 2.08 \times 10^{-2}$ in the original block error rate domain, outperforming conventional fixed-form regressions and offering comparable accuracy to neural networks while remaining fully interpretable. Overall, the proposed Stabilized Symbolic Regression Framework for V2X combines predictive performance, physical fidelity, and computational efficiency thus providing a powerful tool for real-time V2X communication system design, adaptive resource allocation, and rapid scenario evaluation.

</details>


### [17] [Parallel Delay-Doppler Estimation via Order-Reversed Two-Stage Prony Method](https://arxiv.org/abs/2511.19866)
*Yutaka Jitsumatsu,Liangchen Sun*

Main category: eess.SP

TL;DR: 提出基于Prony的并行两阶段方法用于OTFS系统中的延迟-多普勒估计，通过并行执行延迟优先和多普勒优先估计并融合结果，解决路径特征相似引起的模糊问题。


<details>
  <summary>Details</summary>
Motivation: 解决OTFS系统中由于路径特征相似导致的延迟-多普勒估计模糊问题，为V2V和ISAC等未来应用提供准确可靠的估计方法。

Method: 采用Prony-based并行两阶段方法，分别进行延迟优先估计和多普勒优先估计，然后将两个阶段的结果进行融合。

Result: 仿真结果表明该方法在各种条件下都具有优越的准确性和鲁棒性。

Conclusion: 该方法为V2V和ISAC等未来应用提供了有前景的解决方案。

Abstract: This paper proposes a Prony-based parallel two-stage method for delay-Doppler estimation in OTFS systems. By performing delay-first and Doppler-first estimations in parallel and fusing the results, the method resolves ambiguities caused by similar path characteristics. The simulation results demonstrate the superior accuracy and robustness of the proposed method under various conditions. This method provides a promising solution for future applications such as Vehicle-to-Vehicle (V2V) and Integrated Sensing and Communication (ISAC).

</details>


### [18] [Joint Classification and Regression Deep Learning Model for Universal Phase-based Ranging in Multiple Environments](https://arxiv.org/abs/2511.19891)
*Pantelis Stefanakis,Ming Shen*

Main category: eess.SP

TL;DR: 本研究提出了一种基于双神经网络(2NN)的相位测距方法，在开放场地、办公室和建筑附近三种环境中显著优于传统非神经网络方法，实现了最低的均方根误差和最大预测误差。


<details>
  <summary>Details</summary>
Motivation: 相位测距(PBR)具有高精度、无需天线阵列等优势，但需要适应不同环境。本研究旨在探索神经网络模型在不同环境中的准确测距性能，并与传统方法进行比较。

Method: 提出新颖的2NN模型，包含两个神经网络：一个用于环境分类，另一个用于距离预测。在三种不同环境中进行测试，并与非神经网络方法比较性能。

Result: 2NN模型在所有环境中表现最佳，经常在最小化均方根误差和最大误差方面排名第一。其过滤版本在所有数据集上实现了最低的均方根误差和最大误差。

Conclusion: 神经网络模型在不同环境中提供稳健、高精度的测距性能，优于非神经网络方法，当在全面距离数据集上训练时，具有作为通用PBR解决方案的潜力。

Abstract: Phase-Based Ranging (PBR) offers several advantages for estimating distances between wirelessly connected devices, including high accuracy over large distances and the removal of the need for antenna arrays at each transceiver. This study investigates the use of Neural Network (NN)-based models for accurate PBR in three distinct environments: Openfield, Office, and Near Buildings, comparing their performance with established non-NN methods. A novel 2NN Model is proposed, integrating two neural networks: one to classify the environment and another to predict distances. Performance was evaluated over 20 trials for each method and dataset using root mean square error (RMSE) and maximum prediction error.
  Results show that the 2NN Model consistently outperformed other methods, frequently ranking among the top methods in minimizing both RMSE and maximum error. In addition, the 2NN Model achieved the best average RMSE and the lowest maximum error. To assess the effect of environment misclassification, filtered versions of the NN models were evaluated by omitting misclassified measurements prior to RMSE calculation. Although unsuitable for production use, the filtered models revealed that misclassifications in the 2NN Model had a significant impact. Its filtered variant achieved the lowest RMSE and maximum error across all datasets, and ranked first in the frequency of attaining the lowest maximum error over 20 trials.
  Overall, the findings show that NN models deliver robust, high-accuracy ranging across diverse environments, outperforming non-NN methods and reinforcing their potential as universal PBR solutions when trained on comprehensive distance datasets.

</details>


### [19] [AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload](https://arxiv.org/abs/2511.19943)
*Akash Doshi,Pinar Sen,Kirill Ivanov,Wei Yang,June Namgoong,Runxin Wang,Rachel Wang,Taesang Yoo,Jing Jiang,Tingfang Ji*

Main category: eess.SP

TL;DR: 提出基于Transformer的联合源信道编码方案，利用HARQ-ACK比特的非均匀分布特性，通过功率整形和不等差错保护技术，在5G NR上行链路中实现显著的功率节省和覆盖增益。


<details>
  <summary>Details</summary>
Motivation: 传统信道编码假设物理层输入比特均匀分布，但HARQ-ACK比特实际上是非均匀分布的，这为联合源信道编码提供了优化空间。

Method: 使用Transformer编码器和"免费午餐"训练算法，结合每码字功率整形技术，并在解码器端采用扩展的Neyman-Pearson测试实现NACK比特的不等差错保护。

Result: 与5G NR基线相比，在达到目标误码率时平均发射功率降低3-6 dB，最大发射功率降低2-3 dB。

Conclusion: 所提出的联合源信道编码方案能够显著提升5G NR上行链路的功率效率和覆盖性能。

Abstract: Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed. However, hybrid automatic repeat request acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently non-uniformly distributed. For such sources, significant performance gains could be obtained by employing joint source channel coding, aided by deep learning-based techniques. In this paper, we learn a transformer-based encoder using a novel "free-lunch" training algorithm and propose per-codeword power shaping to exploit the source prior at the encoder whilst being robust to small changes in the HARQ-ACK distribution. Furthermore, any HARQ-ACK decoder has to achieve a low negative acknowledgement (NACK) error rate to avoid radio link failures resulting from multiple NACK errors. We develop an extension of the Neyman-Pearson test to a coded bit system with multiple information bits to achieve Unequal Error Protection of NACK over ACK bits at the decoder. Finally, we apply the proposed encoder and decoder designs to a 5G New Radio (NR) compliant uplink setup under a fading channel, describing the optimal receiver design and a low complexity coherent approximation to it. Our results demonstrate 3-6 dB reduction in the average transmit power required to achieve the target error rates compared to the NR baseline, while also achieving a 2-3 dB reduction in the maximum transmit power, thus providing for significant coverage gains and power savings.

</details>


### [20] [Cross-Modal Semantic Communication for Heterogeneous Collaborative Perception](https://arxiv.org/abs/2511.20000)
*Mingyi Lu,Guowei Liu,Le Liang,Chongtao Guo,Hao Ye,Shi Jin*

Main category: eess.SP

TL;DR: 提出跨模态语义通信(CMSC)框架，解决自动驾驶中不同传感器配置车辆间的协作感知问题，通过统一语义空间实现异构感知特征的有效融合。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的协作感知系统面临车辆间传感器异构性的挑战，这种多样性使得统一通信框架设计和信息有效融合变得困难。

Method: 将不同传感器模态的异构感知特征转换到统一的标准化语义空间，在该空间内进行编码、传输和解码，实现无缝有效的信息融合。

Result: 大量实验表明，CMSC在感知性能上显著优于现有方法，特别是在低信噪比(SNR)环境下表现更佳。

Conclusion: CMSC框架能够有效促进具有不同传感器配置的CAV之间的协作，提升协作感知系统的整体性能。

Abstract: Collaborative perception, an emerging paradigm in autonomous driving, has been introduced to mitigate the limitations of single-vehicle systems, such as limited sensor range and occlusion. To improve the robustness of inter-vehicle data sharing, semantic communication has recently further been integrated into collaborative perception systems to enhance overall performance. However, practical deployment of such systems is challenged by the heterogeneity of sensors across different connected autonomous vehicles (CAVs). This diversity in perceptual data complicates the design of a unified communication framework and impedes the effective fusion of shared information. To address this challenge, we propose a novel cross-modal semantic communication (CMSC) framework to facilitate effective collaboration among CAVs with disparate sensor configurations. Specifically, the framework first transforms heterogeneous perceptual features from different sensor modalities into a unified and standardized semantic space. Subsequently, encoding, transmission, and decoding are performed within this semantic space, enabling seamless and effective information fusion. Extensive experiments demonstrate that CMSC achieves significantly stronger perception performance than existing methods, particularly in low signal-to-noise ratio (SNR) regimes.

</details>


### [21] [Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds](https://arxiv.org/abs/2511.20003)
*Simin Zhu,Satish Ravindran,Alexander Yarovoy,Francesco Fioranelli*

Main category: eess.SP

TL;DR: 提出了一种基于神经网络的雷达点云分割方法，能够同时分割静态和动态物体，并估计移动平台的瞬时2D速度，无需复杂的预处理步骤。


<details>
  <summary>Details</summary>
Motivation: 传统雷达分割研究主要关注移动物体的类别标签，但雷达与光学传感器的根本差异使得类别预测的可靠性不同。在汽车雷达感知任务中，判断物体是静态还是动态是大多数任务的前提条件。

Method: 使用多层感知机(MLPs)和循环神经网络(RNNs)等简单有效的构建块进行特征提取，直接从原始点云中提取信息，无需点云聚合、多普勒补偿、运动补偿等中间信号处理步骤。

Result: 在RadarScenes真实世界雷达数据集上的测试结果表明，该方法在双任务上表现良好，并在其他雷达感知任务中具有广泛的应用潜力。

Conclusion: 该方法首次实现了直接从雷达点云同时分割静态/动态物体和估计平台速度的双任务，证明了无需复杂预处理即可提取所需信息的可行性。

Abstract: Conventional radar segmentation research has typically focused on learning category labels for different moving objects. Although fundamental differences between radar and optical sensors lead to differences in the reliability of predicting accurate and consistent category labels, a review of common radar perception tasks in automotive reveals that determining whether an object is moving or static is a prerequisite for most tasks. To fill this gap, this study proposes a neural network based solution that can simultaneously segment static and moving objects from radar point clouds. Furthermore, since the measured radial velocity of static objects is correlated with the motion of the radar, this approach can also estimate the instantaneous 2D velocity of the moving platform or vehicle (ego motion). However, despite performing dual tasks, the proposed method employs very simple yet effective building blocks for feature extraction: multi layer perceptrons (MLPs) and recurrent neural networks (RNNs). In addition to being the first of its kind in the literature, the proposed method also demonstrates the feasibility of extracting the information required for the dual task directly from unprocessed point clouds, without the need for cloud aggregation, Doppler compensation, motion compensation, or any other intermediate signal processing steps. To measure its performance, this study introduces a set of novel evaluation metrics and tests the proposed method using a challenging real world radar dataset, RadarScenes. The results show that the proposed method not only performs well on the dual tasks, but also has broad application potential in other radar perception tasks.

</details>


### [22] [Time-Domain Linear Model-based Framework for Passive Acoustic Mapping of Cavitation Activity](https://arxiv.org/abs/2511.20551)
*Tatiana Gelvez-Barrera,Barbara Nicolas,Denis Kouamé,Bruno Gilles,Adrian Basarab*

Main category: eess.SP

TL;DR: 提出了一种基于线性模型的时域波束形成框架，通过时空正则化技术提高被动声学映射的数据效率和空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统波束形成方法存在轴向分辨率有限、数据需求量大或空间分辨率低的问题，特别是在缺乏参考发射起始时间的情况下。

Method: 构建线性前向模型，将空化的时空分布与探头记录的时域信号相关联，考虑声波传播时间延迟，并使用时空正则化技术进行模型反演。

Result: 实验结果显示，该方法仅需频域方法20%的数据量即可获得相当或更好的空化图质量，显著提高了数据效率。

Conclusion: 该框架在数据效率和空化图质量方面优于现有技术，能够适应各种被动空化场景。

Abstract: Passive acoustic mapping enables the spatial mapping and temporal monitoring of cavitation activity, playing a crucial role in therapeutic ultrasound applications. Most conventional beamforming methods, whether implemented in the time or frequency domains, suffer from limited axial resolution due to the absence of a reference emission onset time. While frequency-domain methods, the most efficient of which are based on the cross-spectral matrix, require long signals for accurate estimation, time-domain methods typically achieve lower spatial resolution. To address these limitations, we propose a linear model-based beamforming framework fully formulated in the time domain. The linear forward model relates a discretized spatiotemporal distribution of cavitation activity to the temporal signals recorded by a probe, explicitly accounting for time-of-flight delays dictated by the acquisition geometry. This model is then inverted using regularization techniques that exploit prior knowledge of cavitation activity in both spatial and temporal domains. Experimental results show that the proposed framework achieves enhanced or competitive cavitation map quality while using only 20\% of the data typically required by frequency-domain methods. This highlights the substantial gain in data efficiency and the flexibility of our spatiotemporal regularization to adapt to diverse passive cavitation scenarios, outperforming state-of-the-art techniques.

</details>


### [23] [Sparse MIMO-OFDM Channel Estimation via RKHS Regularization](https://arxiv.org/abs/2511.20082)
*James Delfeld,Gian Marti,Chris Dick*

Main category: eess.SP

TL;DR: 提出了一种基于RKHS正则化优化的MIMO-OFDM信道估计方法，利用延迟波束空间的带稀疏性，通过FBS算法实现准线性计算复杂度，并引入深度展开扩展提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统线性信道估计方法在MIMO-OFDM系统中性能有限，需要利用信道在延迟波束空间的稀疏特性来提高估计精度和下游性能。

Method: 将无限维RKHS优化问题转化为有限维问题，使用FBS算法求解，并引入深度展开扩展来减少迭代次数。

Result: 在SionnaRT生成的射线追踪信道上测试，显著优于基于聚合信道统计的LMMSE方法，在原始估计精度和下游性能方面都有提升。

Conclusion: 该方法有效利用了信道稀疏性，实现了高性能的信道估计，且计算复杂度可控。

Abstract: We propose a method for channel estimation in multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) wireless communication systems. The method exploits the band-sparsity of wireless channels in the delay-beamspace domain by solving a regularized optimization problem in a reproducing kernel Hilbert space (RKHS). A suitable representer theorem allows us to transform the infinite-dimensional optimization problem into a finite-dimensional one, which we then approximate with a low-dimensional surrogate. We solve the resulting optimization problem using a forward-backward splitting (FBS)-based algorithm. By exploiting the problem's modulation structure, we achieve a computational complexity per iteration that is quasi-linear in the number of unknown variables. We also propose a data-driven deep-unfolding based extension to improve the performance at a reduced number of iterations. We evaluate our channel estimators on ray-traced channels generated with SionnaRT. The results show that our methods significantly outperform linear methods such as linear minimum mean squared error (LMMSE) channel estimation based on aggregate channel statistics, both in terms of raw estimation accuracy as well as in downstream performance.

</details>


### [24] [Joint Bit-Partitioning and Modulation Design for Digital AirComp](https://arxiv.org/abs/2511.20113)
*Xiaojing Yan,Carlo Fischione*

Main category: eess.SP

TL;DR: 该论文提出将比特分割过程集成到ChannelComp框架中，通过将输入比特序列分割成多个组，每个组映射到单个调制符号，在多时隙中传输编码符号序列，以降低调制设计复杂度并提高计算可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了降低数字空中计算的调制设计复杂度，同时提高计算可靠性，需要开发更有效的比特分割和调制方法。

Method: 开发了两种比特分割方法：均匀比特分割（通过CCCP求解二阶锥规划子问题）和重要性自适应比特分割（IABP），后者使用模拟退火更新分割，内环使用CCCP进行调制设计。

Result: 数值结果显示两种方法都能在噪声信道中提供鲁棒计算，IABP相比Sequential Modulation for AirComp在乘积计算中可将计算误差降低高达5 dB。

Conclusion: 比特分割方法能有效提高数字空中计算的性能，特别是重要性自适应比特分割在计算精度方面表现优异。

Abstract: For digital over-the-air computation, the ChannelComp framework has recently been proposed to design digital modulations to compute any arbitrary function over a multiple access channel. To reduce modulation design complexity while increasing computation reliability, this paper integrates a bit-partitioning procedure into ChannelComp. The key process is to partition the input bit sequence into several groups, map each group to a single modulation symbol and transmit the encoded symbol sequence across multiple time slots. With the objective to maximize a worst-case constellation distance, we develop two bit-partitioning methods. In uniform bit-partitioning, bits are evenly distributed across groups and modulation is designed via a max-min optimization, which is handled by a CCCP that solves a sequence of second-order cone programming subproblems. In importance-adaptive bit-partitioning (IABP), the bit allocation is adapted to the significance of individual bit positions, and the modulation and partitioning are jointly optimized. To keep the overall complexity manageable, simulated annealing is employed in the outer loop to update the partitioning, while a CCCP-based solver is used in the inner loop for modulation design. Numerical results show that both methods provide robust computation in noisy channels, and IABP achieves up to a 5 dB reduction in computation error compared to Sequential Modulation for AirComp, especially for product computation.

</details>


### [25] [Optimal Waveform Design for Continuous Aperture Array (CAPA)-aided ISAC Systems](https://arxiv.org/abs/2511.20203)
*Junjie Ye,Zhaolin Wang,Yuanwei Liu,Peichang Zhang,Lei Huang,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出了一种基于连续孔径阵列(CAPA)的集成感知与通信(ISAC)框架，设计了最优连续ISAC波形，在实现多目标感知的同时抑制多用户干扰。


<details>
  <summary>Details</summary>
Motivation: 传统空间离散阵列在ISAC系统中存在性能限制，需要开发更高效的波形设计方法来同时优化感知性能和通信可靠性。

Method: 基于格林函数推导CAPA的定向波束模式，通过波数域优化获得参考感知波形，使用拉格朗日变换和变分法推导最优CAPA-ISAC波形结构。

Result: 数值结果表明，CAPA相比传统离散阵列在感知精度和通信可靠性方面均获得显著性能提升。

Conclusion: CAPA框架为ISAC系统提供了有效的解决方案，通过连续孔径阵列和优化波形设计实现了感知与通信性能的协同提升。

Abstract: A novel continuous-aperture-array (CAPA)-aided integrated sensing and communication (ISAC) framework is proposed. Specifically, an optimal continuous ISAC waveform is designed to form a directive beampattern for multi-target sensing while suppressing the multi-user interference (MUI). To achieve the goal of optimal waveform design, the directional beampattern of CAPA is first derived based on Green's function, whereafter a reference sensing waveform is obtained through wavenumber-domain optimization. Based on the reference sensing waveform, a weighted functional programming on the tradeoff between sensing beampattern mismatch and MUI is formulated. To solve the resulting problem, an optimal CAPA-ISAC waveform structure is analytically derived using a Lagrangian-transformation and calculus-of-variations method, where the Lagrangian multiplier associated with the optimal waveform structure is determined via Bisection search. The obtained optimal waveform reveals that it is concurrently affected by the reference sensing waveform, the channel correlations and the channel-symbol correlations. Finally, numerical results validate the effectiveness of the proposed system and waveform design, demonstrating that CAPA can achieve significant performance gains against the ISAC designs based on conventional spatially discrete array in both sensing accuracy and communication reliability.

</details>


### [26] [Rectified Flow for Vision-Aided mmWave V2I Beam Prediction](https://arxiv.org/abs/2511.20265)
*Can Zheng,Jiguang He,Chung G. Kang,Guofa Cai,Chongwen Huang,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出基于整流流的流匹配框架用于车联网视觉辅助波束预测，通过连续潜在流建模实现平滑波束轨迹和快速采样，显著提升预测精度和推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统方法建模离散波束索引序列存在局限性，需要更高效的连续流建模方法来提升车联网波束预测的精度和效率。

Method: 使用基于常微分方程的流匹配框架学习连续潜在流，引入终端流约束确保有限步积分下的全局一致性，实现稳定长期预测。

Result: 相比RNN和LSTM基线显著提升top-K准确率，接近大语言模型方法性能，在GPU和CPU上分别实现10倍和10^4倍的推理加速。

Conclusion: 流匹配框架为车联网波束预测提供了高效解决方案，在保持高精度的同时大幅提升推理速度，具有实际部署价值。

Abstract: This paper proposes a flow matching (FM) framework based on rectified flow for vision-aided beam prediction in vehicle-to-infrastructure (V2I) links. Instead of modeling discrete beam index sequences, the method learns a continuous latent flow governed by an ordinary differential equation (ODE)-based vector field, enabling smooth beam trajectories and fast sampling. A terminal flow constraint enforces global consistency under finite-step integration, stabilizing long-term prediction. The resulting FM-based model significantly improves top-K accuracy over RNN and LSTM baselines, approaches the performance of large language model-based approaches, and achieves inference speedups on the order of 10 x and 10^4 x on identical GPU and CPU deployments, respectively.

</details>


### [27] [Log-Mu Fading Process: Second-Order Statistics for Diversity-Combining Techniques](https://arxiv.org/abs/2511.20298)
*Godfred Kumi Tenkorang,Michel Daoud Yacoub*

Main category: eess.SP

TL;DR: 本文推导了Log-mu衰落信道上分集合并技术的二阶统计特性，包括纯选择合并的闭式解以及等增益合并和最大比合并的多维积分表达式。


<details>
  <summary>Details</summary>
Motivation: 研究Log-mu衰落信道下不同分集合并技术的性能，为无线通信系统设计提供理论依据。

Method: 推导了纯选择合并的闭式表达式，以及等增益合并和最大比合并的精确多维积分表达式，并通过蒙特卡洛仿真验证理论结果。

Result: 理论分析与蒙特卡洛仿真结果高度一致，验证了所提表达式的准确性。

Conclusion: 成功建立了Log-mu衰落信道上分集合并技术的二阶统计模型，为实际系统性能评估提供了有效工具。

Abstract: This paper derives second-order statistics for diversity-combining techniques over Log-mu fading channels. Closed-form expressions for the level crossing rate (LCR) and average fading duration (AFD) are derived for pure selection combining (PSC), while exact multidimensional integral expressions are obtained for equal gain combining (EGC) and maximal ratio combining (MRC). The analysis considers M unbalanced, independent, and non-identically distributed (i.n.i.d.) Log-mu fading channels. Monte Carlo simulations are conducted to validate the theoretical results, demonstrating excellent agreement and confirming the accuracy of the proposed expressions.

</details>


### [28] [Next-Generation MIMO Transceivers for Integrated Sensing and Communications: Unique Security Vulnerabilities and Solutions](https://arxiv.org/abs/2511.20309)
*Kawon Han,Christos Masouros,Taneli Riihonen,Moeness G. Amin*

Main category: eess.SP

TL;DR: 本文综述了MIMO ISAC收发器设计的最新进展，重点关注ISAC特有的安全威胁及应对措施，包括安全信号设计、干扰利用和对抗条件下的收发器优化。


<details>
  <summary>Details</summary>
Motivation: ISAC作为6G的关键使能技术，在实现智能、可持续和连接无线网络的同时，也引入了超越传统物理层安全的新安全漏洞，如高功率传输可能增强窃听者能力，ISAC回波可能泄露敏感目标信息。

Method: 从发射机视角、接收机架构和全双工实现三个方面分析MIMO ISAC收发器设计，研究在ISAC特有安全威胁下的收发器设计，包括安全信号设计、干扰利用和对抗条件下的收发器优化。

Result: 提出了针对ISAC特有安全威胁的应对措施，包括安全信号设计、干扰利用和收发器优化等方法，以增强ISAC系统的安全性。

Conclusion: 讨论了在下一代无线网络中开发安全ISAC系统面临的挑战和研究机遇，强调了在ISAC集成环境中安全设计的重要性。

Abstract: Integrated sensing and communications (ISAC), which is recognized as a key enabler for sixth generation (6G), has brought new opportunities for intelligent, sustainable, and connected wireless networks. Multiple-input multiple-output (MIMO) transceiver technology lies at the core of this paradigm, providing the degrees of freedom required for simultaneous data transmission and accurate radar sensing. The tight integration of sensing and communication introduces unique security vulnerabilities that extend beyond conventional physical-layer security (PLS). In particular, high-power transmissions directed at sensing targets may empower adversarial eavesdroppers, whereas passive interception of ISAC echoes can reveal sensitive information such as target locations and mobility patterns. This article presents an overview of recent advances in MIMO ISAC transceiver design, considering transmitter perspectives, receiver architectures, and full-duplex implementations. We examine MIMO transceiver designs under unique security threats specific to ISAC and highlight emerging countermeasures, including secure signaling design, interference exploitation, and transceiver optimization under adversarial conditions. Finally, we discuss challenges and research opportunities for developing secure ISAC systems in next-generation wireless networks.

</details>


### [29] [Bridging the Educational Divide: A Delay-Tolerant Networking Approach for Equitable Digital Learning in Rural Areas](https://arxiv.org/abs/2511.20334)
*Salah Abdeljabar,Mohamed-Slim Alouini*

Main category: eess.SP

TL;DR: 提出基于延迟容忍网络(DTN)的数字学习平台框架，为网络连接有限的农村地区提供教育机会，通过利用现有交通基础设施实现可持续的教育服务。


<details>
  <summary>Details</summary>
Motivation: 解决农村地区因网络连接有限而导致的教育不平等问题，促进教育公平和数字包容，符合全球包容性教育和可持续发展的目标。

Method: 开发基于延迟容忍网络(DTN)的数字学习平台框架，利用现有交通基础设施传输教育内容，不依赖持续互联网连接，并在大学校园测试原型系统。

Result: 原型测试证明了DTN在教育交付方面的可行性，能够为网络连接有限的地区提供可负担且可持续的教育解决方案。

Conclusion: DTN框架为解决数字鸿沟提供了有效途径，能够扩展教育机会到服务不足的社区，支持包容性教育和可持续发展目标。

Abstract: Access to quality education remains unequal, particularly in rural areas where Internet connectivity is limited or nonexistent. This paper introduces a framework for a digital learning platform that uses Delay Tolerant Networking (DTN) to extend educational opportunities to underserved communities. Unlike conventional models that rely on continuous Internet access, DTN offers an affordable and sustainable solution by leveraging existing transportation infrastructure. Beyond its technical contributions, the framework addresses ethical imperatives by promoting educational equity and digital inclusion. We present a prototype tested on a university campus, demonstrating the feasibility of DTN for educational delivery. By addressing the digital divide, this framework aligns with global goals of inclusive education and sustainable development.

</details>


### [30] [Digital Twin-Assisted High-Precision Massive MIMO Localization in Urban Canyons](https://arxiv.org/abs/2511.20453)
*Ziqin Zhou,Hui Chen,Gerhard Steinböck,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出了一种结合数字孪生模型和RANSAC算法的三阶段定位方法，有效利用NLOS路径信息实现高精度无线定位


<details>
  <summary>Details</summary>
Motivation: 解决城市峡谷环境中无线定位面临的噪声测量和严重NLOS传播挑战，降低对直接LOS路径的依赖并减少系统部署成本

Method: 三阶段算法：1) 使用数字孪生模型进行几何路径关联 2) 应用RANSAC算法识别可靠的LOS和单次反射NLOS路径，拒绝多次反射异常值 3) 在最终内点集上进行优化估计用户位置和时钟偏差

Result: 仿真验证表明该方法能有效将NLOS路径转化为有价值的几何信息，实现精确定位，降低对直接LOS的依赖，显著降低系统部署成本

Conclusion: 该方法通过数字孪生和RANSAC的协同作用，克服了城市峡谷环境的定位限制，适合实际部署应用

Abstract: High-precision wireless localization in urban canyons is challenged by noisy measurements and severe non-line-of-sight (NLOS) propagation. This paper proposes a robust three-stage algorithm synergizing a digital twin (DT) model with the random sample consensus (RANSAC) algorithm to overcome these limitations. The method leverages the DT for geometric path association and employs RANSAC to identify reliable line-of-sight (LOS) and single-bounce NLOS paths while rejecting multi-bounce outliers. A final optimization on the resulting inlier set estimates the user's position and clock bias. Simulations validate that by effectively turning NLOS paths into valuable geometric information via the DT, the approach enables accurate localization, reduces reliance on direct LOS, and significantly lowers system deployment costs, making it suitable for practical deployment.

</details>


### [31] [Near-Field Multipath MIMO Channels: Modeling Reflectors and Exploiting NLOS Paths](https://arxiv.org/abs/2511.20572)
*Mohamadreza Delbari,George C. Alexandropoulos,Robert Schober,H. Vincent Poor,Vahid Jamali*

Main category: eess.SP

TL;DR: 本文提出了一种广义的近场MIMO信道模型，扩展了点散射框架以考虑来自大表面的不完美反射，并证明在近场多用户场景中仅依赖LOS链路可能不足以实现复用增益。


<details>
  <summary>Details</summary>
Motivation: 现有近场信道模型基于点散射假设，不适用于墙壁、天花板等大反射体，需要开发能考虑大表面不完美反射的广义统计模型。

Method: 开发了广义统计近场MIMO信道模型，扩展点散射框架以包含大表面的不完美反射，并用于分析反射体物理特性对信道的影响。

Result: 仿真验证了模型准确性，表明在许多实际场景中NLOS分量的贡献不可忽略，必须仔细考虑。

Conclusion: 在近场多用户系统中，仅依赖LOS链路可能无法实现复用增益，利用NLOS链路变得至关重要，所提模型为系统设计提供了准确基础。

Abstract: Near-field (NF) communications is receiving renewed interest in the context of multiple-input multiple-output (MIMO) systems involving large physical apertures with respect to the signal wavelength. While line-of-sight (LOS) links are typically expected to dominate in NF scenarios, the impact of non-LOS (NLOS) components at both in centimeter- and millimeter-wave frequencies may be in general non-negligible. Moreover, although weaker than the LOS path, NLOS links may be essential for achieving multiplexing gains in MIMO systems. The commonly used NF channel models for NLOS links in the literature are based on the point scattering assumption, which is not valid for large reflectors such as walls, ceilings, and the ground. In this paper, we develop a generalized statistical NF MIMO channel model that extends the widely adopted point scattering framework to account for imperfect reflections from large surfaces. This model is then leveraged to investigate how the physical characteristics of these reflectors influence the resulting NF MIMO channel. In addition, using the proposed channel model, we analytically demonstrate for a multi-user scenario that, even when users are located within the NF regime, relying solely on LOS NF links may be insufficient to achieve multiplexing gains, thus exploiting NLOS links becomes essential. Our simulation results validate the accuracy of the proposed model and show that, in many practical settings, the contribution of NLOS components is non-negligible and must be carefully accounted for in the system design.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [32] [A model of the Unity High Definition Render Pipeline, with applications to flat-panel and head-mounted display characterization](https://arxiv.org/abs/2511.19447)
*Richard F. Murray*

Main category: eess.IV

TL;DR: 本文分析了Unity HDRP渲染管线中的亮度和颜色数学模型，揭示了其非线性特性，并提供了伽马校正的配置方法和专用文件生成软件。


<details>
  <summary>Details</summary>
Motivation: Unity和Unreal等游戏引擎已成为创建基于复杂交互场景的感知和行为实验的流行工具，但需要确保刺激显示的精确控制。

Method: 描述并测试Unity HDRP渲染管线中的亮度和颜色数学模型，分析其非线性特性，并开发伽马校正配置方法。

Result: 发现HDRP具有多个不明显的非线性特性，如对材质属性和渲染值应用的非线性变换，这些必须考虑才能显示良好控制的刺激。

Conclusion: 通过适当配置HDRP可以实现伽马校正的亮度和颜色显示，并提供了创建专用伽马校正文件的软件工具。

Abstract: Game engines such as Unity and Unreal Engine have become popular tools for creating perceptual and behavioral experiments based on complex, interactive scenes. They are often used with flat-panel displays, and also with head-mounted displays. Here I describe and test a mathematical model of luminance and color in Unity's High Definition Render Pipeline (HDRP). I show that the HDRP has several non-obvious features, such as nonlinearities applied to material properties and rendered values, that must be taken into account in order to show well-controlled stimuli. I also show how the HDRP can be configured to display gamma-corrected luminance and color, and I provide software to create the specialized files needed for gamma correction.

</details>


### [33] [Not Quite Anything: Overcoming SAMs Limitations for 3D Medical Imaging](https://arxiv.org/abs/2511.19471)
*Keith Moore*

Main category: eess.IV

TL;DR: 提出了一种组合式方法，将基础分割模型（如SAM-2）的输出作为额外输入通道与MRI图像一起处理，用于脑部MRI中基底节等低对比度结构的精确分割。


<details>
  <summary>Details</summary>
Motivation: 基础分割模型在自然图像上表现良好，但在脑部MRI中对于缺乏清晰边界和低对比度的结构（如尾状核和丘脑）效果不佳。

Method: 使用轻量级3D U-Net生成SAM-2提示，将基础模型输出作为额外输入通道与MRI图像组合，并平滑边缘以改善对齐。同时测试了使用DINO注意力图的无提示分割。

Result: 在基底节分割上达到约96%的体积精度，足以用于纵向体积变化研究。方法快速、标签高效且对分布外扫描具有鲁棒性。

Conclusion: 这种组合架构避免了修改基础模型权重，能够适应领域偏移而无需重新训练基础模型，成功应用于研究突发性儿童强迫症中与炎症相关的体积变化。

Abstract: Foundation segmentation models such as SAM and SAM-2 perform well on natural images but struggle with brain MRIs where structures like the caudate and thalamus lack sharp boundaries and have low contrast. Rather than fine tune these models (for example MedSAM), we propose a compositional alternative where the foundation model output is treated as an additional input channel and passed alongside the MRI to highlight regions of interest.
  We generate SAM-2 prompts by using a lightweight 3D U-Net that was previously trained on MRI segmentation. The U-Net may have been trained on a different dataset, so its guesses are often imprecise but usually in the correct region. The edges of the resulting foundation model guesses are smoothed to improve alignment with the MRI. We also test prompt free segmentation using DINO attention maps in the same framework.
  This has-a architecture avoids modifying foundation weights and adapts to domain shift without retraining the foundation model. It reaches about 96 percent volume accuracy on basal ganglia segmentation, which is sufficient for our study of longitudinal volume change. The approach is fast, label efficient, and robust to out of distribution scans. We apply it to study inflammation linked changes in sudden onset pediatric OCD.

</details>


### [34] [A Multi-Stage Deep Learning Framework with PKCP-MixUp Augmentation for Pediatric Liver Tumor Diagnosis Using Multi-Phase Contrast-Enhanced CT](https://arxiv.org/abs/2511.19478)
*Wanqi Wang,Chun Yang,Jianbo Shao,Yaokai Zhang,Xuehua Peng,Jin Sun,Chao Xiong,Long Lu,Lianting Hu*

Main category: eess.IV

TL;DR: 开发了一个多阶段深度学习框架，使用多期相增强CT自动诊断儿童肝肿瘤，解决了数据稀缺和类别不平衡问题，实现了高精度的良恶性分类和亚型诊断。


<details>
  <summary>Details</summary>
Motivation: 儿童肝肿瘤是儿科常见实体肿瘤，传统病理活检具有侵入性风险且儿童配合度差。现有AI研究大多忽略了儿童肝肿瘤领域，需要建立非侵入性诊断方法。

Method: 采用多阶段深度学习框架：1) 使用PKCP-MixUp数据增强解决数据问题；2) 训练肿瘤检测模型提取ROI；3) 建立两阶段诊断流程，使用ROI掩膜图像和三个主干网络进行良恶性分类和亚型诊断。

Result: 肿瘤检测模型mAP=0.871，良恶性分类AUC=0.989，良性亚型分类AUC=0.915，恶性亚型分类AUC=0.979。进行了消融研究和可解释性分析验证模型鲁棒性。

Conclusion: 该框架填补了儿童特异性DL诊断空白，为CT期相选择和模型设计提供了可行见解，为精确、可及的儿童肝肿瘤诊断铺平了道路。

Abstract: Pediatric liver tumors are one of the most common solid tumors in pediatrics, with differentiation of benign or malignant status and pathological classification critical for clinical treatment. While pathological examination is the gold standard, the invasive biopsy has notable limitations: the highly vascular pediatric liver and fragile tumor tissue raise complication risks such as bleeding; additionally, young children with poor compliance require anesthesia for biopsy, increasing medical costs or psychological trauma. Although many efforts have been made to utilize AI in clinical settings, most researchers have overlooked its importance in pediatric liver tumors. To establish a non-invasive examination procedure, we developed a multi-stage deep learning (DL) framework for automated pediatric liver tumor diagnosis using multi-phase contrast-enhanced CT. Two retrospective and prospective cohorts were enrolled. We established a novel PKCP-MixUp data augmentation method to address data scarcity and class imbalance. We also trained a tumor detection model to extract ROIs, and then set a two-stage diagnosis pipeline with three backbones with ROI-masked images. Our tumor detection model has achieved high performance (mAP=0.871), and the first stage classification model between benign and malignant tumors reached an excellent performance (AUC=0.989). Final diagnosis models also exhibited robustness, including benign subtype classification (AUC=0.915) and malignant subtype classification (AUC=0.979). We also conducted multi-level comparative analyses, such as ablation studies on data and training pipelines, as well as Shapley-Value and CAM interpretability analyses. This framework fills the pediatric-specific DL diagnostic gap, provides actionable insights for CT phase selection and model design, and paves the way for precise, accessible pediatric liver tumor diagnosis.

</details>


### [35] [The Selective Disk Bispectrum and Its Inversion, with Application to Multi-Reference Alignment](https://arxiv.org/abs/2511.19706)
*Adele Myers,Nina Miolane*

Main category: eess.IV

TL;DR: 提出了一种选择性圆盘双谱方法，用于图像的旋转不变表示，解决了传统圆盘双谱方法计算复杂度高、不可逆的问题，实现了高效的形状分析和多参考对齐。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉和形状分析任务中，需要学习物体的形状特征而忽略其方向。因此需要一种旋转不变的图像表示方法，能够保留所有图像信息但忽略物体在帧中的旋转方式，并且需要计算高效、可逆以便可视化。

Method: 提出了选择性圆盘双谱方法，推导出了圆盘双谱的显式逆变换，从而定义了只使用最小数量系数的选择性圆盘双谱，用于忠实形状恢复。

Result: 该表示方法能够实现旋转图像的多参考对齐任务，这是传统圆盘双谱方法以前无法解决的。

Conclusion: 选择性圆盘双谱为旋转不变形状数据的学习提供了一个实用且理论可靠的工具。

Abstract: In many computer vision and shape analysis tasks, practitioners are interested in learning from the shape of the object in an image, while disregarding the object's orientation. To this end, it is valuable to define a rotation-invariant representation of images, retaining all information about that image, but disregarding the way an object is rotated in the frame. To be practical for learning tasks, this representation must be computationally efficient for large datasets and invertible, so the representation can be visualized in image space. To this end, we present the selective disk bispectrum: a fast, rotation-invariant representation for image shape analysis. While the translational bispectrum has long been used as a translational invariant representation for 1-D and 2-D signals, its extension to 2-D (disk) rotational invariance on images has been hindered by the absence of an invertible formulation and its cubic complexity. In this work, we derive an explicit inverse for the disk bispectrum, which allows us to define a "selective" disk bispectrum, which only uses the minimal number of coefficients needed for faithful shape recovery. We show that this representation enables multi-reference alignment for rotated images-a task previously intractable for disk bispectrum methods. These results establish the disk bispectrum as a practical and theoretically grounded tool for learning on rotation-invariant shape data.

</details>


### [36] [DLADiff: A Dual-Layer Defense Framework against Fine-Tuning and Zero-Shot Customization of Diffusion Models](https://arxiv.org/abs/2511.19910)
*Jun Jia,Hongyi Miao,Yingjie Zhou,Linhan Cao,Yanwei Jiang,Wangqiu Zhou,Dandan Zhu,Hua Yang,Wei Sun,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 本文提出DLADiff方法，通过双层保护机制防御扩散模型的微调攻击和零样本生成攻击，有效保护面部隐私。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型的发展，恶意攻击者仅用少量甚至一张图像就能创建与原身份几乎相同的合成身份，现有防御方法主要针对微调方法而忽略了零样本生成防御。

Method: 提出双层反扩散(DLADiff)机制：第一层使用双代理模型(DSUR)和交替动态微调(ADFT)防御微调攻击；第二层简单但有效地防止零样本生成方法。

Result: 实验结果表明，该方法在防御扩散模型微调方面显著优于现有方法，并在防御零样本生成方面实现了前所未有的性能。

Conclusion: DLADiff能够有效防御扩散模型的微调攻击和零样本生成攻击，为面部隐私保护提供了全面解决方案。

Abstract: With the rapid advancement of diffusion models, a variety of fine-tuning methods have been developed, enabling high-fidelity image generation with high similarity to the target content using only 3 to 5 training images. More recently, zero-shot generation methods have emerged, capable of producing highly realistic outputs from a single reference image without altering model weights. However, technological advancements have also introduced significant risks to facial privacy. Malicious actors can exploit diffusion model customization with just a few or even one image of a person to create synthetic identities nearly identical to the original identity. Although research has begun to focus on defending against diffusion model customization, most existing defense methods target fine-tuning approaches and neglect zero-shot generation defenses. To address this issue, this paper proposes Dual-Layer Anti-Diffusion (DLADiff) to defense both fine-tuning methods and zero-shot methods. DLADiff contains a dual-layer protective mechanism. The first layer provides effective protection against unauthorized fine-tuning by leveraging the proposed Dual-Surrogate Models (DSUR) mechanism and Alternating Dynamic Fine-Tuning (ADFT), which integrates adversarial training with the prior knowledge derived from pre-fine-tuned models. The second layer, though simple in design, demonstrates strong effectiveness in preventing image generation through zero-shot methods. Extensive experimental results demonstrate that our method significantly outperforms existing approaches in defending against fine-tuning of diffusion models and achieves unprecedented performance in protecting against zero-shot generation.

</details>


### [37] [Development of a fully deep learning model to improve the reproducibility of sector classification systems for predicting unerupted maxillary canine likelihood of impaction](https://arxiv.org/abs/2511.20493)
*Marzio Galdi,Davide Cannatà,Flavia Celentano,Luigia Rizzo,Domenico Rossi,Tecla Bocchino,Stefano Martina*

Main category: eess.IV

TL;DR: 本研究开发了深度学习模型来减少上颌未萌出尖牙嵌塞预测中扇形分类系统的操作者间和操作者内变异，发现3-扇形系统重复性最高，DenseNet121模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决上颌未萌出尖牙嵌塞预测中不同扇形分类系统存在的操作者间和操作者内变异问题，提高诊断的一致性和准确性。

Method: 3名正畸医生和3名全科牙医使用三种扇形分类系统（5、4、3扇形）对306张X光片进行评估，并在4周后重复评估。同时使用在1,222张X光片预训练的AI模型进行测试。

Result: 3-扇形系统重复性最高（Cohen's K 0.80-0.92），操作者间一致性为0.69-0.7。DenseNet121模型在三类嵌塞尖牙分类中表现最佳，总体准确率达76.8%。教育背景不影响评估一致性。

Conclusion: AI模型可用于自动分类上颌未萌出尖牙的位置，为临床诊断提供可靠工具。

Abstract: Objectives. The aim of the present study was to develop a fully deep learning model to reduce the intra- and inter-operator reproducibility of sector classification systems for predicting unerupted maxillary canine likelihood of impaction. Methods. Three orthodontists (Os) and three general dental practitioners (GDPs) classified the position of unerupted maxillary canines on 306 radiographs (T0) according to the three different sector classification systems (5-, 4-, and 3-sector classification system). The assessment was repeated after four weeks (T1). Intra- and inter-observer agreement were evaluated with Cohen's K and Fleiss K, and between group differences with a z-test. The same radiographs were tested on different artificial intelligence (AI) models, pre-trained on an extended dataset of 1,222 radiographs. The best-performing model was identified based on its sensitivity and precision. Results. The 3-sector system was found to be the classification method with highest reproducibility, with an agreement (Cohen's K values) between observations (T0 versus T1) for each examiner ranged from 0.80 to 0.92, and an overall agreement of 0.85 [95% confidence interval (CI) = 0.83-0.87]. The overall inter-observer agreement (Fleiss K) ranged from 0.69 to 0.7. The educational background did not affect either intra- or inter-observer agreement (p>0.05). DenseNet121 proved to be the best-performing model in allocating impacted canines in the three different classes, with an overall accuracy of 76.8%. Conclusion. AI models can be designed to automatically classify the position of unerupted maxillary canines.

</details>
