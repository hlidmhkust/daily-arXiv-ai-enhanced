{"id": "2508.14931", "categories": ["eess.IV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.14931", "abs": "https://arxiv.org/abs/2508.14931", "authors": ["Zahra TehraniNasab", "Amar Kumar", "Tal Arbel"], "title": "Pixels Under Pressure: Exploring Fine-Tuning Paradigms for Foundation Models in High-Resolution Medical Imaging", "comment": null, "summary": "Advancements in diffusion-based foundation models have improved text-to-image\ngeneration, yet most efforts have been limited to low-resolution settings. As\nhigh-resolution image synthesis becomes increasingly essential for various\napplications, particularly in medical imaging domains, fine-tuning emerges as a\ncrucial mechanism for adapting these powerful pre-trained models to\ntask-specific requirements and data distributions. In this work, we present a\nsystematic study, examining the impact of various fine-tuning techniques on\nimage generation quality when scaling to high resolution 512x512 pixels. We\nbenchmark a diverse set of fine-tuning methods, including full fine-tuning\nstrategies and parameter-efficient fine-tuning (PEFT). We dissect how different\nfine-tuning methods influence key quality metrics, including Fr\\'echet\nInception Distance (FID), Vendi score, and prompt-image alignment. We also\nevaluate the utility of generated images in a downstream classification task\nunder data-scarce conditions, demonstrating that specific fine-tuning\nstrategies improve both generation fidelity and downstream performance when\nsynthetic images are used for classifier training and evaluation on real\nimages. Our code is accessible through the project website -\nhttps://tehraninasab.github.io/PixelUPressure/.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u4e0d\u540c\u5fae\u8c03\u6280\u672f\u5bf9512x512\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u5168\u5fae\u8c03\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u8bc4\u4f30\u4e86\u751f\u6210\u8d28\u91cf\u548c\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u5728\u533b\u7597\u6210\u50cf\u7b49\u9886\u57df\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5fae\u8c03\u6280\u672f\u5c06\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u9002\u914d\u5230\u7279\u5b9a\u4efb\u52a1\u548c\u6570\u636e\u5206\u5e03\u3002", "method": "\u91c7\u7528\u591a\u79cd\u5fae\u8c03\u65b9\u6cd5\uff08\u5305\u62ec\u5168\u5fae\u8c03\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03PEFT\uff09\uff0c\u5728512x512\u5206\u8fa8\u7387\u4e0b\u8bc4\u4f30FID\u3001Vendi\u5206\u6570\u548c\u63d0\u793a-\u56fe\u50cf\u5bf9\u9f50\u7b49\u8d28\u91cf\u6307\u6807\uff0c\u5e76\u5728\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u8bc4\u4f30\u751f\u6210\u56fe\u50cf\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7279\u5b9a\u5fae\u8c03\u7b56\u7565\u80fd\u591f\u540c\u65f6\u63d0\u9ad8\u751f\u6210\u4fdd\u771f\u5ea6\u548c\u4e0b\u6e38\u6027\u80fd\uff0c\u5f53\u4f7f\u7528\u5408\u6210\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u5668\u8bad\u7ec3\u5e76\u5728\u771f\u5b9e\u56fe\u50cf\u4e0a\u8bc4\u4f30\u65f6\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u7cfb\u7edf\u7814\u7a76\u4e3a\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u4e86\u5fae\u8c03\u65b9\u6cd5\u7684\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u5fae\u8c03\u5728\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2508.14932", "categories": ["eess.IV", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.14932", "abs": "https://arxiv.org/abs/2508.14932", "authors": ["Jiacheng Xie", "Ziyang Zhang", "Biplab Poudel", "Congyu Guo", "Yang Yu", "Guanghui An", "Xiaoting Tang", "Lening Zhao", "Chunhui Xu", "Dong Xu"], "title": "TOM: An Open-Source Tongue Segmentation Method with Multi-Teacher Distillation and Task-Specific Data Augmentation", "comment": "Tongue segmentation, data augmentation, synthetic data for AI\n  training, prompt engineering, Segment Anything Model, knowledge distillation,\n  tongue classification", "summary": "Tongue imaging serves as a valuable diagnostic tool, particularly in\nTraditional Chinese Medicine (TCM). The quality of tongue surface segmentation\nsignificantly affects the accuracy of tongue image classification and\nsubsequent diagnosis in intelligent tongue diagnosis systems. However, existing\nresearch on tongue image segmentation faces notable limitations, and there is a\nlack of robust and user-friendly segmentation tools. This paper proposes a\ntongue image segmentation model (TOM) based on multi-teacher knowledge\ndistillation. By incorporating a novel diffusion-based data augmentation\nmethod, we enhanced the generalization ability of the segmentation model while\nreducing its parameter size. Notably, after reducing the parameter count by\n96.6% compared to the teacher models, the student model still achieves an\nimpressive segmentation performance of 95.22% mIoU. Furthermore, we packaged\nand deployed the trained model as both an online and offline segmentation tool\n(available at https://itongue.cn/), allowing TCM practitioners and researchers\nto use it without any programming experience. We also present a case study on\nTCM constitution classification using segmented tongue patches. Experimental\nresults demonstrate that training with tongue patches yields higher\nclassification performance and better interpretability than original tongue\nimages. To our knowledge, this is the first open-source and freely available\ntongue image segmentation tool.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6559\u5e08\u77e5\u8bc6\u8403\u53d6\u7684\u820c\u50cf\u5206\u5272\u6a21\u578b(TOM)\uff0c\u901a\u8fc7\u65b0\u9898\u6563\u6e10\u6570\u636e\u589e\u5e3d\u6280\u672f\u63d0\u5347\u6a21\u578b\u901a\u7528\u6027\uff0c\u5728\u53c2\u6570\u91cf\u51cf\u5c1196.6%\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u8fbe\u523095.22% mIoU\u7684\u5206\u5272\u6027\u80fd\uff0c\u5e76\u63a8\u51fa\u4e86\u9996\u4e2a\u5f00\u6e90\u514d\u8d39\u7684\u820c\u50cf\u5206\u5272\u5de5\u5177\u3002", "motivation": "\u820c\u8c61\u5728\u4e2d\u533b\u8bca\u65ad\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u820c\u50cf\u5206\u5272\u7814\u7a76\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u7f3a\u4e4f\u5065\u58ee\u4e14\u6613\u7528\u7684\u5206\u5272\u5de5\u5177\uff0c\u5f71\u54cd\u667a\u80fd\u820c\u8bca\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u591a\u6559\u5e08\u77e5\u8bc6\u8403\u53d6\u6280\u672f\uff0c\u7ed3\u5408\u65b0\u9898\u6563\u6e10\u6570\u636e\u589e\u5e3d\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u9ad8\u5206\u5272\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u91cf\u3002\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5305\u88c5\u4e3a\u5728\u7ebf\u548c\u79bb\u7ebf\u5206\u5272\u5de5\u5177\u3002", "result": "\u5b66\u751f\u6a21\u578b\u5728\u53c2\u6570\u91cf\u51cf\u5c1196.6%\u540e\u4ecd\u80fd\u8fbe\u523095.22% mIoU\u7684\u9ad8\u5206\u5272\u6027\u80fd\u3002\u901a\u8fc7\u820c\u50cf\u7247\u8fdb\u884c\u4e2d\u533b\u4f53\u8d28\u5206\u7c7b\u7684\u6848\u4f8b\u7814\u7a76\u663e\u793a\uff0c\u4f7f\u7528\u5206\u5272\u540e\u7684\u820c\u50cf\u7247\u8bad\u7ec3\u80fd\u83b7\u5f97\u66f4\u9ad8\u7684\u5206\u7c7b\u6027\u80fd\u548c\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u9996\u4e2a\u5f00\u6e90\u514d\u8d39\u7684\u820c\u50cf\u5206\u5272\u5de5\u5177\uff0c\u901a\u8fc7\u77e5\u8bc6\u8403\u53d6\u548c\u6563\u6e10\u589e\u5e3d\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5c0f\u578b\u5316\u6a21\u578b\uff0c\u4e3a\u4e2d\u533b\u5b9e\u8df5\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u65e0\u9700\u7f16\u7a0b\u7ecf\u9a8c\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u667a\u80fd\u820c\u8bca\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.14950", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14950", "abs": "https://arxiv.org/abs/2508.14950", "authors": ["Oliver Welin Odeback", "Arivazhagan Geetha Balasubramanian", "Jonas Schollenberger", "Edward Ferdiand", "Alistair A. Young", "C. Alberto Figueroa", "Susanne Schnell", "Outi Tammisola", "Ricardo Vinuesa", "Tobias Granberg", "Alexander Fyrdahl", "David Marlevi"], "title": "Potential and challenges of generative adversarial networks for super-resolution in 4D Flow MRI", "comment": "23 pages, 9 figures", "summary": "4D Flow Magnetic Resonance Imaging (4D Flow MRI) enables non-invasive\nquantification of blood flow and hemodynamic parameters. However, its clinical\napplication is limited by low spatial resolution and noise, particularly\naffecting near-wall velocity measurements. Machine learning-based\nsuper-resolution has shown promise in addressing these limitations, but\nchallenges remain, not least in recovering near-wall velocities. Generative\nadversarial networks (GANs) offer a compelling solution, having demonstrated\nstrong capabilities in restoring sharp boundaries in non-medical\nsuper-resolution tasks. Yet, their application in 4D Flow MRI remains\nunexplored, with implementation challenged by known issues such as training\ninstability and non-convergence. In this study, we investigate GAN-based\nsuper-resolution in 4D Flow MRI. Training and validation were conducted using\npatient-specific cerebrovascular in-silico models, converted into synthetic\nimages via an MR-true reconstruction pipeline. A dedicated GAN architecture was\nimplemented and evaluated across three adversarial loss functions: Vanilla,\nRelativistic, and Wasserstein. Our results demonstrate that the proposed GAN\nimproved near-wall velocity recovery compared to a non-adversarial reference\n(vNRMSE: 6.9% vs. 9.6%); however, that implementation specifics are critical\nfor stable network training. While Vanilla and Relativistic GANs proved\nunstable compared to generator-only training (vNRMSE: 8.1% and 7.8% vs. 7.2%),\na Wasserstein GAN demonstrated optimal stability and incremental improvement\n(vNRMSE: 6.9% vs. 7.2%). The Wasserstein GAN further outperformed the\ngenerator-only baseline at low SNR (vNRMSE: 8.7% vs. 10.7%). These findings\nhighlight the potential of GAN-based super-resolution in enhancing 4D Flow MRI,\nparticularly in challenging cerebrovascular regions, while emphasizing the need\nfor careful selection of adversarial strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u57fa\u4e8eGAN\u7684\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u57284D Flow MRI\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8fd1\u58c1\u901f\u5ea6\u6062\u590d\u95ee\u9898\u3002\u901a\u8fc7\u6bd4\u8f83\u4e09\u79cd\u5bf9\u6297\u635f\u5931\u51fd\u6570\uff0c\u53d1\u73b0Wasserstein GAN\u5728\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u65b9\u9762\u8868\u73b0\u6700\u4f18\u3002", "motivation": "4D Flow MRI\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u53d7\u9650\u4e8e\u4f4e\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u566a\u58f0\uff0c\u7279\u522b\u662f\u5728\u8fd1\u58c1\u901f\u5ea6\u6d4b\u91cf\u65b9\u9762\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u6709\u6f5c\u529b\uff0c\u4f46\u8fd1\u58c1\u901f\u5ea6\u6062\u590d\u4ecd\u5177\u6311\u6218\u6027\u3002GAN\u5728\u975e\u533b\u5b66\u8d85\u5206\u8fa8\u7387\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u57284D Flow MRI\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u60a3\u8005\u7279\u5f02\u6027\u8111\u8840\u7ba1\u7845\u6a21\u578b\u751f\u6210\u5408\u6210\u56fe\u50cf\uff0c\u901a\u8fc7MR\u771f\u5b9e\u91cd\u5efa\u7ba1\u9053\u3002\u5b9e\u73b0\u4e13\u7528GAN\u67b6\u6784\uff0c\u8bc4\u4f30\u4e09\u79cd\u5bf9\u6297\u635f\u5931\u51fd\u6570\uff1aVanilla\u3001Relativistic\u548cWasserstein GAN\u3002", "result": "\u63d0\u51fa\u7684GAN\u76f8\u6bd4\u975e\u5bf9\u6297\u53c2\u8003\u6539\u5584\u4e86\u8fd1\u58c1\u901f\u5ea6\u6062\u590d\uff08vNRMSE: 6.9% vs. 9.6%\uff09\u3002Wasserstein GAN\u8868\u73b0\u51fa\u6700\u4f73\u7a33\u5b9a\u6027\u548c\u589e\u91cf\u6539\u8fdb\uff08vNRMSE: 6.9% vs. 7.2%\uff09\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u4e5f\u4f18\u4e8e\u751f\u6210\u5668\u57fa\u7ebf\uff08vNRMSE: 8.7% vs. 10.7%\uff09\u3002", "conclusion": "GAN-based\u8d85\u5206\u8fa8\u7387\u5728\u589e\u5f3a4D Flow MRI\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8111\u8840\u7ba1\u533a\u57df\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u9009\u62e9\u5bf9\u6297\u7b56\u7565\u4ee5\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002"}}
{"id": "2508.14952", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14952", "abs": "https://arxiv.org/abs/2508.14952", "authors": ["Paul Fischer", "Jan Nikolas Morshuis", "Thomas K\u00fcstner", "Christian Baumgartner"], "title": "CUTE-MRI: Conformalized Uncertainty-based framework for Time-adaptivE MRI", "comment": null, "summary": "Magnetic Resonance Imaging (MRI) offers unparalleled soft-tissue contrast but\nis fundamentally limited by long acquisition times. While deep learning-based\naccelerated MRI can dramatically shorten scan times, the reconstruction from\nundersampled data introduces ambiguity resulting from an ill-posed problem with\ninfinitely many possible solutions that propagates to downstream clinical\ntasks. This uncertainty is usually ignored during the acquisition process as\nacceleration factors are often fixed a priori, resulting in scans that are\neither unnecessarily long or of insufficient quality for a given clinical\nendpoint. This work introduces a dynamic, uncertainty-aware acquisition\nframework that adjusts scan time on a per-subject basis. Our method leverages a\nprobabilistic reconstruction model to estimate image uncertainty, which is then\npropagated through a full analysis pipeline to a quantitative metric of\ninterest (e.g., patellar cartilage volume or cardiac ejection fraction). We use\nconformal prediction to transform this uncertainty into a rigorous, calibrated\nconfidence interval for the metric. During acquisition, the system iteratively\nsamples k-space, updates the reconstruction, and evaluates the confidence\ninterval. The scan terminates automatically once the uncertainty meets a\nuser-predefined precision target. We validate our framework on both knee and\ncardiac MRI datasets. Our results demonstrate that this adaptive approach\nreduces scan times compared to fixed protocols while providing formal\nstatistical guarantees on the precision of the final image. This framework\nmoves beyond fixed acceleration factors, enabling patient-specific acquisitions\nthat balance scan efficiency with diagnostic confidence, a critical step\ntowards personalized and resource-efficient MRI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u52a8\u6001MRI\u91c7\u96c6\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u91cd\u5efa\u6a21\u578b\u4f30\u8ba1\u56fe\u50cf\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u4fdd\u5f62\u9884\u6d4b\u751f\u6210\u7f6e\u4fe1\u533a\u95f4\uff0c\u5b9e\u73b0\u6309\u9700\u81ea\u52a8\u7ec8\u6b62\u626b\u63cf\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u51cf\u5c11\u626b\u63cf\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edfMRI\u52a0\u901f\u91cd\u5efa\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u52a0\u901f\u56e0\u5b50\uff0c\u8981\u4e48\u626b\u63cf\u65f6\u95f4\u8fc7\u957f\uff0c\u8981\u4e48\u56fe\u50cf\u8d28\u91cf\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4e3a\u4e0b\u6e38\u4e34\u5e8a\u4efb\u52a1\u63d0\u4f9b\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6839\u636e\u4e2a\u4f53\u9700\u6c42\u52a8\u6001\u8c03\u6574\u626b\u63cf\u65f6\u95f4\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6982\u7387\u91cd\u5efa\u6a21\u578b\u4f30\u8ba1\u56fe\u50cf\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b(conformal prediction)\u751f\u6210\u91cf\u5316\u6307\u6807\u7684\u6821\u51c6\u7f6e\u4fe1\u533a\u95f4\u3002\u5728\u91c7\u96c6\u8fc7\u7a0b\u4e2d\u8fed\u4ee3\u91c7\u6837k-space\u3001\u66f4\u65b0\u91cd\u5efa\u5e76\u8bc4\u4f30\u7f6e\u4fe1\u533a\u95f4\uff0c\u5f53\u4e0d\u786e\u5b9a\u6027\u8fbe\u5230\u7528\u6237\u9884\u8bbe\u7cbe\u5ea6\u76ee\u6807\u65f6\u81ea\u52a8\u7ec8\u6b62\u626b\u63cf\u3002", "result": "\u5728\u819d\u5173\u8282\u548c\u5fc3\u810fMRI\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u56fa\u5b9a\u534f\u8bae\u51cf\u5c11\u4e86\u626b\u63cf\u65f6\u95f4\uff0c\u540c\u65f6\u4e3a\u6700\u7ec8\u56fe\u50cf\u7684\u7cbe\u5ea6\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7684\u7edf\u8ba1\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u6846\u67b6\u8d85\u8d8a\u4e86\u56fa\u5b9a\u52a0\u901f\u56e0\u5b50\uff0c\u5b9e\u73b0\u4e86\u60a3\u8005\u7279\u5f02\u6027\u7684\u91c7\u96c6\uff0c\u5728\u626b\u63cf\u6548\u7387\u548c\u8bca\u65ad\u7f6e\u4fe1\u5ea6\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u662f\u5411\u4e2a\u6027\u5316\u548c\u8d44\u6e90\u9ad8\u6548MRI\u8fc8\u8fdb\u7684\u5173\u952e\u4e00\u6b65\u3002"}}
{"id": "2508.15257", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15257", "abs": "https://arxiv.org/abs/2508.15257", "authors": ["Eduard E. Bahingayi", "Shuying Lin", "Murat Uysal", "Marco Di Renzo", "Le-Nam Tran"], "title": "A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems", "comment": null, "summary": "Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive\ntechnology for future wireless networks. To investigate their capabilities, we\nstudy the sum rate maximization problem in an SIM-based multiuser (MU)\nmultiple-input single-output (MISO) downlink system. A vast majority of pioneer\nstudies, if not all, address this fundamental problem using the prevailing\nalternating optimization (AO) framework, where the digital beamforming (DB) and\nSIM phase shifts are optimized alternately. However, many of these approaches\nsuffer from suboptimal performance, quickly leading to performance saturation,\nwhen the number of SIM layers increases assuming the \\emph{fixed SIM\nthickness}. In this letter, we demonstrate that significant performance gains\ncan still be achieved, and such saturation does not occur with the proposed\nmethod in the considered setting. To this end, we provide practical design\nguidelines to improve AO-based optimization of digital precoders and SIM phase\nshifts. Specifically, we show that (i) optimizing the SIM phase shifts first\nyields significant performance improvements, compared to optimizing the DB\nfirst; and (ii) when applying projected gradient (PG) methods, which are\ngradually becoming more popular to optimize the phase shifts thanks to their\nscalability, we find that using an iterative PG method achieves better\nperformance than the single PG step, which is commonly used in existing\nsolutions. Based on these customizations, the proposed method achieves a higher\nachievable sum rate (ASR) of up to $\\ensuremath{115.53\\%}$, compared to\nbenchmark schemes for the scenarios under consideration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762(SIM)\u591a\u7528\u6237MISO\u7cfb\u7edf\u7684\u548c\u901f\u7387\u6700\u5927\u5316\uff0c\u901a\u8fc7\u5148\u4f18\u5316SIM\u76f8\u4f4d\u504f\u79fb\u518d\u4f18\u5316\u6570\u5b57\u6ce2\u675f\u6210\u5f62\uff0c\u4ee5\u53ca\u4f7f\u7528\u8fed\u4ee3\u6295\u5f71\u68af\u5ea6\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u5904\u7406SIM\u7cfb\u7edf\u7684\u548c\u901f\u7387\u6700\u5927\u5316\u95ee\u9898\u65f6\uff0c\u5f53SIM\u5c42\u6570\u589e\u52a0\u4f46\u539a\u5ea6\u56fa\u5b9a\u65f6\uff0c\u6027\u80fd\u5bb9\u6613\u8fbe\u5230\u9971\u548c\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6027\u80fd\u74f6\u9888\uff0c\u5bfb\u6c42\u66f4\u4f18\u7684\u4f18\u5316\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\uff1a1) \u5148\u4f18\u5316SIM\u76f8\u4f4d\u504f\u79fb\u518d\u4f18\u5316\u6570\u5b57\u6ce2\u675f\u6210\u5f62\uff1b2) \u4f7f\u7528\u8fed\u4ee3\u6295\u5f71\u68af\u5ea6\u65b9\u6cd5\u4f18\u5316\u76f8\u4f4d\u504f\u79fb\uff0c\u800c\u975e\u5e38\u7528\u7684\u5355\u6b65\u6295\u5f71\u68af\u5ea6\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\uff0c\u53ef\u5b9e\u73b0\u9ad8\u8fbe115.53%\u7684\u548c\u901f\u7387\u63d0\u5347\uff0c\u5728SIM\u5c42\u6570\u589e\u52a0\u65f6\u4e0d\u4f1a\u51fa\u73b0\u6027\u80fd\u9971\u548c\u73b0\u8c61\u3002", "conclusion": "\u4f18\u5316\u987a\u5e8f\u548c\u6295\u5f71\u68af\u5ea6\u65b9\u6cd5\u7684\u6539\u8fdb\u5bf9SIM\u7cfb\u7edf\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5148\u4f18\u5316SIM\u76f8\u4f4d\u504f\u79fb\u518d\u4f18\u5316\u6570\u5b57\u6ce2\u675f\u6210\u5f62\uff0c\u914d\u5408\u8fed\u4ee3\u6295\u5f71\u68af\u5ea6\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.15185", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15185", "abs": "https://arxiv.org/abs/2508.15185", "authors": ["Dingzhu Wen", "Sijing Xie", "Xiaowen Cao", "Yuanhao Cui", "Jie Xu", "Yuanming Shi", "Shuguang Cui"], "title": "Integrated Sensing, Communication, and Computation for Over-the-Air Federated Edge Learning", "comment": "The paper has been accepted for publication in IEEE Transactions on\n  Wireless Communications", "summary": "This paper studies an over-the-air federated edge learning (Air-FEEL) system\nwith integrated sensing, communication, and computation (ISCC), in which one\nedge server coordinates multiple edge devices to wirelessly sense the objects\nand use the sensing data to collaboratively train a machine learning model for\nrecognition tasks. In this system, over-the-air computation (AirComp) is\nemployed to enable one-shot model aggregation from edge devices. Under this\nsetup, we analyze the convergence behavior of the ISCC-enabled Air-FEEL in\nterms of the loss function degradation, by particularly taking into account the\nwireless sensing noise during the training data acquisition and the AirComp\ndistortions during the over-the-air model aggregation. The result theoretically\nshows that sensing, communication, and computation compete for network\nresources to jointly decide the convergence rate. Based on the analysis, we\ndesign the ISCC parameters under the target of maximizing the loss function\ndegradation while ensuring the latency and energy budgets in each round. The\nchallenge lies on the tightly coupled processes of sensing, communication, and\ncomputation among different devices. To tackle the challenge, we derive a\nlow-complexity ISCC algorithm by alternately optimizing the batch size control\nand the network resource allocation. It is found that for each device, less\nsensing power should be consumed if a larger batch of data samples is obtained\nand vice versa. Besides, with a given batch size, the optimal computation speed\nof one device is the minimum one that satisfies the latency constraint.\nNumerical results based on a human motion recognition task verify the\ntheoretical convergence analysis and show that the proposed ISCC algorithm well\ncoordinates the batch size control and resource allocation among sensing,\ncommunication, and computation to enhance the learning performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u96c6\u6210\u4e86\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u7a7a\u4e2d\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u65e0\u7ebf\u611f\u77e5\u566a\u58f0\u548c\u7a7a\u4e2d\u8ba1\u7b97\u5931\u771f\u5bf9\u6536\u655b\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4f4e\u590d\u6742\u5ea6\u7684ISCC\u7b97\u6cd5\u6765\u534f\u8c03\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u548c\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u9700\u8981\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u3002\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u901a\u4fe1\u74f6\u9888\u548c\u8d44\u6e90\u9650\u5236\uff0c\u800c\u96c6\u6210\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u4e00\u4f53\u5316\u8bbe\u8ba1\u53ef\u4ee5\u63d0\u5347\u5b66\u4e60\u6027\u80fd\uff0c\u4f46\u9700\u8981\u7406\u8bba\u5206\u6790\u548c\u4f18\u5316\u7b97\u6cd5\u652f\u6301\u3002", "method": "\u91c7\u7528\u7a7a\u4e2d\u8ba1\u7b97\u6280\u672f\u5b9e\u73b0\u5355\u6b21\u6a21\u578b\u805a\u5408\uff0c\u7406\u8bba\u5206\u6790ISCC-enabled Air-FEEL\u7684\u6536\u655b\u884c\u4e3a\uff0c\u8003\u8651\u65e0\u7ebf\u611f\u77e5\u566a\u58f0\u548c\u7a7a\u4e2d\u8ba1\u7b97\u5931\u771f\u3002\u8bbe\u8ba1ISCC\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\uff0c\u4ea4\u66ff\u4f18\u5316\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u548c\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7ade\u4e89\u7f51\u7edc\u8d44\u6e90\u5171\u540c\u51b3\u5b9a\u6536\u655b\u901f\u7387\u3002\u63d0\u51fa\u7684ISCC\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u534f\u8c03\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u548c\u8d44\u6e90\u5206\u914d\uff0c\u5728\u4eba\u4f53\u8fd0\u52a8\u8bc6\u522b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u5e76\u63d0\u5347\u4e86\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "ISCC-enabled Air-FEEL\u7cfb\u7edf\u901a\u8fc7\u534f\u8c03\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\u8bbe\u5907\u5728\u83b7\u5f97\u66f4\u5927\u6279\u91cf\u6570\u636e\u65f6\u5e94\u6d88\u8017\u66f4\u5c11\u7684\u611f\u77e5\u529f\u7387\uff0c\u4e14\u5728\u7ed9\u5b9a\u6279\u91cf\u5927\u5c0f\u65f6\u6700\u4f18\u8ba1\u7b97\u901f\u5ea6\u662f\u6ee1\u8db3\u5ef6\u8fdf\u7ea6\u675f\u7684\u6700\u5c0f\u503c\u3002"}}
{"id": "2508.15003", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.15003", "abs": "https://arxiv.org/abs/2508.15003", "authors": ["Andrew C. Freeman"], "title": "Scalable Event-Based Video Streaming for Machines with MoQ", "comment": "Accepted to ACM Mile High Video 2025", "summary": "Lossy compression and rate-adaptive streaming are a mainstay in traditional\nvideo steams. However, a new class of neuromorphic ``event'' sensors records\nvideo with asynchronous pixel samples rather than image frames. These sensors\nare designed for computer vision applications, rather than human video\nconsumption. Until now, researchers have focused their efforts primarily on\napplication development, ignoring the crucial problem of data transmission. We\nsurvey the landscape of event-based video systems, discuss the technical issues\nwith our recent scalable event streaming work, and propose a new low-latency\nevent streaming format based on the latest additions to the Media Over QUIC\nprotocol draft.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u795e\u7ecf\u5f62\u6001\u4e8b\u4ef6\u4f20\u611f\u5668\u89c6\u9891\u6d41\u7684\u538b\u7f29\u548c\u4f20\u8f93\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eMedia Over QUIC\u534f\u8bae\u7684\u4f4e\u5ef6\u8fdf\u4e8b\u4ef6\u6d41\u683c\u5f0f", "motivation": "\u4f20\u7edf\u89c6\u9891\u538b\u7f29\u548c\u81ea\u9002\u5e94\u6d41\u6280\u672f\u4e0d\u9002\u7528\u4e8e\u5f02\u6b65\u50cf\u7d20\u91c7\u6837\u7684\u795e\u7ecf\u5f62\u6001\u4e8b\u4ef6\u4f20\u611f\u5668\u6570\u636e\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u4f20\u8f93\u89e3\u51b3\u65b9\u6848", "method": "\u8c03\u67e5\u4e8b\u4ef6\u89c6\u9891\u7cfb\u7edf\u73b0\u72b6\uff0c\u7ed3\u5408\u8fd1\u671f\u53ef\u6269\u5c55\u4e8b\u4ef6\u6d41\u5de5\u4f5c\uff0c\u57fa\u4e8eMedia Over QUIC\u534f\u8bae\u8349\u6848\u8bbe\u8ba1\u65b0\u7684\u4f4e\u5ef6\u8fdf\u4e8b\u4ef6\u6d41\u683c\u5f0f", "result": "\u63d0\u51fa\u4e86\u4e13\u95e8\u9488\u5bf9\u4e8b\u4ef6\u4f20\u611f\u5668\u6570\u636e\u7279\u70b9\u7684\u6d41\u5a92\u4f53\u4f20\u8f93\u65b9\u6848", "conclusion": "\u4e8b\u4ef6\u4f20\u611f\u5668\u89c6\u9891\u6d41\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u4f20\u8f93\u534f\u8bae\uff0cMedia Over QUIC\u534f\u8bae\u4e3a\u4f4e\u5ef6\u8fdf\u4e8b\u4ef6\u6d41\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u57fa\u7840"}}
{"id": "2508.15375", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15375", "abs": "https://arxiv.org/abs/2508.15375", "authors": ["Hanwen Hu", "Jiancheng An", "Lu Gan", "Chau Yuen"], "title": "Performance Analysis of RIS-Aided High-Mobility Wireless Systems", "comment": "This paper has been accepted for publication in 2025 IEEE 102nd\n  Vehicular Technology Conference", "summary": "Reconfigurable intelligent surface (RIS) technology holds immense potential\nfor increasing the performance of wireless networks. Therefore, RIS is also\nregarded as one of the solutions to address communication challenges in\nhigh-mobility scenarios, such as Doppler shift and fast fading. This paper\ninvestigates a high-speed train (HST) multiple-input single-output (MISO)\ncommunication system aided by a RIS. We propose a block coordinate descent\n(BCD) algorithm to jointly optimize the RIS phase shifts and the transmit\nbeamforming vectors to maximize the channel gain. Numerical results are\nprovided to demonstrate that the proposed algorithm significantly enhances the\nsystem performance, achieving an average channel gain improvement of 15 dB\ncompared to traditional schemes. Additionally, the introduction of RIS\neliminates outage probability and improves key performance metrics such as\nachievable rate, channel capacity, and bit error rate (BER). These findings\nhighlight the critical role of RIS in enhancing HST communication systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76RIS\u8f85\u52a9\u7684\u9ad8\u901f\u5217\u8f66MISO\u901a\u4fe1\u7cfb\u7edf\uff0c\u63d0\u51faBCD\u7b97\u6cd5\u8054\u5408\u4f18\u5316RIS\u76f8\u79fb\u548c\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd15dB\uff0c\u6d88\u9664\u4e2d\u65ad\u6982\u7387\u5e76\u6539\u5584\u591a\u4e2a\u5173\u952e\u6307\u6807", "motivation": "RIS\u6280\u672f\u5177\u6709\u63d0\u5347\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e2d\u89e3\u51b3\u591a\u666e\u52d2\u9891\u79fb\u548c\u5feb\u901f\u8870\u843d\u7b49\u901a\u4fe1\u6311\u6218", "method": "\u63d0\u51fa\u5757\u5750\u6807\u4e0b\u964d(BCD)\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316RIS\u76f8\u79fb\u548c\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u5411\u91cf\uff0c\u4ee5\u6700\u5927\u5316\u4fe1\u9053\u589e\u76ca", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u5e73\u5747\u4fe1\u9053\u589e\u76ca\u63d0\u9ad815dB\uff0c\u6d88\u9664\u4e2d\u65ad\u6982\u7387\uff0c\u6539\u5584\u53ef\u8fbe\u901f\u7387\u3001\u4fe1\u9053\u5bb9\u91cf\u548c\u8bef\u7801\u7387\u7b49\u5173\u952e\u6027\u80fd\u6307\u6807", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86RIS\u5728\u589e\u5f3a\u9ad8\u901f\u5217\u8f66\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u4f5c\u7528"}}
{"id": "2508.15277", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15277", "abs": "https://arxiv.org/abs/2508.15277", "authors": ["Ping Zhang", "Kai Niu", "Yiming Liu", "Zijian Liang", "Nan Ma", "Xiaodong Xu", "Wenjun Xu", "Mengying Sun", "Yinqiu Liu", "Xiaoyun Wang", "Ruichen Zhang"], "title": "Way to Build Native AI-driven 6G Air Interface: Principles, Roadmap, and Outlook", "comment": "14 pages, 7 figures", "summary": "Artificial intelligence (AI) is expected to serve as a foundational\ncapability across the entire lifecycle of 6G networks, spanning design,\ndeployment, and operation. This article proposes a native AI-driven air\ninterface architecture built around two core characteristics: compression and\nadaptation. On one hand, compression enables the system to understand and\nextract essential semantic information from the source data, focusing on task\nrelevance rather than symbol-level accuracy. On the other hand, adaptation\nallows the air interface to dynamically transmit semantic information across\ndiverse tasks, data types, and channel conditions, ensuring scalability and\nrobustness. This article first introduces the native AI-driven air interface\narchitecture, then discusses representative enabling methodologies, followed by\na case study on semantic communication in 6G non-terrestrial networks. Finally,\nit presents a forward-looking discussion on the future of native AI in 6G,\noutlining key challenges and research opportunities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u538b\u7f29\u548c\u9002\u5e94\u4e24\u5927\u6838\u5fc3\u7279\u6027\u7684\u539f\u751fAI\u9a71\u52a8\u76846G\u7a7a\u53e3\u67b6\u6784\uff0c\u901a\u8fc7\u8bed\u4e49\u901a\u4fe1\u5b9e\u73b0\u4efb\u52a1\u76f8\u5173\u7684\u9ad8\u6548\u4fe1\u606f\u4f20\u8f93\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u9884\u8ba1\u5c06\u57286G\u7f51\u7edc\u7684\u5168\u751f\u547d\u5468\u671f\u4e2d\u53d1\u6325\u57fa\u7840\u6027\u4f5c\u7528\uff0c\u9700\u8981\u6784\u5efa\u80fd\u591f\u7406\u89e3\u8bed\u4e49\u4fe1\u606f\u5e76\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u548c\u4fe1\u9053\u6761\u4ef6\u7684\u667a\u80fd\u7a7a\u53e3\u67b6\u6784\u3002", "method": "\u91c7\u7528\u538b\u7f29\u548c\u9002\u5e94\u4e24\u5927\u6838\u5fc3\u7279\u6027\uff1a\u538b\u7f29\u6280\u672f\u4ece\u6e90\u6570\u636e\u4e2d\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7684\u8bed\u4e49\u4fe1\u606f\uff1b\u9002\u5e94\u673a\u5236\u4f7f\u7a7a\u53e3\u80fd\u591f\u8de8\u4e0d\u540c\u4efb\u52a1\u3001\u6570\u636e\u7c7b\u578b\u548c\u4fe1\u9053\u6761\u4ef6\u52a8\u6001\u4f20\u8f93\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u63d0\u51fa\u4e86\u539f\u751fAI\u9a71\u52a8\u7684\u7a7a\u53e3\u67b6\u6784\uff0c\u5e76\u901a\u8fc76G\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u7684\u8bed\u4e49\u901a\u4fe1\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u539f\u751fAI\u6280\u672f\u4e3a6G\u7f51\u7edc\u5e26\u6765\u4e86\u65b0\u7684\u673a\u9047\uff0c\u4f46\u4ecd\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5b9e\u73b0\u5176\u57286G\u4e2d\u7684\u5168\u9762\u5e94\u7528\u3002"}}
{"id": "2508.15011", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2508.15011", "abs": "https://arxiv.org/abs/2508.15011", "authors": ["Asadullah Bin Rahman", "Masud Ibn Afjal", "Md. Abdulla Al Mamun"], "title": "Systematic Evaluation of Wavelet-Based Denoising for MRI Brain Images: Optimal Configurations and Performance Benchmarks", "comment": null, "summary": "Medical imaging modalities including magnetic resonance imaging (MRI),\ncomputed tomography (CT), and ultrasound are essential for accurate diagnosis\nand treatment planning in modern healthcare. However, noise contamination\nduring image acquisition and processing frequently degrades image quality,\nobscuring critical diagnostic details and compromising clinical\ndecision-making. Additionally, enhancement techniques such as histogram\nequalization may inadvertently amplify existing noise artifacts, including\nsalt-and-pepper distortions. This study investigates wavelet transform-based\ndenoising methods for effective noise mitigation in medical images, with the\nprimary objective of identifying optimal combinations of threshold values,\ndecomposition levels, and wavelet types to achieve superior denoising\nperformance and enhanced diagnostic accuracy. Through systematic evaluation\nacross various noise conditions, the research demonstrates that the bior6.8\nbiorthogonal wavelet with universal thresholding at decomposition levels 2-3\nconsistently achieves optimal denoising performance, providing significant\nnoise reduction while preserving essential anatomical structures and diagnostic\nfeatures critical for clinical applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u57fa\u4e8e\u5c0f\u6ce2\u53d8\u6362\u7684\u533b\u5b66\u56fe\u50cf\u53bb\u566a\u65b9\u6cd5\uff0c\u53d1\u73b0bior6.8\u53cc\u6b63\u4ea4\u5c0f\u6ce2\u5728\u5206\u89e3\u7ea7\u522b2-3\u914d\u5408\u901a\u7528\u9608\u503c\u5904\u7406\u80fd\u5b9e\u73b0\u6700\u4f73\u53bb\u566a\u6548\u679c\uff0c\u5728\u4fdd\u6301\u5173\u952e\u89e3\u5256\u7ed3\u6784\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u566a\u58f0\u3002", "motivation": "\u533b\u5b66\u6210\u50cf\uff08MRI\u3001CT\u3001\u8d85\u58f0\uff09\u5728\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56fe\u50cf\u91c7\u96c6\u548c\u5904\u7406\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u6c61\u67d3\u4f1a\u964d\u4f4e\u56fe\u50cf\u8d28\u91cf\uff0c\u5f71\u54cd\u4e34\u5e8a\u51b3\u7b56\u3002\u73b0\u6709\u589e\u5f3a\u6280\u672f\u53ef\u80fd\u653e\u5927\u566a\u58f0\u4f2a\u5f71\uff0c\u9700\u8981\u6709\u6548\u7684\u53bb\u566a\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5c0f\u6ce2\u53d8\u6362\u53bb\u566a\u65b9\u6cd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u9608\u503c\u3001\u5206\u89e3\u7ea7\u522b\u548c\u5c0f\u6ce2\u7c7b\u578b\u7684\u6700\u4f18\u7ec4\u5408\uff0c\u7814\u7a76\u5728\u5404\u79cd\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u53bb\u566a\u6027\u80fd\u3002", "result": "bior6.8\u53cc\u6b63\u4ea4\u5c0f\u6ce2\u914d\u5408\u901a\u7528\u9608\u503c\u5904\u7406\u5728\u5206\u89e3\u7ea7\u522b2-3\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u566a\u58f0\u540c\u65f6\u4fdd\u7559\u5173\u952e\u89e3\u5256\u7ed3\u6784\u548c\u8bca\u65ad\u7279\u5f81\u3002", "conclusion": "\u5c0f\u6ce2\u53d8\u6362\u53bb\u566a\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u533b\u5b66\u56fe\u50cf\u8d28\u91cf\uff0cbior6.8\u5c0f\u6ce2\u5728\u7279\u5b9a\u53c2\u6570\u8bbe\u7f6e\u4e0b\u53ef\u4e3a\u4e34\u5e8a\u5e94\u7528\u63d0\u4f9b\u6700\u4f18\u7684\u53bb\u566a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15544", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15544", "abs": "https://arxiv.org/abs/2508.15544", "authors": ["Pedro H. C. de Souza", "Luiz A. M. Pereira", "Faustino R. G\u00f3mez", "Elsa M. Mater\u00f3n", "Jorge Ricardo Mej\u00eda-Salazar"], "title": "Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems", "comment": null, "summary": "Ongoing discussions about the future of wireless communications are reaching\na turning point as standardization activities for the sixth generation of\nmobile networks (6G) become more mature. New technologies must now face renewed\nscrutiny by the industry and academia in order to be ready for deployment in\nthe near future. Recently, reconfigurable intelligent surfaces (RISs) gained\nattention as a promising solution for improving the propagation conditions of\nsignal transmission in general. The RIS is a planar array of tunable resonant\nelements designed to dynamically and precisely manipulate the reflection of\nincident electromagnetic waves. However, the physical structure of the RIS and\nits components may be subject to practical limitations and imperfections. It is\nimperative that the hardware imperfections (HWIs) associated with the RIS be\nanalyzed, so that it remains a feasible technology from a practical standpoint.\nMoreover, solutions for mitigating the HWIs must be considered, as is discussed\nin this work. More specifically, we introduce a gradient descent optimization\nfor mitigating HWIs in RIS-aided wideband communication systems. Numerical\nresults show that the proposed optimization is able to compensate for HWIs such\nas the phase-shift noise (PSN) and RIS surface deformations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5\u6765\u7f13\u89e3RIS\u8f85\u52a9\u5bbd\u5e26\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u786c\u4ef6\u7f3a\u9677\uff0c\u5305\u62ec\u76f8\u4f4d\u504f\u79fb\u566a\u58f0\u548c\u8868\u9762\u53d8\u5f62\u95ee\u9898\u3002", "motivation": "\u968f\u77406G\u6807\u51c6\u5316\u8fdb\u7a0b\u63a8\u8fdb\uff0c\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u4f5c\u4e3a\u6539\u5584\u4fe1\u53f7\u4f20\u8f93\u6761\u4ef6\u7684\u6709\u524d\u666f\u6280\u672f\u53d7\u5230\u5173\u6ce8\u3002\u4f46RIS\u7684\u7269\u7406\u7ed3\u6784\u548c\u7ec4\u4ef6\u5b58\u5728\u5b9e\u9645\u9650\u5236\u548c\u7f3a\u9677\uff0c\u9700\u8981\u5206\u6790\u786c\u4ef6\u7f3a\u9677\u5e76\u5f00\u53d1\u7f13\u89e3\u65b9\u6848\u4ee5\u786e\u4fdd\u6280\u672f\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7b97\u6cd5\u6765\u7f13\u89e3RIS\u7cfb\u7edf\u4e2d\u7684\u786c\u4ef6\u7f3a\u9677\uff0c\u7279\u522b\u9488\u5bf9\u76f8\u4f4d\u504f\u79fb\u566a\u58f0\u548c\u8868\u9762\u53d8\u5f62\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8865\u507f\u76f8\u4f4d\u504f\u79fb\u566a\u58f0\u548cRIS\u8868\u9762\u53d8\u5f62\u7b49\u786c\u4ef6\u7f3a\u9677\u3002", "conclusion": "\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u662f\u7f13\u89e3RIS\u786c\u4ef6\u7f3a\u9677\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347RIS\u6280\u672f\u57286G\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u53ef\u884c\u6027\u3002"}}
{"id": "2508.15325", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15325", "abs": "https://arxiv.org/abs/2508.15325", "authors": ["Bingsheng Shen", "Zhengchun Zhou", "Yang Yang", "Pingzhi Fan"], "title": "Some Optimal and Near Optimal Doppler Resilient Complementary Sequence Sets", "comment": null, "summary": "Sequences with excellent ambiguity functions are very useful in radar\ndetection and modern mobile communications. Doppler resilient complementary\nsequence (DRCS) is a new type of sequence proposed recently, which can achieve\nlower ambiguity function sidelobes by summing the ambiguity functions of\nsubsequences. In this paper, we introduce some new constructions of DRCS sets\n(DRCSSs) based on one-coincidence frequency-hopping sequence sets (OC-FHSSs),\nalmost difference sets (ADSs), some specific sequences, etc. Critically, the\nproposed DRCSSs are optimal or near optimal.", "AI": {"tldr": "\u57fa\u4e8eOC-FHSSs\u3001ADSs\u7b49\u65b0\u65b9\u6cd5\u6784\u9020\u4f18\u5316\u6216\u8fd1\u4f18\u7684\u591c\u5c3e\u5f39\u6027\u8865\u5145\u5e8f\u5217\u96c6\uff0c\u63d0\u9ad8\u96f7\u8fbe\u68c0\u6d4b\u548c\u901a\u4fe1\u6027\u80fd", "motivation": "\u4f19\u591c\u5c3e\u5f39\u6027\u8865\u5145\u5e8f\u5217(DRCS)\u5728\u96f7\u8fbe\u68c0\u6d4b\u548c\u73b0\u4ee3\u79fb\u52a8\u901a\u4fe1\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u9700\u8981\u6784\u9020\u66f4\u4f18\u79cd\u7c7b\u7684DRCS\u96c6\u5408\u6765\u83b7\u5f97\u66f4\u4f4e\u7684\u6a21\u7cca\u51fd\u6570\u65c1\u7f6e\u6d6a", "method": "\u57fa\u4e8e\u4e00\u5143\u91cd\u5408\u9891\u7387\u8df3\u53d8\u5e8f\u5217\u96c6(OC-FHSSs)\u3001\u51e0\u4e4e\u5dee\u96c6(ADSs)\u4ee5\u53ca\u4e00\u4e9b\u7279\u5b9a\u5e8f\u5217\u8fdb\u884c\u65b0\u7684DRCS\u96c6\u6784\u9020", "result": "\u63d0\u51fa\u7684DRCS\u96c6\u5408\u8fbe\u5230\u4e86\u4f18\u5316\u6216\u8fd1\u4f18\u7684\u6027\u80fd", "conclusion": "\u901a\u8fc7\u5229\u7528OC-FHSSs\u3001ADSs\u7b49\u5de5\u5177\u53ef\u4ee5\u6784\u9020\u51fa\u6027\u80fd\u4f18\u5f02\u7684\u4f18\u591c\u5c3e\u5f39\u6027\u8865\u5145\u5e8f\u5217\u96c6\uff0c\u4e3a\u96f7\u8fbe\u68c0\u6d4b\u548c\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5e8f\u5217\u9009\u62e9"}}
{"id": "2508.15132", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2508.15132", "abs": "https://arxiv.org/abs/2508.15132", "authors": ["Nicholas Dwork", "Alex McManus", "Stephen Becker", "Gennifer T. Smith"], "title": "SPIRiT Regularization: Parallel MRI with a Combination of Sensitivity Encoding and Linear Predictability", "comment": null, "summary": "Accelerated Magnetic Resonance Imaging (MRI) permits high quality images from\nfewer samples that can be collected with a faster scan. Two established methods\nfor accelerating MRI include parallel imaging and compressed sensing. Two types\nof parallel imaging include linear predictability, which assumes that the\nFourier samples are linearly related, and sensitivity encoding, which\nincorporates a priori knowledge of the sensitivity maps. In this work, we\ncombine compressed sensing with both types of parallel imaging using a novel\nregularization term: SPIRiT regularization. When combined, the reconstructed\nimages are improved. We demonstrate results on data of a brain, a knee, and an\nankle.", "AI": {"tldr": "\u7ed3\u5408\u538b\u7f29\u611f\u77e5\u4e0e\u4e24\u79cd\u5e76\u884c\u6210\u50cf\u65b9\u6cd5\uff08\u7ebf\u6027\u9884\u6d4b\u6027\u548c\u7075\u654f\u5ea6\u7f16\u7801\uff09\uff0c\u63d0\u51faSPIRiT\u6b63\u5219\u5316\u9879\uff0c\u663e\u8457\u63d0\u5347MRI\u91cd\u5efa\u56fe\u50cf\u8d28\u91cf", "motivation": "\u73b0\u6709MRI\u52a0\u901f\u65b9\u6cd5\u5305\u62ec\u5e76\u884c\u6210\u50cf\u548c\u538b\u7f29\u611f\u77e5\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u6548\u679c\u6709\u9650\u3002\u9700\u8981\u7ed3\u5408\u4e24\u79cd\u5e76\u884c\u6210\u50cf\u65b9\u6cd5\u4e0e\u538b\u7f29\u611f\u77e5\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u91cd\u5efa\u8d28\u91cf", "method": "\u63d0\u51faSPIRiT\u6b63\u5219\u5316\u9879\uff0c\u5c06\u538b\u7f29\u611f\u77e5\u4e0e\u7ebf\u6027\u9884\u6d4b\u6027\u548c\u7075\u654f\u5ea6\u7f16\u7801\u4e24\u79cd\u5e76\u884c\u6210\u50cf\u65b9\u6cd5\u76f8\u7ed3\u5408", "result": "\u5728\u8111\u90e8\u3001\u819d\u76d6\u548c\u811a\u8e1d\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u91cd\u5efa\u56fe\u50cf\u8d28\u91cf\u5f97\u5230\u660e\u663e\u6539\u5584", "conclusion": "SPIRiT\u6b63\u5219\u5316\u65b9\u6cd5\u6210\u529f\u6574\u5408\u4e86\u538b\u7f29\u611f\u77e5\u4e0e\u5e76\u884c\u6210\u50cf\u6280\u672f\uff0c\u4e3a\u52a0\u901fMRI\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u91cd\u5efa\u65b9\u6848"}}
{"id": "2508.15581", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15581", "abs": "https://arxiv.org/abs/2508.15581", "authors": ["Pedro H. C. de Souza", "Luciano Mendes"], "title": "Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces", "comment": null, "summary": "Recently, the reconfigurable intelligent surface (RIS) technology has ushered\nin the prospect of control over the wireless propagation environment. By\nestablishing alternative propagation paths for the transmitted signals, and by\nreflecting them in a controllable manner, the RIS is able to improve the signal\nreception. However, an aspect often overlooked is the potential bandwidth\nrestrictions on the wideband signal reflected by the RIS. If not carefully\nconsidered, this can become an impediment for the adoption of the RIS in the\nnext generation of communications systems. Therefore, in this work we propose a\nRIS configuration method that provides frequency selective signal reflection\nfor wideband signals.", "AI": {"tldr": "\u91cd\u914d\u667a\u80fd\u8868\u9762\u6280\u672f\u5728\u5e7f\u5e26\u4fe1\u53f7\u53cd\u5c04\u4e2d\u5b58\u5728\u5e26\u5bbd\u9650\u5236\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9891\u7387\u9009\u62e9\u6027\u53cd\u5c04\u7684\u65b0\u65b9\u6cd5", "motivation": "\u867d\u7136\u91cd\u914d\u667a\u80fd\u8868\u9762(RIS)\u6280\u672f\u80fd\u591f\u63a7\u5236\u65e0\u7ebf\u4f20\u64ad\u73af\u5883\u5e76\u6539\u5584\u4fe1\u53f7\u63a5\u6536\uff0c\u4f46\u5e7f\u5e26\u4fe1\u53f7\u53cd\u5c04\u7684\u5e26\u5bbd\u9650\u5236\u95ee\u9898\u5f80\u5f80\u88ab\u5ffd\u89c6\uff0c\u53ef\u80fd\u6210\u4e3a\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\u91c7\u7528RIS\u7684\u969c\u788d", "method": "\u63d0\u51fa\u4e00\u79cdRIS\u914d\u7f6e\u65b9\u6cd5\uff0c\u80fd\u591f\u4e3a\u5e7f\u5e26\u4fe1\u53f7\u63d0\u4f9b\u9891\u7387\u9009\u62e9\u6027\u7684\u4fe1\u53f7\u53cd\u5c04", "result": "\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5e7f\u5e26\u4fe1\u53f7\u53cd\u5c04\u7684\u5e26\u5bbd\u9650\u5236\u95ee\u9898", "conclusion": "\u901a\u8fc7\u9891\u7387\u9009\u62e9\u6027\u53cd\u5c04\u65b9\u6cd5\uff0cRIS\u6280\u672f\u53ef\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\u7684\u5e7f\u5e26\u9700\u6c42"}}
{"id": "2508.15639", "categories": ["cs.IT", "eess.SP", "math.IT", "94A14", "E.4"], "pdf": "https://arxiv.org/pdf/2508.15639", "abs": "https://arxiv.org/abs/2508.15639", "authors": ["Eito Kurihara", "Hideki Ochiai"], "title": "High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering", "comment": "13 pages, 13 figures", "summary": "We address a design of high-capacity and low-peak-to-average power ratio\n(PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on\nbit-interleaved coded modulation (BICM) utilizing non-equiprobable and\nnon-uniform (NENU) constellations as well as clipping and filtering (CAF). The\nproposed constellations are generated using a truncated Gaussian distribution,\nand the merging of constellation points, where the former creates a non-uniform\nconstellation (NUC), and the latter decreases the number of signal points\nwithout compromising the achievable bit-wise mutual information (BMI). Since\nthe proposed constellations are uniquely determined by only the two parameters,\neach associated with NUC and cardinality, the complexity required for the\nnumerical optimization process can be significantly low. We focus on the\nconstellation design based on one dimension, i.e., pulse amplitude modulation\n(PAM), which facilitates the reduction of demapping complexity for the BICM\nreceiver. The use of CAF at the transmitter can efficiently reduce the PAPR of\nOFDM signals; however, it introduces clipping noise that may degrade error rate\nperformance, making the application of clipping noise cancellation (CNC) at the\nreceiver essential. Therefore, we optimize the NENU constellations in the\npresence of CAF and CNC. Simulation results demonstrate that the combination of\nconstellation shaping with CAF and CNC enables BICM-OFDM systems to\nsimultaneously achieve low PAPR and high spectral efficiency over additive\nwhite Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading\nchannels. Furthermore, comparative studies confirm that the proposed system\nsignificantly outperforms the single-carrier counterpart (i.e., DFT-precoded\nBICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading\nchannels.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u5747\u5300\u975e\u7b49\u6982\u7387\u661f\u5ea7\u548c\u526a\u5207\u6ee4\u6ce2\u6280\u672f\u7684\u9ad8\u5bb9\u91cf\u4f4ePAPR OFDM\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4f18\u5316\u661f\u5ea7\u5f62\u72b6\u548c\u526a\u5207\u566a\u58f0\u6d88\u9664\u6280\u672f\uff0c\u5728AWGN\u548c\u9891\u7387\u9009\u6025\u8870\u843d\u4fe1\u9053\u4e0a\u540c\u65f6\u5b9e\u73b0\u4f4e\u5cf0\u5747\u6bd4\u548c\u9ad8\u8c31\u6548\u7387\u3002", "motivation": "\u89e3\u51b3OFDM\u7cfb\u7edf\u4e2d\u9ad8\u5cf0\u5747\u6bd4(PAPR)\u95ee\u9898\u548c\u63d0\u9ad8\u8c31\u6548\u7387\u7684\u9700\u6c42\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u8fd9\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u4e89\u8bae\u3002", "method": "\u91c7\u7528\u622a\u65ad\u9ad8\u65af\u5206\u5e03\u751f\u6210\u975e\u5747\u5300\u975e\u7b49\u6982\u7387(NENU)\u661f\u5ea7\uff0c\u7ed3\u5408\u526a\u5207\u6ee4\u6ce2(CAF)\u6280\u672f\u964d\u4f4ePAPR\uff0c\u5e76\u5728\u63a5\u6536\u7aef\u4f7f\u7528\u526a\u5207\u566a\u58f0\u6d88\u9664(CNC)\u6280\u672f\u3002\u91c7\u7528\u5355\u7ef4PAM\u8c03\u5236\u4ee5\u964d\u4f4e\u89e3\u6620\u590d\u6742\u5ea6\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u5728AWGN\u548c\u9891\u7387\u9009\u6025\u8870\u843d\u4fe1\u9053\u4e0a\u540c\u65f6\u5b9e\u73b0\u4e86\u4f4ePAPR\u548c\u9ad8\u8c31\u6548\u7387\uff0c\u4e14\u5728PAPR\u548cBER\u6027\u80fd\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5355\u8f7d\u6ce2\u5bf9\u7167\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7NENU\u661f\u5ea7\u3001CAF\u548cCNC\u6280\u672f\u7684\u7ed3\u5408\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u5bb9\u91cf\u4f4ePAPR OFDM\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4e3a\u9ad8\u901f\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15151", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15151", "abs": "https://arxiv.org/abs/2508.15151", "authors": ["Jeonghyun Noh", "Hyun-Jic Oh", "Byungju Chae", "Won-Ki Jeong"], "title": "Zero-shot Volumetric CT Super-Resolution using 3D Gaussian Splatting with Upsampled 2D X-ray Projection Priors", "comment": null, "summary": "Computed tomography (CT) is widely used in clinical diagnosis, but acquiring\nhigh-resolution (HR) CT is limited by radiation exposure risks. Deep\nlearning-based super-resolution (SR) methods have been studied to reconstruct\nHR from low-resolution (LR) inputs. While supervised SR approaches have shown\npromising results, they require large-scale paired LR-HR volume datasets that\nare often unavailable. In contrast, zero-shot methods alleviate the need for\npaired data by using only a single LR input, but typically struggle to recover\nfine anatomical details due to limited internal information. To overcome these,\nwe propose a novel zero-shot 3D CT SR framework that leverages upsampled 2D\nX-ray projection priors generated by a diffusion model. Exploiting the\nabundance of HR 2D X-ray data, we train a diffusion model on large-scale 2D\nX-ray projection and introduce a per-projection adaptive sampling strategy. It\nselects the generative process for each projection, thus providing HR\nprojections as strong external priors for 3D CT reconstruction. These\nprojections serve as inputs to 3D Gaussian splatting for reconstructing a 3D CT\nvolume. Furthermore, we propose negative alpha blending (NAB-GS) that allows\nnegative values in Gaussian density representation. NAB-GS enables residual\nlearning between LR and diffusion-based projections, thereby enhancing\nhigh-frequency structure reconstruction. Experiments on two datasets show that\nour method achieves superior quantitative and qualitative results for 3D CT SR.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u77633D CT\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u5229\u7528\u6fc0\u5149\u6563\u5c04\u6a21\u578b\u751f\u6210\u9ad8\u5206\u8fa8\u73872D X\u5149\u6295\u5f71\u4f5c\u4e3a\u5916\u90e8\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc73D\u9ad8\u65af\u62df\u5408\u548c\u8d1f\u503c\u6df7\u5408\u6280\u672f\u5b9e\u73b0\u4f18\u79c0\u76843D CT\u91cd\u5efa\u6548\u679c", "motivation": "\u89e3\u51b3\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6210\u5bf9LR-HR\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u96f6\u6837\u672c\u65b9\u6cd5\u56e0\u5185\u90e8\u4fe1\u606f\u6709\u9650\u800c\u65e0\u6cd5\u6062\u590d\u7ec6\u817b\u89e3\u5256\u7ec6\u8282\u7684\u9650\u5236", "method": "\u8bad\u7ec3\u6fc0\u5149\u6563\u5c04\u6a21\u578b\u751f\u6210\u9ad8\u5206\u8fa8\u73872D X\u5149\u6295\u5f71\u4f5c\u4e3a\u5916\u90e8\u5148\u9a8c\uff0c\u91c7\u7528\u6bcf\u4e2a\u6295\u5f71\u9002\u5e94\u6027\u91c7\u6837\u7b56\u7565\uff0c\u4f7f\u75283D\u9ad8\u65af\u62df\u5408\u91cd\u5efa3D CT\u4f53\u79ef\uff0c\u5e76\u63d0\u51fa\u652f\u6301\u8d1f\u503c\u7684\u8d1f\u503calpha\u6df7\u5408\u6280\u672f\u4ee5\u589e\u5f3a\u9ad8\u9891\u7ed3\u6784\u91cd\u5efa", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u57283D CT\u8d85\u5206\u8fa8\u7387\u4efb\u52a1\u4e2d\u83b7\u5f97\u4e86\u4f18\u79c0\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u7ed3\u679c", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u6fc0\u5149\u6563\u5c04\u6a21\u578b\u751f\u6210\u7684\u9ad8\u8d28\u91cf2D X\u5149\u6295\u5f71\u4f5c\u4e3a\u5916\u90e8\u5148\u9a8c\uff0c\u6709\u6548\u5145\u5206\u5229\u7528\u4e86\u4e30\u5bcc\u7684HR 2D X\u5149\u6570\u636e\uff0c\u6210\u529f\u514b\u670d\u4e86\u4f20\u7ed3\u96f6\u6837\u672c\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u4e3a3D CT\u8d85\u5206\u8fa8\u7387\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b0\u65b9\u6cd5"}}
{"id": "2508.15599", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15599", "abs": "https://arxiv.org/abs/2508.15599", "authors": ["P. H. C. de Souza", "M. Khazaee", "L. L. Mendes"], "title": "On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems", "comment": "To be published in the PIERS2025 Abu Dhabi proceedings", "summary": "The reconfigurable intelligent surface (RIS) technology for metasurfaces is\nushering in a new paradigm for wireless communication systems. It provides an\naccessible way for controlling the interaction between electromagnetic waves\nwith the propagation medium. One particularly important aspect is the\nconfiguration of the RIS elements or reflectors. Simply stated, the objective\nof the RIS configuration is to choose the optimum phase-shift combination that\nmaximizes the channel capacity. Recently, neural networks (NNs) were proposed\nfor tackling this task and results have shown that the proposed NN promotes far\nless reconfigurations of the RIS, consequently reducing the configuration\noverhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift\nin high-mobility communication systems. Despite not being its usual primary\ngoal, results have also demonstrated that the RIS can compensate for the\nDoppler shift at a small cost in performance. However, the typical\nreflection-only constraint for RIS systems limits the spatial coverage and\nsignal amplification potential achieved by such systems. Therefore, the\nsimultaneously transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) can be employed to address these limitations by its dual\nfunctionality of transmitting and reflecting signals concurrently. It can be\nshown that the STAR-RIS can augment coverage, energy efficiency, and latency\nreduction, while enhancing sum-rate and physical-layer security across several\nwireless contexts.", "AI": {"tldr": "STAR-RIS\u6280\u672f\u901a\u8fc7\u540c\u65f6\u4f20\u8f93\u548c\u53cd\u5c04\u4fe1\u53f7\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRIS\u7cfb\u7edf\u7684\u7a7a\u95f4\u8986\u76d6\u548c\u4fe1\u53f7\u653e\u5927\u9650\u5236\uff0c\u80fd\u591f\u63d0\u5347\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u8986\u76d6\u8303\u56f4\u3001\u80fd\u6548\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edfRIS\u7cfb\u7edf\u53d7\u9650\u4e8e\u4ec5\u53cd\u5c04\u529f\u80fd\uff0c\u9650\u5236\u4e86\u7a7a\u95f4\u8986\u76d6\u548c\u4fe1\u53f7\u653e\u5927\u6f5c\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f20\u8f93\u548c\u53cd\u5c04\u4fe1\u53f7\u7684\u65b0\u578b\u667a\u80fd\u8868\u9762\u6280\u672f\u6765\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u91c7\u7528\u540c\u65f6\u4f20\u8f93\u548c\u53cd\u5c04\u7684\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08STAR-RIS\uff09\u6280\u672f\uff0c\u901a\u8fc7\u5176\u53cc\u91cd\u529f\u80fd\u7279\u6027\uff0c\u540c\u65f6\u5904\u7406\u4f20\u8f93\u548c\u53cd\u5c04\u4fe1\u53f7\u3002", "result": "STAR-RIS\u80fd\u591f\u589e\u5f3a\u8986\u76d6\u8303\u56f4\u3001\u63d0\u9ad8\u80fd\u6548\u3001\u51cf\u5c11\u5ef6\u8fdf\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u65e0\u7ebf\u573a\u666f\u4e2d\u63d0\u5347\u603b\u901f\u7387\u548c\u7269\u7406\u5c42\u5b89\u5168\u6027\u3002", "conclusion": "STAR-RIS\u6280\u672f\u4ee3\u8868\u4e86\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5176\u72ec\u7279\u7684\u53cc\u529f\u80fd\u7279\u6027\uff0c\u4e3a\u89e3\u51b3\u4f20\u7edfRIS\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.15671", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15671", "abs": "https://arxiv.org/abs/2508.15671", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Saif Khan Mohammed", "Ronny Hadani", "Robert Calderbank"], "title": "Discrete Radar based on Modulo Arithmetic", "comment": "36 pages, 7 figures, submitted to EURASIP JASP", "summary": "Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler\n(DD) domain, converted to the time domain (DD) for transmission and reception,\nthen returned to the DD domain for processing. We describe how to use the same\narchitecture for radar sensing. The intended delay resolution is $\\frac{1}{B}$\nwhere $B$ is the radar bandwidth, and the intended Doppler resolution is\n$\\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in\nthe DD domain, illuminate the scattering environment, match filter the return,\nthen correlate with delay and Doppler shifts of the transmitted waveform. This\nproduces an image of the scattering environment, and the radar ambiguity\nfunction expresses the blurriness of this image. The possible delay and Doppler\nshifts generate the continuous Heisenberg-Weyl group which has been widely\nstudied in the theory of radar. We describe how to approach the problem of\nwaveform design, not from the perspective of this continuous group, but from\nthe perspective of a discrete group of delay and Doppler shifts, where the\ndiscretization is determined by the intended delay and Doppler resolution of\nthe radar. We describe how to approach the problem of shaping the ambiguity\nsurface through symplectic transformations that normalize our discrete\nHeisenberg-Weyl group. The complexity of traditional continuous radar signal\nprocessing is $\\mathcal{O}\\big(B^2T^2\\big)$. We describe how to reduce this\ncomplexity to $\\mathcal{O}\\big(BT\\log T\\big)$ by choosing the radar waveform to\nbe a common eigenvector of a maximal commutative subgroup of our discrete\nHeisenberg-Weyl group. The theory of symplectic transformations also enables\ndefining libraries of optimal radar waveforms with small peak-to-average power\nratios.", "AI": {"tldr": "Zak-OTFS\u8c03\u5236\u65b9\u6848\u7528\u4e8e\u96f7\u8fbe\u611f\u77e5\uff0c\u901a\u8fc7\u79bb\u6563\u6d77\u68ee\u5821-\u5916\u5c14\u7fa4\u548c\u8f9b\u53d8\u6362\u8bbe\u8ba1\u6ce2\u5f62\uff0c\u5c06\u4f20\u7edf\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u590d\u6742\u5ea6\u4eceO(B\u00b2T\u00b2)\u964d\u4f4e\u5230O(BT log T)\u3002", "motivation": "\u4f20\u7edf\u8fde\u7eed\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u96f7\u8fbe\u6ce2\u5f62\u8bbe\u8ba1\u548c\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u5728\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u5f62\u6210\u96f7\u8fbe\u6ce2\u5f62\uff0c\u901a\u8fc7\u5339\u914d\u6ee4\u6ce2\u548c\u76f8\u5173\u5904\u7406\uff0c\u5229\u7528\u79bb\u6563\u6d77\u68ee\u5821-\u5916\u5c14\u7fa4\u548c\u8f9b\u53d8\u6362\u8fdb\u884c\u6ce2\u5f62\u8bbe\u8ba1\u548c\u6a21\u7cca\u8868\u9762\u6574\u5f62\u3002", "result": "\u5b9e\u73b0\u4e86\u590d\u6742\u5ea6\u4eceO(B\u00b2T\u00b2)\u5230O(BT log T)\u7684\u663e\u8457\u964d\u4f4e\uff0c\u5e76\u80fd\u5b9a\u4e49\u5177\u6709\u5c0f\u5cf0\u5747\u529f\u7387\u6bd4\u7684\u6700\u4f18\u96f7\u8fbe\u6ce2\u5f62\u5e93\u3002", "conclusion": "\u57fa\u4e8e\u79bb\u6563\u7fa4\u548c\u8f9b\u53d8\u6362\u7684\u65b9\u6cd5\u4e3a\u96f7\u8fbe\u6ce2\u5f62\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u65b0\u9014\u5f84\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.15236", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15236", "abs": "https://arxiv.org/abs/2508.15236", "authors": ["Jiamu Wang", "Keunho Byeon", "Jinsol Song", "Anh Nguyen", "Sangjeong Ahn", "Sung Hak Lee", "Jin Tae Kwak"], "title": "Pathology-Informed Latent Diffusion Model for Anomaly Detection in Lymph Node Metastasis", "comment": null, "summary": "Anomaly detection is an emerging approach in digital pathology for its\nability to efficiently and effectively utilize data for disease diagnosis.\nWhile supervised learning approaches deliver high accuracy, they rely on\nextensively annotated datasets, suffering from data scarcity in digital\npathology. Unsupervised anomaly detection, however, offers a viable alternative\nby identifying deviations from normal tissue distributions without requiring\nexhaustive annotations. Recently, denoising diffusion probabilistic models have\ngained popularity in unsupervised anomaly detection, achieving promising\nperformance in both natural and medical imaging datasets. Building on this, we\nincorporate a vision-language model with a diffusion model for unsupervised\nanomaly detection in digital pathology, utilizing histopathology prompts during\nreconstruction. Our approach employs a set of pathology-related keywords\nassociated with normal tissues to guide the reconstruction process,\nfacilitating the differentiation between normal and abnormal tissues. To\nevaluate the effectiveness of the proposed method, we conduct experiments on a\ngastric lymph node dataset from a local hospital and assess its generalization\nability under domain shift using a public breast lymph node dataset. The\nexperimental results highlight the potential of the proposed method for\nunsupervised anomaly detection across various organs in digital pathology.\nCode: https://github.com/QuIIL/AnoPILaD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\u7684\u6570\u5b57\u75c5\u7406\u5b66\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u7ec4\u7ec7\u75c5\u7406\u5b66\u63d0\u793a\u8fdb\u884c\u91cd\u5efa\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u5373\u53ef\u533a\u5206\u6b63\u5e38\u548c\u5f02\u5e38\u7ec4\u7ec7\u3002", "motivation": "\u6570\u5b57\u75c5\u7406\u5b66\u4e2d\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u4e2d\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u3002\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u901a\u8fc7\u8bc6\u522b\u4e0e\u6b63\u5e38\u7ec4\u7ec7\u5206\u5e03\u7684\u504f\u5dee\u6765\u907f\u514d\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u6269\u6563\u6a21\u578b\u5728\u8be5\u9886\u57df\u5c55\u73b0\u51fa\u6f5c\u529b\u3002", "method": "\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u6269\u6563\u6a21\u578b\u7ed3\u5408\uff0c\u4f7f\u7528\u4e00\u7ec4\u4e0e\u6b63\u5e38\u7ec4\u7ec7\u76f8\u5173\u7684\u75c5\u7406\u5b66\u5173\u952e\u8bcd\u4f5c\u4e3a\u63d0\u793a\u6765\u6307\u5bfc\u91cd\u5efa\u8fc7\u7a0b\uff0c\u5e2e\u52a9\u533a\u5206\u6b63\u5e38\u548c\u5f02\u5e38\u7ec4\u7ec7\u3002", "result": "\u5728\u672c\u5730\u533b\u9662\u80c3\u6dcb\u5df4\u7ed3\u6570\u636e\u96c6\u548c\u516c\u5171\u4e73\u817a\u6dcb\u5df4\u7ed3\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5728\u9886\u57df\u8f6c\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u6570\u5b57\u75c5\u7406\u5b66\u4e0d\u540c\u5668\u5b98\u4e2d\u8fdb\u884c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u7684\u6f5c\u529b\uff0c\u4e3a\u51cf\u5c11\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.15251", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15251", "abs": "https://arxiv.org/abs/2508.15251", "authors": ["Aqib Nazir Mir", "Danish Raza Rizvi"], "title": "Explainable Knowledge Distillation for Efficient Medical Image Classification", "comment": null, "summary": "This study comprehensively explores knowledge distillation frameworks for\nCOVID-19 and lung cancer classification using chest X-ray (CXR) images. We\nemploy high-capacity teacher models, including VGG19 and lightweight Vision\nTransformers (Visformer-S and AutoFormer-V2-T), to guide the training of a\ncompact, hardware-aware student model derived from the OFA-595 supernet. Our\napproach leverages hybrid supervision, combining ground-truth labels with\nteacher models' soft targets to balance accuracy and computational efficiency.\nWe validate our models on two benchmark datasets: COVID-QU-Ex and LCS25000,\ncovering multiple classes, including COVID-19, healthy, non-COVID pneumonia,\nlung, and colon cancer. To interpret the spatial focus of the models, we employ\nScore-CAM-based visualizations, which provide insight into the reasoning\nprocess of both teacher and student networks. The results demonstrate that the\ndistilled student model maintains high classification performance with\nsignificantly reduced parameters and inference time, making it an optimal\nchoice in resource-constrained clinical environments. Our work underscores the\nimportance of combining model efficiency with explainability for practical,\ntrustworthy medical AI solutions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684COVID-19\u548c\u80ba\u764c\u5206\u7c7b\u6846\u67b6\uff0c\u4f7f\u7528\u9ad8\u5bb9\u91cf\u6559\u5e08\u6a21\u578b\u6307\u5bfc\u7d27\u51d1\u5b66\u751f\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u53c2\u6570\u548c\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u5f00\u53d1\u5728\u8d44\u6e90\u53d7\u9650\u7684\u4e34\u5e8a\u73af\u5883\u4e2d\u5b9e\u7528\u7684\u533b\u7597AI\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8981\u5e73\u8861\u6a21\u578b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u786e\u4fdd\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4ee5\u5efa\u7acb\u4e34\u5e8a\u4fe1\u4efb\u3002", "method": "\u91c7\u7528VGG19\u548c\u8f7b\u91cf\u7ea7Vision Transformers\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u6765\u81eaOFA-595\u8d85\u7f51\u7684\u7d27\u51d1\u5b66\u751f\u6a21\u578b\uff0c\u7ed3\u5408\u771f\u5b9e\u6807\u7b7e\u548c\u6559\u5e08\u8f6f\u76ee\u6807\u8fdb\u884c\u6df7\u5408\u76d1\u7763\uff0c\u5e76\u4f7f\u7528Score-CAM\u53ef\u89c6\u5316\u89e3\u91ca\u6a21\u578b\u51b3\u7b56\u3002", "result": "\u84b8\u998f\u540e\u7684\u5b66\u751f\u6a21\u578b\u5728COVID-QU-Ex\u548cLCS25000\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u9ad8\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\u548c\u63a8\u7406\u65f6\u95f4\uff0c\u9002\u5408\u4e34\u5e8a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5c06\u6a21\u578b\u6548\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\u76f8\u7ed3\u5408\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u5f00\u53d1\u5b9e\u7528\u3001\u53ef\u4fe1\u8d56\u7684\u533b\u7597AI\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5728\u533b\u7597\u5f71\u50cf\u5206\u7c7b\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.15673", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15673", "abs": "https://arxiv.org/abs/2508.15673", "authors": ["Enrico Testi", "Giulia Torcolacci", "Nicol\u00f2 Decarli", "Davide Dardari", "Enrico Paolini"], "title": "A Grant-free Coded Random Access Scheme for Near-field Communications", "comment": null, "summary": "The industrial Internet of things (IIoT) is revolutionizing industrial\nprocesses by facilitating massive machine-type communications among countless\ninterconnected devices. To efficiently handle the resulting large-scale and\nsporadic traffic, grant-free random access protocols-especially coded random\naccess (CRA)-have emerged as scalable and reliable solutions. At the same time,\nadvancements in wireless hardware, including extremely large-scale MIMO arrays\nand high-frequency communication (e.g., mmWave, Terahertz), are pushing network\noperations into the near-field propagation regime, allowing for dense\nconnectivity and enhanced spatial multiplexing. This paper proposes an\ninnovative approach that combines near-field spatial multiplexing with the\ninterference mitigation capabilities of CRA, utilizing an extremely large\naperture array at the access point. This integration improves reliability and\nreduces access latency, offering a robust framework for IIoT connectivity in\nnext-generation 6G networks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u5c06\u8fd1\u573a\u7a7a\u95f4\u590d\u7528\u4e0e\u7f16\u7801\u968f\u673a\u8bbf\u95ee\u534f\u8bae\u76f8\u7ed3\u5408\uff0c\u5229\u7528\u6781\u5927\u5f3a\u5ea6MIMO\u6570\u7ec4\u63d0\u5347IIoT\u8fde\u63a5\u7684\u53ef\u9760\u6027\u548c\u964d\u4f4e\u8bbf\u95ee\u5ef6\u8fdf\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51(IIoT)\u9700\u8981\u5904\u7406\u5927\u89c4\u6a21\u95f4\u969c\u6027\u6d41\u91cf\uff0c\u800c\u65e0\u6388\u6743\u968f\u673a\u8bbf\u95ee\u534f\u8bae\u662f\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002\u540c\u65f6\uff0c\u65b0\u578b\u65e0\u7ebf\u786c\u4ef6\u6280\u672f\u5c06\u7f51\u7edc\u8fd0\u884c\u63a8\u5411\u8fd1\u573a\u4f20\u64ad\u6cbb\u7406\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u5229\u7528\u8fd9\u4e9b\u7279\u6027\u63d0\u5347IIoT\u6027\u80fd\u3002", "method": "\u7ed3\u5408\u8fd1\u573a\u7a7a\u95f4\u590d\u7528\u6280\u672f\u548c\u7f16\u7801\u968f\u673a\u8bbf\u95ee(CRA)\u534f\u8bae\uff0c\u5229\u7528\u6781\u5927\u5f3a\u5ea6MIMO\u6570\u7ec4\u5728\u63a5\u5165\u70b9\u8fdb\u884c\u5e72\u6270\u963b\u7f13\u89e3\u3002\u901a\u8fc7\u8fd1\u573a\u4f20\u64ad\u7684\u7279\u6027\u5b9e\u73b0\u5bc6\u96c6\u8fde\u63a5\u548c\u66f4\u597d\u7684\u7a7a\u95f4\u590d\u7528\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86IIoT\u8fde\u63a5\u7684\u53ef\u9760\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bbf\u95ee\u5ef6\u8fdf\uff0c\u4e3a\u4e0b\u4e00\u4ee36G\u7f51\u7edc\u4e2d\u7684\u5de5\u4e1a\u7269\u8054\u7f51\u5e94\u7528\u63d0\u4f9b\u4e86\u5065\u58c1\u7684\u8fde\u63a5\u6846\u67b6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6210\u529f\u5c06\u8fd1\u573a\u7a7a\u95f4\u590d\u7528\u4e0e\u7f16\u7801\u968f\u673a\u8bbf\u95ee\u534f\u8bae\u76f8\u7ed3\u5408\uff0c\u4e3aIIoT\u5927\u89c4\u6a21\u8bbe\u5907\u901a\u4fe1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.15379", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15379", "abs": "https://arxiv.org/abs/2508.15379", "authors": ["Jinliang Yu", "Mingduo Xie", "Yue Wang", "Tianfan Fu", "Xianglai Xu", "Jiajun Wang"], "title": "Bladder Cancer Diagnosis with Deep Learning: A Multi-Task Framework and Online Platform", "comment": null, "summary": "Clinical cystoscopy, the current standard for bladder cancer diagnosis,\nsuffers from significant reliance on physician expertise, leading to\nvariability and subjectivity in diagnostic outcomes. There is an urgent need\nfor objective, accurate, and efficient computational approaches to improve\nbladder cancer diagnostics.\n  Leveraging recent advancements in deep learning, this study proposes an\nintegrated multi-task deep learning framework specifically designed for bladder\ncancer diagnosis from cystoscopic images. Our framework includes a robust\nclassification model using EfficientNet-B0 enhanced with Convolutional Block\nAttention Module (CBAM), an advanced segmentation model based on\nResNet34-UNet++ architecture with self-attention mechanisms and attention\ngating, and molecular subtyping using ConvNeXt-Tiny to classify molecular\nmarkers such as HER-2 and Ki-67. Additionally, we introduce a Gradio-based\nonline diagnostic platform integrating all developed models, providing\nintuitive features including multi-format image uploads, bilingual interfaces,\nand dynamic threshold adjustments.\n  Extensive experimentation demonstrates the effectiveness of our methods,\nachieving outstanding accuracy (93.28%), F1-score (82.05%), and AUC (96.41%)\nfor classification tasks, and exceptional segmentation performance indicated by\na Dice coefficient of 0.9091. The online platform significantly improved the\naccuracy, efficiency, and accessibility of clinical bladder cancer diagnostics,\nenabling practical and user-friendly deployment. The code is publicly\navailable.\n  Our multi-task framework and integrated online tool collectively advance the\nfield of intelligent bladder cancer diagnosis by improving clinical\nreliability, supporting early tumor detection, and enabling real-time\ndiagnostic feedback. These contributions mark a significant step toward\nAI-assisted decision-making in urology.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u4efb\u52a1\u6846\u67b6\uff0c\u7528\u4e8e\u8180\u80f1\u764c\u7684\u667a\u80fd\u8bca\u65ad\uff0c\u5305\u62ec\u5206\u7c7b\u3001\u5206\u5272\u548c\u5206\u5b50\u5206\u578b\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u5728\u7ebf\u8bca\u65ad\u5e73\u53f0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u8180\u80f1\u764c\u8bca\u65ad\u4e3b\u8981\u4f9d\u8d56\u533b\u751f\u7ecf\u9a8c\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u5ba2\u89c2\u3001\u51c6\u786e\u7684\u8ba1\u7b97\u65b9\u6cd5\u6765\u6539\u5584\u8bca\u65ad\u6548\u679c\u3002", "method": "\u91c7\u7528\u591a\u4efb\u52a1\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff1aEfficientNet-B0+CBAM\u8fdb\u884c\u5206\u7c7b\uff0cResNet34-UNet+++\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u5206\u5272\uff0cConvNeXt-Tiny\u8fdb\u884c\u5206\u5b50\u5206\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eGradio\u7684\u5728\u7ebf\u8bca\u65ad\u5e73\u53f0\u3002", "result": "\u5206\u7c7b\u4efb\u52a1\u8fbe\u523093.28%\u51c6\u786e\u7387\u300182.05% F1\u5206\u6570\u548c96.41% AUC\uff0c\u5206\u5272\u4efb\u52a1Dice\u7cfb\u6570\u8fbe0.9091\uff0c\u5728\u7ebf\u5e73\u53f0\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u53ca\u6027\u3002", "conclusion": "\u8be5\u591a\u4efb\u52a1\u6846\u67b6\u548c\u96c6\u6210\u5728\u7ebf\u5de5\u5177\u901a\u8fc7\u63d0\u9ad8\u4e34\u5e8a\u53ef\u9760\u6027\u3001\u652f\u6301\u65e9\u671f\u80bf\u7624\u68c0\u6d4b\u548c\u5b9e\u73b0\u5b9e\u65f6\u8bca\u65ad\u53cd\u9988\uff0c\u63a8\u52a8\u4e86\u667a\u80fd\u8180\u80f1\u764c\u8bca\u65ad\u9886\u57df\u7684\u53d1\u5c55\uff0c\u662f\u6ccc\u5c3f\u5916\u79d1AI\u8f85\u52a9\u51b3\u7b56\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2508.15687", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15687", "abs": "https://arxiv.org/abs/2508.15687", "authors": ["Masoud Nateghi", "Reza Sameni"], "title": "Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings", "comment": null, "summary": "Oscillometry is the standard method for non-invasive, cuff-based blood\npressure (BP) measurement, but it introduces systematic errors that may impact\nclinical accuracy. This study investigates the sources of these\nerrors--primarily the limitations of oscillometry itself and\nrespiration-induced fluctuations--using BP waveform data from the MIMIC\ndatabase. Oscillometry tends to underestimate systolic BP and overestimate\ndiastolic BP, while respiration introduces cyclical variations that further\ndegrade measurement precision. To mitigate these effects, we propose an\nestimation-theoretic framework employing least squares (LS) and maximum\nlikelihood (ML) methods for correcting both single and repeated BP\nmeasurements. LS estimation supports conventional multi-measurement averaging\nprotocols, whereas the ML approach incorporates prior knowledge of measurement\nerrors, offering improved performance. Our results demonstrate that leveraging\nstatistical priors across multiple readings can enhance the accuracy of\nnon-invasive BP monitoring, with potential implications for improving\ncardiovascular diagnosis and treatment.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u793a\u6ce2\u6cd5\u8840\u538b\u6d4b\u91cf\u7684\u7cfb\u7edf\u8bef\u5dee\u6765\u6e90\uff0c\u63d0\u51fa\u57fa\u4e8e\u6700\u5c0f\u4e8c\u4e58\u548c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u7edf\u8ba1\u6821\u6b63\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6d4b\u91cf\u5e73\u5747\u548c\u5148\u9a8c\u77e5\u8bc6\u6574\u5408\u6765\u63d0\u9ad8\u975e\u4fb5\u5165\u6027\u8840\u538b\u76d1\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u793a\u6ce2\u6cd5\u4f5c\u4e3a\u6807\u51c6\u7684\u65e0\u521b\u8896\u5e26\u8840\u538b\u6d4b\u91cf\u65b9\u6cd5\u5b58\u5728\u7cfb\u7edf\u8bef\u5dee\uff0c\u53ef\u80fd\u5f71\u54cd\u4e34\u5e8a\u51c6\u786e\u6027\u3002\u7814\u7a76\u65e8\u5728\u8bc6\u522b\u8fd9\u4e9b\u8bef\u5dee\u6765\u6e90\uff08\u4e3b\u8981\u662f\u793a\u6ce2\u6cd5\u81ea\u8eab\u5c40\u9650\u6027\u548c\u547c\u5438\u5f15\u8d77\u7684\u6ce2\u52a8\uff09\uff0c\u5e76\u5f00\u53d1\u6821\u6b63\u65b9\u6cd5\u6765\u63d0\u9ad8\u6d4b\u91cf\u7cbe\u5ea6\u3002", "method": "\u4f7f\u7528MIMIC\u6570\u636e\u5e93\u7684\u8840\u538b\u6ce2\u5f62\u6570\u636e\uff0c\u63d0\u51fa\u57fa\u4e8e\u4f30\u8ba1\u7406\u8bba\u7684\u6846\u67b6\uff0c\u91c7\u7528\u6700\u5c0f\u4e8c\u4e58(LS)\u548c\u6700\u5927\u4f3c\u7136(ML)\u65b9\u6cd5\u5bf9\u5355\u6b21\u548c\u91cd\u590d\u8840\u538b\u6d4b\u91cf\u8fdb\u884c\u6821\u6b63\u3002LS\u652f\u6301\u4f20\u7edf\u7684\u591a\u6d4b\u91cf\u5e73\u5747\u534f\u8bae\uff0cML\u65b9\u6cd5\u5219\u6574\u5408\u6d4b\u91cf\u8bef\u5dee\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u793a\u6ce2\u6cd5\u503e\u5411\u4e8e\u4f4e\u4f30\u6536\u7f29\u538b\u548c\u9ad8\u4f30\u8212\u5f20\u538b\uff0c\u547c\u5438\u5f15\u5165\u7684\u5468\u671f\u6027\u53d8\u5316\u8fdb\u4e00\u6b65\u964d\u4f4e\u6d4b\u91cf\u7cbe\u5ea6\u3002\u7edf\u8ba1\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u591a\u4e2a\u8bfb\u6570\u7684\u7edf\u8ba1\u5148\u9a8c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u975e\u4fb5\u5165\u6027\u8840\u538b\u76d1\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u8ba1\u6821\u6b63\u6846\u67b6\u80fd\u6709\u6548\u51cf\u8f7b\u793a\u6ce2\u6cd5\u8840\u538b\u6d4b\u91cf\u7684\u7cfb\u7edf\u8bef\u5dee\uff0c\u5bf9\u6539\u5584\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u548c\u6cbb\u7597\u5177\u6709\u6f5c\u5728\u91cd\u8981\u610f\u4e49\uff0c\u7279\u522b\u662f\u6700\u5927\u4f3c\u7136\u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15452", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15452", "abs": "https://arxiv.org/abs/2508.15452", "authors": ["U\u011furcan Aky\u00fcz", "Deniz Katircioglu-\u00d6zt\u00fcrk", "Emre K. S\u00fcsl\u00fc", "Burhan Kele\u015f", "Mete C. Kaya", "Gamze Durhan", "Meltem G. Akp\u0131nar", "Figen B. Demirkaz\u0131k", "G\u00f6zde B. Akar"], "title": "DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation", "comment": null, "summary": "Numerous deep learning-based solutions have been developed for the automatic\nrecognition of breast cancer using mammography images. However, their\nperformance often declines when applied to data from different domains,\nprimarily due to domain shift - the variation in data distributions between\nsource and target domains. This performance drop limits the safe and equitable\ndeployment of AI in real-world clinical settings. In this study, we present\nDoSReMC (Domain Shift Resilient Mammography Classification), a batch\nnormalization (BN) adaptation framework designed to enhance cross-domain\ngeneralization without retraining the entire model. Using three large-scale\nfull-field digital mammography (FFDM) datasets - including HCTP, a newly\nintroduced, pathologically confirmed in-house dataset - we conduct a systematic\ncross-domain evaluation with convolutional neural networks (CNNs). Our results\ndemonstrate that BN layers are a primary source of domain dependence: they\nperform effectively when training and testing occur within the same domain, and\nthey significantly impair model generalization under domain shift. DoSReMC\naddresses this limitation by fine-tuning only the BN and fully connected (FC)\nlayers, while preserving pretrained convolutional filters. We further integrate\nthis targeted adaptation with an adversarial training scheme, yielding\nadditional improvements in cross-domain generalizability. DoSReMC can be\nreadily incorporated into existing AI pipelines and applied across diverse\nclinical environments, providing a practical pathway toward more robust and\ngeneralizable mammography classification systems.", "AI": {"tldr": "DoSReMC\u662f\u4e00\u4e2a\u9488\u5bf9\u4e73\u817a\u94bc\u9776\u56fe\u50cf\u5206\u7c7b\u7684\u6279\u5f52\u4e00\u5316\u5c42\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u4ec5\u5fae\u8c03BN\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u6765\u63d0\u5347\u8de8\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4e73\u817a\u94bc\u9776\u56fe\u50cf\u8bc6\u522b\u4e2d\u9762\u4e34\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5bfc\u81f4\u5728\u4e0d\u540c\u57df\u6570\u636e\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u9650\u5236\u4e86AI\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u516c\u5e73\u90e8\u7f72\u3002", "method": "\u63d0\u51faDoSReMC\u6846\u67b6\uff0c\u4ec5\u5fae\u8c03\u6279\u5f52\u4e00\u5316(BN)\u5c42\u548c\u5168\u8fde\u63a5(FC)\u5c42\uff0c\u4fdd\u6301\u9884\u8bad\u7ec3\u5377\u79ef\u6ee4\u6ce2\u5668\u4e0d\u53d8\uff0c\u5e76\u7ed3\u5408\u5bf9\u6297\u8bad\u7ec3\u65b9\u6848\u63d0\u5347\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eBN\u5c42\u662f\u57df\u4f9d\u8d56\u7684\u4e3b\u8981\u6765\u6e90\uff0cDoSReMC\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u8de8\u57df\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u53ef\u5728\u73b0\u6709AI\u7ba1\u9053\u4e2d\u8f7b\u677e\u96c6\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u4e73\u817a\u94bc\u9776\u5206\u7c7b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u4e34\u5e8a\u73af\u5883\u3002"}}
{"id": "2508.15553", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15553", "abs": "https://arxiv.org/abs/2508.15553", "authors": ["Jin Ye", "Jingran Wang", "Fengchao Xiong", "Jingzhou Chen", "Yuntao Qian"], "title": "Deep Equilibrium Convolutional Sparse Coding for Hyperspectral Image Denoising", "comment": null, "summary": "Hyperspectral images (HSIs) play a crucial role in remote sensing but are\noften degraded by complex noise patterns. Ensuring the physical property of the\ndenoised HSIs is vital for robust HSI denoising, giving the rise of deep\nunfolding-based methods. However, these methods map the optimization of a\nphysical model to a learnable network with a predefined depth, which lacks\nconvergence guarantees. In contrast, Deep Equilibrium (DEQ) models treat the\nhidden layers of deep networks as the solution to a fixed-point problem and\nmodels them as infinite-depth networks, naturally consistent with the\noptimization. Under the framework of DEQ, we propose a Deep Equilibrium\nConvolutional Sparse Coding (DECSC) framework that unifies local\nspatial-spectral correlations, nonlocal spatial self-similarities, and global\nspatial consistency for robust HSI denoising. Within the convolutional sparse\ncoding (CSC) framework, we enforce shared 2D convolutional sparse\nrepresentation to ensure global spatial consistency across bands, while\nunshared 3D convolutional sparse representation captures local spatial-spectral\ndetails. To further exploit nonlocal self-similarities, a transformer block is\nembedded after the 2D CSC. Additionally, a detail enhancement module is\nintegrated with the 3D CSC to promote image detail preservation. We formulate\nthe proximal gradient descent of the CSC model as a fixed-point problem and\ntransform the iterative updates into a learnable network architecture within\nthe framework of DEQ. Experimental results demonstrate that our DECSC method\nachieves superior denoising performance compared to state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5747\u8861\u6a21\u578b\u7684\u5377\u79ef\u7a00\u758f\u7f16\u7801\u6846\u67b6DECSC\uff0c\u7edf\u4e00\u5229\u7528\u5c40\u90e8\u7a7a\u95f4-\u5149\u8c31\u76f8\u5173\u6027\u3001\u975e\u5c40\u90e8\u7a7a\u95f4\u81ea\u76f8\u4f3c\u6027\u548c\u5168\u5c40\u7a7a\u95f4\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u9ad8\u5149\u8c31\u56fe\u50cf\u53bb\u566a", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5c55\u5f00\u65b9\u6cd5\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\uff0c\u800c\u6df1\u5ea6\u5747\u8861\u6a21\u578b\u81ea\u7136\u7b26\u5408\u4f18\u5316\u8fc7\u7a0b\uff0c\u80fd\u591f\u63d0\u4f9b\u65e0\u9650\u6df1\u5ea6\u7f51\u7edc\u8868\u793a", "method": "\u5728\u5377\u79ef\u7a00\u758f\u7f16\u7801\u6846\u67b6\u4e2d\u7ed3\u54082D\u548c3D\u5377\u79ef\u7a00\u758f\u8868\u793a\uff0c\u5d4c\u5165Transformer\u5757\u5229\u7528\u975e\u5c40\u90e8\u81ea\u76f8\u4f3c\u6027\uff0c\u96c6\u6210\u7ec6\u8282\u589e\u5f3a\u6a21\u5757\uff0c\u5e76\u901a\u8fc7\u6df1\u5ea6\u5747\u8861\u6a21\u578b\u5c06\u8fed\u4ee3\u66f4\u65b0\u8f6c\u5316\u4e3a\u53ef\u5b66\u4e60\u7f51\u7edc", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eDECSC\u65b9\u6cd5\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u53bb\u566a\u6027\u80fd", "conclusion": "\u6240\u63d0\u51fa\u7684DECSC\u6846\u67b6\u6709\u6548\u7edf\u4e00\u4e86\u591a\u79cd\u7279\u5f81\u8868\u793a\uff0c\u5728\u6df1\u5ea6\u5747\u8861\u6a21\u578b\u6846\u67b6\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u7684\u9ad8\u5149\u8c31\u56fe\u50cf\u53bb\u566a"}}
{"id": "2508.15594", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15594", "abs": "https://arxiv.org/abs/2508.15594", "authors": ["Ana C. Perre", "Lu\u00eds A. Alexandre", "Lu\u00eds C. Freire"], "title": "Are Virtual DES Images a Valid Alternative to the Real Ones?", "comment": "10 pages, 4 figures, 3 tables", "summary": "Contrast-enhanced spectral mammography (CESM) is an imaging modality that\nprovides two types of images, commonly known as low-energy (LE) and dual-energy\nsubtracted (DES) images. In many domains, particularly in medicine, the\nemergence of image-to-image translation techniques has enabled the artificial\ngeneration of images using other images as input. Within CESM, applying such\ntechniques to generate DES images from LE images could be highly beneficial,\npotentially reducing patient exposure to radiation associated with high-energy\nimage acquisition. In this study, we investigated three models for the\nartificial generation of DES images (virtual DES): a pre-trained U-Net model, a\nU-Net trained end-to-end model, and a CycleGAN model. We also performed a\nseries of experiments to assess the impact of using virtual DES images on the\nclassification of CESM examinations into malignant and non-malignant\ncategories. To our knowledge, this is the first study to evaluate the impact of\nvirtual DES images on CESM lesion classification. The results demonstrate that\nthe best performance was achieved with the pre-trained U-Net model, yielding an\nF1 score of 85.59% when using the virtual DES images, compared to 90.35% with\nthe real DES images. This discrepancy likely results from the additional\ndiagnostic information in real DES images, which contributes to a higher\nclassification accuracy. Nevertheless, the potential for virtual DES image\ngeneration is considerable and future advancements may narrow this performance\ngap to a level where exclusive reliance on virtual DES images becomes\nclinically viable.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528U-Net\u548cCycleGAN\u6a21\u578b\u4ece\u4f4e\u80fd\u91cf\u56fe\u50cf\u751f\u6210\u865a\u62df\u53cc\u80fd\u91cf\u51cf\u5f71\u56fe\u50cf\uff0c\u8bc4\u4f30\u5176\u5728\u4e73\u817a\u75c5\u53d8\u5206\u7c7b\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3U-Net\u8868\u73b0\u6700\u4f73\u4f46\u7565\u900a\u4e8e\u771f\u5b9e\u56fe\u50cf\u3002", "motivation": "\u901a\u8fc7\u56fe\u50cf\u751f\u6210\u6280\u672f\u4ece\u4f4e\u80fd\u91cf\u56fe\u50cf\u751f\u6210\u53cc\u80fd\u91cf\u51cf\u5f71\u56fe\u50cf\uff0c\u53ef\u51cf\u5c11\u60a3\u8005\u63a5\u53d7\u9ad8\u80fd\u91cf\u6210\u50cf\u65f6\u7684\u8f90\u5c04\u66b4\u9732\uff0c\u5177\u6709\u91cd\u8981\u7684\u4e34\u5e8a\u610f\u4e49\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u6a21\u578b\uff1a\u9884\u8bad\u7ec3U-Net\u3001\u7aef\u5230\u7aef\u8bad\u7ec3U-Net\u548cCycleGAN\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u865a\u62dfDES\u56fe\u50cf\uff0c\u5e76\u8bc4\u4f30\u8fd9\u4e9b\u865a\u62df\u56fe\u50cf\u5728\u6076\u6027/\u975e\u6076\u6027\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u9884\u8bad\u7ec3U-Net\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f7f\u7528\u865a\u62dfDES\u56fe\u50cf\u83b7\u5f9785.59%\u7684F1\u5206\u6570\uff0c\u800c\u4f7f\u7528\u771f\u5b9eDES\u56fe\u50cf\u4e3a90.35%\uff0c\u5b58\u5728\u4e00\u5b9a\u6027\u80fd\u5dee\u8ddd\u4f46\u6f5c\u529b\u663e\u8457\u3002", "conclusion": "\u865a\u62dfDES\u56fe\u50cf\u751f\u6210\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u672a\u6765\u6280\u672f\u8fdb\u6b65\u53ef\u80fd\u7f29\u5c0f\u6027\u80fd\u5dee\u8ddd\uff0c\u4f7f\u5176\u5728\u4e34\u5e8a\u4e0a\u53ef\u884c\uff0c\u4ece\u800c\u51cf\u5c11\u60a3\u8005\u8f90\u5c04\u66b4\u9732\u3002"}}
{"id": "2508.15635", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.15635", "abs": "https://arxiv.org/abs/2508.15635", "authors": ["Malini Shivaram", "Gautam Rajendrakumar Gare", "Laura Hutchins", "Jacob Duplantis", "Thomas Deiss", "Thales Nogueira Gomes", "Thong Tran", "Keyur H. Patel", "Thomas H Fox", "Amita Krishnan", "Deva Ramanan", "Bennett DeBoisblanc", "Ricardo Rodriguez", "John Galeotti"], "title": "Label Uncertainty for Ultrasound Segmentation", "comment": "Paper under review", "summary": "In medical imaging, inter-observer variability among radiologists often\nintroduces label uncertainty, particularly in modalities where visual\ninterpretation is subjective. Lung ultrasound (LUS) is a prime example-it\nfrequently presents a mixture of highly ambiguous regions and clearly\ndiscernible structures, making consistent annotation challenging even for\nexperienced clinicians. In this work, we introduce a novel approach to both\nlabeling and training AI models using expert-supplied, per-pixel confidence\nvalues. Rather than treating annotations as absolute ground truth, we design a\ndata annotation protocol that captures the confidence that radiologists have in\neach labeled region, modeling the inherent aleatoric uncertainty present in\nreal-world clinical data. We demonstrate that incorporating these confidence\nvalues during training leads to improved segmentation performance. More\nimportantly, we show that this enhanced segmentation quality translates into\nbetter performance on downstream clinically-critical tasks-specifically,\nestimating S/F oxygenation ratio values, classifying S/F ratio change, and\npredicting 30-day patient readmission. While we empirically evaluate many\nmethods for exposing the uncertainty to the learning model, we find that a\nsimple approach that trains a model on binarized labels obtained with a (60%)\nconfidence threshold works well. Importantly, high thresholds work far better\nthan a naive approach of a 50% threshold, indicating that training on very\nconfident pixels is far more effective. Our study systematically investigates\nthe impact of training with varying confidence thresholds, comparing not only\nsegmentation metrics but also downstream clinical outcomes. These results\nsuggest that label confidence is a valuable signal that, when properly\nleveraged, can significantly enhance the reliability and clinical utility of AI\nin medical imaging.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u533b\u5b66\u5f71\u50cf\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u6536\u96c6\u5c04\u5f69\u79d1\u533b\u751f\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u7684\u4fe1\u5fc3\u503c\u6765\u6a21\u578b\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u8bad\u7ec3AI\u6a21\u578b\u65f6\u5229\u7528\u8fd9\u4e9b\u4fe1\u5fc3\u503c\u63d0\u9ad8\u5206\u5272\u548c\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u533b\u5b66\u5f71\u50cf\u4e2d\u89c2\u5bdf\u8005\u95f4\u7684\u6807\u6ce8\u53d8\u5f02\u6027\u5f15\u5165\u4e86\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u80ba\u90e8\u8d85\u58f0\u8fd9\u79cd\u89c6\u89c9\u89e3\u91ca\u4e3b\u89c2\u6027\u5f3a\u7684\u6a21\u6001\u4e2d\u3002\u4f20\u7edf\u7684\u7edd\u5bf9\u771f\u5b9e\u6807\u7b7e\u65b9\u6cd5\u65e0\u6cd5\u6293\u53d6\u8fd9\u79cd\u5185\u5728\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6570\u636e\u6807\u6ce8\u534f\u8bae\uff0c\u6536\u96c6\u5c04\u5f69\u79d1\u533b\u751f\u5bf9\u6bcf\u4e2a\u6807\u6ce8\u533a\u57df\u7684\u4fe1\u5fc3\u503c\u3002\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u4e0d\u540c\u4fe1\u5fc3\u9608\u503c\uff0860%\uff09\u6765\u4e8c\u503c\u5316\u6807\u7b7e\uff0c\u5e76\u5bf9\u6bd4\u4e86\u591a\u79cd\u5c55\u73b0\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u8bad\u7ec3\u65f6\u7ed3\u5408\u4fe1\u5fc3\u503c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5206\u5272\u6027\u80fd\uff0c\u5e76\u4f18\u5316\u4e0b\u6e38\u4e34\u5e8a\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u5305\u62ecS/F\u6c27\u5408\u6bd4\u4f30\u8ba1\u3001S/F\u6bd4\u503c\u53d8\u5316\u5206\u7c7b\u548c30\u5929\u518d\u5165\u9662\u9884\u6d4b\u3002\u9ad8\u4fe1\u5fc3\u9608\u503c\uff0860%\uff09\u6bd4\u4f4e\u9608\u503c\uff0850%\uff09\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u6807\u7b7e\u4fe1\u5fc3\u503c\u662f\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u4fe1\u53f7\uff0c\u901a\u8fc7\u5408\u7406\u5229\u7528\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8AI\u5728\u533b\u5b66\u5f71\u50cf\u4e2d\u7684\u53ef\u9760\u6027\u548c\u4e34\u5e8a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.15660", "categories": ["eess.IV", "cs.CV", "I.4.6; I.5.4; J.3"], "pdf": "https://arxiv.org/pdf/2508.15660", "abs": "https://arxiv.org/abs/2508.15660", "authors": ["Alexandra Bernadotte", "Elfimov Nikita", "Mikhail Shutov", "Ivan Menshikov"], "title": "Hessian-based lightweight neural network for brain vessel segmentation on a minimal training dataset", "comment": "11 pages, 2 figures", "summary": "Accurate segmentation of blood vessels in brain magnetic resonance\nangiography (MRA) is essential for successful surgical procedures, such as\naneurysm repair or bypass surgery. Currently, annotation is primarily performed\nthrough manual segmentation or classical methods, such as the Frangi filter,\nwhich often lack sufficient accuracy. Neural networks have emerged as powerful\ntools for medical image segmentation, but their development depends on\nwell-annotated training datasets. However, there is a notable lack of publicly\navailable MRA datasets with detailed brain vessel annotations.\n  To address this gap, we propose a novel semi-supervised learning lightweight\nneural network with Hessian matrices on board for 3D segmentation of complex\nstructures such as tubular structures, which we named HessNet. The solution is\na Hessian-based neural network with only 6000 parameters. HessNet can run on\nthe CPU and significantly reduces the resource requirements for training neural\nnetworks. The accuracy of vessel segmentation on a minimal training dataset\nreaches state-of-the-art results. It helps us create a large, semi-manually\nannotated brain vessel dataset of brain MRA images based on the IXI dataset\n(annotated 200 images). Annotation was performed by three experts under the\nsupervision of three neurovascular surgeons after applying HessNet. It provides\nhigh accuracy of vessel segmentation and allows experts to focus only on the\nmost complex important cases. The dataset is available at\nhttps://git.scinalytics.com/terilat/VesselDatasetPartly.", "AI": {"tldr": "\u63d0\u51faHessNet\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u8111MRA\u8840\u7ba1\u5206\u5272\uff0c\u4ec5\u97006000\u53c2\u6570\u53ef\u5728CPU\u8fd0\u884c\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u5e76\u57fa\u4e8e\u6b64\u521b\u5efa\u4e86\u534a\u624b\u52a8\u6807\u6ce8\u7684\u8111\u8840\u7ba1\u6570\u636e\u96c6", "motivation": "\u8111\u78c1\u5171\u632f\u8840\u7ba1\u6210\u50cf(MRA)\u4e2d\u8840\u7ba1\u7684\u7cbe\u786e\u5206\u5272\u5bf9\u624b\u672f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u516c\u5f00\u7684\u8be6\u7ec6\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u7cbe\u5ea6\u4e0d\u8db3", "method": "\u63d0\u51fa\u57fa\u4e8eHessian\u77e9\u9635\u7684\u534a\u76d1\u7763\u5b66\u4e60\u8f7b\u91cf\u795e\u7ecf\u7f51\u7edcHessNet\uff0c\u4e13\u95e8\u7528\u4e8e3D\u7ba1\u72b6\u7ed3\u6784\u5206\u5272\uff0c\u4ec5\u542b6000\u4e2a\u53c2\u6570", "result": "\u5728\u6700\u5c0f\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u8840\u7ba1\u5206\u5272\u7cbe\u5ea6\uff0c\u521b\u5efa\u4e86\u5305\u542b200\u5f20\u56fe\u50cf\u7684\u534a\u624b\u52a8\u6807\u6ce8\u8111\u8840\u7ba1\u6570\u636e\u96c6", "conclusion": "HessNet\u663e\u8457\u964d\u4f4e\u4e86\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u8d44\u6e90\u9700\u6c42\uff0c\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u8840\u7ba1\u5206\u5272\uff0c\u4f7f\u4e13\u5bb6\u80fd\u4e13\u6ce8\u4e8e\u6700\u590d\u6742\u7684\u75c5\u4f8b\uff0c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53ef\u7528"}}
