<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 6]
- [cs.IT](#cs.IT) [Total: 29]
- [eess.SP](#eess.SP) [Total: 15]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Comprehensive Machine Learning Benchmarking for Fringe Projection Profilometry with Photorealistic Synthetic Data](https://arxiv.org/abs/2601.08900)
*Anush Lakshman S,Adam Haroon,Beiwen Li*

Main category: eess.IV

TL;DR: 该论文创建了首个用于条纹投影轮廓术(FPP)的开源、照片级真实感合成数据集，并评估了四种神经网络架构在单次深度重建中的性能，发现所有模型表现相似，揭示了无显式相位信息的条纹到深度映射存在基本限制。


<details>
  <summary>Details</summary>
Motivation: 条纹投影轮廓术的机器学习方法受到缺乏大规模、多样化数据集和全面基准测试协议的限制。现有数据集不足，无法支持系统性的方法比较和发展。

Method: 使用NVIDIA Isaac Sim生成首个开源、照片级真实感的FPP合成数据集，包含15,600张条纹图像和300个深度重建，涵盖50个不同物体。在单次深度重建任务上基准测试了四种神经网络架构：UNet、Hformer、ResUNet和Pix2Pix。

Result: 所有模型在单次深度重建中表现出相似的性能（58-77 mm RMSE），尽管架构差异显著。重建误差达到典型物体深度范围的75-95%，表明无显式相位信息的直接条纹到深度映射存在基本限制。

Conclusion: 该资源提供了标准化评估协议，支持基于学习的FPP方法的系统性比较和发展。研究揭示了当前直接映射方法的局限性，为未来改进方向提供了重要参考。

Abstract: Machine learning approaches for fringe projection profilometry (FPP) are hindered by the lack of large, diverse datasets and comprehensive benchmarking protocols. This paper introduces the first open-source, photorealistic synthetic dataset for FPP, generated using NVIDIA Isaac Sim with 15,600 fringe images and 300 depth reconstructions across 50 diverse objects. We benchmark four neural network architectures (UNet, Hformer, ResUNet, Pix2Pix) on single-shot depth reconstruction, revealing that all models achieve similar performance (58-77 mm RMSE) despite substantial architectural differences. Our results demonstrate fundamental limitations of direct fringe-to-depth mapping without explicit phase information, with reconstruction errors approaching 75-95\% of the typical object depth range. This resource provides standardized evaluation protocols enabling systematic comparison and development of learning-based FPP approaches.

</details>


### [2] [W-DUALMINE: Reliability-Weighted Dual-Expert Fusion With Residual Correlation Preservation for Medical Image Fusion](https://arxiv.org/abs/2601.08920)
*Md. Jahidul Islam*

Main category: eess.IV

TL;DR: W-DUALMINE：一种基于可靠性加权的双专家医学图像融合框架，通过架构约束和理论驱动的损失设计，解决了全局统计相似性与局部结构保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法（包括AdaFuse和ASFE-Fusion等空间频率框架）在全局统计相似性（CC和MI）与局部结构保真度之间存在根本性权衡，需要一种能够明确解决这一矛盾的方法。

Method: 提出可靠性加权的双专家融合框架，包括：1）自适应模态加权的密集可靠性图；2）结合全局上下文空间专家和小波域频率专家的双专家融合策略；3）基于软梯度的仲裁机制；4）残差到平均融合范式，保证全局相关性同时增强局部细节。

Result: 在CT-MRI、PET-MRI和SPECT-MRI数据集上的广泛实验表明，W-DUALMINE在CC和MI指标上持续优于AdaFuse和ASFE-Fusion。

Conclusion: W-DUALMINE通过架构约束和理论驱动的损失设计，成功解决了医学图像融合中全局统计相似性与局部结构保真度之间的权衡问题，为多模态医学图像融合提供了有效解决方案。

Abstract: Medical image fusion integrates complementary information from multiple imaging modalities to improve clinical interpretation. However, existing deep learningbased methods, including recent spatial-frequency frameworks such as AdaFuse and ASFE-Fusion, often suffer from a fundamental trade-off between global statistical similaritymeasured by correlation coefficient (CC) and mutual information (MI)and local structural fidelity. This paper proposes W-DUALMINE, a reliability-weighted dual-expert fusion framework designed to explicitly resolve this trade-off through architectural constraints and a theoretically grounded loss design. The proposed method introduces dense reliability maps for adaptive modality weighting, a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, and a soft gradient-based arbitration mechanism. Furthermore, we employ a residual-to-average fusion paradigm that guarantees the preservation of global correlation while enhancing local details. Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics while

</details>


### [3] [GOUHFI 2.0: A Next-Generation Toolbox for Brain Segmentation and Cortex Parcellation at Ultra-High Field MRI](https://arxiv.org/abs/2601.09006)
*Marc-Antoine Fortin,Anne Louise Kristoffersen,Paal Erik Goa*

Main category: eess.IV

TL;DR: GOUHFI 2.0是一个用于超高场MRI的深度学习工具箱，通过两个3D U-Net网络实现全脑分割和皮层分区，解决了UHF-MRI数据自动分析的挑战。


<details>
  <summary>Details</summary>
Motivation: 超高场MRI在大型神经影像研究中应用增多，但由于信号不均匀性、对比度异质性和分辨率差异，以及缺乏针对UHF数据优化的工具，自动脑分割和皮层分区仍然具有挑战性。现有软件包如FastSurferVINN和SynthSeg+直接应用于UHF图像时效果不佳，限制了基于区域的定量分析。

Method: GOUHFI 2.0保留了原始工具箱的对比度和分辨率无关设计，引入了两个独立训练的3D U-Net分割任务：1）使用238名受试者的训练数据，通过领域随机化策略实现35个标签的全脑分割；2）使用相同训练数据，按照DKT协议实现62个标签的皮层分区。

Result: 在多个数据集上，GOUHFI 2.0相比原始工具箱显示出改进的分割准确性，特别是在异质队列中，并产生可靠的皮层分区结果。集成的体积测量流程与标准体积工作流程结果一致。

Conclusion: GOUHFI 2.0为跨场强的脑分割、分区和体积测量提供了全面解决方案，是首个能够在UHF-MRI上实现稳健皮层分区的深度学习工具箱。

Abstract: Ultra-High Field MRI (UHF-MRI) is increasingly used in large-scale neuroimaging studies, yet automatic brain segmentation and cortical parcellation remain challenging due to signal inhomogeneities, heterogeneous contrasts and resolutions, and the limited availability of tools optimized for UHF data. Standard software packages such as FastSurferVINN and SynthSeg+ often yield suboptimal results when applied directly to UHF images, thereby restricting region-based quantitative analyses. To address this need, we introduce GOUHFI 2.0, an updated implementation of GOUHFI that incorporates increased training data variability and additional functionalities, including cortical parcellation and volumetry.
  GOUHFI 2.0 preserves the contrast- and resolution-agnostic design of the original toolbox while introducing two independently trained 3D U-Net segmentation tasks. The first performs whole-brain segmentation into 35 labels across contrasts, resolutions, field strengths and populations, using a domain-randomization strategy and a training dataset of 238 subjects. Using the same training data, the second network performs cortical parcellation into 62 labels following the Desikan-Killiany-Tourville (DKT) protocol.
  Across multiple datasets, GOUHFI 2.0 demonstrated improved segmentation accuracy relative to the original toolbox, particularly in heterogeneous cohorts, and produced reliable cortical parcellations. In addition, the integrated volumetry pipeline yielded results consistent with standard volumetric workflows. Overall, GOUHFI 2.0 provides a comprehensive solution for brain segmentation, parcellation and volumetry across field strengths, and constitutes the first deep-learning toolbox enabling robust cortical parcellation at UHF-MRI.

</details>


### [4] [Universal Latent Homeomorphic Manifolds: Cross-Domain Representation Learning via Homeomorphism Verification](https://arxiv.org/abs/2601.09025)
*Tong Wu,Tayab Uddin Wara,Daniel Hernandez,Sidong Lei*

Main category: eess.IV

TL;DR: ULHM框架通过同胚映射统一语义表示和观测表示，为稀疏恢复、跨域迁移和零样本学习提供理论保证和验证算法。


<details>
  <summary>Details</summary>
Motivation: 尽管语义表示（如人类描述、诊断标签）和观测驱动表示（如像素强度、传感器读数）来源不同，但它们都捕捉相同的底层现实。需要建立一个统一的潜在结构来连接这两种模态，并确保这种统一具有数学上的严谨性。

Method: 提出通用潜在同胚流形（ULHM）框架，以同胚（连续双射且保持拓扑结构）作为数学准则，通过条件变分推断学习流形到流形的连续变换，避免脆弱的点对点映射。开发包括信任度、连续性和Wasserstein距离度量的验证算法。

Result: 实验显示：1）从5%的CelebA像素稀疏恢复图像，MNIST数字多级稀疏重建；2）MNIST到Fashion-MNIST跨域分类器迁移达到86.73%准确率无需重训练；3）零样本分类在未见类别上达到MNIST 89.47%、Fashion-MNIST 84.70%、CIFAR-10 78.76%。同胚准则能正确拒绝不兼容数据集。

Conclusion: ULHM框架通过同胚映射为语义和观测表示的统一定义了严格的数学准则，为稀疏恢复、跨域迁移和零样本学习提供了理论保证，并能验证结构兼容性，防止无效统一，为分解通用基础模型到已验证的领域特定组件提供了可行途径。

Abstract: We present the Universal Latent Homeomorphic Manifold (ULHM), a framework that unifies semantic representations (e.g., human descriptions, diagnostic labels) and observation-driven machine representations (e.g., pixel intensities, sensor readings) into a single latent structure. Despite originating from fundamentally different pathways, both modalities capture the same underlying reality. We establish \emph{homeomorphism}, a continuous bijection preserving topological structure, as the mathematical criterion for determining when latent manifolds induced by different semantic-observation pairs can be rigorously unified. This criterion provides theoretical guarantees for three critical applications: (1) semantic-guided sparse recovery from incomplete observations, (2) cross-domain transfer learning with verified structural compatibility, and (3) zero-shot compositional learning via valid transfer from semantic to observation space. Our framework learns continuous manifold-to-manifold transformations through conditional variational inference, avoiding brittle point-to-point mappings. We develop practical verification algorithms, including trust, continuity, and Wasserstein distance metrics, that empirically validate homeomorphic structure from finite samples. Experiments demonstrate: (1) sparse image recovery from 5\% of CelebA pixels and MNIST digit reconstruction at multiple sparsity levels, (2) cross-domain classifier transfer achieving 86.73\% accuracy from MNIST to Fashion-MNIST without retraining, and (3) zero-shot classification on unseen classes achieving 89.47\% on MNIST, 84.70\% on Fashion-MNIST, and 78.76\% on CIFAR-10. Critically, the homeomorphism criterion correctly rejects incompatible datasets, preventing invalid unification and providing a feasible way to principled decomposition of general foundation models into verified domain-specific components.

</details>


### [5] [POWDR: Pathology-preserving Outpainting with Wavelet Diffusion for 3D MRI](https://arxiv.org/abs/2601.09044)
*Fei Tan,Ashok Vardhan Addala,Bruno Astuto Arouche Nunes,Xucheng Zhu,Ravi Soni*

Main category: eess.IV

TL;DR: POWDR是一种基于条件小波扩散模型的病理保留外绘框架，用于3D MRI数据增强，保留真实病理区域的同时生成解剖合理的周围组织。


<details>
  <summary>Details</summary>
Motivation: 医学影像数据集常存在类别不平衡和病理丰富病例有限的问题，限制了分割、分类和视觉语言任务的机器学习模型性能。

Method: 提出POWDR框架，基于条件小波扩散模型，利用小波域条件增强高频细节，引入随机连接掩码训练策略防止条件诱导崩溃并提高病灶外多样性。

Result: 定量指标（FID、SSIM、LPIPS）证实图像真实性，随机掩码训练显著提高多样性（余弦相似度从0.9947降至0.9580）。肿瘤分割性能提升（Dice分数从0.6992提高至0.7137），组织体积分析显示与真实图像无显著差异。

Conclusion: POWDR是解决医学影像数据稀缺和类别不平衡的实用方案，可扩展到多种解剖结构，为生成多样化的病理保留合成数据提供可控框架。

Abstract: Medical imaging datasets often suffer from class imbalance and limited availability of pathology-rich cases, which constrains the performance of machine learning models for segmentation, classification, and vision-language tasks. To address this challenge, we propose POWDR, a pathology-preserving outpainting framework for 3D MRI based on a conditioned wavelet diffusion model. Unlike conventional augmentation or unconditional synthesis, POWDR retains real pathological regions while generating anatomically plausible surrounding tissue, enabling diversity without fabricating lesions.
  Our approach leverages wavelet-domain conditioning to enhance high-frequency detail and mitigate blurring common in latent diffusion models. We introduce a random connected mask training strategy to overcome conditioning-induced collapse and improve diversity outside the lesion. POWDR is evaluated on brain MRI using BraTS datasets and extended to knee MRI to demonstrate tissue-agnostic applicability. Quantitative metrics (FID, SSIM, LPIPS) confirm image realism, while diversity analysis shows significant improvement with random-mask training (cosine similarity reduced from 0.9947 to 0.9580; KL divergence increased from 0.00026 to 0.01494). Clinically relevant assessments reveal gains in tumor segmentation performance using nnU-Net, with Dice scores improving from 0.6992 to 0.7137 when adding 50 synthetic cases. Tissue volume analysis indicates no significant differences for CSF and GM compared to real images.
  These findings highlight POWDR as a practical solution for addressing data scarcity and class imbalance in medical imaging. The method is extensible to multiple anatomies and offers a controllable framework for generating diverse, pathology-preserving synthetic data to support robust model development.

</details>


### [6] [Equi-ViT: Rotational Equivariant Vision Transformer for Robust Histopathology Analysis](https://arxiv.org/abs/2601.09130)
*Fuyao Chen,Yuexi Du,Elèonore V. Lieffrig,Nicha C. Dvornek,John A. Onofrey*

Main category: eess.IV

TL;DR: 提出Equi-ViT，在Vision Transformer的patch embedding阶段集成等变卷积核，使学习到的表示具有旋转等变性，提高病理图像分析的数据效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准ViT对旋转、反射等变换不具有等变性，而病理图像中这些变换普遍存在。现有卷积神经网络擅长局部模式捕获但全局上下文推理能力有限，ViT能建模长距离依赖但缺乏等变性特性。

Method: 在ViT架构的patch embedding阶段集成等变卷积核，使学习到的表示具有内置的旋转等变性，实现旋转一致的patch嵌入。

Result: 在结直肠癌公开数据集上，Equi-ViT实现了旋转一致的patch嵌入和跨图像方向的稳定分类性能，提高了数据效率和鲁棒性。

Conclusion: 等变Transformer可以作为更通用的骨干网络应用于组织病理学中的ViT应用，如数字病理基础模型，具有更好的泛化能力。

Abstract: Vision Transformers (ViTs) have gained rapid adoption in computational pathology for their ability to model long-range dependencies through self-attention, addressing the limitations of convolutional neural networks that excel at local pattern capture but struggle with global contextual reasoning. Recent pathology-specific foundation models have further advanced performance by leveraging large-scale pretraining. However, standard ViTs remain inherently non-equivariant to transformations such as rotations and reflections, which are ubiquitous variations in histopathology imaging. To address this limitation, we propose Equi-ViT, which integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, imparting built-in rotational equivariance to learned representations. Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations. Our results on a public colorectal cancer dataset demonstrate that incorporating equivariant patch embedding enhances data efficiency and robustness, suggesting that equivariant transformers could potentially serve as more generalizable backbones for the application of ViT in histopathology, such as digital pathology foundation models.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [7] [Two-dimensional Entanglement-assisted Quantum Quasi-cyclic Low-density Parity-check Codes](https://arxiv.org/abs/2601.08927)
*Pavan Kumar,Shayan Srinivasa Garani*

Main category: cs.IT

TL;DR: 本文研究了二维准循环LDPC码的环结构条件，构建了多种无4环或6环的经典码，并基于这些经典码构造了具有单ebit需求的EA量子LDPC码，所有码都具有p×p的纠删能力。


<details>
  <summary>Details</summary>
Motivation: 研究二维准循环LDPC码中环结构的条件，特别是避免短环（如4环和6环）以提高码的性能，并基于经典码构造高效的EA量子LDPC码。

Method: 1. 推导二维经典QC-LDPC码中2g环存在的通用条件；2. 通过堆叠p×p×p张量构造无4环的经典码（p为奇素数）；3. 对于复合p值，提出两种张量堆叠构造方法，分别实现无4环和无6环；4. 基于经典码构造两种EA量子LDPC码：一种使用一对经典码且无4环，另一种使用单个无4环经典码。

Result: 1. 建立了二维QC-LDPC码环结构的理论条件；2. 构造了多种具有不同围长（大于4或大于6）的经典码；3. 所有经典码具有至少p×p的纠删能力；4. 成功构造了两种EA量子LDPC码，第一种只需单ebit且无4环，第二种基于单个无4环经典码；5. 量子码继承了经典码的p×p纠删能力。

Conclusion: 本文系统研究了二维QC-LDPC码的环结构，提出了多种构造方法，成功构建了高性能的经典和EA量子LDPC码，所有码都具有良好的纠删能力，为量子纠错码设计提供了新思路。

Abstract: For any positive integer $g \ge 2$, we derive general conditions for the existence of a $2g$-cycle in the Tanner graph of two-dimensional ($2$-D) classical quasi-cyclic (QC) low-density parity-check (LDPC) codes. Based on these conditions, we construct a family of $2$-D classical QC-LDPC codes with girth greater than $4$ by stacking $p \times p \times p$ tensors, where $p$ is an odd prime. Furthermore, for composite values of $p$, we propose two additional families of $2$-D classical LDPC codes obtained via similar tensor stacking. In this case, one family achieves girth greater than $4$, while the other attains girth greater than $6$. All the proposed $2$-D classical QC-LDPC codes exhibit an erasure correction capability of at least $p \times p$. Based on the constructed classical $2$-D QC-LDPC codes, we derive two families of $2$-D entanglement-assisted (EA) quantum low-density parity-check (QLDPC) codes. The first family of $2$-D EA-QLDPC codes is obtained from a pair of binary $2$-D classical LDPC codes and is designed such that the unassisted part of the Tanner graph of the resulting EA-QLDPC code is free of cycles of length four, while requiring only a single ebit to be shared across the quantum transceiver. The second family is constructed from a single $2$-D classical LDPC code whose Tanner graph is free from $4$-cycles. Moreover, the constructed EA-QLDPC codes inherit an erasure correction capability of $p \times p$, as the underlying classical codes possess the same erasure correction property.

</details>


### [8] [A Local Characterization of $f$-Divergences Yielding PSD Mutual-Information Matrices](https://arxiv.org/abs/2601.08929)
*Zachary Roberston*

Main category: cs.IT

TL;DR: 研究f-互信息矩阵在弱依赖条件下的正半定性条件：当且仅当f在1处解析且泰勒展开系数非负时，矩阵在独立附近保持正半定。


<details>
  <summary>Details</summary>
Motivation: 研究变量索引的f-互信息矩阵何时是正半定的，这对于理解信息度量的几何性质和构建信息理论中的核方法具有重要意义。

Method: 使用局部分析方法，结合副本嵌入技术将单项式项转化为Gram矩阵，通过副本强制约简为正定点积核，并应用Schoenberg-Berg-Christensen-Ressel分类定理。

Result: 给出了一个尖锐的局部特征：存在δ(f)>0，使得对于任意n和任意有限字母表变量族，当两两联合-乘积比在(1-δ,1+δ)范围内时，M^(f)是PSD当且仅当f在1处解析且泰勒展开系数a_m≥0。

Conclusion: f-互信息矩阵的正半定性要求f在1处解析且泰勒系数非负，这与分布间距离的希尔伯特性质不同，为信息度量的几何性质提供了新的理解。

Abstract: We study when the variable-indexed matrix of pairwise \(f\)-mutual informations \(M^{(f)}_{ij}=I_f(X_i;X_j)\) is positive semidefinite (PSD). Let \(f:(0,\infty)\to\mathbb{R}\) be convex with \(f(1)=0\), finite in a neighborhood of \(1\), and with \(f(0)<\infty\) so that diagonal terms are finite. We give a sharp \emph{local} characterization around independence: there exists \(δ=δ(f)>0\) such that for every \(n\) and every finite-alphabet family \((X_1,\ldots,X_n)\) whose pairwise joint-to-product ratios lie in \((1-δ,1+δ)\), the matrix \(M^{(f)}\) is PSD if and only if \(f\) is analytic at \(1\) with a convergent expansion \(f(t)=\sum_{m=2}^{\infty} a_m (t-1)^m\) and \(a_m\ge 0\) on a neighborhood of \(1\). Consequently, any negative Taylor coefficient yields an explicit finite-alphabet counterexample under arbitrarily weak dependence, and non-analytic convex divergences (e.g.\ total variation) are excluded. This PSD requirement is distinct from Hilbertian/metric properties of divergences between distributions (e.g.\ \(\sqrt{\mathrm{JS}}\)): we study PSD of the \emph{variable-indexed} mutual-information matrix. The proof combines a replica embedding that turns monomial terms into Gram matrices with a replica-forcing reduction to positive-definite dot-product kernels, enabling an application of the Schoenberg--Berg--Christensen--Ressel classification.

</details>


### [9] [On the Information Leakage Envelope of the Gaussian Mechanism](https://arxiv.org/abs/2601.08986)
*Sara Saeidian*

Main category: cs.IT

TL;DR: 本文研究了高斯机制的点态最大泄漏包络，推导了高斯秘密下的闭式解，并扩展到一般无界秘密，特别是强对数凹先验满足条件。


<details>
  <summary>Details</summary>
Motivation: 研究高斯机制的信息泄漏边界，特别是在任意后处理下以高概率成立的最小泄漏界，这对于隐私保护机制的理论分析很重要。

Method: 对于高斯秘密，推导了确定性PML包络的闭式表达式；对于一般无界秘密，通过Brascamp-Lieb不等式证明强对数凹先验满足条件。

Result: 得到了高斯机制在高斯秘密下PML包络的闭式解，并证明强对数凹先验的泄漏包络与高斯情况一致。

Conclusion: 高斯机制的PML包络在高斯秘密下可解析表达，且强对数凹先验的泄漏特性与高斯情况相同，为隐私分析提供了理论工具。

Abstract: We study the pointwise maximal leakage (PML) envelope of the Gaussian mechanism, which characterizes the smallest information leakage bound that holds with high probability under arbitrary post-processing. For the Gaussian mechanism with a Gaussian secret, we derive a closed-form expression for the deterministic PML envelope for sufficiently small failure probabilities. We then extend this result to general unbounded secrets by identifying a sufficient condition under which the envelope coincides with the Gaussian case. In particular, we show that strongly log-concave priors satisfy this condition via an application of the Brascamp-Lieb inequality.

</details>


### [10] [An Information-Theoretic Perspective on LLM Tokenizers](https://arxiv.org/abs/2601.09039)
*Mete Erdogan,Abhiram Gorle,Shubham Chandak,Mert Pilanci,Tsachy Weissman*

Main category: cs.IT

TL;DR: 论文研究LLM分词器作为结构化压缩器的特性，发现训练规模会重新分配熵：训练数据增加时，分词流整体多样性提高但上下文可预测性增强，表明分词器吸收了短程规律性，但在领域不匹配时效果下降。


<details>
  <summary>Details</summary>
Motivation: LLM分词器作为结构化压缩器，通过将文本映射到离散分词序列，决定了分词数量（计算和上下文使用）以及下游模型看到的统计结构。尽管分词器在LLM流程中处于核心地位，但分词化、压缩效率和诱导结构之间的联系尚未得到充分理解。

Method: 1) 将预训练的GPT系列分词器作为黑盒压缩器在不同领域进行基准测试；2) 研究不同配置（词汇量、训练规模、领域）下的学习分词器；3) 将分词化作为通用压缩的变换进行研究，并引入压缩感知的BPE变体；4) 采用信道视角，引入容量利用率指标来分析分词器行为。

Result: 实证表明分词器训练规模会重新分配熵：随着训练数据增加，分词流整体多样性提高（一元熵更高），但上下文可预测性显著增强（高阶条件熵更低），表明分词器吸收了大量短程规律性，但这些增益在训练-测试领域不匹配时会下降。

Conclusion: 研究结果揭示了压缩、诱导结构和领域偏移鲁棒性之间的各种权衡，并激励了基于原则的、压缩感知的分词器设计。需要更深入地理解分词化如何影响下游模型性能和效率。

Abstract: Large language model (LLM) tokenizers act as structured compressors: by mapping text to discrete token sequences, they determine token count (and thus compute and context usage) and the statistical structure seen by downstream models. Despite their central role in LLM pipelines, the link between tokenization, compression efficiency and induced structure is not well understood. We empirically demonstrate that tokenizer training scale redistributes entropy: as training data grows, the token stream becomes more diverse in aggregate (higher unigram entropy) yet markedly more predictable in-context (lower higher-order conditional entropies), indicating that tokenization absorbs substantial short-range regularity although these gains degrade under train-test domain mismatch. To ground these observations, we first benchmark i) pretrained GPT-family tokenizers as black-box compressors across various domains, and ii) learned tokenizers across configurations spanning vocabulary size, training scale, and domain. Next, we study tokenization as a transform for universal compression and introduce a compression-aware BPE variant. Finally, we adopt a channel lens and introduce capacity-utilization metrics to analyze tokenizer behaviour and outline implications for downstream modeling. Put together, our results expose various trade-offs between compression, induced structure, and robustness under domain shift, and motivate principled, compression-aware tokenizer design.

</details>


### [11] [Hybrid Mono- and Bi-static OFDM-ISAC via BS-UE Cooperation: Closed-Form CRLB and Coverage Analysis](https://arxiv.org/abs/2601.09057)
*Xiaoli Xu,Yong Zeng*

Main category: cs.IT

TL;DR: 本文提出了一种混合单/双基地感知框架，利用ISAC系统中的基站和用户设备协作，无需额外频谱或小区间协调，显著提升了目标定位和速度估计性能。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信（ISAC）系统中，如何充分利用基站和用户设备协作来提升感知性能，同时避免额外频谱成本和复杂的网络协调，是当前研究的挑战。

Method: 基于3GPP支持的感知模式，提出混合单/双基地感知框架，推导目标定位和速度估计的闭式CRLB，分析几何构型对性能的影响，并通过参数估计算法和加权MSE融合进行验证。

Result: 当BS-目标-UE形成接近直角三角形的有利几何构型时，混合感知相比纯单/双基地感知能获得显著性能增益；感知覆盖随BS-UE距离先增后减；UE密度影响最佳感知精度。

Conclusion: 混合单/双基地感知框架能有效提升ISAC系统的感知性能，几何构型是关键因素，为网络部署和UE选择提供了理论指导。

Abstract: This paper proposes a hybrid mono- and bi-static sensing framework, by leveraging the base station (BS) and user equipment (UE) cooperation in integrated sensing and communication (ISAC) systems. This scheme is built on 3GPP-supported sensing modes, and it does not incur any extra spectrum cost or inter-cell coordination. To reveal the fundamental performance limit of the proposed hybrid sensing mode, we derive closed-form Cramér-Rao lower bound (CRLB) for sensing target localization and velocity estimation, as functions of target and UE positions. The results reveal that significant performance gains can be achieved over the purely mono- or bi-static sensing, especially when the BS-target-UE form a favorable geometry, which is close to a right triangle. The analytical results are validated by simulations using effective parameter estimation algorithm and weighted mean square error (MSE) fusion method. Based on the derived sensing bound, we further analyze the sensing coverage by varying the UE positions, which shows that sensing coverage first improves then degrades as the BS-UE separation increases. Furthermore, the sensing accuracy for a potential target with best UE selection is derived as a function of the UE density in the network.

</details>


### [12] [Overcoming the Shadow: Bending Airy Beams for Radiative Near-Field Multi-User Access in Half-Space Blockage Scenarios](https://arxiv.org/abs/2601.09098)
*Yifeng Qin,Jing Chen,Zhi Hao Jiang,Zhi Ning Chen,Yongming Huang*

Main category: cs.IT

TL;DR: 提出利用艾里光束的自弯曲特性来缓解下一代无线通信中大规模天线阵列面临的半空间遮挡问题，无需额外硬件即可恢复阴影区域连接性。


<details>
  <summary>Details</summary>
Motivation: 下一代大规模天线阵列通信进入辐射近场区域，但高频近场链路在室内环境中易受墙壁、角落等半空间障碍物遮挡。传统近场聚焦波束在视距场景下增益高，但在阴影区域会出现严重的能量截断和有效秩崩溃，使得可重构智能表面等硬件解决方案不切实际。

Method: 提出一种利用艾里光束自弯曲特性的波束成形策略：1）基于格林函数的辐射近场多用户信道模型，解析揭示刀边障碍物后的奇异值崩溃；2）艾里模拟波束成形方案，优化弯曲轨迹以恢复有效信道秩；3）艾里零陷导向方法，将振荡零陷与明亮区域用户对齐以抑制混合阴影/明亮场景中的干扰。

Result: 仿真显示，相比传统辐射近场聚焦，提出的边缘"骑行"艾里策略在阴影链路中实现了超过20 dB的信噪比提升，恢复了满秩连接性，几乎消除了几何阴影中的中断，在典型室内超大规模天线阵列配置下将多用户频谱效率提高了约35%。

Conclusion: 该方法在不依赖可重构智能表面的情况下，实现了半空间遮挡场景下稳健的辐射近场多用户接入，为下一代无线通信中的遮挡问题提供了有效的软件解决方案。

Abstract: The move to next-generation wireless communications with extremely large-scale antenna arrays (ELAAs) brings the communications into the radiative near-field (RNF) region, where distance-aware focusing is feasible. However, high-frequency RNF links are highly vulnerable to blockage in indoor environments dominated by half-space obstacles (walls, corners) that create knife-edge shadows. Conventional near-field focused beams offer high gain in line-of-sight (LoS) scenarios but suffer from severe energy truncation and effective-rank collapse in shadowed regions, making hardware remedies such as reconfigurable intelligent surfaces (RIS) impractical. We propose a beamforming strategy that exploits the auto-bending property of Airy beams to mitigate half-space blockage without additional hardware. The Airy beam is designed to ``ride'' the diffraction edge, accelerating its main lobe into the shadow to restore connectivity. Our contributions are threefold: (i) a Green's function-based RNF multi-user channel model that analytically reveals singular-value collapse behind knife-edge obstacles; (ii) an Airy analog beamforming scheme that optimizes the bending trajectory to recover the effective channel rank; and (iii) an Airy null-steering method that aligns oscillatory nulls with bright-region users to suppress interference in mixed shadow/bright scenarios. Simulations show that the proposed edge-riding Airy strategy achieves an SNR improvement of over 20 dB and restores full-rank connectivity in shadowed links compared to conventional RNF focusing, virtually eliminating outage in geometric shadows and increasing multi-user spectral efficiency by approximately 35\% under typical indoor ELAA configurations. These results demonstrate robust RNF multi-user access in half-space blockage scenarios without relying on RIS.

</details>


### [13] [The .serva Standard: One Primitive for All AI Cost Reduced, Barriers Removed](https://arxiv.org/abs/2601.09124)
*Rachel St. Clair,John Austin Cook,Peter Sutor,Victor Cavero,Garrett Mindt*

Main category: cs.IT

TL;DR: ServaStack提出了一种革命性的AI基础设施解决方案，通过.serva格式（基于激光全息原理的无损压缩）和Chimera计算引擎，实现了无需解压的直接计算，大幅降低了AI训练和推理的能耗与成本。


<details>
  <summary>Details</summary>
Motivation: 当前AI基础设施面临两大危机：1）计算负载危机 - 训练和推理的能源与资本成本不可持续，可能超出电网容量并导致能力集中在少数组织手中；2）数据混乱危机 - 80%的项目精力消耗在数据准备、转换和预处理上，阻碍开发速度并将数据集锁定在单一模型架构中。现有方法将这些视为独立问题，仅进行增量优化，反而增加了生态系统复杂性。

Method: 提出ServaStack解决方案，包含两个核心组件：1）通用数据格式.serva - 基于激光全息原理实现无损压缩；2）通用AI计算引擎Chimera - 将计算操作转换为表示空间，直接在.serva文件上进行计算而无需解压。Chimera引擎允许现有模型无需重新训练即可处理.serva数据。

Result: 内部基准测试显示：与RNN、CNN和MLP模型在FashionMNIST和MNIST数据集上相比，实现了30-374倍的能效提升（96-99%能耗降低），4-34倍的无损存储压缩，以及68倍的计算负载减少且无精度损失。在超大规模场景下（每日10亿次迭代），每PB每训练周期可节省485万美元。

Conclusion: ServaStack通过统一的数据格式和计算引擎，从根本上改变了AI开发范式，将瓶颈从基础设施转移到了想象力，实现了"任何数据流向任何模型在任何硬件上"的愿景，为AI基础设施带来了革命性的效率提升。

Abstract: Artificial Intelligence (AI) infrastructure faces two compounding crises. Compute payload - the unsustainable energy and capital costs of training and inference - threatens to outpace grid capacity and concentrate capability among a handful of organizations. Data chaos - the 80% of project effort consumed by preparation, conversion, and preprocessing - strangles development velocity and locks datasets to single model architectures. Current approaches treat these as separate problems, managing each with incremental optimization while increasing ecosystem complexity. This paper presents ServaStack: a universal data format (.serva) paired with a universal AI compute engine (Chimera). The .serva format achieves lossless compression by encoding information using laser holography principles, while Chimera converts compute operations into a representational space where computation occurs directly on .serva files without decompression. The result is automatic data preprocessing. The Chimera engine enables any existing model to operate on .serva data without retraining, preserving infrastructure investments while revamping efficiency. Internal benchmarks demonstrate 30-374x energy efficiency improvements (96-99% reduction), 4x-34x lossless storage compression, and 68x compute payload reduction without accuracy loss when compared to RNN, CNN, and MLP models on FashionMNIST and MNIST datasets. At hyperscale with one billion daily iterations, these gains translate to $4.85M savings per petabyte per training cycle. When any data flows to any model on any hardware, the AI development paradigm shifts. The bottleneck moves from infrastructure to imagination.

</details>


### [14] [Movable Antenna Assisted Dual-Polarized Multi-Cell Cooperative AirComp: An Alternating Optimization Approach](https://arxiv.org/abs/2601.09137)
*Mingyu Hu,Nan Liu,Wei Kang*

Main category: cs.IT

TL;DR: 提出基于双极化可移动天线的多小区协作空中计算框架，通过联合优化组合矩阵、极化向量、天线位置和用户发射系数来最小化均方误差，显著提升分布式优化性能。


<details>
  <summary>Details</summary>
Motivation: 空中计算(AirComp)是分布式优化的关键技术，但传统固定单极化基站阵列无法充分利用空间自由度且存在极化失配问题，限制了系统性能。

Method: 提出双极化可移动天线(D-PMA)辅助的多小区协作空中计算框架，采用交替优化算法：组合矩阵和发射系数闭式更新，极化向量使用SCA和SDR方法优化，天线位置采用梯度法更新，并开发了基于统计信道的天线位置优化方案。

Result: 数值结果表明，所提可移动双极化方案在瞬时信道和统计信道下均优于可移动单极化和固定天线基线方案。

Conclusion: 双极化可移动天线能有效克服传统空中计算系统的局限性，通过联合优化显著提升系统性能，为分布式优化提供了更高效的通信解决方案。

Abstract: Over-the-air computation (AirComp) is a key enabler for distributed optimization, since it leverages analog waveform superposition to perform aggregation and thereby mitigates the communication bottleneck caused by iterative information exchange. However, AirComp is sensitive to wireless environment and conventional systems with fixed single-polarized base-station arrays cannot fully exploit spatial degrees of freedom while also suffering from polarization mismatch. To overcome these limitations, this paper proposes a multi-cell cooperative air-computation framework assisted by dual-polarized movable antennas (D-PMA), and formulates a mean squared error (MSE) minimization problem by jointly optimizing the combining matrix, polarization vectors, antenna positions, and user transmit coefficients. The resulting problem is highly nonconvex, so an alternating algorithm is developed in which closed-form updates are obtained for the combining matrix and transmit coefficients. Then a method based on successive convex approximation (SCA) and semidefinite relaxation (SDR) is proposed to refine polarization vectors, and the antenna positions are updated using a gradient-based method. In addition, we develop a statistical-channel-based scheme for optimizing the antenna locations, and we further present the corresponding algorithm to efficiently obtain the solution. Numerical results show that the proposed movable dual-polarized scheme consistently outperforms movable single-polarized and fixed-antenna baselines under both instantaneous and statistical channels.

</details>


### [15] [Reducing The Sub-packetization Level of Optimal-Access Cooperative MSR Codes](https://arxiv.org/abs/2601.09188)
*Yaqian Zhang,Jingke Xu*

Main category: cs.IT

TL;DR: 提出了一种降低最优访问协同MSR码子分组化程度的构造方法，将子分组化从r^(C(n,2))降低到r^(C(n,2)-⌊n/r⌋(C(r,2)-1))


<details>
  <summary>Details</summary>
Motivation: 协同MSR码在保持MDS码最小存储的同时，能以协同方式最优带宽修复多个节点故障。但现有最优访问协同MSR码的子分组化程度较高，导致实际应用中复杂度高、I/O开销大，需要降低子分组化程度。

Method: 首先设计两种修复特定双故障模式的最优访问MDS阵列码，然后将这两种码作为构建块，通过多次堆叠构造出最优访问协同MSR码。

Result: 获得了子分组化ℓ=r^(C(n,2)-⌊n/r⌋(C(r,2)-1))的最优访问协同MSR码，相比现有技术ℓ=r^(C(n,2))降低了1/r^(⌊n/r⌋(C(r,2)-1))倍。

Conclusion: 成功降低了最优访问协同MSR码的子分组化程度，减少了实际应用中的复杂度和I/O开销，同时保持了最优访问特性。

Abstract: Cooperative MSR codes are a kind of storage codes which enable optimal-bandwidth repair of any $h\geq2$ node erasures in a cooperative way, while retaining the minimum storage as an $[n,k]$ MDS code. Each code coordinate (node) is assumed to store an array of $\ell$ symbols, where $\ell$ is termed as sub-packetization. Large sub-packetization tends to induce high complexity, large input/output in practice. To address the disk IO capability, a cooperative MSR code is said to have optimal-access property, if during node repair, the amount of data accessed at each helper node meets a theoretical lower bound.
  In this paper, we focus on reducing the sub-packetization of optimal-access cooperative MSR codes with two erasures. At first, we design two crucial MDS array codes for repairing a specific repair pattern of two erasures with optimal access. Then, using the two codes as building blocks and by stacking up of the two codes for several times, we obtain an optimal-access cooperative MSR code with two erasures. The derived code has sub-packetization $\ell=r^{\binom{n}{2}-\lfloor\frac{n}{r}\rfloor(\binom{r}{2}-1)}$ where $r=n-k$, and it reduces $\ell$ by a fraction of $1/r^{\lfloor\frac{n}{r}\rfloor(\binom{r}{2}-1)}$ compared with the state of the art ($\ell=r^{\binom{n}{2}}$).

</details>


### [16] [Second-Order Asymptotics of Two-Sample Tests](https://arxiv.org/abs/2601.09196)
*K V Harsha,Jithin Ravi,Tobias Koch*

Main category: cs.IT

TL;DR: 本文提出了一种基于任意散度的两样本检验推广方法，称为散度检验，证明了其具有最优的一阶指数衰减率，且当使用不变散度时能达到与Gutman检验相同的二阶渐近性能。


<details>
  <summary>Details</summary>
Motivation: 两样本检验中，Gutman检验使用Jensen-Shannon散度作为检验统计量。本文旨在推广这一方法，研究使用任意散度的检验性能，特别是其错误概率的指数衰减特性。

Method: 提出散度检验方法，用任意散度替代JS散度作为检验统计量。分析该检验的I型和II型错误概率，特别关注II型错误概率的指数衰减率。研究不变散度下的二阶渐近性能。

Result: 1) 散度检验无论选择何种散度都能达到最优的一阶指数衰减率；2) 使用不变散度的散度检验能达到与Gutman检验相同的二阶渐近性能；3) 证明了Gutman检验是两样本检验问题的广义似然比检验；4) 建立了两样本检验与鲁棒拟合优度检验之间的联系。

Conclusion: 散度检验为两样本检验提供了一个灵活的框架，在保持最优一阶性能的同时，通过选择不变散度可以获得与经典Gutman检验相当的二阶性能，为统计推断提供了新的理论见解和实用工具。

Abstract: In two-sampling testing, one observes two independent sequences of independent and identically distributed random variables distributed according to the distributions $P_1$ and $P_2$ and wishes to decide whether $P_1=P_2$ (null hypothesis) or $P_1\neq P_2$ (alternative hypothesis). The Gutman test for this problem compares the empirical distributions of the observed sequences and decides on the null hypothesis if the Jensen-Shannon (JS) divergence between these empirical distributions is below a given threshold. This paper proposes a generalization of the Gutman test, termed \emph{divergence test}, which replaces the JS divergence by an arbitrary divergence. For this test, the exponential decay of the type-II error probability for a fixed type-I error probability is studied. First, it is shown that the divergence test achieves the optimal first-order exponent, irrespective of the choice of divergence. Second, it is demonstrated that the divergence test with an invariant divergence achieves the same second-order asymptotics as the Gutman test. In addition, it is shown that the Gutman test is the GLRT for the two-sample testing problem, and a connection between two-sample testing and robust goodness-of-fit testing is established.

</details>


### [17] [On Polar Coding with Feedback](https://arxiv.org/abs/2601.09222)
*Ling Liu,Qi Cao,Liping Li,Baoming Bai*

Main category: cs.IT

TL;DR: 研究反馈辅助下极化码的性能，反馈虽不提升信道容量，但能显著改善极化码的有限长度性能，通过启用genie辅助译码和更灵活的构造阈值。


<details>
  <summary>Details</summary>
Motivation: 虽然已知反馈不能提升无记忆信道的容量，但反馈可能改善极化码的有限长度性能。本研究旨在探索反馈如何通过genie辅助译码和更灵活的极化码构造阈值来提升实际通信系统中的性能。

Method: 提出在反馈辅助下的极化码新构造方法，利用反馈实现genie辅助的逐次消除(SC)译码。为了分析新构造的性能，提出了genie辅助SC译码下错误事件分布的精确表征方法。

Result: 反馈能显著改善极化码的有限长度性能。提出的错误分布表征方法不仅适用于反馈辅助系统，也能预测接近容量时标准SC译码的性能。

Conclusion: 反馈虽然不改变信道容量，但通过启用genie辅助译码和更灵活的构造阈值，能显著提升极化码的有限长度性能。提出的错误分布表征方法为分析极化码性能提供了有效工具。

Abstract: In this work, we investigate the performance of polar codes with the assistance of feedback in communication systems. Although it is well known that feedback does not improve the capacity of memoryless channels, we show that the finite length performance of polar codes can be significantly improved as feedback enables genie-aided decoding and allows more flexible thresholds for the polar coding construction. To analyze the performance under the new construction, we then propose an accurate characterization of the distribution of the error event under the genie-aided successive cancellation (SC) decoding. This characterization can be also used to predict the performance of the standard SC decoding of polar codes with rates close to capacity.

</details>


### [18] [A Theoretical Framework for Rate-Distortion Limits in Learned Image Compression](https://arxiv.org/abs/2601.09254)
*Changshuo Wang,Zijian Liang,Kai Niu,Ping Zhang*

Main category: cs.IT

TL;DR: 提出一个理论框架分析学习型图像压缩的率失真极限，将性能损失分解为方差估计、量化策略和上下文建模三个关键组件，提供可解释的R-D极限近似。


<details>
  <summary>Details</summary>
Motivation: 尽管神经编解码器取得了显著经验成果，但其与信息论极限的距离仍不明确。现有R-D估计器缺乏结构可解释性，无法与真实压缩模块对齐。

Method: 1) 推导高斯假设下的最优潜在方差作为二阶矩；2) 量化均匀量化与高斯测试信道之间的差距；3) 扩展框架包含上下文建模，分析准确均值预测的熵减效果。通过联合仿真和端到端训练获得理论R-D极限的紧致近似。

Result: 提出一个结构可解释的理论框架，能够分解R-D性能损失，提供与真实压缩模块对齐的精细分析，为设计更高效的学习型压缩系统提供新见解。

Conclusion: 该框架填补了学习型图像压缩理论与实际性能之间的差距，通过可解释的组件分解为优化神经编解码器提供了理论指导和设计原则。

Abstract: We present a novel systematic theoretical framework to analyze the rate-distortion (R-D) limits of learned image compression. While recent neural codecs have achieved remarkable empirical results, their distance from the information-theoretic limit remains unclear. Our work addresses this gap by decomposing the R-D performance loss into three key components: variance estimation, quantization strategy, and context modeling. First, we derive the optimal latent variance as the second moment under a Gaussian assumption, providing a principled alternative to hyperprior-based estimation. Second, we quantify the gap between uniform quantization and the Gaussian test channel derived from the reverse water-filling theorem. Third, we extend our framework to include context modeling, and demonstrate that accurate mean prediction yields substantial entropy reduction. Unlike prior R-D estimators, our method provides a structurally interpretable perspective that aligns with real compression modules and enables fine-grained analysis. Through joint simulation and end-to-end training, we derive a tight and actionable approximation of the theoretical R-D limits, offering new insights into the design of more efficient learned compression systems.

</details>


### [19] [Regenerating codes with minimal disk I/O cost achieving optimal tradeoff between storage and repair bandwidth](https://arxiv.org/abs/2601.09300)
*Minhan Gao,Kenneth Shum*

Main category: cs.IT

TL;DR: 提出一种基于gammoids理论的分布式存储编码方案，在单节点故障修复时，所有存活节点参与修复，能实现存储与修复带宽之间的最优权衡，支持无限次修复迭代。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统中，修复带宽和磁盘I/O成本是关键性能指标。现有方案在修复时需要编码操作，增加了计算开销。本文旨在设计一种无编码修复方案，既能最小化磁盘I/O成本，又能实现存储与修复带宽的最优权衡。

Method: 基于gammoids理论（一种基于图的拟阵特化类）设计编码方案。该方案在单节点故障修复时，所有存活节点参与修复，实现无编码修复（uncoded repair），即从内存读取的数据包数量与发送给新节点的数据包数量完全相同。

Result: 证明了该方案能够实现存储与修复带宽之间的所有基本权衡曲线点。同时证明了该方案在固定大小的域上能够容忍无限次节点修复迭代。

Conclusion: 基于gammoids理论的编码方案在单节点故障修复中，通过无编码修复机制实现了存储与修复带宽的最优权衡，同时最小化了磁盘I/O成本和计算开销，并支持无限次修复迭代。

Abstract: There are multiple performance metrics in the design of coding schemes for distributed storage systems. The first metric is called repair bandwidth, which measures the network resources required during the repair process. Another critical metric for repair efficiency is disk I/O cost, defined as the amount of data packets accessed at helper nodes to repair the failed node. In an encoding scheme with optimal I/O cost, the number of packets sent to the newcomer is exactly the same as the number of packets read from memory. This mode of repair is referred to as uncoded repair, as no coding operations are performed at the helper node. In addition to minimizing disk I/O cost, an uncoded repair mechanism has the advantage of incurring minimal computational overhead at the helper node. In this paper, we demonstrate that for single node failures, if all surviving nodes participate in the repair of the failed node, we can achieve all points on the fundamental tradeoff curve between storage and repair bandwidth. The design of the proposed encoding scheme is based on the theory of gammoids, a specialized class of graph-based matroids. We prove that this scheme can tolerate an unlimited number of node repair iterations over a field of fixed size.

</details>


### [20] [An Information Theoretic Proof of the Radon-Nikodym Theorem](https://arxiv.org/abs/2601.09308)
*Peter Harremoës*

Main category: cs.IT

TL;DR: 论文探讨了Radon-Nikodym定理在信息论基础概念中的核心作用，以及该定理证明在概率和信息论教材中被省略的原因。


<details>
  <summary>Details</summary>
Motivation: Radon-Nikodym定理是信息论中香农熵、f-散度等基本概念定义的基础，但在概率论和信息论教材中，该定理的存在性证明经常被省略，因为证明被认为过于困难。作者旨在阐明这一现象并强调该定理的重要性。

Method: 通过分析Radon-Nikodym定理在信息论中的应用，对比其在测度论教材与概率/信息论教材中的处理方式，指出证明被省略的原因。

Result: 论文明确了Radon-Nikodym定理在信息论中的基础性地位，揭示了该定理证明在相关教材中被省略的普遍现象，并指出了这种省略对教学的影响。

Conclusion: 虽然Radon-Nikodym定理的证明在技术上有难度，但其在信息论中的核心作用不容忽视。教材编写者需要在理论严谨性和教学可接受性之间找到平衡。

Abstract: The Radon-Nikodym theorem plays a significant role in the definition of Shannon entropy, f-divergences, and other basic quantities in information theory. The existence of Radon Nikodym derivates appear in many text books in measure theory but in text books on probability or information theory it is often omitted because the proof is often considered to be too difficult.

</details>


### [21] [Contraction of Rényi Divergences for Discrete Channels: Properties and Applications](https://arxiv.org/abs/2601.09328)
*Adrien Vandenbroucque,Amedeo Roberto Esposito,Michael Gastpar*

Main category: cs.IT

TL;DR: 该论文研究了Rényi散度的强数据处理常数性质，揭示了其与φ-散度收缩性质的差异，并将结果应用于马尔可夫链收敛速度的界估计。


<details>
  <summary>Details</summary>
Motivation: 研究Rényi散度的强数据处理常数性质，探索其与已深入研究的φ-散度收缩性质的异同，为理解信息处理系统的收缩特性提供新视角。

Method: 通过分析Rényi散度的阶数α对其收缩性质的影响，特别关注α>1时的偏差，研究∞-Rényi散度的收缩特性及其与ε-局部差分隐私的关系。

Result: 发现当α>1时，Rényi散度的收缩性质与φ-散度存在显著差异；揭示了∞-Rényi散度的特定收缩特性及其与隐私保护的联系；将结果应用于马尔可夫链收敛速度的界估计。

Conclusion: Rényi散度的收缩性质为理解信息处理系统的收缩特性提供了新视角，特别是在α>1时展现出与φ-散度不同的行为，这些结果对马尔可夫链收敛分析有重要应用价值。

Abstract: This work explores properties of Strong Data-Processing constants for Rényi Divergences. Parallels are made with the well-studied $\varphi$-Divergences, and it is shown that the order $α$ of Rényi Divergences dictates whether certain properties of the contraction of $\varphi$-Divergences are mirrored or not. In particular, we demonstrate that when $α>1$, the contraction properties can deviate quite strikingly from those of $\varphi$-Divergences. We also uncover specific characteristics of contraction for the $\infty$-Rényi Divergence and relate it to $\varepsilon$-Local Differential Privacy. The results are then applied to bound the speed of convergence of Markov chains, where we argue that the contraction of Rényi Divergences offers a new perspective on the contraction of $L^α$-norms commonly studied in the literature.

</details>


### [22] [Generalized Schalkwijk-Kailath Coding for Autoregressive Gaussian Channels](https://arxiv.org/abs/2601.09329)
*Jun Su,Guangyue Han,Shlomo Shamai*

Main category: cs.IT

TL;DR: 提出了一种用于AR(p)高斯信道的SK(2)编码方案，推广了经典的Schalkwijk-Kailath方案，并证明了SK方案并非普遍最优


<details>
  <summary>Details</summary>
Motivation: 推广经典的Schalkwijk-Kailath编码方案，研究其在AR(p)高斯信道中的性能，检验Butman关于SK方案普遍最优性的猜想

Method: 提出了SK(2)编码方案，这是一种高斯随机编码方案，能够推广经典的SK方案，并给出了可达率的闭式表征

Result: 证明了SK编码方案并非普遍最优，从而推翻了Butman在1976年提出的猜想

Conclusion: SK(2)编码方案为AR(p)高斯信道提供了有效的编码方法，并揭示了经典SK方案的局限性

Abstract: We propose a Gaussian random coding scheme for AR($p$) Gaussian channels that generalizes the celebrated Schalkwijk-Kailath (SK) coding scheme. This constructive coding scheme, termed the SK(2) coding scheme, yields a closed-form characterization for the corresponding achievable rate. Among many others, this result shows that the celebrated SK coding scheme is not universally optimal, and therefore, disprove the conjecture proposed by Butman in \cite{butman1976linear}.

</details>


### [23] [A Constructive Method to Minimize the Index of Coincidence under Marginal Constraints](https://arxiv.org/abs/2601.09347)
*Pierre Jean-Claude Robert Bertrand*

Main category: cs.IT

TL;DR: 本文提出了一个完整构造性解决方案，用于在固定边际约束下最小化联合分布的索引重合度，通过单调阶梯状零值结构实现有限步收敛。


<details>
  <summary>Details</summary>
Motivation: 索引重合度最小化在信息论中有多个应用，但现有闭式解需要强可行性条件，而该条件在实际中很少满足。本文旨在解决一般情况下的最小化问题。

Method: 首先分析边际集合的测度性质，然后证明最优耦合具有单调阶梯状零值结构，基于此结构提出显式迭代构造算法。

Result: 证明了最优耦合的单调阶梯结构，提出了有限步收敛的显式迭代构造，实现了索引重合度最小化的完整构造性解决方案。

Conclusion: 本文解决了固定边际约束下索引重合度最小化问题，提供了完整的构造性解决方案，克服了现有方法需要强可行性条件的限制。

Abstract: We consider the problem of minimizing the index of coincidence of a joint distribution under fixed marginal constraints. This objective is motivated by several applications in information theory, where the index of coincidence naturally arises. A closed-form solution is known when the marginals satisfy a strong feasibility condition, but this condition is rarely met in practice. We first show that the measure of the set of marginals for which condition applies vanishes as the dimension grows. We then characterize the structure of the optimal coupling in the general case, proving that it exhibits a monotone staircase of zero entries. Based on this structure, we propose an explicit iterative construction and prove that it converges in finitely many steps to a minimizer. Main result of the paper is a complete constructive solution of index-of-coincidence minimization.

</details>


### [24] [Asymptotic Rate Bounds and Constructions for the Inclusive Variant of Disjunct Matrices](https://arxiv.org/abs/2601.09362)
*Yuto Mizunuma,Yuichiro Fujiwara*

Main category: cs.IT

TL;DR: 本文首次建立了包容性分离矩阵的渐进下界，匹配了已知上界（对数因子内），证明了该变体可实现渐进正速率，为抑制剂复杂模型下的可扩展群组测试提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 包容性分离矩阵在抑制剂复杂模型下的群组测试中具有重要应用价值，但其渐进行为一直未被充分研究，特别是能否实现渐进正速率这一可扩展设计的关键问题尚不清楚。

Method: 采用概率方法证明渐进下界，并基于此提出简单高效的随机化构造，进一步通过去随机化技术获得确定性多项式时间构造。

Result: 首次建立了包容性分离矩阵的非平凡渐进下界，该下界与已知最强上界在对数因子内匹配，证明了该变体可实现渐进正速率。

Conclusion: 研究结果阐明了在一般抑制剂复杂模型下，稳健且可扩展的群组测试的渐进潜力，为实际应用提供了理论基础和构造方法。

Abstract: Disjunct matrices, also known as cover-free families and superimposed codes, are combinatorial arrays widely used in group testing. Among their variants, those that satisfy an additional combinatorial property called inclusiveness form a special class suitable for computationally efficient and highly error-tolerant group testing under the general inhibitor complex model, a broad framework that subsumes practical settings such as DNA screening. Despite this relevance, the asymptotic behavior of the inclusive variant of disjunct matrices has remained largely unexplored. In particular, it was not previously known whether this variant can achieve an asymptotically positive rate, a requirement for scalable group testing designs. In this work, we establish the first nontrivial asymptotic lower bound on the maximum achievable rate of the inclusive variant, which matches the strongest known upper bound up to a logarithmic factor. Our proof is based on the probabilistic method and yields a simple and efficient randomized construction. Furthermore, we derandomize this construction to obtain a deterministic polynomial-time construction. These results clarify the asymptotic potential of robust and scalable group testing under the general inhibitor complex model.

</details>


### [25] [On Decoding First- and Second-Order BiD Codes](https://arxiv.org/abs/2601.09390)
*Devansh Jain,Lakshmi Prasad Natarajan*

Main category: cs.IT

TL;DR: 本文提出了针对一阶BiD码的快速ML和max-log-MAP解码器，针对二阶BiD码识别了最小权重奇偶校验并确认了投影特性，设计了性能接近ML解码器的置信传播解码器。


<details>
  <summary>Details</summary>
Motivation: BiD码是一种新的代数码族，在比特MAP解码下能达到擦除信道容量，且具有比Reed-Muller码更大的最小距离。然而，需要设计高效的解码算法来实现其理论优势。

Method: 1. 为一阶BiD码设计快速最大似然(ML)和max-log-MAP解码器；2. 为二阶BiD码识别最小权重奇偶校验并确认投影特性；3. 基于这些结果设计置信传播解码器。

Result: 设计的置信传播解码器在块长度81和243时，性能在ML解码器的1 dB范围内，实现了接近最优的解码性能。

Conclusion: 本文为BiD码开发了高效的解码算法，特别是置信传播解码器在二阶BiD码上表现出接近ML解码器的性能，为实际应用提供了可行的解码方案。

Abstract: BiD codes, which are a new family of algebraic codes of length $3^m$, achieve the erasure channel capacity under bit-MAP decoding and offer asymptotically larger minimum distance than Reed-Muller (RM) codes. In this paper we propose fast maximum-likelihood (ML) and max-log-MAP decoders for first-order BiD codes. For second-order codes, we identify their minimum-weight parity checks and ascertain a code property known as 'projection' in the RM coding literature. We use these results to design a belief propagation decoder that performs within 1 dB of ML decoder for block lengths 81 and 243.

</details>


### [26] [A Generalized Leakage Interpretation of Alpha-Mutual Information](https://arxiv.org/abs/2601.09406)
*Akira Kamatsuka,Takahiro Yoshida*

Main category: cs.IT

TL;DR: 该论文提出α-互信息在广义g-泄漏框架下的统一解释，将α参数解释为对手风险厌恶的度量


<details>
  <summary>Details</summary>
Motivation: 现有α-互信息缺乏在信息安全领域的统一解释框架，需要将其与定量信息流分析中的广义泄漏概念联系起来，以更好地理解信息泄漏的对抗性特征

Method: 基于对抗性广义决策问题建立扩展的定量信息流框架，使用Kolmogorov-Nagumo均值和q-对数来表征对抗性收益，在此框架下解释α-互信息

Result: 成功建立了α-互信息与广义g-泄漏之间的统一解释，证明了α参数可以解释为对手风险厌恶程度的度量

Conclusion: 该研究为α-互信息提供了在信息安全领域的新解释框架，将信息论概念与对抗性风险评估联系起来，有助于更深入地理解信息泄漏的对抗性本质

Abstract: This paper presents a unified interpretation of $α$-mutual information ($α$-MI) in terms of generalized $g$-leakage. Specifically, we present a novel interpretation of $α$-MI within an extended framework for quantitative information flow based on adversarial generalized decision problems. This framework employs the Kolmogorov-Nagumo mean and the $q$-logarithm to characterize adversarial gain. Furthermore, we demonstrate that, within this framework, the parameter $α$ can be interpreted as a measure of the adversary's risk aversion.

</details>


### [27] [Dobrushin Coefficients of Private Mechanisms Beyond Local Differential Privacy](https://arxiv.org/abs/2601.09498)
*Leonhard Grosse,Sara Saeidian,Tobias J. Oechtering,Mikael Skoglund*

Main category: cs.IT

TL;DR: 研究具有有界逐点最大泄漏(PML)的离散马尔可夫核的Dobrushin系数，该定义在c→0时恢复局部差分隐私(LDP)。推导了基于核PML保证的收缩界，并提供了实现这些界的机制构造。通过Binette不等式将结果扩展到一般f-散度。


<details>
  <summary>Details</summary>
Motivation: 研究具有有界逐点最大泄漏(PML)的离散马尔可夫核的收缩性质，该框架扩展了局部差分隐私(LDP)的概念，允许在最小概率质量有下界的情况下分析隐私机制。

Method: 分析具有有界PML的离散马尔可夫核的Dobrushin系数，推导基于核PML保证的收缩界，构造实现这些界的机制，并通过Binette不等式将结果扩展到一般f-散度。

Result: 获得了基于核PML保证的收缩界，提供了实现这些界的机制构造，得到了比LDP更紧的界，并将结果扩展到任何离散核和一般f-散度。

Conclusion: 该研究扩展了LDP分析框架，为具有有界PML的离散马尔可夫核提供了更紧的收缩界，并将结果推广到一般f-散度，适用于更广泛的隐私机制分析。

Abstract: We investigate Dobrushin coefficients of discrete Markov kernels that have bounded pointwise maximal leakage (PML) with respect to all distributions with a minimum probability mass bounded away from zero by a constant $c>0$. This definition recovers local differential privacy (LDP) for $c\to 0$. We derive achievable bounds on contraction in terms of a kernels PML guarantees, and provide mechanism constructions that achieve the presented bounds. Further, we extend the results to general $f$-divergences by an application of Binette's inequality. Our analysis yields tighter bounds for mechanisms satisfying LDP and extends beyond the LDP regime to any discrete kernel.

</details>


### [28] [Error Exponents for Randomised List Decoding](https://arxiv.org/abs/2601.09519)
*Henrique K. Miyamoto,Sheng Yang*

Main category: cs.IT

TL;DR: 研究随机列表解码的随机编码错误指数，分析固定列表大小和指数增长列表大小两种机制下的性能界限


<details>
  <summary>Details</summary>
Motivation: 探索随机列表解码（解码器根据解码度量随机选择L个消息）的错误指数性能，特别是在不匹配和匹配解码度量下的表现，以理解列表解码对错误概率的影响

Method: 采用随机编码理论分析，研究两种机制：1) 固定列表大小下的集合紧密随机编码错误指数；2) 列表大小随块长度指数增长时的非平凡下界

Result: 对于固定列表大小，推导出集合紧密的错误指数，但发现匹配度量下不能改善普通解码的错误指数；对于指数增长列表大小，在匹配度量下高码率时获得紧致的非平凡下界

Conclusion: 随机列表解码在固定列表大小下对匹配度量没有性能提升，但在列表大小指数增长时，在高码率下能获得有意义的错误指数改进

Abstract: This paper studies random-coding error exponents of randomised list decoding, in which the decoder randomly selects $L$ messages with probabilities proportional to the decoding metric of the codewords. The exponents (or bounds) are given for mismatched, and then particularised to matched and universal decoding metrics. Two regimes are studied: for fixed list size, we derive an ensemble-tight random-coding error exponent, and show that, for the matched metric, it does not improve the error exponent of ordinary decoding. For list sizes growing exponentially with the block-length, we provide a non-trivial lower bound to the error exponent that is tight at high rates under the matched metric.

</details>


### [29] [A Finite-Sample Strong Converse for Binary Hypothesis Testing via (Reverse) Rényi Divergence](https://arxiv.org/abs/2601.09550)
*Roberto Bruno,Adrien Vandenbroucque,Amedeo Roberto Esposito*

Main category: cs.IT

TL;DR: 本文研究有限样本下非对称错误约束的二元假设检验，利用"反向"Rényi散度推导了第二类错误概率的非渐近界，建立了强逆定理，并展示了在指数衰减约束下的误差行为。


<details>
  <summary>Details</summary>
Motivation: 在有限样本情况下，传统渐近分析无法准确描述假设检验的性能边界，特别是在非对称错误约束下。现有有限样本结果存在改进空间，需要更紧的边界来指导实际应用。

Method: 采用"反向"Rényi散度作为分析工具，推导第二类错误概率的非渐近上界。通过数学分析建立错误概率与散度度量之间的关系，特别关注指数衰减约束下的渐近行为。

Result: 1. 建立了基于反向Rényi散度的第二类错误非渐近界；2. 证明了强逆定理；3. 当第一类错误以速率c指数衰减时：若c>D(P1∥P0)，第二类错误指数收敛到1；若c<D(P1∥P0)，第二类错误指数衰减到0；4. 数值实验显示所提逆界严格优于现有有限样本结果。

Conclusion: 反向Rényi散度为有限样本假设检验提供了有效的分析框架，所得非渐近界改进了现有结果，为实际应用中错误概率的精确控制提供了理论依据。

Abstract: This work investigates binary hypothesis testing between $H_0\sim P_0$ and $H_1\sim P_1$ in the finite-sample regime under asymmetric error constraints. By employing the ``reverse" Rényi divergence, we derive novel non-asymptotic bounds on the Type II error probability which naturally establish a strong converse result. Furthermore, when the Type I error is constrained to decay exponentially with a rate $c$, we show that the Type II error converges to 1 exponentially fast if $c$ exceeds the Kullback-Leibler divergence $D(P_1\|P_0)$, and vanishes exponentially fast if $c$ is smaller. Finally, we present numerical examples demonstrating that the proposed converse bounds strictly improve upon existing finite-sample results in the literature.

</details>


### [30] [On Linear Estimators for some Stable Vectors](https://arxiv.org/abs/2601.09554)
*Rayan Chouity,Charbel Hannoun,Jihad Fahs,Ibrahim Abou-Faycal*

Main category: cs.IT

TL;DR: 研究联合稳定随机变量的估计问题，在线性变换和子高斯对称α稳定向量两种依赖模型下，证明了条件均值估计器是线性的，并找到了最优线性估计器。


<details>
  <summary>Details</summary>
Motivation: 研究联合稳定随机变量的估计问题，特别是在非高斯稳定分布下，探索条件均值估计器的性质，以及如何找到最优线性估计器，推广高斯分布中的经典结果。

Method: 考虑两种特定的依赖模型：1）两个独立稳定变量的线性变换；2）子高斯对称α稳定向量。在这两种模型下分析条件均值估计器的性质，并寻找最优线性估计器。

Result: 证明了在这两种依赖模型下，条件均值估计器都是线性的。找到了最优线性估计器。特别地，对于子高斯对称α稳定向量，两种估计器是相同的，这推广了高斯分布中条件均值是最优线性最小均方误差估计器的经典结果。

Conclusion: 研究扩展了高斯分布中的经典估计理论到稳定分布框架，证明了在某些依赖结构下，条件均值估计器保持线性性质，并且可以找到最优线性估计器，为稳定随机变量的估计问题提供了理论支持。

Abstract: We consider the estimation problem for jointly stable random variables. Under two specific dependency models: a linear transformation of two independent stable variables and a sub-Gaussian symmetric $α$-stable (S$α$S) vector, we show that the conditional mean estimator is linear in both cases. Moreover, we find dispersion optimal linear estimators. Interestingly, for the sub-Gaussian (S$α$S) vector, both estimators are identical generalizing the well-known Gaussian result of the conditional mean being the best linear minimum-mean square estimator.

</details>


### [31] [The Spectral Representations Of The Simple Hypothesis Testing Problem](https://arxiv.org/abs/2601.09564)
*Barış Nakiboğlu*

Main category: cs.IT

TL;DR: 论文研究了假设检验问题中Type II错误概率（体积）作为Type I错误概率函数的凸共轭（Legendre变换），推导了原始熵谱的表达式，并应用于乘积测度情况得到最新边界。


<details>
  <summary>Details</summary>
Motivation: 研究假设检验中Type I和Type II错误概率之间的基本关系，特别是通过凸共轭分析来理解Type II错误体积的数学特性，为统计推断提供理论基础。

Method: 使用随机检测器，基于似然比分位数性质推导凸共轭表达式，通过标准谱恒等式将原始熵谱表示为似然比互补分布函数的积分，并应用Berry-Esseen定理和Gaussian Mills比性质分析乘积测度情况。

Result: 得到了Type II错误体积的凸共轭（原始熵谱）的精确表达式，建立了对偶表征，并通过Berry-Esseen定理获得了乘积测度情况下的最新边界，包括有倾斜和无倾斜两种情况。

Conclusion: 该研究为假设检验中错误概率的凸分析提供了系统框架，推导的原始熵谱和对偶表征具有理论意义，所得边界在统计推断中具有实际应用价值。

Abstract: The convex conjugate (i.e., the Legendre transform) of Type II error probability (volume) as a function of Type I error probability (volume) is determined for the hypothesis testing problem with randomized detectors. The derivation relies on properties of likelihood ratio quantiles and is general enough to extend to the case of $σ$-finite measures in all non-trivial cases. The convex conjugate of the Type II error volume, called the primitive entropy spectrum, is expressed as an integral of the complementary distribution function of the likelihood ratio using a standard spectral identity. The resulting dual characterization of the Type II error volume leads to state of the art bounds for the case of product measures via Berry--Esseen theorem through a brief analysis relying on properties of the Gaussian Mills ratio, both with and without tilting.

</details>


### [32] [On the Error Probability of RPA Decoding of Reed-Muller Codes over BMS Channels](https://arxiv.org/abs/2601.09581)
*Dorsa Fathollahi,V. Arvind Rameshwar,V. Lalitha*

Main category: cs.IT

TL;DR: 本文分析了RPA解码器在一般二进制无记忆对称信道下对Reed-Muller码的性能，将BSC信道的结果推广到所有BMS信道，证明了在码率较低时错误概率趋于零。


<details>
  <summary>Details</summary>
Motivation: 之前的研究只证明了RPA解码器在二进制对称信道（BSC）下对低码率RM码能达到渐近零错误概率。本文旨在将这一结果推广到所有二进制无记忆对称（BMS）信道，消除对特定信道类型的限制。

Method: 通过建立RPA投影操作与极化码"信道组合"阶段的等价关系，避免了先前证明方法所需的额外限制性假设。利用这种等价性，可以在最大似然解码下对一阶RM码（RPA解码器的"基础情况"）使用通用的联合界。

Result: 证明了对于所有BMS信道，当码阶大致按log log n增长时，在大块长n极限下，RPA解码器能够实现渐近零错误概率，这显著推广了先前仅适用于BSC信道的结果。

Conclusion: RPA解码器对所有BMS信道都具有鲁棒性，能够在低码率RM码下实现渐近零错误概率，这一结果通过建立与极化码的等价关系而得到，无需对信道特性施加额外限制。

Abstract: We analyze the performance of the Recursive Projection-Aggregation (RPA) decoder of Ye and Abbe (2020), for Reed-Muller (RM) codes, over general binary memoryless symmetric (BMS) channels. Our work is a significant generalization of a recent result of Rameshwar and Lalitha (2025) that showed that the RPA decoder provably achieves vanishing error probabilities for "low-rate" RM codes, over the binary symmetric channel (BSC). While a straightforward generalization of the proof strategy in that paper will require additional, restrictive assumptions on the BMS channel, our technique, which employs an equivalence between the RPA projection operation and a part of the "channel combining" phase in polar codes, requires no such assumptions. Interestingly, such an equivalence allows for the use of a generic union bound on the error probability of the first-order RM code (the "base case" of the RPA decoder), under maximum-likelihood decoding, which holds for any BMS channel. We then exploit these observations in the proof strategy outlined in the work of Rameshwar and Lalitha (2025), and argue that, much like in the case of the BSC, one can obtain vanishing error probabilities, in the large $n$ limit (where $n$ is the blocklength), for RM orders that scale roughly as $\log \log n$, for all BMS channels.

</details>


### [33] [Secret sharing with additive access structures from correlated random variables](https://arxiv.org/abs/2601.09640)
*David Miller,Rémi A. Chou*

Main category: cs.IT

TL;DR: 将基于相关随机性和公共通信的秘密共享模型推广到动态访问结构序列，称为加法访问结构，证明存在策略在每一步达到与固定访问结构相同的秘密率


<details>
  <summary>Details</summary>
Motivation: 传统秘密共享模型针对固定访问结构设计，需要扩展到支持动态变化的访问结构，其中访问结构可以随时间单调增长，参与者子集可以在不同时间步被添加

Method: 提出加法访问结构模型，访问结构随时间单调增长，经销商只在变化发生时获知访问结构变更。证明存在秘密共享策略在每一步达到与固定访问结构模型相同的最优秘密率

Result: 证明了存在策略在每个时间步达到与固定访问结构版本相同的最优秘密率，并且当访问结构是阈值访问结构时，存在在任何时间步都能达到容量的策略

Conclusion: 成功将秘密共享模型扩展到动态访问结构，保持了与固定访问结构相同的性能，为动态环境下的秘密共享提供了理论基础

Abstract: We generalize secret-sharing models that rely on correlated randomness and public communication, originally designed for a fixed access structure, to support a sequence of dynamic access structures, which we term an Additive Access Structure. Specifically, the access structure is allowed to monotonically grow by having any subset of participants added to it at a given time step, and the dealer only learns of these changes to the access structure on the time step that they occur. For this model, we prove the existence of a secret sharing strategy that achieves the same secret rate at each time step as the best known strategy for the fixed access structure version of this model. We also prove that there exists a strategy that is capacity-achieving at any time step where the access structure is a threshold access structure.

</details>


### [34] [Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions](https://arxiv.org/abs/2601.09674)
*Lei Huang*

Main category: cs.IT

TL;DR: 本文量化了QC-SC-LDPC码设计空间的大小和结构，推导了满足结构避免约束的分区矩阵数量的显式下界，并提供了MT算法输出不同解数量的可计算下界。


<details>
  <summary>Details</summary>
Motivation: 设计具有低错误平层的大耦合存储QC-SC-LDPC码需要消除由边扩展和提升引起的特定有害子结构（如短环）。需要量化可行设计空间的大小和结构，为随机化构造提供具体的多样性保证。

Method: 基于Clique Lovász Local Lemma (CLLL)设计原则和Moser-Tardos (MT)型构造方法，使用定量CLLL推导满足结构避免约束的分区矩阵数量的显式下界，通过Rényi熵界分析MT分布，提供MT算法输出不同解数量的可计算下界。

Result: 获得了分区矩阵数量的下界、行/列置换下非等价解数量的界，以及MT算法输出不同解数量的可计算下界。针对消除4环候选的特殊情况，得到了系统参数函数的闭式界。

Conclusion: 该工作为QC-SC-LDPC码设计提供了量化设计空间的方法，为确定内存/提升大小和估计剩余搜索空间提供了原则性指导，并为随机化构造提供了具体的多样性保证。

Abstract: Designing large coupling memory quasi-cyclic spatially-coupled LDPC (QC-SC-LDPC) codes with low error floors requires eliminating specific harmful substructures (e.g., short cycles) induced by edge spreading and lifting. Building on our work~\cite{r15} that introduced a Clique Lovász Local Lemma (CLLL)-based design principle and a Moser--Tardos (MT)-type constructive approach, this work quantifies the size and structure of the feasible design space. Using the quantitative CLLL, we derive explicit lower bounds on the number of partition matrices satisfying a given family of structure-avoidance constraints, and further obtain bounds on the number of non-equivalent solutions under row/column permutations. Moreover, via Rényi-entropy bounds for the MT distribution, we provide a computable lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete diversity guarantee for randomized constructions. Specializations for eliminating 4-cycle candidates yield closed-form bounds as functions of system parameters, offering a principled way to size memory/lifting and to estimate the remaining search space.

</details>


### [35] [Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information](https://arxiv.org/abs/2601.09679)
*Adel Javanmard,David P. Woodruff*

Main category: cs.IT

TL;DR: 本文解决了Courtade-Kumar猜想相关的两个重要问题：1) 证明了任意布尔函数（无论偏置）的输出与各噪声输入坐标互信息之和的上界为1-H(α)；2) 在高噪声区域改进了熵展开的误差界至O(λ²)，扩展了猜想成立的噪声参数范围。


<details>
  <summary>Details</summary>
Motivation: Courtade-Kumar猜想认为独裁函数在布尔超立方上最大化函数输出与其噪声输入之间的互信息。该猜想在信息论和布尔函数分析中具有重要意义，但之前的结果存在限制：1) 仅适用于平衡布尔函数；2) 在高噪声区域的误差界不够精确。

Method: 1) 对于第一个问题，采用信息论和布尔函数分析技术，推广了Courtade和Kumar之前的结果，移除了平衡函数的限制；2) 对于第二个问题，通过改进熵展开的渐近分析，获得了更精确的误差界O(λ²)，其中λ=(1-2α)²，并推导出高度信息性函数的尖锐线性傅里叶集中界。

Result: 1) 证明了任意布尔函数（无论偏置）的输出与各噪声输入坐标互信息之和的上界为1-H(α)，其中α是二进制对称信道的噪声参数；2) 在高噪声区域获得了最优的误差界O(λ²)，显著扩展了Courtade-Kumar猜想成立的噪声参数范围，并得到了高度信息性函数的尖锐线性傅里叶集中界。

Conclusion: 本文在Courtade-Kumar猜想研究方面取得了重要进展：1) 完全解决了Courtade和Kumar提出的开放问题，将互信息和上界推广到任意偏置的布尔函数；2) 在高噪声区域改进了分析技术，获得了更精确的误差界，显著扩展了猜想成立的参数范围，为进一步研究该猜想奠定了基础。

Abstract: The Courtade-Kumar conjecture posits that dictatorship functions maximize the mutual information between the function's output and a noisy version of its input over the Boolean hypercube. We present two significant advancements related to this conjecture. First, we resolve an open question posed by Courtade and Kumar, proving that for any Boolean function (regardless of bias), the sum of mutual information between the function's output and the individual noisy input coordinates is bounded by $1-H(α)$, where $α$ is the noise parameter of the Binary Symmetric Channel. This generalizes their previous result which was restricted to balanced Boolean functions. Second, we advance the study of the main conjecture in the high noise regime. We establish an optimal error bound of $O(λ^2)$ for the asymptotic entropy expansion, where $λ= (1-2α)^2$, improving upon the previous best-known bounds. This refined analysis leads to a sharp, linear Fourier concentration bound for highly informative functions and significantly extends the range of the noise parameter $λ$ for which the conjecture is proven to hold.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [36] [Joint Beamforming and Position Optimization for Movable-Antenna and Movable-Element RIS-Aided Full-Duplex 6G MISO Systems](https://arxiv.org/abs/2601.08922)
*Ayda Nodel Hokmabadi,Chadi Assi*

Main category: eess.SP

TL;DR: 该论文提出了一种利用可移动天线基站和可移动元件智能反射面来增强全双工MISO网络性能的新架构，通过联合优化天线位置、RIS元件位置和相位偏移来最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 全双工通信虽然能显著提高频谱效率，但实际部署受到强残余自干扰和用户间干扰的限制，严重降低系统性能。需要新的解决方案来克服这些挑战，特别是在6G系统中。

Method: 提出了一种全双工MISO网络架构，结合可移动天线基站和可移动元件智能反射面。通过联合优化发射和接收波束成形向量、上行链路发射功率、RIS相位偏移以及BS天线和RIS元件的空间位置来最大化系统和速率。采用交替优化算法，使用半定松弛进行波束成形设计，使用逐次凸逼近进行位置优化。

Result: 仿真结果表明，所提出的ME-RIS辅助架构结合可移动BS天线相比传统的固定位置全双工网络提供了显著性能增益。

Conclusion: 将可移动天线与可移动RIS元件集成是实现未来6G无线系统高性能全双工操作的关键使能技术，为解决全双工通信中的干扰问题提供了有效解决方案。

Abstract: Full-duplex communication substantially enhances spectral efficiency by enabling simultaneous transmission and reception on the same time-frequency resources. However, its practical deployment remains hindered by strong residual self-interference and inter-user interference, which severely degrade system performance. This work investigates a full-duplex MISO network that leverages movable-antenna base stations (MA-BS) and movable-element reconfigurable intelligent surfaces (ME-RIS) to overcome these limitations in next-generation 6G systems. Unlike conventional fixed-geometry architectures, the proposed framework jointly optimizes antenna and RIS element positions, together with RIS phase shifts, to strengthen desired links while suppressing interference. Our design objective is to maximize the system sum rate through the joint optimization of transmit and receive beamforming vectors, uplink transmit powers, RIS phase shifts, and the spatial locations of both the BS antennas and RIS elements. To solve this challenging nonconvex problem, an alternating optimization algorithm is developed, employing semidefinite relaxation for beamforming design and successive convex approximation for position optimization. Simulation results demonstrate that the proposed ME-RIS-assisted architecture with movable BS antennas offers substantial gains over conventional fixed-position full-duplex networks. These findings highlight the potential of integrating movable antennas with movable RIS elements as a key enabler for high-performance full-duplex operation in future 6G wireless systems.

</details>


### [37] [Robust Consensus-Based Distributed Beamforming for Wideband Cell-free Multi-RIS MISO Systems](https://arxiv.org/abs/2601.08946)
*Konstantinos D. Katsanos,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 提出了一种用于宽带无小区多RIS赋能的MISO系统的分布式协同主动和被动波束成形方案，以替代依赖中央处理单元的集中式方案。


<details>
  <summary>Details</summary>
Motivation: 无小区网络架构与可重构智能表面（RIS）的结合代表了未来无线网络的革命性架构。现有集中式方案依赖中央处理单元，存在合作开销问题，需要更高效的分布式替代方案。

Method: 针对宽带无小区多RIS赋能的MISO系统，考虑不完美的信道信息和RIS元件响应的实际频率选择性行为，提出基于共识更新的分布式优化方法，用于RIS相位配置。

Result: 仿真结果表明，所提出的分布式设计优于基于各种洛伦兹型宽带建模方法的集中式RIS方案。

Conclusion: 分布式协同主动和被动波束成形方案为宽带无小区多RIS系统提供了高效的替代方案，能够克服集中式方案的合作开销问题，在实际信道条件和频率选择性行为下表现优越。

Abstract: The cell-free networking paradigm constitutes a revolutionary architecture for future generations of wireless networks, which has been recently considered in synergy with Reconfigurable Intelligent Surfaces (RISs), a promising physical-layer technology for signal propagation programmability. In this paper, we focus on wideband cell-free multi-RIS-empowered Multiple-Input Single-Output (MISO) systems and present a decentralized cooperative active and passive beamforming scheme, aiming to provide an efficient alternative towards the cooperation overhead of available centralized schemes depending on central processing unit. Considering imperfect channel information availability and realistic frequency selectivity behavior of each RIS's element response, we devise a distributed optimization approach based on consensus updates for the RISs' phase configurations. Our simulation results showcase that the proposed distributed design is superior to centralized schemes that are based on various Lorentzian-type wideband modeling approaches for the RISs.

</details>


### [38] [Joint DOA and Non-circular Phase Estimation of Non-circular Signals for Antenna Arrays: Block Sparse Bayesian Learning Method](https://arxiv.org/abs/2601.09148)
*Zihan Shen,Jiaqi Li,Xudong Dong,Xiaofei Zhang*

Main category: eess.SP

TL;DR: 提出一种适用于任意未知非圆相位的块稀疏贝叶斯学习算法，用于非圆信号的DOA估计


<details>
  <summary>Details</summary>
Motivation: 针对非圆信号DOA估计问题，现有方法通常假设已知非圆相位或采用特定分布假设，无法处理任意未知非圆相位的情况，需要开发更通用的算法

Method: 1. 通过置换策略构建块稀疏非圆信号表示模型，捕捉块内结构信息；2. 在BSBL框架下建立稀疏概率模型并推导代价函数；3. 引入快速边缘似然最大化算法，通过基函数的增减实现快速信号恢复

Result: 仿真结果表明所提方法有效且性能优越，能够处理任意未知非圆相位，相比现有方法具有更好的恢复性能

Conclusion: 提出的BSBL算法能够有效处理任意未知非圆相位的DOA估计问题，通过利用块稀疏结构和快速实现算法，在性能上优于现有方法

Abstract: This letter proposes a block sparse Bayesian learning (BSBL) algorithm of non-circular (NC) signals for direction-of-arrival (DOA) estimation, which is suitable for arbitrary unknown NC phases. The block sparse NC signal representation model is constructed through a permutation strategy, capturing the available intra-block structure information to enhance recovery performance. After that, we create the sparse probability model and derive the cost function under BSBL framework. Finally, the fast marginal likelihood maximum (FMLM) algorithm is introduced, enabling the rapid implementation of signal recovery by the addition and removal of basis functions. Simulation results demonstrate the effectiveness and the superior performance of our proposed method.

</details>


### [39] [User-Centric Stream Sensing for Grant-Free Access: Deep Learning with Covariance Differencing](https://arxiv.org/abs/2601.09168)
*Sojeong Park,Yeongjun Kim,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 提出差分流感知框架，通过协方差差分隔离新激活流，结合深度学习分类器，在过载场景下提升免授权接入性能


<details>
  <summary>Details</summary>
Motivation: 免授权接入面临碰撞风险，用户侧感知可缓解碰撞，但传统方法在过载场景（活跃流超过接收天线数）下失效，需要新解决方案

Method: 提出差分流感知框架，将问题从估计总流数重构为通过协方差差分隔离新激活流；分析信道变化引起的协方差偏差，建立基于信道相关的理论边界确定感知窗口大小；集成深度学习分类器缓解有限采样带来的残余干扰

Result: 在独立同分布平坦瑞利衰落和标准化信道环境下的仿真表明，该方法始终优于非深度学习基线，并在过载场景下保持鲁棒性

Conclusion: 差分流感知框架结合深度学习分类器能有效解决免授权接入在过载场景下的碰撞问题，提供优于传统方法的性能

Abstract: Grant-free (GF) access is essential for massive connectivity but faces collision risks due to uncoordinated transmissions. While user-side sensing can mitigate these collisions by enabling autonomous transmission decisions, conventional methods become ineffective in overloaded scenarios where active streams exceed receive antennas. To address this problem, we propose a differential stream sensing framework that reframes the problem from estimating the total stream count to isolating newly activated streams via covariance differencing. We analyze the covariance deviation induced by channel variations to establish a theoretical bound based on channel correlation for determining the sensing window size. To mitigate residual interference from finite sampling, a deep learning (DL) classifier is integrated. Simulations across both independent and identically distributed flat Rayleigh fading and standardized channel environments demonstrate that the proposed method consistently outperforms non-DL baselines and remains robust in overloaded scenarios.

</details>


### [40] [WiFo-M$^2$: Plug-and-Play Multi-Modal Sensing via Foundation Model to Empower Wireless Communications](https://arxiv.org/abs/2601.09179)
*Haotian Zhang,Shijian Gao,Xiang Cheng*

Main category: eess.SP

TL;DR: WiFo-M²是一个可插入现有深度学习收发器的通用基础模型，通过对比预训练从多模态传感中提取可泛化的带外信道特征，提升多种收发器设计的性能。


<details>
  <summary>Details</summary>
Motivation: 随着传感器丰富的智能系统普及，多模态传感被用于改进无线通信。但传统方法需要大量手动设计数据预处理、网络架构和任务特定微调，限制了开发可扩展性和实际部署。

Method: 提出WiFo-M²基础模型，引入ContraSoM对比预训练策略从多模态传感中提取可泛化的带外信道特征。预训练后，模型从历史传感器数据推断未来带外信道特征，并通过模态特定数据增强增强特征鲁棒性。

Result: 实验表明WiFo-M²在多种收发器设计中都能提升性能，并对未见场景表现出强大的泛化能力。

Conclusion: WiFo-M²是一个可轻松集成到现有深度学习收发器中的基础模型，通过对比预训练和多模态传感实现通用性能提升，解决了传统方法开发可扩展性和部署限制的问题。

Abstract: The growing adoption of sensor-rich intelligent systems has boosted the use of multi-modal sensing to improve wireless communications. However, traditional methods require extensive manual design of data preprocessing, network architecture, and task-specific fine-tuning, which limits both development scalability and real-world deployment. To address this, we propose WiFo-M$^2$, a foundation model that can be easily plugged into existing deep learning-based transceivers for universal performance gains. To extract generalizable out-of-band (OOB) channel features from multi-modal sensing, we introduce ContraSoM, a contrastive pre-training strategy. Once pre-trained, WiFo-M$^2$ infers future OOB channel features from historical sensor data and strengthens feature robustness via modality-specific data augmentation. Experiments show that WiFo-M$^2$ improves performance across multiple transceiver designs and demonstrates strong generalization to unseen scenarios.

</details>


### [41] [WiFo-E: A Scalable Wireless Foundation Model for End-to-End FDD Precoding in Communication Networks](https://arxiv.org/abs/2601.09186)
*Weibo Wen,Shijian Gao,Haotian Zhang,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: WiFo-E是一个用于大规模MIMO FDD系统可扩展端到端预编码的无线基础模型，通过多任务预训练和稀疏MoE Transformer架构学习可迁移的无线原理表示，能泛化到未见过的系统配置。


<details>
  <summary>Details</summary>
Motivation: 传统端到端学习框架在大规模MIMO FDD系统中缺乏可扩展性，无法泛化到不同系统配置（如天线数和用户数变化），需要更灵活的解决方案。

Method: 采用多任务预训练在多样化配置上学习可迁移的无线原理表示，核心是稀疏混合专家（MoE）Transformer架构，通过自适应激活专用参数子集来减轻任务干扰并提高训练效率。

Result: 大量仿真表明WiFo-E优于传统的按配置训练方法，对未见过的系统配置表现出强大的泛化能力。

Conclusion: WiFo-E为自适应大规模MIMO预编码提供了一个灵活高效的基础模型，解决了传统端到端学习框架的可扩展性和泛化性问题。

Abstract: Accurate precoding in massive multiple-input multiple-output (MIMO) frequency-division duplexing (FDD) systems relies on efficient channel state information (CSI) acquisition. End-to-end learning frameworks improve performance by jointly optimizing this process, but they lack scalability and fail to generalize across different system configurations, such as varying numbers of antennas and users. To overcome this limitation, we introduce WiFo-E, a wireless foundation model designed for scalable end-to-end precoding. WiFo-E employs multi-task pretraining on a diverse set of configurations to learn transferable representations of underlying wireless principles. Central to the model is a sparse Mixture-of-Experts (MoE) Transformer architecture, which mitigates task interference and enhances training efficiency by activating specialized parameter subsets adaptively. Extensive simulations demonstrate that WiFo-E outperforms conventional per-configuration training and shows strong generalization to unseen system configurations, providing a flexible and efficient foundation for adaptive massive MIMO precoding.

</details>


### [42] [Artificial Intelligence Empowered Channel Prediction: A New Paradigm for Propagation Channel Modeling](https://arxiv.org/abs/2601.09205)
*Ruisi He,Mi Yang,Zhengyu Zhang,Bo Ai,Zhangdui Zhong*

Main category: eess.SP

TL;DR: 提出AI赋能的传播信道预测新范式，通过深度集成环境数据和物理知识实现站点特定信道推断，显著提升预测精度和效率


<details>
  <summary>Details</summary>
Motivation: 传统信道建模方法存在局限性，需要更准确、高效的站点特定信道预测方法来支持未来通信网络发展

Method: 提出综合框架，将异构环境数据和物理传播知识深度集成到AI模型中，采用AI-native和AI-hybrid推理方法，结合迁移学习和可解释AI技术

Result: 平均路径损耗预测RMSE约4dB，训练时间减少60%-75%，实现了高精度、高效率的信道预测

Conclusion: 该AI赋能的信道预测新范式为未来通信网络提供了高保真、可泛化且物理一致的传播信道预测基础路径

Abstract: This paper proposes a novel paradigm centered on Artificial Intelligence (AI)-empowered propagation channel prediction to address the limitations of traditional channel modeling. We present a comprehensive framework that deeply integrates heterogeneous environmental data and physical propagation knowledge into AI models for site-specific channel prediction, which referred to as channel inference. By leveraging AI to infer site-specific wireless channel states, the proposed paradigm enables accurate prediction of channel characteristics at both link and area levels, capturing spatio-temporal evolution of radio propagation. Some novel strategies to realize the paradigm are introduced and discussed, including AI-native and AI-hybrid inference approaches. This paper also investigates how to enhance model generalization through transfer learning and improve interpretability via explainable AI techniques. Our approach demonstrates significant practical efficacy, achieving an average path loss prediction root mean square error (RMSE) of $\sim$ 4 dB and reducing training time by 60\%-75\%. This new modeling paradigm provides a foundational pathway toward high-fidelity, generalizable, and physically consistent propagation channel prediction for future communication networks.

</details>


### [43] [Range-Doppler-Acceleration Estimation for Fast-Moving and Accelerating Targets](https://arxiv.org/abs/2601.09317)
*Nadav Neuberger,Simon Kollecker,Martin Kaeske*

Main category: eess.SP

TL;DR: 提出一种广义波形无关的距离-多普勒压缩方法，补偿传统方法在非线性目标运动、宽带信号等场景下的性能退化


<details>
  <summary>Details</summary>
Motivation: 传统雷达信号处理方法基于线性目标运动、窄带操作或恒定速度等简化假设，但在涉及二次距离-时间行为、高径向速度/加速度或宽带信号的场景中，这些假设会失效，导致脉冲内多普勒频移/拉伸和目标在距离-多普勒单元间迁移等问题

Method: 提出一种广义波形无关的距离-多普勒压缩方法，能够补偿这些效应，同时保持最小的信噪比损失和实际计算效率

Result: 分析了所提方法的性能极限，并通过一个依赖于场景和系统参数的统一度量来表达；与其他方法比较显示，传统方法存在估计偏差和性能退化

Conclusion: 该方法能够有效处理传统假设失效的场景，为雷达信号处理提供了一种更通用和鲁棒的解决方案

Abstract: A central aspect of every pulsed radar signal processor is the targets Range-Doppler estimation within a Coherent Processing Interval. Conventional methods typically rely on simplifying assumptions, such as linear target motion, narrowband operation, or constant velocity, to enable fast computation. However, these assumptions break down in scenarios involving quadratic range-time behavior, high radial velocities or accelerations, or wideband signals, leading to undesired effects such as intra-pulse Doppler shift/stretch and target migration across Range-Doppler cells. This paper presents a generalized waveform-independent Range-Doppler compression approach that compensates for these effects while maintaining minimal Signal-to-Noise-Ratio loss and practical computational efficiency. The performance limits of the proposed method are analyzed and expressed through a unified metric that depends on both scene and system parameters. Comparison with other approaches is presented, showing their estimation bias and performance degradation.

</details>


### [44] [A Hybrid Machine Learning Framework for Improved Short-Term Peak-Flow Forecasting](https://arxiv.org/abs/2601.09336)
*Gabriele Bertoli,Kai Schroeter,Rossella Arcucci,Enrica Caporali*

Main category: eess.SP

TL;DR: 提出结合XGBoost和随机森林的混合框架，用于河流流量和洪峰预测，在857个流域上验证，性能优于欧洲洪水预警系统。


<details>
  <summary>Details</summary>
Motivation: 传统基于过程的模型和纯数据驱动方法在极端事件（特别是洪峰预测）中表现不佳，需要更可靠的河流流量预测来支持洪水风险管理和早期预警系统。

Method: 开发混合预测框架：使用XGBoost进行连续径流预测，随机森林专门训练用于洪峰预测，将两者输出结合为增强预测。在LamaH-CE数据集的857个流域上实施，使用6小时分辨率的降雨和流量观测数据。

Result: 71%的流域Kling-Gupta效率大于0.90；洪峰检测率达到87%，误报率13%；相比欧洲洪水预警系统，峰值误差更低、误报更少、流量和洪峰预测精度更高；计算轻量，标准CPU上仅需数秒训练时间。

Conclusion: 该框架展示了将水文理解与高效机器学习结合提升洪水预测准确性和可靠性的潜力，为混合水文-机器学习模型开发指明了未来方向。

Abstract: Reliable river flow forecasting is an essential component of flood risk management and early warning systems. It enables improved emergency response coordination and is critical for protecting infrastructure, communities, and ecosystems from extreme hydrological events. Process-based hydrological models and purely data-driven approaches often underperform during extreme events, particularly in forecasting peak flows. To address this limitation, this study introduces a hybrid forecasting framework that couples Extreme Gradient Boosting (XGBoost) and Random Forest (RF). XGBoost is employed for continuous streamflow forecasting, while RF is specifically trained for peak-flow prediction, and the two outputs are combined into an enhanced forecast. The approach is implemented across 857 catchments of the LamaH-CE dataset, using rainfall and discharge observations at 6-hour resolution. Results demonstrate consistently high skill, with 71% of catchments achieving a Kling-Gupta Efficiency (KGE) greater than 0.90. Peak-flow detection reaches 87%, with a false-alarm rate of 13%. Compared to the European Flood Awareness System (EFAS), the framework achieves lower peak-magnitude errors, fewer false alarms, and improved streamflow and peak-flow forecasting accuracy. The proposed framework is computationally lightweight, scalable, and easily transferable across watersheds, with training times of only seconds on standard CPUs. These findings highlight the potential of integrating hydrological understanding with efficient machine learning to improve the accuracy and reliability of operational flood forecasting, and outline future directions for hybrid hydrological-machine learning model development.

</details>


### [45] [Unique Word Channel Estimation for Oversampled OTFS](https://arxiv.org/abs/2601.09364)
*Radim Zedka,Roman Marsalek,Marek Bobula,Arman Farhang*

Main category: eess.SP

TL;DR: 本文首次研究OTFS中过采样和脉冲成形导致的数据-导频能量泄漏问题，提出UW-OTFS新方案，在频谱效率、误码率和带外辐射方面优于传统OTFS。


<details>
  <summary>Details</summary>
Motivation: OTFS中的信道估计和分数延迟多普勒信道性能是研究热点，但现有文献未在信道估计背景下讨论过采样和脉冲成形导致的数据-导频能量泄漏问题。

Method: 1) 对采用嵌入式导频信道估计技术的过采样脉冲成形OTFS进行理论分析；2) 提出UW-OTFS新方案，将导频放置在过采样时域而非DD域；3) 分析能量泄漏与脉冲成形引入的额外带宽之间的权衡关系。

Result: 1) 揭示了能量泄漏与额外带宽之间的权衡关系；2) UW-OTFS比嵌入式导频OTFS的频谱效率提高36%；3) UW-OTFS在误码率和带外辐射方面优于传统OTFS。

Conclusion: 本文首次解决了OTFS中过采样和脉冲成形导致的能量泄漏问题，提出的UW-OTFS方案在多个性能指标上显著优于传统OTFS，为OTFS系统的实际应用提供了重要改进。

Abstract: Practical aspects of orthogonal time frequency space (OTFS), such as channel estimation and its performance in fractional delay-Doppler (DD) channels, are a lively topic in the OTFS community. Oversampling and pulse shaping are also discussed in the existing literature, but not in the context of channel estimation. To the best of our knowledge, this paper is the first to address the problem of data-to-pilot and vice versa energy leakage caused by oversampling and pulse shaping in OTFS. Theoretical analysis is performed on an oversampled, pulse-shaped OTFS implementing the embedded pilot channel estimation technique, revealing a trade-off between the amount of energy leakage and excess bandwidth introduced by the pulse shape. Next, a novel variant of OTFS is introduced, called UW-OTFS, which is designed to overcome the leakage problem by placing the pilot in the oversampled time domain instead of the DD domain. The unique structure of UW-OTFS offers 36 percent higher spectral efficiency than the OTFS with embedded pilot. UW-OTFS also outperforms traditional OTFS in terms of bit error ratio and out-of-band emissions.

</details>


### [46] [Uplink Multi-User MIMO Implementation in OpenAirInterface for a Cell-Free O-RAN Testbed](https://arxiv.org/abs/2601.09384)
*Utku Uçak,Fariba Armandoust,Matthias Mehlhose,Daniel Schäufele,Jochen Fink,Renato L. G. Cavalcante,Sławomir Stańczak*

Main category: eess.SP

TL;DR: 基于OpenAirInterface的实时上行多用户MIMO测试平台，验证了使用SRS信道估计计算上行组合器的可行性，为构建完整无小区MU-MIMO系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 无小区MIMO和O-RAN是无线通信领域的研究热点，需要实际测试平台来验证新想法。OpenAirInterface作为开源的5G协议栈实现，为部署和测试无线通信系统提供了宝贵工具。

Method: 使用通用计算机和商用软件定义无线电构建2x2 MU-MIMO系统，采用修改的OAI gNB和两个未修改的OAI UE，利用SRS信道估计计算上行组合器来分离和解码非正交时频资源中的用户信号。

Result: 验证了使用SRS信道估计计算上行组合器的方法能够有效分离和解码两个用户在非正交时频资源中传输的信号，证明了该方法的可行性。

Conclusion: 这项工作为构建完整的无小区MU-MIMO系统提供了重要验证步骤，该系统将利用TDD互易性在多个小区进行下行波束成形。

Abstract: Cell-Free Multiple-Input Multiple-Output (MIMO) and Open Radio Access Network (O-RAN) have been active research topics in the wireless communication community in recent years. As an open-source software implementation of the 3rd Generation Partnership Project (3GPP) 5th Generation (5G) protocol stack, OpenAirInterface (OAI) has become a valuable tool for deploying and testing new ideas in wireless communication systems. In this paper, we present our OAI based real-time uplink Multi-User MIMO (MU-MIMO) testbed developed at Fraunhofer HHI. As a part of our Cell-Free MIMO testbed development, we built a 2x2 MU-MIMO system using general purpose computers and commercially available software defined radios (SDRs). Using a modified OAI next-Generation Node-B (gNB) and two unmodified OAI user equipment (UE), we show that it is feasible to use Sounding Reference Signal (SRS) channel estimates to compute uplink combiners. Our results verify that this method can be used to separate and decode signals from two users transmitting in nonorthogonal time-frequency resources. This work serves as an important verification step to build a complete Cell-Free MU-MIMO system that leverages time domain duplexing (TDD) reciprocity to do downlink beamforming over multiple cells.

</details>


### [47] [Beamforming Gain with Nonideal Phase Shifters](https://arxiv.org/abs/2601.09426)
*Heedong Do,Angel Lozano*

Main category: eess.SP

TL;DR: 提出通用框架分析非理想移相器的波束成形增益损失，证明损失由可行波束成形系数凸包周长决定，适用于发射端、接收端和智能反射面


<details>
  <summary>Details</summary>
Motivation: 实际系统中移相器通常非理想，需要量化分析非理想移相器对波束成形性能的影响，建立通用理论框架

Method: 建立通用数学框架，分析任意非理想移相器的波束成形增益损失，推导损失与可行波束成形系数凸包周长的关系

Result: 证明波束成形增益损失由可行系数凸包周长决定，在i.i.d.衰落信道中，当天线数增加时损失收敛到最大可能损失

Conclusion: 非理想移相器的波束成形性能损失有理论极限，由凸包周长决定，为实际系统设计提供理论指导

Abstract: This research sets forth a universal framework to characterize the beamforming gain achievable with arbitrarily nonideal phase shifters. Precisely, the maximum possible shortfall relative to the gain attainable with ideal phase shifters is established. Such shortfall is shown to be fundamentally determined by the perimeter of the convex hull of the set of feasible beamforming coefficients on the complex plane. This result holds regardless of whether the beamforming is at the transmitter, at the receiver, or at a reconfigurable intelligent surface. In i.i.d. fading channels, the shortfall hardens to the maximum possible shortfall as the number of antennas grows.

</details>


### [48] [Two-Scale Spatial Deployment for Cost-Effective Wireless Networks via Cooperative IRSs and Movable Antennas](https://arxiv.org/abs/2601.09463)
*Ying Gao,Qingqing Wu,Ziyuan Zheng,Yanze Zhu,Wen Chen,Xin Lin,Shanpu Shen*

Main category: eess.SP

TL;DR: 提出两尺度空间部署策略，结合宏观智能反射面和细粒度可移动天线，为多个目标区域提供可靠覆盖，最小化部署成本。


<details>
  <summary>Details</summary>
Motivation: 现有部署策略要么依赖独立区域规划，要么采用全IRS部署，成本效率不高。需要一种能同时利用大规模传播几何和小尺度信道变化的集成方案。

Method: 提出两尺度部署：宏观层面从候选站点选择性部署IRS以塑造传播几何；微观层面在离散位置重新定位MA以利用小尺度信道变化。采用基于惩罚的双循环算法，结合交替优化和逐次凸逼近解决混合整数非凸优化问题。

Result: 仿真结果表明，所提设计在成本效率上优于独立区域规划或全IRS部署的基准方案。对于成本最小化，大放置孔径下MA架构更优，紧凑孔径下全FPA架构更优；对于最坏情况SNR最大化，MA架构具有更低的可行性成本阈值。

Conclusion: 两尺度IRS-MA集成部署策略能有效平衡成本与覆盖性能，为不同场景提供适应性解决方案，显著提升无线网络部署的成本效率。

Abstract: This paper proposes a two-scale spatial deployment strategy to ensure reliable coverage for multiple target areas, integrating macroscopic intelligent reflecting surfaces (IRSs) and fine-grained movable antennas (MAs). Specifically, IRSs are selectively deployed from candidate sites to shape the propagation geometry, while MAs are locally repositioned among discretized locations to exploit small-scale channel variations. The objective is to minimize the total deployment cost of MAs and IRSs by jointly optimizing the IRS site selection, MA positions, transmit precoding, and IRS phase shifts, subject to the signal-to-noise ratio (SNR) requirements for all target areas. This leads to a challenging mixed-integer non-convex optimization problem that is intractable to solve directly. To address this, we first formulate an auxiliary problem to verify the feasibility. A penalty-based double-loop algorithm integrating alternating optimization and successive convex approximation (SCA) is developed to solve this feasibility issue, which is subsequently adapted to obtain a suboptimal solution for the original cost minimization problem. Finally, based on the obtained solution, we formulate an element refinement problem to further reduce the deployment cost, which is solved by a penalty-based SCA algorithm. Simulation results demonstrate that the proposed designs consistently outperform benchmarks relying on independent area planning or full IRS deployment in terms of cost-efficiency. Moreover, for cost minimization, MA architectures are preferable in large placement apertures, whereas fully populated FPA architectures excel in compact ones; for worst-case SNR maximization, MA architectures exhibit a lower cost threshold for feasibility, while FPA architectures can attain peak SNR at a lower total cost.

</details>


### [49] [Echo-Side Integrated Sensing and Communication via Space-Time Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.09484)
*Marouan Mizmizi,Stefano Tebaldini,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 提出了一种用于集成感知与通信系统的回波侧调制框架，利用空时可重构智能表面在雷达回波上施加连续相位调制，实现上行数据传输与感知功能的共享。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信系统需要同时实现感知和通信功能，但传统方法中这两种功能往往相互干扰。本文旨在解决感知波形与通信信号之间的资源竞争问题，通过创新的调制框架实现两者的高效协同。

Method: 采用空时可重构智能表面在雷达回波上施加连续相位调制，将通信数据嵌入感知波形中。接收信号是感知波形和通信相位的乘积组合。推导了通信速率与耦合参数的关系，建立了凸帕累托前沿，并给出了满足最小感知要求的最优带宽分配闭式解。

Result: 推导了距离估计的修正克拉美罗界闭式解，提出了基于广义似然比检验的帧同步方法，并通过特征函数反演获得检测概率。数值结果验证了理论界限，并表征了整个工作范围内的权衡关系。

Conclusion: 提出的回波侧调制框架有效实现了感知与通信功能的集成，通过理论分析和数值验证展示了系统性能的帕累托最优权衡，为ISAC系统设计提供了新的解决方案。

Abstract: This paper presents an echo-side modulation framework for integrated sensing and communication (ISAC) systems. A space-time reconfigurable intelligent surface (ST-RIS) impresses a continuous-phase modulation onto the radar echo, enabling uplink data transmission with a phase modulation of the transmitted radar-like waveform. The received signal is a multiplicative composition of the sensing waveform and the phase for communication. Both functionalities share the same physical signal and perceive each other as impairments.
  The achievable communication rate is expressed as a function of a coupling parameter that links sensing accuracy to phase error accumulation. Under a fixed bandwidth constraint, the sensing and communication figures of merit define a convex Pareto frontier. The optimal bandwidth allocation satisfying a minimum sensing requirement is derived in closed form. The modified Cramer-Rao bound (MCRB) for range estimation is derived in closed form; this parameter must be estimated to compensate for the frequency offset before data demodulation. Frame synchronization is formulated as a generalized likelihood ratio test (GLRT), and the detection probability is obtained through characteristic function inversion, accounting for residual frequency errors from imperfect range estimation. Numerical results validate the theoretical bounds and characterize the trade-off across the operating range.

</details>


### [50] [Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems](https://arxiv.org/abs/2601.09701)
*Fahimeh Orvati Nia,Shima Salehi,Joshua Peeples*

Main category: eess.SP

TL;DR: 本文提出了一种基于GAN-LSTM的智能电表异常检测框架，在LEAD数据集上取得了0.89的F1分数，显著优于六种基线方法。


<details>
  <summary>Details</summary>
Motivation: 高级计量基础设施（AMI）提供的高分辨率用电数据对现代配电系统的监控、诊断和决策至关重要，但由于非线性、非平稳和多尺度的时间特性，以及不同建筑类型和运行条件的多样性，检测这些时间序列中的异常具有挑战性。

Method: 提出了一个系统化的、面向电力系统的GAN-LSTM框架评估方法，使用LEAD数据集（包含406栋建筑一年的小时级测量数据）。采用一致的预处理、时间窗口化和阈值选择流程，并将GAN-LSTM方法与六种广泛使用的基线方法（包括统计、核方法、重构方法和GAN模型）进行比较。

Result: 实验结果表明，GAN-LSTM显著提高了检测性能，F1分数达到0.89，优于所有基线方法。

Conclusion: 对抗性时间建模具有作为实际工具支持资产监控、非技术损失检测和配电网络态势感知的潜力。该工作的代码已公开可用。

Abstract: Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly available

</details>
