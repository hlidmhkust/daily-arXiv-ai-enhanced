<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 6]
- [eess.IV](#eess.IV) [Total: 3]
- [cs.IT](#cs.IT) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Multiscale Approach for Enhancing Weak Signal Detection](https://arxiv.org/abs/2510.20828)
*Dixon Vimalajeewa,Ursula U. Muller,Brani Vidakovic*

Main category: eess.SP

TL;DR: 提出了一种双阈值检测系统，结合随机共振和多尺度分析来增强弱信号检测，相比传统单阈值方法在原始数据域和频域都表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统随机共振技术基于单阈值检测器，只能处理与时间无关的信号，且需要大量噪声，这会扭曲复杂信号特征。需要解决这些限制来改进弱信号检测。

Method: 开发了双阈值检测系统，整合两个单阈值检测器，在原始数据域和多尺度域（使用小波变换）进行评估，并与现有方法比较性能。

Result: 在原始数据域中，双阈值检测器显著改善了弱信号检测；在频域中性能进一步提升，需要更低的噪声水平且优于现有检测系统。

Conclusion: 该研究通过引入稳健的弱信号识别方法推进了基于随机共振的检测方法学，在多个学科中具有潜在应用价值。

Abstract: Stochastic resonance (SR), a phenomenon originally introduced in climate
modeling, enhances signal detection by leveraging optimal noise levels within
non-linear systems. Traditional SR techniques, mainly based on single-threshold
detectors, are limited to signals whose behavior does not depend on time. Often
large amounts of noise are needed to detect weak signals, which can distort
complex signal characteristics. To address these limitations, this study
explores multi-threshold systems and the application of SR in multiscale
applications using wavelet transforms. In the multiscale domain signals can be
analyzed at different levels of resolution to better understand the underlying
dynamics.
  We propose a double-threshold detection system that integrates two
single-threshold detectors to enhance weak signal detection. We evaluate it
both in the original data domain and in the multiscale domain using simulated
and real-world signals and compare its performance with existing methods.
  Experimental results demonstrate that, in the original data domain, the
proposed double-threshold detector significantly improves weak signal detection
compared to conventional single-threshold approaches. Its performance is
further improved in the frequency domain, requiring lower noise levels while
outperforming existing detection systems. This study advances SR-based
detection methodologies by introducing a robust approach to weak signal
identification, with potential applications in various disciplines.

</details>


### [2] [Is Repeater-Assisted Massive MIMO Compatible with Dynamic TDD?](https://arxiv.org/abs/2510.20998)
*Martin Andersson,Anubhab Chowdhury,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出了一个在动态TDD中继辅助大规模MIMO网络中联合优化中继器增益放大和相移的框架，通过算法校准中继器增益以放大期望信号同时限制干扰。


<details>
  <summary>Details</summary>
Motivation: 中继器作为具有放大和相移功能的有源散射体，能增强用户接收信号强度，但在动态TDD系统中会同时放大噪声和干扰信号，特别是由于上下行并发传输引入的跨链路干扰，导致期望信号和干扰信号放大之间存在复杂权衡。

Method: 首先推导下行和上行频谱效率，然后开发用于频谱效率最大化的中继器增益优化算法。

Result: 数值结果表明，所提算法成功校准中继器增益，在放大期望信号的同时限制干扰。

Conclusion: 该框架能够有效解决动态TDD中继辅助网络中期望信号与干扰信号放大之间的权衡问题，通过优化中继器增益提升系统性能。

Abstract: We present a framework for joint amplification and phase shift optimization
of the repeater gain in dynamic time-division duplex (TDD) repeater-assisted
massive MIMO networks. Repeaters, being active scatterers with amplification
and phase shift, enhance the received signal strengths for users. However, they
inevitably also amplify undesired noise and interference signals, which become
particularly prominent in dynamic TDD systems due to the concurrent downlink
(DL) and uplink (UL) transmissions, introducing cross-link interference among
access points and users operating in opposite transmit directions. This causes
a non-trivial trade-off between amplification of desired and undesired signals.
To underpin the conditions under which such a trade-off can improve
performance, we first derive DL and UL spectral efficiencies (SEs), and then
develop a repeater gain optimization algorithm for SE maximization.
Numerically, we show that our proposed algorithm successfully calibrates the
repeater gain to amplify the desired signal while limiting the interference.

</details>


### [3] [6D Movable Holographic Surface Assisted Integrated Data and Energy Transfer: A Sensing Enhanced Approach](https://arxiv.org/abs/2510.21137)
*Zhonglun Wang,Yizhe Zhao,Gangming Hu,Yali Zheng,Kun Yang*

Main category: eess.SP

TL;DR: 本文提出了一种6D可移动全息表面集成数据与能量传输系统，通过三阶段协议协调6DMHS，有效服务IDET接收器，显著提升了IDET性能。


<details>
  <summary>Details</summary>
Motivation: 可重构全息表面的大规模阵列具有高空间增益，但其幅度控制的全息波束成形存在方向波动问题，难以充分利用RHS的空间增益。6D可移动天线为解决这一问题提供了潜在方案。

Method: 提出三阶段协议：上行链路感知阶段、方向调整阶段和下行链路传输阶段。首先利用全息感知技术获取接收器信息，然后优化6DMHS的方向和位置，最后设计数字波束成形、功率分配因子和能量收集功率。

Result: 仿真结果表明，所提出的方案能够将最大波束成形增益方向与每个IDET接收器对齐，相比基准方法显著提升了IDET性能。

Conclusion: 6D可移动全息表面集成数据与能量传输系统通过协调感知、方向调整和传输优化，有效解决了全息波束成形的方向波动问题，实现了性能提升。

Abstract: Reconfigurable holographic surface (RHS) enables cost-effective large-scale
arrays with high spatial gain. However, its amplitude-controlled holographic
beamforming suffers from directional fluctuations, making it difficult to fully
exploit the spatial gain of RHS. Fortunately, the promising 6D movable antenna
(6DMA) provides a potential solution to this problem. In this paper, we study a
6D movable holographic surface (6DMHS) integrated data and energy transfer
(IDET) system, where a three-stage protocol is proposed, consisting of an
uplink sensing stage, an orientation adjustment stage and a downlink
transmission stage, to coordinate the 6DMHS and effectively serve the IDET
receivers. Firstly, the holographic-based sensing technology is proposed and
the sensing information of the IDET receivers is exploited. Secondly, by fixing
the rotations with the sensing information, the orientation optimization
problem is formulated for designing the holographic beamforming of the RHS and
adjusting the translations of the 6DMHS. As a result, the directions with
maximum beamforming gain are aligned with each IDET receiver. Thirdly, by
fixing the orientation of the 6DMHS and the holographic beamforming, the
equivalent wireless channel is obtained. The IDET performance optimization
problem is formulated for obtaining the optimal digital beamforming, power
splitting factor and energy harvesting (EH) power. Simulation results
demonstrate that the proposed scheme is capable of improving the IDET
performance compared to the benchmarks.

</details>


### [4] [Track-to-Track Association for Collective Perception based on Stochastic Optimization](https://arxiv.org/abs/2510.21278)
*Laura M. Wolf,Vincent Albert Wolff,Simon Steuernagel,Kolja Thormann,Marcus Baum*

Main category: eess.SP

TL;DR: 提出基于随机优化的多传感器轨迹关联算法，通过多维似然度计算多个关联假设，在模糊场景中实现高似然度关联


<details>
  <summary>Details</summary>
Motivation: 解决智能车辆集体感知中的轨迹关联问题，克服现有方法计算复杂度高或基于启发式的局限性

Method: 采用随机优化方法，利用包含轨迹数量和空间分布的多维似然度，计算多个关联假设

Result: 在蒙特卡洛模拟和真实集体感知场景中验证了算法的有效性，能够在模糊设置中计算高似然度关联

Conclusion: 提出的随机优化关联算法能够有效解决多传感器融合中的轨迹关联问题，优于传统方法

Abstract: Collective perception is a key aspect for autonomous driving in smart cities
as it aims to combine the local environment models of multiple intelligent
vehicles in order to overcome sensor limitations. A crucial part of
multi-sensor fusion is track-to-track association. Previous works often suffer
from high computational complexity or are based on heuristics. We propose an
association algorithms based on stochastic optimization, which leverages a
multidimensional likelihood incorporating the number of tracks and their
spatial distribution and furthermore computes several association hypotheses.
We demonstrate the effectiveness of our approach in Monte Carlo simulations and
a realistic collective perception scenario computing high-likelihood
associations in ambiguous settings.

</details>


### [5] [Optimized Power Control for Multi-User Integrated Sensing and Edge AI](https://arxiv.org/abs/2510.21378)
*Biao Dong,Bin Cao*

Main category: eess.SP

TL;DR: 本文研究了一个集成传感与边缘人工智能系统，其中多个设备首先传输探测信号进行目标感知，然后通过模拟空中计算将本地提取的特征卸载到接入点进行协同推理。


<details>
  <summary>Details</summary>
Motivation: 研究集成传感与边缘人工智能系统，探索空中计算误差与推理性能之间的关系，为协同推理提供理论基础和优化方案。

Method: 建立了两个代理模型：最小化聚合失真的计算最优代理和最大化类间可分性的决策最优代理，并针对时分复用和频分复用场景推导了最优收发器设计的闭式功率分配方案。

Result: 理论分析揭示了时分复用场景下的阈值结构和频分复用场景下的双分解结构，实验结果验证了理论发现的有效性。

Conclusion: 提出的集成传感与边缘人工智能系统框架和优化方法能够有效提升协同推理性能，为实际应用提供了理论指导。

Abstract: This work investigates an integrated sensing and edge artificial intelligence
(ISEA) system, where multiple devices first transmit probing signals for target
sensing and then offload locally extracted features to the access point (AP)
via analog over-the-air computation (AirComp) for collaborative inference. To
characterize the relationship between AirComp error and inference performance,
two proxies are established: the \emph{computation-optimal} proxy that
minimizes the aggregation distortion, and the \emph{decision-optimal} proxy
that maximizes the inter-class separability, respectively. Optimal transceiver
designs in terms of closed-form power allocation are derived for both
time-division multiplexing (TDM) and frequency-division multiplexing (FDM)
settings, revealing threshold-based and dual-decomposition structures,
respectively. Experimental results validate the theoretical findings.

</details>


### [6] [On Irradiance Distributions for Weakly Turbulent FSO Links: Log-Normal vs. Gamma-Gamma](https://arxiv.org/abs/2510.21509)
*Carmen Álvarez Roa,Yunus Can Gültekin,Vincent van Vliet,Menno van den Hout,Chigo Okonkwo,Alex Alvarado*

Main category: eess.SP

TL;DR: 实验表明对数正态分布无法准确描述弱湍流下的光强波动，Gamma-Gamma模型更准确


<details>
  <summary>Details</summary>
Motivation: 验证弱湍流中常用的对数正态分布模型是否准确描述光强波动特性

Method: 通过实验测量弱湍流条件下的光强波动数据，对比分析对数正态分布和Gamma-Gamma模型的拟合效果

Result: 对数正态分布在弱湍流条件下无法准确捕捉光强波动特征，而Gamma-Gamma模型表现出更好的准确性

Conclusion: 在弱湍流建模中，Gamma-Gamma模型比传统的对数正态分布更适合描述光强波动特性

Abstract: Weak turbulence is commonly modeled using the log-normal distribution. Our
experimental results show that this distribution fails to capture irradiance
fluctuations in this regime. The Gamma-Gamma model is shown to be more
accurate.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [7] [Lightweight Classifier for Detecting Intracranial Hemorrhage in Ultrasound Data](https://arxiv.org/abs/2510.20857)
*Phat Tran,Enbai Kuang,Fred Xu*

Main category: eess.IV

TL;DR: 该研究使用机器学习方法结合超声组织脉动成像(TPI)自动检测创伤性脑损伤(TBI)引起的颅内出血(ICH)，在资源受限环境中提供便携式诊断方案。


<details>
  <summary>Details</summary>
Motivation: 传统CT和MRI诊断颅内出血存在成本高、可用性有限和基础设施依赖等问题，特别是在资源受限环境中。需要开发便携、低成本的替代诊断方法。

Method: 使用超声TPI信号，包含每个心动周期的30个时间帧和记录角度信息。预处理采用z-score归一化和PCA降维，评估多种分类算法在不同特征空间中的表现。

Result: PCA变换显著提升分类器性能，集成方法达到98.0%准确率和0.890的F1分数，在类别不平衡情况下有效平衡了精确率和召回率。

Conclusion: 研究证实了基于机器学习的便携超声设备检测TBI患者颅内出血的可行性，在急诊医学、农村医疗和军事环境中具有应用前景。

Abstract: Intracranial hemorrhage (ICH) secondary to Traumatic Brain Injury (TBI)
represents a critical diagnostic challenge, with approximately 64,000
TBI-related deaths annually in the United States. Current diagnostic modalities
including Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) have
significant limitations: high cost, limited availability, and infrastructure
dependence, particularly in resource-constrained environments. This study
investigates machine learning approaches for automated ICH detection using
Ultrasound Tissue Pulsatility Imaging (TPI), a portable technique measuring
tissue displacement from hemodynamic forces during cardiac cycles. We analyze
ultrasound TPI signals comprising 30 temporal frames per cardiac cycle with
recording angle information, collected from TBI patients with CT-confirmed
ground truth labels. Our preprocessing pipeline employs z-score normalization
and Principal Component Analysis (PCA) for dimensionality reduction, retaining
components explaining 95% of cumulative variance. We systematically evaluate
multiple classification algorithms spanning probabilistic, kernel-based, neural
network, and ensemble learning approaches across three feature representations:
original 31-dimensional space, reduced subset, and PCA-transformed space.
Results demonstrate that PCA transformation substantially improves classifier
performance, with ensemble methods achieving 98.0% accuracy and F1-score of
0.890, effectively balancing precision and recall despite class imbalance.
These findings establish the feasibility of machine learning-based ICH
detection in TBI patients using portable ultrasound devices, with applications
in emergency medicine, rural healthcare, and military settings where
traditional imaging is unavailable.

</details>


### [8] [Eye-Tracking as a Tool to Quantify the Effects of CAD Display on Radiologists' Interpretation of Chest Radiographs](https://arxiv.org/abs/2510.20864)
*Daisuke Matsumoto,Tomohiro Kikuchi,Yusuke Takagi,Soichiro Kojima,Ryoma Kobayashi,Daiju Ueda,Kohei Yamamoto,Sho Kawabe,Harushi Mori*

Main category: eess.IV

TL;DR: 这项研究使用眼动追踪技术评估了边界框(BB)显示对胸部X光片解读过程中视觉搜索行为的影响，发现BB显示会延长解读时间、增加病灶注视时间和总注视路径长度，但缩短了首次注视病灶的时间。


<details>
  <summary>Details</summary>
Motivation: 计算机辅助检测系统在胸部X光片中广泛使用，但边界框等并发显示可能会影响阅读过程。本研究旨在通过眼动追踪量化视觉搜索行为的变化。

Method: 从VinDR-CXR数据集中选取180张胸部X光片，3名放射科医生在有无边界框显示条件下各解读一次，使用EyeTech VT3 Mini记录眼动数据，分析解读时间、首次注视病灶时间、病灶注视时间、总注视路径长度和肺野覆盖率等指标。

Result: 边界框显示使解读时间延长4.9秒，病灶注视时间增加1.3秒，总注视路径长度增加2076像素，肺野覆盖率提高10.5%，首次注视病灶时间缩短1.3秒。

Conclusion: 眼动追踪能够捕捉到边界框显示对胸部X光片解读过程中搜索行为的可测量改变，支持了该方法的可行性，并强调需要更大规模研究来确认效果并探索跨模态和临床环境的影响。

Abstract: Rationale and Objectives: Computer-aided detection systems for chest
radiographs are widely used, and concurrent reader displays, such as
bounding-box (BB) highlights, may influence the reading process. This pilot
study used eye tracking to conduct a preliminary experiment to quantify which
aspects of visual search were affected. Materials and Methods: We sampled 180
chest radiographs from the VinDR-CXR dataset: 120 with solitary pulmonary
nodules or masses and 60 without. The BBs were configured to yield an overall
display sensitivity and specificity of 80%. Three radiologists (with 11, 5, and
1 years of experience, respectively) interpreted each case twice - once with
BBs visible and once without - after a washout of >= 2 weeks. Eye movements
were recorded using an EyeTech VT3 Mini. Metrics included interpretation time,
time to first fixation on the lesion, lesion dwell time, total gaze-path
length, and lung-field coverage ratio. Outcomes were modeled using a linear
mixed model, with reading condition as a fixed effect and case and reader as
random intercepts. The primary analysis was restricted to true positives
(n=96). Results: Concurrent BB display prolonged interpretation time by 4.9 s
(p<0.001) and increased lesion dwell time by 1.3 s (p<0.001). Total gaze-path
length increased by 2,076 pixels (p<0.001), and lung-field coverage ratio
increased by 10.5% (p<0.001). Time to first fixation on the lesion was reduced
by 1.3 s (p<0.001). Conclusion: Eye tracking captured measurable alterations in
search behavior associated with concurrent BB displays during chest radiograph
interpretation. These findings support the feasibility of this approach and
highlight the need for larger studies to confirm effects and explore
implications across modalities and clinical contexts.

</details>


### [9] [Efficient Meningioma Tumor Segmentation Using Ensemble Learning](https://arxiv.org/abs/2510.21040)
*Mohammad Mahdi Danesh Pajouh,Sara Saeedi*

Main category: eess.IV

TL;DR: 提出一种基于集成学习的脑膜瘤分割方法，结合三种不同架构的模型，在有限硬件条件下实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 脑膜瘤是最常见的原发性脑肿瘤，准确分割对治疗策略至关重要。现有深度学习方法计算需求大、训练时间长，限制了在有限硬件条件下的应用。

Method: 集成三种架构：基础SegResNet、带注意力机制和连接跳跃连接的SegResNet、带注意力门控跳跃连接的双解码器U-Net(DDUNet)。每个模型仅训练20个epoch。

Result: 在BraTS-MEN 2025数据集上，集成模型在测试集上获得平均病灶级Dice分数：增强肿瘤77.30%、肿瘤核心76.37%、全肿瘤73.9%。

Conclusion: 集成学习在有限硬件约束下也能实现有效的脑肿瘤分割，为脑膜瘤诊断提供了实用且易用的工具。

Abstract: Meningiomas represent the most prevalent form of primary brain tumors,
comprising nearly one-third of all diagnosed cases. Accurate delineation of
these tumors from MRI scans is crucial for guiding treatment strategies, yet
remains a challenging and time-consuming task in clinical practice. Recent
developments in deep learning have accelerated progress in automated tumor
segmentation; however, many advanced techniques are hindered by heavy
computational demands and long training schedules, making them less accessible
for researchers and clinicians working with limited hardware. In this work, we
propose a novel ensemble-based segmentation approach that combines three
distinct architectures: (1) a baseline SegResNet model, (2) an
attention-augmented SegResNet with concatenative skip connections, and (3) a
dual-decoder U-Net enhanced with attention-gated skip connections (DDUNet). The
ensemble aims to leverage architectural diversity to improve robustness and
accuracy while significantly reducing training demands. Each baseline model was
trained for only 20 epochs and Evaluated on the BraTS-MEN 2025 dataset. The
proposed ensemble model achieved competitive performance, with average
Lesion-Wise Dice scores of 77.30%, 76.37% and 73.9% on test dataset for
Enhancing Tumor (ET), Tumor Core (TC) and Whole Tumor (WT) respectively. These
results highlight the effectiveness of ensemble learning for brain tumor
segmentation, even under limited hardware constraints. Our proposed method
provides a practical and accessible tool for aiding the diagnosis of
meningioma, with potential impact in both clinical and research settings.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [10] [Information Theoretic Learning for Diffusion Models with Warm Start](https://arxiv.org/abs/2510.20903)
*Yirong Shen,Lu Gan,Cong Ling*

Main category: cs.IT

TL;DR: 提出了一种更紧致的似然界，用于改进基于噪声的生成模型的极大似然学习，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 基于扰动的似然估计模型收敛缓慢且理论理解有限，需要改进其学习效率和理论基础。

Method: 将经典KL散度Fisher信息关系扩展到任意噪声扰动，超越高斯假设，允许结构化噪声分布，将扩散过程视为高斯通道。

Result: 在CIFAR-10上获得竞争性NLL，在ImageNet多个分辨率上达到SOTA结果，无需数据增强，框架可自然扩展到离散数据。

Conclusion: 提出的方法通过更紧致的似然界改进了噪声驱动模型的极大似然学习，在多个数据集上取得了优异性能。

Abstract: Generative models that maximize model likelihood have gained traction in many
practical settings. Among them, perturbation based approaches underpin many
strong likelihood estimation models, yet they often face slow convergence and
limited theoretical understanding. In this paper, we derive a tighter
likelihood bound for noise driven models to improve both the accuracy and
efficiency of maximum likelihood learning. Our key insight extends the
classical KL divergence Fisher information relationship to arbitrary noise
perturbations, going beyond the Gaussian assumption and enabling structured
noise distributions. This formulation allows flexible use of randomized noise
distributions that naturally account for sensor artifacts, quantization
effects, and data distribution smoothing, while remaining compatible with
standard diffusion training. Treating the diffusion process as a Gaussian
channel, we further express the mismatched entropy between data and model,
showing that the proposed objective upper bounds the negative log-likelihood
(NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA
results on ImageNet across multiple resolutions, all without data augmentation,
and the framework extends naturally to discrete data.

</details>


### [11] [Overlapped-repetition Shor codes achieving fourfold asymptotic rate](https://arxiv.org/abs/2510.21030)
*En-Jui Chang*

Main category: cs.IT

TL;DR: 通过重叠少量重复码，将Shor码的渐近码率提高四倍，在最小距离d=3时从[[9,1,3]]优化到[[7,1,3]]配置。


<details>
  <summary>Details</summary>
Motivation: 标准Shor码使用两个重复码作为内外码，结构简单但码率相对较低，需要提高码率以减少开销。

Method: 通过重叠少量重复码来增强渐近码率，在最小距离情况下优化码结构。

Result: 渐近码率提高了四倍，在d=3时从[[9,1,3]]减少到[[7,1,3]]，显著降低了开销。

Conclusion: 重叠重复码的方法能有效提高量子纠错码的码率，在保持纠错能力的同时减少资源消耗。

Abstract: The standard Shor code employs two repetition codes as inner and outer codes,
yielding a simple structure but a relatively low code rate. By overlapping a
small number of repetition codes, we enhance the asymptotic code rate fourfold.
In the minimal-distance case $d = 3$, this construction reduces the overhead
from $[[9,1,3]]$ to the more efficient $[[7,1,3]]$ configuration.

</details>


### [12] [Complex DNA Synthesis Sequences](https://arxiv.org/abs/2510.21253)
*Boaz Moav,Ryan Gabrys,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出了一种混合DNA合成框架，结合了酶合成和光刻合成的优点，通过受限核苷酸子集进行并行合成，建立了新的复杂合成序列理论，并分析了最大信息率和渐近行为。


<details>
  <summary>Details</summary>
Motivation: DNA存储具有高密度和耐久性，但可扩展性受限于并行链合成的效率。现有方法要么允许无约束的核苷酸添加（如酶合成），要么强制所有链添加相同核苷酸（如光刻合成），需要一种更灵活的混合方法。

Method: 引入混合合成框架：每个周期从受限核苷酸子集中选择并并行合成。扩展了信息率定义，分析了删除球的类似概念，设计了动态规划算法计算最优复杂合成序列，并定义了二维阵列模型。

Result: 推导了最大信息率的紧致表达式及其渐近行为，建立了约束模型与理想化设置之间的理论桥梁。为已知链设计了动态规划算法，发现了与最短公共超序列问题的结构相似性。

Conclusion: 建立了一个全面统一的DNA合成理论框架，包含了先前的模型，为未来该领域的进展奠定了基础。

Abstract: DNA-based storage offers unprecedented density and durability, but its
scalability is fundamentally limited by the efficiency of parallel strand
synthesis. Existing methods either allow unconstrained nucleotide additions to
individual strands, such as enzymatic synthesis, or enforce identical additions
across many strands, such as photolithographic synthesis. We introduce and
analyze a hybrid synthesis framework that generalizes both approaches: in each
cycle, a nucleotide is selected from a restricted subset and incorporated in
parallel. This model gives rise to a new notion of a complex synthesis
sequence. Building on this framework, we extend the information rate definition
of Lenz et al. and analyze an analog of the deletion ball, defined and studied
in this setting, deriving tight expressions for the maximal information rate
and its asymptotic behavior. These results bridge the theoretical gap between
constrained models and the idealized setting in which every nucleotide is
always available. For the case of known strands, we design a dynamic
programming algorithm that computes an optimal complex synthesis sequence,
highlighting structural similarities to the shortest common supersequence
problem. We also define a distinct two-dimensional array model with synthesis
constraints over the rows, which extends previous synthesis models in the
literature and captures new structural limitations in large-scale strand
arrays. Additionally, we develop a dynamic programming algorithm for this
problem as well. Our results establish a new and comprehensive theoretical
framework for constrained DNA, subsuming prior models and setting the stage for
future advances in the field.

</details>


### [13] [Text-Guided Diffusion Model-based Generative Communication for Wireless Image Transmission](https://arxiv.org/abs/2510.21299)
*Shengkang Chen,Tong Wu,Zhiyong Chen,Feng Yang,Meixia Tao,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出基于扩散模型的生成式通信框架，结合联合信源信道编码和语义引导重建，在极低传输速率下实现高质量图像传输。


<details>
  <summary>Details</summary>
Motivation: 解决极低传输速率下传统压缩和信道编码方案无法保持足够视觉质量的问题，特别是在无线信道中可靠图像传输的挑战。

Method: 发送端通过JSCC编码源图像并与文本提示一起传输；接收端将受损的低速率表示与提示融合，通过带ControlNet的Stable Diffusion模型进行高质量视觉重建。

Result: 实验结果表明该方法在各种信道条件下始终优于传统编码方案和深度学习基线，实现了卓越的感知质量和鲁棒性。

Conclusion: 该生成式通信框架利用生成先验和语义指导，即使在极端带宽限制下也能产生感知上令人信服的图像，有效解决了低速率图像传输的挑战。

Abstract: Reliable image transmission over wireless channels is particularly
challenging at extremely low transmission rates, where conventional compression
and channel coding schemes fail to preserve adequate visual quality. To address
this issue, we propose a generative communication framework based on diffusion
models, which integrates joint source channel coding (JSCC) with
semantic-guided reconstruction leveraging a pre-trained generative model.
Unlike conventional architectures that aim to recover exact pixel values of the
original image, the proposed method focuses on preserving and reconstructing
semantically meaningful visual content under severely constrained rates,
ensuring perceptual plausibility and faithfulness to the scene intent.
Specifically, the transmitter encodes the source image via JSCC and jointly
transmits it with a textual prompt over the wireless channel. At the receiver,
the corrupted low-rate representation is fused with the prompt and
reconstructed through a Stable Diffusion model with ControlNet, enabling
high-quality visual recovery. Leveraging both generative priors and semantic
guidance, the proposed framework produces perceptually convincing images even
under extreme bandwidth limitations. Experimental results demonstrate that the
proposed method consistently outperforms conventional coding-based schemes and
deep learning baselines, achieving superior perceptual quality and robustness
across various channel conditions.

</details>


### [14] [Low-Complexity MIMO Channel Estimation with Latent Diffusion Models](https://arxiv.org/abs/2510.21386)
*Xiaotian Fan,Xingyu Zhou,Le Liang,Shi Jin*

Main category: cs.IT

TL;DR: 提出基于潜在扩散模型的新型信道估计算法PSLD-CE，通过轻量级LDM架构捕获复杂信道分布，在保持低计算复杂度和快速推理的同时显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型能够学习无线信道的复杂先验分布，为传统信道估计提供了更强大的替代方案。

Method: 设计轻量级潜在扩散模型架构作为生成先验，引入似然项的有效近似和变分自编码器潜在空间的定制自一致性约束来增强扩散后验采样过程。

Result: 实验结果表明PSLD-CE在广泛实验中始终优于现有多种方法，实现了显著的性能提升。

Conclusion: 该方法在保持低计算复杂度和快速推理速度的同时获得了显著性能增益，成为下一代无线系统极具前景的实用解决方案。

Abstract: Deep generative models offer a powerful alternative to conventional channel
estimation by learning the complex prior distribution of wireless channels.
Capitalizing on this potential, this paper proposes a novel channel estimation
algorithm based on latent diffusion models (LDMs), termed posterior sampling
with latent diffusion for channel estimation (PSLD-CE). The core of our
approach is a lightweight LDM architecture specifically designed for channel
estimation, which serves as a powerful generative prior to capture the
intricate channel distribution. Furthermore, we enhance the diffusion posterior
sampling process by introducing an effective approximation for the likelihood
term and a tailored self-consistency constraint on the variational autoencoder
latent space. Extensive experimental results demonstrate that PSLD-CE
consistently outperforms a wide range of existing methods. Notably, these
significant performance gains are achieved while maintaining low computational
complexity and fast inference speed, establishing our method as a highly
promising and practical solution for next-generation wireless systems.

</details>


### [15] [Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication](https://arxiv.org/abs/2510.21414)
*Hoang Ly,Emina Soljanin*

Main category: cs.IT

TL;DR: 提出了一种通用的最大似然解码框架，将最坏情况复杂度从q^{k}n降低到q^{k}，通过向量-矩阵乘法和Mailman算法实现。


<details>
  <summary>Details</summary>
Motivation: 传统最大似然解码复杂度高，需要q^{k}n次操作，限制了实际应用。

Method: 将条件概率表示为两个向量的内积，通过向量-矩阵乘法计算所有码字的似然值，使用Mailman算法降低计算成本。

Result: 将最坏情况复杂度降低n倍，适用于线性和非线性分组码、硬软判决解码、ISI信道和列表解码。

Conclusion: 该框架显著降低了ML解码的计算复杂度，但需要较高的存储空间来存储预计算的码本矩阵。

Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains
fundamentally hard, with worst-case time complexity-measured by the total
number of multiplications-being no better than straightforward exhaustive
search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper
introduces a simple, code-agnostic framework that reduces the worst-case
complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable
reduction in practice. The result holds for both linear and nonlinear block
codes over general memoryless channels and under both hard-decision and
soft-decision decoding. It naturally extends to intersymbol-interference (ISI)
channels and ML list decoding with only a negligible increase in complexity.
Our core insight is that, upon receipt of each sequence at the receiver, the
conditional probability of that sequence for each codeword in the codebook
(i.e., the \emph{likelihood}) can be expressed as the inner product of two
carefully constructed vectors -- the first depending on the received sequence,
and the second on that codeword itself. As a result, evaluating the likelihoods
for all codewords in the codebook reduces to a single vector-matrix
multiplication, and ML decoding (MLD) becomes the simple task of picking the
maximum entry in the resulting vector. The only non-trivial cost lies in the
vector-matrix product. However, our matrix construction allows the use of the
Mailman algorithm to reduce this cost. This time reduction is achieved at the
cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to
store the pre-computed codebook matrix.

</details>


### [16] [Resilient Radio Access Networks: AI and the Unknown Unknowns](https://arxiv.org/abs/2510.21587)
*Bho Matthiesen,Armin Dekorsy,Petar Popovski*

Main category: cs.IT

TL;DR: 本文探讨了5G网络在面临意外故障时的弹性设计挑战，指出当前统计学习方法在应对罕见和未预见中断方面的局限性，并建议结合在线学习和因果推断方法。


<details>
  <summary>Details</summary>
Motivation: 5G网络虽然具有高可靠性和可用性，但在面对意外情况时仍可能失效。弹性系统能够适应现实世界的复杂性，包括系统设计时完全未预料到的运行条件，这对缺乏模型或过于复杂无法提供统计保证的通信系统至关重要。

Method: 通过理论分析研究设计弹性无线接入网络AI的挑战，特别关注未预见和罕见中断情况。

Result: 理论结果表明当前统计学习方法在弹性方面存在严重局限性。

Conclusion: AI在提供网络弹性方面将发挥重要作用，但需要结合在线学习和因果推断方法来克服当前统计学习方法的不足。

Abstract: 5G networks offer exceptional reliability and availability, ensuring
consistent performance and user satisfaction. Yet they might still fail when
confronted with the unexpected. A resilient system is able to adapt to
real-world complexity, including operating conditions completely unanticipated
during system design. This makes resilience a vital attribute for communication
systems that must sustain service in scenarios where models are absent or too
intricate to provide statistical guarantees. Such considerations indicate that
artifical intelligence (AI) will play a major role in delivering resilience. In
this paper, we examine the challenges of designing AIs for resilient radio
access networks, especially with respect to unanticipated and rare disruptions.
Our theoretical results indicate strong limitations of current statistical
learning methods for resilience and suggest connections to online learning and
causal inference.

</details>
