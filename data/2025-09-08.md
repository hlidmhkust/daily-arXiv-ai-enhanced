<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.IV](#eess.IV) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Communication-Efficient Collaborative LLM Inference via Distributed Speculative Decoding](https://arxiv.org/abs/2509.04576)
*Ce Zheng,Tingting Yang*

Main category: eess.SP

TL;DR: 通过传输只最大的K个令牌的原始概率和索引，大幅减少分布式猜测解码的上行通信开销，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有分布式猜测解码需要从设备传输全部词汇表概率分布到基站，导致上行通信开销过大，特别在AI-RAN网络中存在问题。

Method: 提出了"Top-K稀疏对数概率传输(TK-SLT)"方案，只传输top-K令牌的原始概率和对应索引，而不是整个分布。还推导了最优草稿长度的分析表达式。

Result: 实验结果验证了方法的效率和有效性，显著减少带宽消耗的同时保持了推理性能。

Conclusion: TK-SLT方案能够在AI-RAN网络中高效地减少分布式猜测解码的通信开销，同时保持良好的加速效果。

Abstract: Speculative decoding is an emerging technique that accelerates large language
model (LLM) inference by allowing a smaller draft model to predict multiple
tokens in advance, which are then verified or corrected by a larger target
model. In AI-native radio access networks (AI-RAN), this paradigm is
well-suited for collaborative inference between resource-constrained end
devices and more capable edge servers or base stations (BSs). However, existing
distributed speculative decoding requires transmitting the full vocabulary
probability distribution from the draft model on the device to the target model
at the BS, which leads to prohibitive uplink communication overhead. To address
this issue, we propose a ``Top-K Sparse Logits Transmission (TK-SLT)`` scheme,
where the draft model transmits only the top-K token raw probabilities and the
corresponding token indices instead of the entire distribution. This approach
significantly reduces bandwidth consumption while maintaining inference
performance. We further derive an analytical expression for the optimal draft
length that maximizes inference throughput, and provide a theoretical analysis
of the achievable speedup ratio under TK-SLT. Experimental results validate
both the efficiency and effectiveness of the proposed method.

</details>


### [2] [Tangential Velocity Estimation Using Near-Field Automotive Radar Model](https://arxiv.org/abs/2509.04692)
*Michael Shifrin,Joseph Tabrikian,Igal Bilik*

Main category: eess.SP

TL;DR: 该论文提出了一种基于近场雷达模型的切向速度估计算法，解决了传统车载雷达无法估计目标切向速度的问题，通过利用目标在距离、径向速度和多普勒频移上的迁移效应来提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统车载雷达基于远场模型，只能估计目标的距离、径向速度和到达方向，但无法估计切向速度这一对动态环境感知至关重要的参数。近场模型中的迁移效应虽然通常会导致似然函数模糊，但如果正确建模，这些效应可以为切向速度估计提供有用信息。

Method: 提出了分离阵列配置和基于最大似然的高效算法，利用目标在距离、径向速度和多普勒上的迁移效应进行切向速度估计，同时保持计算复杂度在实用范围内。通过克拉美-罗界和模糊函数进行可辨识性分析。

Result: 仿真验证了理论可行性研究，在单目标和多目标场景下评估了算法性能。提出的方法提高了车载雷达的准确性和可靠性，增强了高级驾驶辅助系统和自动驾驶车辆的情境感知能力。

Conclusion: 该研究证明了近场雷达模型在切向速度估计中的有效性，提出的算法不仅能够估计切向速度，还能减轻距离、径向速度和多普勒上的似然模糊问题，为汽车雷达系统提供了重要的性能提升。

Abstract: This work investigates the problem of tangential velocity estimation in
automotive radar systems, addressing the limitations of conventionally
considered models. Conventional automotive radars are usually based on
far-field models and estimate the target's range, radial velocity, and
direction-of-arrival (DOA) but are not able to estimate the tangential
component of the target 2-D velocity, which is a critical parameter for
reliable perception of dynamic environments. To address this challenge, we
introduce the near-field radar model, which considers various migration
elements in range, radial velocity, and Doppler along time and space.
Conventionally, these migration effects result in smearing of the likelihood
function for estimating the target parameters. However, if the model is
correctly specified, these migration effects are informative for tangential
velocity estimation. We conduct an identifiability analysis for tangential
velocity estimation using the Cram\'er-Rao bound and ambiguity function. The
insights from this study motivate the use of a separated array configuration
and the development of a computationally efficient maximum likelihood based
algorithm designed to utilize target migrations for tangential velocity
estimation, while maintaining practical computational complexity. In addition
to tangential velocity estimation, the proposed algorithm mitigates likelihood
smearing in range, radial velocity, and Doppler. Simulations validate the
theoretical feasibility study, and evaluate the algorithms' performance in both
single- and multi-target scenarios. The proposed approach improves the accuracy
and reliability of automotive radars, enhancing situational awareness for
advanced driver assistance systems and autonomous vehicles.

</details>


### [3] [Environment-Aware IRS Deployment via Channel Knowledge Map: Joint Sensing-Communications Coverage Optimization](https://arxiv.org/abs/2509.04768)
*Yilong Chen,Zixiang Ren,Jie Xu,Rui Zhang*

Main category: eess.SP

TL;DR: 本文研究了智能反射面(IRS)在集成感知与通信(ISAC)系统中的部署优化问题，通过利用信道知识地图(CKM)来优化IRS部署位置、基站波束成形和IRS反射波束成形，以最小化系统成本同时满足感知和通信需求。


<details>
  <summary>Details</summary>
Motivation: 随着ISAC系统的发展，如何有效部署多个IRS来同时增强感知和通信覆盖成为一个重要问题。传统方法缺乏对环境信息的充分利用，需要一种环境感知的部署方案来优化系统性能。

Method: 提出基于CKM的环境感知IRS部署设计，将问题建模为混合整数非凸优化问题。采用基于连续凸近似(SCA)的松弛-定界方法，首先将二进制部署指标松弛为连续变量，通过SCA找到收敛解，最后将松弛指标四舍五入为二进制值。

Result: 数值结果表明，所提出的算法在满足感知和通信要求的同时，能够有效降低系统成本。算法适用于IRS反射波束成形的实时动态优化和准静态优化两种情况。

Conclusion: 基于CKM的IRS部署优化方法为ISAC系统提供了一种有效的环境感知部署方案，能够在保证感知和通信性能的同时优化系统资源配置，具有重要的实际应用价值。

Abstract: This paper studies the intelligent reflecting surface (IRS) deployment
optimization problem for IRS-enabled integrated sensing and communications
(ISAC) systems, in which multiple IRSs are strategically deployed at candidate
locations to assist a base station (BS) to enhance the coverage of both sensing
and communications. We present an environment-aware IRS deployment design via
exploiting the channel knowledge map (CKM), which provides the channel state
information (CSI) between each candidate IRS location and BS or targeted
sensing/communication points. Based on the obtained CSI from CKM, we optimize
the deployment of IRSs, jointly with the BS's transmit beamforming and IRSs'
reflective beamforming during operation, with the objective of minimizing the
system cost, while guaranteeing the minimum illumination power requirements at
sensing areas and the minimum signal-to-noise ratio (SNR) requirements at
communication areas. In particular, we consider two cases when the IRSs'
reflective beamforming optimization can be implemented dynamically in real time
and quasi-stationarily over the whole operation period, respectively. For both
cases, the joint IRS deployment and transmit/reflective beamforming designs are
formulated as mixed-integer non-convex optimization problems, which are solved
via the successive convex approximation (SCA)-based relax-and-bound method.
Specifically, we first relax the binary IRS deployment indicators into
continuous variables, then find converged solutions via SCA, and finally round
relaxed indicators back to binary values. Numerical results demonstrate the
effectiveness of our proposed algorithms in reducing the system cost while
meeting the sensing and communication requirements.

</details>


### [4] [SREC: Encrypted Semantic Super-Resolution Enhanced Communication](https://arxiv.org/abs/2509.04787)
*Zhidi Zhang,Rui Meng,Song Gao,Haixiao Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: 提出加密语义超分辨率增强通信(SREC)方法，通过模256加密和超分辨率重建技术保护语义通信安全，在低信噪比条件下实现安全且高效的图像传输。


<details>
  <summary>Details</summary>
Motivation: 语义通信(SemCom)作为AI与通信技术深度融合的典型范式，显著提高了通信效率和资源利用率，但其安全问题日益突出。明文传输的语义特征容易被窃听者截获，需要解决语义通信的安全性问题。

Method: 使用模256加密方法对语义特征进行加密，并采用超分辨率重建方法来提高图像的重建质量。在不同调制方法下测试加密语义通信系统的性能。

Result: 在加性高斯白噪声(AWGN)信道中，当使用不同调制方法时，SREC不仅能稳定保证安全性，还能在低信噪比(SNR)条件下实现更好的传输性能。

Conclusion: 提出的SREC方法有效解决了语义通信的安全问题，通过加密和超分辨率技术的结合，在保证安全性的同时提升了低信噪比环境下的通信性能。

Abstract: Semantic communication (SemCom), as a typical paradigm of deep integration
between artificial intelligence (AI) and communication technology,
significantly improves communication efficiency and resource utilization
efficiency. However, the security issues of SemCom are becoming increasingly
prominent. Semantic features transmitted in plaintext over physical channels
are easily intercepted by eavesdroppers. To address this issue, this paper
proposes Encrypted Semantic Super-Resolution Enhanced Communication (SREC) to
secure SemCom. SREC uses the modulo-256 encryption method to encrypt semantic
features, and employs super-resolution reconstruction method to improve the
reconstruction quality of images. The simulation results show that in the
additive Gaussian white noise (AWGN) channel, when different modulation methods
are used, SREC can not only stably guarantee security, but also achieve better
transmission performance under low signal-to-noise ratio (SNR) conditions.

</details>


### [5] [Rotatable Antenna Aided Mixed Near-Field and Far-Field Communications in the Upper Mid-Band: Interference Analysis and Joint Optimization](https://arxiv.org/abs/2509.04865)
*Yunpu Zhang,Changsheng You,Hing Cheung So,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文提出利用可旋转天线(RAs)来改善混合近场远场通信系统性能，通过天线旋转提供新的空间自由度来抑制复杂的近场干扰和混合场干扰。


<details>
  <summary>Details</summary>
Motivation: 传统固定天线系统在混合近场远场通信场景中面临复杂的干扰问题，需要新的技术手段来提升通信性能。

Method: 提出模块化RA使能的混合场下行通信系统，通过联合优化功率分配和子阵列旋转角度来最大化近场用户的和速率。采用双层算法：内层使用SCA技术优化功率分配，外层使用PSO确定旋转角度。

Result: 理论分析和数值结果表明，天线旋转能有效抑制近场干扰和混合场干扰，相比传统固定天线系统获得显著性能增益。

Conclusion: 可旋转天线为混合近场远场通信系统提供了一种有效的干扰抑制解决方案，通过空间自由度优化显著提升通信性能。

Abstract: In this paper, we propose to leverage rotatable antennas (RAs) for improving
the communication performance in mixed near-field and far-field communication
systems by exploiting a new spatial degree-of-freedom (DoF) offered by antenna
rotation to mitigate complex near-field interference and mixed-field
interference. Specifically, we investigate a modular RA-enabled mixed-field
downlink communication system, where a base station (BS) consisting of multiple
RA subarrays communicates with multiple near-field users in the presence of
several legacy far-field users. We formulate an optimization problem to
maximize the sum-rate of the near-field users by jointly optimizing the power
allocation and rotation angles of all subarrays at the BS. To gain useful
insights into the effect of RAs on mixed-field communications, we first analyze
a special case where all subarrays share the same rotation angle and obtain
closed-form expressions for the rotation-aware normalized near-field
interference and the rotation-aware normalized mixed-field interference using
the Fresnel integrals. We then analytically reveal that array rotation
effectively suppresses both interference types, thereby significantly enhancing
mixed-field communication performance. For the general case involving
subarray-wise rotation, we propose an efficient double-layer algorithm to
obtain a high-quality solution, where the inner layer optimizes power
allocation using the successive convex approximation (SCA) technique, while the
outer layer determines the rotation angles of all subarrays via particle swarm
optimization (PSO). Finally, numerical results highlight the significant
performance gains achieved by RAs over conventional fixed-antenna systems and
demonstrate the effectiveness of our developed joint design compared to
benchmark schemes.

</details>


### [6] [KGRAG-SC: Knowledge Graph RAG-Assisted Semantic Communication](https://arxiv.org/abs/2509.04801)
*Dayu Fan,Rui Meng,Song Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: KGRAG-SC是一个基于知识图谱的语义通信框架，通过检索增强生成技术解决传统语义通信缺乏可解释性和鲁棒性的问题，在低信噪比条件下实现更高的语义保真度和更低的传输开销。


<details>
  <summary>Details</summary>
Motivation: 现有的语义通信方案通常依赖端到端深度学习框架，缺乏可解释性，且在噪声条件下难以实现鲁棒的语义选择和重建。

Method: 采用知识图谱辅助的多维框架，通过社区引导的实体链接和GraphRAG处理实现高效语义提取。发射端构建最小连通子图传输紧凑实体索引，接收端使用大语言模型进行知识驱动的文本重建。

Result: 实验结果表明KGRAG-SC在低信噪比条件下实现了优越的语义保真度，同时相比传统通信方法显著降低了传输开销。

Conclusion: 将结构化知识表示与生成式语言模型集成到语义通信系统中是有效的，能够提供鲁棒的语义恢复和高效的通信性能。

Abstract: The state-of-the-art semantic communication (SC) schemes typically rely on
end-to-end deep learning frameworks that lack interpretability and struggle
with robust semantic selection and reconstruction under noisy conditions. To
address this issue, this paper presents KGRAG-SC, a knowledge graph-assisted SC
framework that leverages retrieval-augmented generation principles. KGRAG-SC
employs a multi-dimensional knowledge graph, enabling efficient semantic
extraction through community-guided entity linking and GraphRAG-assisted
processing. The transmitter constructs minimal connected subgraphs that capture
essential semantic relationships and transmits only compact entity indices
rather than full text or semantic triples. An importance-aware adaptive
transmission strategy provides unequal error protection based on structural
centrality metrics, prioritizing critical semantic elements under adverse
channel conditions. At the receiver, large language models perform
knowledge-driven text reconstruction using the shared knowledge graph as
structured context, ensuring robust semantic recovery even with partial
information loss. Experimental results demonstrate that KGRAG-SC achieves
superior semantic fidelity in low Signal-to-Noise Ratio (SNR) conditions while
significantly reducing transmission overhead compared to traditional
communication methods, highlighting the effectiveness of integrating structured
knowledge representation with generative language models for SC systems.

</details>


### [7] [SemSteDiff: Generative Diffusion Model-based Coverless Semantic Steganography Communication](https://arxiv.org/abs/2509.04803)
*Song Gao,Rui Meng,Xiaodong Xu,Haixiao Gao,Yiming Liu,Chenyuan Feng,Ping Zhang,Tony Q. S. Quek,Dusit Niyato*

Main category: eess.SP

TL;DR: 基于生成式滴温模型的无封装语义隐写通信方案SemSteDiff，通过生成隐藏图像来保护秘密图像传输，免去对预选封装图像的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前语义隐写通信方案依赖于预选封装图像，限制了普适性。需要解决这一限制，提高通信安全性和灵活性。

Method: 使用生成式滴温模型生成含有秘密图像信息的隐藏图像，通过语义相关的私钥和公钥实现合法接收方正确解码。

Result: 在SNR=0dB时，合法接收方的PSNR比偷听者高4.14dB，证明方案在不同JSCC框架中都有效。

Conclusion: SemSteDiff方案通过生成式方法实现了无封装语义隐写通信，显著提高了通信安全性和灵活性。

Abstract: Semantic communication (SemCom), as a novel paradigm for future communication
systems, has recently attracted much attention due to its superiority in
communication efficiency. However, similar to traditional communication, it
also suffers from eavesdropping threats. Intelligent eavesdroppers could launch
advanced semantic analysis techniques to infer secret semantic information.
Therefore, some researchers have designed Semantic Steganography Communication
(SemSteCom) scheme to confuse semantic eavesdroppers. However, the
state-of-the-art SemSteCom schemes for image transmission rely on the
pre-selected cover image, which limits the universality. To address this issue,
we propose a Generative Diffusion Model-based Coverless Semantic Steganography
Communication (SemSteDiff) scheme to hide secret images into generated stego
images. The semantic related private and public keys enable legitimate receiver
to decode secret images correctly while the eavesdropper without completely
true key-pairs fail to obtain them. Simulation results demonstrate the
effectiveness of the plug-and-play design in different Joint Source-Channel
Coding (JSCC) frameworks. The comparison results under different eavesdroppers'
threats show that, when Signal-to-Noise Ratio (SNR) = 0 dB, the peak
signal-to-noise ratio (PSNR) of the legitimate receiver is 4.14 dB higher than
that of the eavesdropper.

</details>


### [8] [AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design](https://arxiv.org/abs/2509.04805)
*Keqin Zhang*

Main category: eess.SP

TL;DR: AI驱动的无线前传压缩技术综述，重点分析CSI反馈和RB粒度预编码压缩，提出面向cell-free架构的高压缩比低延迟压缩策略


<details>
  <summary>Details</summary>
Motivation: 现代无线系统前传链路需要在高带宽和低延迟约束下传输高维信号，传统压缩方法在高压缩比下性能急剧下降且难以调优，需要AI技术来更好地利用信道状态信息等信号结构

Method: 1) 综述AI驱动的压缩技术；2) 重点分析两种高压缩路径：端到端学习的CSI反馈压缩、RB粒度预编码优化与压缩结合；3) 提出面向cell-free架构的前传压缩策略，支持RB级速率自适应和低延迟推理

Result: 提出的压缩策略能够实现高压缩比下的可控性能损失，支持RB级速率自适应，适用于下一代网络集中式协作传输的低延迟需求

Conclusion: AI驱动的压缩技术能够有效解决无线前传链路的高维信号传输挑战，提出的cell-free架构压缩策略为下一代网络提供了可行的解决方案

Abstract: Modern fronthaul links in wireless systems must transport high-dimensional
signals under stringent bandwidth and latency constraints, which makes
compression indispensable. Traditional strategies such as compressed sensing,
scalar quantization, and fixed-codec pipelines often rely on restrictive
priors, degrade sharply at high compression ratios, and are hard to tune across
channels and deployments. Recent progress in Artificial Intelligence (AI) has
brought end-to-end learned transforms, vector and hierarchical quantization,
and learned entropy models that better exploit the structure of Channel State
Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first
surveys AI-driven compression techniques and then provides a focused analysis
of two representative high-compression routes: CSI feedback with end-to-end
learning and Resource Block (RB) granularity precoding optimization combined
with compression. Building on these insights, we propose a fronthaul
compression strategy tailored to cell-free architectures. The design targets
high compression with controlled performance loss, supports RB-level rate
adaptation, and enables low-latency inference suitable for centralized
cooperative transmission in next-generation networks.

</details>


### [9] [Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering with Application to Brain Imaging](https://arxiv.org/abs/2509.04860)
*Rui Guo,Yi Zhang,Yhonatan Kvich,Tianyao Huang,Maokun Li,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出基于潜在扩散的后验采样方法用于电磁脑成像，通过结合物理前向模型和学习的先验分布，实现高精度重建并保持理论保证


<details>
  <summary>Details</summary>
Motivation: 现有电磁成像方法无法同时兼顾复杂先验分布整合和理论保证，在解释性、失真误差和可靠性之间存在平衡困难

Method: 使用潜在扩散模型学习目标先验分布，然后通过交替采样器执行后验采样，分别强制执行似然和先验分布，最后基于样本进行最小均方误差估计

Result: 在脑成像实验中达到最先进的重建精度和结构相似性，同时保持高测量保真度

Conclusion: 该方法能够灵活整合先验知识到基于物理的反演中，无需配对测量-标签数据集，实现了定量电磁脑成像的可靠重建

Abstract: Electromagnetic (EM) imaging is an important tool for non-invasive sensing
with low-cost and portable devices. One emerging application is EM stroke
imaging, which enables early diagnosis and continuous monitoring of brain
strokes. Quantitative imaging is achieved by solving an inverse scattering
problem (ISP) that reconstructs permittivity and conductivity maps from
measurements. In general, the reconstruction accuracy is limited by its
inherent nonlinearity and ill-posedness. Existing methods, including
learning-free and learning-based approaches, fail to either incorporate
complicated prior distributions or provide theoretical guarantees, posing
difficulties in balancing interpretability, distortion error, and reliability.
To overcome these limitations, we propose a posterior sampling method based on
latent diffusion for quantitative EM brain imaging, adapted from a generative
plug-and-play (PnP) posterior sampling framework. Our approach allows to
flexibly integrate prior knowledge into physics-based inversion without
requiring paired measurement-label datasets. We first learn the prior
distribution of targets from an unlabeled dataset, and then incorporate the
learned prior into posterior sampling. In particular, we train a latent
diffusion model on permittivity and conductivity maps to capture their prior
distribution. Then, given measurements and the forward model describing EM wave
physics, we perform posterior sampling by alternating between two samplers that
respectively enforce the likelihood and prior distributions. Finally, reliable
reconstruction is obtained through minimum mean squared error (MMSE) estimation
based on the samples. Experimental results on brain imaging demonstrate that
our approach achieves state-of-the-art performance in reconstruction accuracy
and structural similarity while maintaining high measurement fidelity.

</details>


### [10] [Movable IRS-Aided ISAC Systems: Joint Beamforming and Position Optimization](https://arxiv.org/abs/2509.04873)
*Yue Geng,Tee Hiang Cheng,Kai Zhong,Kah Chan Teh,Qingqing Wu*

Main category: eess.SP

TL;DR: 这篇论文研究了可移动智能反射表面(MIRS)在集成感知通信(ISAC)系统中的应用，通过关键参数优化来最小化系统功耗，并提出了元素级和数组级两种控制方案以及基于鲁曼流形的优化算法。


<details>
  <summary>Details</summary>
Motivation: 结合智能反射表面(IRS)和可移动天线(MA)技术，可移动IRS(MIRS)能够提高传统IRS的适应性和性能，通过灵活调整反射元素位置来改善集成感知通信系统的性能。

Method: 提出了元素级控制和数组级控制两种MIRS方案，并使用产品鲁曼流形优化(PRMO)方法，通过罚函数转换和鲁曼流形BFGS算法在构建的产品鲁曼流形空间(PRMS)上并行更新变量。

Result: 模拟结果显示，提出的MIRS方案在功耗最小化方面超过传统IRS。元素级控制方案能实现最优功耗，而数组级控制方案虽然是次优解但具有更高的计算效率。

Conclusion: MIRS技术在ISAC系统中具有重要价值，元素级控制能提供最优性能，而数组级控制在性能和计算效率之间取得了良好平衡。产品鲁曼流形优化方法有效解决了关键参数的聚合优化问题。

Abstract: Driven by intelligent reflecting surface (IRS) and movable antenna (MA)
technologies, movable IRS (MIRS) has been proposed to improve the adaptability
and performance of conventional IRS, enabling flexible adjustment of the IRS
reflecting element positions. This paper investigates MIRS-aided integrated
sensing and communication (ISAC) systems. The objective is to minimize the
power required for satisfying the quality-of-service (QoS) of sensing and
communication by jointly optimizing the MIRS element positions, IRS reflection
coefficients, transmit beamforming, and receive filters. To balance the
performance-cost trade-off, we proposed two MIRS schemes: element-wise control
and array-wise control, where the positions of individual reflecting elements
and arrays consisting of multiple elements are controllable, respectively. To
address the joint beamforming and position optimization, a product Riemannian
manifold optimization (PRMO) method is proposed, where the variables are
updated over a constructed product Riemannian manifold space (PRMS) in parallel
via penalty-based transformation and Riemannian
Broyden-Fletcher-Goldfarb-Shanno (RBFGS) algorithm. Simulation results
demonstrate that the proposed MIRS outperforms conventional IRS in power
minimization with both element-wise control and array-wise control.
Specifically, with different system parameters, the minimum power is achieved
by the MIRS with the element-wise control scheme, while suboptimal solution and
higher computational efficiency are achieved by the MIRS with array-wise
control scheme.

</details>


### [11] [Coupled tensor models for probability mass function estimation: Part I, Principles and algorithms](https://arxiv.org/abs/2509.04930)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 提出了一种名为PCTF3D的概率质量函数估计方法，通过部分耦合3D边际张量来克服维度灾难问题


<details>
  <summary>Details</summary>
Motivation: 为了解决高维概率质量函数估计中的维度灾难问题，传统方法在处理高维数据时面临计算复杂度和存储需求的挑战

Method: PCTF3D方法通过选择3D边际张量的子集进行部分耦合，利用超图理论来表述边际选择策略，构建张量分解模型

Result: 提出了新的算法框架，包括可能的耦合策略、数值实验和方法应用，为概率质量张量分解提供了有效途径

Conclusion: PCTF3D是处理高维PMF估计的有效方法，本文是第一部分专注于算法框架，第二部分将研究模型唯一性性质

Abstract: In this article, a Probability Mass Function (PMF) estimation method which
tames the curse of dimensionality is proposed. This method, called Partial
Coupled Tensor Factorization of 3D marginals or PCTF3D, has for principle to
partially couple order-3 data projections -- seen as order-3 tensors -- to
obtain a tensor decomposition of the probability mass tensor. The novelty of
PCTF3D relies on partial coupling which consists in choosing a subset of 3D
marginals. The choice of marginals is then formulated with hypergraphs. After
presenting possible coupling strategies, some numerical experiments and an
application of the method are proposed. This article is the first of a two-part
article. While this first article focuses on a new algorithmic framework for
PMF estimation, the second studies uniqueness properties of the model
introduced in this article.

</details>


### [12] [Coupled tensor models for probability mass function estimation: Part II, Uniqueness of the model](https://arxiv.org/abs/2509.04931)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 本文研究了PCTF3D方法中耦合张量模型的唯一性特性，分析了不同耦合策略对唯一性的影响，并给出了笛卡尔耦合的可辨识性边界。


<details>
  <summary>Details</summary>
Motivation: 张量方法在统计学习中广泛应用，其最大优势是具有强唯一性特性。PCTF3D方法通过耦合3D边缘分布来估计概率质量函数，需要评估其约束耦合低秩模型的唯一性特性。

Method: 提出了雅可比算法来提供最大可恢复秩，并检查了Part I文章中提出的不同耦合策略的唯一性特性。

Result: 研究表明唯一性高度依赖于PCTF3D中使用的耦合方式。对于笛卡尔耦合给出了可辨识性边界，这改进了文献中的充分边界。

Conclusion: PCTF3D方法的唯一性特性与耦合策略密切相关，笛卡尔耦合提供了更好的可辨识性保证，为概率质量函数估计提供了理论支撑。

Abstract: In this paper, uniqueness properties of a coupled tensor model are studied.
This new coupled tensor model is used in a new method called Partial Coupled
Tensor Factorization of 3D marginals or PCTF3D. This method performs estimation
of probability mass functions by coupling 3D marginals, seen as order-3
tensors. The core novelty of PCTF3D's approach (detailed in the part I article)
relies on the partial coupling which consists on the choice of 3D marginals to
be coupled. Tensor methods are ubiquitous in many applications of statistical
learning, with their biggest advantage of having strong uniqueness properties.
In this paper, the uniqueness properties of PCTF3D's constrained coupled
low-rank model is assessed. While probabilistic constraints of the coupled
model are handled properly, it is shown that uniqueness highly depends on the
coupling used in PCTF3D. After proposing a Jacobian algorithm providing maximum
recoverable rank, different coupling strategies presented in the Part I article
are examined with respect to their uniqueness properties. Finally, an
identifiability bound is given for a so-called Cartesian coupling which permits
enhancing sufficient bounds of the literature.

</details>


### [13] [ROPE: A Novel Method for Real-Time Phase Estimation of Complex Biological Rhythms](https://arxiv.org/abs/2509.04962)
*Antonio Spallone,Marco Coraggio,Francesco De Lellis,Mario di Bernardo*

Main category: eess.SP

TL;DR: ROPE是首个能够处理任意维度信号并实时运行且误差最小的相位估计算法，通过识别信号重复性进行分段并执行高效搜索来分配相位值。


<details>
  <summary>Details</summary>
Motivation: 现有相位估计方法通常仅限于离线处理和/或一维信号，无法满足实时分析复杂生物节律的需求。

Method: ROPE通过识别信号中的重复模式将其分割为（伪）周期，并在先前信号段上执行高效、可处理的搜索来分配相位值。

Result: 在混沌动力系统轨迹、人体运动捕捉数据和心电图记录等多种信号类型上验证，ROPE对噪声和信号漂移具有鲁棒性，性能显著优于最先进的相位估计方法。

Conclusion: ROPE实现了复杂生物节律的实时分析，为病理节律紊乱的早期诊断和基于节律的神经与心血管疾病治疗干预开辟了新途径。

Abstract: Accurate phase estimation -- the process of assigning phase values between
$0$ and $2\pi$ to repetitive or periodic signals -- is a cornerstone in the
analysis of oscillatory signals across diverse fields, from neuroscience to
robotics, where it is fundamental, e.g., to understanding coordination in
neural networks, cardiorespiratory coupling, and human-robot interaction.
However, existing methods are often limited to offline processing and/or
constrained to one-dimensional signals. In this paper, we introduce ROPE,
which, to the best of our knowledge, is the first phase-estimation algorithm
capable of (i) handling signals of arbitrary dimension and (ii) operating in
real-time, with minimal error. ROPE identifies repetitions within the signal to
segment it into (pseudo-)periods and assigns phase values by performing
efficient, tractable searches over previous signal segments. We extensively
validate the algorithm on a variety of signal types, including trajectories
from chaotic dynamical systems, human motion-capture data, and
electrocardiographic recordings. Our results demonstrate that ROPE is robust
against noise and signal drift, and achieves significantly superior performance
compared to state-of-the-art phase estimation methods. This advancement enables
real-time analysis of complex biological rhythms, opening new pathways, for
example, for early diagnosis of pathological rhythm disruptions and developing
rhythm-based therapeutic interventions in neurological and cardiovascular
disorders.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [14] [Inferring the Graph Structure of Images for Graph Neural Networks](https://arxiv.org/abs/2509.04677)
*Mayur S Gowda,John Shi,Augusto Santos,José M. F. Moura*

Main category: eess.IV

TL;DR: 通过分析MNIST和Fashion-MNIST图像像素值的相关性，构建行相关、列相关和积图等替代图表示，提升了图神经网络的图像分类准确率


<details>
  <summary>Details</summary>
Motivation: 传统的格子图和超像素方法在图像表示中存在限制，需要找到更优的图表示方法来提高图神经网络的下游任务性能

Method: 使用像素值之间的相关性构建行相关图、列相关图和积图，并将这些替代图表示作为图神经网络的输入

Result: 实验结果显示，使用这些新的图表示方法比传统的格子图和超像素方法能够显著提高图像分类的准确率

Conclusion: 通过分析像素相关性来构建更优的图表示是一种有效的方法，能够显著提升GNN在图像分类任务上的性能

Abstract: Image datasets such as MNIST are a key benchmark for testing Graph Neural
Network (GNN) architectures. The images are traditionally represented as a grid
graph with each node representing a pixel and edges connecting neighboring
pixels (vertically and horizontally). The graph signal is the values
(intensities) of each pixel in the image. The graphs are commonly used as input
to graph neural networks (e.g., Graph Convolutional Neural Networks (Graph
CNNs) [1, 2], Graph Attention Networks (GAT) [3], GatedGCN [4]) to classify the
images. In this work, we improve the accuracy of downstream graph neural
network tasks by finding alternative graphs to the grid graph and superpixel
methods to represent the dataset images, following the approach in [5, 6]. We
find row correlation, column correlation, and product graphs for each image in
MNIST and Fashion-MNIST using correlations between the pixel values building on
the method in [5, 6]. Experiments show that using these different graph
representations and features as input into downstream GNN models improves the
accuracy over using the traditional grid graph and superpixel methods in the
literature.

</details>


### [15] [AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive Representations](https://arxiv.org/abs/2509.04819)
*Shuhan Ding,Jingjing Fu,Yu Gu,Naiteek Sangani,Mu Wei,Paul Vozila,Nan Liu,Jiang Bian,Hoifung Poon*

Main category: eess.IV

TL;DR: AURAD是一个可控的放射学合成框架，能够联合生成高保真胸部X光片和伪语义掩码，通过渐进式管道和预训练医学模型确保临床合理性，在放射科医生评估中78%的合成图像被分类为真实图像。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像合成中细粒度和可控性合成的难题，特别是在胸部X光片领域，疾病模式形态多样且与解剖结构紧密交织，现有方法难以泛化到这种复杂场景。

Method: 采用渐进式管道：首先从基于解剖结构的临床提示生成伪掩码，然后使用这些掩码指导图像合成；利用预训练专家医学模型过滤输出确保临床合理性；生成的掩码还可用于下游检测和分割任务。

Result: 78%的合成图像被认证放射科医生分类为真实图像；超过40%的预测分割覆盖被评定为临床有用；在跨任务和数据集上展示了方法的有效性和泛化能力。

Conclusion: AURAD框架成功解决了胸部X光片合成的可控性和临床相关性挑战，生成的图像和掩码不仅视觉逼真，还具有实际临床应用价值，为生成建模与真实世界临床应用之间搭建了桥梁。

Abstract: Medical image synthesis has become an essential strategy for augmenting
datasets and improving model generalization in data-scarce clinical settings.
However, fine-grained and controllable synthesis remains difficult due to
limited high-quality annotations and domain shifts across datasets. Existing
methods, often designed for natural images or well-defined tumors, struggle to
generalize to chest radiographs, where disease patterns are morphologically
diverse and tightly intertwined with anatomical structures. To address these
challenges, we propose AURAD, a controllable radiology synthesis framework that
jointly generates high-fidelity chest X-rays and pseudo semantic masks. Unlike
prior approaches that rely on randomly sampled masks-limiting diversity,
controllability, and clinical relevance-our method learns to generate masks
that capture multi-pathology coexistence and anatomical-pathological
consistency. It follows a progressive pipeline: pseudo masks are first
generated from clinical prompts conditioned on anatomical structures, and then
used to guide image synthesis. We also leverage pretrained expert medical
models to filter outputs and ensure clinical plausibility. Beyond visual
realism, the synthesized masks also serve as labels for downstream tasks such
as detection and segmentation, bridging the gap between generative modeling and
real-world clinical applications. Extensive experiments and blinded radiologist
evaluations demonstrate the effectiveness and generalizability of our method
across tasks and datasets. In particular, 78% of our synthesized images are
classified as authentic by board-certified radiologists, and over 40% of
predicted segmentation overlays are rated as clinically useful. All code,
pre-trained models, and the synthesized dataset will be released upon
publication.

</details>


### [16] [Multi-modal Uncertainty Robust Tree Cover Segmentation For High-Resolution Remote Sensing Images](https://arxiv.org/abs/2509.04870)
*Yuanyuan Gui,Wei Li,Yinjian Wang,Xiang-Gen Xia,Mauro Marty,Christian Ginzler,Zuyuan Wang*

Main category: eess.IV

TL;DR: 提出了MURTreeFormer框架，通过概率潜在表示和VAE重采样机制处理多模态遥感图像中的时序不确定性，显著提升树冠覆盖分割精度


<details>
  <summary>Details</summary>
Motivation: 多模态遥感图像（光学、LiDAR、SAR）通常在不同时间采集，存在时序错位导致的跨模态不确定性，严重影响分割准确性

Method: 将一种模态作为主模态，其他作为辅助模态，通过概率潜在表示建模辅助模态的补丁级不确定性，使用VAE重采样机制重建不确定补丁，并集成梯度幅度注意力模块和轻量级细化头

Result: 在上海和苏黎世的多模态数据集上实验表明，MURTreeFormer显著提升了分割性能，有效减少了时序引起的随机不确定性影响

Conclusion: 该框架通过显式建模和处理跨模态不确定性，为多模态遥感图像的树冠覆盖映射提供了鲁棒的解决方案

Abstract: Recent advances in semantic segmentation of multi-modal remote sensing images
have significantly improved the accuracy of tree cover mapping, supporting
applications in urban planning, forest monitoring, and ecological assessment.
Integrating data from multiple modalities-such as optical imagery, light
detection and ranging (LiDAR), and synthetic aperture radar (SAR)-has shown
superior performance over single-modality methods. However, these data are
often acquired days or even months apart, during which various changes may
occur, such as vegetation disturbances (e.g., logging, and wildfires) and
variations in imaging quality. Such temporal misalignments introduce
cross-modal uncertainty, especially in high-resolution imagery, which can
severely degrade segmentation accuracy. To address this challenge, we propose
MURTreeFormer, a novel multi-modal segmentation framework that mitigates and
leverages aleatoric uncertainty for robust tree cover mapping. MURTreeFormer
treats one modality as primary and others as auxiliary, explicitly modeling
patch-level uncertainty in the auxiliary modalities via a probabilistic latent
representation. Uncertain patches are identified and reconstructed from the
primary modality's distribution through a VAE-based resampling mechanism,
producing enhanced auxiliary features for fusion. In the decoder, a gradient
magnitude attention (GMA) module and a lightweight refinement head (RH) are
further integrated to guide attention toward tree-like structures and to
preserve fine-grained spatial details. Extensive experiments on multi-modal
datasets from Shanghai and Zurich demonstrate that MURTreeFormer significantly
improves segmentation performance and effectively reduces the impact of
temporally induced aleatoric uncertainty.

</details>


### [17] [INR meets Multi-Contrast MRI Reconstruction](https://arxiv.org/abs/2509.04888)
*Natascha Niessen,Carolin M. Pirkl,Ana Beatriz Solana,Hannah Eichhorn,Veronika Spieker,Wenqi Huang,Tim Sprenger,Marion I. Menzel,Julia A. Schnabel*

Main category: eess.IV

TL;DR: 提出基于隐式神经表示(INR)的多对比度MRI重建方法，利用对比度间的互补信息实现更高加速因子，在MPnRAGE序列上优于传统并行成像压缩感知方法


<details>
  <summary>Details</summary>
Motivation: 多对比度MRI扫描时间过长限制了临床应用，需要通过k空间欠采样加速，但传统重建方法在高加速因子下效果有限

Method: 使用对比度特定的欠采样模式（中心保留对比信息，高频互补采样），提出INR网络联合重建所有对比度图像，利用对比度间的冗余解剖信息

Result: 在MPnRAGE序列上，该方法在更高加速因子下仍优于state-of-the-art的并行成像压缩感知(PICS)重建方法

Conclusion: INR方法能有效利用多对比度MRI中的互补信息，实现更高的加速因子同时保持图像质量，有望推动多对比度MRI在临床的常规应用

Abstract: Multi-contrast MRI sequences allow for the acquisition of images with varying
tissue contrast within a single scan. The resulting multi-contrast images can
be used to extract quantitative information on tissue microstructure. To make
such multi-contrast sequences feasible for clinical routine, the usually very
long scan times need to be shortened e.g. through undersampling in k-space.
However, this comes with challenges for the reconstruction. In general,
advanced reconstruction techniques such as compressed sensing or deep
learning-based approaches can enable the acquisition of high-quality images
despite the acceleration. In this work, we leverage redundant anatomical
information of multi-contrast sequences to achieve even higher acceleration
rates. We use undersampling patterns that capture the contrast information
located at the k-space center, while performing complementary undersampling
across contrasts for high frequencies. To reconstruct this highly sparse
k-space data, we propose an implicit neural representation (INR) network that
is ideal for using the complementary information acquired across contrasts as
it jointly reconstructs all contrast images. We demonstrate the benefits of our
proposed INR method by applying it to multi-contrast MRI using the MPnRAGE
sequence, where it outperforms the state-of-the-art parallel imaging compressed
sensing (PICS) reconstruction method, even at higher acceleration factors.

</details>


### [18] [VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced Medical Image Segmentation](https://arxiv.org/abs/2509.05154)
*Julia Dietlmeier,Oluwabukola Grace Adegboro,Vayangi Ganepola,Claudia Mazo,Noel E. O'Connor*

Main category: eess.IV

TL;DR: 通过将视觉语言分割模型与低复杂度CNN集成，在医学图像分割任务中显著提升了性能，在BKAI息肉数据集上Dice分数提高了6.3%，其他数据集也有1-6%的提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP和BiomedCLIP的视觉语言分割模型性能仍落后于更复杂的架构如CRIS，研究希望通过模型集成而非文本提示工程来缩小这一差距。

Method: 采用视觉语言分割模型(VLSMs)与低复杂度CNN进行集成的方法，而不是传统的文本提示工程优化。

Result: 在BKAI息肉数据集上Dice分数提升了6.3%，其他数据集也有1-6%的性能提升，并在四个放射学和非放射学数据集上提供了初步结果。

Conclusion: 集成方法在不同数据集上的表现差异很大（从优于到劣于CRIS模型），这为社区提供了未来研究的方向。代码已开源。

Abstract: Vision-language models and their adaptations to image segmentation tasks
present enormous potential for producing highly accurate and interpretable
results. However, implementations based on CLIP and BiomedCLIP are still
lagging behind more sophisticated architectures such as CRIS. In this work,
instead of focusing on text prompt engineering as is the norm, we attempt to
narrow this gap by showing how to ensemble vision-language segmentation models
(VLSMs) with a low-complexity CNN. By doing so, we achieve a significant Dice
score improvement of 6.3% on the BKAI polyp dataset using the ensembled
BiomedCLIPSeg, while other datasets exhibit gains ranging from 1% to 6%.
Furthermore, we provide initial results on additional four radiology and
non-radiology datasets. We conclude that ensembling works differently across
these datasets (from outperforming to underperforming the CRIS model),
indicating a topic for future investigation by the community. The code is
available at https://github.com/juliadietlmeier/VLSM-Ensemble.

</details>


### [19] [Exploring Autoregressive Vision Foundation Models for Image Compression](https://arxiv.org/abs/2509.05169)
*Huu-Tai Phung,Yu-Hsiang Lin,Yen-Kuan Ho,Wen-Hsiao Peng*

Main category: eess.IV

TL;DR: 首次尝试重新利用视觉基础模型（VFMs）作为图像编码器，通过自回归模型进行低码率图像压缩，在极低码率下展现优秀的感知质量。


<details>
  <summary>Details</summary>
Motivation: 探索视觉基础模型在低码率图像压缩中的演绎能力，利用其编码器-解码器架构和自回归模型特性，以实现语义丰富的图像压缩。

Method: 重新利用VFMs中的自回归模型进行位置编码，基于已编码的token对下一个token进行位置预测，这种方法不同于以往仅依赖条件生成的语义压缩方法。

Result: 完整的实验分析显示，某些预训练的通用视觉基础模型在极低码率下比专门的学习型图像编码器具有更优的感知质量。

Conclusion: 这一发现为利用视觉基础模型进行低码率、语义丰富的图像压缩开启了有前景的研究方向。

Abstract: This work presents the first attempt to repurpose vision foundation models
(VFMs) as image codecs, aiming to explore their generation capability for
low-rate image compression. VFMs are widely employed in both conditional and
unconditional generation scenarios across diverse downstream tasks, e.g.,
physical AI applications. Many VFMs employ an encoder-decoder architecture
similar to that of end-to-end learned image codecs and learn an autoregressive
(AR) model to perform next-token prediction. To enable compression, we
repurpose the AR model in VFM for entropy coding the next token based on
previously coded tokens. This approach deviates from early semantic compression
efforts that rely solely on conditional generation for reconstructing input
images. Extensive experiments and analysis are conducted to compare VFM-based
codec to current SOTA codecs optimized for distortion or perceptual quality.
Notably, certain pre-trained, general-purpose VFMs demonstrate superior
perceptual quality at extremely low bitrates compared to specialized learned
image codecs. This finding paves the way for a promising research direction
that leverages VFMs for low-rate, semantically rich image compression.

</details>


### [20] [Generation of realistic cardiac ultrasound sequences with ground truth motion and speckle decorrelation](https://arxiv.org/abs/2509.05261)
*Thierry Judge,Nicolas Duchateau,Khuram Faraz,Pierre-Marc Jodoin,Olivier Bernard*

Main category: eess.IV

TL;DR: 提出一种改进的超声模拟框架，通过显式考虑斑点去相关来提高左室应变估计算法训练的图像实体性


<details>
  <summary>Details</summary>
Motivation: 现有的超声模拟流水线存在限制，不考虑斑点去相关，导致模拟图像实体性不足

Method: 在现有模拟流程基础上添加动态斑点变化模型，使用真实超声序列和心肌分割生成网格，通过相关性地图本地适配斑点去相关

Result: 在CAMUS数据库98名患者数据上评估，通过比较真实和模拟图像的相关曲线，方法获得了更低的平均绝对误差

Conclusion: 提出的方法能够更准确地重现临床数据中观察到的去相关行为，提高了超声模拟序列的实体性

Abstract: Simulated ultrasound image sequences are key for training and validating
machine learning algorithms for left ventricular strain estimation. Several
simulation pipelines have been proposed to generate sequences with
corresponding ground truth motion, but they suffer from limited realism as they
do not consider speckle decorrelation. In this work, we address this limitation
by proposing an improved simulation framework that explicitly accounts for
speckle decorrelation. Our method builds on an existing ultrasound simulation
pipeline by incorporating a dynamic model of speckle variation. Starting from
real ultrasound sequences and myocardial segmentations, we generate meshes that
guide image formation. Instead of applying a fixed ratio of myocardial and
background scatterers, we introduce a coherence map that adapts locally over
time. This map is derived from correlation values measured directly from the
real ultrasound data, ensuring that simulated sequences capture the
characteristic temporal changes observed in practice. We evaluated the realism
of our approach using ultrasound data from 98 patients in the CAMUS database.
Performance was assessed by comparing correlation curves from real and
simulated images. The proposed method achieved lower mean absolute error
compared to the baseline pipeline, indicating that it more faithfully
reproduces the decorrelation behavior seen in clinical data.

</details>
