{"id": "2508.09177", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09177", "abs": "https://arxiv.org/abs/2508.09177", "authors": ["Xuanru Zhou", "Cheng Li", "Shuqiang Wang", "Ye Li", "Tao Tan", "Hairong Zheng", "Shanshan Wang"], "title": "Generative Artificial Intelligence in Medical Imaging: Foundations, Progress, and Clinical Translation", "comment": null, "summary": "Generative artificial intelligence (AI) is rapidly transforming medical\nimaging by enabling capabilities such as data synthesis, image enhancement,\nmodality translation, and spatiotemporal modeling. This review presents a\ncomprehensive and forward-looking synthesis of recent advances in generative\nmodeling including generative adversarial networks (GANs), variational\nautoencoders (VAEs), diffusion models, and emerging multimodal foundation\narchitectures and evaluates their expanding roles across the clinical imaging\ncontinuum. We systematically examine how generative AI contributes to key\nstages of the imaging workflow, from acquisition and reconstruction to\ncross-modality synthesis, diagnostic support, and treatment planning. Emphasis\nis placed on both retrospective and prospective clinical scenarios, where\ngenerative models help address longstanding challenges such as data scarcity,\nstandardization, and integration across modalities. To promote rigorous\nbenchmarking and translational readiness, we propose a three-tiered evaluation\nframework encompassing pixel-level fidelity, feature-level realism, and\ntask-level clinical relevance. We also identify critical obstacles to\nreal-world deployment, including generalization under domain shift,\nhallucination risk, data privacy concerns, and regulatory hurdles. Finally, we\nexplore the convergence of generative AI with large-scale foundation models,\nhighlighting how this synergy may enable the next generation of scalable,\nreliable, and clinically integrated imaging systems. By charting technical\nprogress and translational pathways, this review aims to guide future research\nand foster interdisciplinary collaboration at the intersection of AI, medicine,\nand biomedical engineering.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u533b\u5b66\u5f71\u50cf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5305\u62ec\u6570\u636e\u5408\u6210\u3001\u56fe\u50cf\u589e\u5f3a\u7b49\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\u7684\u8d21\u732e\u4e0e\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u533b\u5b66\u5f71\u50cf\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u3001\u6807\u51c6\u5316\u548c\u591a\u6a21\u6001\u6574\u5408\u7b49\u957f\u671f\u6311\u6218\u3002", "method": "\u7efc\u8ff0\u4e86GANs\u3001VAEs\u3001\u6269\u6563\u6a21\u578b\u7b49\u751f\u6210\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e09\u5c42\u6b21\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u751f\u6210\u5f0fAI\u5728\u4e34\u5e8a\u5f71\u50cf\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u6cdb\u5316\u6027\u3001\u9690\u79c1\u7b49\u95ee\u9898\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u7ed3\u5408\u6709\u671b\u63a8\u52a8\u4e0b\u4e00\u4ee3\u4e34\u5e8a\u5f71\u50cf\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.09382", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09382", "abs": "https://arxiv.org/abs/2508.09382", "authors": ["Sreejith Sreekumar", "Kengo Kato"], "title": "Deviation Inequalities for R\u00e9nyi Divergence Estimators via Variational Expression", "comment": null, "summary": "R\\'enyi divergences play a pivotal role in information theory, statistics,\nand machine learning. While several estimators of these divergences have been\nproposed in the literature with their consistency properties established and\nminimax convergence rates quantified, existing accounts of probabilistic bounds\ngoverning the estimation error are premature. Here, we make progress in this\nregard by establishing exponential deviation inequalities for smoothed plug-in\nestimators and neural estimators by relating the error to an appropriate\nempirical process and leveraging tools from empirical process theory. In\nparticular, our approach does not require the underlying distributions to be\ncompactly supported or have densities bounded away from zero, an assumption\nprevalent in existing results. The deviation inequality also leads to a\none-sided concentration bound from the expectation, which is useful in\nrandom-coding arguments over continuous alphabets in information theory with\npotential applications to physical-layer security. As another concrete\napplication, we consider a hypothesis testing framework for auditing R\\'{e}nyi\ndifferential privacy using the neural estimator as a test statistic and obtain\nnon-asymptotic performance guarantees for such a test.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9R\u00e9nyi\u6563\u5ea6\u7684\u4f30\u8ba1\u8bef\u5dee\u63d0\u51fa\u4e86\u6307\u6570\u504f\u5dee\u4e0d\u7b49\u5f0f\uff0c\u9002\u7528\u4e8e\u5e73\u6ed1\u63d2\u4ef6\u4f30\u8ba1\u5668\u548c\u795e\u7ecf\u4f30\u8ba1\u5668\uff0c\u65e0\u9700\u4f20\u7edf\u5047\u8bbe\uff08\u5982\u7d27\u652f\u6491\u6216\u6709\u754c\u5bc6\u5ea6\uff09\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5bf9R\u00e9nyi\u6563\u5ea6\u4f30\u8ba1\u8bef\u5dee\u7684\u6982\u7387\u754c\u9650\u7814\u7a76\u4e0d\u8db3\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5c06\u8bef\u5dee\u4e0e\u9002\u5f53\u7684\u7ecf\u9a8c\u8fc7\u7a0b\u5173\u8054\uff0c\u5e76\u5229\u7528\u7ecf\u9a8c\u8fc7\u7a0b\u7406\u8bba\u5de5\u5177\uff0c\u5efa\u7acb\u6307\u6570\u504f\u5dee\u4e0d\u7b49\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u975e\u7d27\u652f\u6491\u6216\u65e0\u754c\u5bc6\u5ea6\u5206\u5e03\u7684\u504f\u5dee\u4e0d\u7b49\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u4fe1\u606f\u8bba\u548c\u9690\u79c1\u5ba1\u8ba1\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u4e3aR\u00e9nyi\u6563\u5ea6\u4f30\u8ba1\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u6982\u7387\u754c\u9650\uff0c\u6269\u5c55\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2508.09179", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09179", "abs": "https://arxiv.org/abs/2508.09179", "authors": ["Hongli Chen", "Pengcheng Fang", "Yuxia Chen", "Yingxuan Ren", "Jing Hao", "Fangfang Tang", "Xiaohao Cai", "Shanshan Shan", "Feng Liu"], "title": "HiFi-Mamba: Dual-Stream W-Laplacian Enhanced Mamba for High-Fidelity MRI Reconstruction", "comment": null, "summary": "Reconstructing high-fidelity MR images from undersampled k-space data remains\na challenging problem in MRI. While Mamba variants for vision tasks offer\npromising long-range modeling capabilities with linear-time complexity, their\ndirect application to MRI reconstruction inherits two key limitations: (1)\ninsensitivity to high-frequency anatomical details; and (2) reliance on\nredundant multi-directional scanning. To address these limitations, we\nintroduce High-Fidelity Mamba (HiFi-Mamba), a novel dual-stream Mamba-based\narchitecture comprising stacked W-Laplacian (WL) and HiFi-Mamba blocks.\nSpecifically, the WL block performs fidelity-preserving spectral decoupling,\nproducing complementary low- and high-frequency streams. This separation\nenables the HiFi-Mamba block to focus on low-frequency structures, enhancing\nglobal feature modeling. Concurrently, the HiFi-Mamba block selectively\nintegrates high-frequency features through adaptive state-space modulation,\npreserving comprehensive spectral details. To eliminate the scanning\nredundancy, the HiFi-Mamba block adopts a streamlined unidirectional traversal\nstrategy that preserves long-range modeling capability with improved\ncomputational efficiency. Extensive experiments on standard MRI reconstruction\nbenchmarks demonstrate that HiFi-Mamba consistently outperforms\nstate-of-the-art CNN-based, Transformer-based, and other Mamba-based models in\nreconstruction accuracy while maintaining a compact and efficient model design.", "AI": {"tldr": "HiFi-Mamba\u662f\u4e00\u79cd\u65b0\u578b\u53cc\u6d41Mamba\u67b6\u6784\uff0c\u7528\u4e8e\u4ece\u6b20\u91c7\u6837\u7684k\u7a7a\u95f4\u6570\u636e\u91cd\u5efa\u9ad8\u4fdd\u771fMR\u56fe\u50cf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9ad8\u9891\u7ec6\u8282\u4e0d\u654f\u611f\u548c\u626b\u63cf\u5197\u4f59\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfMamba\u53d8\u4f53\u5728MRI\u91cd\u5efa\u4e2d\u5b58\u5728\u5bf9\u9ad8\u9891\u89e3\u5256\u7ec6\u8282\u4e0d\u654f\u611f\u548c\u4f9d\u8d56\u5197\u4f59\u591a\u65b9\u5411\u626b\u63cf\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faHiFi-Mamba\u67b6\u6784\uff0c\u5305\u542bWL\u5757\u548cHiFi-Mamba\u5757\uff0c\u5206\u522b\u5904\u7406\u4f4e\u9891\u548c\u9ad8\u9891\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u5355\u5411\u904d\u5386\u7b56\u7565\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728\u6807\u51c6MRI\u91cd\u5efa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHiFi-Mamba\u5728\u91cd\u5efa\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709CNN\u3001Transformer\u548c\u5176\u4ed6Mamba\u6a21\u578b\u3002", "conclusion": "HiFi-Mamba\u5728\u4fdd\u6301\u9ad8\u6548\u8bbe\u8ba1\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86MRI\u91cd\u5efa\u7684\u51c6\u786e\u6027\u548c\u9891\u8c31\u7ec6\u8282\u4fdd\u7559\u80fd\u529b\u3002"}}
{"id": "2508.09687", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09687", "abs": "https://arxiv.org/abs/2508.09687", "authors": ["Chun'e Zhao", "Yuxin Han", "Wenping Ma", "Tongjiang Yan", "Yuhua Sun"], "title": "Hermitian Self-dual Twisted Generalized Reed-Solomon Codes", "comment": "This manuscript has been submitted to the IEEE Transactions on\n  Information Theory for possible publication", "summary": "Self-dual maximum distance separable (MDS) codes over finite fields are\nlinear codes with significant combinatorial and cryptographic applications.\nTwisted generalized Reed-Solomon (TGRS) codes can be both MDS and self-dual. In\nthis paper, we study a general class of TGRS codes (A-TGRS), which encompasses\nall previously known special cases. First, we establish a sufficient and\nnecessary condition for an A-TGRS code to be Hermitian self-dual. Furthermore,\nwe present four constructions of self-dual TGRS codes, which, to the best of\nour knowledge, nearly cover all the related results previously reported in the\nliterature. More importantly, we also obtain several new classes of Hermitian\nself-dual TGRS codes with flexible parameters. Based on this framework, we\nderive a sufficient and necessary condition for an A-TGRS code to be Hermitian\nself-dual and MDS. In addition, we construct a class of MDS Hermitian self-dual\nTGRS code by appropriately selecting the evaluation points. This work\ninvestigates the Hermitian self-duality of TGRS codes from the perspective of\nmatrix representation, leading to more concise and transparent analysis. More\ngenerally, the Euclidean self-dual TGRS codes and the Hermitian self-dual GRS\ncodes can also be understood easily from this point.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e7f\u4e49\u626d\u66f2Reed-Solomon\uff08A-TGRS\uff09\u7801\u7684Hermitian\u81ea\u5bf9\u5076\u6027\uff0c\u63d0\u51fa\u4e86\u56db\u4e2a\u6784\u9020\u65b9\u6cd5\uff0c\u5e76\u83b7\u5f97\u4e86\u65b0\u7684Hermitian\u81ea\u5bf9\u5076TGRS\u7801\u7c7b\u3002\u6b64\u5916\uff0c\u8fd8\u7ed9\u51fa\u4e86A-TGRS\u7801\u4e3aHermitian\u81ea\u5bf9\u5076\u4e14MDS\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u77e9\u9635\u8868\u793a\u7b80\u5316\u4e86\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u81ea\u5bf9\u5076MDS\u7801\u5728\u7ec4\u5408\u548c\u5bc6\u7801\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662fTGRS\u7801\u7684\u81ea\u5bf9\u5076\u6027\u3002", "method": "\u901a\u8fc7\u77e9\u9635\u8868\u793a\u5206\u6790A-TGRS\u7801\u7684Hermitian\u81ea\u5bf9\u5076\u6027\uff0c\u63d0\u51fa\u6784\u9020\u65b9\u6cd5\u5e76\u9a8c\u8bc1\u5176\u5145\u8981\u6761\u4ef6\u3002", "result": "\u83b7\u5f97\u4e86\u65b0\u7684Hermitian\u81ea\u5bf9\u5076TGRS\u7801\u7c7b\uff0c\u5e76\u6784\u9020\u4e86\u4e00\u7c7bMDS Hermitian\u81ea\u5bf9\u5076TGRS\u7801\u3002", "conclusion": "\u77e9\u9635\u8868\u793a\u65b9\u6cd5\u7b80\u5316\u4e86\u5206\u6790\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684Euclidean\u81ea\u5bf9\u5076TGRS\u7801\u548cHermitian\u81ea\u5bf9\u5076GRS\u7801\u3002"}}
{"id": "2508.09182", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09182", "abs": "https://arxiv.org/abs/2508.09182", "authors": ["Baraa Al Jorf", "Farah Shamout"], "title": "MedPatch: Confidence-Guided Multi-Stage Fusion for Multimodal Clinical Data", "comment": null, "summary": "Clinical decision-making relies on the integration of information across\nvarious data modalities, such as clinical time-series, medical images and\ntextual reports. Compared to other domains, real-world medical data is\nheterogeneous in nature, limited in size, and sparse due to missing modalities.\nThis significantly limits model performance in clinical prediction tasks.\nInspired by clinical workflows, we introduce MedPatch, a multi-stage multimodal\nfusion architecture, which seamlessly integrates multiple modalities via\nconfidence-guided patching. MedPatch comprises three main components: (i) a\nmulti-stage fusion strategy that leverages joint and late fusion\nsimultaneously, (ii) a missingness-aware module that handles sparse samples\nwith missing modalities, (iii) a joint fusion module that clusters latent token\npatches based on calibrated unimodal token-level confidence. We evaluated\nMedPatch using real-world data consisting of clinical time-series data, chest\nX-ray images, radiology reports, and discharge notes extracted from the\nMIMIC-IV, MIMIC-CXR, and MIMIC-Notes datasets on two benchmark tasks, namely\nin-hospital mortality prediction and clinical condition classification.\nCompared to existing baselines, MedPatch achieves state-of-the-art performance.\nOur work highlights the effectiveness of confidence-guided multi-stage fusion\nin addressing the heterogeneity of multimodal data, and establishes new\nstate-of-the-art benchmark results for clinical prediction tasks.", "AI": {"tldr": "MedPatch\u662f\u4e00\u79cd\u591a\u9636\u6bb5\u591a\u6a21\u6001\u878d\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u5206\u5757\u65b9\u6cd5\u6574\u5408\u4e34\u5e8a\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u533b\u7597\u6570\u636e\u7684\u5f02\u8d28\u6027\u548c\u7a00\u758f\u6027\u95ee\u9898\uff0c\u5e76\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u6570\u636e\u5177\u6709\u5f02\u8d28\u6027\u3001\u89c4\u6a21\u6709\u9650\u548c\u6a21\u6001\u7f3a\u5931\u7684\u7279\u70b9\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u7684\u6a21\u578b\u6027\u80fd\u3002\u53d7\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u542f\u53d1\uff0c\u63d0\u51fa\u4e86MedPatch\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "MedPatch\u5305\u542b\u591a\u9636\u6bb5\u878d\u5408\u7b56\u7565\u3001\u7f3a\u5931\u611f\u77e5\u6a21\u5757\u548c\u8054\u5408\u878d\u5408\u6a21\u5757\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u5206\u5757\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u3002", "result": "\u5728MIMIC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMedPatch\u5728\u9662\u5185\u6b7b\u4ea1\u7387\u9884\u6d4b\u548c\u4e34\u5e8a\u6761\u4ef6\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "MedPatch\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u591a\u9636\u6bb5\u878d\u5408\u6709\u6548\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u7684\u5f02\u8d28\u6027\uff0c\u4e3a\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\u3002"}}
{"id": "2508.09695", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09695", "abs": "https://arxiv.org/abs/2508.09695", "authors": ["Han Xiao", "Xiaoyan Hu", "Kai-Kit Wong", "Xusheng Zhu", "Hanjiang Hong", "Chan-Byoung Chae"], "title": "Fluid Reconfigurable Intelligent Surface with Element-Level Pattern Reconfigurability: Beamforming and Pattern Co-Design", "comment": null, "summary": "This paper proposes a novel pattern-reconfigurable fluid reconfigurable\nintelligent surface (FRIS) framework, where each fluid element can dynamically\nadjust its radiation pattern based on instantaneous channel conditions. To\nevaluate its potential, we first conduct a comparative analysis of the received\nsignal power in point-to-point communication systems assisted by three types of\nsurfaces: (1) the proposed pattern-reconfigurable FRIS, (2) a\nposition-reconfigurable FRIS, and (3) a conventional RIS. Theoretical results\ndemonstrate that the pattern-reconfigurable FRIS provides a significant\nadvantage in modulating transmission signals compared to the other two\nconfigurations. To further study its capabilities, we extend the framework to a\nmultiuser communication scenario. In this context, the spherical harmonics\northogonal decomposition (SHOD) method is employed to accurately model the\nradiation patterns of individual fluid elements, making the pattern design\nprocess more tractable. An optimization problem is then formulated with the\nobjective of maximizing the weighted sum rate among users by jointly designing\nthe active beamforming vectors and the spherical harmonics coefficients,\nsubject to both transmit power and pattern energy constraints. To tackle the\nresulting non-convex optimization problem, we propose an iterative algorithm\nthat alternates between a minimum mean-square error (MMSE) approach for active\nbeamforming and a Riemannian conjugate gradient (RCG) method for updating the\nspherical harmonics coefficients. Simulation results show that the proposed\npattern-reconfigurable FRIS significantly outperforms traditional RIS\narchitectures based on the 3GPP 38.901 and isotropic radiation models,\nachieving average performance gains of 161.5% and 176.2%, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u53ef\u91cd\u6784\u6d41\u4f53\u667a\u80fd\u8868\u9762\uff08FRIS\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6d41\u4f53\u5143\u4ef6\u7684\u8f90\u5c04\u6a21\u5f0f\u4f18\u5316\u901a\u4fe1\u6027\u80fd\u3002\u7406\u8bba\u5206\u6790\u548c\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u591a\u7528\u6237\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edfRIS\u67b6\u6784\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6d41\u4f53\u5143\u4ef6\u7684\u8f90\u5c04\u6a21\u5f0f\u6765\u4f18\u5316\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u70b9\u5bf9\u70b9\u548c\u591a\u7528\u6237\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7403\u5f62\u8c10\u6ce2\u6b63\u4ea4\u5206\u89e3\uff08SHOD\uff09\u7684\u65b9\u6cd5\u5efa\u6a21\u6d41\u4f53\u5143\u4ef6\u7684\u8f90\u5c04\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u7b97\u6cd5\uff08MMSE\u548cRCG\uff09\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u548c\u7403\u5f62\u8c10\u6ce2\u7cfb\u6570\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684FRIS\u6846\u67b6\u57283GPP 38.901\u548c\u5404\u5411\u540c\u6027\u8f90\u5c04\u6a21\u578b\u4e0b\uff0c\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e86161.5%\u548c176.2%\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u52a8\u6001\u6a21\u5f0f\u53ef\u91cd\u6784FRIS\u5728\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u8868\u9762\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09189", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09189", "abs": "https://arxiv.org/abs/2508.09189", "authors": ["Madan Baduwal"], "title": "Hybrid(Transformer+CNN)-based Polyp Segmentation", "comment": "8 pages", "summary": "Colonoscopy is still the main method of detection and segmentation of colonic\npolyps, and recent advancements in deep learning networks such as U-Net,\nResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp\nsegmentation. Yet, the problem is extremely challenging due to high variation\nin size, shape, endoscopy types, lighting, imaging protocols, and ill-defined\nboundaries (fluid, folds) of the polyps, rendering accurate segmentation a\nchallenging and problematic task. To address these critical challenges in polyp\nsegmentation, we introduce a hybrid (Transformer + CNN) model that is crafted\nto enhance robustness against evolving polyp characteristics. Our hybrid\narchitecture demonstrates superior performance over existing solutions,\nparticularly in addressing two critical challenges: (1) accurate segmentation\nof polyps with ill-defined margins through boundary-aware attention mechanisms,\nand (2) robust feature extraction in the presence of common endoscopic\nartifacts, including specular highlights, motion blur, and fluid occlusions.\nQuantitative evaluations reveal significant improvements in segmentation\naccuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%,\ni.e., 0.9849) and artifact resilience compared to state-of-the-art polyp\nsegmentation methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Transformer\u548cCNN\u7684\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8\u7ed3\u80a0\u606f\u8089\u5206\u5272\u7684\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u8fb9\u754c\u6a21\u7cca\u548c\u5185\u7aa5\u955c\u4f2a\u5f71\u7684\u6311\u6218\u3002", "motivation": "\u7ed3\u80a0\u606f\u8089\u5206\u5272\u56e0\u606f\u8089\u5927\u5c0f\u3001\u5f62\u72b6\u3001\u5185\u7aa5\u955c\u7c7b\u578b\u3001\u5149\u7167\u548c\u8fb9\u754c\u6a21\u7cca\u7b49\u56e0\u7d20\u6781\u5177\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u91c7\u7528Transformer\u4e0eCNN\u7ed3\u5408\u7684\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u548c\u9c81\u68d2\u7279\u5f81\u63d0\u53d6\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u5206\u5272\u51c6\u786e\u7387\uff08\u53ec\u56de\u7387\u63d0\u53471.76%\uff0c\u51c6\u786e\u7387\u63d0\u53470.07%\uff09\u548c\u4f2a\u5f71\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6df7\u5408\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u606f\u8089\u5206\u5272\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u5728\u5904\u7406\u6a21\u7cca\u8fb9\u754c\u548c\u5185\u7aa5\u955c\u4f2a\u5f71\u65f6\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.09744", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09744", "abs": "https://arxiv.org/abs/2508.09744", "authors": ["Andreas Zunker", "Marvin R\u00fcbenacke", "Stephan ten Brink"], "title": "ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding", "comment": "6 pages, 2 figures. Submitted to IEEE for possible publication", "summary": "Motivated by the need for channel codes with low-complexity soft-decision\ndecoding algorithms, we consider the recursive Plotkin concatenation of optimal\nlow-rate and high-rate codes based on simplex codes and their duals. These\ncomponent codes come with low-complexity maximum likelihood (ML) decoding\nwhich, in turn, enables efficient successive cancellation (SC)-based decoding.\nAs a result, the proposed optimally recursively concatenated simplex (ORCAS)\ncodes achieve a performance that is at least as good as that of polar codes.\nFor practical parameters, the proposed construction significantly outperforms\npolar codes in terms of block error rate by up to 0.5 dB while maintaining\nsimilar decoding complexity. Furthermore, the codes offer greater flexibility\nin codeword length than conventional polar codes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9012\u5f52Plotkin\u7ea7\u8054\u7684\u4f4e\u590d\u6742\u5ea6\u8f6f\u5224\u51b3\u89e3\u7801\u7b97\u6cd5\uff0c\u79f0\u4e3aORCAS\u7801\uff0c\u6027\u80fd\u4f18\u4e8e\u6216\u7b49\u4e8e\u6781\u5316\u7801\uff0c\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u3002", "motivation": "\u9700\u8981\u5f00\u53d1\u4f4e\u590d\u6742\u5ea6\u8f6f\u5224\u51b3\u89e3\u7801\u7b97\u6cd5\u7684\u4fe1\u9053\u7f16\u7801\u3002", "method": "\u9012\u5f52\u7ea7\u8054\u57fa\u4e8e\u5355\u7eaf\u5f62\u7801\u53ca\u5176\u5bf9\u5076\u7801\u7684\u4f4e\u7801\u7387\u548c\u9ad8\u7801\u7387\u6700\u4f18\u7801\uff0c\u91c7\u7528\u4f4e\u590d\u6742\u5ea6\u6700\u5927\u4f3c\u7136\u89e3\u7801\u548c\u8fde\u7eed\u62b5\u6d88\u89e3\u7801\u3002", "result": "ORCAS\u7801\u6027\u80fd\u81f3\u5c11\u4e0e\u6781\u5316\u7801\u76f8\u5f53\uff0c\u5b9e\u9645\u53c2\u6570\u4e0b\u5757\u9519\u8bef\u7387\u4f18\u4e8e\u6781\u5316\u78010.5 dB\uff0c\u89e3\u7801\u590d\u6742\u5ea6\u76f8\u8fd1\uff0c\u4e14\u7801\u957f\u66f4\u7075\u6d3b\u3002", "conclusion": "ORCAS\u7801\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e0a\u4f18\u4e8e\u6781\u5316\u7801\uff0c\u9002\u7528\u4e8e\u4f4e\u590d\u6742\u5ea6\u89e3\u7801\u9700\u6c42\u7684\u5e94\u7528\u3002"}}
{"id": "2508.09140", "categories": ["eess.SP", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09140", "abs": "https://arxiv.org/abs/2508.09140", "authors": ["Honggang Jia", "Nan Cheng", "Xiucheng Wang", "Conghao Zhou", "Ruijin Sun", "Xuemin", "Shen"], "title": "RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet", "comment": null, "summary": "Radio map (RM) has recently attracted much attention since it can provide\nreal-time and accurate spatial channel information for 6G services and\napplications. However, current deep learning-based methods for RM construction\nexhibit well known accuracy-efficiency trade-off. In this paper, we introduce\nRadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the\ntrade-off. Generally, accurate RM construction requires modeling long-range\nspatial dependencies, reflecting the global nature of wave propagation physics.\nRadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures\nthese global dependencies with linear complexity, while a parallel\nconvolutional branch extracts local features. This hybrid design generates\nfeature representations that capture both global context and local detail.\nExperiments show that RadioMamba achieves higher accuracy than existing\nmethods, including diffusion models, while operating nearly 20 times faster and\nusing only 2.9\\% of the model parameters. By improving both accuracy and\nefficiency, RadioMamba presents a viable approach for real-time intelligent\noptimization in next generation wireless systems.", "AI": {"tldr": "RadioMamba\u662f\u4e00\u79cd\u6df7\u5408Mamba-UNet\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u4e2d\u7684\u7cbe\u5ea6\u4e0e\u6548\u7387\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u6743\u8861\u95ee\u9898\uff0c\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u9700\u6c42\u3002", "method": "RadioMamba\u91c7\u7528Mamba-\u5377\u79ef\u5757\uff0cMamba\u5206\u652f\u4ee5\u7ebf\u6027\u590d\u6742\u5ea6\u6355\u83b7\u5168\u5c40\u4f9d\u8d56\uff0c\u5377\u79ef\u5206\u652f\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\uff0c\u5b9e\u73b0\u5168\u5c40\u4e0e\u5c40\u90e8\u7279\u5f81\u7684\u7ed3\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRadioMamba\u5728\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u6269\u6563\u6a21\u578b\uff09\uff0c\u901f\u5ea6\u63d0\u5347\u8fd120\u500d\uff0c\u53c2\u6570\u4ec5\u53602.9%\u3002", "conclusion": "RadioMamba\u901a\u8fc7\u63d0\u5347\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u7684\u5b9e\u65f6\u667a\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.09195", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09195", "abs": "https://arxiv.org/abs/2508.09195", "authors": ["Maria Boyko", "Aleksandra Beliaeva", "Dmitriy Kornilov", "Alexander Bernstein", "Maxim Sharaev"], "title": "impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction", "comment": null, "summary": "The use of diverse modalities, such as omics, medical images, and clinical\ndata can not only improve the performance of prognostic models but also deepen\nan understanding of disease mechanisms and facilitate the development of novel\ntreatment approaches. However, medical data are complex, often incomplete, and\ncontains missing modalities, making effective handling its crucial for training\nmultimodal models. We introduce impuTMAE, a novel transformer-based end-to-end\napproach with an efficient multimodal pre-training strategy. It learns inter-\nand intra-modal interactions while simultaneously imputing missing modalities\nby reconstructing masked patches. Our model is pre-trained on heterogeneous,\nincomplete data and fine-tuned for glioma survival prediction using\nTCGA-GBM/LGG and BraTS datasets, integrating five modalities: genetic (DNAm,\nRNA-seq), imaging (MRI, WSI), and clinical data. By addressing missing data\nduring pre-training and enabling efficient resource utilization, impuTMAE\nsurpasses prior multimodal approaches, achieving state-of-the-art performance\nin glioma patient survival prediction. Our code is available at\nhttps://github.com/maryjis/mtcp", "AI": {"tldr": "impuTMAE\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u5efa\u63a9\u7801\u8865\u4e01\u5b66\u4e60\u6a21\u6001\u95f4\u548c\u6a21\u6001\u5185\u4ea4\u4e92\uff0c\u540c\u65f6\u586b\u8865\u7f3a\u5931\u6a21\u6001\uff0c\u5728\u80f6\u8d28\u7624\u751f\u5b58\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u7ec4\u5b66\u3001\u533b\u5b66\u5f71\u50cf\u548c\u4e34\u5e8a\u6570\u636e\uff09\u53ef\u63d0\u5347\u9884\u540e\u6a21\u578b\u6027\u80fd\u5e76\u6df1\u5316\u75be\u75c5\u673a\u5236\u7406\u89e3\uff0c\u4f46\u6570\u636e\u590d\u6742\u4e14\u5e38\u7f3a\u5931\uff0c\u9700\u6709\u6548\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51faimpuTMAE\uff0c\u4e00\u79cd\u7aef\u5230\u7aef\u7684Transformer\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u5b66\u4e60\u591a\u6a21\u6001\u4ea4\u4e92\u5e76\u586b\u8865\u7f3a\u5931\u6570\u636e\uff0c\u518d\u5fae\u8c03\u7528\u4e8e\u80f6\u8d28\u7624\u751f\u5b58\u9884\u6d4b\u3002", "result": "\u5728TCGA-GBM/LGG\u548cBraTS\u6570\u636e\u96c6\u4e0a\uff0cimpuTMAE\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u80f6\u8d28\u7624\u751f\u5b58\u9884\u6d4b\u7684\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "impuTMAE\u901a\u8fc7\u5904\u7406\u7f3a\u5931\u6570\u636e\u548c\u9ad8\u6548\u8d44\u6e90\u5229\u7528\uff0c\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u4e3a\u75be\u75c5\u9884\u6d4b\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09782", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09782", "abs": "https://arxiv.org/abs/2508.09782", "authors": ["Qin Yi", "Zilong Liu", "Leila Musavian", "Zeping Sui"], "title": "Non-Orthogonal Affine Frequency Division Multiplexing for Spectrally Efficient High-Mobility Communications", "comment": "13 pages, 13 figures, submitted to IEEE Transactions on Wireless\n  Communications", "summary": "This paper proposes a novel non-orthogonal affine frequency division\nmultiplexing {(nAFDM)} waveform for reliable high-mobility communications with\nenhanced spectral efficiency {(SE)}. The key idea is {to introduce} a bandwidth\ncompression factor into the AFDM {modulator} to enable controllable subcarrier\noverlapping. We first {detail the proposed nAFDM transceiver} and derive the\ncorresponding input-output {signal} relationship. Then, an efficient {nAFDM}\nsignal generation method based on the inverse discrete Fourier transform (IDFT)\nis proposed, enabling practical implementation using existing inverse fast\nFourier transform (IFFT) modules without additional hardware complexity. Next,\nto characterize the impact of non-orthogonal modulation, we derive a\nclosed-form expression {of} inter-carrier interference (ICI), showing its\ndependence on the bandwidth compression factor. To mitigate the resulting\ninterference, we propose a soft iterative detection algorithm and a\nlow-complexity implementation approach that leverages the distribution\ncharacteristics of ICI. {Simulation results demonstrate that 1) in terms of bit\nerror rate (BER), the proposed nAFDM can achieve near identical BER compared to\nconventional AFDM, while outperforms other waveform counterparts; 2) nAFDM is\ncapable of striking higher SE compared to other existing waveforms; and 3) the\nproposed nAFDM achieves an attractive BER vs. SE trade-off, and the proposed\nsoft ID scheme can attain a trade-off between BER and complexity.}", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u975e\u6b63\u4ea4\u4eff\u5c04\u9891\u5206\u590d\u7528\uff08nAFDM\uff09\u6ce2\u5f62\uff0c\u7528\u4e8e\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u9891\u8c31\u6548\u7387\u3002\u901a\u8fc7\u5f15\u5165\u5e26\u5bbd\u538b\u7f29\u56e0\u5b50\u5b9e\u73b0\u53ef\u63a7\u5b50\u8f7d\u6ce2\u91cd\u53e0\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eIDFT\u7684\u751f\u6210\u65b9\u6cd5\u548c\u8f6f\u8fed\u4ee3\u68c0\u6d4b\u7b97\u6cd5\u3002\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cnAFDM\u5728\u8bef\u7801\u7387\u548c\u9891\u8c31\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u6ce2\u5f62\u3002", "motivation": "\u89e3\u51b3\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u4e2d\u9891\u8c31\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u975e\u6b63\u4ea4\u8c03\u5236\u5b9e\u73b0\u66f4\u9ad8\u7684\u9891\u8c31\u5229\u7528\u7387\u3002", "method": "\u5f15\u5165\u5e26\u5bbd\u538b\u7f29\u56e0\u5b50\u5b9e\u73b0\u5b50\u8f7d\u6ce2\u91cd\u53e0\uff0c\u63d0\u51fa\u57fa\u4e8eIDFT\u7684\u4fe1\u53f7\u751f\u6210\u65b9\u6cd5\u548c\u8f6f\u8fed\u4ee3\u68c0\u6d4b\u7b97\u6cd5\u3002", "result": "nAFDM\u5728\u8bef\u7801\u7387\u4e0a\u4e0e\u4f20\u7edfAFDM\u63a5\u8fd1\uff0c\u9891\u8c31\u6548\u7387\u66f4\u9ad8\uff0c\u4e14\u80fd\u5b9e\u73b0\u8bef\u7801\u7387\u4e0e\u590d\u6742\u5ea6\u7684\u5e73\u8861\u3002", "conclusion": "nAFDM\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u6ce2\u5f62\uff0c\u5177\u6709\u4f18\u5f02\u7684\u8bef\u7801\u7387\u548c\u9891\u8c31\u6548\u7387\u8868\u73b0\u3002"}}
{"id": "2508.09142", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09142", "abs": "https://arxiv.org/abs/2508.09142", "authors": ["Wenlihan Lu", "Shijian Gao", "Miaowen Wen", "Yuxuan Liang", "Chan-Byoung Chae", "H. Vincent Poor"], "title": "Bayesian-Driven Graph Reasoning for Active Radio Map Construction", "comment": null, "summary": "With the emergence of the low-altitude economy, radio maps have become\nessential for ensuring reliable wireless connectivity to aerial platforms.\nAutonomous aerial agents are commonly deployed for data collection using\nwaypoint-based navigation; however, their limited battery capacity\nsignificantly constrains coverage and efficiency. To address this, we propose\nan uncertainty-aware radio map (URAM) reconstruction framework that explicitly\nleverages graph-based reasoning tailored for waypoint navigation. Our approach\nintegrates two key deep learning components: (1) a Bayesian neural network that\nestimates spatial uncertainty in real time, and (2) an attention-based\nreinforcement learning policy that performs global reasoning over a\nprobabilistic roadmap, using uncertainty estimates to plan informative and\nenergy-efficient trajectories. This graph-based reasoning enables intelligent,\nnon-myopic trajectory planning, guiding agents toward the most informative\nregions while satisfying safety constraints. Experimental results show that\nURAM improves reconstruction accuracy by up to 34% over existing baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u65e0\u7ebf\u7535\u5730\u56fe\u91cd\u5efa\u6846\u67b6\uff08URAM\uff09\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u5f3a\u5316\u5b66\u4e60\uff0c\u4f18\u5316\u65e0\u4eba\u673a\u5bfc\u822a\u7684\u8986\u76d6\u8303\u56f4\u548c\u6548\u7387\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\uff0c\u65e0\u7ebf\u7535\u5730\u56fe\u5bf9\u65e0\u4eba\u673a\u65e0\u7ebf\u8fde\u63a5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7535\u6c60\u5bb9\u91cf\u9650\u5236\u4e86\u6570\u636e\u6536\u96c6\u7684\u8986\u76d6\u548c\u6548\u7387\u3002", "method": "\u7ed3\u5408\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u5b9e\u65f6\u4f30\u8ba1\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u53ca\u6ce8\u610f\u529b\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u5168\u5c40\u8def\u5f84\u89c4\u5212\u3002", "result": "URAM\u6bd4\u73b0\u6709\u57fa\u7ebf\u91cd\u5efa\u7cbe\u5ea6\u63d0\u9ad834%\u3002", "conclusion": "URAM\u901a\u8fc7\u667a\u80fd\u975e\u77ed\u89c6\u8def\u5f84\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u6570\u636e\u6536\u96c6\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09196", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09196", "abs": "https://arxiv.org/abs/2508.09196", "authors": ["Asim Ukaye", "Numan Saeed", "Karthik Nandakumar"], "title": "FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation", "comment": "17 pages, 5 figures, Machine Learning for Healthcare Conference", "summary": "Different CT segmentation datasets are typically obtained from different\nscanners under different capture settings and often provide segmentation labels\nfor a limited and often disjoint set of organs. Using these heterogeneous data\neffectively while preserving patient privacy can be challenging. This work\npresents a novel federated learning approach to achieve universal segmentation\nacross diverse abdominal CT datasets by utilizing model uncertainty for\naggregation and predictive uncertainty for inference. Our approach leverages\nthe inherent noise in stochastic mini-batch gradient descent to estimate a\ndistribution over the model weights to provide an on-the-go uncertainty over\nthe model parameters at the client level. The parameters are then aggregated at\nthe server using the additional uncertainty information using a\nBayesian-inspired inverse-variance aggregation scheme. Furthermore, the\nproposed method quantifies prediction uncertainty by propagating the\nuncertainty from the model weights, providing confidence measures essential for\nclinical decision-making. In line with recent work shown, predictive\nuncertainty is utilized in the inference stage to improve predictive\nperformance. Experimental evaluations demonstrate the effectiveness of this\napproach in improving both the quality of federated aggregation and\nuncertainty-weighted inference compared to previously established baselines.\nThe code for this work is made available at: https://github.com/asimukaye/fiva", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u8de8\u4e0d\u540c\u8179\u90e8CT\u6570\u636e\u96c6\u7684\u901a\u7528\u5206\u5272\u3002", "motivation": "\u89e3\u51b3\u4e0d\u540cCT\u6570\u636e\u96c6\u56e0\u626b\u63cf\u5668\u548c\u8bbe\u7f6e\u5dee\u5f02\u5bfc\u81f4\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u3002", "method": "\u5229\u7528\u968f\u673a\u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\u7684\u566a\u58f0\u4f30\u8ba1\u6a21\u578b\u6743\u91cd\u5206\u5e03\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u9006\u65b9\u5dee\u805a\u5408\u65b9\u6848\u5728\u670d\u52a1\u5668\u7aef\u805a\u5408\u53c2\u6570\uff0c\u5e76\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8054\u90a6\u805a\u5408\u8d28\u91cf\u548c\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u63a8\u7406\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8de8\u6570\u636e\u96c6\u5206\u5272\u7684\u6027\u80fd\u548c\u4e34\u5e8a\u51b3\u7b56\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09817", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09817", "abs": "https://arxiv.org/abs/2508.09817", "authors": ["Zhehan Zhou", "Xiaoming Chen", "Ming Ying", "Zhaohui Yang", "Chongwen Huang", "Yunlong Cai", "Zhaoyang Zhang"], "title": "Unified Design of Space-Air-Ground-Sea Integrated Maritime Communications", "comment": null, "summary": "With the explosive growth of maritime activities, it is expected to provide\nseamless communications with quality of service (QoS) guarantee over broad sea\narea. In the context, this paper proposes a space-air-ground-sea integrated\nmaritime communication architecture combining satellite, unmanned aerial\nvehicle (UAV), terrestrial base station (TBS) and unmanned surface vessel\n(USV). Firstly, according to the distance away from the shore, the whole marine\nspace is divided to coastal area, offshore area, middle-sea area and open-sea\narea, the maritime users in which are served by TBS, USV, UAV and satellite,\nrespectively. Then, by exploiting the potential of integrated maritime\ncommunication system, a joint beamforming and trajectory optimization algorithm\nis designed to maximize the minimum transmission rate of maritime users.\nFinally, theoretical analysis and simulation results validate the effectiveness\nof the proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u536b\u661f\u3001\u65e0\u4eba\u673a\u3001\u5730\u9762\u57fa\u7ad9\u548c\u65e0\u4eba\u8239\u7684\u5929\u5730\u6d77\u4e00\u4f53\u5316\u6d77\u4e0a\u901a\u4fe1\u67b6\u6784\uff0c\u901a\u8fc7\u8054\u5408\u6ce2\u675f\u6210\u5f62\u548c\u8f68\u8ff9\u4f18\u5316\u7b97\u6cd5\uff0c\u6700\u5927\u5316\u7528\u6237\u7684\u6700\u5c0f\u4f20\u8f93\u901f\u7387\u3002", "motivation": "\u968f\u7740\u6d77\u4e0a\u6d3b\u52a8\u7684\u7206\u70b8\u6027\u589e\u957f\uff0c\u9700\u8981\u4e3a\u5e7f\u9614\u6d77\u57df\u63d0\u4f9b\u65e0\u7f1d\u901a\u4fe1\u5e76\u4fdd\u969c\u670d\u52a1\u8d28\u91cf\u3002", "method": "\u5c06\u6d77\u57df\u5212\u5206\u4e3a\u6cbf\u6d77\u3001\u8fd1\u6d77\u3001\u4e2d\u6d77\u548c\u8fdc\u6d77\u533a\u57df\uff0c\u5206\u522b\u7531\u5730\u9762\u57fa\u7ad9\u3001\u65e0\u4eba\u8239\u3001\u65e0\u4eba\u673a\u548c\u536b\u661f\u63d0\u4f9b\u670d\u52a1\uff0c\u5e76\u8bbe\u8ba1\u8054\u5408\u6ce2\u675f\u6210\u5f62\u548c\u8f68\u8ff9\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u548c\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6d77\u4e0a\u901a\u4fe1\u7684\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2508.09348", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.09348", "abs": "https://arxiv.org/abs/2508.09348", "authors": ["Chunmei Xu", "Yi Ma", "Rahim Tafazolli", "Peiying Zhu"], "title": "Generative AI-Enabled Robust 6G Uplink: Principles, Challenges, and Directions", "comment": null, "summary": "Next-generation wireless networks (6G) face a critical uplink bottleneck due\nto stringent device-side resource constraints and challenging channel\nconditions. This article introduces GenCom, a novel system-level paradigm for\nrobust 6G uplink that leverages Generative AI and exploits the inherent\nresource imbalance between transmitters and receivers. In GenCom, resource-rich\nreceivers deploy powerful offline-trained GenAI models to reconstruct high\nsemantic-fidelity content from degraded signals, while resource-constrained\ntransmitters are simplified in both source and channel coding design. We\npresent the core mechanisms and key design principles behind GenCom, which\nshifts from conventional approaches toward simple semantic-preserving\ncompression, weak error-distribution codes, and semantic-aware retransmissions.\nThrough a case study, GenCom is shown to deliver robust performance across a\nwide range of low and uncertain SNR/SINR conditions where conventional systems\nfail. Finally, we outline critical challenges and research directions toward\nmaking GenCom a practical enabler of future human-centric, intelligent, and\nsustainable wireless networks.", "AI": {"tldr": "GenCom\u662f\u4e00\u79cd\u5229\u7528\u751f\u6210\u5f0fAI\u89e3\u51b36G\u4e0a\u884c\u94fe\u8def\u74f6\u9888\u7684\u65b0\u7cfb\u7edf\u8303\u5f0f\uff0c\u901a\u8fc7\u7b80\u5316\u53d1\u5c04\u7aef\u8bbe\u8ba1\u5e76\u5229\u7528\u63a5\u6536\u7aef\u7684\u5f3a\u5927AI\u6a21\u578b\u91cd\u6784\u5185\u5bb9\uff0c\u63d0\u5347\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "motivation": "6G\u7f51\u7edc\u4e0a\u884c\u94fe\u8def\u9762\u4e34\u8bbe\u5907\u8d44\u6e90\u9650\u5236\u548c\u4fe1\u9053\u6761\u4ef6\u6311\u6218\uff0c\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "GenCom\u91c7\u7528\u751f\u6210\u5f0fAI\u6a21\u578b\u5728\u63a5\u6536\u7aef\u91cd\u6784\u4fe1\u53f7\uff0c\u53d1\u5c04\u7aef\u7b80\u5316\u7f16\u7801\u8bbe\u8ba1\uff0c\u652f\u6301\u8bed\u4e49\u4fdd\u7559\u538b\u7f29\u548c\u5f31\u9519\u8bef\u5206\u5e03\u7f16\u7801\u3002", "result": "GenCom\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7cfb\u7edf\u3002", "conclusion": "GenCom\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u65b9\u6848\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2508.09200", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09200", "abs": "https://arxiv.org/abs/2508.09200", "authors": ["Jinho Kim", "Marcel Dominik Nickel", "Florian Knoll"], "title": "Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction", "comment": "23 pages, 6 figures, 2 tabels", "summary": "Purpose: To investigate the feasibility of applying zero-shot self-supervised\nlearning reconstruction to reduce breath-hold times in magnetic resonance\ncholangiopancreatography (MRCP). Methods: Breath-hold MRCP was acquired from 11\nhealthy volunteers on a 3T scanner using an incoherent k-space sampling pattern\nleading to a breath-hold duration of 14s. We evaluated zero-shot reconstruction\nof breath-hold MRCP against parallel imaging of respiratory-triggered MRCP\nacquired in 338s on average and compressed sensing reconstruction of\nbreath-hold MRCP. To address the long computation times of zero-shot trainings,\nwe used a training approach that leverages a pretrained network to reduce\nbackpropagation depth during training. Results: Zero-shot learning\nreconstruction significantly improved visual image quality compared to\ncompressed sensing reconstruction, particularly in terms of signal-to-noise\nratio and ductal delineation, and reached a level of quality comparable to that\nof successful respiratory-triggered acquisitions with regular breathing\npatterns. Shallow training provided nearly equivalent reconstruction\nperformance with a training time of 11 minutes in comparison to 271 minutes for\na conventional zero-shot training. Conclusion: Zero-shot learning delivers\nhigh-fidelity MRCP reconstructions with reduced breath-hold times, and shallow\ntraining offers a practical solution for translation to time-constrained\nclinical workflows.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u96f6\u6837\u672c\u81ea\u76d1\u7763\u5b66\u4e60\u91cd\u5efa\u5728\u51cf\u5c11\u78c1\u5171\u632f\u80f0\u80c6\u7ba1\u9020\u5f71\uff08MRCP\uff09\u5c4f\u6c14\u65f6\u95f4\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u7ed3\u679c\u663e\u793a\u5176\u4f18\u4e8e\u538b\u7f29\u611f\u77e5\u91cd\u5efa\uff0c\u4e14\u6d45\u5c42\u8bad\u7ec3\u5927\u5e45\u7f29\u77ed\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u51cf\u5c11MRCP\u68c0\u67e5\u4e2d\u7684\u5c4f\u6c14\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e34\u5e8a\u6548\u7387\u3002", "method": "\u4f7f\u7528\u96f6\u6837\u672c\u91cd\u5efa\u6280\u672f\uff0c\u5bf9\u6bd4\u5e76\u884c\u6210\u50cf\u548c\u538b\u7f29\u611f\u77e5\u91cd\u5efa\uff0c\u5e76\u91c7\u7528\u6d45\u5c42\u8bad\u7ec3\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "result": "\u96f6\u6837\u672c\u91cd\u5efa\u663e\u8457\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\uff0c\u6d45\u5c42\u8bad\u7ec3\u5c06\u8bad\u7ec3\u65f6\u95f4\u4ece271\u5206\u949f\u7f29\u77ed\u81f311\u5206\u949f\u3002", "conclusion": "\u96f6\u6837\u672c\u5b66\u4e60\u80fd\u9ad8\u6548\u51cf\u5c11\u5c4f\u6c14\u65f6\u95f4\uff0c\u6d45\u5c42\u8bad\u7ec3\u9002\u5408\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2508.09374", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.09374", "abs": "https://arxiv.org/abs/2508.09374", "authors": ["Rohith Reddy Vennam", "Luke Wilson", "Ish Kumar Jain", "Dinesh Bharadia"], "title": "Satellites are closer than you think: A near field MIMO approach for Ground stations", "comment": "11 pages, 11 figures", "summary": "The rapid growth of low Earth orbit (LEO) satellite constellations has\nrevolutionized broadband access, earth observation, and direct-to-device\nconnectivity. However, the expansion of ground station infrastructure has not\nkept pace, creating a critical bottleneck in satellite-to-ground backhaul\ncapacity. Traditional parabolic dish antennas, though effective for\ngeostationary (GEO) satellites, are ill-suited for dense, fastmoving LEO\nnetworks due to mechanical steering delays and their inability to track\nmultiple satellites simultaneously. Phased array antennas offer electronically\nsteerable beams and multisatellite support, but their integration into ground\nstations is limited by the high cost, hardware issues, and complexity of\nachieving sufficient antenna gain. We introduce ArrayLink, a distributed phased\narray architecture that coherently combines multiple small commercially\navailable panels to achieve high-gain beamforming and unlock line-of-sight MIMO\nspatial multiplexing with minimal additional capital expenditure. By spacing 16\n(32x32) panels across a kilometer-scale aperture, ArrayLink enters the\nradiative near-field, focusing energy in both angle and range while supporting\nup to four simultaneous spatial streams on a single feeder link. Through\nrigorous theoretical analysis, detailed 2D beam pattern simulations and\nreal-world hardware experiments, we show that ArrayLink (i) achieves dish-class\ngain with in range 1-2 dB of 1.47 m reflector, (ii) maintains four parallel\nstreams at ranges of hundreds of kilometers (falling to two beyond 2000 km),\nand (iii) exhibits tight agreement across theory, simulation, and experiment\nwith minimal variance. These findings open a practical and scalable path to\nboosting LEO backhaul capacity.", "AI": {"tldr": "ArrayLink\u662f\u4e00\u79cd\u5206\u5e03\u5f0f\u76f8\u63a7\u9635\u67b6\u6784\uff0c\u901a\u8fc7\u7ec4\u5408\u591a\u4e2a\u5c0f\u578b\u5546\u7528\u9762\u677f\u5b9e\u73b0\u9ad8\u589e\u76ca\u6ce2\u675f\u6210\u5f62\uff0c\u63d0\u5347LEO\u536b\u661f\u56de\u4f20\u5bb9\u91cf\u3002", "motivation": "\u5730\u9762\u7ad9\u57fa\u7840\u8bbe\u65bd\u6269\u5c55\u6ede\u540e\u4e8eLEO\u536b\u661f\u661f\u5ea7\u589e\u957f\uff0c\u4f20\u7edf\u629b\u7269\u9762\u5929\u7ebf\u4e0d\u9002\u5408\u5feb\u901f\u79fb\u52a8\u7684LEO\u7f51\u7edc\uff0c\u76f8\u63a7\u9635\u5929\u7ebf\u6210\u672c\u9ad8\u4e14\u590d\u6742\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u76f8\u63a7\u9635\u67b6\u6784\uff08ArrayLink\uff09\uff0c\u901a\u8fc716\u4e2a\uff0832x32\uff09\u9762\u677f\u5728\u5343\u7c73\u7ea7\u5b54\u5f84\u4e0a\u5b9e\u73b0\u9ad8\u589e\u76ca\u6ce2\u675f\u6210\u5f62\u548c\u7a7a\u95f4\u590d\u7528\u3002", "result": "ArrayLink\u57281-2 dB\u8303\u56f4\u5185\u8fbe\u52301.47\u7c73\u53cd\u5c04\u5668\u7684\u589e\u76ca\uff0c\u652f\u6301\u6700\u591a4\u4e2a\u5e76\u884c\u7a7a\u95f4\u6d41\uff0c\u5b9e\u9a8c\u4e0e\u7406\u8bba\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "ArrayLink\u4e3a\u63d0\u5347LEO\u56de\u4f20\u5bb9\u91cf\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09205", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09205", "abs": "https://arxiv.org/abs/2508.09205", "authors": ["Yoni Schirris", "Eric Marcus", "Jonas Teuwen", "Hugo Horlings", "Efstratios Gavves"], "title": "From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations", "comment": "10 pages, 2 figures, 2 tables, submitted at MICCAI IMIMIC workshop", "summary": "Explaining deep learning models is essential for clinical integration of\nmedical image analysis systems. A good explanation highlights if a model\ndepends on spurious features that undermines generalization and harms a subset\nof patients or, conversely, may present novel biological insights. Although\ntechniques like GradCAM can identify influential features, they are measurement\ntools that do not themselves form an explanation. We propose a\nhuman-machine-VLM interaction system tailored to explaining classifiers in\ncomputational pathology, including multi-instance learning for whole-slide\nimages. Our proof of concept comprises (1) an AI-integrated slide viewer to run\nsliding-window experiments to test claims of an explanation, and (2)\nquantification of an explanation's predictiveness using general-purpose\nvision-language models. The results demonstrate that this allows us to\nqualitatively test claims of explanations and can quantifiably distinguish\ncompeting explanations. This offers a practical path from explainable AI to\nexplained AI in digital pathology and beyond. Code and prompts are available at\nhttps://github.com/nki-ai/x2x.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u673a-VLM\u4ea4\u4e92\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u91ca\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684\u5206\u7c7b\u5668\uff0c\u7ed3\u5408AI\u96c6\u6210\u7684\u5e7b\u706f\u7247\u67e5\u770b\u5668\u548c\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u9a8c\u8bc1\u89e3\u91ca\u7684\u9884\u6d4b\u6027\u3002", "motivation": "\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u533b\u5b66\u56fe\u50cf\u5206\u6790\u7cfb\u7edf\u7684\u4e34\u5e8a\u6574\u5408\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u8bc6\u522b\u6a21\u578b\u662f\u5426\u4f9d\u8d56\u865a\u5047\u7279\u5f81\u6216\u63ed\u793a\u65b0\u751f\u7269\u5b66\u89c1\u89e3\u3002", "method": "\u5f00\u53d1\u4e86AI\u96c6\u6210\u7684\u5e7b\u706f\u7247\u67e5\u770b\u5668\u8fdb\u884c\u6ed1\u52a8\u7a97\u53e3\u5b9e\u9a8c\uff0c\u5e76\u4f7f\u7528\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u89e3\u91ca\u7684\u9884\u6d4b\u6027\u3002", "result": "\u7cfb\u7edf\u80fd\u5b9a\u6027\u6d4b\u8bd5\u89e3\u91ca\u7684\u5408\u7406\u6027\uff0c\u5e76\u91cf\u5316\u533a\u5206\u7ade\u4e89\u6027\u89e3\u91ca\u3002", "conclusion": "\u4e3a\u4ece\u53ef\u89e3\u91caAI\u5230\u89e3\u91caAI\u7684\u5b9e\u8df5\u8def\u5f84\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.09545", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.09545", "abs": "https://arxiv.org/abs/2508.09545", "authors": ["Lutfi Samara", "Simon Haussmann", "Erind Tufa", "Antonio Alberto D'Amico", "Tommaso Zugno", "Ingmar Kallfass", "Thomas K\u00fcrner"], "title": "Sub-THz Power Amplifiers: Measurements, Behavioral Modeling and Predistortion Algorithms", "comment": null, "summary": "With global IMT traffic expected to grow 10-100 times from 2020 to 20301, the\nTerahertz (THz) spectrum offers a promising solution to satisfy such forecasts.\nHowever, occupying the THz spectrum comes with its own challenges, an important\none being impairments caused by broadband RF components in THz transceivers.\nNonlinearities in power amplifiers (PAs) complicate meeting link budget\nrequirements, with amplitude and phase distortions degrading the system's\nperformance, especially when adopting waveforms with high peak-to-average power\nratios (PAPRs), such as Orthogonal Frequency Division Multiplexing (OFDM). In\nthis paper, we present characterization results of a 300 GHz PA using\nsmall-signal and large-signal continuous-wave measurements. Models capturing\nAmplitude-to- Amplitude Modulation (AM-AM) and Amplitude-to-Phase Modulation\n(AMPM) behavior across 270-330 GHz are developed and verified with wideband\nmeasurements, confirming the compression behavior, while nonetheless showing\ninaccuracies for low input powers due to unaccounted frequency dependencies.\nBased on the derived models, a predistortion algorithm is designed and\nanalyzed, revealing significant error performance degradation when switching\nbetween single- and multi-carrier waveforms. We finally show that an\nappropriate selection of pre-distorter parameters can significantly improve the\nperformance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u592a\u8d6b\u5179\uff08THz\uff09\u9891\u8c31\u4e2d\u529f\u7387\u653e\u5927\u5668\uff08PA\uff09\u7684\u975e\u7ebf\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8868\u5f81\u6a21\u578b\u548c\u9884\u5931\u771f\u7b97\u6cd5\u4ee5\u6539\u5584\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5168\u7403IMT\u6d41\u91cf\u9884\u8ba1\u589e\u957f10-100\u500d\uff0c\u592a\u8d6b\u5179\u9891\u8c31\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5bbd\u5e26\u5c04\u9891\u7ec4\u4ef6\u7684\u975e\u7ebf\u6027\u95ee\u9898\uff08\u5982PA\uff09\u5f71\u54cd\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5c0f\u4fe1\u53f7\u548c\u5927\u4fe1\u53f7\u8fde\u7eed\u6ce2\u6d4b\u91cf\u8868\u5f81300 GHz PA\uff0c\u5efa\u7acbAM-AM\u548cAM-PM\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u9884\u5931\u771f\u7b97\u6cd5\u3002", "result": "\u6a21\u578b\u9a8c\u8bc1\u4e86\u538b\u7f29\u884c\u4e3a\uff0c\u4f46\u4f4e\u8f93\u5165\u529f\u7387\u4e0b\u5b58\u5728\u4e0d\u51c6\u786e\u6027\uff1b\u9884\u5931\u771f\u7b97\u6cd5\u5728\u591a\u8f7d\u6ce2\u6ce2\u5f62\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u4f46\u53c2\u6570\u4f18\u5316\u53ef\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u9002\u5f53\u7684\u9884\u5931\u771f\u53c2\u6570\u9009\u62e9\u80fd\u663e\u8457\u63d0\u5347\u592a\u8d6b\u5179\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2508.09225", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09225", "abs": "https://arxiv.org/abs/2508.09225", "authors": ["Nak-Jun Sung", "Donghyun Lee", "Bo Hwa Choi", "Chae Jung Park"], "title": "AMRG: Extend Vision Language Models for Automatic Mammography Report Generation", "comment": null, "summary": "Mammography report generation is a critical yet underexplored task in medical\nAI, characterized by challenges such as multiview image reasoning,\nhigh-resolution visual cues, and unstructured radiologic language. In this\nwork, we introduce AMRG (Automatic Mammography Report Generation), the first\nend-to-end framework for generating narrative mammography reports using large\nvision-language models (VLMs). Building upon MedGemma-4B-it-a\ndomain-specialized, instruction-tuned VLM-we employ a parameter-efficient\nfine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling\nlightweight adaptation with minimal computational overhead. We train and\nevaluate AMRG on DMID, a publicly available dataset of paired high-resolution\nmammograms and diagnostic reports. This work establishes the first reproducible\nbenchmark for mammography report generation, addressing a longstanding gap in\nmultimodal clinical AI. We systematically explore LoRA hyperparameter\nconfigurations and conduct comparative experiments across multiple VLM\nbackbones, including both domain-specific and general-purpose models under a\nunified tuning protocol. Our framework demonstrates strong performance across\nboth language generation and clinical metrics, achieving a ROUGE-L score of\n0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582.\nQualitative analysis further highlights improved diagnostic consistency and\nreduced hallucinations. AMRG offers a scalable and adaptable foundation for\nradiology report generation and paves the way for future research in multimodal\nmedical AI.", "AI": {"tldr": "AMRG\u662f\u9996\u4e2a\u7528\u4e8e\u751f\u6210\u4e73\u817aX\u5149\u62a5\u544a\u7684\u5168\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u57fa\u4e8e\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\uff0c\u901a\u8fc7LoRA\u5b9e\u73b0\u9ad8\u6548\u5fae\u8c03\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e73\u817aX\u5149\u62a5\u544a\u751f\u6210\u5728\u533b\u7597AI\u4e2d\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u4efb\u52a1\uff0c\u9762\u4e34\u591a\u89c6\u56fe\u56fe\u50cf\u63a8\u7406\u3001\u9ad8\u5206\u8fa8\u7387\u89c6\u89c9\u7ebf\u7d22\u548c\u975e\u7ed3\u6784\u5316\u653e\u5c04\u5b66\u8bed\u8a00\u7b49\u6311\u6218\u3002", "method": "\u57fa\u4e8eMedGemma-4B-it\u6a21\u578b\uff0c\u91c7\u7528LoRA\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u8bad\u7ec3\u548c\u8bc4\u4f30\u4f7f\u7528\u516c\u5f00\u6570\u636e\u96c6DMID\u3002", "result": "\u5728\u8bed\u8a00\u751f\u6210\u548c\u4e34\u5e8a\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cROUGE-L\u4e3a0.5691\uff0cMETEOR\u4e3a0.6152\uff0cCIDEr\u4e3a0.5818\uff0cBI-RADS\u51c6\u786e\u7387\u4e3a0.5582\u3002", "conclusion": "AMRG\u4e3a\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u9002\u5e94\u6027\u5f3a\u7684\u6846\u67b6\uff0c\u4e3a\u591a\u6a21\u6001\u533b\u7597AI\u7684\u672a\u6765\u7814\u7a76\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2508.09546", "categories": ["eess.SP", "cs.AR"], "pdf": "https://arxiv.org/pdf/2508.09546", "abs": "https://arxiv.org/abs/2508.09546", "authors": ["Dumitra Iancu", "Liang Liu", "Ove Edfors", "Erik Leitinger", "Xuhong Li"], "title": "Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm", "comment": "This work has been submitted to the IEEE for possible publication,\n  copyright information may be affected upon publication", "summary": "Distributed MIMO and integrated sensing and communication are expected to be\nkey technologies in future wireless systems, enabling reliable, low-latency\ncommunication and accurate localization. Dedicated localization solutions must\nsupport distributed architecture, provide scalability across different system\nconfigurations and meet strict latency requirements. We present a scalable\nmessage-passing localization method and architecture co-designed for a\npanel-based distributed MIMO system and network topology, in which\ninterconnected units operate without centralized processing. This method\njointly detects line-of-sight paths to distributed units from multipath\nmeasurements in dynamic scenarios, localizes the agent, and achieves very low\nlatency. Additionally, we introduce a cycle-accurate system latency model based\non implemented FPGA operations, and show important insights into processing\nlatency and hardware utilization and system-level trade-offs. We compare our\nmethod to a multipath-based localization method and show that it can achieve\nsimilar localization performance, with wide enough distribution of array\nelements, while offering lower latency and computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5206\u5e03\u5f0fMIMO\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6d88\u606f\u4f20\u9012\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u548c\u52a8\u6001\u573a\u666f\u4e0b\u7684\u591a\u8def\u5f84\u6d4b\u91cf\u3002", "motivation": "\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u9700\u8981\u652f\u6301\u5206\u5e03\u5f0f\u67b6\u6784\u3001\u53ef\u6269\u5c55\u6027\u548c\u4f4e\u5ef6\u8fdf\u7684\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u8054\u5408\u68c0\u6d4b\u591a\u8def\u5f84\u6d4b\u91cf\u4e2d\u7684\u89c6\u8ddd\u8def\u5f84\uff0c\u5e76\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5b9a\u4f4d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u9635\u5217\u5143\u7d20\u8db3\u591f\u5bbd\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9a\u4f4d\u6027\u80fd\u4e0e\u591a\u8def\u5f84\u5b9a\u4f4d\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u5177\u6709\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5206\u5e03\u5f0fMIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u5ef6\u8fdf\u7684\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09271", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09271", "abs": "https://arxiv.org/abs/2508.09271", "authors": ["Reihaneh Hassanzadeh", "Anees Abrol", "Hamid Reza Hassanzadeh", "Vince D. Calhoun"], "title": "A Generative Imputation Method for Multimodal Alzheimer's Disease Diagnosis", "comment": null, "summary": "Multimodal data analysis can lead to more accurate diagnoses of brain\ndisorders due to the complementary information that each modality adds.\nHowever, a major challenge of using multimodal datasets in the neuroimaging\nfield is incomplete data, where some of the modalities are missing for certain\nsubjects. Hence, effective strategies are needed for completing the data.\nTraditional methods, such as subsampling or zero-filling, may reduce the\naccuracy of predictions or introduce unintended biases. In contrast, advanced\nmethods such as generative models have emerged as promising solutions without\nthese limitations. In this study, we proposed a generative adversarial network\nmethod designed to reconstruct missing modalities from existing ones while\npreserving the disease patterns. We used T1-weighted structural magnetic\nresonance imaging and functional network connectivity as two modalities. Our\nfindings showed a 9% improvement in the classification accuracy for Alzheimer's\ndisease versus cognitive normal groups when using our generative imputation\nmethod compared to the traditional approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u73b0\u6709\u6a21\u6001\u4e2d\u91cd\u5efa\u7f3a\u5931\u7684\u795e\u7ecf\u5f71\u50cf\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\u80fd\u63d0\u9ad8\u8111\u90e8\u75be\u75c5\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u4f46\u6570\u636e\u7f3a\u5931\u662f\u4e3b\u8981\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u964d\u4f4e\u51c6\u786e\u6027\u6216\u5f15\u5165\u504f\u5dee\u3002", "method": "\u4f7f\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u4eceT1\u52a0\u6743\u7ed3\u6784MRI\u548c\u529f\u80fd\u7f51\u7edc\u8fde\u63a5\u4e2d\u91cd\u5efa\u7f3a\u5931\u6a21\u6001\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u751f\u6210\u586b\u8865\u65b9\u6cd5\u5c06\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e0e\u8ba4\u77e5\u6b63\u5e38\u7ec4\u7684\u5206\u7c7b\u51c6\u786e\u6027\u63d0\u9ad8\u4e869%\u3002", "conclusion": "\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u6a21\u6001\u6570\u636e\u586b\u8865\u65b9\u6cd5\uff0c\u80fd\u4fdd\u7559\u75be\u75c5\u6a21\u5f0f\u5e76\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09574", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.09574", "abs": "https://arxiv.org/abs/2508.09574", "authors": ["Zhiyuan Ren", "Yutao Liu", "Wenchi Cheng", "Kun Yang"], "title": "Profiling Multi-Level Operator Costs for Bottleneck Diagnosis in High-Speed Data Planes", "comment": null, "summary": "This paper proposes a saturation throughput delta-based methodology to\nprecisely measure operator costs in high-speed data planes without intrusive\ninstrumentation. The approach captures non-linear scaling, revealing that\ncompute-intensive operators like CRC exhibit super-linear behavior, while most\nothers are sub-linear. We introduce the Operator Performance Quadrant (OPQ)\nframework to classify operators by base and scaling costs, exposing a\ncross-architecture Quadrant Shift between Arm and x86. This method provides\naccurate, architecture-aware bottleneck diagnosis and a realistic basis for\nperformance modeling and optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9971\u548c\u541e\u5410\u91cf\u589e\u91cf\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u7cbe\u786e\u6d4b\u91cf\u9ad8\u901f\u6570\u636e\u5e73\u9762\u4e2d\u7684\u7b97\u5b50\u6210\u672c\uff0c\u65e0\u9700\u4fb5\u5165\u5f0f\u68c0\u6d4b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u7cbe\u786e\u6d4b\u91cf\u9ad8\u901f\u6570\u636e\u5e73\u9762\u4e2d\u7684\u7b97\u5b50\u6210\u672c\uff0c\u4e14\u65e0\u6cd5\u6355\u6349\u975e\u7ebf\u6027\u6269\u5c55\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u9971\u548c\u541e\u5410\u91cf\u589e\u91cf\u65b9\u6cd5\uff0c\u5f15\u5165\u7b97\u5b50\u6027\u80fd\u8c61\u9650\uff08OPQ\uff09\u6846\u67b6\uff0c\u5206\u7c7b\u7b97\u5b50\u7684\u57fa\u7840\u548c\u6269\u5c55\u6210\u672c\u3002", "result": "\u53d1\u73b0\u8ba1\u7b97\u5bc6\u96c6\u578b\u7b97\u5b50\uff08\u5982CRC\uff09\u8868\u73b0\u51fa\u8d85\u7ebf\u6027\u884c\u4e3a\uff0c\u800c\u5927\u591a\u6570\u5176\u4ed6\u7b97\u5b50\u4e3a\u6b21\u7ebf\u6027\u3002\u540c\u65f6\u63ed\u793a\u4e86Arm\u548cx86\u67b6\u6784\u95f4\u7684\u8c61\u9650\u504f\u79fb\u73b0\u8c61\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6027\u80fd\u5efa\u6a21\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u51c6\u786e\u3001\u67b6\u6784\u611f\u77e5\u7684\u74f6\u9888\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2508.09328", "categories": ["eess.IV", "cs.CV", "stat.AP", "stat.OT"], "pdf": "https://arxiv.org/pdf/2508.09328", "abs": "https://arxiv.org/abs/2508.09328", "authors": ["Bingfan Liu", "Haolun Shi", "Jiguo Cao"], "title": "Dynamic Survival Prediction using Longitudinal Images based on Transformer", "comment": null, "summary": "Survival analysis utilizing multiple longitudinal medical images plays a\npivotal role in the early detection and prognosis of diseases by providing\ninsight beyond single-image evaluations. However, current methodologies often\ninadequately utilize censored data, overlook correlations among longitudinal\nimages measured over multiple time points, and lack interpretability. We\nintroduce SurLonFormer, a novel Transformer-based neural network that\nintegrates longitudinal medical imaging with structured data for survival\nprediction. Our architecture comprises three key components: a Vision Encoder\nfor extracting spatial features, a Sequence Encoder for aggregating temporal\ninformation, and a Survival Encoder based on the Cox proportional hazards\nmodel. This framework effectively incorporates censored data, addresses\nscalability issues, and enhances interpretability through occlusion sensitivity\nanalysis and dynamic survival prediction. Extensive simulations and a\nreal-world application in Alzheimer's disease analysis demonstrate that\nSurLonFormer achieves superior predictive performance and successfully\nidentifies disease-related imaging biomarkers.", "AI": {"tldr": "SurLonFormer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u6574\u5408\u7eb5\u5411\u533b\u5b66\u5f71\u50cf\u548c\u7ed3\u6784\u5316\u6570\u636e\u4ee5\u9884\u6d4b\u751f\u5b58\u7387\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u622a\u5c3e\u6570\u636e\u3001\u65f6\u95f4\u76f8\u5173\u6027\u53ca\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u622a\u5c3e\u6570\u636e\u3001\u5904\u7406\u7eb5\u5411\u5f71\u50cf\u7684\u65f6\u95f4\u76f8\u5173\u6027\u53ca\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u751f\u5b58\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faSurLonFormer\uff0c\u5305\u542b\u89c6\u89c9\u7f16\u7801\u5668\uff08\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff09\u3001\u5e8f\u5217\u7f16\u7801\u5668\uff08\u805a\u5408\u65f6\u95f4\u4fe1\u606f\uff09\u548c\u57fa\u4e8eCox\u6a21\u578b\u7684\u751f\u5b58\u7f16\u7801\u5668\uff0c\u7ed3\u5408\u622a\u5c3e\u6570\u636e\u5e76\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u6a21\u62df\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cSurLonFormer\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u75be\u75c5\u76f8\u5173\u5f71\u50cf\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "SurLonFormer\u4e3a\u751f\u5b58\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u7eb5\u5411\u533b\u5b66\u5f71\u50cf\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2508.09708", "categories": ["eess.SP", "cs.NI", "C.2.1; C.2.2; C.2.4"], "pdf": "https://arxiv.org/pdf/2508.09708", "abs": "https://arxiv.org/abs/2508.09708", "authors": ["Thomas Fehrenbach", "Luis Omar Ortiz Abrego", "Cornelius Hellge", "Thomas Schierl", "J\u00f6rg Ott"], "title": "3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator", "comment": "7 pages, 10 figures, 2 tables, V2X communication, vehicular networks,\n  platooning simulation", "summary": "Vehicle-to-everything (V2X) communication is a key technology for enabling\nintelligent transportation systems (ITS) that can improve road safety, traffic\nefficiency, and environmental sustainability. Among the various V2X\napplications, platooning is one of the most promising ones, as it allows a\ngroup of vehicles to travel closely together at high speeds, reducing fuel\nconsumption and emissions. However, it poses significant challenges for\nwireless communication, such as high reliability and low latency. In this\npaper, we evaluate the benefits of group scheduling, also referred to as Mode\n2d, which is based on a distributed and scheduled resource allocation scheme\nthat allows the group of cars to select resources from a configured pool\nwithout network assistance. We evaluated the scheme through simulations, and\nthe results show that this approach can meet the reliability, low latency, and\ndata rate requirements for platooning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86V2X\u901a\u4fe1\u4e2d\u7684\u8f66\u961f\u8c03\u5ea6\uff08Mode 2d\uff09\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u8d44\u6e90\u5206\u914d\u63d0\u5347\u8f66\u961f\u901a\u4fe1\u7684\u53ef\u9760\u6027\u3001\u4f4e\u5ef6\u8fdf\u548c\u6570\u636e\u901f\u7387\u3002", "motivation": "\u8f66\u961f\u6280\u672f\u80fd\u63d0\u5347\u4ea4\u901a\u6548\u7387\u548c\u73af\u4fdd\u6027\uff0c\u4f46\u65e0\u7ebf\u901a\u4fe1\u7684\u9ad8\u53ef\u9760\u6027\u548c\u4f4e\u5ef6\u8fdf\u9700\u6c42\u662f\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u8c03\u5ea6\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff08Mode 2d\uff09\uff0c\u8f66\u961f\u4ece\u914d\u7f6e\u7684\u8d44\u6e90\u6c60\u4e2d\u81ea\u4e3b\u9009\u62e9\u8d44\u6e90\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u80fd\u6ee1\u8db3\u8f66\u961f\u901a\u4fe1\u7684\u53ef\u9760\u6027\u3001\u4f4e\u5ef6\u8fdf\u548c\u6570\u636e\u901f\u7387\u9700\u6c42\u3002", "conclusion": "Mode 2d\u65b9\u6848\u662f\u89e3\u51b3\u8f66\u961f\u901a\u4fe1\u6311\u6218\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.09919", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09919", "abs": "https://arxiv.org/abs/2508.09919", "authors": ["Xiaojiao Xiao", "Jianfeng Zhao", "Qinmin Vivian Hu", "Guanghui Wang"], "title": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis", "comment": "IEEE Journal of Biomedical and Health Informatics, 2025", "summary": "Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of\nliver cancer, significantly improving the classification of the lesion and\npatient outcomes. However, traditional MRI faces challenges including risks\nfrom contrast agent (CA) administration, time-consuming manual assessment, and\nlimited annotated datasets. To address these limitations, we propose a\nTime-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for\nsynthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from\nnon-contrast MRI (NCMRI). T-CACE introduces three core innovations: a\nconditional token encoding (CTE) mechanism that unifies anatomical priors and\ntemporal phase information into latent representations; and a dynamic\ntime-aware attention mask (DTAM) that adaptively modulates inter-phase\ninformation flow using a Gaussian-decayed attention mechanism, ensuring smooth\nand physiologically plausible transitions across phases. Furthermore, a\nconstraint for temporal classification consistency (TCC) aligns the lesion\nclassification output with the evolution of the physiological signal, further\nenhancing diagnostic reliability. Extensive experiments on two independent\nliver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods\nin image synthesis, segmentation, and lesion classification. This framework\noffers a clinically relevant and efficient alternative to traditional\ncontrast-enhanced imaging, improving safety, diagnostic efficiency, and\nreliability for the assessment of liver lesion. The implementation of T-CACE is\npublicly available at: https://github.com/xiaojiao929/T-CACE.", "AI": {"tldr": "T-CACE\u6846\u67b6\u901a\u8fc7\u5408\u6210\u591a\u671f\u76f8\u589e\u5f3aMRI\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMRI\u7684\u5bf9\u6bd4\u5242\u98ce\u9669\u3001\u8017\u65f6\u8bc4\u4f30\u548c\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u809d\u810f\u75c5\u53d8\u7684\u8bca\u65ad\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edfMRI\u5728\u809d\u810f\u764c\u75c7\u8bca\u65ad\u4e2d\u5b58\u5728\u5bf9\u6bd4\u5242\u98ce\u9669\u3001\u624b\u52a8\u8bc4\u4f30\u8017\u65f6\u548c\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faT-CACE\u6846\u67b6\uff0c\u5305\u62ec\u6761\u4ef6\u4ee4\u724c\u7f16\u7801\uff08CTE\uff09\u3001\u52a8\u6001\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u529b\u63a9\u7801\uff08DTAM\uff09\u548c\u65f6\u95f4\u5206\u7c7b\u4e00\u81f4\u6027\u7ea6\u675f\uff08TCC\uff09\uff0c\u7528\u4e8e\u4ece\u975e\u5bf9\u6bd4MRI\u5408\u6210\u591a\u671f\u76f8\u589e\u5f3aMRI\u3002", "result": "\u5728\u4e24\u4e2a\u72ec\u7acb\u809d\u810fMRI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cT-CACE\u5728\u56fe\u50cf\u5408\u6210\u3001\u5206\u5272\u548c\u75c5\u53d8\u5206\u7c7b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "T-CACE\u4e3a\u4f20\u7edf\u589e\u5f3a\u6210\u50cf\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e34\u5e8a\u76f8\u5173\u4e14\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u809d\u810f\u75c5\u53d8\u8bc4\u4f30\u7684\u5b89\u5168\u6027\u3001\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09727", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.09727", "abs": "https://arxiv.org/abs/2508.09727", "authors": ["Jinhui Hu", "Haiquan Zhao", "Yi Peng"], "title": "CKFNet: Neural Network Aided Cubature Kalman filtering", "comment": null, "summary": "The cubature Kalman filter (CKF), while theoretically rigorous for nonlinear\nestimation, often suffers performance degradation due to model-environment\nmismatches in practice. To address this limitation, we propose CKFNet-a hybrid\narchitecture that synergistically integrates recurrent neural networks (RNN)\nwith the CKF framework while preserving its cubature principles. Unlike\nconventional model-driven approaches, CKFNet embeds RNN modules in the\nprediction phase to dynamically adapt to unmodeled uncertainties, effectively\nreducing cumulative error propagation through temporal noise correlation\nlearning. Crucially, the architecture maintains CKF's analytical\ninterpretability via constrained optimization of cubature point distributions.\nNumerical simulation experiments have confirmed that our proposed CKFNet\nexhibits superior accuracy and robustness compared to conventional model-based\nmethods and existing KalmanNet algorithms.", "AI": {"tldr": "CKFNet\u901a\u8fc7\u7ed3\u5408RNN\u4e0eCKF\u6846\u67b6\uff0c\u52a8\u6001\u9002\u5e94\u672a\u5efa\u6a21\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u4e86\u975e\u7ebf\u6027\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3CKF\u56e0\u6a21\u578b\u4e0e\u73af\u5883\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u5728CKF\u7684\u9884\u6d4b\u9636\u6bb5\u5d4c\u5165RNN\u6a21\u5757\uff0c\u901a\u8fc7\u65f6\u95f4\u566a\u58f0\u76f8\u5173\u6027\u5b66\u4e60\u51cf\u5c11\u7d2f\u79ef\u8bef\u5dee\u4f20\u64ad\u3002", "result": "CKFNet\u5728\u6570\u503c\u6a21\u62df\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u6bd4\u4f20\u7edf\u6a21\u578b\u65b9\u6cd5\u548c\u73b0\u6709KalmanNet\u7b97\u6cd5\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "CKFNet\u6210\u529f\u7ed3\u5408\u4e86\u6a21\u578b\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86CKF\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.09751", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.09751", "abs": "https://arxiv.org/abs/2508.09751", "authors": ["Sungyoung Ha", "Ikbeom Lee", "Seunghyeon Jeon", "Yo-Seb Jeon"], "title": "Online Data Generation for MIMO-OFDM Channel Denoising: Transfer Learning vs. Meta Learning", "comment": null, "summary": "Channel denoising is a practical and effective technique for mitigating\nchannel estimation errors in multiple-input multiple-output orthogonal\nfrequency-division multiplexing (MIMO-OFDM) systems. However, adapting\ndenoising techniques to varying channel conditions typically requires prior\nknowledge or incurs significant training overhead. To address these challenges,\nwe propose a standard-compatible strategy for generating online training data\nthat enables online adaptive channel denoising. The key idea is to leverage\nhigh-quality channel estimates obtained via data-aided channel estimation as\npractical substitutes for unavailable ground-truth channels. Our data-aided\nmethod exploits adjacent detected data symbols within a specific time-frequency\nneighborhood as virtual reference signals, and we analytically derive the\noptimal size of this neighborhood to minimize the mean squared error of the\nresulting estimates. By leveraging the proposed strategy, we devise two channel\ndenoising approaches, one based on transfer learning, which fine-tunes a\npre-trained denoising neural network, and the other based on meta learning,\nwhich rapidly adapts to new channel environments with minimal updates.\nSimulation results demonstrate that the proposed methods effectively adapt to\ndynamic channel conditions and significantly reduce channel estimation errors\ncompared to conventional techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6807\u51c6\u517c\u5bb9\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u5728\u7ebf\u751f\u6210\u8bad\u7ec3\u6570\u636e\u5b9e\u73b0\u81ea\u9002\u5e94\u4fe1\u9053\u53bb\u566a\uff0c\u5229\u7528\u6570\u636e\u8f85\u52a9\u4fe1\u9053\u4f30\u8ba1\u66ff\u4ee3\u771f\u5b9e\u4fe1\u9053\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\u548c\u5143\u5b66\u4e60\u7684\u4e24\u79cd\u53bb\u566a\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4fe1\u9053\u53bb\u566a\u6280\u672f\u9700\u8981\u5148\u9a8c\u77e5\u8bc6\u6216\u9ad8\u8bad\u7ec3\u5f00\u9500\u7684\u95ee\u9898\uff0c\u9002\u5e94\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u3002", "method": "\u5229\u7528\u6570\u636e\u8f85\u52a9\u4fe1\u9053\u4f30\u8ba1\u751f\u6210\u9ad8\u8d28\u91cf\u4fe1\u9053\u4f30\u8ba1\u4f5c\u4e3a\u66ff\u4ee3\u771f\u5b9e\u4fe1\u9053\uff0c\u63a8\u5bfc\u6700\u4f18\u90bb\u57df\u5927\u5c0f\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\u548c\u5143\u5b66\u4e60\u7684\u53bb\u566a\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u9002\u5e94\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\uff0c\u663e\u8457\u964d\u4f4e\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b56\u7565\u548c\u65b9\u6cd5\u5728\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\u3002"}}
{"id": "2508.09882", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.09882", "abs": "https://arxiv.org/abs/2508.09882", "authors": ["Umair Ali Khan", "Lester Ho", "Holger Claussen", "Chinmoy Kundu"], "title": "Location Privacy-Enabled Beamforming in ISAC Scenarios", "comment": "This paper has been submitted to IEEE Globecom Workshops 2025 and is\n  currently under review", "summary": "Integrated sensing and communication (ISAC) technology enables simultaneous\nenvironmental perception and data transmission in wireless networks; however,\nit also exposes user location to receivers. In this paper, we introduce a novel\nbeamforming framework guided by the proposed privacy metric direction of\narrival obfuscation ratio (DAOR) to protect transmitter location privacy in\nISAC scenarios. Unlike previous approaches, we do not suppress the\nline-of-sight (LOS) component while reshaping the angular power distribution so\nthat a false direction appears dominant at the receiver. We derive closed-form\nbounds on the feasible DAOR via generalized eigenvalue analysis and formulate\nan achievable rate-maximization problem under the DAOR constraint. The\nresulting problem is non-convex, which is efficiently solved using semidefinite\nrelaxation, eigenmode selection, and optimal power allocation. A suboptimal\ndesign strategy is also proposed with reduced complexity. Numerical results\ndemonstrate that the proposed DAOR-based beamformer achieves a trade-off\nbetween location privacy and communication rate without nullifying the LOS\npath. Results also show that a suboptimal design achieves a near-optimal\ncommunication rate with nearly an 85% reduction in computation time at a\nsignal-to-noise ratio (SNR) of 10 dB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b9\u5411\u5230\u8fbe\u6df7\u6dc6\u6bd4\uff08DAOR\uff09\u7684\u6ce2\u675f\u6210\u5f62\u6846\u67b6\uff0c\u7528\u4e8e\u4fdd\u62a4ISAC\u573a\u666f\u4e2d\u7684\u53d1\u5c04\u673a\u4f4d\u7f6e\u9690\u79c1\uff0c\u540c\u65f6\u4f18\u5316\u901a\u4fe1\u901f\u7387\u3002", "motivation": "ISAC\u6280\u672f\u5728\u5b9e\u73b0\u73af\u5883\u611f\u77e5\u548c\u6570\u636e\u4f20\u8f93\u7684\u540c\u65f6\u66b4\u9732\u7528\u6237\u4f4d\u7f6e\uff0c\u9700\u8981\u4fdd\u62a4\u9690\u79c1\u3002", "method": "\u901a\u8fc7\u5e7f\u4e49\u7279\u5f81\u503c\u5206\u6790\u63a8\u5bfcDAOR\u7684\u95ed\u5f0f\u8fb9\u754c\uff0c\u5e76\u5728DAOR\u7ea6\u675f\u4e0b\u63d0\u51fa\u901f\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u91c7\u7528\u534a\u5b9a\u677e\u5f1b\u3001\u7279\u5f81\u6a21\u5f0f\u9009\u62e9\u548c\u6700\u4f18\u529f\u7387\u5206\u914d\u6c42\u89e3\u3002", "result": "\u63d0\u51fa\u7684DAOR\u6ce2\u675f\u6210\u5f62\u5728\u9690\u79c1\u548c\u901a\u4fe1\u901f\u7387\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u6b21\u4f18\u8bbe\u8ba1\u572810 dB SNR\u4e0b\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1185%\u3002", "conclusion": "DAOR\u6846\u67b6\u6709\u6548\u4fdd\u62a4\u9690\u79c1\u4e14\u4e0d\u6291\u5236LOS\u8def\u5f84\uff0c\u6b21\u4f18\u8bbe\u8ba1\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2508.09942", "categories": ["eess.SP", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2508.09942", "abs": "https://arxiv.org/abs/2508.09942", "authors": ["Vaibhav Choudhary", "Akshay Agarwal", "Vivek K Goyal"], "title": "Beam Cross Sections Create Mixtures: Improving Feature Localization in Secondary Electron Imaging", "comment": "13 pages, 8 figures", "summary": "Secondary electron (SE) imaging techniques, such as scanning electron\nmicroscopy and helium ion microscopy (HIM), use electrons emitted by a sample\nin response to a focused beam of charged particles incident at a grid of raster\nscan positions. Spot size -- the diameter of the incident beam's spatial\nprofile -- is one of the limiting factors for resolution, along with various\nsources of noise in the SE signal. The effect of the beam spatial profile is\ncommonly understood as convolutional. We show that under a simple and plausible\nphysical abstraction for the beam, though convolution describes the mean of the\nSE counts, the full distribution of SE counts is a mixture. We demonstrate that\nthis more detailed modeling can enable resolution improvements over\nconventional estimators through a stylized application in semiconductor\ninspection of localizing the edge in a two-valued sample. We derive Fisher\ninformation about edge location in conventional and time-resolved measurements\n(TRM) and also derive the maximum likelihood estimate (MLE) from the latter.\nEmpirically, the MLE computed from TRM is approximately efficient except at\nvery low beam diameter, so Fisher information comparisons are predictive of\nperformance and can be used to optimize the beam diameter relative to the\nraster scan spacing. Monte Carlo simulations show that the MLE gives a 5-fold\nreduction in root mean-squared error (RMSE) of edge localization as compared to\nconventional interpolation-based estimation. Applied to three real HIM\ndatasets, the average RMSE reduction factor is 5.4.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u5206\u5e03\u7684\u4e8c\u6b21\u7535\u5b50\uff08SE\uff09\u8ba1\u6570\u6a21\u578b\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u5377\u79ef\u6a21\u578b\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u63cf\u8ff0SE\u4fe1\u53f7\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u5206\u8fa8\u6d4b\u91cf\uff08TRM\uff09\u548c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u663e\u8457\u63d0\u9ad8\u4e86\u534a\u5bfc\u4f53\u8fb9\u7f18\u5b9a\u4f4d\u7684\u5206\u8fa8\u7387\u3002", "motivation": "\u4f20\u7edf\u5377\u79ef\u6a21\u578b\u4ec5\u63cf\u8ff0SE\u8ba1\u6570\u7684\u5747\u503c\uff0c\u65e0\u6cd5\u5b8c\u5168\u6355\u6349SE\u4fe1\u53f7\u7684\u5206\u5e03\u7279\u6027\uff0c\u9650\u5236\u4e86\u6210\u50cf\u5206\u8fa8\u7387\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5206\u5e03\u6a21\u578b\uff0c\u63a8\u5bfc\u4e86TRM\u4e0b\u7684Fisher\u4fe1\u606f\u548cMLE\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u548c\u5b9e\u9645HIM\u6570\u636e\u96c6\u9a8c\u8bc1\u3002", "result": "MLE\u5728TRM\u4e0b\u5b9e\u73b0\u4e865\u500dRMSE\u964d\u4f4e\uff0c\u5b9e\u9645\u6570\u636e\u4e2d\u5e73\u5747\u964d\u4f4e5.4\u500d\u3002", "conclusion": "\u6df7\u5408\u5206\u5e03\u6a21\u578b\u548cTRM\u7ed3\u5408\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u5b9a\u4f4d\u5206\u8fa8\u7387\uff0cFisher\u4fe1\u606f\u53ef\u7528\u4e8e\u4f18\u5316\u5149\u675f\u76f4\u5f84\u3002"}}
