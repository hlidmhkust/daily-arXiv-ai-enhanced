<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 10]
- [eess.SP](#eess.SP) [Total: 18]
- [eess.IV](#eess.IV) [Total: 7]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge Low-Rank Matrices? Yes, $MAM^*$!](https://arxiv.org/abs/2507.17036)
*Edem Boahen,Simone Brugiapaglia,Hung-Hsu Chou,Mark Iwen,Felix Krahmer*

Main category: cs.IT

TL;DR: 本文提出了一种基于压缩感知的单次扫描算法，能够高效地近似超大规模矩阵的稀疏主特征向量，内存占用量仅与目标稀疏特征向量大小相关，运行时间亚线性于原矩阵大小。


<details>
  <summary>Details</summary>
Motivation: 针对稀疏主成分分析等应用场景，需要处理过于庞大而无法完全存储在内存中的矩阵的主特征向量近似问题，传统方法在内存和计算效率上存在瓶颈。

Method: 基于压缩感知理论，设计了单次线性草图（linear sketch）的算法框架，通过紧凑的线性测量来捕获矩阵的关键信息，然后利用压缩感知恢复算法从这些测量中重构稀疏的主特征向量近似。

Result: 算法具有可证明的准确性保证，内存占用量与目标稀疏特征向量的大小成正比（而非原矩阵大小），运行时间主要取决于所求稀疏近似的大小，实现了相对于大矩阵尺寸的亚线性时间复杂度。在具有约10^16个元素的超大矩阵上的初步实验验证了理论结果。

Conclusion: 提出的压缩感知方法为处理超大规模矩阵的稀疏主特征向量问题提供了一个内存高效且计算可扩展的解决方案，在理论保证和实际应用潜力方面都表现出色。

Abstract: Motivated by applications such as sparse PCA, in this paper we present
provably-accurate one-pass algorithms for the sparse approximation of the top
eigenvectors of extremely massive matrices based on a single compact linear
sketch. The resulting compressive-sensing-based approaches can approximate the
leading eigenvectors of huge approximately low-rank matrices that are too large
to store in memory based on a single pass over its entries while utilizing a
total memory footprint on the order of the much smaller desired sparse
eigenvector approximations. Finally, the compressive sensing recovery algorithm
itself (which takes the gathered compressive matrix measurements as input, and
then outputs sparse approximations of its top eigenvectors) can also be
formulated to run in a time which principally depends on the size of the sought
sparse approximations, making its runtime sublinear in the size of the large
matrix whose eigenvectors one aims to approximate. Preliminary experiments on
huge matrices having $\sim 10^{16}$ entries illustrate the developed theory and
demonstrate the practical potential of the proposed approach.

</details>


### [2] [Secure Wireless Communication via Polarforming](https://arxiv.org/abs/2507.17129)
*Jingze Ding,Zijian Zhou,Bingli Jiao,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于极化可重构天线的极化成形技术，通过联合优化发射波束成形和极化成形来最大化无线通信系统的保密速率，相比传统固定极化天线系统显著提升了安全性能。


<details>
  <summary>Details</summary>
Motivation: 在电磁波传播过程中经常遇到去极化效应，需要动态调整天线极化来缓解这一问题。同时，在存在窃听者的安全无线通信系统中，需要利用极化自由度来增强通信安全性。

Method: 提出了一种高效的迭代算法来联合优化发射波束成形和极化成形。波束成形利用空间自由度将发射波束指向合法用户，而极化成形利用极化自由度使用户接收到的电磁波极化状态与其天线极化状态对齐。

Result: 仿真结果表明，与传统的固定极化天线系统相比，极化成形技术能够充分利用天线极化优化中的自由度，显著提升无线通信系统的安全性能。

Conclusion: 极化成形技术通过动态调整天线极化，结合波束成形和极化成形的联合优化，能够有效提升安全无线通信系统的保密速率和整体安全性能。

Abstract: Polarforming is a promising technique that enables dynamic adjustment of
antenna polarization to mitigate depolarization effects commonly encountered
during electromagnetic (EM) wave propagation. In this letter, we investigate
the polarforming design for secure wireless communication systems, where the
base station (BS) is equipped with polarization-reconfigurable antennas (PRAs)
and can flexibly adjust the antenna polarization to transmit confidential
information to a legitimate user in the presence of an eavesdropper. To
maximize the achievable secrecy rate, we propose an efficient iterative
algorithm to jointly optimize transmit beamforming and polarforming, where
beamforming exploits spatial degrees of freedom (DoFs) to steer the transmit
beam toward the user, while polarforming leverages polarization DoFs to align
the polarization state of the EM wave received by the user with that of its
antenna. Simulation results demonstrate that, compared to conventional
fixed-polarization antenna (FPA) systems, polarforming can fully exploit the
DoFs in antenna polarization optimization to significantly enhance the security
performance of wireless communication systems.

</details>


### [3] [Construction of Self-Orthogonal Quasi-Cyclic Codes and Their Application to Quantum Error-Correcting Codes](https://arxiv.org/abs/2507.17319)
*Mengying Gao,Yuhua Sun,Tongjiang Yan,Chun'e Zhao*

Main category: cs.IT

TL;DR: 本文研究了t-生成元准循环码的自正交性条件，并基于此构造了具有良好参数的量子稳定子码和量子同步码


<details>
  <summary>Details</summary>
Motivation: 为了系统地研究准循环码在不同内积下的自正交性质，特别是2-生成元准循环码的对偶包含条件，以便构造具有良好参数的量子码

Method: 通过分析t-生成元准循环码在欧几里得、厄米特和辛内积下的结构特性，研究一类2-生成元准循环码的对偶码结构，推导出这些码成为对偶包含码的充分必要条件

Result: 得到了t-生成元准循环码在三种内积下自正交的充分必要条件，推导出2-生成元准循环码对偶包含的充分必要条件，构造了多个具有良好参数的量子稳定子码和量子同步码

Conclusion: 建立了准循环码自正交性的完整理论框架，成功构造的量子码中有些与Grassl码表中的最佳已知码具有相同参数，证明了该方法的有效性

Abstract: In this paper, necessary and sufficient conditions for the self-orthogonality
of t-generator quasi-cyclic (QC) codes are presented under the Euclidean,
Hermitian, and symplectic inner products, respectively. Particularly, by
studying the structure of the dual codes of a class of 2-generator QC codes, we
derive necessary and sufficient conditions for the QC codes to be
dual-containing under the above three inner products. This class of 2-generator
QC codes generalizes many known codes in the literature. Based on the above
conditions, we construct several quantum stabilizer codes and quantum
synchronizable codes with good parameters, some of which share parameters with
certain best-known codes listed in Grassl's code table.

</details>


### [4] [On Distributionally Robust Lossy Source Coding](https://arxiv.org/abs/2507.17366)
*Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.IT

TL;DR: 本文研究分布鲁棒信源编码问题，提出强函数表示引理的两个扩展，针对有限分布集合和KL散度球的情况，导出了单次和渐近情况下的鲁棒编码方案，并提出了计算鲁棒率失真函数的新算法。


<details>
  <summary>Details</summary>
Motivation: 现有信源编码方法假设源分布已知且固定，但实际应用中源分布往往存在不确定性。因此需要研究在源分布不确定情况下的分布鲁棒信源编码问题，以提高编码方案的鲁棒性和实用性。

Method: 提出强函数表示引理(SFRL)的两个扩展：一是考虑边际分布属于有限分布集合的情况，二是考虑边际分布属于以固定名义分布为中心的KL散度球的情况。基于这些扩展，导出单次和渐近情况下的分布鲁棒编码方案，并针对KL散度球情况提出计算鲁棒率失真函数的新算法。

Result: 成功将现有文献结果推广到更一般的分布鲁棒设置，得到了KL散度球情况下鲁棒率失真函数达到点的隐式特征化，实现了计算鲁棒率失真函数的新算法，并给出了伯努利源的鲁棒率失真函数解析表达式作为理论基准。

Conclusion: 本文成功解决了分布鲁棒信源编码的理论和计算问题，提出的强函数表示引理扩展为处理分布不确定性提供了有效工具，新算法能够有效计算鲁棒率失真函数，伯努利源的解析结果为算法性能评估提供了理论基准。

Abstract: In this paper, we investigate the problem of distributionally robust source
coding, i.e., source coding under uncertainty in the source distribution,
discussing both the coding and computational aspects of the problem. We propose
two extensions of the so-called Strong Functional Representation Lemma (SFRL),
considering the cases where, for a fixed conditional distribution, the marginal
inducing the joint coupling belongs to either a finite set of distributions or
a Kullback-Leibler divergence sphere (KL-Sphere) centered at a fixed nominal
distribution. Using these extensions, we derive distributionally robust coding
schemes for both the one-shot and asymptotic regimes, generalizing previous
results in the literature. Focusing on the case where the source distribution
belongs to a given KL-Sphere, we derive an implicit characterization of the
points attaining the robust rate-distortion function (R-RDF), which we later
exploit to implement a novel algorithm for computing the R-RDF. Finally, we
characterize the analytical expression of the R-RDF for Bernoulli sources,
providing a theoretical benchmark to evaluate the estimation performance of the
proposed algorithm.

</details>


### [5] [Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning](https://arxiv.org/abs/2507.17426)
*Jaiprakash Nagar,Zheng Chen,Marios Kountouris,Photios A. Stavrou*

Main category: cs.IT

TL;DR: 本文提出了一种基于信息熵的重要性度量方法，用于资源受限网络中的分布式随机梯度下降算法的节点和链路调度，在通信预算较低时相比现有方法实现了更快的收敛速度


<details>
  <summary>Details</summary>
Motivation: 在资源受限的网络环境中，分布式随机梯度下降算法面临通信效率低下的问题，需要在有限的通信成本约束下优化节点和链路的调度策略以提高算法性能

Method: 提出了基于信息熵的新颖重要性度量方法来确定节点和链路调度概率，在每次迭代中只激活少数不相交的节点子集或链路子集，同时满足给定的通信成本约束

Result: 通过大量仿真验证，在节点调度方面相比基于介数中心性的方法实现了一致的性能提升，在较低通信预算下收敛速度提高了60%；在较高通信预算下保持相当或更优的性能；在链路调度方面相比MATCHA方法取得了优于或相当的结果

Conclusion: 基于信息熵的重要性度量方法能够有效提升分布式随机梯度下降算法在资源受限网络中的通信效率，特别是在低通信预算场景下表现突出，为分布式机器学习中的通信优化提供了新的解决方案

Abstract: This paper addresses decentralized stochastic gradient descent (D-SGD) over
resource-constrained networks by introducing node-based and link-based
scheduling strategies to enhance communication efficiency. In each iteration of
the D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly
activated, subject to a given communication cost constraint. We propose a novel
importance metric based on information entropy to determine node and link
scheduling probabilities. We validate the effectiveness of our approach through
extensive simulations, comparing it against state-of-the-art methods, including
betweenness centrality (BC) for node scheduling and \textit{MATCHA} for link
scheduling. The results show that our method consistently outperforms the
BC-based method in the node scheduling case, achieving faster convergence with
up to 60\% lower communication budgets. At higher communication budgets (above
60\%), our method maintains comparable or superior performance. In the link
scheduling case, our method delivers results that are superior to or on par
with those of \textit{MATCHA}.

</details>


### [6] [Learning to Write on Dirty Paper](https://arxiv.org/abs/2507.17427)
*Ezgi Ozyilkan,Oğuzhan Kubilay Ülger,Elza Erkip*

Main category: cs.IT

TL;DR: 本文提出了一种基于神经网络的脏纸编码方案，无需先验知识即可实现有效的干扰预消除，在多种场景下超越了传统的THP和格基预编码方法。


<details>
  <summary>Details</summary>
Motivation: 虽然脏纸编码(DPC)在信息论中具有重要理论意义，但现有的实用方案如THP或格基方案往往依赖于对输入、状态和信道的特定建模假设。现代学习方法可能为DPC问题提供互补的解决路径。

Method: 提出了一种数据驱动的解决方案，其中编码器和解码器都由神经网络参数化。该模型无需状态（干扰）、信道或输入统计的先验知识，能够恢复产生有效干扰预消除的非线性映射。

Result: 这是首个可解释的概念验证，证明基于学习的DPC方案能够恢复传统解决方案（如THP和格基预编码）的特征性特点，并在多种场景下超越它们的性能。

Conclusion: 基于神经网络的学习方法为脏纸编码问题提供了一种有效的新途径，能够在不依赖先验假设的情况下实现优异性能，为实际DPC应用开辟了新的可能性。

Abstract: Dirty paper coding (DPC) is a classical problem in information theory that
considers communication in the presence of channel state known only at the
transmitter. While the theoretical impact of DPC has been substantial,
practical realizations of DPC, such as Tomlinson-Harashima precoding (THP) or
lattice-based schemes, often rely on specific modeling assumptions about the
input, state and channel. In this work, we explore whether modern
learning-based approaches can offer a complementary path forward by revisiting
the DPC problem. We propose a data-driven solution in which both the encoder
and decoder are parameterized by neural networks. Our proposed model operates
without prior knowledge of the state (also referred to as "interference"),
channel or input statistics, and recovers nonlinear mappings that yield
effective interference pre-cancellation. To the best of our knowledge, this is
the first interpretable proof-of-concept demonstrating that learning-based DPC
schemes can recover characteristic features of well-established solutions, such
as THP and lattice-based precoding, and outperform them in several regimes.

</details>


### [7] [Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding](https://arxiv.org/abs/2507.17432)
*Jiahui Wei,Philippe Mary,Elsa Dupraz*

Main category: cs.IT

TL;DR: 本文研究了间接Wyner-Ziv源编码问题，在该问题中编码器和解码器都无法观察到潜在源S，但解码器需要重建S。文章推导了渐近情况下的间接Wyner-Ziv率失真函数，提出了有限块长度下的可达区域，并设计了专门的Blahut-Arimoto算法进行数值评估。


<details>
  <summary>Details</summary>
Motivation: 在目标导向通信背景下，存在这样的场景：编码器需要编码源X，解码器有副信息Y，但同时还需要重建一个编码器和解码器都无法直接观察到的潜在源S（如语义信息）。这种间接设置在实际应用中越来越重要，但理论分析相对缺乏。

Method: 1. 在渐近情况下推导间接Wyner-Ziv率失真函数的理论表达式；2. 提供有限块长度情况下的可达区域分析；3. 设计针对间接Wyner-Ziv设置的专门Blahut-Arimoto算法；4. 将S视为分类标签进行数值实验验证。

Result: 成功推导出间接Wyner-Ziv率失真函数，建立了有限块长度下的可达区域理论框架，开发了有效的数值计算算法，并通过将S作为分类标签的实验验证了理论结果的有效性。

Conclusion: 本文为间接Wyner-Ziv源编码问题提供了完整的理论框架，包括渐近和有限块长度情况下的率失真分析，并通过专门设计的算法验证了理论结果。这为目标导向通信中的语义信息传输提供了重要的理论基础。

Abstract: In the Wyner-Ziv source coding problem, a source $X$ has to be encoded while
the decoder has access to side information $Y$. This paper investigates the
indirect setup, in which a latent source $S$, unobserved by both the encoder
and the decoder, must also be reconstructed at the decoder. This scenario is
increasingly relevant in the context of goal-oriented communications, where $S$
can represent semantic information obtained from $X$. This paper derives the
indirect Wyner-Ziv rate-distortion function in asymptotic regime and provides
an achievable region in finite block-length. Furthermore, a Blahut-Arimoto
algorithm tailored for the indirect Wyner-Ziv setup, is proposed. This
algorithm is then used to give a numerical evaluation of the achievable
indirect rate-distortion region when $S$ is treated as a classification label.

</details>


### [8] [Bounds and Equivalence of Skew Polycyclic Codes over Finite Fields](https://arxiv.org/abs/2507.17571)
*Hassan Ou-azzou,Anna-Lena Horlemann,Nuh Aydin*

Main category: cs.IT

TL;DR: 本文研究有限域上的偏斜多循环码，证明了Roos类界限，分析了不同多循环码类之间的汉明距离和秩等价性，并提供了理论应用实例。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上与偏斜多项式相关的偏斜多循环码的性质，特别是其在汉明度量和秩度量下的界限问题，以及不同码类之间的等价关系。

Method: 通过引入等价关系来分析偏斜多循环码，证明汉明度量和秩度量下的Roos类界限，描述等价类的特征，并建立两类多循环码之间的汉明等价和秩等价关系。

Result: 成功证明了偏斜多循环码在汉明度量和秩度量下的Roos类界限，建立了多循环码类之间的等价关系理论框架，并通过具体实例验证了理论的有效性。

Conclusion: 建立了偏斜多循环码的完整理论框架，包括界限理论和等价关系分析，为编码理论提供了新的理论工具和应用方向。

Abstract: We study skew polycyclic codes over a finite field $\mathbb{F}_q$, associated
with a skew polynomial $f(x) \in \mathbb{F}_q[x;\sigma]$, where $\sigma$ is an
automorphism of $\mathbb{F}_q$. We start by proving the Roos-like bound for
both the Hamming and the rank metric for this class of codes. Next, we focus on
the Hamming and rank equivalence between two classes of polycyclic codes by
introducing an equivalence relation and describing its equivalence classes.
Finally, we present examples that illustrate applications of the theory
developed in this paper.

</details>


### [9] [On Function-Correcting Codes in the Lee Metric](https://arxiv.org/abs/2507.17654)
*Gyanendra K. Verma,Abhay Kumar Singh*

Main category: cs.IT

TL;DR: 本文扩展了Liu和Liu关于函数纠错码的研究，从Z_4上的齐次度量扩展到任意Z_m上的Lee度量，通过引入不规则Lee距离码来确定最优冗余度，并针对特定函数类别得到了改进的界限。


<details>
  <summary>Details</summary>
Motivation: 现有的函数纠错码研究主要集中在Z_{2^l}上使用齐次度量，需要将研究扩展到更一般的Z_m环上使用Lee度量，以确定这些码的最优冗余度并改进现有结果。

Method: 引入不规则Lee距离码的概念，通过刻画这类码的最短可能长度来推导最优冗余度的上界和下界，然后将这些一般性界限简化并应用到特定的函数类别。

Result: 获得了Z_m上Lee度量下函数纠错码最优冗余度的上界和下界，针对Lee-局部函数、Lee权重函数和Lee权重分布函数等特定类别，相比Liu和Liu在Z_4上的结果有所改进，并将其他界限推广到Z_m上。

Conclusion: 成功将函数纠错码的研究从Z_4扩展到一般的Z_m环，在Lee度量下建立了最优冗余度的理论框架，为特定函数类别提供了更好的界限，推进了函数纠错码理论的发展。

Abstract: Function-correcting codes are a coding framework designed to minimize
redundancy while ensuring that specific functions or computations of encoded
data can be reliably recovered, even in the presence of errors. The choice of
metric is crucial in designing such codes, as it determines which computations
must be protected and how errors are measured and corrected. Previous work by
Liu and Liu [6] studied function-correcting codes over $\mathbb{Z}_{2^l},\
l\geq 2$ using the homogeneous metric, which coincides with the Lee metric over
$\mathbb{Z}_4$. In this paper, we extend the study to codes over
$\mathbb{Z}_m,$ for any positive integer $m\geq 2$ under the Lee metric and aim
to determine their optimal redundancy. To achieve this, we introduce irregular
Lee distance codes and derive upper and lower bounds on the optimal redundancy
by characterizing the shortest possible length of such codes. These general
bounds are then simplified and applied to specific classes of functions,
including Lee-local functions, Lee weight functions, and Lee weight
distribution functions, leading to improved some bounds compared to those of
Liu and Liu [6] over $\mathbb{Z}_4$ and generalize the other bounds over
$\mathbb{Z}_m$ in the Lee metric.

</details>


### [10] [Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems](https://arxiv.org/abs/2507.17736)
*Shreya Meel,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文研究了在复制数据库上的对称私有信息检索(SPIR)问题，其中数据库由简单图建模，每个顶点对应一个服务器，消息在相邻服务器间复制。文章建立了SPIR容量的下界，证明了消息特定随机性的最小大小要求，并推导出路径图和正则图的精确SPIR容量。


<details>
  <summary>Details</summary>
Motivation: 现有的私有信息检索研究主要关注完全复制的数据库，但在实际应用中，由于存储和带宽限制，数据往往只在部分服务器上复制。因此需要研究在图结构建模的复制数据库上的对称私有信息检索问题，以更好地反映实际的分布式存储场景。

Method: 提出了一种基于图结构的SPIR模型，其中每个顶点代表服务器，边表示消息在相邻服务器间的复制关系。设计了消息特定公共随机性的概念，即服务器端的公共随机性也按照图结构进行复制。通过构造可达成的SPIR方案来建立容量下界，并通过信息论方法证明上界。

Result: 建立了一般图上SPIR容量的下界；证明了任何可行SPIR方案的消息特定随机性最小大小必须等于消息大小；对于路径图和正则图，通过提供匹配的上界，推导出了精确的SPIR容量表达式。

Conclusion: 在图结构建模的复制数据库上，SPIR的容量受到图的拓扑结构显著影响。消息特定公共随机性的大小下界为消息大小，这是实现SPIR的基本要求。对于特定的图类别（路径图和正则图），可以精确确定SPIR容量，为实际系统设计提供了理论指导。

Abstract: We introduce the problem of symmetric private information retrieval (SPIR) on
replicated databases modeled by a simple graph. In this model, each vertex
corresponds to a server, and a message is replicated on two servers if and only
if there is an edge between them. We consider the setting where the server-side
common randomness necessary to accomplish SPIR is also replicated at the
servers according to the graph, and we call this as message-specific common
randomness. In this setting, we establish a lower bound on the SPIR capacity,
i.e., the maximum download rate, for general graphs, by proposing an achievable
SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the
minimum size of message-specific randomness should be equal to the size of a
message. Finally, by providing matching upper bounds, we derive the exact SPIR
capacity for the class of path and regular graphs.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [11] [PPAAS: PVT and Pareto Aware Analog Sizing via Goal-conditioned Reinforcement Learning](https://arxiv.org/abs/2507.17003)
*Seunggeun Kim,Ziyi Wang,Sungyoung Lee,Youngmin Oh,Hanqing Zhu,Doyun Kim,David Z. Pan*

Main category: eess.SP

TL;DR: 提出了一个目标条件强化学习框架，用于模拟电路器件尺寸设计，在PVT变化下实现高效训练和强泛化能力，相比现有方法在样本效率和仿真效率上分别提升约1.6倍和4.1倍。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号电路设计中的器件尺寸优化是一个关键但具有挑战性的步骤，需要在满足多样化性能规格的同时考虑工艺、电压、温度(PVT)变化的影响。现有强化学习方法虽然在固定目标的尺寸设计中显示出潜力，但训练能够适应PVT变化下广泛设计规格的通用策略需要大量训练样本和资源。

Method: 提出目标条件强化学习框架，包含三个关键技术：1) Pareto前沿主导目标采样，通过从先前达成目标的Pareto前沿采样构建自动课程；2) 保守后见经验回放，为重标记目标分配保守虚拟奖励以稳定训练并加速收敛；3) 失败时跳过仿真策略，当标称角仿真未达到目标规格时跳过全角仿真以减少仿真开销。

Result: 在基准电路上的实验表明，相比现有尺寸设计方法，该框架在样本效率上提升约1.6倍，在仿真效率上提升约4.1倍。代码和基准测试已公开发布。

Conclusion: 所提出的目标条件强化学习框架有效解决了模拟电路器件尺寸设计中的PVT变化适应性问题，通过创新的目标采样、经验回放和仿真优化策略，显著提升了训练效率和泛化能力，为自动化模拟电路设计提供了有效解决方案。

Abstract: Device sizing is a critical yet challenging step in analog and mixed-signal
circuit design, requiring careful optimization to meet diverse performance
specifications. This challenge is further amplified under process, voltage, and
temperature (PVT) variations, which cause circuit behavior to shift across
different corners. While reinforcement learning (RL) has shown promise in
automating sizing for fixed targets, training a generalized policy that can
adapt to a wide range of design specifications under PVT variations requires
much more training samples and resources. To address these challenges, we
propose a \textbf{Goal-conditioned RL framework} that enables efficient policy
training for analog device sizing across PVT corners, with strong
generalization capability. To improve sample efficiency, we introduce
Pareto-front Dominance Goal Sampling, which constructs an automatic curriculum
by sampling goals from the Pareto frontier of previously achieved goals. This
strategy is further enhanced by integrating Conservative Hindsight Experience
Replay, which assigns relabeled goals with conservative virtual rewards to
stabilize training and accelerate convergence. To reduce simulation overhead,
our framework incorporates a Skip-on-Fail simulation strategy, which skips
full-corner simulations when nominal-corner simulation fails to meet target
specifications. Experiments on benchmark circuits demonstrate $\sim$1.6$\times$
improvement in sample efficiency and $\sim$4.1$\times$ improvement in
simulation efficiency compared to existing sizing methods. Code and benchmarks
are publicly available at https://github.com/SeunggeunKimkr/PPAAS

</details>


### [12] [Efficient and Distortion-less Spectrum Multiplexer via Neural Network-based Filter Banks](https://arxiv.org/abs/2507.17106)
*Jiazhao Wang,Wenchao Jiang*

Main category: eess.SP

TL;DR: 本文提出了一种基于神经网络滤波器组的频谱复用器，通过模型驱动方法将神经网络集成到滤波器设计中，实现多个窄带IoT信号的同时传输，相比传统方法显著提升了频谱利用率和传输效率。


<details>
  <summary>Details</summary>
Motivation: 现有的频谱复用方法在处理多个窄带IoT信号时存在效率低下和失真较大的问题，需要一种新的解决方案来提高频谱利用率，减少信号失真，并提升系统整体性能。

Method: 采用模型驱动方法，将神经网络模型解释为滤波器组，设计了基于神经网络的滤波器组系统。该方法利用神经网络的学习能力实现无失真复用，并通过硬件加速提高执行效率。

Result: 实验结果显示：信号失真水平低至-39dB归一化均方误差；相比传统方法，执行效率提升35倍，信噪比增益达10dB；在实际应用中，对异构和同构IoT网络的数据包接收率高达98%。

Conclusion: 基于神经网络的滤波器组频谱复用器成功解决了传统方法的局限性，在保持低失真的同时大幅提升了执行效率和信号质量，在实际IoT网络部署中表现出色，为多信号并发传输提供了有效的解决方案。

Abstract: Spectrum multiplexer enables simultaneous transmission of multiple
narrow-band IoT signals through gateway devices, thereby enhancing overall
spectrum utilization. We propose a novel solution based on filter banks that
offer increased efficiency and minimal distortion compared with conventional
methods. We follow a model-driven approach to integrate the neural networks
into the filter bank design by interpreting the neural network models as filter
banks. The proposed NN-based filter banks can leverage advanced learning
capabilities to achieve distortionless multiplexing and harness hardware
acceleration for high efficiency. Then, we evaluate the performance of the
spectrum multiplexer implemented by NN-based filter banks for various types of
signals and environmental conditions. The results show that it can achieve a
low distortion level down to $-39$dB normalized mean squared error.
Furthermore, it achieves up to $35$ times execution efficiency gain and $10$dB
SNR gain compared with the conventional methods. The field applications show
that it can handle both the heterogeneous and homogeneous IoT networks,
resulting in high packet reception ratio at the standard receivers up to
$98\%$.

</details>


### [13] [Stacked Intelligent Metasurface Assisted Multiuser Communications: From a Rate Fairness Perspective](https://arxiv.org/abs/2507.17153)
*Junjie Fang,Chao Zhang,Jiancheng An,Hongwen Yu,Qingqing Wu,Mérouane Debbah,Chau Yuen*

Main category: eess.SP

TL;DR: 本文研究了堆叠智能超表面(SIM)在多用户下行系统中提升速率公平性的应用，通过最大化最小速率和几何平均速率两种优化方法，实现了用户公平性与系统性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统单层可重构全息表面在电磁波传播控制和信号处理能力方面存在局限性，需要通过多层结构的堆叠智能超表面来增强控制能力，并解决多用户下行系统中的速率公平性问题。

Method: 针对最大化最小速率问题，采用基于共识交替方向乘数法(ADMM)的方法，将近似问题分解为具有闭式解的子问题；针对几何平均速率最大化，开发了基于交替优化(AO)的算法，同样可获得闭式解并可适配于和速率最大化。

Result: 数值结果验证了所提算法的有效性和收敛性。最大化最小速率方法确保了近乎完美的公平性，而几何平均速率最大化在公平性和系统和速率之间实现了平衡。两种算法在最小速率和和速率性能方面分别优于现有相关工作。

Conclusion: 堆叠智能超表面能够有效提升多用户下行系统的速率公平性，在较低功耗条件下实现了与多天线数字波束成形相当的性能，为无线通信系统的公平性和能效优化提供了新的解决方案。

Abstract: Stacked intelligent metasurface (SIM) extends the concept of single-layer
reconfigurable holographic surfaces (RHS) by incorporating a multi-layered
structure, thereby providing enhanced control over electromagnetic wave
propagation and improved signal processing capabilities. This study
investigates the potential of SIM in enhancing the rate fairness in multiuser
downlink systems by addressing two key optimization problems: maximizing the
minimum rate (MR) and maximizing the geometric mean of rates (GMR). {The former
strives to enhance the minimum user rate, thereby ensuring fairness among
users, while the latter relaxes fairness requirements to strike a better
trade-off between user fairness and system sum-rate (SR).} For the MR
maximization, we adopt a consensus alternating direction method of multipliers
(ADMM)-based approach, which decomposes the approximated problem into
sub-problems with closed-form solutions. {For GMR maximization, we develop an
alternating optimization (AO)-based algorithm that also yields closed-form
solutions and can be seamlessly adapted for SR maximization. Numerical results
validate the effectiveness and convergence of the proposed algorithms.}
Comparative evaluations show that MR maximization ensures near-perfect
fairness, while GMR maximization balances fairness and system SR. Furthermore,
the two proposed algorithms respectively outperform existing related works in
terms of MR and SR performance. Lastly, SIM with lower power consumption
achieves performance comparable to that of multi-antenna digital beamforming.

</details>


### [14] [Design of a Noval Wearable ECG Monitoring Device](https://arxiv.org/abs/2507.17154)
*Ruihua Wang,Mingtong Chen,Zhengbao Yang*

Main category: eess.SP

TL;DR: 本研究开发了一种新型无线供电的可穿戴心电监测设备，采用镀银织物一体式电极设计，解决了传统心电监测设备功耗高和长期佩戴不适的问题。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴智能心电解决方案在高精度心电诊断和传输过程中存在高功耗问题；传统Ag/AgCl凝胶电极不适合长期动态监测，容易引起皮肤刺激、炎症和过敏反应；需要开发适合长期佩戴的小型化无线心电监测设备。

Method: 采用镀银织物一体式切割技术制作电极和导线；将导线部分切割成接近S形的弯曲结构以确保良好的延展性；通过算法优化和降低噪声功率来改善信噪比；设计无线供电系统以降低功耗。

Result: 成功开发出可长期佩戴的无线心电监测设备，采用镀银织物电极替代传统凝胶电极，S形导线设计保证了日常运动中的舒适性和信号完整性，解决了传统电极的皮肤刺激问题。

Conclusion: 新型无线供电可穿戴心电监测设备通过创新的镀银织物一体式电极设计和S形导线结构，实现了长期舒适佩戴和可靠的心电信号监测，为心脏疾病的持续监护提供了有效的技术解决方案。

Abstract: The aim of this project is to develop a new wireless powered wearable ECG
monitoring device. The main goal of the project is to provide a wireless,
small-sized ECG monitoring device that can be worn for a long period of time by
the monitored person. Electrocardiogram ECG reflects physiological and
pathological information about heart activity and is commonly used to diagnose
heart disease. Existing wearable smart ECG solutions suffer from high power
consumption in both ECG diagnosis and transmission for high accuracy.
Monitoring of ECG devices is mainly done by data extraction and acquisition,
pre-processing, feature extraction, processing and analysis, visualisation and
auxiliary procedures. During the pre-processing of the information, different
kinds of noise generated during the signal collection need to be taken into
account. The quality of the signal-to-noise ratio can usually be improved by
optimising algorithms and reducing the noise power. The choice of electrodes
usually has a direct impact on the signal-to-noise ratio and the user
experience, and conventional Ag/AgCl gel electrodes are not suitable for
long-term and dynamic monitoring as they are prone to skin irritation,
inflammation and allergic reactions. Therefore, a completely new way of
combining electrodes and wires will be used in the report. The electrodes and
wires are cut in one piece from a silver-plated fabric. The wire portion is cut
into a curved structure close to an S shape to ensure that it has good
ductility for comfort and signal integrity during daily movement of the
garment.

</details>


### [15] [Hybrid Semantic-Complementary Transmission for High-Fidelity Image Reconstruction](https://arxiv.org/abs/2507.17196)
*Hyelin Nam,Jihong Park,Jinho Choi,Seong-Lyun Kim*

Main category: eess.SP

TL;DR: 提出了混合语义通信(HSC)框架，通过在语义表示基础上添加互补表示来捕获图像特定的残差信息，从而显著提高图像重建保真度


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的语义通信收发器在多样化图像分布上训练，经常无法重建细粒度的图像特定细节，导致重建保真度有限

Method: 提出混合语义通信(HSC)框架，在发送端构建捕获残差图像特定信息的互补表示(CR)，在接收端将CR与语义通信结果结合，生成高保真重建图像。推导了重建误差的闭式表达式和相应的最优CR

Result: 仿真结果表明，在各种信道和神经网络架构下，HSC相比不传输CR的基线语义通信方法大幅降低了均方误差(MSE)

Conclusion: HSC框架通过灵活调节互补表示的传输负载来实现期望的保真度，有效解决了语义通信中图像重建保真度有限的问题

Abstract: Recent advances in semantic communication (SC) have introduced neural network
(NN)-based transceivers that convey semantic representation (SR) of signals
such as images. However, these NNs are trained over diverse image distributions
and thus often fail to reconstruct fine-grained image-specific details. To
overcome this limited reconstruction fidelity, we propose an extended SC
framework, hybrid semantic communication (HSC), which supplements SR with
complementary representation (CR) capturing residual image-specific
information. The CR is constructed at the transmitter, and is combined with the
actual SC outcome at the receiver to yield a high-fidelity recomposed image.
While the transmission load of SR is fixed due to its NN-based structure, the
load of CR can be flexibly adjusted to achieve a desirable fidelity. This
controllability directly influences the final reconstruction error, for which
we derive a closed-form expression and the corresponding optimal CR. Simulation
results demonstrate that HSC substantially reduces MSE compared to the baseline
SC without CR transmission across various channels and NN architectures.

</details>


### [16] [HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes](https://arxiv.org/abs/2507.17224)
*Feng Cao,Zishuo Feng*

Main category: eess.SP

TL;DR: 提出了HuiduRep，一个用于细胞外记录中尖峰分拣的自监督表示学习框架，通过对比学习和去噪自编码器学习鲁棒的尖峰波形表示，在噪声和漂移条件下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 细胞外记录中的尖峰分拣是脑活动解码的关键步骤，但在低信噪比、电极漂移和跨会话变异性等条件下仍面临挑战，需要开发更鲁棒和可泛化的方法。

Method: 提出HuiduRep框架，结合对比学习和去噪自编码器来学习细胞外尖峰波形的判别性和可泛化特征表示，然后基于该表示构建无监督的尖峰聚类分拣流水线。

Result: 在混合数据集和真实世界数据集上的实验表明，HuiduRep具有强鲁棒性，其分拣流水线的性能与KiloSort4和MountainSort5等最先进工具相当或更优。

Conclusion: 自监督尖峰表示学习作为细胞外记录鲁棒和可泛化处理的基础工具具有巨大潜力，HuiduRep为神经科学中的脑活动解码提供了有效的解决方案。

Abstract: Extracellular recordings are brief voltage fluctuations recorded near
neurons, widely used in neuroscience as the basis for decoding brain activity
at single-neuron resolution. Spike sorting, which assigns each spike to its
source neuron, is a critical step in brain sensing pipelines. However, it
remains challenging under low signal-to-noise ratio (SNR), electrode drift, and
cross-session variability. In this paper, we propose HuiduRep, a robust
self-supervised representation learning framework that extracts discriminative
and generalizable features from extracellular spike waveforms. By combining
contrastive learning with a denoising autoencoder, HuiduRep learns latent
representations that are robust to noise and drift. Built on HuiduRep, we
develop a spike sorting pipeline that clusters spike representations without
supervision. Experiments on hybrid and real-world datasets demonstrate that
HuiduRep achieves strong robustness and the pipeline matches or outperforms
state-of-the-art tools such as KiloSort4 and MountainSort5. These findings
demonstrate the potential of self-supervised spike representation learning as a
foundational tool for robust and generalizable processing of extracellular
recordings.

</details>


### [17] [Joint Resource Optimization Over Licensed and Unlicensed Spectrum in Spectrum Sharing UAV Networks Against Jamming Attacks](https://arxiv.org/abs/2507.17261)
*Rui Ding,Fuhui Zhou,Yuhang Wu,Qihui Wu,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该论文研究了无人机通信网络中的频谱共享和抗干扰技术，通过联合优化发射功率、子信道分配和无人机轨迹来最大化网络和速率，提出了基于交替优化的低复杂度迭代算法。


<details>
  <summary>Details</summary>
Motivation: 无人机通信在异构无线应用场景中至关重要，但用户密集和高数据速率需求导致无人机频谱利用率稀缺。将未充分利用的非授权频谱与授权频谱结合可以提升网络容量，但非授权频谱的开放性使无人机容易受到潜在干扰器的安全威胁。

Method: 将复杂的非凸问题分解为两个子问题：1）联合功率和子信道分配，2）无人机轨迹设计。提出基于交替优化的低复杂度迭代算法，利用拉格朗日对偶分解迭代优化发射功率和子信道分配，然后采用基于连续凸近似的高效迭代算法获得无人机轨迹的次优解。

Result: 仿真结果表明，与基准方案相比，所提出的算法能够显著提高和传输速率。

Conclusion: 该研究成功解决了频谱共享无人机网络中与授权蜂窝网络和非授权Wi-Fi网络共存的抗干扰问题，通过联合优化实现了辅助网络和速率的最大化，提出的算法在性能上优于现有基准方案。

Abstract: Unmanned aerial vehicle (UAV) communication is of crucial importance in
realizing heterogeneous practical wireless application scenarios. However, the
densely populated users and diverse services with high data rate demands has
triggered an increasing scarcity of UAV spectrum utilization. To tackle this
problem, it is promising to incorporate the underutilized unlicensed spectrum
with the licensed spectrum to boost network capacity. However, the openness of
unlicensed spectrum makes UAVs susceptible to security threats from potential
jammers. Therefore, a spectrum sharing UAV network coexisting with licensed
cellular network and unlicensed Wi-Fi network is considered with the
anti-jamming technique in this paper. The sum rate maximization of the
secondary network is studied by jointly optimizing the transmit power,
subchannel allocation, and UAV trajectory. We first decompose the challenging
non-convex problem into two subproblems, 1) the joint power and subchannel
allocation and 2) UAV trajectory design subproblems. A low-complexity iterative
algorithm is proposed in a alternating optimization manner over these two
subproblems to solve the formulated problem. Specifically, the Lagrange dual
decomposition is exploited to jointly optimize the transmit power and
subchannel allocation iteratively. Then, an efficient iterative algorithm
capitalizing on successive convex approximation is designed to get a suboptimal
solution for UAV trajectory. Simulation results demonstrate that our proposed
algorithm can significantly improve the sum transmission rate compared with the
benchmark schemes.

</details>


### [18] [State Estimation with 1-Bit Observations and Imperfect Models: Bussgang Meets Kalman in Neural Networks](https://arxiv.org/abs/2507.17284)
*Chaehyun Jung,TaeJun Ha,Hyeonuk Kim,Jeonghun Park*

Main category: eess.SP

TL;DR: 本文提出了针对1比特量化观测的状态估计方法，包括Bussgang辅助卡尔曼滤波器及其深度学习变体，有效解决了量化失真和信息损失问题


<details>
  <summary>Details</summary>
Motivation: 传统状态估计方法假设没有量化失真，但在实际应用中1比特量化不可避免，会造成严重的量化失真和信息损失，使得传统方法不再适用

Method: 基于Bussgang分解技术开发Bussgang辅助卡尔曼滤波器，提出计算高效的简化版本，并结合门控循环单元(GRU)架构构建Bussgang辅助KalmanNet深度学习方法，使用抖动技术缓解量化影响

Result: 在Lorenz-Attractor模型和Michigan NCLT数据集上的仿真实验表明，即使在高度非线性、模型失配和1比特观测条件下，所提方法仍能实现准确的状态估计性能

Conclusion: 所提出的Bussgang辅助方法能够有效处理1比特量化带来的挑战，在模型已知和部分已知情况下都能保持良好的状态估计精度，为量化系统中的状态估计提供了可行解决方案

Abstract: State estimation from noisy observations is a fundamental problem in many
applications of signal processing. Traditional methods, such as the extended
Kalman filter, work well under fully-known Gaussian models, while recent hybrid
deep learning frameworks, combining model-based and data-driven approaches, can
also handle partially known models and non-Gaussian noise. However, existing
studies commonly assume the absence of quantization distortion, which is
inevitable, especially with non-ideal analog-to-digital converters. In this
work, we consider a state estimation problem with 1-bit quantization. 1-bit
quantization causes significant quantization distortion and severe information
loss, rendering conventional state estimation strategies unsuitable. To address
this, inspired by the Bussgang decomposition technique, we first develop the
Bussgang-aided Kalman filter by assuming perfectly known models. The proposed
method suitably captures quantization distortion into the state estimation
process. In addition, we propose a computationally efficient variant, referred
to as the reduced Bussgang-aided Kalman filter and, building upon it, introduce
a deep learning-based approach for handling partially known models, termed the
Bussgang-aided KalmanNet. In particular, the Bussgang-aided KalmanNet jointly
uses a dithering technique and a gated recurrent unit (GRU) architecture to
effectively mitigate the effects of 1-bit quantization and model mismatch.
Through simulations on the Lorenz-Attractor model and the Michigan NCLT
dataset, we demonstrate that our proposed methods achieve accurate state
estimation performance even under highly nonlinear, mismatched models and 1-bit
observations.

</details>


### [19] [Non-Orthogonal AFDM: A Promising Spectrum-Efficient Waveform for 6G High-Mobility Communications](https://arxiv.org/abs/2507.17292)
*Yu Zhang,Qin Yi,Leila Musavian,Tongyang Xu,Zilong Liu*

Main category: eess.SP

TL;DR: 本文提出了一种频谱高效的非正交仿射频分复用(AFDM)波形，通过引入压缩因子实现可控的子载波重叠，结合线性预编码和迭代检测技术来减少载波间干扰，为6G高移动性通信提供了平衡频谱效率和多普勒弹性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在即将到来的第六代(6G)移动系统中，需要在高移动性环境下实现可靠通信，同时提高频谱效率。传统的正交调制方案在高移动性场景下面临多普勒效应带来的载波间干扰问题，因此需要开发新的波形技术来平衡频谱效率和多普勒弹性。

Method: 提出了一种非正交AFDM波形设计方法：1)引入压缩因子来实现可控的子载波重叠，提高频谱效率；2)在发射端采用线性预编码技术；3)在接收端采用迭代检测方案来减轻载波间干扰(ICI)。这些技术结合chirp-based AFDM调制来构建完整的通信系统。

Result: 仿真结果表明，即使在激进的压缩因子和高移动性信道条件下，所提出的技术能够有效减少干扰并保持稳健的误码率(BER)性能。验证了非正交AFDM波形在频谱效率和多普勒弹性之间取得了良好的平衡。

Conclusion: 所提出的非正交AFDM波形为下一代无线网络提供了一个有前景的解决方案，能够在高度动态的环境中平衡频谱效率和多普勒弹性，适用于6G高移动性通信场景。

Abstract: This paper proposes a spectrum-efficient nonorthogonal affine frequency
division multiplexing (AFDM) waveform for reliable high-mobility communications
in the upcoming sixth-generation (6G) mobile systems. Our core idea is to
introduce a compression factor to enable controllable subcarrier overlapping in
chirp-based AFDM modulation. To mitigate intercarrier interference (ICI), we
introduce linear precoding at the transmitter and an iterative detection scheme
at the receiver. Simulation results demonstrate that these techniques can
effectively reduce interference and maintain robust bit error rate (BER)
performance even under aggressive compression factors and high-mobility channel
conditions. The proposed non-orthogonal AFDM waveform offers a promising
solution for next-generation wireless networks, balancing spectrum efficiency
and Doppler resilience in highly dynamic environments.

</details>


### [20] [LightCom: A Generative AI-Augmented Framework for QoE-Oriented Communications](https://arxiv.org/abs/2507.17352)
*Chunmei Xu,Siqi Zhang,Yi Ma,Rahim Tafazolli*

Main category: eess.SP

TL;DR: 本文提出LightCom框架，采用轻量级编码和生成式AI解码方案，在低信噪比条件下实现面向用户体验质量(QoE)的通信，相比传统系统在鲁棒性和感知覆盖范围方面分别提升14dB和9dB。


<details>
  <summary>Details</summary>
Motivation: 数据密集型和沉浸式应用(如虚拟现实)对用户体验质量提出严格要求，挑战了传统基于服务质量(QoS)驱动的通信系统。需要开发新的通信框架来满足这些应用在低信噪比条件下的QoE需求。

Method: 提出LightCom框架：发射端采用基础低通滤波进行信源编码和最小信道编码，简化处理复杂度；接收端使用生成式AI模型从高压缩和降质信号中重建高保真内容，利用生成先验推断语义和结构信息；开发重要性感知的功率分配策略。

Result: 仿真结果显示LightCom在鲁棒性方面提升高达14dB，在感知覆盖范围方面获得9dB增益，性能优于依赖复杂信源和信道编码的传统QoS驱动系统。

Conclusion: 该研究实现了通信系统从比特级保真度向以人为中心的QoE指标的范式转换，为构建更高效和更具弹性的无线网络铺平了道路，标志着通信系统设计理念的重要转变。

Abstract: Data-intensive and immersive applications, such as virtual reality, impose
stringent quality of experience (QoE) requirements that challenge traditional
quality of service (QoS)-driven communication systems. This paper presents
LightCom, a lightweight encoding and generative AI (GenAI)-augmented decoding
framework, designed for QoE-oriented communications under low signal-to-noise
ratio (SNR) conditions. LightCom simplifies transmitter design by applying
basic low-pass filtering for source coding and minimal channel coding,
significantly reducing processing complexity and energy consumption. At the
receiver, GenAI models reconstruct high-fidelity content from highly compressed
and degraded signals by leveraging generative priors to infer semantic and
structural information beyond traditional decoding capabilities. The key design
principles are analyzed, along with the sufficiency and error-resilience of the
source representation. We also develop importance-aware power allocation
strategies to enhance QoE and extend perceived coverage. Simulation results
demonstrate that LightCom achieves up to a $14$ dB improvement in robustness
and a $9$ dB gain in perceived coverage, outperforming traditional QoS-driven
systems relying on sophisticated source and channel coding. This paradigm shift
moves communication systems towards human-centric QoE metrics rather than
bit-level fidelity, paving the way for more efficient and resilient wireless
networks.

</details>


### [21] [Partially Reflected Surface (PRS)-Loaded Graphene-Based Patch Antenna for 6G](https://arxiv.org/abs/2507.17393)
*Omar Osman,Abdullah Qayyum,Maziar Nekovee*

Main category: eess.SP

TL;DR: 本文提出了一种基于石墨烯材料的缝隙贴片天线，集成部分反射表面(PRS)，工作在太赫兹频段，用于6G通信。通过5×4单元阵列的PRS优化，实现了70 GHz带宽(750-820 GHz)和1.07 dBi的增益提升。


<details>
  <summary>Details</summary>
Motivation: 为满足6G通信对太赫兹频段天线的需求，需要开发高性能的太赫兹天线。传统天线在太赫兹频段存在增益不足、辐射方向图不稳定等问题，因此需要通过集成部分反射表面来增强天线性能。

Method: 设计了基于石墨烯材料的缝隙贴片天线，使用Rogers RT Duroid 6010基板。集成了由5×4单元阵列组成的部分反射表面(PRS)，通过优化PRS单元结构来增强天线的整体实现增益和辐射特性。

Result: 天线实现了70 GHz的工作带宽(750-820 GHz)，整体实现增益提升了1.07 dBi。PRS有效改善了天线辐射方向图，在整个工作带宽内表现出稳定的特性。仿真验证了改进后天线的性能提升。

Conclusion: 通过集成部分反射表面，成功实现了太赫兹频段石墨烯缝隙贴片天线的性能优化。该设计在6G通信应用中具有良好的潜力，为太赫兹天线设计提供了有效的解决方案。

Abstract: This work investigates a slotted patch antenna integrated with a partially
reflected surface (PRS) to operate in the TeraHertz (THz) frequency range for
6G. The antenna is based on graphene material, on a Rogers RT Duroid 6010
substrate. The proposed antenna achieves a bandwidth of 70 GHz (750 GHz to 820
GHz). The PRS sheet consists of 5x4 unit cells, which are optimised to enhance
the overall realized gain of the antenna. The overall realized gain has
increased by 1.07 dBi. Also, the PRS enhanced the antenna radiation pattern,
showing stable properties over the operating bandwidth. The improved antenna
performance is validated via simulations.

</details>


### [22] [Learning from Scratch: Structurally-masked Transformer for Next Generation Lib-free Simulation](https://arxiv.org/abs/2507.17396)
*Junlang Huang,Hao Chen,Zhong Guan*

Main category: eess.SP

TL;DR: 提出了一个基于神经网络的多级数据路径功率和时序预测框架，使用CNN-Transformer混合架构直接从SPICE网表推断瞬态波形和传播延迟，在工业电路上达到SPICE级精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于库的分析方法依赖于驱动器特征化和负载简化，存在局限性。需要一种能够准确捕获内在延迟和耦合延迟效应的新方法，无需简化或插值，并能处理复杂信号路径中的完整波形可见性。

Method: 采用两个预训练神经模型进行波形预测和延迟估计，直接从SPICE网表推断瞬态波形和传播延迟。使用混合CNN-Transformer架构配合网表感知的节点级编码，实现递归传播策略进行多级时序预测，并设置专门的子网络分别处理主要延迟估计和串扰校正。

Result: 在多样化的工业电路上实现了SPICE级精度，RMSE始终低于0.0098。该框架提供了可扩展、结构自适应的神经网络替代方案，对物理电路行为表现出高保真度。

Conclusion: 提出的神经框架成功替代了传统的功率和时序引擎，为标准单元设计了首个基于语言的、网表感知的神经网络，在保持SPICE级精度的同时提供了更好的可扩展性和结构适应性。

Abstract: This paper proposes a neural framework for power and timing prediction of
multi-stage data path, distinguishing itself from traditional lib-based
analytical methods dependent on driver characterization and load
simplifications. To the best of our knowledge, this is the first
language-based, netlist-aware neural network designed explicitly for standard
cells. Our approach employs two pre-trained neural models of waveform
prediction and delay estimation that directly infer transient waveforms and
propagation delays from SPICE netlists, conditioned on critical physical
parameters such as load capacitance, input slew, and gate size. This method
accurately captures both intrinsic and coupling-induced delay effects without
requiring simplification or interpolation. For multi-stage timing prediction,
we implement a recursive propagation strategy where predicted waveforms from
each stage feed into subsequent stages, cumulatively capturing delays across
the logic chain. This approach ensures precise timing alignment and complete
waveform visibility throughout complex signal pathways. The waveform prediction
utilizes a hybrid CNN-Transformer architecture with netlist-aware node-level
encoding, addressing traditional Transformers' fixed input dimensionality
constraints. Additionally, specialized subnetworks separately handle primary
delay estimation and crosstalk correction. Experimental results demonstrate
SPICE-level accuracy, consistently achieving RMSE below 0.0098 across diverse
industrial circuits. The proposed framework provides a scalable, structurally
adaptable neural alternative to conventional power and timing engines,
demonstrating high fidelity to physical circuit behaviors.

</details>


### [23] [Power Allocation and RIS Elements Optimisation for Reconfigurable Intelligent Surfaces assisted RSMA](https://arxiv.org/abs/2507.17419)
*Abdullah Qayyum,Maziar Nekovee*

Main category: eess.SP

TL;DR: 本文提出了在RIS辅助的速率分割多址接入系统中的功率分配和RIS元件数量优化方法(ORIS-RSMA)，通过联合优化RIS元件数量和功率分配因子来最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的RSMA系统中，需要同时优化RIS元件数量和功率分配策略，以在满足目标公共速率的约束下最大化系统和速率，现有方法缺乏这种联合优化。

Method: 提出ORIS-RSMA方法，联合优化RIS元件的最优数量和消息公共部分、私有部分的功率分配因子，在确保满足目标公共速率的前提下最大化系统和速率。

Result: 仿真结果表明，相比传统的RIS-RSMA和RSMA方案，ORIS-RSMA方法能够实现更高的系统和速率性能。

Conclusion: ORIS-RSMA方法通过联合优化RIS元件数量和功率分配，有效提升了RIS辅助RSMA系统的和速率性能，验证了所提方法的有效性。

Abstract: This paper proposes power allocation and the number of reconfigurable
intelligent surfaces (RIS) elements optimisation in a RIS-assisted rate
splitting multiple access (RSMA) system. The optimised RIS-RSMA (ORIS-RSMA)
method determines the optimal number of RIS elements and the power allocation
factors for both common and private parts of a message. Additionally, it
maximises the sum rate while ensuring that a target common rate is satisfied.
The performance of the proposed ORIS-RSMA is compared to that of the
conventional RIS-RSMA and RSMA. Simulation results show that ORIS-RSMA achieves
a higher sum rate.

</details>


### [24] [Detecting Multiple Targets with Distributed Sensing and Communication in Cell-Free Massive MIMO](https://arxiv.org/abs/2507.17441)
*Zinat Behdad,Ozlem Tugfe Demir,Ki Won Sung,Cicek Cavdar*

Main category: eess.SP

TL;DR: 该论文研究了在无小区大规模MIMO框架下的集成感知通信系统中的多目标检测问题，提出了用户中心化通信和分布式感知方案，通过加权信号干扰比和功率分配算法来平衡通信-感知权衡。


<details>
  <summary>Details</summary>
Motivation: 在集成感知通信(ISAC)系统中，需要在无小区大规模MIMO环境下实现高效的多目标检测，同时平衡通信和感知性能之间的权衡关系。

Method: 采用用户中心化的通信方案和分布式感知方案；提出启发式接入点模式选择算法和基于信道感知的分布式感知方案；使用基于接收信号干扰比(SIR)的加权测量；应用最大后验比检验(MAPRT)检测器；开发功率分配算法来联合最大化最小检测概率和通信信干噪比。

Result: 所提出的加权方案优于非加权方法；增加更多接收接入点的测试统计量可能由于信道较弱而降低感知性能，但可通过优化加权指数来缓解；为感知区域分配更多感知接收接入点会导致最小通信SINR损失约10dB。

Conclusion: 该研究成功实现了无小区大规模MIMO框架下ISAC系统的多目标检测，通过智能的功率分配和加权策略有效平衡了通信与感知性能，为未来6G网络的集成感知通信提供了有价值的解决方案。

Abstract: This paper investigates multi-target detection in an integrated sensing and
communication (ISAC) system within a cell-free massive MIMO (CF-mMIMO)
framework. We adopt a user-centric approach for communication user equipments
(UEs) and a distributed sensing approach for multi-target detection. A
heuristic access point (AP) mode selection algorithm and a channel-aware
distributed sensing scheme are proposed, where local measurements at receive
APs (RX-APs) are weighted based on the received signals signal-to-interference
ratio (SIR). A maximum a posteriori ratio test (MAPRT) detector is applied
under two awareness levels at RX-APs. To balance the communication-sensing
trade-off, we develop a power allocation algorithm to jointly maximize the
minimum detection probability and communication
signal-to-interference-plus-noise ratio (SINR) while satisfying power
constraints. The proposed scheme outperforms non-weighted methods. Adding test
statistics from more RX-APs can degrade sensing performance due to weaker
channels, but this effect can be mitigated by optimizing the weighting
exponent. Additionally, assigning more sensing RX-APs to a sensing area results
in approximately 10 dB loss in minimum communication SINR due to limited
communication resources.

</details>


### [25] [Slow Fluid Antenna Multiple Access with Multiport Receivers](https://arxiv.org/abs/2507.17505)
*José P. González-Coma,F. Javier López-Martínez*

Main category: eess.SP

TL;DR: 本文研究了为流体天线接收器配备多条射频链是否能改善慢流体天线多址接入技术的性能，提出了端口选择矩阵和合并向量的联合设计方案。


<details>
  <summary>Details</summary>
Motivation: 传统的慢流体天线多址接入技术仅在接收端可获得信道状态信息，性能受限。研究者希望通过为流体天线接收器配备多条射频链来提升系统性能，探索多端口接收在有限射频链条件下的潜力。

Method: 分析配备多端口接收器的慢流体天线多址接入用户场景，选择流体天线的L个端口并进行合并以减少干扰。提出端口选择矩阵和各接收器合并向量的联合设计方法。

Result: 联合设计方案相比参考方案获得了显著的性能提升，证明了在射频链数量有限的流体天线系统中多端口接收的有效性。

Conclusion: 多端口接收技术能够有效改善慢流体天线多址接入系统的性能，通过合理的端口选择和信号合并设计可以在有限的射频链条件下实现性能优化。

Abstract: We investigate whether equipping fluid-antenna (FA) receivers with multiple
($L>1$) radiofrequency (RF) chains can improve the performance of the slow
fluid-antenna multiple access (FAMA) technique, which enables open-loop
connectivity with channel state information (CSI) available only at the
receiver side. We analyze the case of slow-FAMA users equipped with multiport
receivers, so that $L$ ports of the FA are selected and combined to reduce
interference. We show that a joint design of the port selection matrix and the
combining vector at each receiver yields significant performance gains over
reference schemes, demonstrating the potential of multiport reception in FA
systems with a limited number of RF chains.

</details>


### [26] [Joint Multi-Target Detection-Tracking in Cognitive Massive MIMO Radar via POMCP](https://arxiv.org/abs/2507.17506)
*Imad Bouhou,Stefano Fortunati,Leila Gharsalli,Alexandre Renaux*

Main category: eess.SP

TL;DR: 本文提出了一个功率感知的认知雷达框架，用于在大规模MIMO雷达环境中对多目标进行联合检测和跟踪。该方法扩展了基于部分可观测蒙特卡洛规划(POMCP)的单目标算法到多目标场景，通过自适应波形设计和功率分配来提高弱目标的检测概率和跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 在大规模MIMO雷达环境中，传统的均匀功率分配方法在面对不同信噪比的多目标时往往是次优的。需要一个能够自适应分配发射功率，优先检测弱目标或远距离目标，同时确保高信噪比目标有足够功率的智能雷达系统。

Method: 将基于POMCP的单目标算法扩展到多目标场景，为每个目标分配独立的POMCP树。基于目标的估计距离和雷达散射截面预测其未来角位置和期望接收功率，通过约束优化问题进行自适应波形设计，合理分配发射能量。同时修改部分可观测马尔可夫决策过程中的奖励函数以优先考虑精确的空间和功率估计。

Result: 仿真结果显示，与使用均匀或正交波形的方法相比，该框架提高了低信噪比目标的检测概率，实现了更准确的跟踪性能。证明了基于POMCP框架在自适应、高效多目标雷达系统中的潜力。

Conclusion: 提出的功率感知认知雷达框架成功解决了多目标检测和跟踪中的功率分配问题，通过智能的自适应波形设计显著改善了系统性能，为未来认知雷达系统的发展提供了有效的解决方案。

Abstract: This correspondence presents a power-aware cognitive radar framework for
joint detection and tracking of multiple targets in a massive multiple-input
multiple-output (MIMO) radar environment. Building on a previous single-target
algorithm based on Partially Observable Monte Carlo Planning (POMCP), we extend
it to the multi-target case by assigning each target an independent POMCP tree,
enabling scalable and efficient planning.
  Departing from uniform power allocation-which is often suboptimal with
varying signal-to-noise ratios (SNRs)-our approach predicts each target's
future angular position and expected received power, based on its estimated
range and radar cross-section (RCS). These predictions guide adaptive waveform
design via a constrained optimization problem that allocates transmit energy to
enhance the detectability of weaker or distant targets, while ensuring
sufficient power for high-SNR targets. The reward function in the underlying
partially observable Markov decision process (POMDP) is also modified to
prioritize accurate spatial and power estimation.
  Simulations involving multiple targets with different SNRs confirm the
effectiveness of our method. The proposed framework for the cognitive radar
improves detection probability for low-SNR targets and achieves more accurate
tracking compared to approaches using uniform or orthogonal waveforms. These
results demonstrate the potential of the POMCP-based framework for adaptive,
efficient multi-target radar systems.

</details>


### [27] [SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices](https://arxiv.org/abs/2507.17623)
*Guangteng Liu,Xiayue Liu,Zhixiang Xu,Yufeng Yuan,Hui Zhao,Yuxuan Liu,Yufei Jiang*

Main category: eess.SP

TL;DR: 本文提出了一个单天线Wi-Fi感知框架(SA-WiSense)，通过跨子载波信道状态信息比值(CSCR)方法和遗传算法子载波选择(GASS)技术，解决了Wi-Fi呼吸监测中的盲点问题，在8米距离内实现了91.2%的检测率。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知技术在非接触式人体呼吸监测方面具有前景，但面临由随机相位偏移引起的盲点问题，这会破坏呼吸信号的互补性。现有方法多采用多天线系统，成本较高且不适用于大多数配备单天线的物联网设备。

Method: 提出SA-WiSense框架，包含两个关键技术：1)跨子载波信道状态信息比值(CSCR)盲点缓解方法，利用子载波间CSI值的比值来消除随机相位偏移；2)基于遗传算法的子载波选择(GASS)方法，通过优化感知信噪比(SSNR)来选择最优子载波组合。

Result: 使用ESP32微控制器进行实验验证，在最远8.0米距离内实现了91.2%的呼吸检测率，显著优于现有单天线方法的性能表现。

Conclusion: SA-WiSense框架成功解决了单天线Wi-Fi感知中的盲点问题，通过CSCR方法消除随机相位偏移，恢复信号固有互补性，结合GASS优化实现了高精度呼吸监测，为低成本物联网应用提供了可行的解决方案。

Abstract: Wi-Fi sensing offers a promising technique for contactless human respiration
monitoring. A key challenge, however, is the blind spot problem caused by
random phase offsets that corrupt the complementarity of respiratory signals.
To address the challenge, we propose a single-antenna-Wi-Fi-sensing
(SA-WiSense) framework to improve accuracy of human respiration monitoring,
robust against random phase offsets. The proposed SA-WiSense framework is
cost-efficient, as only a single antenna is used rather than multiple antennas
as in the previous works. Therefore, the proposed framework is applicable to
Internet of Thing (IoT), where most of sensors are equipped with a single
antenna. On one hand, we propose a cross-subcarrier channel state information
(CSI) ratio (CSCR) based blind spot mitigation approach for IoT, where the
ratios of two values of CSI between subcarriers are leveraged to mitigate
random phase offsets. We prove that the random phase offsets can be cancelled
by the proposed CSCR approach, thereby restoring the inherent complementarity
of signals for blind-spot-free sensing. On the other hand, we propose a genetic
algorithm (GA) based subcarrier selection (GASS) approach by formulating an
optimization problem in terms of the sensing-signal-to-noise ratio (SSNR) of
CSCR between subcarriers. GA is utilized to solve the formulated optimization
problem. We use commodity ESP32 microcontrollers to build an experiment test.
The proposed works are validated to achieve an detection rate of 91.2% for
respiration monitoring at distances up to 8.0 meters, substantially more
accurate than the state-of-the-art methods with a single antenna.

</details>


### [28] [Quaternion-Domain Super MDS for Robust 3D Localization](https://arxiv.org/abs/2507.17645)
*Alessio Lukaj,Keigo Masuoka,Takumi Takahashi,Giuseppe Thadeu Freitas de Abreu,Hideki Ochiai*

Main category: eess.SP

TL;DR: 提出了一种基于四元数代数的三维无线传感器网络定位算法QD-SMDS，通过构建秩1的Gram边核矩阵整合距离和角度信息，提高了定位精度并降低了计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统的SMDS算法在实域中运行，在面对测量误差时鲁棒性不足，且计算复杂度较高。需要一种能够更好地处理三维定位问题、提高抗噪声能力并降低计算成本的新方法

Method: 将原本在实域中的SMDS算法重新表述为四元数域形式，用四元数表示3D坐标，构建秩1的Gram边核(GEK)矩阵来整合节点间的相对距离和角度信息。通过奇异值分解(SVD)进行低秩截断以增强降噪效果。还提出了一个变体算法，利用四元数域GEK矩阵的固有结构，仅通过矩阵乘法直接估计节点坐标，避免了计算昂贵的SVD

Result: 仿真结果表明，与原始SMDS算法相比，所提方法显著提高了定位精度，特别是在存在大量测量误差的场景中表现更优。不需要SVD的变体算法也能达到相当的定位精度

Conclusion: QD-SMDS算法成功地将四元数代数应用于三维定位问题，通过整合距离和角度信息提高了定位精度和鲁棒性，同时提供了低计算复杂度的实现方案，为无线传感器网络的三维定位提供了有效的解决方案

Abstract: This paper proposes a novel low-complexity three-dimensional (3D)
localization algorithm for wireless sensor networks, termed quanternion-domain
super multi-dimensional scaling (QD-SMDS). The algorithm is based on a
reformulation of the SMDS, originally developed in the real domain, using
quaternion algebra. By representing 3D coordinates as quaternions, the method
constructs a rank-1 Gram edge kernel (GEK) matrix that integrates both relative
distance and angular information between nodes, which enhances the noise
reduction effect achieved through low-rank truncation employing singular value
decomposition (SVD), thereby improving robustness against information loss. To
further reduce computational complexity, we also propose a variant of QD-SMDS
that eliminates the need for the computationally expensive SVD by leveraging
the inherent structure of the quaternion-domain GEK matrix. This alternative
directly estimates node coordinates using only matrix multiplications within
the quaternion domain. Simulation results demonstrate that the proposed method
significantly improves localization accuracy compared to the original SMDS
algorithm, especially in scenarios with substantial measurement errors. The
proposed method also achieves comparable localization accuracy without
requiring SVD.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [29] [A Hybrid CNN-VSSM model for Multi-View, Multi-Task Mammography Analysis: Robust Diagnosis with Attention-Based Fusion](https://arxiv.org/abs/2507.16955)
*Yalda Zafari,Roaa Elalfy,Mohamed Mabrok,Somaya Al-Maadeed,Tamer Khattab,Essam A. Rashed*

Main category: eess.IV

TL;DR: 提出了一种新颖的多视图多任务混合深度学习框架，用于乳腺X线摄影筛查，通过结合CNN和视觉状态空间模型(VSSM)来同时预测诊断标签和BI-RADS评分，在多个分类任务中均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法存在局限性，主要集中在单视图输入或单任务输出上，限制了临床实用性。乳腺癌筛查中的乳腺X线摄影解读仍然是一个复杂挑战，存在细微的影像学发现和诊断模糊性问题。

Method: 提出了一种多视图多任务混合深度学习框架，处理所有四个标准乳腺X线摄影视图，联合预测每个乳房的诊断标签和BI-RADS评分。架构整合了混合CNN VSSM骨干网络，结合卷积编码器进行丰富的局部特征提取和视觉状态空间模型捕获全局上下文依赖关系。还融入了基于门控注意力的融合模块，动态权衡跨视图信息。

Result: 在二分类BI-RADS 1 vs. 5任务中，共享混合模型达到了0.9967的AUC和0.9830的F1分数。在更具挑战性的三分类任务中，F1分数达到0.7790，而在五分类BI-RADS任务中，最佳F1分数达到0.4904。混合模型在所有任务中都持续优于基线模型。

Conclusion: 研究结果突出了所提出混合框架的有效性，强调了多任务学习在改善诊断性能和实现有临床意义的乳腺X线摄影分析方面的潜力和局限性。该框架通过处理多视图输入和联合预测多个输出，提高了乳腺癌筛查的鲁棒性和可解释性。

Abstract: Early and accurate interpretation of screening mammograms is essential for
effective breast cancer detection, yet it remains a complex challenge due to
subtle imaging findings and diagnostic ambiguity. Many existing AI approaches
fall short by focusing on single view inputs or single-task outputs, limiting
their clinical utility. To address these limitations, we propose a novel
multi-view, multitask hybrid deep learning framework that processes all four
standard mammography views and jointly predicts diagnostic labels and BI-RADS
scores for each breast. Our architecture integrates a hybrid CNN VSSM backbone,
combining convolutional encoders for rich local feature extraction with Visual
State Space Models (VSSMs) to capture global contextual dependencies. To
improve robustness and interpretability, we incorporate a gated attention-based
fusion module that dynamically weights information across views, effectively
handling cases with missing data. We conduct extensive experiments across
diagnostic tasks of varying complexity, benchmarking our proposed hybrid models
against baseline CNN architectures and VSSM models in both single task and
multi task learning settings. Across all tasks, the hybrid models consistently
outperform the baselines. In the binary BI-RADS 1 vs. 5 classification task,
the shared hybrid model achieves an AUC of 0.9967 and an F1 score of 0.9830.
For the more challenging ternary classification, it attains an F1 score of
0.7790, while in the five-class BI-RADS task, the best F1 score reaches 0.4904.
These results highlight the effectiveness of the proposed hybrid framework and
underscore both the potential and limitations of multitask learning for
improving diagnostic performance and enabling clinically meaningful mammography
analysis.

</details>


### [30] [Harmonization in Magnetic Resonance Imaging: A Survey of Acquisition, Image-level, and Feature-level Methods](https://arxiv.org/abs/2507.16962)
*Qinqin Yang,Firoozeh Shomal-Zadeh,Ali Gholipour*

Main category: eess.IV

TL;DR: 这篇论文是一篇关于医学图像协调化的综述，重点关注如何消除不同扫描仪、采集协议或成像站点之间的"批次效应"，以提高数据的可比性和一致性，特别聚焦于磁共振成像(MRI)领域的方法学进展。


<details>
  <summary>Details</summary>
Motivation: 不同扫描仪、采集协议或成像站点收集的医学成像数据存在显著的异质性，即"批次效应"或"站点效应"。这些非生物学变异源会掩盖真正的生物信号，降低可重复性和统计功效，严重影响基于学习的模型在数据集间的泛化能力。

Method: 论文系统性地涵盖了完整的成像流水线，将协调化方法分类为：前瞻性采集和重建策略、回顾性图像级和特征级方法，以及基于巡回受试者的技术。重点介绍了代表性方法，特别强调基于深度学习的方法。

Result: 论文提供了医学图像协调化领域的关键概念、方法学进展、公开可用数据集的全面概述，系统性地回顾了该领域的现状和发展。

Conclusion: 论文总结了该领域仍存在的主要挑战，并概述了未来研究的有前景方向。图像协调化技术对于消除站点相关偏差、保持有意义的生物信息、提高数据可比性和一致性具有重要意义。

Abstract: Modern medical imaging technologies have greatly advanced neuroscience
research and clinical diagnostics. However, imaging data collected across
different scanners, acquisition protocols, or imaging sites often exhibit
substantial heterogeneity, known as "batch effects" or "site effects". These
non-biological sources of variability can obscure true biological signals,
reduce reproducibility and statistical power, and severely impair the
generalizability of learning-based models across datasets. Image harmonization
aims to eliminate or mitigate such site-related biases while preserving
meaningful biological information, thereby improving data comparability and
consistency. This review provides a comprehensive overview of key concepts,
methodological advances, publicly available datasets, current challenges, and
future directions in the field of medical image harmonization, with a focus on
magnetic resonance imaging (MRI). We systematically cover the full imaging
pipeline, and categorize harmonization approaches into prospective acquisition
and reconstruction strategies, retrospective image-level and feature-level
methods, and traveling-subject-based techniques. Rather than providing an
exhaustive survey, we focus on representative methods, with particular emphasis
on deep learning-based approaches. Finally, we summarize the major challenges
that remain and outline promising avenues for future research.

</details>


### [31] [MyGO: Make your Goals Obvious, Avoiding Semantic Confusion in Prostate Cancer Lesion Region Segmentation](https://arxiv.org/abs/2507.17269)
*Zhengcheng Lin,Zuobin Ying,Zhenyu Li,Zhenyu Liu,Jian Lu,Weiping Ding*

Main category: eess.IV

TL;DR: 提出了一种新颖的像素锚点模块用于前列腺癌病灶分割，通过捕获全局上下文信息和Top_k选择策略来解决语义混淆问题，在PI-CAI数据集上取得了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌的早期诊断和准确的病灶定位对制定有效治疗策略至关重要，但由于病灶区域和非病灶区域之间存在高度语义同质性，现有医学图像分割方法难以准确理解病灶语义，导致语义混淆问题。

Method: 提出像素锚点模块(Pixel Anchor Module)，引导模型发现稀疏的特征锚点集合来捕获和解释全局上下文信息；设计基于自注意力的Top_k选择策略来进一步优化特征锚点识别；结合焦点损失函数来缓解类别不平衡问题。

Result: 在PI-CAI数据集上达到最先进性能，IoU得分为69.73%，Dice得分为74.32%，显著改善了前列腺癌病灶检测效果。

Conclusion: 所提出的方法通过像素锚点模块有效解决了前列腺癌图像分割中的语义混淆问题，增强了模型的非线性表示能力，提高了病灶区域的分割精度，为前列腺癌的精准诊断提供了有效的技术支持。

Abstract: Early diagnosis and accurate identification of lesion location and
progression in prostate cancer (PCa) are critical for assisting clinicians in
formulating effective treatment strategies. However, due to the high semantic
homogeneity between lesion and non-lesion areas, existing medical image
segmentation methods often struggle to accurately comprehend lesion semantics,
resulting in the problem of semantic confusion. To address this challenge, we
propose a novel Pixel Anchor Module, which guides the model to discover a
sparse set of feature anchors that serve to capture and interpret global
contextual information. This mechanism enhances the model's nonlinear
representation capacity and improves segmentation accuracy within lesion
regions. Moreover, we design a self-attention-based Top_k selection strategy to
further refine the identification of these feature anchors, and incorporate a
focal loss function to mitigate class imbalance, thereby facilitating more
precise semantic interpretation across diverse regions. Our method achieves
state-of-the-art performance on the PI-CAI dataset, demonstrating 69.73% IoU
and 74.32% Dice scores, and significantly improving prostate cancer lesion
detection.

</details>


### [32] [A Versatile Pathology Co-pilot via Reasoning Enhanced Multimodal Large Language Model](https://arxiv.org/abs/2507.17303)
*Zhe Xu,Ziyi Liu,Junlin Hou,Jiabo Ma,Cheng Jin,Yihui Wang,Zhixuan Chen,Zhengyu Zhang,Zhengrui Guo,Fengtao Zhou,Yingxue Xu,Xi Wang,Ronald Cheong Kin Chan,Li Liang,Hao Chen*

Main category: eess.IV

TL;DR: SmartPath-R1是一个多模态大语言模型，能够同时处理病理图像的ROI级别和WSI级别任务，通过规模依赖的监督微调和任务感知的强化微调，无需链式思维监督即可实现强大的病理推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在病理学中推理能力受限，主要依赖昂贵的链式思维标注，且仅限于ROI级别的视觉问答任务，无法满足临床实践中ROI分类、检测、分割、全切片图像分类等多样化诊断需求。

Method: 提出SmartPath-R1框架，结合规模依赖的监督微调和任务感知的强化微调方法，利用MLLM内在知识避免链式思维监督需求；通过专家混合机制集成多尺度和多任务分析，实现动态处理多样化任务；构建包含230万ROI样本和18.8万WSI样本的大规模数据集。

Result: 在72个任务上进行了广泛实验验证，证明了所提方法的有效性和优越性，SmartPath-R1能够同时处理ROI级别和WSI级别的各种病理学任务，展现出强大的病理推理能力。

Conclusion: SmartPath-R1代表了在开发用于精准病理学的多功能、推理增强AI系统方面的重要进步，为计算病理学中的复杂诊断任务提供了有效解决方案。

Abstract: Multimodal large language models (MLLMs) have emerged as powerful tools for
computational pathology, offering unprecedented opportunities to integrate
pathological images with language context for comprehensive diagnostic
analysis. These models hold particular promise for automating complex tasks
that traditionally require expert interpretation of pathologists. However,
current MLLM approaches in pathology demonstrate significantly constrained
reasoning capabilities, primarily due to their reliance on expensive
chain-of-thought annotations. Additionally, existing methods remain limited to
simplex application of visual question answering (VQA) at region-of-interest
(ROI) level, failing to address the full spectrum of diagnostic needs such as
ROI classification, detection, segmentation, whole-slide-image (WSI)
classification and VQA in clinical practice. In this study, we present
SmartPath-R1, a versatile MLLM capable of simultaneously addressing both
ROI-level and WSI-level tasks while demonstrating robust pathological reasoning
capability. Our framework combines scale-dependent supervised fine-tuning and
task-aware reinforcement fine-tuning, which circumvents the requirement for
chain-of-thought supervision by leveraging the intrinsic knowledge within MLLM.
Furthermore, SmartPath-R1 integrates multiscale and multitask analysis through
a mixture-of-experts mechanism, enabling dynamic processing for diverse tasks.
We curate a large-scale dataset comprising 2.3M ROI samples and 188K WSI
samples for training and evaluation. Extensive experiments across 72 tasks
validate the effectiveness and superiority of the proposed approach. This work
represents a significant step toward developing versatile, reasoning-enhanced
AI systems for precision pathology.

</details>


### [33] [Efficient and Robust Semantic Image Communication via Stable Cascade](https://arxiv.org/abs/2507.17416)
*Bilal Khalid,Pedro Freire,Sergei K. Turitsyn,Jaroslaw E. Prilepsky*

Main category: eess.IV

TL;DR: 提出了一种基于Stable Cascade启发的新型语义图像通信框架，通过极其紧凑的潜在图像嵌入作为扩散过程的条件，实现了仅0.29%的原始图像大小的数据传输，同时在噪声信道条件下获得了优越的重建质量和显著的计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语义图像通信系统中面临推理速度慢和生成随机性等重大挑战，限制了其可靠性和实用性，需要开发新的框架来克服这些问题。

Method: 提出了受Stable Cascade启发的新型语义图像通信框架，使用极其紧凑的潜在图像嵌入作为扩散过程的条件，大幅降低数据传输开销。

Result: 该方法将传输嵌入压缩至原始图像大小的仅0.29%，在多项指标验证下，在噪声信道条件下的重建质量超越了三种基准方法（GESCO、Img2Img-SC和传统JPEG2000 + LDPC编码），同时实现了显著的计算效率提升：512x512图像重建速度提升3倍以上，1024x1024图像重建速度提升16倍以上。

Conclusion: 该框架成功解决了扩散模型在语义图像通信中的关键挑战，通过极致的数据压缩和高效的重建过程，在保证重建质量的同时大幅提升了计算效率，为实用的语义图像通信系统提供了有前景的解决方案。

Abstract: Diffusion Model (DM) based Semantic Image Communication (SIC) systems face
significant challenges, such as slow inference speed and generation randomness,
that limit their reliability and practicality. To overcome these issues, we
propose a novel SIC framework inspired by Stable Cascade, where extremely
compact latent image embeddings are used as conditioning to the diffusion
process. Our approach drastically reduces the data transmission overhead,
compressing the transmitted embedding to just 0.29% of the original image size.
It outperforms three benchmark approaches - the diffusion SIC model conditioned
on segmentation maps (GESCO), the recent Stable Diffusion (SD)-based SIC
framework (Img2Img-SC), and the conventional JPEG2000 + LDPC coding - by
achieving superior reconstruction quality under noisy channel conditions, as
validated across multiple metrics. Notably, it also delivers significant
computational efficiency, enabling over 3x faster reconstruction for 512 x 512
images and more than 16x faster for 1024 x 1024 images as compared to the
approach adopted in Img2Img-SC.

</details>


### [34] [Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography](https://arxiv.org/abs/2507.17662)
*Farnoush Bayatmakou,Reza Taleei,Nicole Simone,Arash Mohammadi*

Main category: eess.IV

TL;DR: 提出了Mammo-Mamba框架，结合选择性状态空间模型(SSMs)、Transformer注意力和专家驱动特征优化，用于乳腺癌多视角X线摄影分类，在CBIS-DDSM数据集上实现了优异性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌仍是女性癌症相关死亡的主要原因之一。虽然基于Transformer的多视角乳腺X线摄影分类模型表现出色，但其计算复杂度随图像块数量呈二次增长，需要更高效的替代方案来实现准确且高效的早期检测。

Method: 提出Mammo-Mamba框架，将选择性状态空间模型(SSMs)、基于Transformer的注意力机制和专家驱动特征优化集成到统一架构中。通过定制的SecMamba块引入序列专家混合(SeqMoE)机制，扩展了MambaVision骨干网络。SecMamba是修改版的MambaVision块，通过内容自适应特征优化增强高分辨率乳腺X线摄影图像的表示学习。

Result: 在CBIS-DDSM基准数据集上进行评估，Mammo-Mamba在所有关键指标上都实现了优异的分类性能，同时保持了计算效率。相比传统Transformer模型，有效缓解了其局限性。

Conclusion: Mammo-Mamba框架成功解决了传统Transformer模型在多视角乳腺X线摄影分类中的计算复杂度问题，通过创新的SSMs和专家混合机制，在保持高效计算的同时实现了卓越的分类性能，为乳腺癌早期检测提供了有效的AI辅助诊断解决方案。

Abstract: Breast cancer (BC) remains one of the leading causes of cancer-related
mortality among women, despite recent advances in Computer-Aided Diagnosis
(CAD) systems. Accurate and efficient interpretation of multi-view mammograms
is essential for early detection, driving a surge of interest in Artificial
Intelligence (AI)-powered CAD models. While state-of-the-art multi-view
mammogram classification models are largely based on Transformer architectures,
their computational complexity scales quadratically with the number of image
patches, highlighting the need for more efficient alternatives. To address this
challenge, we propose Mammo-Mamba, a novel framework that integrates Selective
State-Space Models (SSMs), transformer-based attention, and expert-driven
feature refinement into a unified architecture. Mammo-Mamba extends the
MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE)
mechanism through its customized SecMamba block. The SecMamba is a modified
MambaVision block that enhances representation learning in high-resolution
mammographic images by enabling content-adaptive feature refinement. These
blocks are integrated into the deeper stages of MambaVision, allowing the model
to progressively adjust feature emphasis through dynamic expert gating,
effectively mitigating the limitations of traditional Transformer models.
Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior
classification performance across all key metrics while maintaining
computational efficiency.

</details>


### [35] [MCM: Mamba-based Cardiac Motion Tracking using Sequential Images in MRI](https://arxiv.org/abs/2507.17678)
*Jiahui Yin,Xinxing Cheng,Jinming Duan,Yan Pang,Declan O'Regan,Hadrien Reynaud,Qingjie Meng*

Main category: eess.IV

TL;DR: 提出了一种基于Mamba的心肌运动追踪网络(MCM)，通过利用心动周期中的连续图像序列来实现平滑且时间一致的心肌运动追踪，相比现有方法显著提升了追踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有心肌运动追踪方法主要基于单一图像对进行学习，忽略了心肌运动的连续性特征，导致运动估计不一致且不平滑的问题。

Method: 开发了基于Mamba的心肌运动追踪网络，包含双向Mamba块和双向扫描机制来估计合理的变形场，以及运动解码器整合相邻帧的运动信息以增强时间连贯性，利用Mamba的结构化状态空间公式从序列图像中学习心肌的连续动力学。

Result: 在两个公共数据集上的实验结果表明，该方法在定量和定性方面都优于传统方法和最先进的基于学习的心肌运动追踪方法。

Conclusion: 提出的MCM网络通过显式整合心动周期中的目标图像序列，成功实现了平滑且时间一致的心肌运动追踪，为心脏功能评估和心血管疾病诊断提供了更可靠的技术方案。

Abstract: Myocardial motion tracking is important for assessing cardiac function and
diagnosing cardiovascular diseases, for which cine cardiac magnetic resonance
(CMR) has been established as the gold standard imaging modality. Many existing
methods learn motion from single image pairs consisting of a reference frame
and a randomly selected target frame from the cardiac cycle. However, these
methods overlook the continuous nature of cardiac motion and often yield
inconsistent and non-smooth motion estimations. In this work, we propose a
novel Mamba-based cardiac motion tracking network (MCM) that explicitly
incorporates target image sequence from the cardiac cycle to achieve smooth and
temporally consistent motion tracking. By developing a bi-directional Mamba
block equipped with a bi-directional scanning mechanism, our method facilitates
the estimation of plausible deformation fields. With our proposed motion
decoder that integrates motion information from frames adjacent to the target
frame, our method further enhances temporal coherence. Moreover, by taking
advantage of Mamba's structured state-space formulation, the proposed method
learns the continuous dynamics of the myocardium from sequential images without
increasing computational complexity. We evaluate the proposed method on two
public datasets. The experimental results demonstrate that the proposed method
quantitatively and qualitatively outperforms both conventional and
state-of-the-art learning-based cardiac motion tracking methods. The code is
available at https://github.com/yjh-0104/MCM.

</details>
