<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 16]
- [eess.SP](#eess.SP) [Total: 15]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Study of Switched Step-size Based Filtered-x NLMS Algorithm for Active Noise Cancellation](https://arxiv.org/abs/2601.16382)
*Zhiyuan Li,Yi Yu,Hongsen He,Yuyu Zhu,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出两种改进的FxNLMS算法：SSS-FxNLMS通过动态选择最优步长解决收敛速度与稳态误差的权衡问题，以及增强鲁棒性的变体以应对脉冲噪声环境。


<details>
  <summary>Details</summary>
Motivation: 传统FxNLMS算法存在两个关键限制：固定步长导致收敛速度与稳态残差之间的权衡，以及在脉冲噪声环境下性能显著恶化。

Method: 1) 推导FxNLMS算法的均方偏差趋势；2) 通过比较不同步长的MSD趋势，为每次迭代选择最优步长，提出SSS-FxNLMS算法；3) 将鲁棒策略集成到SSS-FxNLMS中，形成鲁棒变体。

Result: 通过计算机仿真在不同噪声场景下验证了所提算法的有效性和优越性。

Conclusion: 提出的SSS-FxNLMS算法及其鲁棒变体成功解决了传统FxNLMS算法的步长约束问题和脉冲噪声敏感性，提升了主动噪声控制系统的性能。

Abstract: While the filtered-x normalized least mean square (FxNLMS) algorithm is widely applied due to its simple structure and easy implementation for active noise control system, it faces two critical limitations: the fixed step-size causes a trade-off between convergence rate and steady-state residual error, and its performance deteriorates significantly in impulsive noise environments. To address the step-size constraint issue, we propose the switched \mbox{step-size} FxNLMS (SSS-FxNLMS) algorithm. Specifically, we derive the \mbox{mean-square} deviation (MSD) trend of the FxNLMS algorithm, and then by comparing the MSD trends corresponding to different \mbox{step-sizes}, the optimal step-size for each iteration is selected. Furthermore, to enhance the algorithm's robustness in impulsive noise scenarios, we integrate a robust strategy into the SSS-FxNLMS algorithm, resulting in a robust variant of it. The effectiveness and superiority of the proposed algorithms has been confirmed through computer simulations in different noise scenarios.

</details>


### [2] [Two classes of LCD codes derived from $(\mathcal{L},\mathcal{P})$-TGRS codes](https://arxiv.org/abs/2601.16438)
*Ziwei Zhao,Xiaoni DU,Xingbin Qiao*

Main category: cs.IT

TL;DR: 该论文从扭曲广义Reed-Solomon码构造了两类LCD码，并进一步得到LCD MDS码，给出了具体条件和示例。


<details>
  <summary>Details</summary>
Motivation: 扭曲广义Reed-Solomon码作为经典GRS码的灵活扩展，近年来受到广泛关注。LCD码（线性互补对偶码）在密码学和编码理论中有重要应用，但如何从TGRS码构造LCD码，特别是LCD MDS码，是一个值得研究的问题。

Method: 1. 研究长度为n、维度为k的$(\mathcal{L},\mathcal{P})$-TGRS码$\mathcal{C}_h$，其中$\mathcal{L}=\{0,1,\ldots,l\}$（$l\leq n-k-1$），$\mathcal{P}=\{h\}$（$1\leq h\leq k-1$）
2. 推导$\mathcal{C}_h$的奇偶校验矩阵
3. 给出$\mathcal{C}_h$成为AMDS码的充要条件
4. 通过适当选择评估点并对扭曲项多项式$x^{h-1}$系数施加限制，从$\mathcal{C}_h$构造两类LCD码
5. 从构造的LCD码进一步得到两类LCD MDS码

Result: 1. 得到了$\mathcal{C}_h$的奇偶校验矩阵
2. 给出了$\mathcal{C}_h$成为AMDS码的充要条件
3. 成功构造了两类LCD码
4. 进一步得到了两类LCD MDS码
5. 提供了多个具体示例验证构造的有效性

Conclusion: 该论文系统研究了从扭曲广义Reed-Solomon码构造LCD码的方法，不仅给出了理论条件，还得到了LCD MDS码，为编码理论和密码学应用提供了新的构造方案。

Abstract: Twisted generalized Reed-Solomon (TGRS) codes, as a flexible extension of classical generalized Reed-Solomon (GRS) codes, have attracted significant attention in recent years. In this paper, we construct two classes of LCD codes from the $(\mathcal{L},\mathcal{P})$-TGRS code $\mathcal{C}_h$ of length $n$ and dimension $k$, where $\mathcal{L}=\{0,1,\ldots,l\}$ for $l\leq n-k-1$ and $\mathcal{P}=\{h\}$ for $1\leq h\leq k-1$. First, we derive the parity check matrix of $\mathcal{C}_h$ and provide a necessary and sufficient condition for $\mathcal{C}_h$ to be an AMDS code. Then, we construct two classes of LCD codes from $\mathcal{C}_h$ by suitably choosing the evaluation points together with certain restrictions on the coefficient of $x^{h-1}$ in the polynomial associated with the twisting term. From the constructed LCD codes we further obtain two classes of LCD MDS codes. Finally, several examples are presented.

</details>


### [3] [Cramér-Rao Bound Minimization for Flexible Intelligent Metasurface-Enabled ISAC Systems](https://arxiv.org/abs/2601.16455)
*Qian Zhang,Yufei Zhao,Jiancheng An,Zheng Dong,Yong Liang Guan,Ju Liu,Chau Yuen*

Main category: cs.IT

TL;DR: 该论文首次研究了柔性智能超表面(FIM)使能的ISAC系统中的CRB最小化问题，通过优化FIM表面形状和波束成形，显著降低了感知CRB同时保持通信质量。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)被认为是未来无线网络的关键使能技术，其中克拉美-罗界(CRB)在量化感知精度中起核心作用。然而，在柔性智能超表面(FIM)使能的ISAC系统中，如何最小化CRB尚未得到研究。

Method: 1. 推导了明确依赖于FIM表面形状的平均CRB表达式；2. 采用平均Fisher信息最大化作为替代目标，使用Gauss-Hermite求积法获得目标函数的显式近似；3. 将问题分解为三个子问题：波束成形优化、发射/接收FIM表面形状优化；4. 使用Schur补和基于惩罚的半定松弛技术进行波束成形优化；5. 提出定点方程法和投影梯度算法分别优化接收和发射FIM的表面形状。

Result: 仿真结果表明，与刚性阵列相比，发射和接收FIM的表面形状优化可以显著降低平均感知CRB，同时保持通信质量，并且在多目标场景中仍然有效。

Conclusion: 这是首次研究FIM使能ISAC系统中的CRB最小化问题，证明了FIM表面形状优化能够显著提升感知性能，为未来无线网络中的ISAC系统设计提供了重要指导。

Abstract: Integrated sensing and communication (ISAC) have been widely recognized as a key enabler for future wireless networks, where the Cramér-Rao bound (CRB) plays a central role in quantifying sensing accuracy.In this paper, we present the first study on CRB minimization in flexible intelligent metasurface (FIM)-enabled ISAC systems.Specifically, we first derive an average CRB expression that explicitly depends on FIM surface shape and demonstrate that array reconfigurability can substantially reduce the CRB, thereby significantly enhancing sensing performance.Moreover, to tackle the challenging CRB minimization problem, we adopt average Fisher information maximization as a surrogate objective and use the Gauss-Hermite quadrature method to obtain an explicit approximation of the objective function.The resulting problem is then decoupled into three subproblem, i.e., beamforming optimization and transmit/receive FIM surface shape optimization.For beamforming optimization, we employ the Schur complement and penalty-based semi-definite relaxation (SDR) technique to solve it.Furthermore, we propose a fixed-point equation method and a projected gradient algorithm to optimize the surface shapes of the receive and transmit FIMs, respectively.Simulation results demonstrate that, compared to rigid arrays, surface shaping of both transmit and receive FIMs can significantly reduce the average sensing CRB while maintaining communication quality, and remains effective even in multi-target scenarios.

</details>


### [4] [Log-Likelihood Loss for Semantic Compression](https://arxiv.org/abs/2601.16461)
*Anuj Kumar Yadav,Dan Song,Yanina Shkel,Ayfer Özgür*

Main category: cs.IT

TL;DR: 该论文研究基于指定条件分布P_{X|U}负对数似然定义的失真度量下的有损信源编码，这种对数似然失真建模了压缩场景，其中重建是语义表示而非逐点近似。


<details>
  <summary>Details</summary>
Motivation: 传统有损压缩通常关注逐点近似失真，但许多实际应用需要重建语义表示，从该表示可以概率生成源数据。对数似然失真提供了一种建模这种语义压缩场景的框架。

Method: 提出基于指定条件分布P_{X|U}负对数似然定义的失真度量，制定相应的率失真问题，并分析所得率失真函数的基本性质。

Result: 建立了对数似然失真率失真函数与对数损失下的有损压缩、任意失真度量的经典率失真问题以及完美感知率失真之间的理论联系。

Conclusion: 对数似然失真为语义压缩提供了一种统一的数学框架，连接了多种压缩范式，为从语义表示概率生成源数据的压缩场景提供了理论基础。

Abstract: We study lossy source coding under a distortion measure defined by the negative log-likelihood induced by a prescribed conditional distribution $P_{X|U}$. This \emph{log-likelihood distortion} models compression settings in which the reconstruction is a semantic representation from which the source can be probabilistically generated, rather than a pointwise approximation. We formulate the corresponding rate-distortion problem and characterize fundamental properties of the resulting rate-distortion function, including its connections to lossy compression under log-loss, classical rate-distortion problems with arbitrary distortion measures, and rate-distortion with perfect perception.

</details>


### [5] [Load Balanced ISAC Systems for URLLC Users](https://arxiv.org/abs/2601.16495)
*Shivani Singh,Amudheesan Nakkeeran,Prem Singh,Ekant Sharma,Jyotsna Bapat*

Main category: cs.IT

TL;DR: 提出一种用于集成感知与通信的能效型无小区大规模MIMO网络，通过联合功率分配和接入点负载均衡算法，在满足URLLC用户通信质量和目标检测感知需求的同时，降低约33%的总功耗。


<details>
  <summary>Details</summary>
Motivation: 随着5G/6G网络对超可靠低时延通信(URLLC)和集成感知与通信(ISAC)的需求增长，如何在满足通信和感知服务质量的同时降低网络能耗成为关键挑战。传统方法缺乏有效的负载均衡机制，导致功率消耗较高。

Method: 提出联合功率分配和AP负载均衡(JPALB)算法，将问题建模为混合整数非凸优化问题，采用迭代方法同时优化功率分配和接入点负载均衡。算法支持最大比传输(MRT)和正则化迫零(RZF)预编码器。

Result: 仿真结果显示，与无负载均衡的基准方案相比，JPALB算法在保持通信和感知服务质量的前提下，实现了约33%的总功耗降低。

Conclusion: 所提出的JPALB算法能有效平衡无小区大规模MIMO ISAC网络的功率消耗和负载分布，在满足URLLC通信和目标检测需求的同时显著提升能效，为未来ISAC网络设计提供了实用解决方案。

Abstract: This paper presents an energy-efficient downlink cell-free massive multiple-input multiple-output (CF-mMIMO) integrated sensing and communication (ISAC) network that serves ultra-reliable low-latency communication (URLLC) users while simultaneously detecting a target. We propose a load-balancing algorithm that minimizes the total network power consumption; including transmit power, fixed static power, and traffic-dependent fronthaul power at the access points (APs) without degrading system performance. To this end, we formulate a mixed-integer non-convex optimization problem and introduce an iterative joint power allocation and AP load balancing (JPALB) algorithm. The algorithm aims to reduce total power usage while meeting both the communication quality-of-service (QoS) requirements of URLLC users and the sensing QoS needed for target detection. Proposed JPALB algorithm for ISAC systems was simulated with maximum-ratio transmission (MRT) and regularized zero-forcing (RZF) precoders. Simulation results show approximately 33% reduction in power consumption, using JPALB algorithm compared to a baseline with no load balancing, without compromising communication and sensing QoS requirements.

</details>


### [6] [Noise-immune and AI-enhanced DNA storage via adaptive partition mapping of digital data](https://arxiv.org/abs/2601.16518)
*Zimu Li,Bingyi Liu,Lei Zhao,Qian Zhang,Yang Liu,Jun Liu,Ke Ke,Huating Kong,Xiaolei Zuo,Chunhai Fan,Fei Wang*

Main category: cs.IT

TL;DR: 提出了一种名为PJ（分区映射与跳转旋转）的DNA存储编码方案，具有卓越的抗噪能力，能够在任意链丢失比例下解码原始文件信息，并通过AI推理实现可控恢复。


<details>
  <summary>Details</summary>
Motivation: DNA存储作为应对信息时代和人工智能兴起的数据存储解决方案具有吸引力，但实际应用中受到合成、保存和测序过程中引入错误的限制，传统纠错码在噪声超过预设阈值时仍然脆弱。

Method: 开发了PJ编码方案：1）通过分区映射消除跨链信息依赖，使链丢失表现为局部间隙而非灾难性文件失效；2）采用跳转旋转策略放宽序列约束，通过可调节的跳转长度提供可调信息密度；3）利用AI推理实现可控恢复。

Result: PJ编码能够在任意链丢失比例下解码和恢复原始文件信息，保真度随损坏增加而平滑下降。实验表明：即使10%链丢失也能有效恢复原始文件，存储的机器学习数据集保持分类性能；在加速老化和高强度X射线辐照的极端环境干扰下仍能成功解码图像文件。

Conclusion: PJ编码消除了对先验错误概率的依赖，建立了一个通用的稳健DNA存储框架，能够承受实际保存的严苛条件，为DNA存储的实际应用提供了重要进展。

Abstract: Encoding digital information into DNA sequences offers an attractive potential solution for storing rapidly growing data under the information age and the rise of artificial intelligence. However, practical implementations of DNA storage are constrained by errors introduced during synthesis, preservation, and sequencing processes, and traditional error-correcting codes remain vulnerable to noise levels that exceed predefined thresholds. Here, we developed a Partitioning-mapping with Jump-rotating (PJ) encoding scheme, which exhibits exceptional noise resilience. PJ removes cross-strand information dependencies so that strand loss manifests as localized gaps rather than catastrophic file failure. It prioritizes file decodability under arbitrary noise conditions and leverages AI-based inference to enable controllable recovery of digital information. For the intra-strand encoding, we develop a jump-rotating strategy that relaxes sequence constraints relative to conventional rotating codes and provides tunable information density via an adjustable jump length. Based on this encoding architecture, the original file information can always be decoded and recovered under any strand loss ratio, with fidelity degrading smoothly as damage increases. We demonstrate that original files can be effectively recovered even with 10% strand loss, and machine learning datasets stored under these conditions retain their classification performance. Experiments further confirmed that PJ successfully decodes image files after extreme environmental disturbance using accelerated aging and high-intensity X-ray irradiation. By eliminating reliance on prior error probabilities, PJ establishes a general framework for robust, archival DNA storage capable of withstanding the rigorous conditions of real-world preservation.

</details>


### [7] [Generalized Forms of the Kraft Inequality for Finite-State Encoders](https://arxiv.org/abs/2601.16594)
*Neri Merhav*

Main category: cs.IT

TL;DR: 本文推导了信息无损有限状态编码器的Kraft不等式扩展版本，定义了Kraft矩阵概念，并证明信息无损的必要条件是Kraft矩阵的特征值模不超过1，即谱半径≤1。对于不可约情况，给出了谱半径公式的等价形式，并证明Kraft和有界不随块长增长。还扩展到有边信息和有损压缩情况。


<details>
  <summary>Details</summary>
Motivation: 研究有限状态编码器的信息无损条件，扩展经典的Kraft不等式到更一般的有限状态编码场景，为编码理论提供更强大的分析工具。

Method: 定义Kraft矩阵概念，利用矩阵理论和谱分析建立广义Kraft不等式，证明信息无损的必要条件是Kraft矩阵谱半径不超过1。对于不可约情况，利用谱半径公式推导等价形式。

Result: 建立了有限状态编码器的广义Kraft不等式：信息无损的必要条件是Kraft矩阵谱半径≤1。对于不可约编码器，Kraft和有界且不随块长增长。结果可扩展到有边信息和有损压缩场景。

Conclusion: 本文成功将Kraft不等式推广到有限状态编码器，建立了基于谱半径的信息无损必要条件，为编码理论提供了新的分析框架，并展示了在更复杂编码场景中的应用潜力。

Abstract: We derive a few extended versions of the Kraft inequality for information lossless finite-state encoders. The main basic contribution is in defining a notion of a Kraft matrix and in establishing the fact that a necessary condition for information losslessness of a finite-state encoder is that none of the eigenvalues of this matrix have modulus larger than unity, or equivalently, the generalized Kraft inequality asserts that the spectral radius of the Kraft matrix cannot exceed one. For the important special case where the FS encoder is irreducible, we derive several equivalent forms of this inequality, which are based on well known formulas for spectral radius. It also turns out that in the irreducible case, Kraft sums are bounded by a constant, independent of the block length, and thus cannot grow even in any subexponential rate. Finally, two extensions are outlined - one concerns the case of side information available to both encoder and decoder, and the other is for lossy compression.

</details>


### [8] [An Explicit Upper Bound of Generalized Quadratic Gauss Sums and Its Applications for Asymptotically Optimal Aperiodic Polyphase Sequence Design](https://arxiv.org/abs/2601.16599)
*Huaning Liu,Zilong Liu*

Main category: cs.IT

TL;DR: 该论文解决了设计渐近阶次最优的非周期多相序列集这一长期开放问题，通过推导广义二次高斯和的显式上界，并基于此构建了四种具有低非周期相关性和/或模糊特性的阶次最优序列集。


<details>
  <summary>Details</summary>
Motivation: 解决设计渐近阶次最优的非周期多相序列集这一长期开放问题。虽然Mow在30多年前曾尝试解决，但对该问题的全面理解仍然缺乏。

Method: 1. 通过递归应用Paris渐近展开并利用斐波那契zeta函数的快速收敛性，推导出广义二次高斯和的显式上界；2. 基于这一关键发现，通过精心选择的Chu序列和Alltop序列，系统构建了四种具有低非周期相关性和/或模糊特性的阶次最优序列集。

Result: 1. 首次在文献中揭示了完整的Alltop序列集对其低非周期相关旁瓣是渐近最优的；2. 引入了一个新的Alltop序列子集，在整个时间偏移窗口内同时具有阶次最优的非周期相关性和模糊特性。

Conclusion: 该工作通过数学推导和系统构造，成功解决了设计渐近阶次最优非周期多相序列集的长期开放问题，为序列设计领域提供了重要的理论突破和实用构造方法。

Abstract: This work is motivated by the long-standing open problem of designing asymptotically order-optimal aperiodic polyphase sequence sets with respect to the celebrated Welch bound. Attempts were made by Mow over 30 years ago, but a comprehensive understanding to this problem is lacking. Our first key contribution is an explicit upper bound of generalized quadratic Gauss sums which is obtained by recursively applying Paris' asymptotic expansion and then bounding it by leveraging the fast convergence property of the Fibonacci zeta function. Building upon this major finding, our second key contribution includes four systematic constructions of order-optimal sequence sets with low aperiodic correlation and/or ambiguity properties via carefully selected Chu sequences and Alltop sequences. For the first time in the literature, we reveal that the full Alltop sequence set is asymptotically optimal for its low aperiodic correlation sidelobes. Besides, we introduce a novel subset of Alltop sequences possessing both order-optimal aperiodic correlation and ambiguity properties for the entire time-shift window.

</details>


### [9] [Term Coding: An Entropic Framework for Extremal Combinatorics and the Guessing--Number Sandwich Theorem](https://arxiv.org/abs/2601.16614)
*Søren Riis*

Main category: cs.IT

TL;DR: 本文提出"项编码"概念，将代数恒等式系统的解集大小问题转化为极值组合问题，通过猜测数三明治定理连接图熵，建立规范化方法计算解集大小的渐近指数。


<details>
  <summary>Details</summary>
Motivation: 将代数恒等式系统（如拟群、设计等）的解集存在性问题转化为定量极值问题，研究在给定变量数和函数符号解释下，解集的最大可能规模。

Method: 提出猜测数三明治定理连接项编码与图猜测数（图熵），通过显式规范化和多样化约简，将每个实例转化为具有猜测数α的规范有向依赖结构，利用熵和多拟阵方法计算α。

Result: 证明最大编码大小满足log_n S_n(Γ)=α+o(1)，即S_n(Γ)=n^{α+o(1)}，α可通过熵和多拟阵方法界定或计算，并用极值组合学和信息流约束实例验证框架。

Conclusion: 建立了项编码与图熵的理论连接，提供了计算代数恒等式系统解集渐近大小的系统方法，统一处理了极值组合学和信息流约束中的各类问题。

Abstract: Term Coding asks: given a finite system of term identities $Γ$ in $v$ variables, how large can its solution set be on an $n$--element alphabet, when we are free to choose the interpretations of the function symbols? This turns familiar existence problems for quasigroups, designs, and related objects into quantitative extremal questions.
  We prove a guessing-number sandwich theorem that connects term coding to graph guessing numbers (graph entropy). After explicit normalisation and diversification reductions, every instance yields a canonical directed dependency structure with guessing number $α$ such that the maximum code size satisfies $\log_n \Sn(Γ)=α+o(1)$ (equivalently, $\Sn(Γ)=n^{α+o(1)}$), and $α$ can be bounded or computed using entropy and polymatroid methods.
  We illustrate the framework with examples from extremal combinatorics (Steiner-type identities, self-orthogonal Latin squares) and from information-flow / network-coding style constraints (including a five-cycle instance with fractional exponent and small storage/relay maps).

</details>


### [10] [Taming the Heavy Tail: Age-Optimal Preemption](https://arxiv.org/abs/2601.16624)
*Aimin Li,Yiğit İnce,Elif Uysal*

Main category: cs.IT

TL;DR: 研究连续时间联合采样与抢占问题，考虑采样和抢占惩罚，提出基于脉冲控制PDMP的优化框架，开发高效策略迭代算法，在重尾服务时间下相比基准方法实现高达30倍的平均成本降低。


<details>
  <summary>Details</summary>
Motivation: 传统信息新鲜度优化通常假设无抢占或特定服务时间分布，但在实际系统中，采样和抢占都有成本，且服务时间分布可能具有重尾特性。需要开发一个能够处理一般服务时间分布、同时考虑采样和抢占惩罚的统一框架。

Method: 将系统建模为脉冲控制的分段确定性马尔可夫过程(PDMP)，通过动态规划原理推导耦合积分平均成本最优性方程，避免传统HJB-QVI所需的平滑性假设。利用繁忙阶段的动态不变性将抢占控制简化为最优停止问题，开发带有重尾加速的高效策略迭代算法，采用混合（均匀/对数间隔）动作网格和远场线性闭合技术。

Result: 在Pareto和对数正态服务时间下的仿真显示，相比AoI最优的非抢占采样和零等待基准方法，新方法在重尾机制下实现了高达30倍的平均成本降低。仿真还揭示了一个反直觉的发现：在抢占机制下，延迟方差（通常是负担）可以成为信息新鲜度的战略优势。

Conclusion: 本文提出了一个处理一般服务时间分布下联合采样与抢占问题的统一框架，通过创新的数学建模和高效算法，显著提升了信息新鲜度性能。研究不仅提供了实用的优化方法，还揭示了延迟方差在抢占系统中的战略价值，为未来网络控制系统设计提供了新见解。

Abstract: This paper studies a continuous-time joint sampling-and-preemption problem, incorporating sampling and preemption penalties under general service-time distributions. We formulate the system as an impulse-controlled piecewise-deterministic Markov process (PDMP) and derive coupled integral average-cost optimality equations via the dynamic programming principle, thereby avoiding the smoothness assumptions typically required for an average-cost Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI) characterization. A key invariance in the busy phase collapses the dynamics onto a one-dimensional busy-start boundary, reducing preemption control to an optimal stopping problem. Building on this structure, we develop an efficient policy iteration algorithm with heavy-tail acceleration, employing a hybrid (uniform/log-spaced) action grid and a far-field linear closure. Simulations under Pareto and log-normal service times demonstrate substantial improvements over AoI-optimal non-preemptive sampling and zero-wait baselines, achieving up to a 30x reduction in average cost in heavy-tailed regimes. Finally, simulations uncover a counterintuitive insight: under preemption, delay variance, despite typically being a liability, can become a strategic advantage for information freshness.

</details>


### [11] [The Oval Strikes Back](https://arxiv.org/abs/2601.16628)
*Andrea Di Giusto,Alberto Ravagnani,Emina Soljanin*

Main category: cs.IT

TL;DR: 论文研究射影平面中卵形线在分布式存储中的应用，特别是服务率区域问题，利用卵形线与直线的关联关系构造非系统MDS矩阵，获得更好的服务性能。


<details>
  <summary>Details</summary>
Motivation: 探索有限几何中的经典对象——射影平面中的卵形线——在现代编码理论中的应用价值，特别是在分布式存储系统服务率区域优化方面的潜力。

Method: 利用卵形线与直线的关联关系，构造一类具有大量小型且不相交恢复集的非系统MDS矩阵，分析其服务率区域，并应用于PIR（私有信息检索）特性分析和多数逻辑解码算法设计。

Result: 对于某些参数选择，所构造的非系统MDS矩阵的服务率区域包含相同码的系统生成矩阵的区域，提供更好的服务性能；同时展示了强纠错能力的一步多数逻辑解码算法。

Conclusion: 射影平面中的卵形线作为有限几何的经典对象，在现代编码理论中重新显现为有用的工具，特别是在分布式存储系统优化方面具有重要应用价值。

Abstract: We investigate the applications of ovals in projective planes to distributed storage, with a focus on the Service Rate Region problem. Leveraging the incidence relations between lines and ovals, we describe a class of non-systematic MDS matrices with a large number of small and disjoint recovery sets. For certain parameter choices, the service-rate region of these matrices contains the region of a systematic generator matrix for the same code, yielding better service performance. We further apply our construction to analyze the PIR properties of the considered MDS matrices and present a one-step majority-logic decoding algorithm with strong error-correcting capability. These results highlight how ovals, a classical object in finite geometry, re-emerge as a useful tool in modern coding theory.

</details>


### [12] [Stable Source Coding](https://arxiv.org/abs/2601.16680)
*Zhenduo Wen,Amin Gohari*

Main category: cs.IT

TL;DR: 稳定无损信源编码的速率分析：研究编码器稳定性对压缩率的影响


<details>
  <summary>Details</summary>
Motivation: 随机分组编码技术不稳定，因为相似的源序列可能被映射到完全不相关的分组索引。需要研究稳定信源编码的压缩性能。

Method: 使用组合论证方法，推导稳定参数下可达速率的信息论极限

Result: 推导出稳定无损信源编码的可达速率作为稳定性参数的函数

Conclusion: 稳定信源编码在保证编码器稳定性的同时，其压缩率受到稳定性参数的限制

Abstract: A source encoder is stable if a small change in the source sequence (e.g., changing a few symbols) results in a small (or bounded) change in the output codeword. By this definition, the common technique of random binning is unstable; because the mapping is random, two nearly identical source sequences can be assigned to completely unrelated bin indices. We study compression rates of stable lossless source codes. Using combinatorial arguments, we derive information-theoretic limits on the achievable rate as a function of the stability parameters.

</details>


### [13] [Adaptive Beam Alignment using Noisy Twenty Questions Estimation with Trained Questioner](https://arxiv.org/abs/2601.16799)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 提出基于噪声二十问题估计框架的自适应波束对齐算法，通过训练提问器解决传统方法的可行性问题和黑盒神经网络的解释性问题


<details>
  <summary>Details</summary>
Motivation: 6G通信系统使用毫米波和MIMO技术，需要波束对齐来克服严重信号衰减。传统扇区搜索算法延迟高，现有自适应算法要么缺乏可行性（依赖理想假设），要么缺乏解释性（使用黑盒神经网络）

Method: 使用噪声二十问题估计框架，训练提问器进行自适应波束对齐。提出两种方法：1）通过导向向量加权求和将查询映射到波束赋形向量；2）使用多层全连接神经网络训练提问器，保持解释性

Result: 数值模拟显示所提算法有效，性能优于所有基准算法

Conclusion: 提出的自适应波束对齐算法既避免了理想假设依赖，又保持了可解释性，解决了现有方法的可行性问题和解释性问题

Abstract: The 6G communication systems use mmWave and MIMO technologies to achieve wide bandwidth and high throughout, leading to indispensable need for beam alignment to overcome severe signal attenuation. Traditional sector-search-based beam alignment algorithms rely on sequential sampling to identify the best sector, resulting in a significant latency burden on 6G communication systems. Recently proposed adaptive beam alignment algorithms based on the active learning framework address the problem, aiming to identify the optimal sector with the fewest possible samples under an identical sector partition. Nevertheless, these algorithms either lack feasibility (Chiu, Ronquillo and Javidi, JSAC 2019) due to ideal assumptions or lack interpretability (Sohrabi, Chen and Yu, JSAC 2021) due to the use of end-to-end black-box neural networks. To avoid ideal assumptions and maintain interpretability, we address all above problems by proposing an adaptive beam alignment algorithm using the framework of noisy twenty questions estimation with a trained questioner. Specifically, we use two methods for training the questioner to eliminate reliance on ideal assumptions. The first method maps queries of twenty questions estimation to beamforming vectors via weighted summation of steering vectors, as an initial attempt to address the feasibility problem encountered in prior pioneering study by Chiu, Ronquillo and Javidi (JSAC 2019). The second method uses multi-layer fully connected neural networks to achieve improved performance while only employing them to train the questioner, which can effectively mitigate the interpretability issues in prior study by Sohrabi, Chen and Yu (JSAC 2021). Furthermore, we provide numerical simulations to illustrate the effectiveness of our proposed adaptive beam alignment algorithms and demonstrate that our algorithms outperform all benchmark algorithms.

</details>


### [14] [Privacy-Resolution Tradeoff for Adaptive Noisy Twenty Questions Estimation](https://arxiv.org/abs/2601.16825)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 本文研究带噪声的二十问题估计中的隐私-分辨率权衡，提出两阶段隐私查询程序，分析其非渐近和二阶渐近性能，并在无噪声情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自适应查询程序通常性能更好，但会引发隐私问题。先前研究主要关注无噪声情况，本文将其扩展到更实际的带噪声场景，研究隐私与分辨率之间的权衡。

Method: 提出两阶段隐私查询程序：第一阶段使用非自适应查询获取初步信息，第二阶段基于第一阶段结果设计自适应查询。分析该方法的非渐近和二阶渐近性能。

Result: 在带噪声情况下，提出的隐私查询程序在隐私保护下实现了良好的估计性能。在无噪声情况下，该程序优于Tsitsiklis等人（COLT 2018）和Xu等人（AISTATS 2021）的方法。

Conclusion: 本文成功将隐私-分辨率权衡分析扩展到带噪声的二十问题估计，提出的两阶段隐私查询程序在保护隐私的同时实现了良好的估计性能，并在无噪声情况下优于现有方法。

Abstract: We revisit noisy twenty questions estimation and study the privacy-resolution tradeoff for adaptive query procedures. Specifically, in twenty questions estimation, there are two players: an oracle and a questioner. The questioner aims to estimate target variables by posing queries to the oracle that knows the variables and using noisy responses to form reliable estimates. Typically, there are adaptive and non-adaptive query procedures. In adaptive querying, one designs the current query using previous queries and their noisy responses while in non-adaptive querying, all queries are posed simultaneously. Generally speaking, adaptive query procedures yield better performance. However, adaptive querying leads to privacy concerns, which were first studied by Tsitsiklis, Xu and Xu (COLT 2018) and by Xu, Xu and Yang (AISTATS 2021) for the noiseless case, where the oracle always provides correct answers to queries. In this paper, we generalize the above results to the more practical noisy case, by proposing a two-stage private query procedure, analyzing its non-asymptotic and second-order asymptotic achievable performance and discussing the impact of privacy concerns. Furthermore, when specialized to the noiseless case, our private query procedure achieves better performance than above-mentioned query procedures (COLT 2018, AISTATS 2021).

</details>


### [15] [Information Contraction under $(\varepsilon,δ)$-Differentially Private Mechanisms](https://arxiv.org/abs/2601.16845)
*Theshani Nuradha,Ian George,Christoph Hirche*

Main category: cs.IT

TL;DR: 论文提出了针对(ε,δ)-本地差分隐私机制的线性和非线性强数据处理不等式，改进了之前仅适用于(ε,0)-LDP的界限


<details>
  <summary>Details</summary>
Motivation: 现有的大多数信息度量收缩特性（包括全变差距离、曲棍球散度和f-散度）的紧致刻画仅适用于(ε,0)-本地差分隐私机制，当δ≠0时缺乏有效的分析工具

Method: 推导了适用于所有(ε,δ)-LDP机制的线性和非线性强数据处理不等式，针对曲棍球散度和f-散度

Result: 得到了比先前已知界限更优或更一般的结果，扩展了信息度量收缩特性的适用范围

Conclusion: 该工作为(ε,δ)-LDP机制下的信息度量收缩提供了新的理论工具，改进了现有分析框架

Abstract: The distinguishability quantified by information measures after being processed by a private mechanism has been a useful tool in studying various statistical and operational tasks while ensuring privacy. To this end, standard data-processing inequalities and strong data-processing inequalities (SDPI) are employed. Most of the previously known and even tight characterizations of contraction of information measures, including total variation distance, hockey-stick divergences, and $f$-divergences, are applicable for $(\varepsilon,0)$-local differential private (LDP) mechanisms. In this work, we derive both linear and non-linear strong data-processing inequalities for hockey-stick divergence and $f$-divergences that are valid for all $(\varepsilon,δ)$-LDP mechanisms even when $δ\neq 0$. Our results either generalize or improve the previously known bounds on the contraction of these distinguishability measures.

</details>


### [16] [Perfect Privacy and Strong Stationary Times for Markovian Sources](https://arxiv.org/abs/2601.16857)
*Fangwei Ye,Zonghong Liu,Parimal Parag,Salim El Rouayheb*

Main category: cs.IT

TL;DR: 研究在完美信息论隐私约束下共享相关数据的问题，提出基于窗口的删除机制，在保护初始状态的同时最大化共享数据量，实现最优失真且平均删除数据点数量与数据长度无关


<details>
  <summary>Details</summary>
Motivation: 在完美隐私约束下共享相关数据，需要保护初始状态同时最大化共享数据量，现有方法在效率和隐私保护之间存在平衡问题

Method: 采用删除机制（数据要么保留原样要么删除），基于有限时间齐次马尔可夫链数据，建立完美隐私与基于窗口删除方案的联系，提出两种机制：基于强平稳时间的删除方案和最优顺序删除机制

Result: 证明了两种机制都能在实现最优失真的同时，平均只删除恒定数量的数据点，与数据长度N无关，且最优顺序删除机制具有等效的窗口解释

Conclusion: 基于窗口的删除机制和最优顺序删除机制都能在完美隐私约束下有效保护初始状态，同时最大化数据共享，实现了与数据长度无关的恒定平均删除成本

Abstract: We consider the problem of sharing correlated data under a perfect information-theoretic privacy constraint. We focus on redaction (erasure) mechanisms, in which data are either withheld or released unchanged, and measure utility by the average cardinality of the released set, equivalently, the expected Hamming distortion. Assuming the data are generated by a finite time-homogeneous Markov chain, we study the protection of the initial state while maximizing the amount of shared data. We establish a connection between perfect privacy and window-based redaction schemes, showing that erasing data up to a strong stationary time preserves privacy under suitable conditions. We further study an optimal sequential redaction mechanism and prove that it admits an equivalent window interpretation. Interestingly, we show that both mechanisms achieve the optimal distortion while redacting only a constant average number of data points, independent of the data length~$N$.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [17] [Gesture Recognition from body-Worn RFID under Missing Data](https://arxiv.org/abs/2601.16301)
*Sahar Golipoor,Richard T. Brophy,Ying Liu,Reza Ghazalian,Stephan Sigg*

Main category: eess.SP

TL;DR: 提出基于被动反射标签的手势识别系统，使用数据插补和图卷积神经网络，在21种手势识别上达到98.13%准确率


<details>
  <summary>Details</summary>
Motivation: 探索使用被动身体佩戴反射标签进行手势识别，解决数据缺失问题，提高识别准确性

Method: 1) 数据缺失处理：线性/指数插值和外推、插补和邻近推理；2) 将标签表示为时序图中的节点，基于RSS和相位相关性构建边；3) 训练基于图的自注意力图卷积神经网络

Result: 系统在21种手势识别上达到98.13%准确率，留一人出交叉验证准确率89.28%；手臂标签比手腕标签对识别贡献更大（移除手臂标签准确率下降>10%，移除手腕标签仅下降~2%）

Conclusion: 被动反射标签结合图神经网络能有效识别手势，手臂标签位置比手腕更具表达力，为手势识别提供了新方法

Abstract: We explore hand-gesture recognition through the use of passive body-worn reflective tags. A data processing pipeline is proposed to address the issue of missing data. Specifically, missing information is recovered through linear and exponential interpolation and extrapolation. Furthermore, imputation and proximity-based inference are employed. We represent tags as nodes in a temporal graph, with edges formed based on correlations between received signal strength (RSS) and phase values across successive timestamps, and we train a graph-based convolutional neural network that exploits graph-based self-attention. The system outperforms state-of-the-art methods with an accuracy of 98.13% for the recognition of 21 gestures. We achieve 89.28% accuracy under leave-one-person-out cross-validation. We further investigate the contribution of various body locations on the recognition accuracy. Removing tags from the arms reduces accuracy by more than 10%, while removing the wrist tag only reduces accuracy by around 2%. Therefore, tag placements on the arms are more expressive for gesture recognition than on the wrist.

</details>


### [18] [Angle of Arrival Estimation for Gesture Recognition from reflective body-worn tags](https://arxiv.org/abs/2601.16303)
*Sahar Golipoor,Reza Ghazalian,Ines Lobato Mesquita,Stephan Sigg*

Main category: eess.SP

TL;DR: 利用被动反射标签进行手势识别，通过AoA（到达角）跟踪提升识别性能，相比传统RSS和相位特征提升达15%


<details>
  <summary>Details</summary>
Motivation: 传统基于RSS和相位信号的手势识别方法在处理大量手势时存在局限性，因为这些特征在不同手势间往往相似，难以区分复杂手势模式

Method: 1) 使用MUSIC算法验证AoA估计的可靠性；2) 提出基于卡尔曼平滑的AoA跟踪方法；3) 将AoA特征集成到手势识别系统中

Result: AoA跟踪能有效区分RSS和相位无法区分的手势数据，集成AoA特征的手势识别系统性能提升高达15%

Conclusion: AoA作为区分特征在手势识别中具有重要价值，能显著提升识别性能，特别是在处理复杂手势集时

Abstract: We investigate hand gesture recognition by leveraging passive reflective tags worn on the body. Considering a large set of gestures, distinct patterns are difficult to be captured by learning algorithms using backscattered received signal strength (RSS) and phase signals. This is because these features often exhibit similarities across signals from different gestures. To address this limitation, we explore the estimation of Angle of Arrival (AoA) as a distinguishing feature, since AoA characteristically varies during body motion. To ensure reliable estimation in our system, which employs Smart Antenna Switching (SAS), we first validate AoA estimation using the Multiple SIgnal Classification (MUSIC) algorithm while the tags are fixed at specific angles. Building on this, we propose an AoA tracking method based on Kalman smoothing. Our analysis demonstrates that, while RSS and phase alone are insufficient for distinguishing certain gesture data, AoA tracking can effectively differentiate them. To evaluate the effectiveness of AoA tracking, we implement gesture recognition system benchmarks and show that incorporating AoA features significantly boosts their performance. Improvements of up to 15% confirm the value of AoA-based enhancement.

</details>


### [19] [TransfoREM: Transformer aided 3D Radio Environment Mapping](https://arxiv.org/abs/2601.16421)
*Gautham Reddy,Ismail Guvenc,Mihail L. Sichitiu,Arupjyoti Bhuyan,Bryton Petersen,Jason Abrahamson*

Main category: eess.SP

TL;DR: TransfoREM：一种基于Transformer的3D无线电环境地图生成方法，用于预测无人机高空区域的蜂窝网络覆盖，相比传统方法具有更好的插值能力。


<details>
  <summary>Details</summary>
Motivation: 为无人机提供可靠的蜂窝网络连接面临挑战，因为现有地面网络主要针对地面覆盖设计，高空覆盖有限且受无人机飞行动态影响。

Method: 结合确定性信道模型和真实世界数据，使用Transformer模型将无线电传播映射转化为序列预测任务来构建3D无线电环境地图。

Result: 相比传统的Kriging和其他机器学习技术，TransfoREM在真实世界数据上展现出更好的插值能力。

Conclusion: TransfoREM可集成到基站级别的蜂窝网络中，构建的无线电环境地图可用于增强资源分配、干扰管理和空间频谱利用。

Abstract: Providing reliable cellular connectivity to Unmanned Aerial Vehicles (UAV) is a key challenge, as existing terrestrial networks are deployed mainly for ground-level coverage. The cellular network coverage may be available for a limited range from the antenna side lobes, with poor connectivity further exacerbated by UAV flight dynamics. In this work, we propose TransfoREM, a 3D Radio Environment Map (REM) generation method that combines deterministic channel models and real-world data to map terrestrial network coverage at higher altitudes. At the core of our solution is a transformer model that translates radio propagation mapping into a sequence prediction task to construct REMs. Our results demonstrate that TransfoREM offers improved interpolation capability on real-world data compared against conventional Kriging and other machine learning (ML) techniques. Furthermore, TransfoREM is designed for holistic integration into cellular networks at the base station (BS) level, where it can build REMs, which can then be leveraged for enhanced resource allocation, interference management, and spatial spectrum utilization.

</details>


### [20] [Auditory Attention Decoding without Spatial Information: A Diotic EEG Study](https://arxiv.org/abs/2601.16442)
*Masahiro Yoshino,Haruki Yokota,Junya Hara,Yuichi Tanaka,Hiroshi Higashi*

Main category: eess.SP

TL;DR: 本文提出了一种用于双耳同声环境的听觉注意解码框架，通过将EEG和语音信号映射到共享潜在空间，实现了72.70%的准确率，比现有基于方向的方法提高了22.58%。


<details>
  <summary>Details</summary>
Motivation: 现有听觉注意解码研究主要依赖双耳分听环境，利用空间方向线索来识别注意目标。然而，这种方法在现实世界的"鸡尾酒会"场景中适用性有限，因为说话者可能重叠或动态移动。需要开发不依赖空间线索的AAD方法。

Method: 提出双耳同声环境的AAD框架，消除空间线索。使用独立编码器将EEG和语音信号映射到共享潜在空间：语音特征使用wav2vec 2.0提取，通过2层1D CNN编码；EEG使用BrainNetwork架构编码。通过计算EEG和语音表示之间的余弦相似度来识别注意的语音。

Result: 在双耳同声EEG数据集上评估，达到72.70%的准确率，比最先进的基于方向的AAD方法提高了22.58%。

Conclusion: 该方法成功解决了现有AAD技术对空间线索的依赖问题，为现实世界的听觉场景处理提供了更实用的解决方案，特别是在智能助听器和客观听力测试系统中具有重要应用价值。

Abstract: Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the "cocktail party" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method.

</details>


### [21] [Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity](https://arxiv.org/abs/2601.16543)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Yanze Zhu,Wen Chen,Penghui Huang,Ying Gao,Honghao Wang*

Main category: eess.SP

TL;DR: 本文研究了配备可旋转天线的无蜂窝网络，通过联合优化波束成形和天线方向来最大化最差用户速率，提出了交替优化算法和高效的两阶段方案。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝网络虽然利用分布式接入点实现宏分集，但用户几何位置和障碍物导致的信道质量差异限制了性能。可旋转天线通过调整天线主瓣方向来增强不利链路，从而更好地利用宏分集，提升网络性能和公平性。

Method: 1. 提出交替优化算法：迭代更新波束成形（通过二阶锥规划SOCP）和优化天线方向（使用逐次凸逼近）。2. 提出高效两阶段方案：第一阶段通过流形感知Frank-Wolfe更新最大化比例公平对数效用函数来设计天线方向；第二阶段使用SOCP设计波束成形。

Result: 仿真结果表明，所提出的方向感知设计相比传统仅波束成形基准方案，显著提高了最差用户速率。更大的天线方向性在正确调整方向时能增强公平性，但方向不当反而会降低最差用户性能。

Conclusion: 可旋转天线为无蜂窝网络提供了轻量级的硬件自由度，通过联合优化波束成形和天线方向，能够有效利用宏分集，显著提升网络的最差用户性能和公平性。所提出的算法和方案在实际部署中具有重要价值。

Abstract: Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation results demonstrate that the proposed orientation-aware designs achieve a substantially higher worst-user rate than conventional beamforming-only benchmarks. Furthermore, larger antenna directivity enhances fairness with proper orientation but can degrade the worst-user performance otherwise.

</details>


### [22] [Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques](https://arxiv.org/abs/2601.16550)
*Eike-Manuel Edelmann*

Main category: eess.SP

TL;DR: 该论文研究了基于脉冲神经网络(SNN)的接收机设计，用于非线性时不变频率选择性信道，通过量化编码和强化学习优化，实现了比传统人工神经网络(ANN)接收机更好的性能和更低的功耗。


<details>
  <summary>Details</summary>
Motivation: 现代通信系统复杂度不断增加导致功耗上升，而脉冲神经网络(SNN)受高效人脑启发，具有事件驱动和低功耗特性，有望解决通信接收机的能效问题。但SNN面临学习规则和神经编码等挑战。

Method: 采用基于时间的反向传播配合替代梯度作为学习规则，提出量化编码(QE)作为神经编码方法。研究了两种接收机架构，基于直接检测强度调制链路模型，比较均衡性能和脉冲计数。引入基于策略梯度的更新(PGU)算法，无需反向传播即可优化编码参数。

Result: 结合判决反馈和量化编码的SNN接收机在性能和脉冲计数方面表现优异。SNN接收机显著优于ANN接收机。使用PGU算法优化编码参数，大幅减少了运行时间、复杂度和每次推理的脉冲数，同时保持性能。

Conclusion: 该论文成功建立了SNN接收机的设计和优化框架，解决了SNN优化的关键挑战，为未来设计和部署高能效SNN接收机奠定了基础。

Abstract: Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers.

</details>


### [23] [OFDM-Based ISAC Imaging of Extended Targets via Inverse Virtual Aperture Processing](https://arxiv.org/abs/2601.16664)
*Michael Negosanti,Lorenzo Pucci,Andrea Giorgetti*

Main category: eess.SP

TL;DR: 该研究探讨了利用逆虚拟孔径(IVA)进行车载场景中移动扩展目标成像的集成感知与通信(ISAC)系统性能，使用5G NR波形评估了图像对比度和目标质心距离估计精度。


<details>
  <summary>Details</summary>
Motivation: 随着下一代无线网络的发展，集成感知与通信(ISAC)系统在车载场景中变得越来越重要。需要研究如何利用通信波形同时实现高效感知，特别是对移动扩展目标（如车辆）的成像能力。

Method: 采用MIMO-OFDM波形，基站作为单站传感器。通过运动补偿技术处理目标反射的回波，形成IVA距离-多普勒（跨距离）图像。使用5G NR波形（中高频段），目标模型基于3GPP Release 19定义，将车辆建模为空间分布的散射点集。

Result: 通过图像对比度(IC)和估计目标质心距离的均方根误差(RMSE)评估性能。研究发现，通过调整用于IVA成像的子载波分配，可以在感知精度和通信效率之间进行权衡，为下一代无线网络设计有效的感知策略提供了见解。

Conclusion: 该研究证明了利用IVA技术在ISAC系统中对移动扩展目标进行成像的可行性，为下一代无线网络中感知与通信的协同设计提供了重要参考，特别是在车载场景中的应用。

Abstract: This work investigates the performance of an integrated sensing and communication (ISAC) system exploiting inverse virtual aperture (IVA) for imaging moving extended targets in vehicular scenarios. A base station (BS) operates as a monostatic sensor using MIMO-OFDM waveforms. Echoes reflected by the target are processed through motion-compensation techniques to form an IVA range-Doppler (cross-range) image. A case study considers a 5G NR waveform in the upper mid-band, with the target model defined in 3GPP Release 19, representing a vehicle as a set of spatially distributed scatterers. Performance is evaluated in terms of image contrast (IC) and the root mean squared error (RMSE) of the estimated target-centroid range. Finally, the trade-off between sensing accuracy and communication efficiency is examined by varying the subcarrier allocation for IVA imaging. The results provide insights for designing effective sensing strategies in next-generation radio networks.

</details>


### [24] [Real-Time Evaluation of an Ultra-Tight GNSS/INS Integration Based on Adaptive PLL Bandwidth](https://arxiv.org/abs/2601.16577)
*Gaël Pages,Priot Benoît,Guillaume Beaugendre*

Main category: eess.SP

TL;DR: 提出一种基于向量跟踪环架构的GNSS/INS超紧耦合系统，通过INS信息自适应调整PLL带宽，可在FPGA上实现且占用资源少


<details>
  <summary>Details</summary>
Motivation: 传统GNSS/INS紧耦合系统在FPGA实现时面临资源占用大、存储需求高的问题，需要更高效的实现方案

Method: 采用向量跟踪环架构，利用INS信息自适应调整PLL带宽，在环路内解码导航消息，无需并行标量环或预存星历数据

Result: 实现了GPS L1/C和Galileo E1信号的接收机架构，包含1个捕获模块和16个跟踪通道（8GPS+8Galileo），在Zynq-Ultrascale FPGA上成功实现

Conclusion: 提出的超紧耦合架构在FPGA上实现简单、资源占用少，相比传统向量方案具有更好的实用性和可部署性

Abstract: In this contribution, we propose a GNSS/INS ultra-tight coupling in which the GNSS receiver architecture is based on a vector tracking loop type architecture. In the proposed approach, the phase lock loop bandwidth is adapted according to the inertial navigation system information. The latter has the advantage to be easily implementable on a System-on-Chip component such as an FPGA (Field-Programmable Gate Arrays), and can be implemented with minor modifications on an existing GNSS receiver platform. Moreover, compared to classical vector-based solutions, the proposed architecture decodes the navigation message in the loop, without the need to run scalar loops in parallel or having to store pre-downloaded ephemeris data. This architecture therefore does not increase the area occupied on the FPGA and does not use additional resources for storage. The proposed GNSS receiver architecture uses GPS L1/C and Galileo E1 signals and is composed of one acquisition module and 16 tracking channels (8 GPS and 8 Galileo) which are implemented within a FPGA (Zynq-Ultrascale).

</details>


### [25] [Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection](https://arxiv.org/abs/2601.16586)
*Benedikt Fesl,Fatih Capar*

Main category: eess.SP

TL;DR: 提出recurSIC：一种轻量级学习型MIMO检测框架，基于SIC结构，通过单次前向传播和最小参数实现可靠的软硬检测，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 5G RedCap和IoT设备需要低复杂度的MIMO检测方案，同时需要支持高阶调制和生成可靠的软信息用于信道解码，现有方案难以平衡性能与计算资源限制。

Method: 基于连续干扰消除(SIC)结构设计轻量级学习框架，通过多路径假设跟踪生成软信息，仅需单次前向传播，参数数量极少，复杂度可调。

Result: 在实际无线场景中的数值结果表明，recurSIC在极低复杂度下实现了强大的硬检测和软检测性能，适合边缘受限的MIMO接收器。

Conclusion: recurSIC为边缘设备提供了一种高效的学习型MIMO检测解决方案，在保持低复杂度的同时实现了可靠的软硬检测性能。

Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.

</details>


### [26] [Assessment of Errors of Fundamental Frequency Estimation Methods in the Presence of Voltage Fluctuations and Distortions](https://arxiv.org/abs/2601.16606)
*Antonio Bracale,Pasquale De Falco,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SP

TL;DR: 论文通过数值模拟评估了现代电网条件下各种基频估计方法的误差，包括IEC 61000-4-30标准方法


<details>
  <summary>Details</summary>
Motivation: 基频是定义电能质量的关键参数，在现代电网条件下准确确定该参数至关重要，诊断目的需要在短时间窗口内高效估计该参数

Method: 采用数值模拟研究，使用模拟电网状态的测试信号（包括电压波动和畸变同时发生的情况），评估各种基频估计方法的误差

Result: 提供了不同基频估计方法在模拟现代电网条件下的误差评估结果，包括标准IEC 61000-4-30方法的表现

Conclusion: 基于研究结果提出了结论，为现代电网条件下基频估计方法的选择和应用提供了参考

Abstract: The fundamental frequency is one of the parameters that define power quality. Correctly determining this parameter under the conditions that prevail in modern power grids is crucial. Diagnostic purposes often require an efficient estimation of this parameter within short time windows. Therefore, this article presents the results of numerical simulation studies that allow the assessment of errors in various fundamental frequency estimation methods, including the standard IEC 61000-4-30 method, when the analyzed signal has a form similar to that found in modern power grids. For the purposes of this study, a test signal was adopted recreating the states of the power grid, including the simultaneous occurrence of voltage fluctuations and distortions. Conclusions are presented based on conducted research.

</details>


### [27] [Low-Power On-Device Gesture Recognition with Einsum Networks](https://arxiv.org/abs/2601.16662)
*Sahar Golipoor,Lingyun Yao,Martin Andraud,Stephan Sigg*

Main category: eess.SP

TL;DR: 基于Einsum网络的分布式资源受限设备手势识别系统，在低功耗RFID场景中优于基准模型


<details>
  <summary>Details</summary>
Motivation: 为分布式、资源受限设备网络设计高效的手势识别系统，利用Einsum网络的可处理推理、可解释性和能效优势

Method: 采用Einsum网络概率电路构建手势识别流水线，每个设备包含RSS/相位处理或AoA估计的专用处理单元、特征提取模块和Einsum硬件，最后通过决策聚合模块融合所有设备输出

Result: 实验结果表明该方法在低功耗、可穿戴、被动RFID手势识别场景中优于基准模型

Conclusion: Einsum网络为分布式资源受限设备的手势识别提供了有效的解决方案，结合专用硬件和决策融合机制实现了优越性能

Abstract: We design a gesture-recognition pipeline for networks of distributed, resource constrained devices utilising Einsum Networks. Einsum Networks are probabilistic circuits that feature a tractable inference, explainability, and energy efficiency. The system is validated in a scenario of low-power, body-worn, passive Radio Frequency Identification-based gesture recognition. Each constrained device includes task-specific processing units responsible for Received Signal Strength (RSS) and phase processing or Angle of Arrival (AoA) estimation, along with feature extraction, as well as dedicated Einsum hardware that processes the extracted features. The output of all constrained devices is then fused in a decision aggregation module to predict gestures. Experimental results demonstrate that the method outperforms the benchmark models.

</details>


### [28] [Precise Low-Current Measurement Techniques for IoT Devices: A Case Study on MoleNet](https://arxiv.org/abs/2601.16727)
*Julian Block,Andreas Könsgen,Jens Dede,Anna Förster*

Main category: eess.SP

TL;DR: 比较专用源测量单元(SMUs)在测量物联网设备微小电流方面的性能，并以MoleNet物联网传感器板为例进行演示


<details>
  <summary>Details</summary>
Motivation: 物联网设备通常需要长时间电池供电，功耗是关键因素。传统万用表和示波器在测量睡眠模式等微小电流时精度不足，需要更专业的测量工具

Method: 比较专用的源测量单元(SMUs)，这些设备能够以高精度测量非常小的电流，并以MoleNet物联网传感器板作为应用实例进行电流测量演示

Result: 展示了专用SMUs在测量物联网设备微小电流方面的优势，特别是在设备睡眠模式下的电流测量能力

Conclusion: 专用源测量单元是测量物联网设备微小电流的有效工具，对于设备功耗评估和电池寿命预测具有重要意义

Abstract: Power consumption is a crucial aspect of IoT devices which often have to run on a battery for an extended period of time. Therefore, supply current measurements are crucial before deploying a device in the field. Multimeters and oscilloscopes are not well suited when it comes to measuring very small currents which occur e.g. when an IoT device is in sleep mode. In this report, we compare dedicated source measurement units (SMUs) which allow to measure very small currents with high precision. As an application example, we demonstrate current measurements on our MoleNet IoT sensor board.

</details>


### [29] [A Dynamic Parametric Simulator for Fetal Heart Sounds](https://arxiv.org/abs/2601.16792)
*Yingtong Zhou,Yiang Zhou,Zhengxian Qu,Kang Liu,Ting Tan*

Main category: eess.SP

TL;DR: 提出一个可重复的动态参数模拟器，用于生成腹部胎儿心音图信号，解决现有数据不足、母体干扰和信号衰减的问题。


<details>
  <summary>Details</summary>
Motivation: 胎儿心音图研究面临腹部记录数据有限、母体干扰严重、传输引起的信号衰减等问题，这些因素使得可重复的基准测试变得困难。

Method: 结合周期级的胎儿S1/S2事件合成与卷积传输模块，加上可配置的干扰和背景噪声，生成长期的腹部fPCG序列。模型参数从真实腹部记录中周期性地校准，以捕捉心跳间变异性。

Result: 生成的信号在包络时间结构和频域特性方面与真实记录进行了验证，模拟器作为开源软件发布。

Conclusion: 该模拟器支持在受控采集条件下对fPCG处理方法进行快速、可重复的评估，解决了胎儿心音图研究中的数据挑战。

Abstract: Research on fetal phonocardiogram (fPCG) is challenged by the limited number of abdominal recordings, substantial maternal interference, and marked transmissioninduced signal attenuation that complicate reproducible benchmarking. We present a reproducible dynamic parametric simulator that generates long abdominal fPCG sequences by combining cycle-level fetal S1/S2 event synthesis with a convolutional transmission module and configurable interference and background noise. Model parameters are calibrated cyclewise from real abdominal recordings to capture beat-to-beat variability and to define data-driven admissible ranges for controllable synthesis. The generated signals are validated against real recordings in terms of envelope-based temporal structure and frequency-domain characteristics. The simulator is released as open software to support rapid, reproducible evaluation of fPCG processing methods under controlled acquisition conditions.

</details>


### [30] [Hierarchical Distribution Matcher Design for Probabilistic Constellation Shaping Based on a Novel Semi-Analytical Optimization Approach](https://arxiv.org/abs/2601.16847)
*Pantea Nadimi Goki,Luca Potì*

Main category: eess.SP

TL;DR: 提出了一种实用的分层分布匹配器设计方法，用于概率整形星座系统，通过半解析优化框架联合优化速率和能量损失，在16QAM系统中实现了2.8%的整形增益提升。


<details>
  <summary>Details</summary>
Motivation: 现有分层分布匹配器设计缺乏系统化的优化方法，难以在实际硬件约束下实现最佳性能。需要一种能够确定最优参数、考虑能量损失、速率损失和内存需求的设计流程。

Method: 提出半解析优化框架，联合优化速率和能量损失，确定分层层数、内存大小和块长度。通过分析估计能量损失、速率损失和内存需求的下界，针对MB分布优化HiDM架构。

Result: 在16QAM概率整形系统中验证了模型准确性，模拟结果与分析预测一致。在AWGN信道下，以200Gbps净数据速率和25%FEC开销，相比现有方案实现了2.8%的整形增益提升。

Conclusion: 该方法为HiDM设计提供了实用的分析工具，能够满足ASIC和FPGA等实际硬件约束，在概率整形系统中实现了显著的性能改进。

Abstract: A novel design procedure for practical hierarchical distribution matchers (HiDMs) in probabilistically shaped constellation systems is presented. The proposed approach enables the determination of optimal parameters for any target distribution matcher rate. Specifically, lower bounds on energy loss, rate loss, and memory requirements are analytically estimated for HiDM architectures approximating the Maxwell Boltzmann (MB) distribution. A semi analytical optimization framework is employed to jointly optimize rate and energy loss, allowing the selection of the number of hierarchical layers, memory size, and block length required to optimize channel capacity. The accuracy of the proposed model is validated through probabilistic amplitude shaping of 16QAM (PAS 16QAM), showing good agreement between analytical predictions and simulated results. The proposed analytical tool facilitates the design of HiDM structures that are compatible with practical hardware and implementation constraints, such as those imposed by state-of-the-art application-specific integrated circuits (ASICs) and field-programmable gate arrays (FPGAs). Furthermore, the performance of the optimized HiDM structure, incorporating layer selection based on lower-bound energy loss, is evaluated over the AWGN channel in terms of normalized generalized mutual information (NGMI) as a function of the optical signal-to-noise ratio (OSNR). At a net data rate of 200 Gbps with 25% forward error correction (FEC) overhead, the proposed scheme achieves a shaping gain improvement of 2.8% compared to previously reported solutions.

</details>


### [31] [IRS Compensation of Hyper-Rayleigh Fading: How Many Elements Are Needed?](https://arxiv.org/abs/2601.16915)
*Aleksey S. Gvozdarev*

Main category: eess.SP

TL;DR: 该论文研究了在超瑞利衰落条件下，智能反射面(IRS)所需的最小元素数量问题，发现当源-IRS和IRS-目的地链路都处于最恶劣衰落时，需要至少6个IRS元素才能使总链路脱离最恶劣衰落，需要14个元素才能实现无衰落条件。


<details>
  <summary>Details</summary>
Motivation: 研究动机是确定在严重衰落的多径衰落信道中，智能反射面(IRS)需要多少元素才能补偿衰落效应。衰落严重程度通过超瑞利衰落机制(HRRs)量化，包括最恶劣条件、强衰落、弱衰落和无衰落情况。

Method: 采用逆幂洛马克斯(IPL)信道模型，该模型能涵盖所有HRR情况。推导了单IRS元素信道的闭式信道系数包络统计量，包括子信道和总IRS辅助信道的统计特性。还推导了总信道系数和瞬时信噪比(SNR)统计量的紧致近似表达式。

Result: 当源-IRS和IRS-目的地两条单链路都处于最恶劣衰落(full-HRR)时，需要至少6个IRS元素才能使总IRS辅助链路脱离最恶劣衰落；需要14个IRS元素才能使总链路进入无衰落(no-HRR)状态。

Conclusion: 该研究为IRS系统设计提供了重要指导，明确了在严重衰落条件下所需的最小IRS元素数量。结果表明，即使单个链路处于最恶劣衰落，通过适当数量的IRS元素配置，总链路性能仍能得到显著改善。

Abstract: The letter introduces and studies the problem of defining the minimum number of Intelligent Reflecting Surface (IRS) elements needed to compensate for heavy fading conditions in multipath fading channels. The fading severity is quantified in terms of Hyper-Rayleigh Regimes (HRRs) (i.e., full-HRR (worst-case conditions), strong-, weak-, and no-HRR), and the channel model used (Inverse Power Lomax (IPL)) was chosen since it can account for all HRRs. The research presents the derived closed-form channel coefficient envelope statistics for the single IRS-element channel with IPL statistics in both subchannels and total IRS-assisted channel, as well as tight approximations for the channel coefficient and instantaneous signal-to-noise ratio (SNR) statistics for the latter. The derived expressions helped estimate channel parameters corresponding to the specific HRRs of the total channel and demonstrate that while both single links (i.e., ''source-IRS'' and ''IRS-destination'') are in full-HRR, the minimum number of IRS elements needed to bring the total IRS-assisted link (''source-IRS-destination'') out of full-HRR is no less than $6$ (for the whole range on the IPL scale parameter corresponding full-HRR). Furthermore, the minimum number of IRS elements required to bring the total IRS-assisted link into no-HRR is $14$ (under the same conditions).

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [32] [Experience with Single Domain Generalization in Real World Medical Imaging Deployments](https://arxiv.org/abs/2601.16359)
*Ayan Banerjee,Komandoor Srivathsan,Sandeep K. S. Gupta*

Main category: eess.IV

TL;DR: 该论文提出了一种结合专家知识的深度学习技术DL+EKE，用于解决医学影像中的单域泛化问题，并在糖尿病视网膜病变、癫痫检测和冠状动脉检测三个案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 医学影像应用中，不同扫描设备和成像协议导致的域偏移问题严重影响了模型在真实部署中的泛化能力。特别是在多中心研究中，罕见类特征的变异性加剧了单域泛化（SDG）的挑战。

Method: 提出DL+EKE技术，将专家知识整合到深度学习框架中。首先在糖尿病视网膜病变应用中验证该技术，然后将其部署到两个真实世界案例：基于静息态fMRI的癫痫发作区检测和基于压力心电图的冠状动脉检测。

Result: DL+EKE在糖尿病视网膜病变应用中超越了现有的SOTA SDG方法。在真实部署的压力心电图和静息态fMRI案例中，DL+EKE技术有效解决了SDG面临的挑战。

Conclusion: 专家知识整合的深度学习技术DL+EKE能够有效解决医学影像中的单域泛化问题，在多个真实世界应用中展现出优于现有方法的性能，为医疗AI的实际部署提供了可行方案。

Abstract: A desirable property of any deployed artificial intelligence is generalization across domains, i.e. data generation distribution under a specific acquisition condition. In medical imagining applications the most coveted property for effective deployment is Single Domain Generalization (SDG), which addresses the challenge of training a model on a single domain to ensure it generalizes well to unseen target domains. In multi-center studies, differences in scanners and imaging protocols introduce domain shifts that exacerbate variability in rare class characteristics. This paper presents our experience on SDG in real life deployment for two exemplary medical imaging case studies on seizure onset zone detection using fMRI data, and stress electrocardiogram based coronary artery detection. Utilizing the commonly used application of diabetic retinopathy, we first demonstrate that state-of-the-art SDG techniques fail to achieve generalized performance across data domains. We then develop a generic expert knowledge integrated deep learning technique DL+EKE and instantiate it for the DR application and show that DL+EKE outperforms SOTA SDG methods on DR. We then deploy instances of DL+EKE technique on the two real world examples of stress ECG and resting state (rs)-fMRI and discuss issues faced with SDG techniques.

</details>


### [33] [On The Robustness of Foundational 3D Medical Image Segmentation Models Against Imprecise Visual Prompts](https://arxiv.org/abs/2601.16383)
*Soumitri Chattopadhyay,Basar Demir,Marc Niethammer*

Main category: eess.IV

TL;DR: 本文系统研究了3D医学分割基础模型对不精确视觉提示的鲁棒性，通过控制性扰动实验揭示了模型对形状和空间线索的依赖程度


<details>
  <summary>Details</summary>
Motivation: 尽管3D基础模型在医学体积图像的可提示分割方面显示出潜力，但其对不精确提示的鲁棒性尚未得到充分探索。本研究旨在填补这一空白，系统研究各种受控扰动对密集视觉提示的影响，这些扰动密切模拟了现实世界中的不精确性。

Method: 通过系统研究各种受控扰动对密集视觉提示的影响，这些扰动密切模拟了现实世界中的不精确性。在两种最新基础模型上进行了多器官腹部分割任务的实验。

Result: 实验揭示了可提示医学分割的多个方面，特别是模型对视觉形状和空间线索的依赖程度，以及模型对某些扰动的弹性程度。

Conclusion: 本研究填补了3D医学分割基础模型对不精确提示鲁棒性研究的空白，通过系统实验揭示了模型的行为特征，为未来改进模型鲁棒性提供了基础。

Abstract: While 3D foundational models have shown promise for promptable segmentation of medical volumes, their robustness to imprecise prompts remains under-explored. In this work, we aim to address this gap by systematically studying the effect of various controlled perturbations of dense visual prompts, that closely mimic real-world imprecision. By conducting experiments with two recent foundational models on a multi-organ abdominal segmentation task, we reveal several facets of promptable medical segmentation, especially pertaining to reliance on visual shape and spatial cues, and the extent of resilience of models towards certain perturbations. Codes are available at: https://github.com/ucsdbiag/Prompt-Robustness-MedSegFMs

</details>


### [34] [Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images Using Fully Synthetic Training](https://arxiv.org/abs/2601.16602)
*Xinxin Xu,Yann Gousseau,Christophe Kervazo,Saïd Ladjal*

Main category: eess.IV

TL;DR: 提出了一种基于合成丰度数据的无监督高光谱图像超分辨率训练策略，无需地面真值数据


<details>
  <summary>Details</summary>
Motivation: 现有高光谱单图像超分辨率方法大多需要监督训练和地面真值数据，但这些数据通常难以获取，因此需要开发无监督方法

Method: 1) 通过解混将高光谱图像分解为丰度和端元；2) 使用死叶模型生成合成丰度数据来训练丰度超分辨率神经网络；3) 用训练好的网络提升丰度空间分辨率；4) 与端元重新组合得到高分辨率高光谱图像

Result: 实验结果表明合成图像具有训练潜力，证明了该方法的有效性

Conclusion: 该方法成功解决了高光谱图像超分辨率中缺乏地面真值数据的问题，通过合成丰度数据实现了有效的无监督训练

Abstract: Considerable work has been dedicated to hyperspectral single image super-resolution to improve the spatial resolution of hyperspectral images and fully exploit their potential. However, most of these methods are supervised and require some data with ground truth for training, which is often non-available. To overcome this problem, we propose a new unsupervised training strategy for the super-resolution of hyperspectral remote sensing images, based on the use of synthetic abundance data. Its first step decomposes the hyperspectral image into abundances and endmembers by unmixing. Then, an abundance super-resolution neural network is trained using synthetic abundances, which are generated using the dead leaves model in such a way as to faithfully mimic real abundance statistics. Next, the spatial resolution of the considered hyperspectral image abundances is increased using this trained network, and the high resolution hyperspectral image is finally obtained by recombination with the endmembers. Experimental results show the training potential of the synthetic images, and demonstrate the method effectiveness.

</details>


### [35] [PanopMamba: Vision State Space Modeling for Nuclei Panoptic Segmentation](https://arxiv.org/abs/2601.16631)
*Ming Kang,Fung Fung Ting,Raphaël C. -W. Phan,Zongyuan Ge,Chee-Ming Ting*

Main category: eess.IV

TL;DR: PanopMamba：首个基于Mamba的核全景分割方法，通过混合Mamba-Transformer架构和多尺度特征融合，解决细胞核分割中的小目标检测、模糊边界和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 核全景分割对癌症诊断很重要，但面临小目标检测、模糊边界处理和类别不平衡等挑战。现有方法在这些问题上表现不足，需要更有效的长距离感知和特征融合机制。

Method: 提出PanopMamba混合编码器-解码器架构：1) 多尺度Mamba骨干网络；2) 基于状态空间模型的特征增强融合网络；3) 金字塔特征网络和动态特征增强；4) 引入新的评估指标(iPQ, wPQ, fwPQ)。

Result: 在MoNuSAC2020和NuInsSeg两个多类核分割基准数据集上，PanopMamba优于现有最先进方法，验证了其鲁棒性和有效性。

Conclusion: PanopMamba是首个基于Mamba的全景分割方法，通过整合Mamba和Transformer实现了高效的长距离感知和多尺度特征融合，在核分割任务中表现出优越性能，同时提出的新评估指标能更公平地评估分割质量。

Abstract: Nuclei panoptic segmentation supports cancer diagnostics by integrating both semantic and instance segmentation of different cell types to analyze overall tissue structure and individual nuclei in histopathology images. Major challenges include detecting small objects, handling ambiguous boundaries, and addressing class imbalance. To address these issues, we propose PanopMamba, a novel hybrid encoder-decoder architecture that integrates Mamba and Transformer with additional feature-enhanced fusion via state space modeling. We design a multiscale Mamba backbone and a State Space Model (SSM)-based fusion network to enable efficient long-range perception in pyramid features, thereby extending the pure encoder-decoder framework while facilitating information sharing across multiscale features of nuclei. The proposed SSM-based feature-enhanced fusion integrates pyramid feature networks and dynamic feature enhancement across different spatial scales, enhancing the feature representation of densely overlapping nuclei in both semantic and spatial dimensions. To the best of our knowledge, this is the first Mamba-based approach for panoptic segmentation. Additionally, we introduce alternative evaluation metrics, including image-level Panoptic Quality ($i$PQ), boundary-weighted PQ ($w$PQ), and frequency-weighted PQ ($fw$PQ), which are specifically designed to address the unique challenges of nuclei segmentation and thereby mitigate the potential bias inherent in vanilla PQ. Experimental evaluations on two multiclass nuclei segmentation benchmark datasets, MoNuSAC2020 and NuInsSeg, demonstrate the superiority of PanopMamba for nuclei panoptic segmentation over state-of-the-art methods. Consequently, the robustness of PanopMamba is validated across various metrics, while the distinctiveness of PQ variants is also demonstrated. Code is available at https://github.com/mkang315/PanopMamba.

</details>


### [36] [Fast, faithful and photorealistic diffusion-based image super-resolution with enhanced Flow Map models](https://arxiv.org/abs/2601.16660)
*Maxence Noble,Gonzalo Iñaki Quintana,Benjamin Aubin,Clément Chadebec*

Main category: eess.IV

TL;DR: FlowMapSR：基于Flow Map自蒸馏扩散模型的高效图像超分辨率框架，通过正负提示引导和对抗性微调，在重建保真度和真实感之间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的超分辨率方法面临重建保真度与真实感之间的权衡问题，而教师-学生蒸馏方法会损失感知线索。同时，Flow Map自蒸馏模型在图像生成中表现出色，但尚未应用于超分辨率任务。

Method: 提出FlowMapSR框架：1）将Flow Map模型（Eulerian、Lagrangian、Shortcut三种变体）适配到超分辨率任务；2）引入正负提示引导，将分类器自由引导范式推广到Flow Map模型；3）使用低秩适应（LoRA）进行对抗性微调。

Result: Shortcut变体结合增强方法表现最佳。FlowMapSR在x4和x8超分辨率上比现有方法更好地平衡了重建保真度和真实感，推理时间具有竞争力，且单一模型支持两种放大倍数。

Conclusion: FlowMapSR成功将Flow Map自蒸馏模型应用于超分辨率任务，通过正负提示引导和对抗性微调实现了高效推理，在保真度和真实感之间取得了优越的平衡。

Abstract: Diffusion-based image super-resolution (SR) has recently attracted significant attention by leveraging the expressive power of large pre-trained text-to-image diffusion models (DMs). A central practical challenge is resolving the trade-off between reconstruction faithfulness and photorealism. To address inference efficiency, many recent works have explored knowledge distillation strategies specifically tailored to SR, enabling one-step diffusion-based approaches. However, these teacher-student formulations are inherently constrained by information compression, which can degrade perceptual cues such as lifelike textures and depth of field, even with high overall perceptual quality. In parallel, self-distillation DMs, known as Flow Map models, have emerged as a promising alternative for image generation tasks, enabling fast inference while preserving the expressivity and training stability of standard DMs. Building on these developments, we propose FlowMapSR, a novel diffusion-based framework for image super-resolution explicitly designed for efficient inference. Beyond adapting Flow Map models to SR, we introduce two complementary enhancements: (i) positive-negative prompting guidance, based on a generalization of classifier free-guidance paradigm to Flow Map models, and (ii) adversarial fine-tuning using Low-Rank Adaptation (LoRA). Among the considered Flow Map formulations (Eulerian, Lagrangian, and Shortcut), we find that the Shortcut variant consistently achieves the best performance when combined with these enhancements. Extensive experiments show that FlowMapSR achieves a better balance between reconstruction faithfulness and photorealism than recent state-of-the-art methods for both x4 and x8 upscaling, while maintaining competitive inference time. Notably, a single model is used for both upscaling factors, without any scale-specific conditioning or degradation-guided mechanisms.

</details>


### [37] [PocketDVDNet: Realtime Video Denoising for Real Camera Noise](https://arxiv.org/abs/2601.16780)
*Crispian Morris,Imogen Dexter,Fan Zhang,David R. Bull,Nantheera Anantrasirichai*

Main category: eess.IV

TL;DR: PocketDVDNet是一个轻量级视频去噪器，通过模型压缩框架结合结构化剪枝、物理噪声模型和知识蒸馏，在减少74%模型大小的同时提升去噪质量，实现实时处理。


<details>
  <summary>Details</summary>
Motivation: 现实世界中多分量传感器噪声下的实时视频去噪对于自动对焦、自动驾驶和监控等应用具有挑战性，需要平衡去噪质量和计算效率。

Method: 使用模型压缩框架：1）稀疏引导的结构化剪枝；2）物理信息噪声模型；3）知识蒸馏。从参考模型开始，诱导稀疏性，应用针对性通道剪枝，在真实多分量噪声上重新训练教师网络，学生网络学习隐式噪声处理，无需显式噪声图输入。

Result: PocketDVDNet将原始模型大小减少74%，同时提升去噪质量，能够实时处理5帧图像块，在性能和效率之间取得良好平衡。

Conclusion: 激进的模型压缩结合领域适应的知识蒸馏可以协调性能和效率，为实用的实时视频去噪提供可行解决方案。

Abstract: Live video denoising under realistic, multi-component sensor noise remains challenging for applications such as autofocus, autonomous driving, and surveillance. We propose PocketDVDNet, a lightweight video denoiser developed using our model compression framework that combines sparsity-guided structured pruning, a physics-informed noise model, and knowledge distillation to achieve high-quality restoration with reduced resource demands. Starting from a reference model, we induce sparsity, apply targeted channel pruning, and retrain a teacher on realistic multi-component noise. The student network learns implicit noise handling, eliminating the need for explicit noise-map inputs. PocketDVDNet reduces the original model size by 74% while improving denoising quality and processing 5-frame patches in real-time. These results demonstrate that aggressive compression, combined with domain-adapted distillation, can reconcile performance and efficiency for practical, real-time video denoising.

</details>
