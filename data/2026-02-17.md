<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 10]
- [eess.SP](#eess.SP) [Total: 28]
- [cs.IT](#cs.IT) [Total: 14]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Deep Learning CNN for Pneumonia Detection: Advancing Digital Health in Society 5.0](https://arxiv.org/abs/2602.13270)
*Hadi Almohab*

Main category: eess.IV

TL;DR: 基于深度学习的CNN模型用于胸部X光图像的肺炎自动检测，准确率达91.67%，ROC-AUC为0.96，PR-AUC为0.95


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球严重的健康问题，在诊断工具和医疗资源有限的地区导致高发病率和死亡率，需要开发自动诊断工具

Method: 使用卷积神经网络（CNN）进行训练，采用预处理技术包括归一化、数据增强和图像质量增强，以提高模型的鲁棒性和泛化能力

Result: 优化后的模型在测试中达到91.67%的准确率，ROC-AUC为0.96，PR-AUC为0.95，在区分肺炎和正常图像方面表现出色

Conclusion: 该CNN模型作为快速、一致、可靠的诊断辅助工具具有重要潜力，通过整合人工智能支持社会5.0，改善医疗服务和公共福祉

Abstract: Pneumonia is a serious global health problem, contributing to high morbidity and mortality, especially in areas with limited diagnostic tools and healthcare resources. This study develops a Convolutional Neural Network (CNN) based on deep learning to automatically detect pneumonia from chest X-ray images. The method involves training the model on labeled datasets with preprocessing techniques such as normalization, data augmentation, and image quality enhancement to improve robustness and generalization. Testing results show that the optimized model achieves 91.67% accuracy, ROC-AUC of 0.96, and PR-AUC of 0.95, demonstrating strong performance in distinguishing pneumonia from normal images. In conclusion, this CNN model has significant potential as a fast, consistent, and reliable diagnostic aid, supporting Society 5.0 by integrating artificial intelligence to improve healthcare services and public well-being.

</details>


### [2] [Learning to Select Like Humans: Explainable Active Learning for Medical Imaging](https://arxiv.org/abs/2602.13308)
*Ifrat Ikhtear Uddin,Longwei Wang,Xiao Qin,Yang Zhou,KC Santosh*

Main category: eess.IV

TL;DR: 提出解释性引导的主动学习框架，结合分类不确定性和注意力对齐度双重标准选择样本，在医学影像数据集上实现更好的数据效率和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学影像分析需要大量标注数据，但专家标注昂贵耗时。传统主动学习方法仅依赖预测不确定性，忽略了模型是否学习临床相关特征这一临床部署的关键要求。

Method: 提出解释性引导的主动学习框架，集成空间注意力对齐到样本获取过程。采用双重标准选择策略：1) 分类不确定性识别信息丰富样本；2) 注意力与放射科医生定义ROI的对齐度，针对模型关注错误特征的样本。使用Dice相似度测量Grad-CAM注意力图与专家标注之间的错位。

Result: 在三个专家标注的医学影像数据集上评估：BraTS（MRI脑肿瘤）、VinDr-CXR（胸部X光）、SIIM-COVID-19（胸部X光）。仅使用570个策略选择样本，该方法在所有数据集上一致优于随机采样，在BraTS上达到77.22%准确率，VinDr-CXR 52.37%，SIIM-COVID 52.66%。Grad-CAM可视化确认模型关注诊断相关区域。

Conclusion: 将解释指导纳入样本获取过程，在保持临床可解释性的同时实现优越的数据效率，证明解释性引导的主动学习框架在医学影像分析中的有效性。

Abstract: Medical image analysis requires substantial labeled data for model training, yet expert annotation is expensive and time-consuming. Active learning (AL) addresses this challenge by strategically selecting the most informative samples for the annotation purpose, but traditional methods solely rely on predictive uncertainty while ignoring whether models learn from clinically meaningful features a critical requirement for clinical deployment. We propose an explainability-guided active learning framework that integrates spatial attention alignment into a sample acquisition process. Our approach advocates for a dual-criterion selection strategy combining: (i) classification uncertainty to identify informative examples, and (ii) attention misalignment with radiologist-defined regions-of-interest (ROIs) to target samples where the model focuses on incorrect features. By measuring misalignment between Grad-CAM attention maps and expert annotations using \emph{Dice similarity}, our acquisition function judiciously identifies samples that enhance both predictive performance and spatial interpretability. We evaluate the framework using three expert-annotated medical imaging datasets, namely, BraTS (MRI brain tumors), VinDr-CXR (chest X-rays), and SIIM-COVID-19 (chest X-rays). Using only 570 strategically selected samples, our explainability-guided approach consistently outperforms random sampling across all the datasets, achieving 77.22\% accuracy on BraTS, 52.37\% on VinDr-CXR, and 52.66\% on SIIM-COVID. Grad-CAM visualizations confirm that the models trained by our dual-criterion selection focus on diagnostically relevant regions, demonstrating that incorporating explanation guidance into sample acquisition yields superior data efficiency while maintaining clinical interpretability.

</details>


### [3] [FUTON: Fourier Tensor Network for Implicit Neural Representations](https://arxiv.org/abs/2602.13414)
*Pooya Ashtari,Pourya Behmandpoor,Nikos Deligiannis,Aleksandra Pizurica*

Main category: eess.IV

TL;DR: FUTON是一种基于傅里叶张量网络的隐式神经表示方法，通过低秩张量分解参数化傅里叶系数，在信号表示和逆问题上优于传统MLP方法，训练速度更快。


<details>
  <summary>Details</summary>
Motivation: 传统基于MLP的隐式神经表示存在收敛慢、容易过拟合噪声、外推能力差等问题，需要一种结合互补归纳偏置的新方法。

Method: 提出FUTON方法，将信号建模为广义傅里叶级数，其系数通过低秩张量分解参数化，结合了傅里叶基的平滑性/周期性偏置和低秩参数化的低维谱结构偏置。

Result: 在图像和体数据表示任务中，FUTON始终优于最先进的MLP基INR方法，训练速度快2-5倍；在图像去噪和超分辨率等逆问题上，泛化能力更好且收敛更快。

Conclusion: FUTON通过结合傅里叶基和低秩张量分解的互补归纳偏置，为隐式神经表示提供了一种高效、泛化能力强的替代方案。

Abstract: Implicit neural representations (INRs) have emerged as powerful tools for encoding signals, yet dominant MLP-based designs often suffer from slow convergence, overfitting to noise, and poor extrapolation. We introduce FUTON (Fourier Tensor Network), which models signals as generalized Fourier series whose coefficients are parameterized by a low-rank tensor decomposition. FUTON implicitly expresses signals as weighted combinations of orthonormal, separable basis functions, combining complementary inductive biases: Fourier bases capture smoothness and periodicity, while the low-rank parameterization enforces low-dimensional spectral structure. We provide theoretical guarantees through a universal approximation theorem and derive an inference algorithm with complexity linear in the spectral resolution and the input dimension. On image and volume representation, FUTON consistently outperforms state-of-the-art MLP-based INRs while training 2--5$\times$ faster. On inverse problems such as image denoising and super-resolution, FUTON generalizes better and converges faster.

</details>


### [4] [A real-time UAS hyperspectral anomaly detection system](https://arxiv.org/abs/2602.13509)
*Thomas P. Watson,Kevin McKenzie,Joseph Conroy,Eddie L. Jacobs*

Main category: eess.IV

TL;DR: 论文提出了一种在小型无人机上实时处理高光谱图像异常检测的端到端解决方案，包括数据采集、异常检测、无线传输和地面站交互显示。


<details>
  <summary>Details</summary>
Motivation: 传统高光谱图像异常检测需要后处理，延迟了结果获取。为了解决这一限制，需要在数据采集时实时检测异常，以便操作人员能够立即获得洞察。

Method: 在可见光和近红外推扫式高光谱图像传感器上实时运行异常检测算法，结合创新的快速地理校正算法，将检测到的异常区域通过无线传输到地面站，供操作人员交互式调查和表征。

Result: 开发了一个完整的端到端实时解决方案，从数据采集到地面站显示交互，使用相对低成本的组件实现了高光谱图像异常检测的实时处理。

Conclusion: 该研究展示了在小型无人机平台上实时进行高光谱图像异常检测的可行性，为操作人员提供了即时洞察能力，克服了传统后处理方法的延迟问题。

Abstract: Detecting anomalies in hyperspectral image data, i.e. regions which are spectrally distinct from the image background, is a common task in hyperspectral imaging. Such regions may represent interesting objects to human operators, but obtaining results often requires post-processing of captured data, delaying insight. To address this limitation, we apply an anomaly detection algorithm to a visible and near-infrared (VNIR) push-broom hyperspectral image sensor in real time onboard a small uncrewed aerial system (UAS), exploring how UAS limitations affect the algorithm. As the generated anomaly information is much more concise than the raw hyperspectral data, it can feasibly be transmitted wirelessly. To detection, we couple an innovative and fast georectification algorithm that enables anomalous areas to be interactively investigated and characterized immediately by a human operator receiving the anomaly data at a ground station. Using these elements, we demonstrate a novel and complete end-to-end solution from data capture and preparation, through anomaly detection and transmission, to ground station display and interaction, all in real time and with relatively low cost components.

</details>


### [5] [Frequency-Enhanced Hilbert Scanning Mamba for Short-Term Arctic Sea Ice Concentration Prediction](https://arxiv.org/abs/2602.13522)
*Feng Gao,Zheng Gong,Wenli Liu,Yanhai Gan,Zhuoran Zheng,Junyu Dong,Qian Du*

Main category: eess.IV

TL;DR: 提出FH-Mamba框架，通过3D Hilbert扫描和频率增强技术改进北极海冰浓度短期预测，解决传统Mamba模型在时间相关性和边界细节上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统Mamba模型在北极海冰浓度预测中难以捕捉时间相关性和边界细节，需要改进以提升预测精度。

Method: 1) 3D Hilbert扫描机制：沿保持局部性的路径遍历3D时空网格；2) 小波变换增强高频细节；3) 混合洗牌注意力模块自适应聚合序列和频率特征。

Result: 在OSI-450a1和AMSR2数据集上实验表明，FH-Mamba优于现有基线方法，在时间一致性和边缘重建方面表现更佳。

Conclusion: Hilbert扫描和频率感知注意力能有效提升北极海冰浓度预测的时间一致性和边缘重建能力，FH-Mamba框架具有优越性能。

Abstract: While Mamba models offer efficient sequence modeling, vanilla versions struggle with temporal correlations and boundary details in Arctic sea ice concentration (SIC) prediction. To address these limitations, we propose Frequency-enhanced Hilbert scanning Mamba Framework (FH-Mamba) for short-term Arctic SIC prediction. Specifically, we introduce a 3D Hilbert scan mechanism that traverses the 3D spatiotemporal grid along a locality-preserving path, ensuring that adjacent indices in the flattened sequence correspond to neighboring voxels in both spatial and temporal dimensions. Additionally, we incorporate wavelet transform to amplify high-frequency details and we also design a Hybrid Shuffle Attention module to adaptively aggregate sequence and frequency features. Experiments conducted on the OSI-450a1 and AMSR2 datasets demonstrate that our FH-Mamba achieves superior prediction performance compared with state-of-the-art baselines. The results confirm the effectiveness of Hilbert scanning and frequency-aware attention in improving both temporal consistency and edge reconstruction for Arctic SIC forecasting. Our codes are publicly available at https://github.com/oucailab/FH-Mamba.

</details>


### [6] [NeuroMambaLLM: Dynamic Graph Learning of fMRI Functional Connectivity in Autistic Brains Using Mamba and Language Model Reasoning](https://arxiv.org/abs/2602.13770)
*Yasaman Torabi,Parsa Razmara,Hamed Ajorlou,Bardia Baraeinejad*

Main category: eess.IV

TL;DR: NeuroMambaLLM：整合动态潜在图学习、选择性状态空间时序建模与LLM的端到端框架，用于动态fMRI分析和自闭症诊断


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个主要问题：1) LLM与脑连接图模型整合有限；2) 大多数fMRI分析方法依赖静态功能连接，掩盖了神经发育障碍（如自闭症）的关键瞬态神经动态；3) 现有状态空间方法（如Mamba）通常作为独立特征提取器使用，缺乏显式高级推理能力

Method: 1) 从原始BOLD时间序列动态学习功能连接，用自适应潜在连接替代固定相关图；2) 抑制运动相关伪影并捕捉长程时间依赖；3) 将动态脑表征投影到LLM嵌入空间，冻结基础语言模型，训练轻量级LoRA模块进行参数高效对齐；4) 使LLM能够执行诊断分类和基于语言的推理

Result: 该方法能够分析动态fMRI模式并生成具有临床意义的文本报告，实现了动态脑功能连接学习与高级语言推理的整合

Conclusion: NeuroMambaLLM提供了一个端到端框架，成功整合了动态潜在图学习、选择性状态空间时序建模和大型语言模型，为神经发育障碍（特别是自闭症）的诊断和临床报告生成提供了新的解决方案

Abstract: Large Language Models (LLMs) have demonstrated strong semantic reasoning across multimodal domains. However, their integration with graph-based models of brain connectivity remains limited. In addition, most existing fMRI analysis methods rely on static Functional Connectivity (FC) representations, which obscure transient neural dynamics critical for neurodevelopmental disorders such as autism. Recent state-space approaches, including Mamba, model temporal structure efficiently, but are typically used as standalone feature extractors without explicit high-level reasoning. We propose NeuroMambaLLM, an end-to-end framework that integrates dynamic latent graph learning and selective state-space temporal modelling with LLMs. The proposed method learns the functional connectivity dynamically from raw Blood-Oxygen-Level-Dependent (BOLD) time series, replacing fixed correlation graphs with adaptive latent connectivity while suppressing motion-related artifacts and capturing long-range temporal dependencies. The resulting dynamic brain representations are projected into the embedding space of an LLM model, where the base language model remains frozen and lightweight low-rank adaptation (LoRA) modules are trained for parameter-efficient alignment. This design enables the LLM to perform both diagnostic classification and language-based reasoning, allowing it to analyze dynamic fMRI patterns and generate clinically meaningful textual reports.

</details>


### [7] [A Deep Convolutional Network to Extract Real-Time Landmarks for UAV Navigation](https://arxiv.org/abs/2602.13814)
*Osman Tokluoglu,Mustafa Ozturk*

Main category: eess.IV

TL;DR: 提出基于卷积深度学习的视觉地标提取方法，用于GNSS拒止环境下无人机导航


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号衰减或被干扰的环境下，无人机需要替代导航方案，视觉地标提取成为关键

Method: 采用卷积神经网络处理无人机机载摄像头图像，提取可靠视觉地标

Result: 验证了所提深度学习方法在GNSS拒止环境下导航的有效性

Conclusion: 卷积深度学习能够有效提取视觉地标，为无人机在GNSS不可用环境提供可靠导航方案

Abstract: Recent advances in satellite and communication technologies have significantly improved geographical information and monitoring systems. Global System for Mobile Communications (GSM) and Global Navigation Satellite System (GNSS) technologies, which rely on electromagnetic signals transmitted from satellites and base stations, have long been utilized for geolocation applications. However, signal attenuation due to environmental conditions or intentional interference such as jamming may lead to severe degradation or complete loss of positioning capability. In such GNSS-denied environments, landmark extraction becomes critical for the navigation of unmanned aerial vehicles (UAVs) used in monitoring applications. By processing images captured from onboard UAV cameras, reliable visual landmarks can be identified to enable navigation without GNSS support. In this study, a convolution-based deep learning approach is proposed for the extraction of appropriate landmarks, and its effectiveness is examined.

</details>


### [8] [Scan-Adaptive Dynamic MRI Undersampling Using a Dictionary of Efficiently Learned Patterns](https://arxiv.org/abs/2602.13984)
*Siddhant Gautam,Angqi Li,Prachi P. Agarwal,Anil K. Attili,Jeffrey A. Fessler,Nicole Seiberlich,Saiprasad Ravishankar*

Main category: eess.IV

TL;DR: 提出基于学习的扫描自适应笛卡尔欠采样模式优化框架，用于加速动态心脏MRI，通过k空间低频搜索选择最优采样模式，显著提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统心脏MRI采集时间长，导致患者不适和运动伪影，需要开发高效的扫描自适应欠采样方法来加速采集同时保持诊断图像质量。

Method: 开发基于学习的框架，使用全采样训练数据优化笛卡尔欠采样模式，推理时通过k空间低频最近邻搜索从学习到的模式字典中选择最优采样掩码。

Result: 在公开和内部心脏MRI数据集上，多个加速因子下均提升重建质量：PSNR增益2-3 dB，降低NMSE，改善SSIM，获得更高放射科医生评分。

Conclusion: 提出的扫描自适应采样框架通过适应个体扫描的k空间采样，实现了更快、更高质量的动态心脏MRI。

Abstract: Cardiac MRI is limited by long acquisition times, which can lead to patient discomfort and motion artifacts. We aim to accelerate Cartesian dynamic cardiac MRI by learning efficient, scan-adaptive undersampling patterns that preserve diagnostic image quality. We develop a learning-based framework for designing scan- or slice-adaptive Cartesian undersampling masks tailored to dynamic cardiac MRI. Undersampling patterns are optimized using fully sampled training dynamic time-series data. At inference time, a nearest-neighbor search in low-frequency $k$-space selects an optimized mask from a dictionary of learned patterns. Our learned sampling approach improves reconstruction quality across multiple acceleration factors on public and in-house cardiac MRI datasets, including PSNR gains of 2-3 dB, reduced NMSE, improved SSIM, and higher radiologist ratings. The proposed scan-adaptive sampling framework enables faster and higher-quality dynamic cardiac MRI by adapting $k$-space sampling to individual scans.

</details>


### [9] [Learnable Multi-level Discrete Wavelet Transforms for 3D Gaussian Splatting Frequency Modulation](https://arxiv.org/abs/2602.14199)
*Hung Nguyen,An Le,Truong Nguyen*

Main category: eess.IV

TL;DR: 本文提出了一种基于多级离散小波变换的频率调制框架，用于减少3D高斯泼溅中的高斯原语数量，同时保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在训练过程中高斯原语数量会显著增长，导致内存和存储成本增加。现有方法如AutoOpti3DGS使用可学习的一级离散小波变换进行频率调制，但调制深度有限，且联合优化会引入梯度竞争，导致过度的高斯密集化。

Method: 提出多级DWT频率调制框架，通过递归分解低频子带构建更深的课程学习，在训练早期提供逐步粗糙的监督。此外，使用单一缩放参数而非学习完整的2抽头高通滤波器进行调制。

Result: 在标准基准测试中，该方法进一步减少了高斯数量，同时保持了具有竞争力的渲染质量。

Conclusion: 多级DWT频率调制框架能有效控制3DGS中高斯原语的增长，减少内存和存储需求，同时保持渲染性能。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful approach for novel view synthesis. However, the number of Gaussian primitives often grows substantially during training as finer scene details are reconstructed, leading to increased memory and storage costs. Recent coarse-to-fine strategies regulate Gaussian growth by modulating the frequency content of the ground-truth images. In particular, AutoOpti3DGS employs the learnable Discrete Wavelet Transform (DWT) to enable data-adaptive frequency modulation. Nevertheless, its modulation depth is limited by the 1-level DWT, and jointly optimizing wavelet regularization with 3D reconstruction introduces gradient competition that promotes excessive Gaussian densification. In this paper, we propose a multi-level DWT-based frequency modulation framework for 3DGS. By recursively decomposing the low-frequency subband, we construct a deeper curriculum that provides progressively coarser supervision during early training, consistently reducing Gaussian counts. Furthermore, we show that the modulation can be performed using only a single scaling parameter, rather than learning the full 2-tap high-pass filter. Experimental results on standard benchmarks demonstrate that our method further reduces Gaussian counts while maintaining competitive rendering quality.

</details>


### [10] [Deep Image Prior for Computed Tomography Reconstruction](https://arxiv.org/abs/2602.14709)
*Simon Arridge,Riccardo Barbano,Alexander Denker,Zeljko Kereta*

Main category: eess.IV

TL;DR: 本文全面综述了深度图像先验（DIP）框架及其在CT图像重建中的应用，重点介绍了DIP在无监督、单测量条件下的优势，以及防止过拟合和加速计算的各种策略。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习图像重建方法需要大量有监督数据集，而DIP框架能够在完全无监督、仅需单次测量的条件下工作，即使在噪声存在时也能有效重建，这为解决数据稀缺和标注困难问题提供了新思路。

Method: DIP利用卷积神经网络的隐式偏置，在无监督设置下工作。论文描述了标准DIP公式，并介绍了防止过拟合的策略：早停法、显式正则化、自适应网络输入的自引导方法。还探讨了计算改进：热启动和随机优化方法以减少重建时间。

Result: 在真实μCT测量数据上测试了讨论的方法，能够评估不同修改和扩展之间的权衡关系，验证了DIP在CT图像重建中的有效性。

Conclusion: DIP为CT图像重建提供了一种有前景的无监督方法，通过适当的正则化和优化策略可以有效控制过拟合并提高计算效率，在数据稀缺场景下具有显著优势。

Abstract: We present a comprehensive overview of the Deep Image Prior (DIP) framework and its applications to image reconstruction in computed tomography. Unlike conventional deep learning methods that rely on large, supervised datasets, the DIP exploits the implicit bias of convolutional neural networks and operates in a fully unsupervised setting, requiring only a single measurement, even in the presence of noise. We describe the standard DIP formulation, outline key algorithmic design choices, and review several strategies to mitigate overfitting, including early stopping, explicit regularisation, and self-guided methods that adapt the network input. In addition, we examine computational improvements such as warm-start and stochastic optimisation methods to reduce the reconstruction time. The discussed methods are tested on real $μ$CT measurements, which allows examination of trade-offs among the different modifications and extensions.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [11] [SIM-assisted Secure Mobile Communications via Enhanced Proximal Policy Optimization Algorithm](https://arxiv.org/abs/2602.13265)
*Wenxuan Ma,Bin Lin,Hongyang Pan,Geng Sun,Enyu Shi,Jiancheng An,Chau Yuen*

Main category: eess.SP

TL;DR: 本文提出了一种基于堆叠智能超表面（SIM）的6G移动用户安全通信系统，采用增强型近端策略优化算法（PPO-BOP）解决信道不确定性和硬件损伤下的联合功率与相移优化问题，显著提升了可实现的保密速率。


<details>
  <summary>Details</summary>
Motivation: 随着6G无线通信网络的发展，移动用户面临日益突出的安全挑战。物理层安全技术利用无线信道固有特性提供安全保障，而堆叠智能超表面通过多层结构直接操控电磁波，为高效能物理层安全提供了新可能。本文旨在解决移动环境中信道不确定性、多用户干扰和硬件损伤等实际问题。

Method: 提出SIM辅助的安全通信系统，针对窃听者威胁下的移动用户。为解决联合功率和相移优化问题（JPPSOP），设计了增强型近端策略优化算法PPO-BOP，包含双向长短期记忆机制、离策略数据利用机制和策略反馈机制，以捕获短期信道衰落和长期用户移动性。

Result: 大量仿真结果表明，PPO-BOP算法在可实现保密速率方面显著优于基准策略和其他深度强化学习算法，有效提升了移动用户的安全通信性能。

Conclusion: SIM辅助的安全通信系统结合PPO-BOP算法能够有效应对6G移动环境中的安全挑战，通过智能优化功率和相移配置，在存在信道不确定性和硬件损伤的情况下实现更高的保密通信性能。

Abstract: With the development of sixth-generation (6G) wireless communication networks, the security challenges are becoming increasingly prominent, especially for mobile users (MUs). As a promising solution, physical layer security (PLS) technology leverages the inherent characteristics of wireless channels to provide security assurance. Particularly, stacked intelligent metasurface (SIM) directly manipulates electromagnetic waves through their multilayer structures, offering significant potential for enhancing PLS performance in an energy efficient manner. Thus, in this work, we investigate an SIM-assisted secure communication system for MUs under the threat of an eavesdropper, addressing practical challenges such as channel uncertainty in mobile environments, multiple MU interference, and residual hardware impairments. Consequently, we formulate a joint power and phase shift optimization problem (JPPSOP), aiming at maximizing the achievable secrecy rate (ASR) of all MUs. Given the non-convexity and dynamic nature of this optimization problem, we propose an enhanced proximal policy optimization algorithm with a bidirectional long short-term memory mechanism, an off-policy data utilization mechanism, and a policy feedback mechanism (PPO-BOP). Through these mechanisms, the proposed algorithm can effectively capture short-term channel fading and long-term MU mobility, improve sample utilization efficiency, and enhance exploration capabilities. Extensive simulation results demonstrate that PPO-BOP significantly outperforms benchmark strategies and other deep reinforcement learning algorithms in terms of ASR.10.1109/TWC.2026.3658332

</details>


### [12] [Sample-level EEG-based Selective Auditory Attention Decoding with Markov Switching Models](https://arxiv.org/abs/2602.13447)
*Yuanyuan Yao,Simon Geirnaert,Tinne Tuytelaars,Alexander Bertrand*

Main category: eess.SP

TL;DR: 提出基于马尔可夫切换模型（MSM）的集成框架，用于选择性听觉注意解码，实现样本级解码并提高注意力切换检测速度


<details>
  <summary>Details</summary>
Motivation: 现有方法多在窗口级操作，面临时间分辨率与解码精度的权衡问题。虽然HMM后处理可以平滑窗口级输出，但需要单独的平滑步骤。本文旨在将解码和平滑集成到统一的概率框架中。

Method: 使用马尔可夫切换模型（MSM）将解码和平滑组件集成到单一概率框架中。模型直接建模每个注意力状态下EEG与语音包络的关系，同时纳入注意力的时间动态特性。通过期望最大化算法联合估计模型参数和注意力状态，实现样本级注意力解码。

Result: 实验结果表明，集成的MSM框架在解码精度上与HMM后处理相当，同时提供更快的注意力切换检测速度。

Conclusion: MSM框架成功将选择性听觉注意解码中的解码和平滑过程统一起来，在保持精度的同时提高了时间分辨率，为实时脑机接口应用提供了更好的基础。

Abstract: Selective auditory attention decoding aims to identify the speaker of interest from listeners' neural signals, such as electroencephalography (EEG), in the presence of multiple concurrent speakers. Most existing methods operate at the window level, facing a trade-off between temporal resolution and decoding accuracy. Recent work has shown that hidden Markov model (HMM)-based post-processing can smooth window-level decoder outputs to improve this trade-off. Instead of using a separate smoothing step, we propose to integrate the decoding and smoothing components into a single probabilistic framework using a Markov switching model (MSM). It directly models the relationship between the EEG and speech envelopes under each attention state while incorporating the temporal dynamics of attention. This formulation enables sample-level attention decoding, with model parameters and attention states jointly estimated via the expectation-maximization algorithm. Experimental results demonstrate that this integrated MSM formulation achieves comparable decoding accuracy to HMM post-processing while providing faster attention switch detection. The code for the proposed method is available at https://github.com/YYao-42/MSM.

</details>


### [13] [Towards Causality-Aware Modeling for Multimodal Brain-Muscle Interactions](https://arxiv.org/abs/2602.13459)
*Farwa Abbas,Wei Dai,Zoran Cvetkovic,Verity McClelland*

Main category: eess.SP

TL;DR: 提出了一种结合动态贝叶斯网络和收敛交叉映射的因果推断框架，用于分析多模态生物医学信号中的动态因果相互作用


<details>
  <summary>Details</summary>
Motivation: 传统方法如动态贝叶斯网络通常假设线性或简单统计依赖，而流形方法如收敛交叉映射能捕捉非线性滞后相互作用但缺乏概率量化和干预建模，需要更强大的多模态生物医学信号因果分析方法

Method: 提出DBN-informed CCM框架，将几何流形重建与概率时间建模相结合，应用于肌张力障碍和神经典型儿童的多模态EEG-EMG记录

Result: 该方法能够量化不确定性、支持干预模拟，并揭示肌张力障碍中皮质肌肉通路的频率特异性重组，相比基线方法在预测一致性和因果稳定性方面有显著改进

Conclusion: 该因果感知多模态建模方法具有开发定量生物标志物和指导靶向神经调节干预的潜力

Abstract: Robust characterization of dynamic causal interactions in multivariate biomedical signals is essential for advancing computational and algorithmic methods in biomedical imaging. Conventional approaches, such as Dynamic Bayesian Networks (DBNs), often assume linear or simple statistical dependencies, while manifold based techniques like Convergent Cross Mapping (CCM) capture nonlinear, lagged interactions but lack probabilistic quantification and interventional modeling. We introduce a DBN informed CCM framework that integrates geometric manifold reconstruction with probabilistic temporal modeling. Applied to multimodal EEG-EMG recordings from dystonic and neurotypical children, the method quantifies uncertainty, supports interventional simulation, and reveals distinct frequency specific reorganization of corticomuscular pathways in dystonia. Experimental results show marked improvements in predictive consistency and causal stability as compared to baseline approaches, demonstrating the potential of causality aware multimodal modeling for developing quantitative biomarkers and guiding targeted neuromodulatory interventions.

</details>


### [14] [Blind Deconvolution Demixing using Modulated Inputs](https://arxiv.org/abs/2602.13481)
*Humera Hameed,Ali Ahmed*

Main category: eess.SP

TL;DR: 该论文提出了一种解决涉及调制输入的盲解卷积混合问题的方法，通过确定性子空间假设和梯度下降算法，在满足调制速率和采样复杂度条件下，可以从观测混合信号中恢复所有原始信号和信道。


<details>
  <summary>Details</summary>
Motivation: 解决盲解卷积混合这一具有挑战性的问题，特别是当多个带限输入信号被已知随机序列调制后，经过不同信道卷积并叠加为单一观测信号时，如何从混合信号中恢复原始信号和信道响应。

Method: 采用确定性子空间假设处理输入信号，保持信道冲激响应任意性。当调制序列变化速率满足Q ≥ N²(B+M)且采样复杂度边界被遵守时，使用梯度下降算法从观测混合信号y(t)中估计所有信号和信道{s_n(t), h_n(t)}。

Result: 通过大量仿真验证了算法的鲁棒性，并使用相变图数值研究了算法提供的理论保证。结果表明在满足条件的情况下，可以从观测混合信号中成功恢复所有原始信号和信道。

Conclusion: 该研究证明了在适当的调制速率和采样复杂度条件下，通过梯度下降算法可以有效解决盲解卷积混合问题，为涉及调制输入的信号分离提供了理论保证和实用算法。

Abstract: This paper focuses on solving a challenging problem of blind deconvolution demixing involving modulated inputs. Specifically, multiple input signals $s_n(t)$, each bandlimited to $B$ Hz, are modulated with known random sequences $r_n(t)$ that alter at rate $Q$. Each modulated signal is convolved with a different M tap channel of impulse response $h_n(t)$, and the outputs of each channel are added at a common receiver to give the observed signal $y(t)=\sum_{n=1}^N (r_n(t)\odot s_n(t))\circledast h_n(t)$, where $\odot$ is the point wise multiplication, and $\circledast$ is circular convolution. Given this observed signal $y(t)$, we are concerned with recovering $s_n(t)$ and $h_n(t)$. We employ deterministic subspace assumption for the input signal $s_n(t)$ and keep the channel impulse response $h_n(t)$ arbitrary. We show that if modulating sequence is altered at a rate $Q \geq N^2 (B+M)$ and sample complexity bound is obeyed then all the signals and the channels, $\{s_n(t),h_n(t)\}_{n=1}^N$, can be estimated from the observed mixture $y(t)$ using gradient descent algorithm. We have performed extensive simulations that show the robustness of our algorithm and used phase transitions to numerically investigate the theoretical guarantees provided by our algorithm.

</details>


### [15] [Feasibility of simultaneous EEG-fMRI at 0.55 T: Recording, Denoising, and Functional Mapping](https://arxiv.org/abs/2602.13489)
*Parsa Razmara,Takfarinas Medani,Majid Abbasi Sisara,Anand A. Joshi,Rui Chen,Woojae Jeong,Ye Tian,Krishna S. Nayak,Richard M. Leahy*

Main category: eess.SP

TL;DR: 本研究证明了在0.55T低场强下同时进行EEG-fMRI的可行性，展示了减少的BCG伪影和保留的alpha节律，支持神经血管耦合测量。


<details>
  <summary>Details</summary>
Motivation: 传统高场强（≥3T）EEG-fMRI存在多种技术限制：EEG信号伪影、金属植入物兼容性差、高噪声、高磁敏感区域伪影等。本研究探索低场强（0.55T）作为替代方案，以克服这些限制。

Method: 采用概念验证研究设计，在0.55T磁场下进行视觉任务的同时EEG-fMRI记录。分析梯度伪影和心搏伪影（BCG），建立多模态整合流程，比较EEG功率包络与BOLD血流动力学响应。

Result: 观察到BCG幅度降低，与静态磁场强度相关的脉冲伪影预期缩放一致。alpha节律和信号完整性得以保留。EEG功率包络与BOLD响应对应，支持神经血管耦合测量潜力。

Conclusion: 0.55T低场强下的同时EEG-fMRI是可行的，为多模态神经成像提供了有前景的环境，具有减少伪影、改善兼容性等优势。

Abstract: Simultaneous recording of electroencephalography (EEG) and functional MRI (fMRI) can provide a more complete view of brain function by merging high temporal and spatial resolutions. High-field ($\geq$3T) systems are standard, and require technical trade-offs, including artifacts in the EEG signal, reduced compatibility with metallic implants, high acoustic noise, and artifacts around high-susceptibility areas such as the optic nerve and nasal sinus. This proof-of-concept study demonstrates the feasibility of simultaneous EEG-fMRI at 0.55T in a visual task. We characterize the gradient and ballistocardiogram (BCG) artifacts inherent to this environment and observe reduced BCG magnitude consistent with the expected scaling of pulse-related artifacts with static magnetic field strength. This reduction shows promise for facilitating effective denoising while preserving the alpha rhythm and signal integrity. Furthermore, we tested a multimodal integration pipeline and demonstrated that the EEG power envelope corresponds with the hemodynamic BOLD response, supporting the potential to measure neurovascular coupling in this environment. We demonstrate that combined EEG-fMRI at 0.55T is feasible and represents a promising environment for multimodal neuroimaging.

</details>


### [16] [Sub Specie Aeternitatis: Fourier Transforms from the Theory of Heat to Musical Signals](https://arxiv.org/abs/2602.13520)
*Victor Lazzarini*

Main category: eess.SP

TL;DR: 本文追溯傅里叶定理从热传导物理到现代音乐信号理论的发展历程，探讨时间与频率的固有对偶性。


<details>
  <summary>Details</summary>
Motivation: 论文旨在通过原始文献追溯傅里叶定理的发展历程，展示其如何从1822年傅里叶的热传导理论出发，经过欧姆、亥姆霍兹、德摩根和狄拉克等人的贡献，最终形成现代音乐信号处理的基础理论。

Method: 采用历史研究方法，完全基于原始文献（primary sources）进行分析，追踪傅里叶定理从傅里叶1822年的《热的解析理论》开始，经过19世纪欧姆和亥姆霍兹在音乐声学中的应用，德摩根在微积分中对无穷的处理，到20世纪狄拉克对无穷性质的洞察这一完整发展脉络。

Result: 论文系统梳理了傅里叶定理的完整发展历史：1）傅里叶1822年提出的三角级数系数确定方法和傅里叶二重积分；2）欧姆和亥姆霍兹将其应用于音乐声学理论；3）德摩根1842年用其处理不连续函数中的无穷问题；4）狄拉克对无穷性质的洞察使频率谱和时间函数的对偶描述成为可能；5）最终形成现代音乐信号处理的理论基础。

Conclusion: 傅里叶定理的发展历程展示了数学物理思想从热传导到音乐信号处理的跨领域传播，揭示了时间与频率之间的固有对偶性，这一对偶性已成为现代信号处理理论的核心基础。

Abstract: J. B. Fourier in his \emph{Théorie Analytique de la Chaleur} of 1822 introduced, amongst other things, two ideas that have made a fundamental impact in fields as diverse as Mathematical Physics, Electrical Engineering, Computer Science, and Music. The first one of these, a method to find the coefficients for a trigonometric series describing an arbitrary function, was very early on picked up by G. Ohm and H. Helmholtz as the foundation for a theory of \emph{musical tones}. The second one, which is described by Fourier's double integral, became the basis for treating certain kinds of infinity in discontinuous functions, as shown by A. De Morgan in his 1842 \emph{The Differential and Integral Calculus}. Both make up the fundamental basis for what is now commonly known as the \emph{Fourier theorem}. With the help of P. A. M. Dirac's insights into the nature of these infinities, we can have a compact description of the frequency spectrum of a function of time, or conversely of a waveform corresponding to a given function of frequency. This paper, using solely primary sources, takes us from the physics of heat propagation to the modern theory of musical signals. It concludes with some considerations on the inherent duality of time and frequency emerging from Fourier's theorem.

</details>


### [17] [DopplerGLRTNet for Radar Off-Grid Detection](https://arxiv.org/abs/2602.13546)
*Yadang Alexis Rouzoumka,Jean Pinsolle,Eugénie Terreaux,Christèle Morisseau,Jean-Philippe Ovarlez,Chengfang Ren*

Main category: eess.SP

TL;DR: 提出DopplerGLRTNet，一种摊销的离网格GLRT检测器，通过轻量回归器预测连续多普勒频率，解决传统NMF检测器在离网格目标时检测概率饱和的问题。


<details>
  <summary>Details</summary>
Motivation: 传统归一化匹配滤波(NMF)检测器在处理离网格目标（多普勒或角度不在离散处理网格上）时，即使在高信噪比下，检测概率也会在低虚警率下饱和，严重影响检测性能。连续参数GLRT虽然可以解决此问题，但密集扫描会增加计算成本，且对协方差失配敏感。

Method: 提出DopplerGLRTNet：1）使用轻量回归器从白化观测中预测分辨率单元内的连续多普勒频率；2）检测器输出单个GLRT/NMF类分数，该分数基于预测多普勒处的归一化匹配滤波能量。

Result: 蒙特卡洛仿真表明：1）DopplerGLRTNet缓解了离网格饱和问题；2）以远低于密集扫描的成本接近其性能；3）在相同经验校准的虚警概率下，提高了对协方差估计的鲁棒性。

Conclusion: DopplerGLRTNet通过摊销离网格GLRT，有效解决了传统检测器的离网格目标检测问题，在计算效率和鲁棒性方面均有显著改进。

Abstract: Off-grid targets whose Doppler (or angle) does not lie on the discrete processing grid can severely degrade classical normalized matched-filter (NMF) detectors: even at high SNR, the detection probability may saturate at operationally relevant low false-alarm rates. A principled remedy is the continuous-parameter GLRT, which maximizes a normalized correlation over the parameter domain; however, dense scanning increases test-time cost and remains sensitive to covariance mismatch through whitening. We propose DopplerGLRTNet, an amortized off-grid GLRT: a lightweight regressor predicts the continuous Doppler within a resolution cell from the whitened observation, and the detector outputs a single GLRT/NMF-like score given by the normalized matched-filter energy at the predicted Doppler. Monte Carlo simulations in Gaussian and compound-Gaussian clutter show that DopplerGLRTNet mitigates off-grid saturation, approaches dense-scan performance at a fraction of its cost, and improves robustness to covariance estimation at the same empirically calibrated Pfa.

</details>


### [18] [Twenty-five years of J-DSP Online Labs for Signal Processing Classes and Workforce Development Programs](https://arxiv.org/abs/2602.13863)
*Andreas Spanias*

Main category: eess.SP

TL;DR: J-DSP是一个在线数字信号处理仿真程序，最初用Java开发，后迁移到HTML5，支持数字滤波器设计、FFT频谱分析、机器学习信号分类和量子傅里叶变换等实验，已在多所大学使用并应用于NSF项目。


<details>
  <summary>Details</summary>
Motivation: 开发在线仿真程序支持DSP课程的在线实验室教学，最初于2000年在ASU的DSP课程中部署，旨在提供便捷的数字信号处理实验平台。

Method: 最初使用Java开发，后过渡到更安全的HTML5环境；开发了移动版本（iOS和Android）；支持多种DSP实验功能，包括数字滤波器设计、FFT频谱分析、机器学习信号分类和量子傅里叶变换。

Result: J-DSP至今仍在多所大学使用，其特定功能已应用于NSF的REU、IRES和RET人才培养项目以及高中推广活动；开发过程中进行了评估记录。

Conclusion: J-DSP作为一个持续发展的在线DSP仿真平台，成功支持了大学教学和人才培养项目，证明了其教育价值和实用性。

Abstract: This paper presents the history of the online simulation program Java-DSP (J-DSP) and the most recent function development and deployment. J-DSP was created to support online laboratories in DSP classes and was first deployed in our ASU DSP class in 2000. The development of the program and its extensions was supported by several NSF grants including CCLI and IUSE. The web-based software was developed by our team in Java and later transitioned to the more secure HTML5 environment. J-DSP supports laboratory exercises on: digital filters and their design, the FFT and its utility in spectral analysis, machine learning for signal classification, and more recently online simulations with the Quantum Fourier Transform. Throughout the J-DSP development and deployment of this tool and its associated laboratory exercises, we documented evaluations. Mobile versions of the program for iOS and Android were also developed. J-DSP is used to this day in several universities, and specific functions of the program have been used in NSF REU, IRES and RET workforce development and high school outreach.

</details>


### [19] [Efficient Off-Grid Near-Field Cascade Channel Estimation for XL-IRS Systems via Tucker Decomposition](https://arxiv.org/abs/2602.13988)
*Wenzhou Cao,Yashuai Cao,Tiejun Lv,Mugen Peng*

Main category: eess.SP

TL;DR: 提出基于稀疏Tucker分解的无网格级联信道估计框架，用于解决XL-IRS近场效应下的信道估计问题，相比传统方法在NMSE上提升13.6dB且显著降低运行时间。


<details>
  <summary>Details</summary>
Motivation: XL-IRS的大孔径导致近场球面波传播效应，使级联信道估计复杂化。传统基于字典的方法存在累积量化误差和高复杂度问题，特别是在UPA系统中。

Method: 首先提出基于张量建模的方法，利用UPA结构BS的水平/垂直响应向量与IRS入射-反射阵列响应向量的张量积。然后提出基于稀疏Tucker分解的无网格级联信道估计框架，将接收信号建模为Tucker张量，其中稀疏核心张量捕获路径增益-延迟项，三个因子矩阵由BS和近场IRS阵列响应张成。最后通过高阶奇异值分解预处理、主化-最小化和定制的张量过松弛快速迭代收缩阈值技术加速。

Result: 仿真显示所提方案在归一化均方误差上比基准方法提升13.6dB，同时显著减少运行时间。推导了Cramér-Rao下界并进行了收敛性分析。

Conclusion: 提出的基于稀疏Tucker分解的无网格级联信道估计框架能有效解决XL-IRS近场效应下的信道估计问题，避免了量化误差，提高了估计精度和效率。

Abstract: Accurate cascaded channel state information is pivotal for extremely large-scale intelligent reflecting surfaces (XL-IRS) in next-generation wireless networks. However, the large XL-IRS aperture induces spherical wavefront propagation due to near-field (NF) effects, complicating cascaded channel estimation. Conventional dictionary-based methods suffer from cumulative quantization errors and high complexity, especially in uniform planar array (UPA) systems. To address these issues, we first propose a tensor modelization method for NF cascaded channels by exploiting the tensor product among the horizontal and vertical response vectors of the UPA-structured base station (BS) and the incident-reflective array response vector of the IRS. This structure leverages spatial characteristics, enabling independent estimation of factor matrices to improve efficiency. Meanwhile, to avoid quantization errors, we propose an off-grid cascaded channel estimation framework based on sparse Tucker decomposition. Specifically, we model the received signal as a Tucker tensor, where the sparse core tensor captures path gain-delay terms and three factor matrices are spanned by BS and NF IRS array responses. We then formulate a sparse core tensor minimization problem with tri-modal log-sum sparsity constraints to tackle the NP-hard challenge. Finally, the method is accelerated via higher-order singular value decomposition preprocessing, combined with majorization-minimization and a tailored tensor over-relaxation fast iterative shrinkage-thresholding technique. We derive the Cramér-Rao lower bound and conduct convergence analysis. Simulations show the proposed scheme achieves a 13.6 dB improvement in normalized mean square error over benchmarks with significantly reduced runtime.

</details>


### [20] [Lightweight Range-Angle Imaging Based Algorithm for Quasi-Static Human Detection on Low-Cost FMCW Radar](https://arxiv.org/abs/2602.14001)
*Huy Trinh,George Shaker*

Main category: eess.SP

TL;DR: 提出基于低成本60GHz FMCW雷达的轻量级非视觉图像方法，用于准静态人体存在检测，相比传统CFAR检测器显著提升准确率和速度


<details>
  <summary>Details</summary>
Motivation: 准静态人体活动（如躺、站、坐）产生的多普勒频移极低且雷达特征高度扩散，传统CFAR检测器难以检测；摄像头在长期护理设施中存在隐私和低光照限制

Method: 使用低成本60GHz FMCW雷达，采用基于图像的处理方法，通过共享的距离-角度预处理管道，实现轻量级准静态人体存在检测

Result: 在五种半静态活动数据集上，检测准确率从CA-CFAR的68.3%和OS-CFAR的78.8%提升至93.24%（受试者1），从51.3%/68.3%提升至92.3%（受试者2），从57.72%/69.94%提升至94.82%（受试者3）；在树莓派4B上实现平均每帧8.2ms处理速度，达到120+FPS，比OS-CFAR快74倍

Conclusion: 简单的基于图像的处理方法能够在杂乱室内环境中提供鲁棒且可部署的准静态人体感知，解决了传统雷达检测器和摄像头在长期护理应用中的局限性

Abstract: Quasi-static human activities such as lying, standing or sitting produce very low Doppler shifts and highly spread radar signatures, making them difficult to detect with conventional constant-false-alarm rate (CFAR) detectors tuned for point targets. Moreover, privacy concerns and low lighting conditions limit the use of cameras in long-term care (LTC) facilities. This paper proposes a lightweight, non-visual image-based method for robust quasi-static human presence detection using a low-cost 60 GHz FMCW radar. On a dataset covering five semi-static activities, the proposed method improves average detection accuracy from 68.3% for Cell-Averaging CFAR (CA-CFAR) and 78.8% for Order-Statistics CFAR (OS-CFAR) to 93.24% for Subject 1, from 51.3%, 68.3% to 92.3% for Subject 2, and 57.72%, 69.94% to 94.82% for Subject 3, respectively. Finally, we benchmarked all three detectors across all activities on a Raspberry Pi 4B using a shared Range-Angle (RA) preprocessing pipeline. The proposed algorithm obtains an average 8.2 ms per frame, resulting in over 120 frames per second (FPS) and a 74 times speed-up over OS-CFAR. These results demonstrate that simple image-based processing can provide robust and deployable quasi-static human sensing in cluttered indoor environments.

</details>


### [21] [Rethinking RSSI for WiFi Sensing](https://arxiv.org/abs/2602.14004)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Y. Jay Guo*

Main category: eess.SP

TL;DR: WiRSSI：仅使用RSSI测量的双基地WiFi感知框架，实现被动人体追踪，精度接近CSI方法


<details>
  <summary>Details</summary>
Motivation: RSSI在商用WiFi设备上广泛可用，但通常被认为分辨率太低，不适合精细感知。本文重新审视其感知潜力，探索仅使用RSSI实现被动人体追踪的可能性。

Method: 采用1Tx-3Rx配置，可扩展至MIMO部署。首先揭示CSI功率如何隐式编码相位信息，以及这种关系如何延续到RSSI。通过2D快速傅里叶变换提取多普勒-到达角特征，在没有子载波级相位的情况下从幅度信息推断延迟。然后将估计的到达角和延迟映射到笛卡尔坐标并进行去噪以恢复运动轨迹。

Result: 在实际环境实验中，WiRSSI对椭圆、直线和矩形轨迹的中位XY定位误差分别为0.905米、0.784米和0.785米。相比之下，代表性的CSI方法的中位误差为0.574米、0.599米和0.514米，平均精度差距为0.26米。

Conclusion: 尽管分辨率较低，但RSSI可以支持实用的被动感知，为基于CSI的WiFi感知提供了低成本替代方案。

Abstract: The Received Signal Strength Indicator (RSSI) is widely available on commodity WiFi devices but is commonly regarded as too coarse for fine-grained sensing. This paper revisits its sensing potential and presents WiRSSI, a bistatic WiFi sensing framework for passive human tracking using only RSSI measurements. WiRSSI adopts a 1Tx-3Rx configuration and is readily extensible to Multiple-Input Multiple-Output (MIMO) deployments. We first reveal how CSI power implicitly encodes phase-related information and how this relationship carries over to RSSI, showing that RSSI preserves exploitable Doppler, Angle-of-Arrival (AoA), and delay cues associated with human motion. WiRSSI then extracts Doppler-AoA features via a 2D Fast Fourier Transform and infers delay from amplitude-only information in the absence of subcarrier-level phase. The estimated AoA and delay are then mapped to Cartesian coordinates and denoised to recover motion trajectories. Experiments in practical environments show that WiRSSI achieves median XY localization errors of 0.905 m, 0.784 m, and 0.785 m for elliptical, linear, and rectangular trajectories, respectively. In comparison, a representative CSI-based method attains median errors of 0.574 m, 0.599 m, and 0.514 m, corresponding to an average accuracy gap of 0.26 m. These results demonstrate that, despite its lower resolution, RSSI can support practical passive sensing and offers a low-cost alternative to CSI-based WiFi sensing.

</details>


### [22] [Extended Universal Joint Source-Channel Coding for Digital Semantic Communications: Improving Channel-Adaptability](https://arxiv.org/abs/2602.14018)
*Eunsoo Kim,Yoon Huh,Wan Choi*

Main category: eess.SP

TL;DR: 提出euJSCC框架，通过超网络归一化和动态码本生成实现SNR和调制自适应的语义通信，在块衰落和AWGN信道下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于VQ的JSCC方法（如uJSCC）使用固定的调制专用编码器、解码器和码本，无法适应细粒度的SNR变化，限制了在动态无线环境中的适应性。

Method: 提出euJSCC框架：1）超网络归一化层实现细粒度特征向量归一化；2）动态码本生成网络根据块级SNR优化调制专用基础码本；3）内外编码器-解码器架构处理块衰落信道；4）两阶段训练策略（AWGN预训练+块衰落微调）。

Result: 图像传输实验表明，euJSCC在块衰落和AWGN信道下均优于最先进的信道自适应数字JSCC方案。

Conclusion: euJSCC框架通过SNR和调制自适应传输，在单一模型中实现了对动态无线环境的更好适应性，为语义通信提供了更灵活的解决方案。

Abstract: Recent advances in deep learning (DL)-based joint source-channel coding (JSCC) have enabled efficient semantic communication in dynamic wireless environments. Among these approaches, vector quantization (VQ)-based JSCC effectively maps high-dimensional semantic feature vectors into compact codeword indices for digital modulation. However, existing methods, including universal JSCC (uJSCC), rely on fixed, modulation-specific encoders, decoders, and codebooks, limiting adaptability to fine-grained SNR variations. We propose an extended universal JSCC (euJSCC) framework that achieves SNR- and modulation-adaptive transmission within a single model. euJSCC employs a hypernetwork-based normalization layer for fine-grained feature vector normalization and a dynamic codebook generation (DCG) network that refines modulation-specific base codebooks according to block-wise SNR. To handle block fading channels, which consist of multiple coherence blocks, an inner-outer encoder-decoder architecture is adopted, where the outer encoder and decoder capture long-term channel statistics, and the inner encoder and decoder refine feature vectors to align with block-wise codebooks. A two-phase training strategy, i.e., pretraining on AWGN channels followed by finetuning on block fading channels, ensures stable convergence. Experiments on image transmission demonstrate that euJSCC consistently outperforms state-of-the-art channel-adaptive digital JSCC schemes under both block fading and AWGN channels.

</details>


### [23] [Convexity Meets Curvature: Lifted Near-Field Super-Resolution](https://arxiv.org/abs/2602.14063)
*Sajad Daei,Gábor Fodor,Mikael Skoglund*

Main category: eess.SP

TL;DR: 提出一种基于凸优化的无网格超分辨方法，用于解决近场阵列处理中的联合角度-距离估计问题，特别适用于混合前端和欠采样场景。


<details>
  <summary>Details</summary>
Motivation: 随着超大孔径、高频段和通感一体化的发展，阵列处理进入菲涅尔区域，球面波前导致孔径上的相位随距离变化。这种曲率破坏了经典子空间方法的傅里叶/范德蒙结构，特别是在混合前端仅提供少量测量时，传统方法需要昂贵的2D网格搜索。

Method: 通过贝塞尔-范德蒙分解揭示菲涅尔相位流形的隐藏结构，将角度依赖分离为范德蒙结构，距离依赖压缩为系数映射。引入提升映射将每个距离单元和连续角度映射到结构化秩一原子，将非线性近场模型转化为线性逆问题。采用原子范数最小化，通过有界三角多项式的对偶表征实现基于证书的定位。

Result: 仿真验证表明，在强欠采样的混合观测下，该方法能够可靠地实现联合角度-距离恢复，适用于下一代无线和通感一体化系统。

Conclusion: 通过凸优化方法结合贝塞尔-范德蒙分解，实现了近场测量的无网格超分辨，解决了传统方法在混合前端和欠采样场景下的局限性，为下一代无线系统提供了有效的联合角度-距离估计方案。

Abstract: Extra-large apertures, high carrier frequencies, and integrated sensing and communications (ISAC) are pushing array processing into the Fresnel region, where spherical wavefronts induce a range-dependent phase across the aperture. This curvature breaks the Fourier/Vandermonde structure behind classical subspace methods, and it is especially limiting with hybrid front-ends that provide only a small number of pilot measurements. Consequently, practical systems need continuous angle resolution and joint angle-range inference where many near-field approaches still rely on costly 2D gridding. We show that convexity can meet curvature via a lifted, gridless superresolution framework for near-field measurements. The key is a Bessel-Vandermonde factorization of the Fresnel-phase manifold that exposes a hidden Vandermonde structure in angle while isolating the range dependence into a compact coefficient map. Building on this, we introduce a lifting that maps each range bin and continuous angle to a structured rank-one atom, converting the nonlinear near-field model into a linear inverse problem over a row-sparse matrix. Recovery is posed as atomic-norm minimization and an explicit dual characterization via bounded trigonometric polynomials yields certificate-based localization that super-resolves off-grid angles and identifies active range bins. Simulations with strongly undersampled hybrid observations validate reliable joint angle-range recovery for next-generation wireless and ISAC systems.

</details>


### [24] [Reconfigurable Intelligent Surfaces-assisted Positioning in Integrated Sensing and Communication Systems](https://arxiv.org/abs/2602.14415)
*Huyen-Trang Ta,Ngoc-Son Duong,Trung-Hieu Nguyen,Van-Linh Nguyen,Thai-Mai Dinh*

Main category: eess.SP

TL;DR: 提出一种RIS辅助ISAC系统中的高精度目标定位方法，通过粗估计和快速迭代优化实现精度与复杂度的平衡


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的ISAC系统中，如何实现高精度目标定位同时降低计算复杂度是一个重要挑战。传统方法通常计算成本高，需要更高效的算法。

Method: 1. 使用顺序匹配滤波器估计粗角度参数；2. 基于子载波相位差恢复距离；3. 将定位问题建模为非线性最小二乘优化；4. 提出快速迭代优化算法，利用可分离最小二乘结构解耦参数；5. 采用改进的Levenberg算法和近似策略降低计算成本。

Result: 仿真结果表明，所提出的优化方法在精度上与传统方法相当，同时显著降低了算法复杂度。

Conclusion: 该研究为RIS辅助ISAC系统提供了一种高效的目标定位解决方案，在保持精度的同时大幅降低计算复杂度，具有实际应用价值。

Abstract: This paper investigates the problem of high-precision target localization in integrated sensing and communication (ISAC) systems, where the target is sensed via both a direct path and a reconfigurable intelligent surface (RIS)-assisted reflection path. We first develop a sequential matched-filter estimator to acquire coarse angular parameters, followed by a range recovery process based on subcarrier phase differences. Subsequently, we formulate the target localization problem as a non-linear least squares optimization, using the coarse estimates to initialize the target's position coordinates. To solve this efficiently, we introduce a fast iterative refinement algorithm tailored for RIS-aided ISAC environments. Recognizing that the signal model involves both linear path gains and non-linear geometric dependencies, we exploit the separable least-squares structure to decouple these parameters. Furthermore, we propose a modified Levenberg algorithm with an approximation strategy, which enables low-cost parameter updates without necessitating repeated evaluations of the full non-linear model. Simulation results show that the proposed refinement method achieves accuracy comparable to conventional approaches, while significantly reducing algorithmic complexity.

</details>


### [25] [Wireless Physical Neural Networks (WPNNs): Opportunities and Challenges](https://arxiv.org/abs/2602.14094)
*Meng Hua,Itsik Bergel,Tolga Girici,Marco Di Renzo,Deniz Gunduz*

Main category: eess.SP

TL;DR: 将无线通信系统重构为物理神经网络，将无线传播环境和网络元件视为可微分算子，实现通信与计算的联合优化。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统与神经网络在结构和功能上具有相似性：信号通过级联元件传播、与环境交互并经历变换。这种相似性启发我们将无线网络重新构想为学习架构。

Method: 提出无线物理神经网络（WPNNs）统一范式，将收发器、中继器、反向散射和智能表面等无线网络组件解释为学习架构中的计算层。将无线传播环境和网络元件视为可微分算子，通过基于学习的方法直接对物理网络进行系统优化。

Result: 通过数值示例展示了在处理、适应性、效率和端到端优化方面的潜在性能增益，证明了将无线系统重新配置为学习网络在下一代通信框架中的前景。

Conclusion: 无线物理神经网络为通信与计算的联合设计提供了新机会，使无线介质能够作为计算资源被利用，可与传统数字神经网络层协同工作，实现混合通信学习管道。

Abstract: Wireless communication systems exhibit structural and functional similarities to neural networks: signals propagate through cascaded elements, interact with the environment, and undergo transformations. Building upon this perspective, we introduce a unified paradigm, termed \textit{wireless physical neural networks (WPNNs)}, in which components of a wireless network, such as transceivers, relays, backscatter, and intelligent surfaces, are interpreted as computational layers within a learning architecture. By treating the wireless propagation environment and network elements as differentiable operators, new opportunities arise for joint communication-computation designs, where system optimization can be achieved through learning-based methods applied directly to the physical network. This approach may operate independently of, or in conjunction with, conventional digital neural layers, enabling hybrid communication learning pipelines. In the article, we outline representative architectures that embody this viewpoint and discuss the algorithmic and training considerations required to leverage the wireless medium as a computational resource. Through numerical examples, we highlight the potential performance gains in processing, adaptability, efficiency, and end-to-end optimization, demonstrating the promise of reconfiguring wireless systems as learning networks in next-generation communication frameworks.

</details>


### [26] [Electromagnetic Bounds on Realizing Targeted MIMO Transfer Functions in Real-World Systems with Wave-Domain Programmability](https://arxiv.org/abs/2602.14152)
*Philipp del Hougne*

Main category: eess.SP

TL;DR: 该论文推导了可重构波系统中实现期望线性算子的电磁一致性保真度上界，考虑了可调元件间的互耦和硬件约束，并应用于三种实验装置验证。


<details>
  <summary>Details</summary>
Motivation: 可重构线性波系统（如RIS、DMA等）在实现期望线性算子时的精度问题缺乏电磁一致性理论界限，现有研究未考虑实际硬件约束和元件间互耦效应。

Method: 基于电磁一致性多端口网络模型，考虑可调元件间互耦和硬件约束（有损、1比特可编程），将算子合成任务建模为二次约束分式二次问题，通过半定松弛计算严格保真度上界。

Result: 应用于三种实验装置：2.45GHz自由空间和富散射4×4 MIMO信道（100个1比特可编程RIS元件），以及19GHz 4×4 MIMO DMA信道。研究发现可调元件间耦合强度对保真度界限有显著影响，对于RIS装置，波域灵活性不足以实现所考虑的算子合成。

Conclusion: 首次推导了可重构波系统中实现期望线性算子的电磁一致性保真度界限，为评估实际系统性能提供了理论框架，揭示了元件间耦合对系统灵活性的重要限制。

Abstract: A key question for most applications involving reconfigurable linear wave systems is how accurately a desired linear operator can be realized by configuring the system's tunable elements. The relevance of this question spans from hybrid-MIMO analog combiners via computational meta-imagers to programmable wave-domain signal processing. Yet, no electromagnetically consistent bounds have been derived for the fidelity with which a desired operator can be realized in a real-world reconfigurable wave system. Here, we derive such bounds based on an electromagnetically consistent multiport-network model (capturing mutual coupling between tunable elements) and accounting for real-world hardware constraints (lossy, 1-bit-programmable elements). Specifically, we formulate the operator-synthesis task as a quadratically constrained fractional-quadratic problem and compute rigorous fidelity upper bounds based on semidefinite relaxation. We apply our technique to three distinct experimental setups. The first two setups are, respectively, a free-space and a rich-scattering $4\times 4$ MIMO channel at 2.45 GHz parameterized by a reconfigurable intelligent surface (RIS) comprising 100 1-bit-programmable elements. The third setup is a $4\times 4$ MIMO channel at 19 GHz from four feeds of a dynamic metasurface antenna (DMA) to four users. We systematically study how the achievable fidelity scales with the number of tunable elements, and we probe the tightness of our bounds by trying to find optimized configurations approaching the bounds with standard discrete-optimization techniques. We observe a strong influence of the coupling strength between tunable elements on our fidelity bound. For the two RIS-based setups, our bound attests to insufficient wave-domain flexibility for the considered operator synthesis.

</details>


### [27] [Explainable Interictal Epileptiform Discharge Detection Method Based on Scalp EEG and Retrieval-Augmented Generation](https://arxiv.org/abs/2602.14170)
*Yu Zhu,Jiayang Guo,Jun Jiang,Peipei Gu,Xin Shu,Duo Chen*

Main category: eess.SP

TL;DR: 提出IED-RAG框架，通过检索显式证据实现可解释的癫痫样放电检测与报告生成


<details>
  <summary>Details</summary>
Motivation: 现有癫痫样放电自动检测方法缺乏可解释性，需要既能准确检测又能生成临床可理解报告的方法

Method: 使用双编码器提取电生理和语义特征，通过对比学习在共享EEG-文本嵌入空间对齐；推理时从向量数据库检索临床相关EEG-文本对作为显式证据，条件化大语言模型生成基于证据的报告

Result: 在武汉儿童医院私有数据集和公开TUEV数据集上分别达到89.17%和71.38%的平衡准确率，以及89.61%和64.14%的BLEU分数

Conclusion: 检索显式证据相比传统黑盒方法能同时提升诊断性能和临床可解释性

Abstract: The detection of interictal epileptiform discharge (IED) is crucial for the diagnosis of epilepsy, but automated methods often lack interpretability. This study proposes IED-RAG, an explainable multimodal framework for joint IED detection and report generation. Our approach employs a dual-encoder to extract electrophysiological and semantic features, aligned via contrastive learning in a shared EEG-text embedding space. During inference, clinically relevant EEG-text pairs are retrieved from a vector database as explicit evidence to condition a large language model (LLM) for the generation of evidence-based reports. Evaluated on a private dataset from Wuhan Children's Hospital and the public TUH EEG Events Corpus (TUEV), the framework achieved balanced accuracies of 89.17\% and 71.38\%, with BLEU scores of 89.61\% and 64.14\%, respectively. The results demonstrate that retrieval of explicit evidence enhances both diagnostic performance and clinical interpretability compared to standard black-box methods.

</details>


### [28] [Localization Exploiting Spatial Variations in the Magnetic Field: Principles and Challenges](https://arxiv.org/abs/2602.14181)
*Isaac Skog,Manon Kok,Christophe Prieur,Gustaf Hendeby*

Main category: eess.SP

TL;DR: 本文综述了利用地球磁场空间变化进行定位的信号处理原理、关键技术及研究挑战，从统计信号处理角度分析现有技术的异同。


<details>
  <summary>Details</summary>
Motivation: 信号处理在现代定位技术发展中起着基础性作用，磁场定位技术也不例外。当前基于地球磁场空间变化的定位技术已能达到分米级的室内定位精度，室外精度可与战略级惯性导航系统相媲美。本文旨在从统计信号处理的角度，为读者提供一个对现有磁场定位技术的全面理解，分析其相似性和差异性。

Method: 采用统一的参数化信号模型框架，将现有关键技术整合到与成熟统计推断方法兼容的通用框架中。从统计状态推断、磁场建模和传感器校准三个核心信号处理方法入手，系统分析磁场定位的技术原理。

Result: 磁场定位技术已实现分米级室内定位精度，室外精度达到战略级惯性导航系统水平。通过统一的信号模型框架，能够清晰地展示不同技术之间的内在联系和差异，为技术比较和未来发展提供理论基础。

Conclusion: 地球磁场空间变化定位技术是信号处理在定位领域的重要应用，具有高精度潜力。未来研究需要在现有信号处理原理基础上，解决磁场建模、传感器校准和统计推断等方面的开放挑战，推动该技术向更广泛的应用场景发展。

Abstract: Signal processing has played, and continues to play, a fundamental role in the evolution of modern localization technologies. Localization using spatial variations in the Earth's magnetic field is no exception. It relies on signal-processing methods for statistical state inference, magnetic-field modeling, and sensor calibration. Contemporary localization techniques based on spatial variations in the magnetic field can provide decimeter-level indoor localization accuracy and outdoor localization accuracy on par with strategic-grade inertial navigation systems. This article provides a broad, high-level overview of current signal-processing principles and open research challenges in localization using spatial variations in the Earth's magnetic field. The aim is to provide the reader with an understanding of the similarities and differences among existing key technologies from a statistical signal-processing perspective. To that end, existing key technologies will be presented within a common parametric signal-model framework compatible with well-established statistical inference methods.

</details>


### [29] [Robust SAC-Enabled UAV-RIS Assisted Secure MISO Systems With Untrusted EH Receivers](https://arxiv.org/abs/2602.14191)
*Hamid Reza Hashempour,Le-Nam Tran,Duy H. N. Nguyen,Hien Quoc Ngo*

Main category: eess.SP

TL;DR: 该论文研究无人机辅助RIS多用户MISO网络中的安全下行传输，提出基于SAC深度强化学习的框架，在存在不完美CSI和离散RIS相位的约束下，联合优化无人机位置、RIS相位和功率分配，实现最坏情况保密能效最大化。


<details>
  <summary>Details</summary>
Motivation: 在无人机辅助RIS多用户网络中，存在不可信能量收集接收器可能窃听合法信息，且由于有限反馈导致CSI不完美，需要解决最坏情况保密能效最大化问题，同时考虑离散RIS相位、无人机移动性和能量收集约束。

Method: 提出基于软演员-评论家深度强化学习框架，通过与无线环境交互学习WCSEE最大化策略；同时为完美CSI情况开发了连续凸逼近方法作为基准。

Result: 仿真结果表明，提出的SAC方法相比SCA和DDPG基线分别实现了28%和16%的保密能效增益，对CSI不确定性表现出优越的鲁棒性，在不同发射功率水平和RIS尺寸下保持稳定性能。

Conclusion: 该研究成功解决了无人机辅助RIS网络中复杂的安全传输优化问题，提出的SAC深度强化学习方法在存在不完美CSI和离散约束的情况下，能够有效实现最坏情况保密能效最大化，为未来无线网络安全传输提供了有前景的解决方案。

Abstract: This paper investigates secure downlink transmission in a UAV-assisted reconfigurable intelligent surface (RIS)-enabled multiuser multiple-input single-output network, where legitimate information-harvesting receivers coexist with untrusted energy-harvesting receivers (UEHRs) capable of eavesdropping. A UAV-mounted RIS provides blockage mitigation and passive beamforming, while the base station employs zero-forcing precoding for multiuser interference suppression. Due to limited feedback from UEHRs, their channel state information (CSI) is imperfect, leading to a worst-case secrecy energy efficiency (WCSEE) maximization problem. We jointly optimize the UAV horizontal position, RIS phase shifts, and transmit power allocation under both perfect and imperfect CSI, considering discrete RIS phases, UAV mobility, and energy-harvesting constraints. The resulting problem is highly nonconvex due to coupled channel geometry, robustness requirements, and discrete variables. To address this challenge, we propose a soft actor-critic (SAC)-based deep reinforcement learning framework that learns WCSEE-maximizing policies through interaction with the wireless environment. As a structured benchmark, a successive convex approximation (SCA) approach is developed for the perfect CSI case with continuous RIS phases. Simulation results show that the proposed SAC method achieves up to 28% and 16% secrecy energy efficiency gains over SCA and deep deterministic policy gradient baselines, respectively, while demonstrating superior robustness to CSI uncertainty and stable performance across varying transmit power levels and RIS sizes.

</details>


### [30] [Low-Cost Physical-Layer Security Design for IRS-Assisted mMIMO Systems with One-Bit DACs](https://arxiv.org/abs/2602.14292)
*Weijie Xiong,Jian Yang,Jingran Lin,Hongli Liu,Zhiling Xiao,Qiang Li*

Main category: eess.SP

TL;DR: 本文提出了一种用于IRS辅助mMIMO系统的低成本物理层安全设计，采用1位DAC量化预编码和恒定模IRS相移联合优化，以最大化保密速率。提出了WMMSE-PDD和EPPRGD两种算法解决高度非凸的保密速率最大化问题。


<details>
  <summary>Details</summary>
Motivation: mMIMO系统与IRS结合可增强无线通信的物理层安全，但大规模阵列中的高分辨率量化器和众多IRS元件导致硬件复杂度高。为解决这一问题，本文采用1位DAC设计低成本物理层安全方案。

Method: 联合优化发射端的1位量化预编码和IRS的恒定模相移，最大化保密速率。提出了两种算法：1) WMMSE-PDD算法，将保密速率最大化问题转化为带辅助变量的非分数规划序列；2) EPPRGD算法，将问题转化为乘积黎曼流形上的无约束优化。

Result: 两种算法都能收敛到KKT点，WMMSE-PDD算法提供优越的保密性能，EPPRGD算法收敛更快但保密性能略有折衷。仿真结果验证了所提方法的有效性并突出了各自的优势。

Conclusion: 本文提出的1位DAC IRS辅助mMIMO系统物理层安全设计在降低硬件复杂度的同时，通过两种高效算法实现了良好的保密性能，为低成本安全无线通信提供了可行方案。

Abstract: Integrating massive multiple-input multiple-output (mMIMO) systems with intelligent reflecting surfaces (IRS) presents a promising paradigm for enhancing physical-layer security (PLS) in wireless communications. However, deploying high-resolution quantizers in large-scale mMIMO arrays, along with numerous IRS elements, leads to substantial hardware complexity. To address these challenges, this paper proposes a cost-effective PLS design for IRS-assisted mMIMO systems by employing one-bit digital-to-analog converters (DACs). The focus is on jointly optimizing one-bit quantized precoding at the transmitter and constant-modulus phase shifts at the IRS to maximize the secrecy rate. This leads to a highly non-convex fractional secrecy rate maximization (SRM) problem. To efficiently solve this problem, two algorithms are proposed: (1) the WMMSE-PDD algorithm, which reformulates the SRM problem into a sequence of non-fractional programs with auxiliary variables using the weighted minimum mean-square error (WMMSE) method and solves them via the penalty dual decomposition (PDD) approach, achieving superior secrecy performance; and (2) the exact penalty product Riemannian gradient descent (EPPRGD) algorithm, which transforms the SRM problem into an unconstrained optimization over a product Riemannian manifold, eliminating auxiliary variables and enabling faster convergence with a slight trade-off in secrecy performance. Both algorithms provide analytical solutions at each iteration and are proven to converge to Karush-Kuhn-Tucker (KKT) points. Simulation results confirm the effectiveness of the proposed methods and highlight their respective advantages.

</details>


### [31] [Online Architecture Search for Compressed Sensing based on Hypergradient Descent](https://arxiv.org/abs/2602.14411)
*Ayano Nakai-Kasai,Yusuke Nakane,Tadashi Wadayama*

Main category: eess.SP

TL;DR: 提出HGD-AS-ISTA和HGD-AS-FISTA算法，使用超梯度下降在线优化结构参数，避免传统深度展开方法需要训练数据和大量训练时间的问题。


<details>
  <summary>Details</summary>
Motivation: AS-ISTA和AS-FISTA通过引入结构参数实现架构搜索，但使用深度展开方法需要训练数据和大量训练时间，且环境变化时需要重新训练。

Method: 提出HGD-AS-ISTA和HGD-AS-FISTA，采用超梯度下降（在线超参数优化方法）来确定结构参数，实现无需训练数据的在线优化。

Result: 实验结果表明，所提方法在提升传统ISTA/FISTA性能的同时，避免了环境变化时需要重新训练的问题。

Conclusion: 超梯度下降方法能够有效在线优化AS-ISTA和AS-FISTA的结构参数，既提高了性能又解决了传统深度展开方法的训练依赖问题。

Abstract: AS-ISTA (Architecture Searched-Iterative Shrinkage Thresholding Algorithm) and AS-FISTA (AS-Fast ISTA) are compressed sensing algorithms introducing structural parameters to ISTA and FISTA to enable architecture search within the iterative process. The structural parameters are determined using deep unfolding, but this approach requires training data and the large overhead of training time. In this paper, we propose HGD-AS-ISTA (Hypergradient Descent-AS-ISTA) and HGD-AS-FISTA that use hypergradient descent, which is an online hyperparameter optimization method, to determine the structural parameters. Experimental results show that the proposed method improves performance of the conventional ISTA/FISTA while avoiding the need for re-training when the environment changes.

</details>


### [32] [Cramer--Rao Bounds for Magneto-Inductive Integrated Sensing and Communications](https://arxiv.org/abs/2602.14453)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文推导了磁感应通信中联合估计距离和介质电导率的克拉美-罗界，发现在近场区域联合估计仅导致3dB的精度损失。


<details>
  <summary>Details</summary>
Motivation: 磁感应通信在射频受限环境（地下、水下、体内）中具有应用潜力，其中介质电导率会对信道产生确定性影响。需要研究在这种环境中同时进行通信和感知的可行性。

Method: 推导了磁感应通信中联合估计距离和介质电导率的闭合形式克拉美-罗界，分析了费舍尔信息矩阵，并通过蒙特卡洛最大似然仿真验证理论结果。

Result: 费舍尔信息矩阵分析表明，在近场区域，联合估计的精度损失收敛到3dB，这意味着电导率感知最多只会使测距精度降低两倍。蒙特卡洛仿真证实了该理论界在实际操作条件下是可达到的。

Conclusion: 磁感应通信系统可以在几乎不牺牲测距精度的情况下同时感知介质电导率，为集成感知与通信系统在射频受限环境中的应用提供了理论支持。

Abstract: Magnetic induction (MI) enables communication in RF-denied environments (underground, underwater, in-body), where the medium conductivity imprints a deterministic signature on the channel. This letter derives a closed-form Cramér--Rao bound (CRB) for the joint estimation of range and medium conductivity from MI pilot observations in an integrated sensing and communication (ISAC) framework. The Fisher information matrix reveals that the joint estimation penalty converges to 3\,dB in the near-field regime, meaning conductivity sensing adds at most a factor-of-two loss in ranging precision. Monte Carlo maximum-likelihood simulations confirm that the CRB is achievable under practical operating conditions.

</details>


### [33] [All-pole centroids in the Wasserstein metric with applications to clustering of spectral densities](https://arxiv.org/abs/2602.14583)
*Rumeshika Pallewela,Filip Elvander*

Main category: eess.SP

TL;DR: 提出一种在谱Wasserstein-2度量下计算功率谱密度集合质心的方法，限制质心为特定阶数的全极点谱，可视为寻找自回归模型代表。


<details>
  <summary>Details</summary>
Motivation: 现有Wasserstein质心方法在谱估计和聚类中虽有效，但产生非参数化结果，其表示和存储复杂度依赖于离散化网格选择。需要紧凑、低维、可解释的谱质心用于下游任务。

Method: 将全极点质心计算转化为模型参数的非凸优化问题，提出梯度下降方案求解。虽然不能保证全局最优，但可获得解的次优性量化。

Result: 该方法能够产生紧凑、低维、可解释的谱质心，在音素分类问题上进行了验证。

Conclusion: 提出的方法为谱Wasserstein-2度量下的全极点质心计算提供了有效解决方案，得到可解释的谱代表，适用于下游任务。

Abstract: In this work, we propose a method for computing centroids, or barycenters, in the spectral Wasserstein-2 metric for sets of power spectral densities, where the barycenters are restricted to belong to the set of all-pole spectra with a certain model order. This may be interpreted as finding an autoregressive representative for sets of second-order stationary Gaussian processes. While Wasserstein, or optimal transport, barycenters have been successfully used earlier in problems of spectral estimation and clustering, the resulting barycenters are non-parametric and the complexity of representing and storing them depends on, e.g., the choice of discretization grid. In contrast, the herein proposed method yields compact, low-dimensional, and interpretable spectral centroids that can be used in downstream tasks. Computing the all-pole centroids corresponds to solving a non-convex optimization problem in the model parameters, and we present a gradient descent scheme for addressing this. Although convergence to a globally optimal point cannot be guaranteed, the sub-optimality of the obtained centroids can be quantified. The proposed method is illustrated on a problem of phoneme classification.

</details>


### [34] [Learning Dirac Spectral Transforms for Topological Signals](https://arxiv.org/abs/2602.14590)
*Leonardo Di Nino,Tiziana Cattai,Sergio Barbarossa,Ginestra Bianconi,Paolo Di Lorenzo*

Main category: eess.SP

TL;DR: 本文比较了Dirac算子与Hodge-Laplacian在信号处理中的性能，提出了一种结合两者优点的参数化非冗余变换，通过学习质量参数实现了最佳失真-稀疏性权衡。


<details>
  <summary>Details</summary>
Motivation: Dirac算子为不同阶拓扑域（如节点和边信号）的信号处理提供了统一框架，其本征模式能够捕获跨域交互，而传统的Hodge-Laplacian本征模式只能在单一拓扑维度内操作。需要比较这两种方法在失真/稀疏性权衡方面的表现。

Method: 1) 比较Dirac算子和Hodge-Laplacian两种方法的失真-稀疏性权衡；2) 构建连接两个字典的超完备基；3) 提出参数化非冗余变换，其本征模式包含捕获节点和边模式相互作用的质量参数；4) 从数据中学习质量参数。

Result: 1) 超完备基相比单一方法能提供更好的性能；2) 提出的参数化非冗余变换通过学习质量参数，能够实现比完整基和超完备基都更好的失真-稀疏性权衡。

Conclusion: Dirac算子为拓扑信号处理提供了有前景的框架，通过提出的参数化非冗余变换和学习质量参数的方法，能够在失真和稀疏性之间达到最优权衡，优于传统的Hodge-Laplacian方法和简单的超完备基组合。

Abstract: The Dirac operator provides a unified framework for processing signals defined over different order topological domains, such as node and edge signals. Its eigenmodes define a spectral representation that inherently captures cross-domain interactions, in contrast to conventional Hodge-Laplacian eigenmodes that operate within a single topological dimension. In this paper, we compare the two alternatives in terms of the distortion/sparsity trade-off and we show how an overcomplete basis built concatenating the two dictionaries can provide better performance with respect to each approach. Then, we propose a parameterized nonredundant transform whose eigenmodes incorporate a mode-specific mass parameter that captures the interplay between node and edge modes. Interestingly, we show that learning the mass parameters from data makes the proposed transform able to achieve the best distortion-sparsity tradeoff with respect to both complete and overcomplete bases.

</details>


### [35] [Synthetic Aperture Communication: Principles and Application to Massive IoT Satellite Uplink](https://arxiv.org/abs/2602.14629)
*Lucas Giroto,Marcus Henninger,Silvio Mandelli*

Main category: eess.SP

TL;DR: 论文提出相干合成孔径通信(SAC)概念，用于卫星直连设备上行链路，通过合成孔径技术实现高分辨率DOA估计，解决物联网设备间的相互干扰和功率限制问题。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达已广泛用于远距离高分辨率成像，但相干合成孔径通信概念尚未被探索。本文旨在将合成孔径原理应用于卫星直连设备通信，解决大规模物联网设备在非地面网络中的相互干扰和严格功率限制问题。

Method: 提出相干合成孔径通信(SAC)原理，应用于卫星直连设备上行链路。通过卫星运动形成合成孔径，实现精确到达方向(DOA)估计，从而进行空间信号分离和定位。仿真场景为600km低地球轨道卫星，两个用户设备使用基于OFDM的传输和极性编码，频率为3.5GHz。

Result: 仿真结果显示，即使在强干扰情况下（当用户设备被解析但落在彼此最强的角度旁瓣上），传输功率低至-10dBm时，块错误率仍低于0.1。这验证了所提方案解决相互干扰和严格功率限制的能力。

Conclusion: 相干合成孔径通信方案能够有效解决大规模物联网设备在非地面网络中的相互干扰和功率限制问题，为未来大规模物联网连接在非地面网络中的应用铺平了道路。

Abstract: While synthetic aperture radar is widely adopted to provide high-resolution imaging at long distances using small arrays, the concept of coherent synthetic aperture communication (SAC) has not yet been explored. This article introduces the principles of SAC for direct satellite-to-device uplink, showcasing precise direction-of-arrival estimation for user equipment (UE) devices, facilitating spatial signal separation, localization, and easing link budget constraints. Simulations for a low Earth orbit satellite at 600 km orbit and two UE devices performing orthogonal frequency-division multiplexing-based transmission with polar coding at 3.5 GHz demonstrate block error rates below 0.1 with transmission powers as low as -10 dBm, even under strong interference when UE devices are resolved but fall on each other's strongest angular sidelobe. These results validate the ability of the proposed scheme to address mutual interference and stringent power limitations, paving the way for massive Internet of Things connectivity in non-terrestrial networks.

</details>


### [36] [RF-GPT: Teaching AI to See the Wireless World](https://arxiv.org/abs/2602.14833)
*Hang Zou,Yu Tian,Bohao Wang,Lina Bariah,Samson Lasaulce,Chongwen Huang,Mérouane Debbah*

Main category: eess.SP

TL;DR: RF-GPT：首个基于多模态大语言模型的射频语言模型，通过视觉编码器处理RF频谱图，实现射频信号与高层推理的融合


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型和多模态模型在无线通信领域存在明显缺口：它们主要处理文本和结构化数据，而传统的RF深度学习模型只针对特定信号处理任务，缺乏将RF感知与高层推理相结合的能力

Method: 1. 将复杂的IQ波形映射到时频频谱图；2. 使用预训练视觉编码器处理频谱图；3. 将得到的表示作为RF令牌注入到仅解码器的LLM中；4. 通过完全合成的RF语料库进行监督指令微调；5. 使用标准兼容波形生成器创建六种无线技术的宽带场景

Result: RF-GPT在宽带调制分类、重叠分析、无线技术识别、WLAN用户计数和5G NR信息提取等基准测试中表现出强大的多任务性能，而缺乏RF基础的一般视觉语言模型基本失败

Conclusion: RF-GPT成功填补了射频感知与高层推理之间的空白，通过将RF信号转换为视觉表示并融入LLM框架，实现了对无线通信系统的端到端理解，为电信领域的AI应用开辟了新途径

Abstract: Large language models (LLMs) and multimodal models have become powerful general-purpose reasoning systems. However, radio-frequency (RF) signals, which underpin wireless systems, are still not natively supported by these models. Existing LLM-based approaches for telecom focus mainly on text and structured data, while conventional RF deep-learning models are built separately for specific signal-processing tasks, highlighting a clear gap between RF perception and high-level reasoning. To bridge this gap, we introduce RF-GPT, a radio-frequency language model (RFLM) that utilizes the visual encoders of multimodal LLMs to process and understand RF spectrograms. In this framework, complex in-phase/quadrature (IQ) waveforms are mapped to time-frequency spectrograms and then passed to pretrained visual encoders. The resulting representations are injected as RF tokens into a decoder-only LLM, which generates RF-grounded answers, explanations, and structured outputs. To train RF-GPT, we perform supervised instruction fine-tuning of a pretrained multimodal LLM using a fully synthetic RF corpus. Standards-compliant waveform generators produce wideband scenes for six wireless technologies, from which we derive time-frequency spectrograms, exact configuration metadata, and dense captions. A text-only LLM then converts these captions into RF-grounded instruction-answer pairs, yielding roughly 12,000 RF scenes and 0.625 million instruction examples without any manual labeling. Across benchmarks for wideband modulation classification, overlap analysis, wireless-technology recognition, WLAN user counting, and 5G NR information extraction, RF-GPT achieves strong multi-task performance, whereas general-purpose VLMs with no RF grounding largely fail.

</details>


### [37] [Lattice XBAR Filters in Thin-Film Lithium Niobate](https://arxiv.org/abs/2602.14937)
*Taran Anusorn,Byeongjin Kim,Ian Anderson,Ziqian Yao,Ruochen Lu*

Main category: eess.SP

TL;DR: 该论文展示了基于横向激励体声波谐振器(XBAR)的格型滤波器，在周期性极化压电薄膜(P3F)铌酸锂薄膜(TFLN)上实现了27.42%和39.11%的3dB分数带宽，插入损耗分别为0.88dB和0.96dB，面积小于1.3mm²。


<details>
  <summary>Details</summary>
Motivation: 为下一代无线通信和传感系统开发紧凑、高性能的射频前端，需要低损耗、宽带的声学滤波器。传统滤波器在带宽和性能上存在限制，需要新的架构和材料来实现更好的性能。

Method: 采用横向激励体声波谐振器(XBAR)结合格型滤波器拓扑结构，在周期性极化压电薄膜(P3F)铌酸锂薄膜(TFLN)上设计和制造了两种滤波器：直接格型和布局平衡格型拓扑。利用XBAR在P3F TFLN中的强机电耦合特性和格型拓扑固有的宽带特性。

Result: 在约20GHz频率下，直接格型滤波器实现27.42%的3dB分数带宽和0.88dB插入损耗；布局平衡格型滤波器实现39.11%的3dB分数带宽和0.96dB插入损耗。所有原型芯片面积均小于1.3mm²。

Conclusion: 基于XBAR的格型架构在实现低损耗、宽带声学滤波器方面具有巨大潜力，适用于下一代无线通信和传感系统的紧凑型高性能射频前端。同时指出了进一步优化的关键挑战和方向。

Abstract: This work presents the demonstration of lattice filters based on laterally excited bulk acoustic resonators (XBARs). Two filter implementations, namely direct lattice and layout-balanced lattice topologies, are designed and fabricated in periodically poled piezoelectric film (P3F) thin-film lithium niobate (TFLN). By leveraging the strong electromechanical coupling of XBARs in P3F TFLN together with the inherently wideband nature of the lattice topology, 3-dB fractional bandwidths (FBWs) of 27.42\% and 39.11\% and low insertion losses (ILs) of 0.88 dB and 0.96 dB are achieved at approximately 20 GHz for the direct and layout-balanced lattice filters, respectively, under conjugate matching. Notably, all prototypes feature compact footprints smaller than 1.3 mm\textsuperscript{2}. These results highlight the potential of XBAR-based lattice architectures to enable low-loss, wideband acoustic filters for compact, high-performance RF front ends in next-generation wireless communication and sensing systems, while also identifying key challenges and directions for further optimization.

</details>


### [38] [Real-time Range-Angle Estimation and Tag Localization for Multi-static Backscatter Systems](https://arxiv.org/abs/2602.14985)
*Tara Esmaeilbeig,Kartik Patel,Traian E. Abrudan,John Kimionis,Eleftherios Kampianakis,Michael S. Eggleston*

Main category: eess.SP

TL;DR: 提出两种低复杂度算法JRAC和SRAE用于多静态反向散射网络中的距离和角度估计，以及两种实时定位算法ML和IRLS，在保持精度的同时显著降低计算复杂度，实验验证了实时可扩展反向散射定位的可行性。


<details>
  <summary>Details</summary>
Motivation: 6G环境物联网中的多静态反向散射网络需要实时定位大规模部署中的数千设备，但现有算法计算复杂度高，需要高效的距离、角度估计和定位融合算法。

Method: 提出两种低复杂度算法：联合距离-角度聚类(JRAC)和分阶段距离-角度估计(SRAE)用于参数估计；以及两种定位算法：基于梯度搜索的最大似然(ML)方法和迭代重加权最小二乘(IRLS)方法用于位置融合。

Result: JRAC和SRAE相比FFT和子空间基线方法减少40倍运行时间，IRLS相比ML暴力搜索减少500倍计算复杂度，在4个照射器、1个多天线接收器和100个标签的实际测试中实现3米中值定位误差。

Conclusion: 提出的多静态距离-角度估计和定位算法能够在保持定位精度的同时大幅降低计算复杂度，使实时、可扩展的反向散射定位在下一代环境物联网网络中变得实用可行。

Abstract: Multi-static backscatter networks (BNs) are strong candidates for joint communication and localization in the ambient IoT paradigm for 6G. Enabling real-time localization in large-scale multi-static deployments with thousands of devices require highly efficient algorithms for estimating key parameters such as range and angle of arrival (AoA), and for fusing these parameters into location estimates. We propose two low-complexity algorithms, Joint Range-Angle Clustering (JRAC) and Stage-wise Range-Angle Estimation (SRAE). Both deliver range and angle estimation accuracy comparable to FFT- and subspace-based baselines while significantly reducing the computation. We then introduce two real-time localization algorithms that fuse the estimated ranges and AoAs: a maximum-likelihood (ML) method solved via gradient search and an iterative re-weighted least squares (IRLS) method. Both achieve localization accuracy comparable to ML-based brute force search albeit with far lower complexity. Experiments on a real-world large-scale multi-static testbed with 4 illuminators, 1 multi-antenna receiver, and 100 tags show that JRAC and SRAE reduce runtime by up to 40X and IRLS achieves up to 500X reduction over ML-based brute force search without degrading localization accuracy. The proposed methods achieve 3 m median localization error across all 100 tags in a sub-6GHz band with 40 MHz bandwidth. These results demonstrate that multi-static range-angle estimation and localization algorithms can make real-time, scalable backscatter localization practical for next-generation ambient IoT networks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [39] [Sequential BP-based Decoding of QLDPC Codes](https://arxiv.org/abs/2602.13420)
*Mohsen Moradi,Salman Habib,Vahid Nourozi,David G. M. Mitchell*

Main category: cs.IT

TL;DR: 提出两种顺序调度策略（SCNS和SVNS）改进QLDPC码的BP译码性能，并应用于BPGD得到SBPGD，在保持低复杂度下显著降低误块率


<details>
  <summary>Details</summary>
Motivation: 传统BP译码器在QLDPC码中性能不佳，主要由于稳定子约束导致的短循环和简并性引起的不收敛问题，需要改进调度策略来提升译码性能

Method: 提出两种顺序调度策略：顺序校验节点调度（SCNS）和顺序变量节点调度（SVNS），通过固定顺序处理节点来稳定消息更新；并将此技术应用于BPGD得到SBPGD，在译码迭代中逐步固定符号

Result: 在标准QLDPC基准测试中，顺序调度策略相比传统BP降低了误块率；SBPGD在显著减少固定轮数的情况下优于BPGD，计算成本更低；对于[[1922,50,16]] C2超图乘积码，SVNS-BP在复杂度与标准BP相当的情况下超越了BP-OSD-0

Conclusion: 在不改变编码的情况下，仅通过改变更新调度策略就能同时提升QLDPC码BP译码的可靠性和效率，为量子纠错提供了有效的译码改进方案

Abstract: Quantum low-density parity-check (QLDPC) codes are a leading approach to quantum error correction, yet conventional belief propagation (BP) decoders often perform poorly, primarily due to non-convergence exacerbated by stabilizer constraints, which induce short cycles and degeneracy. We propose two scheduling variants, sequential check node scheduling (SCNS) and sequential variable node scheduling (SVNS), that improve BP's error-correction ability by processing check nodes (CNs) or variable nodes (VNs), respectively, in a fixed order, stabilizing message updates and reducing stalls. We also employ this technique to an improved BP-variant called BP guided decimation (BPGD), where symbols are progressively fixed during decoding iterations. Here, we demonstrate that the sequential BPGD (SBPGD) decoder can further improve the convergence properties and performance of the decoder. On standard QLDPC benchmarks under a Pauli-X noise model, our sequential schedules are shown to lower the block error rate relative to conventional BP, and SBPGD outperforms BPGD while using significantly fewer decimation rounds, translating to lower computational cost. These results demonstrate that changing the update schedule, without altering the code, can improve both the reliability and efficiency of BP-based decoding for QLDPC codes. For the [[1922,50,16]] C2 hypergraph-product code with independent X errors, SVNS-BP surpasses BP-OSD-0 in error correction at roughly the same complexity as standard BP.

</details>


### [40] [End-to-End NOMA with Perfect and Quantized CSI Over Rayleigh Fading Channels](https://arxiv.org/abs/2602.13446)
*Selma Benouadah,Mojtaba Vaezi,Ruizhan Shen,Hamid Jafarkhani*

Main category: cs.IT

TL;DR: 提出端到端自编码器框架用于瑞利衰落信道下的下行NOMA，通过端到端学习生成干扰感知和信道自适应的超星座图，并分析有限反馈量化对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有NOMA方案要么假设AWGN信道，要么在衰落信道中未采用完全端到端学习方法，且未充分考虑实际CSI限制。需要开发能直接在衰落信道中学习并适应实际CSI约束的NOMA方案。

Method: 开发端到端自编码器框架，将无线信道直接嵌入训练和推理过程。考虑实际CSI限制，通过均匀量化和Lloyd-Max量化实现有限反馈，分析不同量化方案对AE训练和BER性能的影响。

Result: 在完美CSI下，提出的AE方案优于现有解析NOMA方案。Lloyd-Max量化相比均匀量化获得更优的BER性能。端到端AE能在瑞利衰落信道中学习到鲁棒的干扰感知信令策略。

Conclusion: 端到端自编码器能直接在瑞利衰落信道中学习有效的NOMA方案，适应实际CSI约束，为衰落环境下NOMA部署提供了可行途径。

Abstract: An end-to-end autoencoder (AE) framework is developed for downlink non-orthogonal multiple access (NOMA) over Rayleigh fading channels, which learns interference-aware and channel-adaptive super-constellations. While existing works either assume additive white Gaussian noise channels or treat fading channels without a fully end-to-end learning approach, our framework directly embeds the wireless channel into both training and inference. To account for practical channel state information (CSI), we further incorporate limited feedback via both uniform and Lloyd-Max quantization of channel gains and analyze their impact on AE training and bit error rate (BER) performance. Simulation results show that, with perfect CSI, the proposed AE outperforms the existing analytical NOMA schemes. In addition, Lloyd-Max quantization achieves superior BER performance compared to uniform quantization. These results demonstrate that end-to-end AEs trained directly over Rayleigh fading can effectively learn robust, interference-aware signaling strategies, paving the way for NOMA deployment in fading environments with realistic CSI constraints.

</details>


### [41] [An Algebraic Invariant for Free Convolutional Codes over Finite Local Rings](https://arxiv.org/abs/2602.13468)
*Mohammed El Oued*

Main category: cs.IT

TL;DR: 本文研究了有限局部环Z_{p^r}上自由卷积码的代数结构，引入了新的结构不变量——残差结构多项式Delta_p(C)，证明了该多项式是码的内在特性，并建立了Delta_p(C)作为内在灾难性判据的充要条件。


<details>
  <summary>Details</summary>
Motivation: 研究有限局部环Z_{p^r}上自由卷积码的代数结构，特别是寻找能够表征码的内在特性的结构不变量，并建立判断卷积码是否具有灾难性（catastrophic）的代数判据。

Method: 通过约化内度矩阵（RIDM）构造残差结构多项式Delta_p(C)，证明该多项式在等价RIDM下是不变量，然后建立Delta_p(C)与码的灾难性之间的关系，并研究其对偶码的相应性质。

Result: 1. Delta_p(C)是码的内在不变量；2. 自由码C存在非灾难性实现的充要条件是Delta_p(C)为单项式D^s；3. 建立了对偶定理：Delta_p(C) = Delta_p(C^perp)，表明灾难性在正交性下保持不变。

Conclusion: 残差结构多项式Delta_p(C)是有限局部环上自由卷积码的重要代数不变量，它不仅提供了判断码是否具有灾难性的代数判据，而且揭示了对偶码之间在灾难性方面的深层结构对称性。

Abstract: This paper investigates the algebraic structure of free convolutional codes over the finite local ring Z_{p^r}. We introduce a new structural invariant, the Residual Structural Polynomial, denoted by Delta_p(C) in F_p[D]. We construct this invariant via encoders which are reduced internal degree matrices (RIDM). We formally demonstrate that Delta_p(C) is an intrinsic characteristic of the code, invariant under equivalent RIDMs. A central result of this work is the establishment that Delta_p(C) serves as an algebraic criterion for intrinsic catastrophicity: we prove that a free code C admits a non-catastrophic realization if and only if Delta_p(C) is a monomial of the form D^s. Furthermore, we establish a fundamental duality theorem, proving that Delta_p(C) = Delta_p(C^perp). This result reveals a deep structural symmetry, showing that the "catastrophicity" of a free code is preserved under orthogonality.

</details>


### [42] [Convergence of Differential Entropies -- II](https://arxiv.org/abs/2602.13493)
*Mahesh Godavarti*

Main category: cs.IT

TL;DR: 在概率密度函数依测度收敛下，当熵被积函数f_n|log f_n|一致可积且紧时，微分熵收敛；给出了比Godavarti-Hero条件更弱的熵加权Orlicz条件，并否定了他们的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究概率密度函数序列依测度收敛时，微分熵的收敛条件。现有文献如Godavarti-Hero(2004)等提出了固定α>1的条件，但需要更弱且更一般的收敛条件。

Method: 利用Vitali收敛定理，证明当熵被积函数f_n|log f_n|一致可积且紧时，微分熵收敛。提出熵加权Orlicz条件：sup_n ∫ f_n Ψ(|log f_n|) < ∞，其中Ψ是单个超线性函数，这比固定α>1的条件更弱。

Result: 1) 给出了微分熵收敛的充分必要条件；2) 提出的Orlicz条件严格弱于Godavarti-Hero的固定α>1条件；3) 否定了Godavarti-Hero关于α_n↓1的猜想；4) 将Godavarti-Hero、Piera-Parada、Ghourchian-Gohari-Amini的条件作为推论恢复；5) 在有界域上证明了条件的必要性。

Conclusion: 本文建立了概率密度函数依测度收敛时微分熵收敛的完整理论框架，提出了更弱且更一般的熵加权Orlicz条件，解决了相关猜想，统一并推广了现有结果。

Abstract: We show that under convergence in measure of probability density functions, differential entropy converges whenever the entropy integrands $f_n |\log f_n|$ are uniformly integrable and tight -- a direct consequence of Vitali's convergence theorem. We give an entropy-weighted Orlicz condition: $\sup_n \int f_n\, Ψ(|\log f_n|) < \infty$ for a single superlinear $Ψ$, strictly weaker than the fixed-$α$ condition of Godavarti and Hero (2004). We also disprove the Godavarti-Hero conjecture that $α> 1$ could be replaced by $α_n \downarrow 1$. We recover the sufficient conditions of Godavarti-Hero, Piera-Parada, and Ghourchian-Gohari-Amini as corollaries, and we show the condition is also necessary on bounded domains.

</details>


### [43] [Constructing Quantum Convolutional Codes via Difference Triangle Sets](https://arxiv.org/abs/2602.13505)
*Vahid Nourozi,David Mitchell*

Main category: cs.IT

TL;DR: 基于差分三角形集构造量子卷积码，通过反射DTS索引确保多项式稳定子满足对易关系，同时保持稀疏性和小编码记忆


<details>
  <summary>Details</summary>
Motivation: 提供一种构造性设计方法，能够保证预设的最小距离，解决量子卷积码构造中稳定子对易关系难以满足的问题

Method: 使用差分三角形集构造经典卷积自正交码作为X(D)，然后通过反射DTS索引得到Z(D)，确保X(D)和Z(D)满足对易关系（辛正交性）

Result: 提供了多种码率的构造数值结果，证明了该方法的有效性

Conclusion: 基于差分三角形集的量子卷积码构造方法能够保证预设的最小距离，为量子卷积码设计提供了一种有效的构造性方案

Abstract: In this paper, we introduce a construction of quantum convolutional codes (QCCs) based on difference triangle sets (DTSs). To construct QCCs, one must determine polynomial stabilizers $X(D)$ and $Z(D)$ that commute (symplectic orthogonality), while keeping the stabilizers sparse and encoding memory small. To construct Z(D), we show that one can use a reflection of the DTS indices of X(D), where X(D) corresponds to a classical convolutional self-orthogonal code (CSOC) constructed from strong DTS supports. The motivation of this approach is to provide a constructive design that guarantees a prescribed minimum distance. We provide numerical results demonstrating the construction for a variety of code rates.

</details>


### [44] [Redundancy-Optimal Constructions of $(1,1)$-Criss-Cross Deletion Correcting Codes with Efficient Encoding/Decoding Algorithms](https://arxiv.org/abs/2602.13548)
*Wenhao Liu,Zhengyi Jiang,Zhongyi Huang,Hanxu Hou*

Main category: cs.IT

TL;DR: 提出一种针对二维(1,1)-交叉删除错误的q进制纠错码构造，具有接近最优的冗余度和高效的编解码算法


<details>
  <summary>Details</summary>
Motivation: 二维纠错码在QR码、DNA存储和赛道存储器中有重要应用，其中(1,1)-交叉删除错误（同时删除一行和一列）是特别重要的错误模式，需要有效的纠错方案

Method: 提出新颖的q进制(1,1)-交叉删除纠错码构造，为n≥11且q≥3的参数提供完整的编码、解码和数据恢复算法，算法复杂度为O(n²)

Result: 当n≥11且q=Ω(n)时，构造的码的冗余度和编码器冗余度均为2n+2log_q n+O(1)，与下界(2n+2log_q n-3)仅相差O(1)，这是首个达到接近最优冗余度且具有显式编解码算法的构造

Conclusion: 该工作首次实现了在(1,1)-交叉删除错误下具有接近最优冗余度的二维纠错码，并提供了高效的显式编解码算法，对二维纠错码的实际应用具有重要意义

Abstract: Two-dimensional error-correcting codes, where codewords are represented as $n \times n$ arrays over a $q$-ary alphabet, find important applications in areas such as QR codes, DNA-based storage, and racetrack memories. Among the possible error patterns, $(t_r,t_c)$-criss-cross deletions-where $t_r$ rows and $t_c$ columns are simultaneously deleted-are of particular significance. In this paper, we focus on $q$-ary $(1,1)$-criss-cross deletion correcting codes. We present a novel code construction and develop complete encoding, decoding, and data recovery algorithms for parameters $n \ge 11$ and $q \ge 3$. The complexity of the proposed encoding, decoding, and data recovery algorithms is $\mathcal{O}(n^2)$. Furthermore, we show that for $n \ge 11$ and $q = Ω(n)$ (i.e., there exists a constant $c>0$ such that $q \ge cn$), both the code redundancy and the encoder redundancy of the constructed codes are $2n + 2\log_q n + \mathcal{O}(1)$, which attain the lower bound ($2n + 2\log_q n - 3$) within an $\mathcal{O}(1)$ gap. To the best of our knowledge, this is the first construction that can achieve the optimal redundancy with only an $\mathcal{O}(1)$ gap, while simultaneously featuring explicit encoding and decoding algorithms.

</details>


### [45] [Discrete-Space Generative AI Pipeline for Semantic Transmission of Signals](https://arxiv.org/abs/2602.13556)
*Silvija Kokalj-Filipovic,Yagna Kaasaragadda*

Main category: cs.IT

TL;DR: Discernment是一个基于GenAI的语义通信系统，通过自回归或扩散生成算法动态适应信道损伤，在信道容量严重下降时仍能保持语义完整性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统通信系统在信道条件恶化时性能急剧下降的问题，需要开发能够适应物理信道损伤、保持语义完整性的高效通信系统，特别适用于物联网部署。

Method: 使用GenAI模型在离散空间中操作，根据信道擦除模式动态切换自回归或扩散生成算法，传输物理信号（基带无线电和音频）的语义含义。

Result: Discernment在信道容量严重下降时仍能保持语义完整性，在分类准确性和重构语义的统计保真度方面表现出非常小且平缓的性能下降。

Conclusion: Discernment能够适应多样化的物理信道条件，同时保持频谱效率和低模型复杂度，非常适合物联网部署，强烈推动了语义信道范式的进一步研究。

Abstract: We introduce Discernment, a semantic communication system that transmits the meaning of physical signals (baseband radio and audio) over a technical channel using GenAI models operating in discrete spaces. Discernment dynamically adapts to channel impairments - modeled as erasure channels - by switching between an autoregressive or a diffusion-based generative algorithm, depending on the erasure pattern. Our results show that Discernment maintains semantic integrity even as channel capacity severely degrades, exhibiting very small and graceful performance decline in both classification accuracy and statistical fidelity of the reconstructed meaning. These findings demonstrate Discernment's ability to adjust to diverse physical channel conditions while maintaining spectral efficiency and low model complexity, making it well suited for IoT deployments and strongly motivating further research on this semantic channel paradigm.

</details>


### [46] [UAV Swarm Enabled Aerial Movable Antenna System for Low-Altitude Economy: From Far-Field to Near-Field Communication](https://arxiv.org/abs/2602.13687)
*Haiquan Lu,Chao Feng,Yong Zeng,Shaodan Ma,Long Shi,Shi Jin,Rui Zhang*

Main category: cs.IT

TL;DR: 本文研究无人机群支持的可移动天线近场通信，考虑非均匀球面波模型，通过联合优化无人机群3D轨迹和接收波束成形来最大化用户的最小平均通信速率。


<details>
  <summary>Details</summary>
Motivation: 无人机具有固有的三维移动性，为通过无人机群协作实现空中可移动天线系统提供了理想平台。此外，可移动天线系统易于实现极大阵列孔径，使得传统的远场均匀平面波模型不再适用于空对地链路，因此需要研究近场通信。

Method: 1. 针对单用户场景，提出使用逐次凸逼近技术优化无人机群轨迹；2. 针对位置优化场景，推导了单无人机和双无人机的最优放置位置闭式解；3. 针对双用户场景，提出通过沿双曲线对称放置偶数个无人机实现无用户间干扰通信；4. 针对任意用户数，提出交替优化算法解决非凸优化问题。

Result: 数值结果表明，所提方案相比基准方案具有显著的性能增益。具体包括：单用户场景下的轨迹优化效果、位置优化闭式解、双用户场景下的无干扰通信方案，以及多用户场景下的有效优化算法。

Conclusion: 本文系统研究了无人机群支持的可移动天线近场通信，通过考虑非均匀球面波模型和联合优化无人机轨迹与波束成形，显著提升了通信性能。提出的各种场景优化方案为实际系统设计提供了理论指导。

Abstract: Unmanned aerial vehicle (UAV) with the intrinsic three-dimensional (3D) mobility provides an ideal platform for implementing aerial movable antenna (AMA) system enabled by UAV swarm cooperation. Besides, AMA system is readily to achieve an extremely large-scale array aperture, rendering the conventional far-field uniform plane wave (UPW) model no longer valid for aerial-to-ground links. This paper studies the UAV swarm enabled near-field AMA communication, by taking into account the non-uniform spherical wave (NUSW) model, where UAV swarm trajectory simultaneously influences the channel amplitude and phase. We formulate a general optimization problem to maximize the minimum average communication rate over user equipments (UEs), by jointly optimizing the 3D UAV swarm trajectory and receive beamforming for all UEs. To draw useful insights, the special case of single UE is first studied, and successive convex approximation (SCA) technique is proposed to efficiently optimize the UAV swarm trajectory. For the special case of placement optimization, the optimal placement positions of UAVs for cases of single UAV and two UAVs are derived in closed-form. Then, for the special case of two UEs, we show that an inter-UE interference (IUI)-free communication can be achieved by symmetrically placing an even number of UAVs along a hyperbola, with its foci corresponding to the locations of the two UEs. Furthermore, for arbitrary number of UEs, an alternating optimization algorithm is proposed to efficiently tackle the non-convex optimization problem. Numerical results validate the significant performance gains over the benchmark schemes.

</details>


### [47] [BRAIN: Bayesian Reasoning via Active Inference for Agentic and Embodied Intelligence in Mobile Networks](https://arxiv.org/abs/2602.14033)
*Osman Tugay Basaran,Martin Maier,Falko Dressler*

Main category: cs.IT

TL;DR: BRAIN：基于主动推理的贝叶斯推理智能体，用于6G网络动态资源分配，相比传统DRL具有更好的鲁棒性、适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要具备实时适应性和决策透明性的AI智能体，而现有基于深度强化学习（DRL）的方法缺乏可解释性，在非平稳环境下容易发生灾难性遗忘，适应性脆弱。

Method: 提出BRAIN（Bayesian reasoning via Active Inference）智能体，利用深度生成模型对环境建模，通过最小化变分自由能量来统一感知和行动，形成闭环范式。在GPU加速的O-RAN xApp测试平台上实现。

Result: BRAIN在实验中表现出：（1）动态无线资源分配的鲁棒因果推理能力，能在不同流量负载下维持切片特定的QoS目标；（2）卓越的适应性，对突发流量变化的鲁棒性比基准方法提高28.3%（无需重新训练）；（3）通过人类可解释的信念状态诊断实现实时决策可解释性。

Conclusion: BRAIN为6G网络AI智能体提供了一种有前景的替代方案，解决了传统DRL方法在可解释性、适应性和鲁棒性方面的不足，实现了感知与行动的统一闭环框架。

Abstract: Future sixth-generation (6G) mobile networks will demand artificial intelligence (AI) agents that are not only autonomous and efficient, but also capable of real-time adaptation in dynamic environments and transparent in their decisionmaking. However, prevailing agentic AI approaches in networking, exhibit significant shortcomings in this regard. Conventional deep reinforcement learning (DRL)-based agents lack explainability and often suffer from brittle adaptation, including catastrophic forgetting of past knowledge under non-stationary conditions. In this paper, we propose an alternative solution for these challenges: Bayesian reasoning via Active Inference (BRAIN) agent. BRAIN harnesses a deep generative model of the network environment and minimizes variational free energy to unify perception and action in a single closed-loop paradigm. We implement BRAIN as O-RAN eXtended application (xApp) on GPU-accelerated testbed and demonstrate its advantages over standard DRL baselines. In our experiments, BRAIN exhibits (i) robust causal reasoning for dynamic radio resource allocation, maintaining slice-specific quality of service (QoS) targets (throughput, latency, reliability) under varying traffic loads, (ii) superior adaptability with up to 28.3% higher robustness to sudden traffic shifts versus benchmarks (achieved without any retraining), and (iii) real-time interpretability of its decisions through human-interpretable belief state diagnostics.

</details>


### [48] [Energy-Efficient Over-the-Air Federated Learning via Pinching Antenna Systems](https://arxiv.org/abs/2602.14250)
*Saba Asaad,Ali Bereyhi*

Main category: cs.IT

TL;DR: PASS（Pinching Antennas Systems）作为一种新型柔性天线技术，通过将低成本pinching元件连接到介质波导上实现。该研究探索了PASS在无线联邦学习（OTA-FL）中的潜在增益，开发了联合优化PASS参数和移动设备调度的低复杂度算法，显著降低了模型聚合所需的能量消耗。


<details>
  <summary>Details</summary>
Motivation: 探索PASS技术在无线联邦学习（OTA-FL）中的应用潜力，解决传统MIMO服务器在OTA-FL中能量消耗较大的问题，为下一代无线系统中的分布式学习提供更节能的技术方案。

Method: 为PASS辅助的服务器开发了低复杂度算法，联合优化PASS参数和移动设备调度，以最小化OTA-FL中的能量消耗。通过波导绕过直接链路，有效补偿无线信道的大尺度效应。

Result: 数值实验表明，在中等规模区域内使用单波导PASS服务器，与全数字MIMO服务器相比，模型聚合所需的能量显著降低。PASS显示出作为下一代无线系统中节能分布式学习技术的潜力。

Conclusion: PASS技术能够有效降低OTA-FL中的能量消耗，为下一代无线系统中的分布式学习提供了一种有前景的节能解决方案，特别是在服务器端部署单波导PASS时效果显著。

Abstract: Pinching antennas systems (PASSs) have recently been proposed as a novel flexible-antenna technology. These systems are implemented by attaching low-cost pinching elements to dielectric waveguides. As the direct link is bypassed through waveguides, PASSs can effectively compensate large-scale effects of the wireless channel. This work explores the potential gains of employing PASSs for over-the-air federated learning (OTA-FL). For a PASS-assisted server, we develop a low-complexity algorithmic approach, which jointly tunes the PASS parameters and schedules the mobile devices for minimal energy consumption in OTA-FL. We study the efficiency of the proposed design and compare it against the conventional OTA-FL setting with MIMO server. Numerical experiments demonstrate that using a single-waveguide PASS at the server within a moderately sized area, the required energy for model aggregation is drastically reduced as compared to the case with fully-digital MIMO server. This introduces PASS as a potential technology for energy-efficient distributed learning in next generations of wireless systems.

</details>


### [49] [Diversity vs Degrees of Freedom in Gaussian Fading Channels](https://arxiv.org/abs/2602.14371)
*Mahesh Godavarti*

Main category: cs.IT

TL;DR: 论文重新定义了自由度(DOF)和分集度的概念，提出基于几何覆盖和扩展的新定义，并引入Bhattacharyya packing来建立跨尺度权衡关系，发现了三种不同的尺度类别。


<details>
  <summary>Details</summary>
Motivation: 传统基于logρ归一化的DOF和分集度定义在某些情况下会失效（为零或未定义），但这些概念本质应该是信道特性而非归一化选择的产物。需要建立更普适的几何定义。

Method: 针对高斯衰落信道，将DOF定义为信道映射X→HX图像的ε-覆盖，分集度定义为衰落映射在所有维度上的扩展。引入Bhattacharyya packing来建立可操作的代理度量（尺度DOF和B-分集度）。

Result: 发现了三种尺度类别：logρ、loglogρ和(logρ)^β。对于非相干快速衰落信道，容量在loglogρ尺度上，而B-分集度在logρ尺度上（指数级更大），并给出了匹配的上下界。该方法也适用于相干MIMO、块衰落和不规则频谱信道。

Conclusion: 论文提出了基于几何覆盖和扩展的DOF和分集度新定义，通过Bhattacharyya packing建立了跨尺度权衡框架，解决了传统定义在某些尺度下失效的问题，为信道特性分析提供了更普适的工具。

Abstract: The standard definitions of degrees of freedom (DOF) and diversity both normalize by $\logρ$. When this ruler is wrong, both measurements give zero or become undefined, yet intuitively DOF and diversity ought to be channel properties, not artifacts of a normalization choice. We formalize this for Gaussian fading channels. For fixed-$H$ MIMO, DOF and diversity are both ranks of the bilinear map~$HX$ with different variables free: $\varepsilon$-covering the image of~$X\!\mapsto\!HX$ gives DOF on the $\logρ$ gauge; expanding across all dimensions of the fading map gives diversity on the linear~$ρ$ gauge. Covering produces logs; expansion produces linear growth; so in every model studied here the two gauges differ. These geometric definitions do not yield tradeoff curves. We bridge the gap with Bhattacharyya packing, obtaining gauge-DOF and B-diversity as workable proxies -- finite and informative on every gauge, including those where the classical diversity order is zero. Three gauge classes emerge: $\logρ$, $\log\logρ$, and $(\logρ)^β$, $β\in(0,1)$. The main result is a cross-gauge tradeoff for noncoherent fast fading: capacity lives on $\log\logρ$, but B-diversity lives on $\logρ$, exponentially larger, with matching upper and lower bounds. For coherent MIMO, block fading, and irregular-spectrum channels, the same approach recovers or extends known scaling laws.

</details>


### [50] [On the Rate-Distortion-Complexity Tradeoff for Semantic Communication](https://arxiv.org/abs/2602.14481)
*Jingxuan Chai,Yong Xiao,Guangming Shi*

Main category: cs.IT

TL;DR: 该论文提出了一个率-失真-复杂度（RDC）框架，将经典率失真理论扩展到语义通信领域，考虑了语义距离和模型复杂度的约束，揭示了速率、语义距离和复杂度之间的三方权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的语义通信方法虽然能有效提取语义信息，但往往忽略了模型训练和推理中的高计算复杂度问题。需要建立一个理论框架来同时考虑通信效率、语义保真度和计算复杂度之间的权衡。

Method: 提出率-失真-复杂度（RDC）框架，扩展经典率失真理论，引入语义距离约束（包括传统比特级失真度量和基于统计差异的散度度量）和复杂度度量（借鉴最小描述长度和信息瓶颈理论）。推导了高斯和二进制语义源在给定语义距离和复杂度约束下的最小可达速率的闭式理论结果。

Result: 理论分析揭示了速率、语义距离和模型复杂度之间的基本三方权衡关系。在真实图像和视频数据集上的实验验证了这种权衡关系，并证明信息论复杂度度量与实际计算成本有效相关。

Conclusion: RDC框架为语义通信系统设计提供了理论基础，特别是在资源受限场景下，能够指导在通信效率、语义保真度和计算复杂度之间进行平衡的系统设计。

Abstract: Semantic communication is a novel communication paradigm that focuses on conveying the user's intended meaning rather than the bit-wise transmission of source signals. One of the key challenges is to effectively represent and extract the semantic meaning of any given source signals. While deep learning (DL)-based solutions have shown promising results in extracting implicit semantic information from a wide range of sources, existing work often overlooks the high computational complexity inherent in both model training and inference for the DL-based encoder and decoder. To bridge this gap, this paper proposes a rate-distortion-complexity (RDC) framework which extends the classical rate-distortion theory by incorporating the constraints on semantic distance, including both the traditional bit-wise distortion metric and statistical difference-based divergence metric, and complexity measure, adopted from the theory of minimum description length and information bottleneck. We derive the closed-form theoretical results of the minimum achievable rate under given constraints on semantic distance and complexity for both Gaussian and binary semantic sources. Our theoretical results show a fundamental three-way tradeoff among achievable rate, semantic distance, and model complexity. Extensive experiments on real-world image and video datasets validate this tradeoff and further demonstrate that our information-theoretic complexity measure effectively correlates with practical computational costs, guiding efficient system design in resource-constrained scenarios.

</details>


### [51] [Center-Fed Pinching Antenna System (C-PASS): Modeling, Analysis, and Beamforming Design](https://arxiv.org/abs/2602.14805)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出新型中心馈电夹持天线系统(C-PASS)的通用框架，推导了其自由度(DoF)和功率缩放定律的闭式表达式，并开发了联合优化算法。


<details>
  <summary>Details</summary>
Motivation: 现有天线系统在自由度和功率增益方面存在限制，需要开发新的天线架构来提高无线通信系统的性能。

Method: 提出C-PASS通用框架，推导DoF和功率缩放定律的闭式表达式，建立和速率最大化问题，开发交替优化算法（闭式解更新预编码和功率分配，BCD方法优化天线位置和辐射系数）。

Result: C-PASS的DoF随输入端口数M和接收天线数K线性增长，功率增益为O(P_T M)；单波导C-PASS优于单波导PASS，在高衰减区域优于多波导PASS，增益超过10dB。

Conclusion: C-PASS框架在自由度和功率增益方面具有显著优势，特别是在高衰减环境中表现优异，为下一代无线通信系统提供了有前景的解决方案。

Abstract: A generalized framework for the novel center-fed pinching antenna system (C-PASS) is proposed. Within this framework, closed-form expressions for the degree of freedom (DoF) and power scaling law of the proposed C-PASS are first derived. These theoretical results reveal that the achievable DoF scales linearly with the number of input ports, $M$, and the number of receive antennas, $K$. Furthermore, the derived power scaling laws demonstrate that the C-PASS achieves a power gain of order $\mathcal{O}(P_T M)$, where $P_T$ denotes the transmit power. Based on the proposed C-PASS modeling, a sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is then formulated. To solve this highly coupled non-convex problem, an efficient alternating optimization algorithm is developed. More particularly, the transmit precoding and power splitting ratios are updated via derived closed-form solutions, while the pinching antenna positions and radiation coefficients are optimized using block coordinate descent (BCD) methods. Finally, our numerical results reveal that the single-waveguide C-PASS: 1) achieves superior DoF and power scaling laws compared to the single-waveguide PASS; and 2) outperforms the multi-waveguide PASS in high-attenuation regimes, yielding a substantial gain exceeding $10$ dB.

</details>


### [52] [Constructions of linear codes from vectorial plateaued functions and their subfield codes with applications to quantum CSS codes](https://arxiv.org/abs/2602.14832)
*Virginio Fratianni,Sihem Mesnager*

Main category: cs.IT

TL;DR: 本文提出了一种基于三个函数的线性码构造框架，扩展了Xu等人2023年的二维方法，并引入了向量值函数设置。利用Bent和s-Plateaued函数，通过Walsh变换分析得到了具有少量权重的码及其对偶码，证明了对偶码在Sphere Packing和Griesmer界下是最优的。还建立了向量方法与经典线性码构造的联系，并探索了在量子编码中的应用。


<details>
  <summary>Details</summary>
Motivation: Xu等人在2023年提出的基于两个函数的3维线性码构造框架已成功生成无限族最优线性码。本文旨在扩展该框架到三个函数以增强参数灵活性，并引入向量值函数来扩展构造空间和可实现的代数结构特性。

Method: 1. 提出基于三个函数的标量构造框架，扩展Xu等人的二维方法；2. 引入向量值函数设置，允许向量值函数作为码生成器；3. 使用Bent函数和s-Plateaued函数（包括Almost Bent函数）定义码生成器；4. 利用Walsh变换的性质分析码的参数和权分布；5. 建立向量方法与经典线性码第一通用构造的理论联系。

Result: 1. 构造的码具有少量权重；2. 对偶码在Sphere Packing界和Griesmer界下都是距离和维度最优的；3. 确定了码及其删减版本的显式参数和权分布；4. 建立了向量方法与经典线性码构造的联系，给出了码为极小码和自正交码的充分条件；5. 在Calderbank-Shor-Steane框架下探索了量子编码理论的应用。

Conclusion: 本文成功扩展了线性码的参数化构造框架，从两个函数扩展到三个函数，并引入了向量值函数设置。新框架不仅增强了参数灵活性，而且生成的码具有优良的代数特性（少量权重、最优对偶码）。理论分析建立了与经典构造的联系，并为量子编码应用提供了基础。

Abstract: Linear codes over finite fields parameterized by functions have proven to be a powerful tool in coding theory, yielding optimal and few-weight codes with significant applications in secret sharing, authentication codes, and association schemes. In 2023, Xu et al. introduced a construction framework for 3-dimensional linear codes parameterized by two functions, which has demonstrated considerable success in generating infinite families of optimal linear codes. Motivated by this approach, we propose a construction that extends the framework to three functions, thereby enhancing the flexibility of the parameters. Additionally, we introduce a vectorial setting by allowing vector-valued functions, expanding the construction space and the set of achievable structural properties. We analyze both scalar and vectorial frameworks, employing Bent and s-Plateaued functions, including Almost Bent, to define the code generators. By exploiting the properties of the Walsh transform, we determine the explicit parameters and weight distributions of these codes and their punctured versions. A key result of this study is that the constructed codes have few weights, and their duals are distance and dimensionally optimal with respect to both the Sphere Packing and Griesmer bounds. Furthermore, we establish a theoretical connection between our vectorial approach and the classical first generic construction of linear codes, providing sufficient conditions for the resulting codes to be minimal and self-orthogonal. Finally, we investigate applications to quantum coding theory within the Calderbank-Shor-Steane framework.

</details>
