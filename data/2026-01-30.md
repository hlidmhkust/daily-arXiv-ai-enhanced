<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 5]
- [eess.SP](#eess.SP) [Total: 13]
- [cs.IT](#cs.IT) [Total: 10]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [ECGFlowCMR: Pretraining with ECG-Generated Cine CMR Improves Cardiac Disease Classification and Phenotype Prediction](https://arxiv.org/abs/2601.20904)
*Xiaocheng Fang,Zhengyao Ding,Jieyi Cai,Yujie Xiao,Bo Liu,Jiarui Jin,Haoyu Wang,Guangkun Nie,Shun Huang,Ting Chen,Hongyan Li,Shenda Hong*

Main category: eess.IV

TL;DR: ECGFlowCMR：一种新颖的ECG到CMR生成框架，通过相位感知掩码自编码器和解剖-运动解耦流解决跨模态时间不匹配和结构信息有限的问题，能够从ECG输入生成逼真的心脏电影CMR序列。


<details>
  <summary>Details</summary>
Motivation: 心脏磁共振（CMR）成像虽然能全面评估心脏结构和功能，但采集成本高且依赖专家标注，限制了大规模标注数据集的可用性。相比之下，心电图（ECG）成本低廉、广泛可用，有望作为生成合成CMR的条件模态。

Method: 提出ECGFlowCMR框架，整合相位感知掩码自编码器（PA-MAE）和解剖-运动解耦流（AMDF），解决ECG多搏动记录与CMR单周期序列之间的跨模态时间不匹配问题，以及ECG固有结构信息有限导致的解剖可观测性差距。

Result: 在UK Biobank和专有临床数据集上的广泛实验表明，ECGFlowCMR能够从ECG输入生成逼真的心脏电影CMR序列，实现可扩展的预训练，并提升下游心脏病分类和表型预测任务的性能。

Conclusion: ECGFlowCMR成功解决了ECG到CMR生成中的关键挑战，为利用广泛可用的ECG数据生成高质量CMR序列提供了有效方案，有助于扩大心脏成像数据的规模并改善下游临床任务性能。

Abstract: Cardiac Magnetic Resonance (CMR) imaging provides a comprehensive assessment of cardiac structure and function but remains constrained by high acquisition costs and reliance on expert annotations, limiting the availability of large-scale labeled datasets. In contrast, electrocardiograms (ECGs) are inexpensive, widely accessible, and offer a promising modality for conditioning the generative synthesis of cine CMR. To this end, we propose ECGFlowCMR, a novel ECG-to-CMR generative framework that integrates a Phase-Aware Masked Autoencoder (PA-MAE) and an Anatomy-Motion Disentangled Flow (AMDF) to address two fundamental challenges: (1) the cross-modal temporal mismatch between multi-beat ECG recordings and single-cycle CMR sequences, and (2) the anatomical observability gap due to the limited structural information inherent in ECGs. Extensive experiments on the UK Biobank and a proprietary clinical dataset demonstrate that ECGFlowCMR can generate realistic cine CMR sequences from ECG inputs, enabling scalable pretraining and improving performance on downstream cardiac disease classification and phenotype prediction tasks.

</details>


### [2] [Denoising and Baseline Correction of Low-Scan FTIR Spectra: A Benchmark of Deep Learning Models Against Traditional Signal Processing](https://arxiv.org/abs/2601.20905)
*Azadeh Mokari,Shravan Raghunathan,Artem Shydliukh,Oleg Ryabchykov,Christoph Krafft,Thomas Bocklitz*

Main category: eess.IV

TL;DR: 提出基于物理约束的级联Unet架构，通过确定性物理桥分离去噪和基线校正任务，实现快速、高质量的FTIR成像，速度提升32倍


<details>
  <summary>Details</summary>
Motivation: 传统FTIR成像需要大量信号平均来降低噪声和漂移，严重限制了临床速度。现有深度学习方法存在光谱幻觉问题，且难以在不稳定大气条件下泛化

Method: 提出物理约束的级联Unet架构，包含确定性物理桥分离去噪和基线校正任务，使用嵌入式SNIP层强制光谱约束而非学习统计近似

Result: 级联模型相比原始单次扫描输入减少51.3%的RMSE，优于单Unet（40.2%）和传统工作流（33.7%），消除光谱幻觉，峰值强度保真度高

Conclusion: 级联Unet是诊断级FTIR成像的稳健解决方案，可实现比现有方法快32倍的成像速度

Abstract: High-quality Fourier Transform Infrared (FTIR) imaging usually needs extensive signal averaging to reduce noise and drift which severely limits clinical speed. Deep learning can accelerate imaging by reconstructing spectra from rapid, single-scan inputs. However, separating noise and baseline drift simultaneously without ground truth is an ill-posed inverse problem. Standard black-box architectures often rely on statistical approximations that introduce spectral hallucinations or fail to generalize to unstable atmospheric conditions. To solve these issues we propose a physics-informed cascade Unet that separates denoising and baseline correction tasks using a new, deterministic Physics Bridge. This architecture forces the network to separate random noise from chemical signals using an embedded SNIP layer to enforce spectroscopic constraints instead of learning statistical approximations. We benchmarked this approach against a standard single Unet and a traditional Savitzky-Golay/SNIP workflow. We used a dataset of human hypopharyngeal carcinoma cells (FaDu). The cascade model outperformed all other methods, achieving a 51.3% reduction in RMSE compared to raw single-scan inputs, surpassing both the single Unet (40.2%) and the traditional workflow (33.7%). Peak-aware metrics show that the cascade architecture eliminates spectral hallucinations found in standard deep learning. It also preserves peak intensity with much higher fidelity than traditional smoothing. These results show that the cascade Unet is a robust solution for diagnostic-grade FTIR imaging. It enables imaging speeds 32 times faster than current methods.

</details>


### [3] [CompSRT: Quantization and Pruning for Image Super Resolution Transformers](https://arxiv.org/abs/2601.21069)
*Dorsa Zeinali,Hailing Wang,Yitian Zhang,Raymond Fu*

Main category: eess.IV

TL;DR: 提出CompSRT方法，通过Hadamard变换和标量分解改进SwinIR-light图像超分辨率模型的量化压缩性能，在3-4比特量化下显著超越现有方法，并兼容剪枝实现更高压缩率。


<details>
  <summary>Details</summary>
Motivation: 现有图像超分辨率模型压缩方法仍与全精度模型存在较大性能差距，需要更深入理解高性能模型的压缩理论。虽然Hadamard变换在LLM量化中显示能减少异常值，但其在图像超分辨率中的具体作用机制仍需实证分析。

Method: 通过统计分析SwinIR-light的权重和激活分布，发现Hadamard变换能减少数值范围并增加接近0的数值比例。基于此提出CompSRT方法：1) 基于Hadamard的量化；2) 引入两个可训练参数的标量分解。在3-4比特量化下还结合40%权重剪枝。

Result: 量化性能在各项指标上显著超越现有SOTA方法，增益最高达1.53dB。视觉质量在所有比特宽度下均有改善，减少了模糊现象。在3-4比特量化结合40%剪枝时，参数比特数减少6.67%-15%，性能仍与SOTA相当。

Conclusion: CompSRT方法通过Hadamard变换和标量分解有效提升了图像超分辨率模型的量化压缩性能，在保持视觉质量的同时实现了更高的压缩率，为高性能模型的压缩提供了新的理论见解和实践方案。

Abstract: Model compression has become an important tool for making image super resolution models more efficient. However, the gap between the best compressed models and the full precision model still remains large and a need for deeper understanding of compression theory on more performant models remains. Prior research on quantization of LLMs has shown that Hadamard transformations lead to weights and activations with reduced outliers, which leads to improved performance. We argue that while the Hadamard transform does reduce the effect of outliers, an empirical analysis on how the transform functions remains needed. By studying the distributions of weights and activations of SwinIR-light, we show with statistical analysis that lower errors is caused by the Hadamard transforms ability to reduce the ranges, and increase the proportion of values around $0$. Based on these findings, we introduce CompSRT, a more performant way to compress the image super resolution transformer network SwinIR-light. We perform Hadamard-based quantization, and we also perform scalar decomposition to introduce two additional trainable parameters. Our quantization performance statistically significantly surpasses the SOTA in metrics with gains as large as 1.53 dB, and visibly improves visual quality by reducing blurriness at all bitwidths. At $3$-$4$ bits, to show our method is compatible with pruning for increased compression, we also prune $40\%$ of weights and show that we can achieve $6.67$-$15\%$ reduction in bits per parameter with comparable performance to SOTA.

</details>


### [4] [Blind Ultrasound Image Enhancement via Self-Supervised Physics-Guided Degradation Modeling](https://arxiv.org/abs/2601.21856)
*Shujaat Khan,Syed Muhammad Atif,Jaeyoung Huh,Syed Saad Azhar*

Main category: eess.IV

TL;DR: 提出一种盲自监督超声图像增强框架，联合去卷积和去噪，无需干净目标图像或已知退化模型，通过物理引导的退化模型训练Swin卷积U-Net。


<details>
  <summary>Details</summary>
Motivation: 超声图像解释受到乘性斑点噪声、点扩散函数导致的采集模糊以及扫描仪和操作员相关伪影的困扰。现有监督增强方法需要干净目标图像或已知退化模型，这在实践中很少能满足。

Method: 使用Swin卷积U-Net构建盲自监督增强框架，通过物理引导的退化模型训练：从训练帧中提取旋转/裁剪的补丁，通过高斯PSF代理进行卷积，并通过空间加性高斯噪声或复杂傅里叶域扰动注入噪声。超声图像使用非局部低秩去噪获得类干净目标，自然图像使用原始图像作为目标。

Result: 在UDIAT B、JNU-IFM、XPIE Set-P和700图像的PSFHS测试集上验证，在Gaussian和斑点噪声水平下获得最高PSNR/SSIM，在强噪声下优势更明显。相比MSANN、Restormer和DnCNN，在严重高斯噪声下保持额外1-4dB PSNR和0.05-0.15 SSIM，在严重斑点噪声下保持额外2-5dB PSNR和0.05-0.20 SSIM。PSF研究显示FWHM降低和峰值梯度提高，表明分辨率恢复而无边缘侵蚀。作为即插即用预处理器，提高胎儿头部和耻骨联合分割的Dice分数。

Conclusion: 该方法提供了一种实用、假设少的鲁棒超声增强路径，能够跨数据集、扫描仪和退化类型泛化，可作为即插即用预处理器提升下游任务性能。

Abstract: Ultrasound (US) interpretation is hampered by multiplicative speckle, acquisition blur from the point-spread function (PSF), and scanner- and operator-dependent artifacts. Supervised enhancement methods assume access to clean targets or known degradations; conditions rarely met in practice. We present a blind, self-supervised enhancement framework that jointly deconvolves and denoises B-mode images using a Swin Convolutional U-Net trained with a \emph{physics-guided} degradation model. From each training frame, we extract rotated/cropped patches and synthesize inputs by (i) convolving with a Gaussian PSF surrogate and (ii) injecting noise via either spatial additive Gaussian noise or complex Fourier-domain perturbations that emulate phase/magnitude distortions. For US scans, clean-like targets are obtained via non-local low-rank (NLLR) denoising, removing the need for ground truth; for natural images, the originals serve as targets. Trained and validated on UDIAT~B, JNU-IFM, and XPIE Set-P, and evaluated additionally on a 700-image PSFHS test set, the method achieves the highest PSNR/SSIM across Gaussian and speckle noise levels, with margins that widen under stronger corruption. Relative to MSANN, Restormer, and DnCNN, it typically preserves an extra $\sim$1--4\,dB PSNR and 0.05--0.15 SSIM in heavy Gaussian noise, and $\sim$2--5\,dB PSNR and 0.05--0.20 SSIM under severe speckle. Controlled PSF studies show reduced FWHM and higher peak gradients, evidence of resolution recovery without edge erosion. Used as a plug-and-play preprocessor, it consistently boosts Dice for fetal head and pubic symphysis segmentation. Overall, the approach offers a practical, assumption-light path to robust US enhancement that generalizes across datasets, scanners, and degradation types.

</details>


### [5] [Wrapper-Aware Rate-Distortion Optimization in Feature Coding for Machines](https://arxiv.org/abs/2601.22070)
*Samuel Fernández-Menduiña,Hyomin Choi,Fabien Racapé,Eduardo Pavez,Antonio Ortega*

Main category: eess.IV

TL;DR: 提出了一种针对FCM的包装器感知率失真优化方法，通过加权SSE度量修改内部编解码器的比特分配，在HEVC上达到与VVC相当的性能


<details>
  <summary>Details</summary>
Motivation: 传统FCM方法使用传统编解码器作为内部编解码器，其基于SSE的率失真优化不考虑后处理包装器，导致比特浪费在后续会被丢弃的信息上

Method: 提出包装器感知率失真优化(WA-RDO)，使用加权SSE度量；采用两种策略：1)跨图像组的权重时间复用；2)离线训练的固定架构和任务相关权重

Result: 在MPEG测试条件下，基于HEVC的实现匹配了基于VVC的FCM最新技术水平，有效弥补了编解码器代际差距，运行时开销最小

Conclusion: 包装器感知率失真优化显著提升了FCM系统的压缩效率，使HEVC能够达到VVC的性能水平，为实际应用提供了有效的解决方案

Abstract: Feature coding for machines (FCM) is a lossy compression paradigm for split-inference. The transmitter encodes the outputs of the first part of a neural network before sending them to the receiver for completing the inference. Practical FCM methods ``sandwich'' a traditional codec between pre- and post-processing neural networks, called wrappers, to make features easier to compress using video codecs. Since traditional codecs are non-differentiable, the wrappers are trained using a proxy codec, which is later replaced by a standard codec after training. These codecs perform rate-distortion optimization (RDO) based on the sum of squared errors (SSE). Because the RDO does not consider the post-processing wrapper, the inner codec can invest bits in preserving information that the post-processing later discards. In this paper, we modify the bit-allocation in the inner codec via a wrapper-aware weighted SSE metric. To make wrapper-aware RDO (WA-RDO) practical for FCM, we propose: 1) temporal reuse of weights across a group of pictures and 2) fixed, architecture- and task-dependent weights trained offline. Under MPEG test conditions, our methods implemented on HEVC match the VVC-based FCM state-of-the-art, effectively bridging a codec generation gap with minimal runtime overhead relative to SSE-RDO HEVC.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [6] [Sparse Grassmannian Design for Noncoherent Codes via Schubert Cell Decomposition](https://arxiv.org/abs/2601.21009)
*Joe Asano,Yuto Hama,Hiroki Iimori,Chandan Pradhan,Szabolcs Malomsoky,Naoki Ishikawa*

Main category: eess.SP

TL;DR: 提出了一种用于非相干MIMO系统的稀疏Grassmannian码设计方法，修正了传统成对错误概率公式以处理稀疏配置引起的秩缺陷问题，并推导了最大化平均互信息的闭式度量。


<details>
  <summary>Details</summary>
Motivation: 传统非相干MIMO系统在非相关瑞利衰落信道下的成对错误概率公式无法处理稀疏配置引起的秩缺陷问题，需要新的设计方法来提高性能并降低复杂度。

Method: 修正了传统成对错误概率公式以统一处理稀疏情况；推导了最大化非相干平均互信息的闭式度量；利用Grassmann流形的Schubert胞分解提供的数学稀疏特性建立稀疏非相干码设计准则。

Result: 提出的稀疏非相干码在符号错误率和平均互信息方面均优于传统方法，在高信噪比下渐近接近最优Grassmannian星座性能，同时降低了时间和空间复杂度（不随发射天线数量增加而增加）。

Conclusion: 该方法成功解决了稀疏配置下的秩缺陷问题，提出的稀疏Grassmannian码在保持高性能的同时显著降低了系统复杂度，为非相干MIMO系统提供了有效的稀疏编码方案。

Abstract: In this paper, we propose a method for designing sparse Grassmannian codes for noncoherent multiple-input multiple-output systems. Conventional pairwise error probability formulations under uncorrelated Rayleigh fading channels fail to account for rank deficiency induced by sparse configurations. We revise these formulations to handle such cases in a unified manner. Furthermore, we derive a closed-form metric that effectively maximizes the noncoherent average mutual information (AMI) at a given signal-to-noise ratio. We focus on the fact that the Schubert cell decomposition of the Grassmann manifold provides a mathematically sparse property, and establish design criteria for sparse noncoherent codes based on our analyses. In numerical results, the proposed sparse noncoherent codes outperform conventional methods in terms of both symbol error rate and AMI, and asymptotically approach the performance of the optimal Grassmannian constellations in the high-signal-to-noise ratio regime. Moreover, they reduce the time and space complexity, which does not scale with the number of transmit antennas.

</details>


### [7] [Impact of Pointing Error on Coverage Performance of 3D Indoor Terahertz Communication Systems](https://arxiv.org/abs/2601.21303)
*Zhifeng Tang,Nan Yang,Xiangyun Zhou,Salman Durrani,Markku Juntti,Josep Miquel Jornet*

Main category: eess.SP

TL;DR: 本文开发了一个三维室内太赫兹通信系统的分析框架，评估指向误差对覆盖性能的影响，发现仅增加天线阵列尺寸不足以改善覆盖概率，需要先进的估计技术。


<details>
  <summary>Details</summary>
Motivation: 太赫兹通信系统中，由于波束成形增益和方向不匹配导致的指向误差会严重影响系统性能，需要建立理论框架来量化分析这种影响。

Method: 使用泊松点过程建模AP位置，随机圆柱过程建模人体遮挡，布尔直线过程建模墙壁遮挡；基于位置估计不准确性表征指向误差；采用多簇波动双射线分布建模小尺度衰落；推导覆盖概率的解析表达式。

Result: 分析表明指向误差对覆盖概率有显著影响；仅增加天线阵列尺寸不足以改善覆盖概率和减轻指向误差的有害影响。

Conclusion: 太赫兹通信系统中，指向误差是影响覆盖性能的关键因素，需要开发先进的估计技术来缓解其负面影响，而不仅仅是增加天线阵列尺寸。

Abstract: In this paper, we develop a tractable analytical framework for a three-dimensional (3D) indoor terahertz (THz) communication system to theoretically assess the impact of the pointing error on its coverage performance. Specifically, we model the locations of access points (APs) using a Poisson point process, human blockages as random cylinder processes, and wall blockages through a Boolean straight line process. A pointing error refers to beamforming gain and direction mismatch between the transmitter and receiver. We characterize it based on the inaccuracy of location estimate. We then analyze the impact of this pointing error on the received signal power and derive a tractable expression for the coverage probability, incorporating the multi-cluster fluctuating two-ray distribution to accurately model small-scale fading in THz communications. Aided by simulation results, we corroborate our analysis and demonstrate that the pointing error has a pronounced impact on the coverage probability. Specifically, we find that merely increasing the antenna array size is insufficient to improve the coverage probability and mitigate the detrimental impact of the pointing error, highlighting the necessity of advanced estimation techniques in THz communication systems.

</details>


### [8] [A Time-Domain Dual-Edge Asynchronous Pipelined SAR ADC Featuring Reset-Free Quantization at Multi-GS/s](https://arxiv.org/abs/2601.21308)
*Richard Zeng,Anthony Chan Carusone,Xilin Liu*

Main category: eess.SP

TL;DR: 提出一种双沿无复位量化技术，用于异步流水线SAR时域ADC，通过利用上升和下降信号边沿消除复位死区，实现高采样率下的连续转换。


<details>
  <summary>Details</summary>
Motivation: 传统时域ADC需要在采样间进行显式复位，引入死区时间，限制了分辨率、速度和能效。随着CMOS技术进步，时域分辨率提升，但复位死区成为高速有线接收器应用的主要瓶颈。

Method: 采用双沿无复位量化概念，在异步流水线SAR时域ADC中同时利用上升和下降信号边沿，实现单转换周期内的无复位量化。包含线性度补偿的双沿电压-时间转换器和具有独立可调上升/下降沿延迟的双沿时间-数字转换器。

Result: 在22nm FD-SOI工艺中实现8位ADC，核心面积0.0089mm²。连续单通道工作达3.5GS/s，间歇工作达10.5GS/s。在3.5GS/s下实现21.6dB SNDR和32.2dB SFDR。

Conclusion: 双沿无复位量化技术可行，性能限制主要来自实现层面而非架构约束，为高速时域ADC提供了有效的解决方案，显著改善了分辨率-速度权衡。

Abstract: Time-domain ADCs are attractive for high-speed wireline receivers, as time resolution scales favorably with advanced CMOS technologies, enabling multi-GS/s single-channel sampling rates. However, conventional time-domain ADCs require explicit reset of voltage-to-time and time-domain signal paths between samples, introducing dead time that fundamentally limits resolution, speed, and energy efficiency. This paper introduces a dual-edge reset-free quantization concept for asynchronous pipelined SAR time-domain ADCs, in which both rising and falling signal edges are exploited to enable reset-free quantization within a single conversion period. By eliminating explicit reset phases, the proposed approach expands the effective conversion window and relaxes the resolution-speed tradeoff at high sampling rates. An 8-bit dual-edge asynchronous pipelined SAR time-domain ADC is implemented in 22-nm FD-SOI, incorporating a linearity-compensated dual-edge voltage-to-time converter and a dual-edge time-to-digital converter with independently tunable rising- and falling-edge delays. The prototype occupies a core area of 0.0089 mm^2 and achieves continuous single-channel operation at 3.5 GS/s, with architectural scalability demonstrated through intermittent operation at 10.5 GS/s and higher. At 3.5 GS/s, the ADC achieves 21.6 dB SNDR and 32.2 dB SFDR. The measured performance is primarily limited by identifiable implementation-level factors rather than by architectural constraints, demonstrating the feasibility of dual-edge reset-free quantization for high-speed time-domain ADCs.

</details>


### [9] [A Linearization of DFT Spectrum for Precision Power Measurement in Presence of Interharmonics](https://arxiv.org/abs/2601.21397)
*Jian Liu,Wei Zhao,Jianting Zhao,Shisong Li*

Main category: eess.SP

TL;DR: 提出基于DFT频谱分析的线性化算法，用于精确测量含间谐波系统的功率，通过构建线性方程组高效提取间谐波分量，显著降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 电力系统中间谐波的存在会导致异步采样，加上基频偏移会进一步恶化功率测量精度。异步条件下间谐波与基波和谐波分量失去正交性，产生额外的功率分量。

Method: 基于DFT频谱分析的线性化算法，从DFT频谱构建线性方程组，通过高效矩阵运算求解，能够准确提取基波和谐波频率附近（频率间隔≥1Hz）的间谐波分量。

Result: 该方法能精确测量基波、谐波、间谐波、交叉功率带及总功率。相比FFT、窗插值FFT和矩阵铅笔-奇异值分解等方法，估计误差降低数倍到多倍，鲁棒性更好，处理10个工频周期（200ms）数据仅需7ms计算时间。

Conclusion: 提出的线性化算法能有效解决含间谐波系统的功率测量问题，在多种条件下（包括变化的间谐波/基波/谐波间隔、基频偏差和噪声）都能准确计算各功率分量，具有高精度和实时性。

Abstract: The presence of interharmonics in power systems can lead to asynchronous sampling, a phenomenon further aggravated by shifts in the fundamental frequency, which significantly degrades the accuracy of power measurements. Under such asynchronous conditions, interharmonics lose orthogonality with the fundamental and harmonic components, giving rise to additional power components. To address these challenges, this paper introduces a linearization algorithm based on DFT spectrum analysis for precise power measurement in systems containing interharmonics. The proposed approach constructs a system of linear equations from the DFT spectrum and solves it through efficient matrix operations, enabling accurate extraction of interharmonic components near the fundamental and harmonic frequencies (with a frequency interval $\geq$1 Hz). This allows for precise measurement of power across the fundamental, harmonic, interharmonic, and cross-power bands, as well as total power. Test results demonstrate that the proposed method accurately computes various power components under diverse conditions--including varying interharmonic/fundamental/harmonic intervals, fundamental frequency deviations, and noise. Compared to existing methods such as fast Fourier transform (FFT), Windowed interpolation FFT, and Matrix pencil-Singular value decomposition, the proposed technique reduces estimation error by several times to multiple folds and exhibits improved robustness, while maintaining a computational time of only 7 ms for processing 10-power-line-cycle (200 ms) data.

</details>


### [10] [Interference Detection and Exploitation for Multi-User Radar Sensing](https://arxiv.org/abs/2601.21429)
*Laurits Randers,Martin Voigt Vejling,Petar Popovski*

Main category: eess.SP

TL;DR: 提出一种用于频谱交错OFDM的干扰检测与利用算法，通过统计严谨的方法检测干扰并控制族错误率，同时利用干扰估计角度、避开干扰估计时延


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，多用户场景下同时传输会在重叠频率上产生相互干扰，导致虚假目标检测和感知精度下降，需要解决干扰问题

Method: 提出干扰检测与利用算法，采用频谱交错正交频分复用，引入统计严谨的程序检测干扰并控制族错误率，算法利用干扰估计角度，同时避开干扰估计时延

Result: 数值实验表明，所提方法能可靠检测干扰，且时延和角度估计误差接近克拉美罗下界

Conclusion: 该算法能有效处理多用户干扰问题，在集成感知与通信系统中实现准确的参数估计

Abstract: Integrated sensing and communication is a key feature in next-generation wireless networks, enabling joint data transmission and environmental radar sensing on shared spectrum. In multi-user scenarios, simultaneous transmissions cause mutual interference on overlapping frequencies, leading to spurious target detections and degraded sensing accuracy. This paper proposes an interference detection and exploitation algorithm for sensing using spectrally interleaved orthogonal frequency division multiplexing. A statistically rigorous procedure is introduced to detect interference while controlling the familywise error rate. We propose an algorithm that estimates the angle by exploiting interference, while estimating the delay by avoiding the interference. Numerical experiments demonstrate that the proposed method reliably detects interference, and that the delay and angle estimation error approaches the Cramér-Rao lower bound.

</details>


### [11] [Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays](https://arxiv.org/abs/2601.21481)
*Sai Pavan Deram,Jacopo Pegoraro,Javier Lorca Hernando,Jesus O. Lacruz,Joerg Widmer*

Main category: eess.SP

TL;DR: SHARE是一种用于近场ISAC定位的两阶段稀疏恢复算法，通过分层处理解决稀疏子阵列架构中的栅瓣模糊问题，在降低硬件成本的同时保持高分辨率。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC定位需要大孔径阵列，但全数字实现成本过高。稀疏子阵列架构虽能降低成本，却会引入严重的栅瓣模糊问题。

Method: 提出SHARE算法，分为两个阶段：第一阶段使用单个子阵列进行粗略但无模糊的角度估计以解决栅瓣模糊；第二阶段利用整个稀疏孔径进行局部化的联合角度-距离搜索。

Result: 仿真结果表明，SHARE在定位精度和鲁棒性上显著优于传统的一阶段稀疏恢复方法（如OMP），并且其整体定位精度与全数字2D-MUSIC算法相当甚至更好。

Conclusion: SHARE为高分辨率近场ISAC系统提供了一条实用路径，在保持大孔径高分辨率的同时，通过稀疏架构降低了硬件成本和复杂度。

Abstract: Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.

</details>


### [12] [Channel Extrapolation for MIMO Systems with the Assistance of Multi-path Information Induced from Channel State Information](https://arxiv.org/abs/2601.21524)
*Yuan Gao,Xinyi Wu,Jiang Jun,Zitian Zhang,Zhaohui Yang,Shugong Xu,Cheng-Xiang Wang,Zhu Han*

Main category: eess.SP

TL;DR: 提出基于CSI-to-PDP模块和多路径特征的MAE架构，无需额外模态即可实现高效信道外推，显著提升性能且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法在6G网络中开销过高，现有基于环境信息的方法存在硬件、隐私和多模态对齐问题，需要一种仅利用CSI本身多路径特征的外推方案。

Method: 1) CSI-to-PDP模块：通过自编码器框架将CSI转换为功率延迟剖面(PDP)；2) 提取多路径特征：总功率和功率加权延迟；3) MAE架构：使用分离编码器提取掩码CSI和多路径特征，通过交叉注意力融合，自监督训练进行信道外推。

Result: 框架显著提升外推性能，推理时间仅增加约0.1ms，在已知CSI比例较小时表现出强泛化能力，优于现有基准方法。

Conclusion: 提出的框架通过利用CSI内在多路径特征，无需额外模态即可实现高效信道外推，为6G网络提供了一种实用且性能优越的解决方案。

Abstract: Acquiring channel state information (CSI) through traditional methods, such as channel estimation, is increasingly challenging for the emerging sixth generation (6G) mobile networks due to high overhead. To address this issue, channel extrapolation techniques have been proposed to acquire complete CSI from a limited number of known CSIs. To improve extrapolation accuracy, environmental information, such as visual images or radar data, has been utilized, which poses challenges including additional hardware, privacy and multi-modal alignment concerns. To this end, this paper proposes a novel channel extrapolation framework by leveraging environment-related multi-path characteristics induced directly from CSI without integrating additional modalities. Specifically, we propose utilizing the multi-path characteristics in the form of power-delay profile (PDP), which is acquired using a CSI-to-PDP module. CSI-to-PDP module is trained in an AE-based framework by reconstructing the PDPs and constraining the latent low-dimensional features to represent the CSI. We further extract the total power & power-weighted delay of all the identified paths in PDP as the multi-path information. Building on this, we proposed a MAE architecture trained in a self-supervised manner to perform channel extrapolation. Unlike standard MAE approaches, our method employs separate encoders to extract features from the masked CSI and the multi-path information, which are then fused by a cross-attention module. Extensive simulations demonstrate that this framework improves extrapolation performance dramatically, with a minor increase in inference time (around 0.1 ms). Furthermore, our model shows strong generalization capabilities, particularly when only a small portion of the CSI is known, outperforming existing benchmarks.

</details>


### [13] [Near-Field Positioning for XL-MIMO Uniform Circular Arrays: An Attention-Enhanced Deep Learning Approach](https://arxiv.org/abs/2601.21550)
*Yuan Gao,Xinyu Guo,Han Li,Jianbo Du,Shugong Xu*

Main category: eess.SP

TL;DR: 论文提出了一种基于注意力增强深度学习的精确定位方法，针对6G XL-MIMO系统中的近场定位挑战，通过双路径通道注意力和空间注意力机制，在定位精度上超越了现有基准模型。


<details>
  <summary>Details</summary>
Motivation: 6G移动通信中XL-MIMO系统天线数量大幅增加，扩展了近场范围，挑战了传统远场假设。均匀圆形阵列(UCAs)相比线性平面阵列具有恒定角度分辨率的优势，但如何利用XL-MIMO的扩展孔径和近场效应进行精确定位仍需深入研究。

Method: 提出注意力增强深度学习定位方法，采用双路径通道注意力机制和空间注意力机制，有效整合通道级和空间级特征。使用输入信号的协方差度量作为模型输入，相比信道状态信息(CSI)在定位精度和模型效率上更具优势。

Result: 综合仿真表明，该模型超越了注意力定位网络(ABPN)、近场定位网络(NFLnet)、卷积神经网络(CNN)和多层感知器(MLP)等现有基准。在定位精度上表现优异，且协方差度量相比CSI在定位精度和模型效率方面更具优势。

Conclusion: 提出的注意力增强深度学习定位方法能有效应对XL-MIMO系统中的近场定位挑战，通过创新的注意力机制和协方差度量输入，实现了更精确的定位性能，为6G通信系统中的定位问题提供了有效解决方案。

Abstract: In the evolving landscape of sixth-generation (6G) mobile communication, multiple-input multiple-output (MIMO) systems are incorporating an unprecedented number of antenna elements, advancing towards Extremely large-scale multiple-input-multiple-output (XL-MIMO) systems. This enhancement significantly increases the spatial degrees of freedom, offering substantial benefits for wireless positioning. However, the expansion of the near-field range in XL-MIMO challenges the traditional far-field assumptions used in previous MIMO models. Among various configurations, uniform circular arrays (UCAs) demonstrate superior performance by maintaining constant angular resolution, unlike linear planar arrays. Addressing how to leverage the expanded aperture and harness the near-field effects in XL-MIMO systems remains an area requiring further investigation. In this paper, we introduce an attention-enhanced deep learning approach for precise positioning. We employ a dual-path channel attention mechanism and a spatial attention mechanism to effectively integrate channel-level and spatial-level features. Our comprehensive simulations show that this model surpasses existing benchmarks such as attention-based positioning networks (ABPN), near-field positioning networks (NFLnet), convolutional neural networks (CNN), and multilayer perceptrons (MLP). The proposed model achieves superior positioning accuracy by utilizing covariance metrics of the input signal. Also, simulation results reveal that covariance metric is advantageous for positioning over channel state information (CSI) in terms of positioning accuracy and model efficiency.

</details>


### [14] [VSE: Variational state estimation of complex model-free process](https://arxiv.org/abs/2601.21887)
*Gustav Norén,Anubhab Ghosh,Fredrik Cumlin,Saikat Chatterjee*

Main category: eess.SP

TL;DR: 提出一种变分状态估计方法，通过RNN提供复杂动态过程的闭式高斯后验，无需物理模型，在跟踪应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对缺乏合适物理模型的复杂动态过程，需要从非线性测量中估计状态。传统方法需要已知系统模型，而实际应用中往往模型未知或不准确。

Method: 使用两个相互辅助的RNN：一个在推理阶段提供闭式高斯后验，另一个在学习阶段辅助训练。基于变分推断原理，两个RNN相互促进学习。

Result: 在随机Lorenz系统的跟踪应用中，VSE方法表现优异，与已知模型的粒子滤波和最近提出的数据驱动状态估计方法相比具有竞争力。

Conclusion: VSE方法为模型未知的复杂动态过程状态估计提供了有效的解决方案，通过RNN实现闭式高斯后验，计算简单且性能良好。

Abstract: We design a variational state estimation (VSE) method that provides a closed-form Gaussian posterior of an underlying complex dynamical process from (noisy) nonlinear measurements. The complex process is model-free. That is, we do not have a suitable physics-based model characterizing the temporal evolution of the process state. The closed-form Gaussian posterior is provided by a recurrent neural network (RNN). The use of RNN is computationally simple in the inference phase. For learning the RNN, an additional RNN is used in the learning phase. Both RNNs help each other learn better based on variational inference principles. The VSE is demonstrated for a tracking application - state estimation of a stochastic Lorenz system (a benchmark process) using a 2-D camera measurement model. The VSE is shown to be competitive against a particle filter that knows the Lorenz system model and a recently proposed data-driven state estimation method that does not know the Lorenz system model.

</details>


### [15] [Joint Laser Inter-Satellite Link Matching and Traffic Flow Routing in LEO Mega-Constellations via Lagrangian Duality](https://arxiv.org/abs/2601.21914)
*Zhouyou Gu,Jihong Park,Jinho Choi*

Main category: eess.SP

TL;DR: 本文提出了一种联合优化激光通信终端连接和流量路由的方法，以最大化低轨卫星星座的吞吐量，考虑了实际的机械限制和全球流量分布。


<details>
  <summary>Details</summary>
Motivation: 现有激光星间链路方案往往忽略激光通信终端的机械限制以及由用户和网关分布不均导致的非均匀全球流量分布，导致吞吐量次优和激光通信终端/链路利用率不足，特别是在每颗卫星仅携带少量激光通信终端的情况下。

Method: 将问题建模为NP难的混合整数规划，通过拉格朗日对偶松弛耦合约束，将问题分解为加权图匹配（用于激光通信终端连接）、加权最短路径路由任务和速率分配的线性规划。拉格朗日乘子反映卫星间的拥塞权重，共同指导匹配、路由和速率分配，使用次梯度下降优化乘子并具有可证明的收敛性。

Result: 使用真实世界星座和地面数据的仿真表明，该方法相比现有的非联合方法，网络吞吐量提高了35%-145%。

Conclusion: 通过联合优化激光通信终端连接和流量路由，考虑实际的机械约束和全球流量分布，可以显著提高低轨卫星星座的吞吐量，有效解决现有方法的局限性。

Abstract: Low Earth orbit (LEO) mega-constellations greatly extend the coverage and resilience of future wireless systems. Within the mega-constellations, laser inter-satellite links (LISLs) enable high-capacity, long-range connectivity. Existing LISL schemes often overlook mechanical limitations of laser communication terminals (LCTs) and non-uniform global traffic profiles caused by uneven user and gateway distributions, leading to suboptimal throughput and underused LCTs/LISLs -- especially when each satellite carries only a few LCTs. This paper investigates the joint optimization of LCT connections and traffic routing to maximize the constellation throughput, considering the realistic LCT mechanics and the global traffic profile. The problem is formulated as an NP-hard mixed-integer program coupling LCT connections with flow-rate variables under link capacity constraints. Due to its intractability, we resort to relaxing the coupling constraints via Lagrangian duality, decomposing the problem into a weighted graph-matching for LCT connections, weighted shortest-path routing tasks, and a linear program for rate allocation. Here, Lagrange multipliers reflect congestion weights between satellites, jointly guiding the matching, routing, and rate allocation. Subgradient descent optimizes the multipliers, with provable convergence. Simulations using real-world constellation and terrestrial data show that our methods substantially improve network throughput by up to $35\%$--$145\%$ over existing non-joint approaches.

</details>


### [16] [Duality-Guided Graph Learning for Real-Time Joint Connectivity and Routing in LEO Mega-Constellations](https://arxiv.org/abs/2601.21921)
*Zhouyou Gu,Jinho Choi,Tony Q. S. Quek,Jihong Park*

Main category: eess.SP

TL;DR: DeepLaDu：基于拉格朗日对偶引导的深度学习框架，通过图神经网络单次前向传播预测链路拥塞价格，实现LEO卫星激光链路连接、路由和流量分配的联合优化，大幅降低计算时间。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道巨型星座的激光星间链路面临激光通信终端有限、机械指向约束和快速时变网络拓扑等挑战，需要实时高效的联合优化管理方案。

Method: 将问题建模为大规模时变星座图上的混合整数优化，提出拉格朗日对偶分解框架DeepLaDu，使用图神经网络直接从星座状态单次前向传播推断链路级拥塞价格，采用基于次梯度的边级损失实现可扩展训练。

Result: 在真实的类星链星座模拟中，DeepLaDu比非联合或启发式基线提高20%的网络吞吐量，同时匹配迭代对偶优化性能，计算时间降低数个数量级，适合动态LEO网络的实时操作。

Conclusion: DeepLaDu通过深度学习与拉格朗日对偶理论的结合，解决了LEO卫星激光链路管理的实时优化难题，为动态非地面网络提供了高效可行的解决方案。

Abstract: Laser inter-satellite links (LISLs) of low Earth orbit (LEO) mega-constellations enable high-capacity backbone connectivity in non-terrestrial networks, but their management is challenged by limited laser communication terminals, mechanical pointing constraints, and rapidly time-varying network topologies. This paper studies the joint problem of LISL connection establishment, traffic routing, and flow-rate allocation under heterogeneous global traffic demand and gateway availability. We formulate the problem as a mixed-integer optimization over large-scale, time-varying constellation graphs and develop a Lagrangian dual decomposition that interprets per-link dual variables as congestion prices coordinating connectivity and routing decisions. To overcome the prohibitive latency of iterative dual updates, we propose DeepLaDu, a Lagrangian duality-guided deep learning framework that trains a graph neural network (GNN) to directly infer per-link (edge-level) congestion prices from the constellation state in a single forward pass. We enable scalable and stable training using a subgradient-based edge-level loss in DeepLaDu. We analyze the convergence and computational complexity of the proposed approach and evaluate it using realistic Starlink-like constellations with optical and traffic constraints. Simulation results show that DeepLaDu achieves up to 20\% higher network throughput than non-joint or heuristic baselines, while matching the performance of iterative dual optimization with orders-of-magnitude lower computation time, suitable for real-time operation in dynamic LEO networks.

</details>


### [17] [Optimal Placement of Movable Antennas for Angle-of-Departure Estimation Under User Location Uncertainty](https://arxiv.org/abs/2601.21997)
*Lucía Pallarés-Rodríguez,Angelo Coluccia,Alessio Fascista,Musa Furkan Keskin,Henk Wymeersch,José A. López-Salcedo,Gonzalo Seco-Granados*

Main category: eess.SP

TL;DR: 该论文研究在用户设备位置不确定情况下，使用可移动天线阵列进行角度离场估计，通过理论性能界限推导和天线位置优化，实现比固定阵列更优越的性能。


<details>
  <summary>Details</summary>
Motivation: 传统超大天线阵列存在成本和功耗限制，可移动天线能克服这些限制。在用户设备位置不确定的实际场景中，需要研究如何利用可移动天线阵列进行准确的角度离场估计。

Method: 1) 推导克拉美-罗界作为理论性能界限；2) 在用户设备不确定性区域内优化天线位置以确保鲁棒性能；3) 通过数值结果比较动态优化天线布局与固定阵列的性能。

Result: 数值结果表明，通过显式考虑不确定性区域来动态优化天线布局，相比固定阵列能获得更优越的性能，证明可移动天线系统具有适应性和超越传统阵列的能力。

Conclusion: 可移动天线阵列在用户设备位置不确定情况下能有效进行角度离场估计，通过动态优化天线位置可以显著提升性能，为实际通信系统提供了有前景的解决方案。

Abstract: Movable antennas (MA) have gained significant attention in recent years to overcome the limitations of extremely large antenna arrays in terms of cost and power consumption. In this paper, we investigate the use of MA arrays at the base station (BS) for angle-of-departure (AoD) estimation under uncertainty in the user equipment (UE) location. Specifically, we (i) derive the theoretical performance limits through the Cramér-Rao bound (CRB) and (ii) optimize the antenna positions to ensure robust performance within the UE's uncertainty region. Numerical results show that dynamically optimizing antenna placement by explicitly considering the uncertainty region yields superior performance compared to fixed arrays, demonstrating the ability of MA systems to adapt and outperform conventional arrays.

</details>


### [18] [Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems](https://arxiv.org/abs/2601.22109)
*Ali Reda,Tamer Mekkawy,Theodoros A. Tsiftsis,Chan-Byoung Chae,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 提出了一种基于流体天线系统辅助可重构智能表面的无人机下行通信方案，通过联合优化天线端口位置和RIS相位偏移来最大化可达速率，显著改善了中断概率和性能


<details>
  <summary>Details</summary>
Motivation: 无人机集成到蜂窝网络面临严重的空对地干扰问题，需要有效的解决方案来提升通信质量

Method: 采用流体天线系统辅助的可重构智能表面，通过联合优化FAS端口位置和RIS相位偏移，使用基于二阶锥规划的逐次凸逼近算法解决非凸优化问题

Result: 仿真结果表明，相比传统固定位置天线方案，该算法显著改善了中断概率和可达速率，在大规模RIS配置下增益尤为明显，且算法收敛速度快，适合实时应用

Conclusion: 提出的FAS辅助RIS方案能有效应对无人机通信中的干扰问题，提升系统性能，具有实际应用价值

Abstract: Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [The Noncomputability of Immune Reaction Complexity: Algorithmic Information Gaps under Effective Constraints](https://arxiv.org/abs/2601.20865)
*Emmanuel Pio Pastore,Francesco De Rango*

Main category: cs.IT

TL;DR: 该论文提出了一种基于算法信息论的"有效性过滤、证书驱动"的反应视图，定义了最小可行实现复杂度M(x)和归一化建议分位数(NAQ)作为任务难度的尺度无关指标。


<details>
  <summary>Details</summary>
Motivation: 需要一种理论框架来量化任务难度，该框架应具有尺度无关性、对通用机选择鲁棒、且能跨任务族比较。传统复杂度度量往往依赖于特定实现细节，缺乏统一的难度指标。

Method: 基于算法信息论，引入固定、总体、输入盲的执行器，将自定界建议字符串映射到候选响应，仅当可判定或半可判定的有效性谓词V(x,r)成立时才接受。定义最小可行实现复杂度M(x) = min_{r: V(x,r)=1} K(r)，其中K为前缀柯尔莫哥洛夫复杂度。进一步定义归一化建议分位数(NAQ)作为M(x)在参考池中的百分位数。

Result: 证明了精确实现恒等式：任何输入盲执行器的最小建议复杂度等于M(x)至多O(1)误差。在有限模糊度机制中M(x)约等于min_y K(y)；在通用纤维机制中边界是紧的。NAQ在有限枚举变化下具有准不变性，并与率失真理论有操作逆关系。扩展包括资源受限变体NAQ_t和NP风格设置，以及DKW边界保证经验NAQ估计的收敛性。

Conclusion: 提出的NAQ框架提供了一个理论严谨、尺度无关、可比较的任务难度度量，能够通过基于压缩器的代理进行数据驱动的校准，为算法信息论在任务难度量化中的应用提供了系统方法。

Abstract: We introduce a validity-filtered, certificate-based view of reactions grounded in Algorithmic Information Theory. A fixed, total, input-blind executor maps a self-delimiting advice string to a candidate response, accepted only if a decidable or semi-decidable validity predicate V(x, r) holds. The minimum feasible realizer complexity M(x) = min_{r: V(x,r)=1} K(r), with K denoting prefix Kolmogorov complexity, measures the minimal information required for a valid outcome. We define the Normalized Advice Quantile (NAQ) as the percentile of M(x) across a reference pool, yielding a scale-free hardness index on [0, 1] robust to the choice of universal machine and comparable across task families. An Exact Realizer Identity shows that the minimal advice for any input-blind executor equals M(x) up to O(1), while a description plus selection upper bound refines it via computable feature maps, separating description cost K(y) from selection cost log i_y(x). In finite-ambiguity regimes M(x) approximately equals min_y K(y); in generic-fiber regimes the bound is tight. NAQ is quasi-invariant under bounded enumeration changes. An operational converse links NAQ to rate-distortion: communicating advice with error epsilon requires average length near the entropy of target features. Extensions include a resource-bounded variant NAQ_t incorporating time-penalized complexity (Levin's Kt) and an NP-style setting showing linear worst-case advice n - O(1). Finally, a DKW bound guarantees convergence of empirical NAQ estimates, enabling data-driven calibration via compressor-based proxies.

</details>


### [20] [Cramér-Rao Bound Analysis and Near-Optimal Performance of the Synchronous Nyquist-Folding Generalized Eigenvalue Method (SNGEM) for Sub-Nyquist Multi-Tone Parameter Estimation](https://arxiv.org/abs/2601.20866)
*Huiguang Zhang*

Main category: cs.IT

TL;DR: SNGEM方法在极端亚奈奎斯特速率下实现多音信号的完整频率/幅度/相位估计，通过联合处理原始信号及其时间导数，在噪声条件下接近CRB下界，优于传统压缩感知OMP方法。


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知方法（如OMP）在亚奈奎斯特采样中存在不可约的误差平坦化问题，这主要是由于DFT网格偏差和混叠噪声造成的。需要开发一种能够在极端压缩比下实现统计接近最优的参数谱分析方法。

Method: 提出同步奈奎斯特折叠广义特征值方法（SNGEM），通过联合处理原始信号及其时间导数来估计多音信号的完整频率、幅度和相位参数。推导了两个通道等SNR条件下幅度比参数R=A/B=1/(2πf)的精确克拉美-罗下界。

Result: 蒙特卡洛模拟验证：在无噪声条件下SNGEM达到机器精度；在所有SNR水平下都接近推导的CRB下界，即使在10-20倍压缩比下也表现良好。相比之下，传统压缩感知OMP方法由于DFT网格偏差和混叠噪声而表现出不可约的误差平坦化。

Conclusion: SNGEM被确立为一种统计上接近最优的确定性亚奈奎斯特参数谱分析方法，在极端压缩比下仍能保持接近理论极限的性能，优于传统压缩感知方法。

Abstract: The synchronous Nyquist folding generalized eigenvalue method (SNGEM) realizes full frequency/amplitude/phase estimation of multitone signals at extreme sub-Nyquist rates by jointly processing the original signals and their time derivatives. In this paper, accurate Cramer-Rao bounds for amplitude ratio parameter R=A/B=1/(2\pif) are derived for two channels with equal SNR. Monte-Carlo simulations confirm that SNGEM achieves machine accuracy in noise-free conditions and closely approaches the derived CRB at all SNR levels, even at 10- 20x compression, whereas classical compressive sensing OMP exhibits irreducible error flattening due to DFT grid bias and aliasing noise. These results establish SNGEM as a statistically nearly optimal deterministic sub-Nyquist parameter spectrum analysis

</details>


### [21] [Power consumption Reduction in ELAA-Assisted ISAC Systems](https://arxiv.org/abs/2601.21010)
*Xiaomin Cao,Mohammadali Mohammadi,Hien Quoc Ngo,Michail Matthaiou*

Main category: cs.IT

TL;DR: 提出一种用于集成感知与通信（ISAC）的超大规模天线阵列（ELAA）节能子阵列激活框架，通过选择最优子阵列子集来最小化总功耗，同时满足感知和通信的服务质量约束。


<details>
  <summary>Details</summary>
Motivation: 超大规模天线阵列（ELAAs）对于实现高分辨率近场感知至关重要，但传统数字架构中完全激活所有天线单元会导致功耗过高，难以实际应用。

Method: 提出节能子阵列激活框架，将问题建模为优化问题，采用基于连续凸逼近（SCA）的迭代算法求解，在满足感知和通信服务质量约束下选择最优子阵列子集。

Result: 仿真结果表明，所提方法能显著降低功耗，同时保持双功能（感知和通信）性能。

Conclusion: 该研究为超大规模天线阵列在集成感知与通信应用中的节能设计提供了有效解决方案，通过智能子阵列激活策略实现了功耗与性能的良好平衡。

Abstract: In this paper, we consider power consumption reduction in extremely large antenna arrays (ELAAs) for integrated sensing and communication (ISAC) applications. Although ELAAs are critical for achieving high-resolution near-field sensing, fully activating all antenna elements in conventional digital architectures leads to prohibitive power demands. To address this, we propose an energy-efficient subarray activation framework that selects an optimal subset of subarrays to minimize the total power consumption, subject to quality-of-service (QoS) constraints for both sensing and communication. We formulate a novel optimization problem and solve it using a successive convex approximation (SCA)-based iterative algorithm. The simulation results confirm that the proposed method significantly reduces power consumption while maintaining dual-function performance.

</details>


### [22] [Deletion-correcting codes for an adversarial nanopore channel](https://arxiv.org/abs/2601.21236)
*Huiling Xie,Zitan Chen*

Main category: cs.IT

TL;DR: 本文研究了对抗性纳米孔通道的删除纠错码，提出了具有2t log_q n + Θ(log log n)冗余符号的显式构造，并证明了最优冗余在t log_q n + Ω(1)和2t log_q n - log_q log_2 n + O(1)之间。


<details>
  <summary>Details</summary>
Motivation: 研究对抗性纳米孔通道中的删除纠错问题，该通道最多可能发生t次删除。与经典对抗性q元删除通道相比，现有显式构造的冗余度较高（4t(1+ε)log_q n + o(log n)），需要更高效的构造方法。

Method: 提出了一种显式构造q元码的方法，码长为n，专门针对最多发生t次删除的对抗性纳米孔通道。构造实现了2t log_q n + Θ(log log n)的冗余符号。

Result: 证明了最优冗余度在t log_q n + Ω(1)和2t log_q n - log_q log_2 n + O(1)之间，提出的显式构造与存在性上界在一阶上匹配。与经典删除通道的4t(1+ε)log_q n + o(log n)冗余相比有明显改进。

Conclusion: 针对对抗性纳米孔通道的删除纠错码，本文提出了接近最优的显式构造，冗余度显著优于经典删除通道的已知构造，填补了该领域的研究空白。

Abstract: We study deletion-correcting codes for an adversarial nanopore channel in which at most $t$ deletions may occur. We propose an explicit construction of $q$-ary codes of length $n$ for this channel with $2t\log_q n+Θ(\log\log n)$ redundant symbols. We also show that the optimal redundancy is between $t\log_q n+Ω(1)$ and $2t\log_q n-\log_q\log_2 n+O(1)$, so our explicit construction matches the existential upper bound to first order. In contrast, for the classical adversarial $q$-ary deletion channel, the smallest redundancy achieved by known explicit constructions that correct up to $t$ deletions is $4t(1+ε)\log_q n+o(\log n)$.

</details>


### [23] [Belief Propagation with Quantum Messages for Symmetric Q-ary Pure-State Channels](https://arxiv.org/abs/2601.21330)
*Avijit Mandal,Henry D. Pfister*

Main category: cs.IT

TL;DR: 将BPQM（量子消息的置信传播）从二进制字母表推广到对称q元纯态信道，建立了密度演化分析框架，可用于LDPC码的阈值估计和极化码构造。


<details>
  <summary>Details</summary>
Motivation: 先前BPQM构造和密度演化分析主要针对二进制字母表，需要将其推广到更一般的q元字母表，特别是对称纯态信道，以扩展BPQM的应用范围。

Method: 针对输出Gram矩阵为循环矩阵的对称q元纯态信道，通过比特节点和校验节点合并的闭式递推，在Gram矩阵特征值上进行跟踪，独立于输出态的具体物理实现。

Result: 得到了BPQM酉变换的显式构造，以及合并信道保真度的解析界，建立了对称q元纯态信道的密度演化框架，可用于LDPC码的BPQM解码阈值估计和极化码构造。

Conclusion: 成功将BPQM推广到对称q元纯态信道，建立了有效的密度演化分析框架，为量子通信中LDPC码和极化码的设计提供了理论基础。

Abstract: Belief propagation with quantum messages (BPQM) provides a low-complexity alternative to collective measurements for communication over classical--quantum channels. Prior BPQM constructions and density-evolution (DE) analyses have focused on binary alphabets. Here, we generalize BPQM to symmetric q-ary pure-state channels (PSCs) whose output Gram matrix is circulant. For this class, we show that bit-node and check-node combining can be tracked efficiently via closed-form recursions on the Gram-matrix eigenvalues, independent of the particular physical realization of the output states. These recursions yield explicit BPQM unitaries and analytic bounds on the fidelities of the combined channels in terms of the input-channel fidelities. This provides a DE framework for symmetric q-ary PSCs that allows one to estimate BPQM decoding thresholds for LDPC codes and to construct polar codes on these channels.

</details>


### [24] [Learning-Based Sensor Scheduling for Delay-Aware and Stable Remote State Estimation](https://arxiv.org/abs/2601.21482)
*Nho-Duc Tran,Aamir Mahmood,Mikael Gidlund*

Main category: cs.IT

TL;DR: 提出一个考虑延迟感知的统一框架，量化延迟依赖的信息增益，设计基于PPO的调度器，在异构传感器网络中实现更低的估计误差和能耗平衡。


<details>
  <summary>Details</summary>
Motivation: 无线远程状态估计中不可预测的传感器到估计器延迟会扭曲信息新鲜度的重要性，需要同时考虑延迟与传感器信息量和能量效率的交互作用。现有基于信息年龄(AoI)的代理指标无法充分捕捉这种耦合关系。

Method: 1) 提出延迟感知的统一框架，量化延迟依赖的信息增益；2) 引入高效的后验融合更新方法，无需状态增广即可处理延迟测量；3) 推导可处理的稳定性条件；4) 将调度建模为马尔可夫决策过程，开发基于PPO的调度器，通过归一化奖励权衡估计精度、新鲜度、传感器异构性和传输能量。

Result: 在异构传感器、实际链路能量模型和随机延迟的仿真中，该方法稳定学习，相比随机调度和强化学习基线(DQN, A2C)，在可比能量消耗下实现更低的估计误差，同时对测量可用性和过程/测量噪声变化具有鲁棒性。

Conclusion: 提出的延迟感知框架和信息每焦耳调度目标超越了传统AoI代理指标，PPO调度器能够直接从交互中学习，无需先验延迟模型，在异构传感器网络中有效平衡估计精度和能量效率。

Abstract: Unpredictable sensor-to-estimator delays fundamentally distort what matters for wireless remote state estimation: not just freshness, but how delay interacts with sensor informativeness and energy efficiency. In this paper, we present a unified, delay-aware framework that models this coupling explicitly and quantifies a delay-dependent information gain, motivating an information-per-joule scheduling objective beyond age of information proxies (AoI). To this end, we first introduce an efficient posterior-fusion update that incorporates delayed measurements without state augmentation, providing a consistent approximation to optimal delayed Kalman updates, and then derive tractable stability conditions ensuring that bounded estimation error is achievable under stochastic, delayed scheduling. This conditions highlight the need for unstable modes to be observable across sensors. Building on this foundation, we cast scheduling as a Markov decision process and develop a proximal policy optimization (PPO) scheduler that learns directly from interaction, requires no prior delay model, and explicitly trades off estimation accuracy, freshness, sensor heterogeneity, and transmission energy through normalized rewards. In simulations with heterogeneous sensors, realistic link-energy models, and random delays, the proposed method learns stably and consistently achieves lower estimation error at comparable energy than random scheduling and strong RL baselines (DQN, A2C), while remaining robust to variations in measurement availability and process/measurement noise.

</details>


### [25] [Transversal gates for quantum CSS codes](https://arxiv.org/abs/2601.21514)
*Eduardo Camps-Moreno,Hiram H. López,Gretchen L. Matthews,Narayanan Rengaswamy,Rodrigo San-José*

Main category: cs.IT

TL;DR: 该论文研究了CSS码的横向门计算问题，确定了逻辑作用，推导了相关群组方程，并针对单项式码族给出了完整的横向稳定子和横向门集合。


<details>
  <summary>Details</summary>
Motivation: 研究CSS码的横向门计算问题，特别是确定固定CSS码的对角横向门集合，这对于量子纠错码的设计和分析具有重要意义。

Method: 通过推导定义群组的方程，确定逻辑门的逻辑作用，计算横向稳定子和横向门的完整集合，特别针对单项式码族（包括递减单项式码和极化码）。

Result: 获得了CSS码横向门的完整理论框架，能够恢复和扩展文献中关于CSS-T码、三重正交码和可除码的相关结果。

Conclusion: 该方法为CSS码的横向门分析提供了系统化的解决方案，特别适用于单项式码族，具有重要的理论和应用价值。

Abstract: In this paper, we focus on the problem of computing the set of diagonal transversal gates fixing a CSS code. We determine the logical actions of the gates as well as the groups of transversal gates that induce non-trivial logical gates and logical identities. We explicitly declare the set of equations defining the groups, a key advantage and differentiator of our approach. We compute the complete set of transversal stabilizers and transversal gates for any CSS code arising from monomial codes, a family that includes decreasing monomial codes and polar codes. As a consequence, we recover and extend some results in the literature on CSS-T codes, triorthogonal codes, and divisible codes.

</details>


### [26] [Subjective Distortion: Achievability and Outer Bounds for Distortion Functions with Memory](https://arxiv.org/abs/2601.21757)
*Hamidreza Abin,Amin Gohari,Andrew W. Eckford*

Main category: cs.IT

TL;DR: 该论文研究了具有历史依赖性的率失真问题，其中失真函数不仅依赖于当前源符号与表示符号之间的瞬时失真，还依赖于过去的表示。论文给出了该问题的形式化定义，并提出了率失真权衡的内界（可达）和外界界限，讨论了问题的凸化方法以简化界限求解。


<details>
  <summary>Details</summary>
Motivation: 在某些率失真类型问题中，信息所需的保真度受到过去动作的影响，导致失真函数不仅依赖于源符号与其表示符号之间的瞬时失真，还依赖于过去的表示。这类问题在生物信息处理和推荐引擎等领域出现，需要建立相应的理论框架。

Method: 论文首先给出了具有历史依赖性的率失真问题的形式化定义，然后提出了该问题率失真权衡的内界（可达界限）和外界界限。为了简化界限求解，讨论了问题的凸化方法，使问题更容易处理。

Result: 论文建立了具有历史依赖性的率失真问题的理论框架，提供了内界和外界界限，并通过凸化方法使界限求解更加容易。作为应用示例，将理论应用于简化的生物信息处理问题。

Conclusion: 该研究为具有历史依赖性的率失真问题提供了系统的理论分析框架，包括形式化定义、界限分析和凸化方法，为生物信息处理和推荐引擎等实际应用提供了理论基础。

Abstract: In some rate-distortion-type problems, the required fidelity of information is affected by past actions. As a result, the distortion function depends not only on the instantaneous distortion between a source symbol and its representation symbol, but also on past representations. In this paper, we give a formal definition of this problem and introduce both inner (achievable) and outer bounds on the rate-distortion tradeoff. We also discuss convexification of the problem, which makes it easier to find bounds. Problems of this type arise in biological information processing, as well as in recommendation engines; we provide an example applied to a simplified biological information processing problem.

</details>


### [27] [Adaptive Privacy of Sequential Data Releases Under Collusion](https://arxiv.org/abs/2601.21859)
*Sophie Taylor,Praneeth Kumar Vippathalla,Justin Coon*

Main category: cs.IT

TL;DR: 论文提出了一种自适应算法，用于处理不同实体（可能合谋）的顺序数据请求，在隐私与效用之间进行权衡优化。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于两个观察：1) 一次性数据发布的隐私机制不能直接扩展到顺序发布；2) 实际数据库可能对多个不同方有用，且无法排除数据共享的可能性。

Method: 采用基于互信息的隐私度量，考虑预期失真和互信息作为效用度量，假设数据接收者之间可能存在合谋攻击。开发了使用改进的Blahut-Arimoto算法的自适应数据发布算法。

Result: 当效用以预期失真衡量时，所得数据发布是最优的；当效用以互信息衡量时，是局部最优的。算法能自适应处理顺序数据请求。

Conclusion: 该研究为顺序数据发布中的隐私-效用权衡提供了解决方案，并讨论了在机器学习应用中的扩展可能性。

Abstract: The fundamental trade-off between privacy and utility remains an active area of research. Our contribution is motivated by two observations. First, privacy mechanisms developed for one-time data release cannot straightforwardly be extended to sequential releases. Second, practical databases are likely to be useful to multiple distinct parties. Furthermore, we can not rule out the possibility of data sharing between parties. With utility in mind, we formulate a privacy-utility trade-off problem to adaptively tackle sequential data requests made by different, potentially colluding entities. We consider both expected distortion and mutual information as measures to quantify utility, and use mutual information to measure privacy. We assume an attack model whereby illicit data sharing, which we call collusion, can occur between data receivers. We develop an adaptive algorithm for data releases that makes use of a modified Blahut-Arimoto algorithm. We show that the resulting data releases are optimal when expected distortion quantifies utility, and locally optimal when mutual information quantifies utility. Finally, we discuss how our findings may extend to applications in machine learning.

</details>


### [28] [Beyond Martingale Estimators: Structured Estimators for Maximizing Information Freshness in Query-Based Update Systems](https://arxiv.org/abs/2601.22098)
*Sahan Liyanaarachchi,Sennur Ulukus,Nail Akar*

Main category: cs.IT

TL;DR: 本文研究连续时间马尔可夫链远程估计系统中的信息新鲜度，提出结构化估计器作为从鞅估计器到MAP估计器的桥梁，并推导了最优查询策略。


<details>
  <summary>Details</summary>
Motivation: 现有远程估计系统主要使用鞅估计器，虽然简单易分析但远非最优，尤其是在查询式更新系统中。MAP估计器虽最优但连续时间下分析困难，需要一种既能保留MAP优点又便于分析的新估计器。

Method: 提出结构化估计器，特别是p-MAP估计器，作为具有有限间断点的分段常数近似。使用二元新鲜度过程表征信息新鲜度，推导新鲜度表达式，并为单源和多源系统提供最优状态依赖采样策略和查询率分配策略。

Result: 对于时间可逆CTMC，MAP估计器可简化为p-MAP估计器。推导了结构化估计器下的新鲜度表达式，并给出了最大化平均二元新鲜度的最优查询策略，以及多源系统约束下的最优查询率分配方案。

Conclusion: 结构化估计器填补了鞅估计器和MAP估计器之间的空白，既保留了MAP估计器的有用特性，又保持了分析可处理性，为连续时间马尔可夫链远程估计系统的信息新鲜度分析提供了有效框架。

Abstract: This paper investigates information freshness in a remote estimation system in which the remote information source is a continuous-time Markov chain (CTMC). For such systems, estimators have been mainly restricted to the class of martingale estimators in which the remote estimate at any time is equal to the value of the most recently received update. This is mainly due to the simplicity and ease of analysis of martingale estimators, which however are far from optimal, especially in query-based (i.e., pull-based) update systems. In such systems, maximum a-posteriori probability (MAP) estimators are optimal. However, MAP estimators can be challenging to analyze in continuous-time settings. In this paper, we introduce a new class of estimators, called structured estimators, which can seamlessly shift from a martingale estimator to a MAP estimator, enabling them to retain useful characteristics of the MAP estimate, while still being analytically tractable. Particularly, we introduce a new estimator termed as the $p$-MAP estimator which is a piecewise-constant approximation of the MAP estimator with finitely many discontinuities, bringing us closer to a full characterization of MAP estimators when modeling information freshness. In fact, we show that for time-reversible CTMCs, the MAP estimator reduces to a $p$-MAP estimator. Using the binary freshness (BF) process for the characterization of information freshness, we derive the freshness expressions and provide optimal state-dependent sampling policies (i.e., querying policies) for maximizing the mean BF (MBF) for pull-based remote estimation of a single CTMC information source, when structured estimators are used. Moreover, we provide optimal query rate allocation policies when a monitor pulls information from multiple heterogeneous CTMCs with a constraint on the overall query rate.

</details>
