<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 12]
- [eess.SP](#eess.SP) [Total: 12]
- [cs.IT](#cs.IT) [Total: 6]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Generative Artificial Intelligence in Medical Imaging: Foundations, Progress, and Clinical Translation](https://arxiv.org/abs/2508.09177)
*Xuanru Zhou,Cheng Li,Shuqiang Wang,Ye Li,Tao Tan,Hairong Zheng,Shanshan Wang*

Main category: eess.IV

TL;DR: 生成式AI在医学影像中的广泛应用，包括数据合成、图像增强等，并探讨了其临床工作流中的贡献与挑战。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中的数据稀缺、标准化和多模态整合等长期挑战。

Method: 综述了GANs、VAEs、扩散模型等生成模型，并提出三层次评估框架。

Result: 生成式AI在临床影像中展现出潜力，但仍需解决泛化性、隐私等问题。

Conclusion: 生成式AI与基础模型的结合有望推动下一代临床影像系统的发展。

Abstract: Generative artificial intelligence (AI) is rapidly transforming medical
imaging by enabling capabilities such as data synthesis, image enhancement,
modality translation, and spatiotemporal modeling. This review presents a
comprehensive and forward-looking synthesis of recent advances in generative
modeling including generative adversarial networks (GANs), variational
autoencoders (VAEs), diffusion models, and emerging multimodal foundation
architectures and evaluates their expanding roles across the clinical imaging
continuum. We systematically examine how generative AI contributes to key
stages of the imaging workflow, from acquisition and reconstruction to
cross-modality synthesis, diagnostic support, and treatment planning. Emphasis
is placed on both retrospective and prospective clinical scenarios, where
generative models help address longstanding challenges such as data scarcity,
standardization, and integration across modalities. To promote rigorous
benchmarking and translational readiness, we propose a three-tiered evaluation
framework encompassing pixel-level fidelity, feature-level realism, and
task-level clinical relevance. We also identify critical obstacles to
real-world deployment, including generalization under domain shift,
hallucination risk, data privacy concerns, and regulatory hurdles. Finally, we
explore the convergence of generative AI with large-scale foundation models,
highlighting how this synergy may enable the next generation of scalable,
reliable, and clinically integrated imaging systems. By charting technical
progress and translational pathways, this review aims to guide future research
and foster interdisciplinary collaboration at the intersection of AI, medicine,
and biomedical engineering.

</details>


### [2] [HiFi-Mamba: Dual-Stream W-Laplacian Enhanced Mamba for High-Fidelity MRI Reconstruction](https://arxiv.org/abs/2508.09179)
*Hongli Chen,Pengcheng Fang,Yuxia Chen,Yingxuan Ren,Jing Hao,Fangfang Tang,Xiaohao Cai,Shanshan Shan,Feng Liu*

Main category: eess.IV

TL;DR: HiFi-Mamba是一种新型双流Mamba架构，用于从欠采样的k空间数据重建高保真MR图像，解决了传统方法对高频细节不敏感和扫描冗余的问题。


<details>
  <summary>Details</summary>
Motivation: 传统Mamba变体在MRI重建中存在对高频解剖细节不敏感和依赖冗余多方向扫描的局限性。

Method: 提出HiFi-Mamba架构，包含WL块和HiFi-Mamba块，分别处理低频和高频特征，并通过单向遍历策略提高效率。

Result: 在标准MRI重建基准测试中，HiFi-Mamba在重建精度上优于现有CNN、Transformer和其他Mamba模型。

Conclusion: HiFi-Mamba在保持高效设计的同时，显著提升了MRI重建的准确性和频谱细节保留能力。

Abstract: Reconstructing high-fidelity MR images from undersampled k-space data remains
a challenging problem in MRI. While Mamba variants for vision tasks offer
promising long-range modeling capabilities with linear-time complexity, their
direct application to MRI reconstruction inherits two key limitations: (1)
insensitivity to high-frequency anatomical details; and (2) reliance on
redundant multi-directional scanning. To address these limitations, we
introduce High-Fidelity Mamba (HiFi-Mamba), a novel dual-stream Mamba-based
architecture comprising stacked W-Laplacian (WL) and HiFi-Mamba blocks.
Specifically, the WL block performs fidelity-preserving spectral decoupling,
producing complementary low- and high-frequency streams. This separation
enables the HiFi-Mamba block to focus on low-frequency structures, enhancing
global feature modeling. Concurrently, the HiFi-Mamba block selectively
integrates high-frequency features through adaptive state-space modulation,
preserving comprehensive spectral details. To eliminate the scanning
redundancy, the HiFi-Mamba block adopts a streamlined unidirectional traversal
strategy that preserves long-range modeling capability with improved
computational efficiency. Extensive experiments on standard MRI reconstruction
benchmarks demonstrate that HiFi-Mamba consistently outperforms
state-of-the-art CNN-based, Transformer-based, and other Mamba-based models in
reconstruction accuracy while maintaining a compact and efficient model design.

</details>


### [3] [MedPatch: Confidence-Guided Multi-Stage Fusion for Multimodal Clinical Data](https://arxiv.org/abs/2508.09182)
*Baraa Al Jorf,Farah Shamout*

Main category: eess.IV

TL;DR: MedPatch是一种多阶段多模态融合架构，通过置信度引导的分块方法整合临床数据，解决了医疗数据的异质性和稀疏性问题，并在临床预测任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医疗数据具有异质性、规模有限和模态缺失的特点，限制了临床预测任务的模型性能。受临床工作流程启发，提出了MedPatch以解决这些问题。

Method: MedPatch包含多阶段融合策略、缺失感知模块和联合融合模块，通过置信度引导的分块整合多模态数据。

Result: 在MIMIC数据集上的实验表明，MedPatch在院内死亡率预测和临床条件分类任务中优于现有基线。

Conclusion: MedPatch通过置信度引导的多阶段融合有效处理多模态数据的异质性，为临床预测任务设定了新的基准。

Abstract: Clinical decision-making relies on the integration of information across
various data modalities, such as clinical time-series, medical images and
textual reports. Compared to other domains, real-world medical data is
heterogeneous in nature, limited in size, and sparse due to missing modalities.
This significantly limits model performance in clinical prediction tasks.
Inspired by clinical workflows, we introduce MedPatch, a multi-stage multimodal
fusion architecture, which seamlessly integrates multiple modalities via
confidence-guided patching. MedPatch comprises three main components: (i) a
multi-stage fusion strategy that leverages joint and late fusion
simultaneously, (ii) a missingness-aware module that handles sparse samples
with missing modalities, (iii) a joint fusion module that clusters latent token
patches based on calibrated unimodal token-level confidence. We evaluated
MedPatch using real-world data consisting of clinical time-series data, chest
X-ray images, radiology reports, and discharge notes extracted from the
MIMIC-IV, MIMIC-CXR, and MIMIC-Notes datasets on two benchmark tasks, namely
in-hospital mortality prediction and clinical condition classification.
Compared to existing baselines, MedPatch achieves state-of-the-art performance.
Our work highlights the effectiveness of confidence-guided multi-stage fusion
in addressing the heterogeneity of multimodal data, and establishes new
state-of-the-art benchmark results for clinical prediction tasks.

</details>


### [4] [Hybrid(Transformer+CNN)-based Polyp Segmentation](https://arxiv.org/abs/2508.09189)
*Madan Baduwal*

Main category: eess.IV

TL;DR: 提出了一种结合Transformer和CNN的混合模型，用于提高结肠息肉分割的鲁棒性，解决了边界模糊和内窥镜伪影的挑战。


<details>
  <summary>Details</summary>
Motivation: 结肠息肉分割因息肉大小、形状、内窥镜类型、光照和边界模糊等因素极具挑战性，现有方法难以应对。

Method: 采用Transformer与CNN结合的混合架构，通过边界感知注意力机制和鲁棒特征提取提升性能。

Result: 在分割准确率（召回率提升1.76%，准确率提升0.07%）和伪影鲁棒性上优于现有方法。

Conclusion: 混合模型显著提升了息肉分割的准确性和鲁棒性，尤其在处理模糊边界和内窥镜伪影时表现突出。

Abstract: Colonoscopy is still the main method of detection and segmentation of colonic
polyps, and recent advancements in deep learning networks such as U-Net,
ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp
segmentation. Yet, the problem is extremely challenging due to high variation
in size, shape, endoscopy types, lighting, imaging protocols, and ill-defined
boundaries (fluid, folds) of the polyps, rendering accurate segmentation a
challenging and problematic task. To address these critical challenges in polyp
segmentation, we introduce a hybrid (Transformer + CNN) model that is crafted
to enhance robustness against evolving polyp characteristics. Our hybrid
architecture demonstrates superior performance over existing solutions,
particularly in addressing two critical challenges: (1) accurate segmentation
of polyps with ill-defined margins through boundary-aware attention mechanisms,
and (2) robust feature extraction in the presence of common endoscopic
artifacts, including specular highlights, motion blur, and fluid occlusions.
Quantitative evaluations reveal significant improvements in segmentation
accuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%,
i.e., 0.9849) and artifact resilience compared to state-of-the-art polyp
segmentation methods.

</details>


### [5] [impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction](https://arxiv.org/abs/2508.09195)
*Maria Boyko,Aleksandra Beliaeva,Dmitriy Kornilov,Alexander Bernstein,Maxim Sharaev*

Main category: eess.IV

TL;DR: impuTMAE是一种基于Transformer的多模态预训练方法，通过重建掩码补丁学习模态间和模态内交互，同时填补缺失模态，在胶质瘤生存预测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多模态数据（如组学、医学影像和临床数据）可提升预后模型性能并深化疾病机制理解，但数据复杂且常缺失，需有效处理方法。

Method: 提出impuTMAE，一种端到端的Transformer方法，通过预训练学习多模态交互并填补缺失数据，再微调用于胶质瘤生存预测。

Result: 在TCGA-GBM/LGG和BraTS数据集上，impuTMAE超越现有方法，达到胶质瘤生存预测的最优性能。

Conclusion: impuTMAE通过处理缺失数据和高效资源利用，在多模态学习中表现卓越，为疾病预测提供新思路。

Abstract: The use of diverse modalities, such as omics, medical images, and clinical
data can not only improve the performance of prognostic models but also deepen
an understanding of disease mechanisms and facilitate the development of novel
treatment approaches. However, medical data are complex, often incomplete, and
contains missing modalities, making effective handling its crucial for training
multimodal models. We introduce impuTMAE, a novel transformer-based end-to-end
approach with an efficient multimodal pre-training strategy. It learns inter-
and intra-modal interactions while simultaneously imputing missing modalities
by reconstructing masked patches. Our model is pre-trained on heterogeneous,
incomplete data and fine-tuned for glioma survival prediction using
TCGA-GBM/LGG and BraTS datasets, integrating five modalities: genetic (DNAm,
RNA-seq), imaging (MRI, WSI), and clinical data. By addressing missing data
during pre-training and enabling efficient resource utilization, impuTMAE
surpasses prior multimodal approaches, achieving state-of-the-art performance
in glioma patient survival prediction. Our code is available at
https://github.com/maryjis/mtcp

</details>


### [6] [FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation](https://arxiv.org/abs/2508.09196)
*Asim Ukaye,Numan Saeed,Karthik Nandakumar*

Main category: eess.IV

TL;DR: 提出了一种新的联邦学习方法，利用模型不确定性和预测不确定性，实现跨不同腹部CT数据集的通用分割。


<details>
  <summary>Details</summary>
Motivation: 解决不同CT数据集因扫描器和设置差异导致的异质性问题，同时保护患者隐私。

Method: 利用随机小批量梯度下降的噪声估计模型权重分布，通过贝叶斯逆方差聚合方案在服务器端聚合参数，并量化预测不确定性。

Result: 实验表明，该方法在联邦聚合质量和不确定性加权推理方面优于现有基线。

Conclusion: 该方法有效提升了跨数据集分割的性能和临床决策的可靠性。

Abstract: Different CT segmentation datasets are typically obtained from different
scanners under different capture settings and often provide segmentation labels
for a limited and often disjoint set of organs. Using these heterogeneous data
effectively while preserving patient privacy can be challenging. This work
presents a novel federated learning approach to achieve universal segmentation
across diverse abdominal CT datasets by utilizing model uncertainty for
aggregation and predictive uncertainty for inference. Our approach leverages
the inherent noise in stochastic mini-batch gradient descent to estimate a
distribution over the model weights to provide an on-the-go uncertainty over
the model parameters at the client level. The parameters are then aggregated at
the server using the additional uncertainty information using a
Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the
proposed method quantifies prediction uncertainty by propagating the
uncertainty from the model weights, providing confidence measures essential for
clinical decision-making. In line with recent work shown, predictive
uncertainty is utilized in the inference stage to improve predictive
performance. Experimental evaluations demonstrate the effectiveness of this
approach in improving both the quality of federated aggregation and
uncertainty-weighted inference compared to previously established baselines.
The code for this work is made available at: https://github.com/asimukaye/fiva

</details>


### [7] [Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction](https://arxiv.org/abs/2508.09200)
*Jinho Kim,Marcel Dominik Nickel,Florian Knoll*

Main category: eess.IV

TL;DR: 研究探讨了零样本自监督学习重建在减少磁共振胰胆管造影（MRCP）屏气时间中的可行性，结果显示其优于压缩感知重建，且浅层训练大幅缩短训练时间。


<details>
  <summary>Details</summary>
Motivation: 减少MRCP检查中的屏气时间，提高临床效率。

Method: 使用零样本重建技术，对比并行成像和压缩感知重建，并采用浅层训练减少计算时间。

Result: 零样本重建显著提升图像质量，浅层训练将训练时间从271分钟缩短至11分钟。

Conclusion: 零样本学习能高效减少屏气时间，浅层训练适合临床工作流程。

Abstract: Purpose: To investigate the feasibility of applying zero-shot self-supervised
learning reconstruction to reduce breath-hold times in magnetic resonance
cholangiopancreatography (MRCP). Methods: Breath-hold MRCP was acquired from 11
healthy volunteers on a 3T scanner using an incoherent k-space sampling pattern
leading to a breath-hold duration of 14s. We evaluated zero-shot reconstruction
of breath-hold MRCP against parallel imaging of respiratory-triggered MRCP
acquired in 338s on average and compressed sensing reconstruction of
breath-hold MRCP. To address the long computation times of zero-shot trainings,
we used a training approach that leverages a pretrained network to reduce
backpropagation depth during training. Results: Zero-shot learning
reconstruction significantly improved visual image quality compared to
compressed sensing reconstruction, particularly in terms of signal-to-noise
ratio and ductal delineation, and reached a level of quality comparable to that
of successful respiratory-triggered acquisitions with regular breathing
patterns. Shallow training provided nearly equivalent reconstruction
performance with a training time of 11 minutes in comparison to 271 minutes for
a conventional zero-shot training. Conclusion: Zero-shot learning delivers
high-fidelity MRCP reconstructions with reduced breath-hold times, and shallow
training offers a practical solution for translation to time-constrained
clinical workflows.

</details>


### [8] [From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations](https://arxiv.org/abs/2508.09205)
*Yoni Schirris,Eric Marcus,Jonas Teuwen,Hugo Horlings,Efstratios Gavves*

Main category: eess.IV

TL;DR: 提出了一种人机-VLM交互系统，用于解释计算病理学中的分类器，结合AI集成的幻灯片查看器和通用视觉语言模型，验证解释的预测性。


<details>
  <summary>Details</summary>
Motivation: 解释深度学习模型对医学图像分析系统的临床整合至关重要，以识别模型是否依赖虚假特征或揭示新生物学见解。

Method: 开发了AI集成的幻灯片查看器进行滑动窗口实验，并使用通用视觉语言模型量化解释的预测性。

Result: 系统能定性测试解释的合理性，并量化区分竞争性解释。

Conclusion: 为从可解释AI到解释AI的实践路径提供了可行方案。

Abstract: Explaining deep learning models is essential for clinical integration of
medical image analysis systems. A good explanation highlights if a model
depends on spurious features that undermines generalization and harms a subset
of patients or, conversely, may present novel biological insights. Although
techniques like GradCAM can identify influential features, they are measurement
tools that do not themselves form an explanation. We propose a
human-machine-VLM interaction system tailored to explaining classifiers in
computational pathology, including multi-instance learning for whole-slide
images. Our proof of concept comprises (1) an AI-integrated slide viewer to run
sliding-window experiments to test claims of an explanation, and (2)
quantification of an explanation's predictiveness using general-purpose
vision-language models. The results demonstrate that this allows us to
qualitatively test claims of explanations and can quantifiably distinguish
competing explanations. This offers a practical path from explainable AI to
explained AI in digital pathology and beyond. Code and prompts are available at
https://github.com/nki-ai/x2x.

</details>


### [9] [AMRG: Extend Vision Language Models for Automatic Mammography Report Generation](https://arxiv.org/abs/2508.09225)
*Nak-Jun Sung,Donghyun Lee,Bo Hwa Choi,Chae Jung Park*

Main category: eess.IV

TL;DR: AMRG是首个用于生成乳腺X光报告的全端到端框架，基于大型视觉语言模型（VLM），通过LoRA实现高效微调，在多个指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 乳腺X光报告生成在医疗AI中是一个重要但未充分探索的任务，面临多视图图像推理、高分辨率视觉线索和非结构化放射学语言等挑战。

Method: 基于MedGemma-4B-it模型，采用LoRA进行参数高效微调，训练和评估使用公开数据集DMID。

Result: 在语言生成和临床指标上表现优异，ROUGE-L为0.5691，METEOR为0.6152，CIDEr为0.5818，BI-RADS准确率为0.5582。

Conclusion: AMRG为放射学报告生成提供了可扩展和适应性强的框架，为多模态医疗AI的未来研究铺平了道路。

Abstract: Mammography report generation is a critical yet underexplored task in medical
AI, characterized by challenges such as multiview image reasoning,
high-resolution visual cues, and unstructured radiologic language. In this
work, we introduce AMRG (Automatic Mammography Report Generation), the first
end-to-end framework for generating narrative mammography reports using large
vision-language models (VLMs). Building upon MedGemma-4B-it-a
domain-specialized, instruction-tuned VLM-we employ a parameter-efficient
fine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling
lightweight adaptation with minimal computational overhead. We train and
evaluate AMRG on DMID, a publicly available dataset of paired high-resolution
mammograms and diagnostic reports. This work establishes the first reproducible
benchmark for mammography report generation, addressing a longstanding gap in
multimodal clinical AI. We systematically explore LoRA hyperparameter
configurations and conduct comparative experiments across multiple VLM
backbones, including both domain-specific and general-purpose models under a
unified tuning protocol. Our framework demonstrates strong performance across
both language generation and clinical metrics, achieving a ROUGE-L score of
0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582.
Qualitative analysis further highlights improved diagnostic consistency and
reduced hallucinations. AMRG offers a scalable and adaptable foundation for
radiology report generation and paves the way for future research in multimodal
medical AI.

</details>


### [10] [A Generative Imputation Method for Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.09271)
*Reihaneh Hassanzadeh,Anees Abrol,Hamid Reza Hassanzadeh,Vince D. Calhoun*

Main category: eess.IV

TL;DR: 提出了一种生成对抗网络方法，用于从现有模态中重建缺失的神经影像数据，提高了阿尔茨海默病分类准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态数据分析能提高脑部疾病诊断准确性，但数据缺失是主要挑战，传统方法可能降低准确性或引入偏差。

Method: 使用生成对抗网络从T1加权结构MRI和功能网络连接中重建缺失模态。

Result: 与传统方法相比，生成填补方法将阿尔茨海默病与认知正常组的分类准确性提高了9%。

Conclusion: 生成对抗网络是一种有效的多模态数据填补方法，能保留疾病模式并提高诊断准确性。

Abstract: Multimodal data analysis can lead to more accurate diagnoses of brain
disorders due to the complementary information that each modality adds.
However, a major challenge of using multimodal datasets in the neuroimaging
field is incomplete data, where some of the modalities are missing for certain
subjects. Hence, effective strategies are needed for completing the data.
Traditional methods, such as subsampling or zero-filling, may reduce the
accuracy of predictions or introduce unintended biases. In contrast, advanced
methods such as generative models have emerged as promising solutions without
these limitations. In this study, we proposed a generative adversarial network
method designed to reconstruct missing modalities from existing ones while
preserving the disease patterns. We used T1-weighted structural magnetic
resonance imaging and functional network connectivity as two modalities. Our
findings showed a 9% improvement in the classification accuracy for Alzheimer's
disease versus cognitive normal groups when using our generative imputation
method compared to the traditional approaches.

</details>


### [11] [Dynamic Survival Prediction using Longitudinal Images based on Transformer](https://arxiv.org/abs/2508.09328)
*Bingfan Liu,Haolun Shi,Jiguo Cao*

Main category: eess.IV

TL;DR: SurLonFormer是一种基于Transformer的神经网络，用于整合纵向医学影像和结构化数据以预测生存率，解决了现有方法在利用截尾数据、时间相关性及可解释性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用截尾数据、处理纵向影像的时间相关性及可解释性方面存在不足，限制了生存分析的准确性和实用性。

Method: 提出SurLonFormer，包含视觉编码器（提取空间特征）、序列编码器（聚合时间信息）和基于Cox模型的生存编码器，结合截尾数据并提升可解释性。

Result: 在模拟和阿尔茨海默病实际应用中，SurLonFormer表现出优越的预测性能，并成功识别疾病相关影像生物标志物。

Conclusion: SurLonFormer为生存分析提供了更高效、可解释的解决方案，尤其在纵向医学影像应用中具有显著优势。

Abstract: Survival analysis utilizing multiple longitudinal medical images plays a
pivotal role in the early detection and prognosis of diseases by providing
insight beyond single-image evaluations. However, current methodologies often
inadequately utilize censored data, overlook correlations among longitudinal
images measured over multiple time points, and lack interpretability. We
introduce SurLonFormer, a novel Transformer-based neural network that
integrates longitudinal medical imaging with structured data for survival
prediction. Our architecture comprises three key components: a Vision Encoder
for extracting spatial features, a Sequence Encoder for aggregating temporal
information, and a Survival Encoder based on the Cox proportional hazards
model. This framework effectively incorporates censored data, addresses
scalability issues, and enhances interpretability through occlusion sensitivity
analysis and dynamic survival prediction. Extensive simulations and a
real-world application in Alzheimer's disease analysis demonstrate that
SurLonFormer achieves superior predictive performance and successfully
identifies disease-related imaging biomarkers.

</details>


### [12] [T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis](https://arxiv.org/abs/2508.09919)
*Xiaojiao Xiao,Jianfeng Zhao,Qinmin Vivian Hu,Guanghui Wang*

Main category: eess.IV

TL;DR: T-CACE框架通过合成多期相增强MRI，解决了传统MRI的对比剂风险、耗时评估和标注数据不足问题，提升了肝脏病变的诊断效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统MRI在肝脏癌症诊断中存在对比剂风险、手动评估耗时和标注数据有限的问题，需要一种更安全高效的替代方法。

Method: 提出T-CACE框架，包括条件令牌编码（CTE）、动态时间感知注意力掩码（DTAM）和时间分类一致性约束（TCC），用于从非对比MRI合成多期相增强MRI。

Result: 在两个独立肝脏MRI数据集上的实验表明，T-CACE在图像合成、分割和病变分类方面优于现有方法。

Conclusion: T-CACE为传统增强成像提供了一种临床相关且高效的替代方案，提升了肝脏病变评估的安全性、效率和可靠性。

Abstract: Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of
liver cancer, significantly improving the classification of the lesion and
patient outcomes. However, traditional MRI faces challenges including risks
from contrast agent (CA) administration, time-consuming manual assessment, and
limited annotated datasets. To address these limitations, we propose a
Time-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for
synthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from
non-contrast MRI (NCMRI). T-CACE introduces three core innovations: a
conditional token encoding (CTE) mechanism that unifies anatomical priors and
temporal phase information into latent representations; and a dynamic
time-aware attention mask (DTAM) that adaptively modulates inter-phase
information flow using a Gaussian-decayed attention mechanism, ensuring smooth
and physiologically plausible transitions across phases. Furthermore, a
constraint for temporal classification consistency (TCC) aligns the lesion
classification output with the evolution of the physiological signal, further
enhancing diagnostic reliability. Extensive experiments on two independent
liver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods
in image synthesis, segmentation, and lesion classification. This framework
offers a clinically relevant and efficient alternative to traditional
contrast-enhanced imaging, improving safety, diagnostic efficiency, and
reliability for the assessment of liver lesion. The implementation of T-CACE is
publicly available at: https://github.com/xiaojiao929/T-CACE.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [13] [RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet](https://arxiv.org/abs/2508.09140)
*Honggang Jia,Nan Cheng,Xiucheng Wang,Conghao Zhou,Ruijin Sun,Xuemin,Shen*

Main category: eess.SP

TL;DR: RadioMamba是一种混合Mamba-UNet架构，用于解决无线电地图构建中的精度与效率权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的无线电地图构建方法存在精度与效率的权衡问题，无法同时满足实时性和准确性需求。

Method: RadioMamba采用Mamba-卷积块，Mamba分支以线性复杂度捕获全局依赖，卷积分支提取局部特征，实现全局与局部特征的结合。

Result: 实验表明，RadioMamba在精度上优于现有方法（包括扩散模型），速度提升近20倍，参数仅占2.9%。

Conclusion: RadioMamba通过提升精度和效率，为下一代无线系统的实时智能优化提供了可行方案。

Abstract: Radio map (RM) has recently attracted much attention since it can provide
real-time and accurate spatial channel information for 6G services and
applications. However, current deep learning-based methods for RM construction
exhibit well known accuracy-efficiency trade-off. In this paper, we introduce
RadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the
trade-off. Generally, accurate RM construction requires modeling long-range
spatial dependencies, reflecting the global nature of wave propagation physics.
RadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures
these global dependencies with linear complexity, while a parallel
convolutional branch extracts local features. This hybrid design generates
feature representations that capture both global context and local detail.
Experiments show that RadioMamba achieves higher accuracy than existing
methods, including diffusion models, while operating nearly 20 times faster and
using only 2.9\% of the model parameters. By improving both accuracy and
efficiency, RadioMamba presents a viable approach for real-time intelligent
optimization in next generation wireless systems.

</details>


### [14] [Bayesian-Driven Graph Reasoning for Active Radio Map Construction](https://arxiv.org/abs/2508.09142)
*Wenlihan Lu,Shijian Gao,Miaowen Wen,Yuxuan Liang,Chan-Byoung Chae,H. Vincent Poor*

Main category: eess.SP

TL;DR: 提出了一种基于不确定性感知的无线电地图重建框架（URAM），结合贝叶斯神经网络和注意力强化学习，优化无人机导航的覆盖范围和效率。


<details>
  <summary>Details</summary>
Motivation: 低空经济中，无线电地图对无人机无线连接至关重要，但电池容量限制了数据收集的覆盖和效率。

Method: 结合贝叶斯神经网络实时估计空间不确定性，以及注意力强化学习策略进行全局路径规划。

Result: URAM比现有基线重建精度提高34%。

Conclusion: URAM通过智能非短视路径规划，显著提升了无人机数据收集的效率和准确性。

Abstract: With the emergence of the low-altitude economy, radio maps have become
essential for ensuring reliable wireless connectivity to aerial platforms.
Autonomous aerial agents are commonly deployed for data collection using
waypoint-based navigation; however, their limited battery capacity
significantly constrains coverage and efficiency. To address this, we propose
an uncertainty-aware radio map (URAM) reconstruction framework that explicitly
leverages graph-based reasoning tailored for waypoint navigation. Our approach
integrates two key deep learning components: (1) a Bayesian neural network that
estimates spatial uncertainty in real time, and (2) an attention-based
reinforcement learning policy that performs global reasoning over a
probabilistic roadmap, using uncertainty estimates to plan informative and
energy-efficient trajectories. This graph-based reasoning enables intelligent,
non-myopic trajectory planning, guiding agents toward the most informative
regions while satisfying safety constraints. Experimental results show that
URAM improves reconstruction accuracy by up to 34% over existing baselines.

</details>


### [15] [Generative AI-Enabled Robust 6G Uplink: Principles, Challenges, and Directions](https://arxiv.org/abs/2508.09348)
*Chunmei Xu,Yi Ma,Rahim Tafazolli,Peiying Zhu*

Main category: eess.SP

TL;DR: GenCom是一种利用生成式AI解决6G上行链路瓶颈的新系统范式，通过简化发射端设计并利用接收端的强大AI模型重构内容，提升语义保真度。


<details>
  <summary>Details</summary>
Motivation: 6G网络上行链路面临设备资源限制和信道条件挑战，需要创新解决方案。

Method: GenCom采用生成式AI模型在接收端重构信号，发射端简化编码设计，支持语义保留压缩和弱错误分布编码。

Result: GenCom在低信噪比条件下表现优于传统系统。

Conclusion: GenCom为未来无线网络提供了一种可行方案，但仍需解决实际应用中的挑战。

Abstract: Next-generation wireless networks (6G) face a critical uplink bottleneck due
to stringent device-side resource constraints and challenging channel
conditions. This article introduces GenCom, a novel system-level paradigm for
robust 6G uplink that leverages Generative AI and exploits the inherent
resource imbalance between transmitters and receivers. In GenCom, resource-rich
receivers deploy powerful offline-trained GenAI models to reconstruct high
semantic-fidelity content from degraded signals, while resource-constrained
transmitters are simplified in both source and channel coding design. We
present the core mechanisms and key design principles behind GenCom, which
shifts from conventional approaches toward simple semantic-preserving
compression, weak error-distribution codes, and semantic-aware retransmissions.
Through a case study, GenCom is shown to deliver robust performance across a
wide range of low and uncertain SNR/SINR conditions where conventional systems
fail. Finally, we outline critical challenges and research directions toward
making GenCom a practical enabler of future human-centric, intelligent, and
sustainable wireless networks.

</details>


### [16] [Satellites are closer than you think: A near field MIMO approach for Ground stations](https://arxiv.org/abs/2508.09374)
*Rohith Reddy Vennam,Luke Wilson,Ish Kumar Jain,Dinesh Bharadia*

Main category: eess.SP

TL;DR: ArrayLink是一种分布式相控阵架构，通过组合多个小型商用面板实现高增益波束成形，提升LEO卫星回传容量。


<details>
  <summary>Details</summary>
Motivation: 地面站基础设施扩展滞后于LEO卫星星座增长，传统抛物面天线不适合快速移动的LEO网络，相控阵天线成本高且复杂。

Method: 采用分布式相控阵架构（ArrayLink），通过16个（32x32）面板在千米级孔径上实现高增益波束成形和空间复用。

Result: ArrayLink在1-2 dB范围内达到1.47米反射器的增益，支持最多4个并行空间流，实验与理论高度一致。

Conclusion: ArrayLink为提升LEO回传容量提供了实用且可扩展的解决方案。

Abstract: The rapid growth of low Earth orbit (LEO) satellite constellations has
revolutionized broadband access, earth observation, and direct-to-device
connectivity. However, the expansion of ground station infrastructure has not
kept pace, creating a critical bottleneck in satellite-to-ground backhaul
capacity. Traditional parabolic dish antennas, though effective for
geostationary (GEO) satellites, are ill-suited for dense, fastmoving LEO
networks due to mechanical steering delays and their inability to track
multiple satellites simultaneously. Phased array antennas offer electronically
steerable beams and multisatellite support, but their integration into ground
stations is limited by the high cost, hardware issues, and complexity of
achieving sufficient antenna gain. We introduce ArrayLink, a distributed phased
array architecture that coherently combines multiple small commercially
available panels to achieve high-gain beamforming and unlock line-of-sight MIMO
spatial multiplexing with minimal additional capital expenditure. By spacing 16
(32x32) panels across a kilometer-scale aperture, ArrayLink enters the
radiative near-field, focusing energy in both angle and range while supporting
up to four simultaneous spatial streams on a single feeder link. Through
rigorous theoretical analysis, detailed 2D beam pattern simulations and
real-world hardware experiments, we show that ArrayLink (i) achieves dish-class
gain with in range 1-2 dB of 1.47 m reflector, (ii) maintains four parallel
streams at ranges of hundreds of kilometers (falling to two beyond 2000 km),
and (iii) exhibits tight agreement across theory, simulation, and experiment
with minimal variance. These findings open a practical and scalable path to
boosting LEO backhaul capacity.

</details>


### [17] [Sub-THz Power Amplifiers: Measurements, Behavioral Modeling and Predistortion Algorithms](https://arxiv.org/abs/2508.09545)
*Lutfi Samara,Simon Haussmann,Erind Tufa,Antonio Alberto D'Amico,Tommaso Zugno,Ingmar Kallfass,Thomas Kürner*

Main category: eess.SP

TL;DR: 论文研究了太赫兹（THz）频谱中功率放大器（PA）的非线性问题，提出了表征模型和预失真算法以改善性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球IMT流量预计增长10-100倍，太赫兹频谱成为解决方案，但宽带射频组件的非线性问题（如PA）影响了系统性能。

Method: 通过小信号和大信号连续波测量表征300 GHz PA，建立AM-AM和AM-PM模型，并设计预失真算法。

Result: 模型验证了压缩行为，但低输入功率下存在不准确性；预失真算法在多载波波形中性能下降，但参数优化可显著改善。

Conclusion: 适当的预失真参数选择能显著提升太赫兹通信系统的性能。

Abstract: With global IMT traffic expected to grow 10-100 times from 2020 to 20301, the
Terahertz (THz) spectrum offers a promising solution to satisfy such forecasts.
However, occupying the THz spectrum comes with its own challenges, an important
one being impairments caused by broadband RF components in THz transceivers.
Nonlinearities in power amplifiers (PAs) complicate meeting link budget
requirements, with amplitude and phase distortions degrading the system's
performance, especially when adopting waveforms with high peak-to-average power
ratios (PAPRs), such as Orthogonal Frequency Division Multiplexing (OFDM). In
this paper, we present characterization results of a 300 GHz PA using
small-signal and large-signal continuous-wave measurements. Models capturing
Amplitude-to- Amplitude Modulation (AM-AM) and Amplitude-to-Phase Modulation
(AMPM) behavior across 270-330 GHz are developed and verified with wideband
measurements, confirming the compression behavior, while nonetheless showing
inaccuracies for low input powers due to unaccounted frequency dependencies.
Based on the derived models, a predistortion algorithm is designed and
analyzed, revealing significant error performance degradation when switching
between single- and multi-carrier waveforms. We finally show that an
appropriate selection of pre-distorter parameters can significantly improve the
performance.

</details>


### [18] [Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm](https://arxiv.org/abs/2508.09546)
*Dumitra Iancu,Liang Liu,Ove Edfors,Erik Leitinger,Xuhong Li*

Main category: eess.SP

TL;DR: 提出了一种适用于分布式MIMO系统的可扩展消息传递定位方法，支持低延迟和动态场景下的多路径测量。


<details>
  <summary>Details</summary>
Motivation: 未来无线系统需要支持分布式架构、可扩展性和低延迟的定位解决方案。

Method: 设计了一种基于消息传递的定位方法，联合检测多路径测量中的视距路径，并实现低延迟定位。

Result: 该方法在分布式阵列元素足够宽的情况下，定位性能与多路径定位方法相当，同时具有更低的延迟和计算复杂度。

Conclusion: 该方法为分布式MIMO系统提供了一种高效、低延迟的定位解决方案。

Abstract: Distributed MIMO and integrated sensing and communication are expected to be
key technologies in future wireless systems, enabling reliable, low-latency
communication and accurate localization. Dedicated localization solutions must
support distributed architecture, provide scalability across different system
configurations and meet strict latency requirements. We present a scalable
message-passing localization method and architecture co-designed for a
panel-based distributed MIMO system and network topology, in which
interconnected units operate without centralized processing. This method
jointly detects line-of-sight paths to distributed units from multipath
measurements in dynamic scenarios, localizes the agent, and achieves very low
latency. Additionally, we introduce a cycle-accurate system latency model based
on implemented FPGA operations, and show important insights into processing
latency and hardware utilization and system-level trade-offs. We compare our
method to a multipath-based localization method and show that it can achieve
similar localization performance, with wide enough distribution of array
elements, while offering lower latency and computational complexity.

</details>


### [19] [Profiling Multi-Level Operator Costs for Bottleneck Diagnosis in High-Speed Data Planes](https://arxiv.org/abs/2508.09574)
*Zhiyuan Ren,Yutao Liu,Wenchi Cheng,Kun Yang*

Main category: eess.SP

TL;DR: 提出了一种基于饱和吞吐量增量的方法，用于精确测量高速数据平面中的算子成本，无需侵入式检测。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以精确测量高速数据平面中的算子成本，且无法捕捉非线性扩展行为。

Method: 采用饱和吞吐量增量方法，引入算子性能象限（OPQ）框架，分类算子的基础和扩展成本。

Result: 发现计算密集型算子（如CRC）表现出超线性行为，而大多数其他算子为次线性。同时揭示了Arm和x86架构间的象限偏移现象。

Conclusion: 该方法为性能建模和优化提供了准确、架构感知的瓶颈诊断工具。

Abstract: This paper proposes a saturation throughput delta-based methodology to
precisely measure operator costs in high-speed data planes without intrusive
instrumentation. The approach captures non-linear scaling, revealing that
compute-intensive operators like CRC exhibit super-linear behavior, while most
others are sub-linear. We introduce the Operator Performance Quadrant (OPQ)
framework to classify operators by base and scaling costs, exposing a
cross-architecture Quadrant Shift between Arm and x86. This method provides
accurate, architecture-aware bottleneck diagnosis and a realistic basis for
performance modeling and optimization.

</details>


### [20] [3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator](https://arxiv.org/abs/2508.09708)
*Thomas Fehrenbach,Luis Omar Ortiz Abrego,Cornelius Hellge,Thomas Schierl,Jörg Ott*

Main category: eess.SP

TL;DR: 论文研究了V2X通信中的车队调度（Mode 2d）方案，通过分布式资源分配提升车队通信的可靠性、低延迟和数据速率。


<details>
  <summary>Details</summary>
Motivation: 车队技术能提升交通效率和环保性，但无线通信的高可靠性和低延迟需求是挑战。

Method: 采用分布式调度资源分配方案（Mode 2d），车队从配置的资源池中自主选择资源。

Result: 仿真结果表明该方案能满足车队通信的可靠性、低延迟和数据速率需求。

Conclusion: Mode 2d方案是解决车队通信挑战的有效方法。

Abstract: Vehicle-to-everything (V2X) communication is a key technology for enabling
intelligent transportation systems (ITS) that can improve road safety, traffic
efficiency, and environmental sustainability. Among the various V2X
applications, platooning is one of the most promising ones, as it allows a
group of vehicles to travel closely together at high speeds, reducing fuel
consumption and emissions. However, it poses significant challenges for
wireless communication, such as high reliability and low latency. In this
paper, we evaluate the benefits of group scheduling, also referred to as Mode
2d, which is based on a distributed and scheduled resource allocation scheme
that allows the group of cars to select resources from a configured pool
without network assistance. We evaluated the scheme through simulations, and
the results show that this approach can meet the reliability, low latency, and
data rate requirements for platooning.

</details>


### [21] [CKFNet: Neural Network Aided Cubature Kalman filtering](https://arxiv.org/abs/2508.09727)
*Jinhui Hu,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: CKFNet通过结合RNN与CKF框架，动态适应未建模的不确定性，提升了非线性估计的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决CKF因模型与环境不匹配导致的性能下降问题。

Method: 在CKF的预测阶段嵌入RNN模块，通过时间噪声相关性学习减少累积误差传播。

Result: CKFNet在数值模拟实验中表现出比传统模型方法和现有KalmanNet算法更高的准确性和鲁棒性。

Conclusion: CKFNet成功结合了模型驱动和数据驱动方法的优势，同时保持了CKF的可解释性。

Abstract: The cubature Kalman filter (CKF), while theoretically rigorous for nonlinear
estimation, often suffers performance degradation due to model-environment
mismatches in practice. To address this limitation, we propose CKFNet-a hybrid
architecture that synergistically integrates recurrent neural networks (RNN)
with the CKF framework while preserving its cubature principles. Unlike
conventional model-driven approaches, CKFNet embeds RNN modules in the
prediction phase to dynamically adapt to unmodeled uncertainties, effectively
reducing cumulative error propagation through temporal noise correlation
learning. Crucially, the architecture maintains CKF's analytical
interpretability via constrained optimization of cubature point distributions.
Numerical simulation experiments have confirmed that our proposed CKFNet
exhibits superior accuracy and robustness compared to conventional model-based
methods and existing KalmanNet algorithms.

</details>


### [22] [Online Data Generation for MIMO-OFDM Channel Denoising: Transfer Learning vs. Meta Learning](https://arxiv.org/abs/2508.09751)
*Sungyoung Ha,Ikbeom Lee,Seunghyeon Jeon,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 提出了一种标准兼容的策略，通过在线生成训练数据实现自适应信道去噪，利用数据辅助信道估计替代真实信道，并设计了基于迁移学习和元学习的两种去噪方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统信道去噪技术需要先验知识或高训练开销的问题，适应动态信道条件。

Method: 利用数据辅助信道估计生成高质量信道估计作为替代真实信道，推导最优邻域大小，设计基于迁移学习和元学习的去噪方法。

Result: 仿真结果表明，所提方法能有效适应动态信道条件，显著降低信道估计误差。

Conclusion: 提出的策略和方法在动态信道条件下表现优异，优于传统技术。

Abstract: Channel denoising is a practical and effective technique for mitigating
channel estimation errors in multiple-input multiple-output orthogonal
frequency-division multiplexing (MIMO-OFDM) systems. However, adapting
denoising techniques to varying channel conditions typically requires prior
knowledge or incurs significant training overhead. To address these challenges,
we propose a standard-compatible strategy for generating online training data
that enables online adaptive channel denoising. The key idea is to leverage
high-quality channel estimates obtained via data-aided channel estimation as
practical substitutes for unavailable ground-truth channels. Our data-aided
method exploits adjacent detected data symbols within a specific time-frequency
neighborhood as virtual reference signals, and we analytically derive the
optimal size of this neighborhood to minimize the mean squared error of the
resulting estimates. By leveraging the proposed strategy, we devise two channel
denoising approaches, one based on transfer learning, which fine-tunes a
pre-trained denoising neural network, and the other based on meta learning,
which rapidly adapts to new channel environments with minimal updates.
Simulation results demonstrate that the proposed methods effectively adapt to
dynamic channel conditions and significantly reduce channel estimation errors
compared to conventional techniques.

</details>


### [23] [Location Privacy-Enabled Beamforming in ISAC Scenarios](https://arxiv.org/abs/2508.09882)
*Umair Ali Khan,Lester Ho,Holger Claussen,Chinmoy Kundu*

Main category: eess.SP

TL;DR: 本文提出了一种基于方向到达混淆比（DAOR）的波束成形框架，用于保护ISAC场景中的发射机位置隐私，同时优化通信速率。


<details>
  <summary>Details</summary>
Motivation: ISAC技术在实现环境感知和数据传输的同时暴露用户位置，需要保护隐私。

Method: 通过广义特征值分析推导DAOR的闭式边界，并在DAOR约束下提出速率最大化问题，采用半定松弛、特征模式选择和最优功率分配求解。

Result: 提出的DAOR波束成形在隐私和通信速率间取得平衡，次优设计在10 dB SNR下计算时间减少85%。

Conclusion: DAOR框架有效保护隐私且不抑制LOS路径，次优设计接近最优性能。

Abstract: Integrated sensing and communication (ISAC) technology enables simultaneous
environmental perception and data transmission in wireless networks; however,
it also exposes user location to receivers. In this paper, we introduce a novel
beamforming framework guided by the proposed privacy metric direction of
arrival obfuscation ratio (DAOR) to protect transmitter location privacy in
ISAC scenarios. Unlike previous approaches, we do not suppress the
line-of-sight (LOS) component while reshaping the angular power distribution so
that a false direction appears dominant at the receiver. We derive closed-form
bounds on the feasible DAOR via generalized eigenvalue analysis and formulate
an achievable rate-maximization problem under the DAOR constraint. The
resulting problem is non-convex, which is efficiently solved using semidefinite
relaxation, eigenmode selection, and optimal power allocation. A suboptimal
design strategy is also proposed with reduced complexity. Numerical results
demonstrate that the proposed DAOR-based beamformer achieves a trade-off
between location privacy and communication rate without nullifying the LOS
path. Results also show that a suboptimal design achieves a near-optimal
communication rate with nearly an 85% reduction in computation time at a
signal-to-noise ratio (SNR) of 10 dB.

</details>


### [24] [Beam Cross Sections Create Mixtures: Improving Feature Localization in Secondary Electron Imaging](https://arxiv.org/abs/2508.09942)
*Vaibhav Choudhary,Akshay Agarwal,Vivek K Goyal*

Main category: eess.SP

TL;DR: 论文提出了一种基于混合分布的二次电子（SE）计数模型，相比传统的卷积模型，能更准确地描述SE信号分布，并通过时间分辨测量（TRM）和最大似然估计（MLE）显著提高了半导体边缘定位的分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统卷积模型仅描述SE计数的均值，无法完全捕捉SE信号的分布特性，限制了成像分辨率的提升。

Method: 提出了一种混合分布模型，推导了TRM下的Fisher信息和MLE，并通过蒙特卡洛模拟和实际HIM数据集验证。

Result: MLE在TRM下实现了5倍RMSE降低，实际数据中平均降低5.4倍。

Conclusion: 混合分布模型和TRM结合显著提升了边缘定位分辨率，Fisher信息可用于优化光束直径。

Abstract: Secondary electron (SE) imaging techniques, such as scanning electron
microscopy and helium ion microscopy (HIM), use electrons emitted by a sample
in response to a focused beam of charged particles incident at a grid of raster
scan positions. Spot size -- the diameter of the incident beam's spatial
profile -- is one of the limiting factors for resolution, along with various
sources of noise in the SE signal. The effect of the beam spatial profile is
commonly understood as convolutional. We show that under a simple and plausible
physical abstraction for the beam, though convolution describes the mean of the
SE counts, the full distribution of SE counts is a mixture. We demonstrate that
this more detailed modeling can enable resolution improvements over
conventional estimators through a stylized application in semiconductor
inspection of localizing the edge in a two-valued sample. We derive Fisher
information about edge location in conventional and time-resolved measurements
(TRM) and also derive the maximum likelihood estimate (MLE) from the latter.
Empirically, the MLE computed from TRM is approximately efficient except at
very low beam diameter, so Fisher information comparisons are predictive of
performance and can be used to optimize the beam diameter relative to the
raster scan spacing. Monte Carlo simulations show that the MLE gives a 5-fold
reduction in root mean-squared error (RMSE) of edge localization as compared to
conventional interpolation-based estimation. Applied to three real HIM
datasets, the average RMSE reduction factor is 5.4.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Deviation Inequalities for Rényi Divergence Estimators via Variational Expression](https://arxiv.org/abs/2508.09382)
*Sreejith Sreekumar,Kengo Kato*

Main category: cs.IT

TL;DR: 本文针对Rényi散度的估计误差提出了指数偏差不等式，适用于平滑插件估计器和神经估计器，无需传统假设（如紧支撑或有界密度）。


<details>
  <summary>Details</summary>
Motivation: 现有文献对Rényi散度估计误差的概率界限研究不足，本文旨在填补这一空白。

Method: 通过将误差与适当的经验过程关联，并利用经验过程理论工具，建立指数偏差不等式。

Result: 提出了适用于非紧支撑或无界密度分布的偏差不等式，并展示了其在信息论和隐私审计中的潜在应用。

Conclusion: 本文为Rényi散度估计提供了更通用的概率界限，扩展了其应用范围。

Abstract: R\'enyi divergences play a pivotal role in information theory, statistics,
and machine learning. While several estimators of these divergences have been
proposed in the literature with their consistency properties established and
minimax convergence rates quantified, existing accounts of probabilistic bounds
governing the estimation error are premature. Here, we make progress in this
regard by establishing exponential deviation inequalities for smoothed plug-in
estimators and neural estimators by relating the error to an appropriate
empirical process and leveraging tools from empirical process theory. In
particular, our approach does not require the underlying distributions to be
compactly supported or have densities bounded away from zero, an assumption
prevalent in existing results. The deviation inequality also leads to a
one-sided concentration bound from the expectation, which is useful in
random-coding arguments over continuous alphabets in information theory with
potential applications to physical-layer security. As another concrete
application, we consider a hypothesis testing framework for auditing R\'{e}nyi
differential privacy using the neural estimator as a test statistic and obtain
non-asymptotic performance guarantees for such a test.

</details>


### [26] [Hermitian Self-dual Twisted Generalized Reed-Solomon Codes](https://arxiv.org/abs/2508.09687)
*Chun'e Zhao,Yuxin Han,Wenping Ma,Tongjiang Yan,Yuhua Sun*

Main category: cs.IT

TL;DR: 本文研究了广义扭曲Reed-Solomon（A-TGRS）码的Hermitian自对偶性，提出了四个构造方法，并获得了新的Hermitian自对偶TGRS码类。此外，还给出了A-TGRS码为Hermitian自对偶且MDS的充要条件，并通过矩阵表示简化了分析。


<details>
  <summary>Details</summary>
Motivation: 研究自对偶MDS码在组合和密码学中的应用，特别是TGRS码的自对偶性。

Method: 通过矩阵表示分析A-TGRS码的Hermitian自对偶性，提出构造方法并验证其充要条件。

Result: 获得了新的Hermitian自对偶TGRS码类，并构造了一类MDS Hermitian自对偶TGRS码。

Conclusion: 矩阵表示方法简化了分析，适用于更广泛的Euclidean自对偶TGRS码和Hermitian自对偶GRS码。

Abstract: Self-dual maximum distance separable (MDS) codes over finite fields are
linear codes with significant combinatorial and cryptographic applications.
Twisted generalized Reed-Solomon (TGRS) codes can be both MDS and self-dual. In
this paper, we study a general class of TGRS codes (A-TGRS), which encompasses
all previously known special cases. First, we establish a sufficient and
necessary condition for an A-TGRS code to be Hermitian self-dual. Furthermore,
we present four constructions of self-dual TGRS codes, which, to the best of
our knowledge, nearly cover all the related results previously reported in the
literature. More importantly, we also obtain several new classes of Hermitian
self-dual TGRS codes with flexible parameters. Based on this framework, we
derive a sufficient and necessary condition for an A-TGRS code to be Hermitian
self-dual and MDS. In addition, we construct a class of MDS Hermitian self-dual
TGRS code by appropriately selecting the evaluation points. This work
investigates the Hermitian self-duality of TGRS codes from the perspective of
matrix representation, leading to more concise and transparent analysis. More
generally, the Euclidean self-dual TGRS codes and the Hermitian self-dual GRS
codes can also be understood easily from this point.

</details>


### [27] [Fluid Reconfigurable Intelligent Surface with Element-Level Pattern Reconfigurability: Beamforming and Pattern Co-Design](https://arxiv.org/abs/2508.09695)
*Han Xiao,Xiaoyan Hu,Kai-Kit Wong,Xusheng Zhu,Hanjiang Hong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文提出了一种新型的可重构流体智能表面（FRIS）框架，通过动态调整流体元件的辐射模式优化通信性能。理论分析和仿真结果表明，该框架在多用户场景下显著优于传统RIS架构。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过动态调整流体元件的辐射模式来优化通信系统的性能，特别是在点对点和多用户场景中。

Method: 提出了一种基于球形谐波正交分解（SHOD）的方法建模流体元件的辐射模式，并通过迭代算法（MMSE和RCG）联合优化波束成形和球形谐波系数。

Result: 仿真结果显示，所提出的FRIS框架在3GPP 38.901和各向同性辐射模型下，性能分别提升了161.5%和176.2%。

Conclusion: 该研究证明了动态模式可重构FRIS在通信系统中的显著优势，为未来智能表面设计提供了新思路。

Abstract: This paper proposes a novel pattern-reconfigurable fluid reconfigurable
intelligent surface (FRIS) framework, where each fluid element can dynamically
adjust its radiation pattern based on instantaneous channel conditions. To
evaluate its potential, we first conduct a comparative analysis of the received
signal power in point-to-point communication systems assisted by three types of
surfaces: (1) the proposed pattern-reconfigurable FRIS, (2) a
position-reconfigurable FRIS, and (3) a conventional RIS. Theoretical results
demonstrate that the pattern-reconfigurable FRIS provides a significant
advantage in modulating transmission signals compared to the other two
configurations. To further study its capabilities, we extend the framework to a
multiuser communication scenario. In this context, the spherical harmonics
orthogonal decomposition (SHOD) method is employed to accurately model the
radiation patterns of individual fluid elements, making the pattern design
process more tractable. An optimization problem is then formulated with the
objective of maximizing the weighted sum rate among users by jointly designing
the active beamforming vectors and the spherical harmonics coefficients,
subject to both transmit power and pattern energy constraints. To tackle the
resulting non-convex optimization problem, we propose an iterative algorithm
that alternates between a minimum mean-square error (MMSE) approach for active
beamforming and a Riemannian conjugate gradient (RCG) method for updating the
spherical harmonics coefficients. Simulation results show that the proposed
pattern-reconfigurable FRIS significantly outperforms traditional RIS
architectures based on the 3GPP 38.901 and isotropic radiation models,
achieving average performance gains of 161.5% and 176.2%, respectively.

</details>


### [28] [ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding](https://arxiv.org/abs/2508.09744)
*Andreas Zunker,Marvin Rübenacke,Stephan ten Brink*

Main category: cs.IT

TL;DR: 论文提出了一种基于递归Plotkin级联的低复杂度软判决解码算法，称为ORCAS码，性能优于或等于极化码，且具有更高的灵活性。


<details>
  <summary>Details</summary>
Motivation: 需要开发低复杂度软判决解码算法的信道编码。

Method: 递归级联基于单纯形码及其对偶码的低码率和高码率最优码，采用低复杂度最大似然解码和连续抵消解码。

Result: ORCAS码性能至少与极化码相当，实际参数下块错误率优于极化码0.5 dB，解码复杂度相近，且码长更灵活。

Conclusion: ORCAS码在性能和灵活性上优于极化码，适用于低复杂度解码需求的应用。

Abstract: Motivated by the need for channel codes with low-complexity soft-decision
decoding algorithms, we consider the recursive Plotkin concatenation of optimal
low-rate and high-rate codes based on simplex codes and their duals. These
component codes come with low-complexity maximum likelihood (ML) decoding
which, in turn, enables efficient successive cancellation (SC)-based decoding.
As a result, the proposed optimally recursively concatenated simplex (ORCAS)
codes achieve a performance that is at least as good as that of polar codes.
For practical parameters, the proposed construction significantly outperforms
polar codes in terms of block error rate by up to 0.5 dB while maintaining
similar decoding complexity. Furthermore, the codes offer greater flexibility
in codeword length than conventional polar codes.

</details>


### [29] [Non-Orthogonal Affine Frequency Division Multiplexing for Spectrally Efficient High-Mobility Communications](https://arxiv.org/abs/2508.09782)
*Qin Yi,Zilong Liu,Leila Musavian,Zeping Sui*

Main category: cs.IT

TL;DR: 本文提出了一种新型非正交仿射频分复用（nAFDM）波形，用于高移动性通信，具有更高的频谱效率。通过引入带宽压缩因子实现可控子载波重叠，并提出了基于IDFT的生成方法和软迭代检测算法。仿真结果表明，nAFDM在误码率和频谱效率上优于现有波形。


<details>
  <summary>Details</summary>
Motivation: 解决高移动性通信中频谱效率低的问题，通过非正交调制实现更高的频谱利用率。

Method: 引入带宽压缩因子实现子载波重叠，提出基于IDFT的信号生成方法和软迭代检测算法。

Result: nAFDM在误码率上与传统AFDM接近，频谱效率更高，且能实现误码率与复杂度的平衡。

Conclusion: nAFDM是一种高效的高移动性通信波形，具有优异的误码率和频谱效率表现。

Abstract: This paper proposes a novel non-orthogonal affine frequency division
multiplexing {(nAFDM)} waveform for reliable high-mobility communications with
enhanced spectral efficiency {(SE)}. The key idea is {to introduce} a bandwidth
compression factor into the AFDM {modulator} to enable controllable subcarrier
overlapping. We first {detail the proposed nAFDM transceiver} and derive the
corresponding input-output {signal} relationship. Then, an efficient {nAFDM}
signal generation method based on the inverse discrete Fourier transform (IDFT)
is proposed, enabling practical implementation using existing inverse fast
Fourier transform (IFFT) modules without additional hardware complexity. Next,
to characterize the impact of non-orthogonal modulation, we derive a
closed-form expression {of} inter-carrier interference (ICI), showing its
dependence on the bandwidth compression factor. To mitigate the resulting
interference, we propose a soft iterative detection algorithm and a
low-complexity implementation approach that leverages the distribution
characteristics of ICI. {Simulation results demonstrate that 1) in terms of bit
error rate (BER), the proposed nAFDM can achieve near identical BER compared to
conventional AFDM, while outperforms other waveform counterparts; 2) nAFDM is
capable of striking higher SE compared to other existing waveforms; and 3) the
proposed nAFDM achieves an attractive BER vs. SE trade-off, and the proposed
soft ID scheme can attain a trade-off between BER and complexity.}

</details>


### [30] [Unified Design of Space-Air-Ground-Sea Integrated Maritime Communications](https://arxiv.org/abs/2508.09817)
*Zhehan Zhou,Xiaoming Chen,Ming Ying,Zhaohui Yang,Chongwen Huang,Yunlong Cai,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种结合卫星、无人机、地面基站和无人船的天地海一体化海上通信架构，通过联合波束成形和轨迹优化算法，最大化用户的最小传输速率。


<details>
  <summary>Details</summary>
Motivation: 随着海上活动的爆炸性增长，需要为广阔海域提供无缝通信并保障服务质量。

Method: 将海域划分为沿海、近海、中海和远海区域，分别由地面基站、无人船、无人机和卫星提供服务，并设计联合波束成形和轨迹优化算法。

Result: 理论分析和仿真结果验证了所提算法的有效性。

Conclusion: 该架构和算法能有效提升海上通信的服务质量。

Abstract: With the explosive growth of maritime activities, it is expected to provide
seamless communications with quality of service (QoS) guarantee over broad sea
area. In the context, this paper proposes a space-air-ground-sea integrated
maritime communication architecture combining satellite, unmanned aerial
vehicle (UAV), terrestrial base station (TBS) and unmanned surface vessel
(USV). Firstly, according to the distance away from the shore, the whole marine
space is divided to coastal area, offshore area, middle-sea area and open-sea
area, the maritime users in which are served by TBS, USV, UAV and satellite,
respectively. Then, by exploiting the potential of integrated maritime
communication system, a joint beamforming and trajectory optimization algorithm
is designed to maximize the minimum transmission rate of maritime users.
Finally, theoretical analysis and simulation results validate the effectiveness
of the proposed algorithm.

</details>
