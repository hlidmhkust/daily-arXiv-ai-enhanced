<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.IV](#eess.IV) [Total: 10]
- [cs.IT](#cs.IT) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Distributed Integrated Sensing, Localization, and Communications over LEO Satellite Constellations](https://arxiv.org/abs/2508.11029)
*Yuchen Zhang,Francis Soualle,Musa Furkan Keskin,Yuan Liu,Linlong Wu,José A. del Peral-Rosado,Bhavani Shankar M. R.,Gonzalo Seco-Granados,Henk Wymeersch,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 本文提出了一种名为DISLAC的分布式集成感知、定位和通信概念，通过LEO卫星星座的协作提升6G应用的性能。


<details>
  <summary>Details</summary>
Motivation: LEO卫星星座在6G应用中面临功率、天线孔径和机载处理等限制，无法满足需求。

Method: 采用分布式多输入多输出架构，通过卫星间链路实现协作，提升吞吐量、定位精度和感知鲁棒性。

Result: 案例研究表明DISLAC能显著改善性能，并分析了同步、天线可重构性和ISL设计等关键问题。

Conclusion: 文章总结了DISLAC的未来研究方向，以推动其在实际非地面网络中的部署。

Abstract: Low Earth orbit (LEO) satellite constellations are rapidly becoming essential
enablers of next-generation wireless systems, offering global broadband access,
high-precision localization, and reliable sensing beyond terrestrial coverage.
However, the inherent limitations of individual LEO satellites, including
restricted power, limited antenna aperture, and constrained onboard processing,
hinder their ability to meet the growing demands of 6G applications. To address
these challenges, this article introduces the concept of distributed integrated
sensing, localization, and communication (DISLAC) over LEO constellations,
inspired by distributed multiple input multiple output architectures. By
enabling inter-satellite cooperation through inter-satellite links, DISLAC can
substantially improve throughput, positioning accuracy, and sensing robustness.
We present illustrative case studies that quantify these benefits and analyze
key system-level considerations, including synchronization, antenna
reconfigurability, and ISL design. The article concludes by outlining open
research directions to advance the practical deployment of DISLAC in future
non-terrestrial networks.

</details>


### [2] [Multi-Satellite Cooperative MIMO Transmission: Statistical CSI-Aware RSMA Precoding Design](https://arxiv.org/abs/2508.11132)
*Sangwon Jo,Seok-Hwan Park*

Main category: eess.SP

TL;DR: 研究了多颗低地球轨道卫星间的协作传输以提高频谱效率，设计了基于统计信道信息的MIMO预编码方案。


<details>
  <summary>Details</summary>
Motivation: 解决因延迟和多普勒效应导致瞬时信道状态信息难以获取的问题，提升卫星通信系统的性能。

Method: 提出基于统计CSI的MIMO预编码方案，通过闭式上界近似和加权最小均方误差算法求解问题。

Result: 仿真表明，该方案接近瞬时CSI性能，显著优于传统空分多址。

Conclusion: 基于统计CSI的RSMA方案在卫星通信中具有高效性和实用性。

Abstract: We investigate inter-satellite cooperative transmission in a multiple
low-Earth orbit (LEO) satellite communication system to enhance spectral
efficiency. Specifically, we design multiple-input multipleoutput (MIMO)
precoding at LEO satellites for cooperative rate-splitting multiple access
(RSMA). Given the difficulty of acquiring instantaneous channel state
information (iCSI) due to long delays and Doppler effects, we formulate an
ergodic max-min fairness rate (MMFR) maximization problem based on statistical
CSI (sCSI). To address the challenge of ergodic rate evaluation, we approximate
the problem using closed-form upper bounds and develop a weighted minimum mean
squared error-based algorithm to obtain a stationary point. Simulation results
demonstrate that the proposed sCSI-based RSMA scheme approaches iCSI-based
performance and significantly outperforms conventional space-division multiple
access.

</details>


### [3] [Near-Field Variable-Width Beam Coverage and Codebook Design for XL-RIS](https://arxiv.org/abs/2508.11178)
*Yida Zhang,Qiuyan Liu,Qiang Wang,Hongtao Luo,Yuqi Xia*

Main category: eess.SP

TL;DR: 论文提出一种可变宽度波束生成算法，用于解决XL-RIS窄波束宽度导致的波束对准和广播复杂性问题，并在近场码本设计中应用。


<details>
  <summary>Details</summary>
Motivation: 解决XL-RIS因窄波束宽度带来的波束对准和广播复杂性，提升覆盖范围和通信效率。

Method: 提出可变宽度波束生成算法，设计近场码本，并应用于多XL-RIS系统。

Result: 仿真显示，该方案能提高用户设备的频谱效率，降低通信中断概率，并对码本区域变化具有更好的鲁棒性。

Conclusion: 该算法有效解决了XL-RIS的波束对准问题，提升了通信性能。

Abstract: To mitigate the issue of limited base station coverage caused by severe
high-frequency electromagnetic wave attenuation, Extremely Large Reconfigurable
Intelligent Surface (XL-RIS) has garnered significant attention due to its high
beam gain. However, XL-RIS exhibits a narrower beam width compared to
traditional RIS, which increases the complexity of beam alignment and
broadcast. To address this problem, we propose a variable-width beam generation
algorithm under the near-field assumption and apply it to the near-field
codebook design for XL-RIS. Our algorithm can achieve beam coverage for
arbitrarily shaped codeword regions and generate a joint codebook for the
multi-XL-RIS system. The simulation results demonstrate that our proposed
scheme enables user equipment (UE) to achieve higher spectral efficiency and
lower communication outage probability within the codeword region compared to
existing works. Furthermore, our scheme exhibits better robustness to codeword
region location and area variations.

</details>


### [4] [KAN-HAR: A Human activity recognition based on Kolmogorov-Arnold Network](https://arxiv.org/abs/2508.11186)
*Mohammad Alikhani*

Main category: eess.SP

TL;DR: 论文提出了一种基于Kolmogorov-Arnold Network (KAN)和单三轴加速度计的人体活动识别方法，具有更高的可解释性和参数效率。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在人体活动识别中需要大量参数调优且缺乏可解释性，KAN能更好地建模复杂非线性关系。

Method: 使用MotionSense数据集，预处理和归一化加速度计和陀螺仪数据，通过KAN进行特征学习和分类。

Result: KAN在分类性能上优于或与传统深度神经网络相当，同时参数数量显著减少。

Conclusion: KAN架构是一种高效且可解释的替代方案，适用于实际人体活动识别系统。

Abstract: Human Activity Recognition (HAR) plays a critical role in numerous
applications, including healthcare monitoring, fitness tracking, and smart
environments. Traditional deep learning (DL) approaches, while effective, often
require extensive parameter tuning and may lack interpretability. In this work,
we investigate the use of a single three-axis accelerometer and the
Kolmogorov--Arnold Network (KAN) for HAR tasks, leveraging its ability to model
complex nonlinear relationships with improved interpretability and parameter
efficiency. The MotionSense dataset, containing smartphone-based motion sensor
signals across various physical activities, is employed to evaluate the
proposed approach. Our methodology involves preprocessing and normalization of
accelerometer and gyroscope data, followed by KAN-based feature learning and
classification. Experimental results demonstrate that the KAN achieves
competitive or superior classification performance compared to conventional
deep neural networks, while maintaining a significantly reduced parameter
count. This highlights the potential of KAN architectures as an efficient and
interpretable alternative for real-world HAR systems. The open-source
implementation of the proposed framework is available at the Project's GitHub
Repository.

</details>


### [5] [Enabling low-power massive MIMO with ternary ADCs for AIoT sensing](https://arxiv.org/abs/2508.11234)
*Shengheng Liu,Ningning Fu*

Main category: eess.SP

TL;DR: 论文探讨了在低功耗AIoT中使用三元ADC（T-ADCs）的解决方案，提出了一种联合导频与数据（JPD）的信道估计方法，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着网络设备的普及和对无处不在智能的需求增长，AIoT的功耗问题日益突出，尤其是高分辨率ADC和多射频链的高功耗问题。

Method: 采用三元ADC（T-ADCs）和JPD方案进行信道估计，分析了其性能极限，并提出了改进的EM和变分推断EM估计器。

Result: JPD方案在温和条件下有效缓解了粗量化效应带来的性能下降，仿真验证了其在均方误差和符号错误率上的有效性。

Conclusion: 三元ADC和JPD方案在低功耗AIoT中具有可行性，为智能感知提供了更环保的解决方案。

Abstract: The proliferation of networked devices and the surging demand for ubiquitous
intelligence have given rise to the artificial intelligence of things (AIoT).
However, the utilization of high-resolution analog-to-digital converters (ADCs)
and numerous radio frequency chains significantly raises power consumption.
This paper explores a cost-effective solution using ternary ADCs (T-ADCs) in
massive multiple-input-multiple-output (MIMO) systems for low-power AIoT and
specifically addresses channel sensing challenges. The channel is first
estimated through a pilot-aided scheme and refined using a joint-pilot-and-data
(JPD) approach. To assess the performance limits of this two-threshold ADC
system, the analysis includes its hardware-ideal counterpart, the parallel
one-bit ADCs (PO-ADCs) and a realistic scenario where noise variance is unknown
at the receiver is considered. Analytical findings indicate that the JPD scheme
effectively mitigates performance degradation in channel estimation due to
coarse quantization effects under mild conditions, without necessitating
additional pilot overhead. For deterministic and random channels, we propose
modified expectation maximization (EM) and variational inference EM estimators,
respectively. Extensive simulations validate the theoretical results and
demonstrate the effectiveness of the proposed estimators in terms of mean
square error and symbol error rate, which showcases the feasibility of
implementing T-ADCs and the associated JPD scheme for greener AIoT smart
sensing.

</details>


### [6] [Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images](https://arxiv.org/abs/2508.11259)
*Ryosuke Isono,Shunsuke Ono*

Main category: eess.SP

TL;DR: TSSTF是一种新的时空融合框架，通过TGTV和TGEC机制提升噪声条件下的图像融合效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决卫星图像时空分辨率权衡问题，并增强噪声鲁棒性，同时避免现有方法导致的细节丢失和伪影。

Method: 引入TGTV和TGEC机制，将融合任务建模为约束优化问题，采用预条件原始对偶分裂算法求解。

Result: TSSTF在无噪声条件下与现有方法相当，在噪声条件下表现更优，并提供了通用参数推荐。

Conclusion: TSSTF在噪声鲁棒性和结构保留方面表现优异，具有实用性和可重复性。

Abstract: This paper proposes a novel spatiotemporal (ST) fusion framework for
satellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF).
ST fusion is a promising approach to address the trade-off between the spatial
and temporal resolution of satellite images. In real-world scenarios, observed
satellite images are severely degraded by noise due to measurement equipment
and environmental conditions. Consequently, some recent studies have focused on
enhancing the robustness of ST fusion methods against noise. However, existing
noise-robust ST fusion approaches often fail to capture fine spatial structure,
leading to oversmoothing and artifacts. To address this issue, TSSTF introduces
two key mechanisms: Temporally-Guided Total Variation (TGTV) and
Temporally-Guided Edge Constraint (TGEC). TGTV is a novel regularization
function that promotes spatial piecewise smoothness while preserving structural
details, guided by a reference high spatial resolution image acquired on a
nearby date. TGEC enforces consistency in edge locations between two temporally
adjacent images, while allowing for spectral variations. We formulate the ST
fusion task as a constrained optimization problem incorporating TGTV and TGEC,
and develop an efficient algorithm based on a preconditioned primal-dual
splitting method. Experimental results demonstrate that TSSTF performs
comparably to state-of-the-art methods under noise-free conditions and
outperforms them under noisy conditions. Additionally, we provide a
comprehensive set of recommended parameter values that consistently yield high
performance across diverse target regions and noise conditions, aiming to
enhance reproducibility and practical utility.

</details>


### [7] [Beyond Diagonal Reconfigurable Intelligent Surface Enabled Sensing: Cramer-Rao Bound Optimization](https://arxiv.org/abs/2508.11292)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Haijun Zhang*

Main category: eess.SP

TL;DR: 本文研究了非对角可重构智能表面（BD-RIS）在6G感知中的优势，提出了一种基于自适应黎曼最速上升算法的优化方案，以最小化CRB，并展示了其优越的感知性能。


<details>
  <summary>Details</summary>
Motivation: 尽管BD-RIS在通信中的优势已被广泛研究，但其在6G感知中的增益尚不明确，这促使作者探索BD-RIS在感知中的应用。

Method: 作者推导了在BD-RIS散射矩阵为酉矩阵约束下的AOA估计的CRB，并提出了一种基于自适应黎曼最速上升算法的优化方案。

Result: 数值结果表明，所提出的BD-RIS辅助目标定位方法具有优越的感知性能。

Conclusion: BD-RIS在6G感知中具有显著优势，其优化方案能有效提升目标定位的精度。

Abstract: Recently, beyond diagonal reconfigurable intelligent surface (BD-RIS) has
emerged as a more flexible solution to engineer the wireless propagation
channels, thanks to its non-diagonal reflecting matrix. Although the gain of
the BD-RIS over the conventional RIS in communication has been revealed in many
works, its gain in 6G sensing is still unknown. This motivates us to study the
BD-RIS assisted sensing in this letter. Specifically, we derive the Cramer-Rao
bound (CRB) for estimating the angle-of-arrival (AOA) from the target to the
BD-RIS under the constraint that the BD-RIS scattering matrix is unitary. To
minimize the CRB, we develop an optimization scheme based on an adaptive
Riemannian steepest ascent algorithm that can satisfy the non-convex unitary
constraint. Numerical results demonstrate that the proposed BD-RIS-assisted
target localization method achieves superior sensing performance.

</details>


### [8] [Optimizing Rate-CRB Performance for Beyond Diagonal Reconfigurable Intelligent Surface Enabled ISAC](https://arxiv.org/abs/2508.11295)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Weifeng Zhu,Haijun Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种基于BD-RIS的ISAC系统，通过优化BS波束成形矩阵和BD-RIS散射矩阵，在满足定位精度约束的同时最大化用户总速率。采用对数障碍黎曼最速上升法求解问题，验证了BD-RIS优于传统RIS的性能增益。


<details>
  <summary>Details</summary>
Motivation: 研究BD-RIS在ISAC系统中的潜力，以同时提升通信性能和定位精度。

Method: 提出对数障碍黎曼最速上升法，优化BS波束成形矩阵和BD-RIS散射矩阵。

Result: 数值结果表明算法有效，且BD-RIS优于传统RIS。

Conclusion: BD-RIS在ISAC系统中具有显著性能优势，优化方法有效。

Abstract: This letter considers a beyond diagonal reconfigurable intelligent surface
(BD-RIS) aided integrated sensing and communication (ISAC) system, where the
BD-RIS can help a multi-antenna base station (BS) serve multiple user
equipments (UEs) and localize a target simultaneously. We formulate an
optimization problem that designs the BS beamforming matrix and the BD-RIS
scattering matrix to maximize UEs' sum rate subject to a localization
Cramer-Rao bound (CRB) constraint and an additional unitary matrix constraint
for the scattering matrix. Because unitary matrices form a manifold, our
problem belongs to constrained manifold optimization. This letter proposes a
log-barrier based Riemannian steepest ascent method to solve this problem
effectively. Numerical results verify the effectiveness of our algorithm and
the performance gain of the BD-RIS aided ISAC systems over the conventional RIS
aided ISAC systems.

</details>


### [9] [Important Bit Prefix M-ary Quadrature Amplitude Modulation for Semantic Communications](https://arxiv.org/abs/2508.11351)
*Haonan Lu,Rui Meng,Xiaodong Xu,Yiming Liu,Ping Zhang,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出了一种基于重要位前缀的MQAM方案（IBP-MQAM），用于语义通信，并通过LDA量化语义，验证了其在语义通信中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 为语义通信（SemCom）设计专用的信道调制技术，提升性能。

Method: 提出IBP-MQAM方案，推导重要符号错误率（ISER）和非重要符号错误率（USER）的近似表达式，使用LDA提取和量化文本语义。

Result: IBP-MQAM在语义通信场景中表现优于传统MQAM，并分析了关键系统参数的影响。

Conclusion: IBP-MQAM为语义通信提供了一种有效的信道调制解决方案。

Abstract: M-ary Quadrature Amplitude Modulation (MQAM) is a commonly used channel
modulation technology in wireless communication systems. To achieve dedicated
channel modulation for semantic communication (SemCom), we propose an
Important-Bit-Prefixed MQAM (IBP-MQAM) scheme and derive its approximate
expression of important symbol error rate (ISER) and unimportant symbol error
rate (USER). By extracting and quantifying text semantics using Latent
Dirichlet Allocation (LDA), we verify that IBP-MQAM achieves improved
performance over MQAM in SemCom scenarios and further analyze the effects of
key system parameters.

</details>


### [10] [Importance-Aware Robust Semantic Transmission for LEO Satellite-Ground Communication](https://arxiv.org/abs/2508.11457)
*Hui Cao,Rui Meng,Xiaodong Xu,Shujun Han,Ping Zhang*

Main category: eess.SP

TL;DR: 提出了一种重要性感知的鲁棒语义传输框架（IRST），用于解决卫星-地面语义通信中的动态SNR波动和带宽限制问题。


<details>
  <summary>Details</summary>
Motivation: 6G时代卫星-地面语义通信面临动态SNR波动和带宽限制的挑战，需要高效的任务导向数据传输方案。

Method: 通过分割模型增强算法提升语义分割精度，采用任务驱动的语义选择方法优先传输关键内容，并结合基于堆栈的SNR感知信道编解码器。

Result: IRST框架在多种操作条件下表现出优于现有基准的性能和鲁棒性。

Conclusion: IRST框架为带宽稀缺和信道多变的卫星-地面语义通信提供了有效的解决方案。

Abstract: Satellite-ground semantic communication is anticipated to serve a critical
role in the forthcoming 6G era. Nonetheless, task-oriented data transmission in
such systems remains a formidable challenge, primarily due to the dynamic
nature of signal-to-noise ratio (SNR) fluctuations and the stringent bandwidth
limitations inherent to low Earth orbit (LEO) satellite channels. In response
to these constraints, we propose an importance-aware robust semantic
transmission (IRST) framework, specifically designed for scenarios
characterized by bandwidth scarcity and channel variability. The IRST scheme
begins by applying a segmentation model enhancement algorithm to improve the
granularity and accuracy of semantic segmentation. Subsequently, a task-driven
semantic selection method is employed to prioritize the transmission of
semantically vital content based on real-time channel state information.
Furthermore, the framework incorporates a stack-based, SNR-aware channel codec
capable of executing adaptive channel coding in alignment with SNR variations.
Comparative evaluations across diverse operating conditions demonstrate the
superior performance and resilience of the IRST model relative to existing
benchmarks.

</details>


### [11] [Efficient Artifacts Removal for Adaptive Deep Brain Stimulation and a Temporal Event Localization Analysis](https://arxiv.org/abs/2508.11459)
*Tzu-Chi Liu,Po-Lin Chen,Yi-Chieh Chen,Po-Hsun Tu,Chih-Hua Yeh,Mun-Chun Yeap,Chiung-Chu Chen,Hau-Tieng Wu*

Main category: eess.SP

TL;DR: SMARTA+是一种高效算法，用于解决aDBS中的信号污染问题，比SMARTA和其他方法更优。


<details>
  <summary>Details</summary>
Motivation: 传统aDBS存在信号污染问题，现有方法在抑制伪迹和算法灵活性之间存在权衡。

Method: 开发SMARTA+，改进SMARTA算法，支持抑制刺激和瞬态DC伪迹，并提高计算效率。

Result: SMARTA+在伪迹去除和计算时间上表现优异，保留信号频谱和时间结构。

Conclusion: SMARTA+有望推动实时闭环aDBS系统的发展。

Abstract: Adaptive deep brain stimulation (aDBS) leverages symptom-related biomarkers
to deliver personalized neuromodulation therapy, with the potential to improve
treatment efficacy and reduce power consumption compared to conventional DBS.
However, stimulation-induced signal contamination remains a major technical
barrier to advancing its clinical application. Existing artifact removal
strategies, both front-end and back-end, face trade-offs between artifact
suppression and algorithmic flexibility. Among back-end algorithms, Shrinkage
and Manifold-based Artifact Removal using Template Adaptation (SMARTA) has
shown promising performance in mitigating stimulus artifacts with minimal
distortion to local field potentials (LFPs), but its high computational demand
and inability to handle transient direct current (DC) artifacts limit its use
in real-time applications. To address this, we developed SMARTA+, a
computationally efficient extension of SMARTA capable of suppressing both
stimulus and transient DC artifacts while supporting flexible algorithmic
design. We evaluated SMARTA+ using semi-real aDBS data and real data from
Parkinson's disease patients. Compared to SMARTA and other established methods,
SMARTA+ achieved comparable or superior artifact removal while significantly
reducing computation time. It preserved spectral and temporal structures,
ranging from beta band to high-frequency oscillations, and demonstrated
robustness across diverse stimulation protocols. Temporal event localization
analysis further showed improved accuracy in detecting beta bursts. These
findings support SMARTA+ as a promising tool for advancing real-time,
closed-loop aDBS systems.

</details>


### [12] [Reducing AoI and Improving Throughput for NOMA-assisted SGF Systems: A Hierarchical Learning Approach](https://arxiv.org/abs/2508.11473)
*Yuqin Liu,Mona Jaber,Yan Liu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 论文提出了一种基于非正交多址（NOMA）的半免授权（SGF）框架，通过利用授权用户的剩余资源为免授权用户（GFUs）提供信道接入。通过联合波束成形设计和传输调度优化系统吞吐量并降低GFUs的信息时效性（AoI）。问题被建模为马尔可夫决策过程，并采用深度强化学习（DRL）和分层学习算法解决。实验结果显示，DRL调度在AoI减少上优于现有方法，分层学习算法在吞吐量提升和AoI控制上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决免授权用户在信道接入中的资源分配问题，同时优化系统吞吐量和信息时效性。

Method: 1. 将问题建模为马尔可夫决策过程；2. 提出基于DRL的传输调度方法；3. 设计分层学习算法，上层策略优化波束成形，下层策略最大化传输时隙利用率。

Result: 1. DRL调度在AoI减少上优于基线方法；2. 分层学习算法提升吞吐量31.82%，同时将GFUs的平均AoI控制在1.5时隙内；3. 方法在GFUs数量为GBUs的1-5倍时均有效。

Conclusion: 提出的NOMA辅助SGF框架及分层学习算法在优化信道接入和AoI方面表现优异，适用于多种场景。

Abstract: A non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF)
framework is proposed to enable channel access for grant-free users (GFUs) by
using residual resources from grant-based users. Under this framework, the
problem of joint beamforming design and transmission scheduling is formulated
to improve the system throughput and reduce the age-of-information of GFUs. The
aforementioned problem is transferred into a Markov Decision Process to model
the changing environment with the transmission/ waiting/ retransmission of
GFUs. In an effort to solve the pertinent problem, firstly, a deep
reinforcement learning (DRL) based transmission scheduling approach is proposed
for determining the optimal transmission probability based on the available
transmission slots and transmission status of GFUs. Secondly, a hierarchical
learning algorithm is proposed to analyze the channel state information of GBUs
and the transmission status of GFUs, and to train an upper-level policy based
on this analysis for beamforming to achieve efficient grant-based transmission,
while a lower-level policy adapts to maximize the utilization of transmission
slots allocated by the upper-level agent. The two policies interact to improve
channel access and avoid collisions. Numerical results reveal that 1) The DRL
based transmission scheduling outperforms existing adaptive and state-dependent
baselines in AoI reduction, where an average
three-time-slots-earlier-transmission can be obtained compared to the
state-dependent choice, and five time slots earlier can be achieved when
comparing to the adaptive choice; 2) The hierarchical learning algorithm is
able to achieve approximately a 31.82% gain while maintaining the average AoI
of GFUs within 1.5 time slots. 3) The effectiveness of the hierarchical
learning scheme in NOMA-assisted SGF system is validated across scenarios with
GFUs counts from 1-5 times of GBUs.

</details>


### [13] [Liquid Crystal-Based RIS Loss-Trade-Off Analysis](https://arxiv.org/abs/2508.11489)
*Bowu Wang,Mohamadreza Delbari,Robin Neuder,Alejandro Jiménez-Sáez,Vahid Jamali*

Main category: eess.SP

TL;DR: 本文研究了基于液晶技术的可重构智能表面（RIS）在毫米波频段的应用，探讨了相位偏移范围与插入损耗之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 液晶技术因其低功耗、可扩展性和连续可调相位偏移等优势成为RIS的有力候选，但其相位偏移范围与插入损耗的权衡尚未在无线系统中研究。

Method: 通过配置基站和RIS以最小化发射功率，同时满足用户的服务质量（QoS），研究了LC-RIS的相位偏移范围与系统性能的关系。

Result: 仿真结果表明，总发射功率与可达到的数据速率之间存在基本权衡，这一权衡是LC相位偏移范围的函数。

Conclusion: 研究揭示了LC-RIS在无线系统中的性能限制，为未来优化设计提供了重要参考。

Abstract: Liquid crystal (LC) technology has emerged as a promising solution for large
reconfigurable intelligent surfaces (RISs) at millimeter wave (mmWave) bands,
offering advantages such as low power consumption, scalability, and
continuously tunable phase shifts. For LC-RIS based on the delay-line
architecture, i.e., with dedicated phase shifters, there exists a trade-off
between the maximum achievable phase-shift range and the corresponding
insertion loss, which has not been studied for LC-RIS-assisted wireless systems
yet. In this paper, we investigate this trade-off where a base station (BS) and
an RIS are configured to minimize the transmit power while satisfying a given
quality of service (QoS) for a number of users. Simulation results reveal a
fundamental trade-off between the total transmit power and the achievable data
rate as a function of the LC phase-shift range.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [14] [The Role of Radiographic Knee Alignment in Knee Replacement Outcomes and Opportunities for Artificial Intelligence-Driven Assessment](https://arxiv.org/abs/2508.10941)
*Zhisen Hu,David S. Johnson,Aleksei Tiulpin,Timothy F. Cootes,Claudia Lindner*

Main category: eess.IV

TL;DR: 本文综述了膝关节置换术（TKR）的预后与膝关节对齐生物标志物的关系，探讨了AI在膝关节对齐评估中的应用及未来方向。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎（OA）的治疗主要依赖TKR，但手术效果难以预测。膝关节对齐是影响TKR预后的关键因素之一，而现有研究多关注OA诊断而非对齐生物标志物。

Method: 综述了TKR预后评分标准及膝关节对齐生物标志物，并讨论了AI在膝关节对齐自动测量中的应用。

Result: AI在膝关节对齐测量中显示出潜力，但现有研究多集中于OA诊断，对齐生物标志物与TKR预后的关系仍需深入探索。

Conclusion: 未来研究应聚焦于膝关节对齐生物标志物的开发及其对TKR预后的预测作用，AI技术有望推动这一领域的发展。

Abstract: Prevalent knee osteoarthritis (OA) imposes substantial burden on health
systems with no cure available. Its ultimate treatment is total knee
replacement (TKR). Complications from surgery and recovery are difficult to
predict in advance, and numerous factors may affect them. Radiographic knee
alignment is one of the key factors that impacts TKR outcomes, affecting
outcomes such as postoperative pain or function. Recently, artificial
intelligence (AI) has been introduced to the automatic analysis of knee
radiographs, for example, to automate knee alignment measurements. Existing
review articles tend to focus on knee OA diagnosis and segmentation of bones or
cartilages in MRI rather than exploring knee alignment biomarkers for TKR
outcomes and their assessment. In this review, we first examine the current
scoring protocols for evaluating TKR outcomes and potential knee alignment
biomarkers associated with these outcomes. We then discuss existing AI-based
approaches for generating knee alignment biomarkers from knee radiographs, and
explore future directions for knee alignment assessment and TKR outcome
prediction.

</details>


### [15] [Deep Learning-Based Automated Segmentation of Uterine Myomas](https://arxiv.org/abs/2508.11010)
*Tausifa Jan Saleem,Mohammad Yaqub*

Main category: eess.IV

TL;DR: 论文探讨了子宫肌瘤的自动化分割需求，并利用公开数据集UMD建立基线，以促进标准化评估和未来研究。


<details>
  <summary>Details</summary>
Motivation: 子宫肌瘤对女性生殖健康造成重大负担，现有MRI分割方法耗时且易受专家差异影响，亟需自动化解决方案。

Method: 利用公开数据集UMD，采用深度学习算法实现子宫肌瘤的自动化分割。

Result: 研究为子宫肌瘤的自动化分割提供了标准化评估基线。

Conclusion: 公开数据集和深度学习算法的结合为子宫肌瘤分割的未来研究奠定了基础。

Abstract: Uterine fibroids (myomas) are the most common benign tumors of the female
reproductive system, particularly among women of childbearing age. With a
prevalence exceeding 70%, they pose a significant burden on female reproductive
health. Clinical symptoms such as abnormal uterine bleeding, infertility,
pelvic pain, and pressure-related discomfort play a crucial role in guiding
treatment decisions, which are largely influenced by the size, number, and
anatomical location of the fibroids. Magnetic Resonance Imaging (MRI) is a
non-invasive and highly accurate imaging modality commonly used by clinicians
for the diagnosis of uterine fibroids. Segmenting uterine fibroids requires a
precise assessment of both the uterus and fibroids on MRI scans, including
measurements of volume, shape, and spatial location. However, this process is
labor intensive and time consuming and subjected to variability due to intra-
and inter-expert differences at both pre- and post-treatment stages. As a
result, there is a critical need for an accurate and automated segmentation
method for uterine fibroids. In recent years, deep learning algorithms have
shown re-markable improvements in medical image segmentation, outperforming
traditional methods. These approaches offer the potential for fully automated
segmentation. Several studies have explored the use of deep learning models to
achieve automated segmentation of uterine fibroids. However, most of the
previous work has been conducted using private datasets, which poses challenges
for validation and comparison between studies. In this study, we leverage the
publicly available Uterine Myoma MRI Dataset (UMD) to establish a baseline for
automated segmentation of uterine fibroids, enabling standardized evaluation
and facilitating future research in this domain.

</details>


### [16] [HistoViT: Vision Transformer for Accurate and Scalable Histopathological Cancer Diagnosis](https://arxiv.org/abs/2508.11181)
*Faisal Ahmed*

Main category: eess.IV

TL;DR: 提出了一种基于Transformer的深度学习框架，用于病理图像中的多类肿瘤分类，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决癌症诊断中复杂组织学变异性的挑战，提升分类性能和可扩展性。

Method: 采用微调的Vision Transformer架构，简化预处理流程，将全切片图像转换为PyTorch张量并进行标准化。

Result: 在四个数据集上表现优异，分类准确率均超过95%，AUC得分均高于99%。

Conclusion: Transformer架构在数字病理学中具有鲁棒性和临床潜力，可推动自动化癌症诊断系统的发展。

Abstract: Accurate and scalable cancer diagnosis remains a critical challenge in modern
pathology, particularly for malignancies such as breast, prostate, bone, and
cervical, which exhibit complex histological variability. In this study, we
propose a transformer-based deep learning framework for multi-class tumor
classification in histopathological images. Leveraging a fine-tuned Vision
Transformer (ViT) architecture, our method addresses key limitations of
conventional convolutional neural networks, offering improved performance,
reduced preprocessing requirements, and enhanced scalability across tissue
types. To adapt the model for histopathological cancer images, we implement a
streamlined preprocessing pipeline that converts tiled whole-slide images into
PyTorch tensors and standardizes them through data normalization. This ensures
compatibility with the ViT architecture and enhances both convergence stability
and overall classification performance. We evaluate our model on four benchmark
datasets: ICIAR2018 (breast), SICAPv2 (prostate), UT-Osteosarcoma (bone), and
SipakMed (cervical) dataset -- demonstrating consistent outperformance over
existing deep learning methods. Our approach achieves classification accuracies
of 99.32%, 96.92%, 95.28%, and 96.94% for breast, prostate, bone, and cervical
cancers respectively, with area under the ROC curve (AUC) scores exceeding 99%
across all datasets. These results confirm the robustness, generalizability,
and clinical potential of transformer-based architectures in digital pathology.
Our work represents a significant advancement toward reliable, automated, and
interpretable cancer diagnosis systems that can alleviate diagnostic burdens
and improve healthcare outcomes.

</details>


### [17] [Efficient Image-to-Image Schrödinger Bridge for CT Field of View Extension](https://arxiv.org/abs/2508.11211)
*Zhenhao Li,Long Yang,Xiaojie Yin,Haijun Yu,Jiazhou Wang,Hongbin Han,Weigang Hu,Yixing Huang*

Main category: eess.IV

TL;DR: 提出了一种基于Schrödinger Bridge扩散模型的高效CT视野扩展方法，显著提升了重建速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统CT重建算法在视野超出时表现不佳，而现有扩散模型计算成本高且速度慢。

Method: 采用图像到图像的Schrödinger Bridge（I²SB）扩散模型，直接学习有限视野与扩展视野图像的映射。

Result: 在模拟和真实数据上均优于现有扩散模型，重建速度显著提升（0.19秒/切片）。

Conclusion: I²SB在准确性和效率上均表现出色，适合实时或临床部署。

Abstract: Computed tomography (CT) is a cornerstone imaging modality for non-invasive,
high-resolution visualization of internal anatomical structures. However, when
the scanned object exceeds the scanner's field of view (FOV), projection data
are truncated, resulting in incomplete reconstructions and pronounced artifacts
near FOV boundaries. Conventional reconstruction algorithms struggle to recover
accurate anatomy from such data, limiting clinical reliability. Deep learning
approaches have been explored for FOV extension, with diffusion generative
models representing the latest advances in image synthesis. Yet, conventional
diffusion models are computationally demanding and slow at inference due to
their iterative sampling process. To address these limitations, we propose an
efficient CT FOV extension framework based on the image-to-image Schr\"odinger
Bridge (I$^2$SB) diffusion model. Unlike traditional diffusion models that
synthesize images from pure Gaussian noise, I$^2$SB learns a direct stochastic
mapping between paired limited-FOV and extended-FOV images. This direct
correspondence yields a more interpretable and traceable generative process,
enhancing anatomical consistency and structural fidelity in reconstructions.
I$^2$SB achieves superior quantitative performance, with root-mean-square error
(RMSE) values of 49.8\,HU on simulated noisy data and 152.0HU on real data,
outperforming state-of-the-art diffusion models such as conditional denoising
diffusion probabilistic models (cDDPM) and patch-based diffusion methods.
Moreover, its one-step inference enables reconstruction in just 0.19s per 2D
slice, representing over a 700-fold speedup compared to cDDPM (135s) and
surpassing diffusionGAN (0.58s), the second fastest. This combination of
accuracy and efficiency makes I$^2$SB highly suitable for real-time or clinical
deployment.

</details>


### [18] [A Convergent Generalized Krylov Subspace Method for Compressed Sensing MRI Reconstruction with Gradient-Driven Denoisers](https://arxiv.org/abs/2508.11219)
*Tao Hong,Umberto Villa,Jeffrey A. Fessler*

Main category: eess.IV

TL;DR: 论文提出了一种广义Krylov子空间方法（GKSM），用于高效解决压缩感知MRI重建中的优化问题，并提供了非凸设置下的严格收敛保证。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的去噪方法（如CNN）在压缩感知MRI重建中表现优异，但缺乏理论保证；而梯度驱动去噪方法虽满足理论分析假设，但计算成本高。

Method: 提出广义Krylov子空间方法（GKSM），用于高效求解优化问题，并验证其在非凸设置下的收敛性。

Result: 在螺旋和径向采集的CS MRI重建实验中，GKSM展示了计算效率和理论预测的准确性。

Conclusion: GKSM是一种适用于任何线性逆问题的高效优化方法，兼具计算效率和理论保证。

Abstract: Model-based reconstruction plays a key role in compressed sensing (CS) MRI,
as it incorporates effective image regularizers to improve the quality of
reconstruction. The Plug-and-Play and Regularization-by-Denoising frameworks
leverage advanced denoisers (e.g., convolutional neural network (CNN)-based
denoisers) and have demonstrated strong empirical performance. However, their
theoretical guarantees remain limited, as practical CNNs often violate key
assumptions. In contrast, gradient-driven denoisers achieve competitive
performance, and the required assumptions for theoretical analysis are easily
satisfied. However, solving the associated optimization problem remains
computationally demanding. To address this challenge, we propose a generalized
Krylov subspace method (GKSM) to solve the optimization problem efficiently.
Moreover, we also establish rigorous convergence guarantees for GKSM in
nonconvex settings. Numerical experiments on CS MRI reconstruction with spiral
and radial acquisitions validate both the computational efficiency of GKSM and
the accuracy of the theoretical predictions. The proposed optimization method
is applicable to any linear inverse problem.

</details>


### [19] [Guiding WaveMamba with Frequency Maps for Image Debanding](https://arxiv.org/abs/2508.11331)
*Xinyi Wang,Smaranda Tasmoc,Nantheera Anantrasirichai,Angeliki Katsenou*

Main category: eess.IV

TL;DR: 论文提出了一种基于小波状态空间模型和频率掩码图的频带修复方法，有效抑制低码率压缩中的条带伪影，并在公开数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 低码率压缩常导致平滑区域（如天空）出现条带伪影，影响视觉质量，尤其在用户生成内容中因多次转码而更常见。

Method: 采用小波状态空间模型和频率掩码图，保留高频细节，同时提出开源频带修复方法的基准测试。

Result: 在公开数据集上，所提方法优于现有技术（DBI值为0.082），且能保留图像纹理。

Conclusion: 该方法能有效抑制条带伪影，视觉检查结果验证了其效果。代码和补充材料已开源。

Abstract: Compression at low bitrates in modern codecs often introduces banding
artifacts, especially in smooth regions such as skies. These artifacts degrade
visual quality and are common in user-generated content due to repeated
transcoding. We propose a banding restoration method that employs the Wavelet
State Space Model and a frequency masking map to preserve high-frequency
details. Furthermore, we provide a benchmark of open-source banding restoration
methods and evaluate their performance on two public banding image datasets.
Experimentation on the available datasets suggests that the proposed
post-processing approach effectively suppresses banding compared to the
state-of-the-art method (a DBI value of 0.082 on BAND-2k) while preserving
image textures. Visual inspections of the results confirm this. Code and
supplementary material are available at:
https://github.com/xinyiW915/Debanding-PCS2025.

</details>


### [20] [AnatoMaskGAN: GNN-Driven Slice Feature Fusion and Noise Augmentation for Medical Semantic Image Synthesis](https://arxiv.org/abs/2508.11375)
*Zonglin Wu,Yule Xue,Qianxiang Hu,Yaoyao Feng,Yuqi Ma,Shanxiong Chen*

Main category: eess.IV

TL;DR: AnatoMaskGAN是一种新型医学图像合成框架，通过嵌入切片相关空间特征、多样化图像增强策略和优化深度特征学习，显著提升了复杂医学图像的性能。


<details>
  <summary>Details</summary>
Motivation: 现有GAN方法在医学图像合成中缺乏空间一致性和多样性，无法满足复杂扫描的需求。

Method: 设计GNN切片特征融合模块、三维空间噪声注入策略和灰度纹理分类器，以增强空间关系和多样性建模。

Result: 在L2R-OASIS和L2R-Abdomen CT数据集上，PSNR和SSIM显著提升，优于现有技术。

Conclusion: AnatoMaskGAN的核心设计均对重建精度和感知质量有独立贡献，验证了其有效性。

Abstract: Medical semantic-mask synthesis boosts data augmentation and analysis, yet
most GAN-based approaches still produce one-to-one images and lack spatial
consistency in complex scans. To address this, we propose AnatoMaskGAN, a novel
synthesis framework that embeds slice-related spatial features to precisely
aggregate inter-slice contextual dependencies, introduces diverse
image-augmentation strategies, and optimizes deep feature learning to improve
performance on complex medical images. Specifically, we design a GNN-based
strongly correlated slice-feature fusion module to model spatial relationships
between slices and integrate contextual information from neighboring slices,
thereby capturing anatomical details more comprehensively; we introduce a
three-dimensional spatial noise-injection strategy that weights and fuses
spatial features with noise to enhance modeling of structural diversity; and we
incorporate a grayscale-texture classifier to optimize grayscale distribution
and texture representation during generation. Extensive experiments on the
public L2R-OASIS and L2R-Abdomen CT datasets show that AnatoMaskGAN raises PSNR
on L2R-OASIS to 26.50 dB (0.43 dB higher than the current state of the art) and
achieves an SSIM of 0.8602 on L2R-Abdomen CT--a 0.48 percentage-point gain over
the best model, demonstrating its superiority in reconstruction accuracy and
perceptual quality. Ablation studies that successively remove the slice-feature
fusion module, spatial 3D noise-injection strategy, and grayscale-texture
classifier reveal that each component contributes significantly to PSNR, SSIM,
and LPIPS, further confirming the independent value of each core design in
enhancing reconstruction accuracy and perceptual quality.

</details>


### [21] [LKFMixer: Exploring Large Kernel Feature For Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11391)
*Yinggan Tang,Quanwei Hu*

Main category: eess.IV

TL;DR: LKFMixer是一种纯卷积神经网络模型，通过大卷积核模拟自注意力的非局部特征捕获能力，提升图像超分辨率性能。


<details>
  <summary>Details</summary>
Motivation: 自注意力在Transformer中表现出色，但计算量大，难以实现轻量级模型。

Method: 使用31大小的卷积核扩大感受野，通过坐标分解减少参数和计算，引入SFMB和FSB模块优化特征提取。

Result: LKFMixer在超分辨率任务中表现优于其他SOTA方法，PSNR提升0.6dB，推理速度快5倍。

Conclusion: LKFMixer通过卷积核模拟自注意力，实现了高效且高性能的图像超分辨率。

Abstract: The success of self-attention (SA) in Transformer demonstrates the importance
of non-local information to image super-resolution (SR), but the huge computing
power required makes it difficult to implement lightweight models. To solve
this problem, we propose a pure convolutional neural network (CNN) model,
LKFMixer, which utilizes large convolutional kernel to simulate the ability of
self-attention to capture non-local features. Specifically, we increase the
kernel size to 31 to obtain the larger receptive field as possible, and reduce
the parameters and computations by coordinate decomposition. Meanwhile, a
spatial feature modulation block (SFMB) is designed to enhance the focus of
feature information on both spatial and channel dimension. In addition, by
introducing feature selection block (FSB), the model can adaptively adjust the
weights between local features and non-local features. Extensive experiments
show that the proposed LKFMixer family outperform other state-of-the-art (SOTA)
methods in terms of SR performance and reconstruction quality. In particular,
compared with SwinIR-light on Manga109 dataset, LKFMixer-L achieves 0.6dB PSNR
improvement at $\times$4 scale, while the inference speed is $\times$5 times
faster. The code is available at https://github.com/Supereeeee/LKFMixer.

</details>


### [22] [Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer](https://arxiv.org/abs/2508.11450)
*Augustine X. W. Lee,Pak-Hei Yeung,Jagath C. Rajapakse*

Main category: eess.IV

TL;DR: 提出一种自动集成框架，利用MRI模型为CT扫描生成高质量皮层下分割标签，填补CT数据空白。


<details>
  <summary>Details</summary>
Motivation: 解决CT扫描中皮层下分割标注数据不足的问题，促进脑部疾病诊断。

Method: 通过集成MRI模型，构建鲁棒的集成流程，应用于未标注的MRI-CT配对数据。

Result: 在多个公共数据集上表现优异，生成的CT数据集提升了分割模型性能。

Conclusion: 开源代码、数据集和模型，推动CT皮层下分割研究。

Abstract: Subcortical segmentation in neuroimages plays an important role in
understanding brain anatomy and facilitating computer-aided diagnosis of
traumatic brain injuries and neurodegenerative disorders. However, training
accurate automatic models requires large amounts of labelled data. Despite the
availability of publicly available subcortical segmentation datasets for
Magnetic Resonance Imaging (MRI), a significant gap exists for Computed
Tomography (CT). This paper proposes an automatic ensemble framework to
generate high-quality subcortical segmentation labels for CT scans by
leveraging existing MRI-based models. We introduce a robust ensembling pipeline
to integrate them and apply it to unannotated paired MRI-CT data, resulting in
a comprehensive CT subcortical segmentation dataset. Extensive experiments on
multiple public datasets demonstrate the superior performance of our proposed
framework. Furthermore, using our generated CT dataset, we train segmentation
models that achieve improved performance on related segmentation tasks. To
facilitate future research, we make our source code, generated dataset, and
trained models publicly available at
https://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation,
marking the first open-source release for CT subcortical segmentation to the
best of our knowledge.

</details>


### [23] [Semi-Supervised Learning with Online Knowledge Distillation for Skin Lesion Classification](https://arxiv.org/abs/2508.11511)
*Siyamalan Manivannan*

Main category: eess.IV

TL;DR: 提出了一种结合集成学习和在线知识蒸馏的半监督深度学习方法，用于皮肤病变分类，减少对大量标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖全监督学习，需要大量标注数据，成本高且难以获取。

Method: 训练卷积神经网络集成模型，通过在线知识蒸馏将集成模型的洞察传递给成员模型，提升性能。

Result: 在公开数据集上超越现有最佳结果，知识蒸馏后的单个模型性能优于独立训练模型。

Conclusion: 该方法降低了标注数据需求，提供了更高效的皮肤病变分类解决方案。

Abstract: Deep Learning has emerged as a promising approach for skin lesion analysis.
However, existing methods mostly rely on fully supervised learning, requiring
extensive labeled data, which is challenging and costly to obtain. To alleviate
this annotation burden, this study introduces a novel semi-supervised deep
learning approach that integrates ensemble learning with online knowledge
distillation for enhanced skin lesion classification. Our methodology involves
training an ensemble of convolutional neural network models, using online
knowledge distillation to transfer insights from the ensemble to its members.
This process aims to enhance the performance of each model within the ensemble,
thereby elevating the overall performance of the ensemble itself.
Post-training, any individual model within the ensemble can be deployed at test
time, as each member is trained to deliver comparable performance to the
ensemble. This is particularly beneficial in resource-constrained environments.
Experimental results demonstrate that the knowledge-distilled individual model
performs better than independently trained models. Our approach demonstrates
superior performance on both the \emph{International Skin Imaging
Collaboration} 2018 and 2019 public benchmark datasets, surpassing current
state-of-the-art results. By leveraging ensemble learning and online knowledge
distillation, our method reduces the need for extensive labeled data while
providing a more resource-efficient solution for skin lesion classification in
real-world scenarios.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [24] [CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems](https://arxiv.org/abs/2508.11287)
*Xuran Liu,Nan Xue,Rui Bao,Yaping Sun,Zhiyong Chen,Meixia Tao,Xiaodong Xu,Shuguang Cui*

Main category: cs.IT

TL;DR: 提出了一种延迟感知调度框架，通过重叠模型加载与计算和通信来最小化推理延迟。


<details>
  <summary>Details</summary>
Motivation: 边缘设备资源有限，现有方法忽略了按需模型加载导致的冷启动延迟。

Method: 设计了一种动态规划算法，优化模型分区和设备分配，隐藏加载时间。

Result: 实验表明，该方法显著降低了冷启动延迟。

Conclusion: 提出的框架有效减少了推理延迟，适用于边缘设备部署。

Abstract: While deploying large language models on edge devices promises low-latency
and privacy-preserving AI services, it is hindered by limited device resources.
Although pipeline parallelism facilitates distributed inference, existing
approaches often ignore the cold-start latency caused by on-demand model
loading. In this paper, we propose a latency-aware scheduling framework that
overlaps model loading with computation and communication to minimize total
inference latency. Based on device and model parameters, the framework
dynamically adjusts layer partitioning and allocation to effectively hide
loading time, thereby eliminating as many idle periods as possible. We
formulate the problem as a Mixed-Integer Non-Linear Program and design an
efficient dynamic programming algorithm to optimize model partitioning and
device assignment. Experimental results show that the proposed method
significantly reduces cold-start latency compared to baseline strategies.

</details>


### [25] [Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks](https://arxiv.org/abs/2508.11291)
*Rui Bao,Nan Xue,Yaping Sun,Zhiyong Chen*

Main category: cs.IT

TL;DR: 论文提出了一种动态、质量-延迟感知的路由框架，用于在移动设备和边缘服务器之间协调推理任务，以平衡推理质量和延迟。


<details>
  <summary>Details</summary>
Motivation: 无线通信与大型语言模型（LLMs）的结合有望实现无处不在的智能服务，但在无线边缘设备协作环境中部署时，推理质量与端到端延迟之间存在关键权衡。

Method: 框架采用两种成本模型：对于单轮查询，结合BERT预测的语义分数与通信和计算开销；对于多轮对话，进一步量化模型切换和KV缓存管理带来的上下文感知成本。

Result: 实验表明，该框架在保持完整推理质量的同时，平均响应延迟降低了5-15%，并在多个基准测试中减少了10-20%的大型模型调用。

Conclusion: 该框架有效解决了任务复杂性与资源分配之间的不匹配问题，为边缘设备协作环境中的智能服务提供了优化方案。

Abstract: The integration of wireless communications and Large Language Models (LLMs)
is poised to unlock ubiquitous intelligent services, yet deploying them in
wireless edge-device collaborative environments presents a critical trade-off
between inference quality and end-to-end latency. A fundamental mismatch exists
between task complexity and resource allocation: offloading simple queries
invites prohibitive latency, while on-device models lack the capacity for
demanding computations. To address this challenge, we propose a dynamic,
quality-latency aware routing framework that orchestrates inference between a
lightweight model on the mobile device and a powerful model on the edge server.
Our framework employs two distinct cost models: for single-turn queries, it
fuses a BERT-predicted semantic score with communication and computation
overheads; for multi-turn dialogues, it further quantifies context-aware costs
arising from model switching and KV-cache management. While maintaining full
inference quality, extensive experiments demonstrate that our framework cuts
average response latency by 5-15% and reduces large model invocations by 10-20%
against competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks.

</details>
