<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 7]
- [eess.SP](#eess.SP) [Total: 13]
- [eess.IV](#eess.IV) [Total: 13]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Directed Information $γ$-covering: An Information-Theoretic Framework for Context Engineering](https://arxiv.org/abs/2510.00079)
*Hai Huang*

Main category: cs.IT

TL;DR: 提出了基于定向信息的γ-覆盖框架，用于冗余感知的上下文工程，通过因果预测性度量来优化上下文选择。


<details>
  <summary>Details</summary>
Motivation: 现有上下文选择方法缺乏对冗余信息的系统处理，需要一种原则性的框架来平衡信息覆盖和多样性。

Method: 使用定向信息度量块间预测性，将上下文选择建模为γ-覆盖问题，并提出具有理论保证的贪心算法。

Result: 在HotpotQA上的实验表明，γ-覆盖方法持续优于BM25基线，在上下文压缩和单槽提示选择等硬决策场景中表现优异。

Conclusion: 定向信息γ-覆盖为现代LLM流水线提供了一个原则性、自组织的骨干框架。

Abstract: We introduce \textbf{Directed Information $\gamma$-covering}, a simple but
general framework for redundancy-aware context engineering. Directed
information (DI), a causal analogue of mutual information, measures asymmetric
predictiveness between chunks. If $\operatorname{DI}_{i \to j} \ge H(C_j) -
\gamma$, then $C_i$ suffices to represent $C_j$ up to $\gamma$ bits. Building
on this criterion, we formulate context selection as a $\gamma$-cover problem
and propose a greedy algorithm with provable guarantees: it preserves query
information within bounded slack, inherits $(1+\ln n)$ and $(1-1/e)$
approximations from submodular set cover, and enforces a diversity margin.
Importantly, building the $\gamma$-cover is \emph{query-agnostic}: it incurs no
online cost and can be computed once offline and amortized across all queries.
Experiments on HotpotQA show that $\gamma$-covering consistently improves over
BM25, a competitive baseline, and provides clear advantages in hard-decision
regimes such as context compression and single-slot prompt selection. These
results establish DI $\gamma$-covering as a principled, self-organizing
backbone for modern LLM pipelines.

</details>


### [2] [An Adaptive cmWave/FR3 Channel Sounder for Integrated Sensing and Communication](https://arxiv.org/abs/2510.00257)
*K. F. Nieman,O. Kanhere,R. Shiu,W. Xu,C. Duan,S. S. Ghassemzadeh*

Main category: cs.IT

TL;DR: 本文介绍了一种先进的信道探测系统，适用于各种蜂窝部署场景的感知和传播实验，具有高适应性、高分辨率和高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够适应各种室内外测量场景的通用信道探测系统，支持双定向信道探测、高速车载通信以及集成通信与感知实验。

Method: 设计具有2.5 ns延迟分辨率、170 dB路径损耗测量能力的系统，能够在0.9 ms内测量360度功率-角度-延迟剖面，并通过更换RF前端天线实现不同频段的重新配置。

Result: 该系统展现出卓越的适应性、高分辨率和灵敏度，成为室内外测量活动中不可或缺的工具。

Conclusion: 该多功能信道探测系统为各种蜂窝部署场景提供了强大的测量能力，特别适用于双定向信道探测、高速车载通信和集成通信感知实验。

Abstract: In this paper, we present an advanced channel sounding system designed for
sensing and propagation experiments in all types of cellular deployment
scenarios. The system's exceptional adaptability, high resolution, and
sensitivity makes it an invaluable tool for utilization in a variety of indoor
and outdoor measurement campaigns. The sounder has a 2.5 ns delay resolution,
170 dB path loss measurement capability and is able to measure a
{360\textdegree} power-angular delay profile of the channel in less than 0.9
ms. Additionally, the system can be easily reconfigured to measure different
frequency bands by changing the RF front-end antennas. This versatile sounder
is suitable for double directional channel sounding, high-speed vehicular
experiments such as vehicle-to-vehicle and vehicle-to-infrastructure
communications, and integrated communication and sensing experiments.

</details>


### [3] [Indoor-Office Large-Scale Wireless Channel Characterization in cmWave/FR3 Spectrum](https://arxiv.org/abs/2510.00269)
*O. Kanhere,K. F. Nieman,S. S. Ghassemzadeh*

Main category: cs.IT

TL;DR: 本文通过6.9、8.3和14.5 GHz频段的广泛实验，研究了商业办公楼内不同室内环境的信道参数特性。


<details>
  <summary>Details</summary>
Motivation: 研究厘米波频段在多样化室内办公环境中的无线信号衰减和色散特性，为改善商业建筑内的网络设计和性能提供依据。

Method: 在商业办公楼四层楼的不同室内环境（隔间、会议室、走廊、实验室）进行广泛的信道测量，建模路径损耗、阴影衰落、延迟扩展和角度扩展。

Result: 获得了厘米波频段在多样化室内环境中的信道参数特性数据，揭示了无线信号在不同室内设置中的衰减和色散特征。

Conclusion: 研究结果为厘米波频段室内网络设计和性能优化提供了重要参考，有助于改善商业建筑内的无线通信系统。

Abstract: This paper presents comprehensive findings on the characterization of Indoor
Hotspot channel parameters, derived from an extensive experimental campaign
conducted at 6.9, 8.3, and 14.5 GHz in a commercial office building. Extensive
measurements were carried out in diverse indoor office settings, including
cubicles, conference rooms, hallways, and laboratory spaces across four floors.
The path loss, shadow fading, delay spread, and angular spread was modeled. Our
results offer significant insights into the attenuation and dispersion
characteristics of wireless signals in diverse indoor settings in the
centimeter-wave frequency band, and can be used for improving indoor network
design and performance in commercial buildings.

</details>


### [4] [cmWave/FR3 Large-Scale Channel Characterization for Urban Macro/Micro and Suburban Environments](https://arxiv.org/abs/2510.00275)
*K. F. Nieman,O. Kanhere,S. S. Ghassemzadeh*

Main category: cs.IT

TL;DR: 本文在7-15 GHz厘米波频段对城市宏/微小区和郊区环境的大规模信道进行了全面表征，分析了路径损耗、大尺度衰落和角度信道统计特性。


<details>
  <summary>Details</summary>
Motivation: 研究厘米波频段在不同环境下的信道特性，为下一代无线网络的规划和设计提供基础数据。

Method: 在7-15 GHz频段对城市宏/微小区和郊区环境进行大规模信道测量，分析路径损耗、大尺度衰落和角度统计特性。

Result: 城市环境由于密集障碍物导致更高的路径损耗和时延扩展，郊区环境路径损耗相对较低但变异性较大。提出了改进的信道预测和系统设计模型。

Conclusion: 研究结果为网络规划者和工程师提供了有价值的见解，有助于开发更高效、自适应的通信策略，推动下一代无线网络的发展。

Abstract: This study delves into the comprehensive characterization of large-scale
channels at centimeter wave frequencies 7-15 GHz for urban macro/micro and
suburban environments. Path-loss, large-scale fading, and angular channel
statistics are presented. Urban environments exhibited higher path loss and
delay spread due to dense obstacles, whereas suburban areas showed relatively
lower path loss but significant variability due to fewer but larger
obstructions. The findings provide valuable insights for network planners and
engineers, aiding in the development of more efficient and adaptive
communication strategies. Enhanced models for channel prediction and system
design are proposed, contributing to the advancement of next-generation
wireless networks.

</details>


### [5] [On the Achievable Performance in the presence of Multiple Path Interference for Intra Data Center applications](https://arxiv.org/abs/2510.00638)
*Wing Chau Ng,Scott Yam*

Main category: cs.IT

TL;DR: 首次提出了PAM4信号在存在多径干扰情况下的可达到误码率的精确解析形式，考虑了理想的多径干扰估计和补偿。


<details>
  <summary>Details</summary>
Motivation: 在PAM4通信系统中，多径干扰(MPI)是影响系统性能的关键因素，需要准确分析其影响并找到有效的补偿方法。

Method: 提出了一个分析模型，考虑理想的多径干扰估计和补偿条件，推导出PAM4系统误码率的精确解析表达式。

Result: 得到了PAM4系统在多径干扰条件下的可达到误码率的精确解析形式，为系统性能评估提供了理论基础。

Conclusion: 该研究为PAM4通信系统在多径干扰环境下的性能分析和优化提供了重要的理论工具。

Abstract: An accurate analytical form of the achievable bit error rate in the presence
of multipath interference (MPI) is proposed for PAM4 for the first time, taking
into account an ideal MPI estimate and compensation.

</details>


### [6] [OTFS for Joint Radar and Communication: Algorithms, Prototypes, and Experiments](https://arxiv.org/abs/2510.00668)
*Xiaojuan Zhang,Yonghong Zeng,Francois Chin Po Shin*

Main category: cs.IT

TL;DR: 提出基于OTFS信号的联合雷达通信系统，具备快速雷达感知算法、自干扰消除功能，可检测目标距离速度、监测人体生命体征，并能区分人与非人目标。


<details>
  <summary>Details</summary>
Motivation: 开发能够同时进行通信和雷达感知的集成系统，利用OTFS信号的优势实现高效的目标检测和生命体征监测。

Method: 采用OTFS通信信号进行快速雷达感知，结合自干扰消除技术；提出基于信号处理和机器学习的两种目标分类方法；基于软件定义无线电技术开发原型系统。

Result: 原型系统在人类和移动机器人场景中有效检测距离、速度和生命体征，并成功区分人与非人目标。

Conclusion: 所提出的JRC系统能够有效集成雷达感知和通信功能，在目标检测、生命体征监测和目标分类方面表现出良好性能。

Abstract: We propose an Joint Radar and Communication (JRC) system that utilizes the
Orthogonal Time Frequency Space (OTFS) signals. The system features a fast
radar sensing algorithm for detecting target range and speed by using the OTFS
communication signals, and a self-interference cancellation for enhanced
multi-target separation. In addition to target detection, we propose methods
for monitoring human vital signs, such as breathing rate and heartbeat.
Furthermore, we explore two approaches for distinguishing between human and
nonhuman targets: one based on signal processing and the other based on machine
learning. We have developed a prototype JRC system using the software-defined
radio (SDR) technology. Experimental results are shown to demonstrate the
effectiveness of the prototype in detecting range, speed, and vital signs in
both human and mobile robot scenarios, as well as in distinguishing between
human and non-human targets.

</details>


### [7] [Layered Normalized Min-Sum Decoding with Bit Flipping for FDPC Codes](https://arxiv.org/abs/2510.01019)
*Niloufar Hosseinzadeh,Mohsen Moradi,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 提出了一种用于FDPC码的分层归一化最小和(LNMS)译码算法，结合伴随式引导比特翻转(SGBF)方法，显著提升了译码性能。


<details>
  <summary>Details</summary>
Motivation: FDPC码在高码率场景下比5G标准中的LDPC码性能更好，但需要更高效的译码算法来充分发挥其潜力。

Method: 使用冲突图着色进行分层调度，在译码失败时激活SGBF方法，通过结合LLR幅度和伴随式错误计数的可靠性度量识别不可靠比特，生成候选序列并重新译码。

Result: 在FDPC(256,192)码上，提出的译码器在FER=10^-3时比单独LNMS译码获得约0.5dB编码增益，比极化码和5G-LDPC码获得0.75-1.5dB增益。

Conclusion: 所提出的LNMS-SGBF译码器显著提升了FDPC码的纠错性能，在高码率场景下优于现有先进编码方案。

Abstract: Fair-density parity-check (FDPC) codes have been recently introduced
demonstrating improved performance compared to low-density parity-check (LDPC)
codes standardized in 5G systems particularly in high-rate regimes. In this
paper, we introduce a layered normalized min-sum (LNMS) message-passing
decoding algorithm for the FDPC codes. We also introduce a syndrome-guided bit
flipping (SGBF) method to enhance the error-correction performance of our
proposed decoder. The LNMS decoder leverages conflict graph coloring for
efficient layered scheduling, enabling faster convergence by grouping
non-conflicting check nodes and updating variable nodes immediately after each
layer. In the event of decoding failure, the SGBF method is activated,
utilizing a novel reliability metric that combines log-likelihood ratio (LLR)
magnitudes and syndrome-derived error counts to identify the least reliable
bits. A set of candidate sequences is then generated by performing single-bit
flips at these positions, with each candidate re-decoded via LNMS. The optimal
candidate is selected based on the minimum syndrome weight. Extensive
simulation results demonstrate the superiority of the proposed decoder.
Numerical simulations on FDPC$(256,192)$ code with a bit-flipping set size of
$T = 128$ and a maximum of $5$ iterations demonstrate that the proposed decoder
achieves approximately a $0.5\,\mathrm{dB}$ coding gain over standalone LNMS
decoding at a frame error rate (FER) of $10^{-3}$, while providing coding gains
of $0.75-1.5\,\mathrm{dB}$ over other state-of-the-art codes including polar
codes and 5G-LDPC codes at the same length and rate and also under belief
propagation decoding.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [8] [WaveMind: Towards a Conversational EEG Foundation Model Aligned to Textual and Visual Modalities](https://arxiv.org/abs/2510.00032)
*Ziyi Zeng,Zhenyang Cai,Yixi Cai,Xidong Wang,Junying Chen,Rongsheng Wang,Yipeng Liu,Siqi Cai,Benyou Wang,Zhiguo Zhang,Haizhou Li*

Main category: eess.SP

TL;DR: 该论文提出了一种使用多模态大语言模型解释脑电图信号的新方法，通过将EEG信号和对应模态映射到统一语义空间来解决跨模态表示学习问题，并构建了首个用于指令调优的跨任务EEG数据集。


<details>
  <summary>Details</summary>
Motivation: 脑电图信号同时编码认知过程和内在神经状态，这种复杂性导致EEG配对数据模态不匹配，阻碍了有效的跨模态表示学习。

Method: 通过将EEG信号和对应模态映射到统一语义空间，并引入WaveMind-Instruct-338k数据集进行指令调优，实现广义解释。

Result: 所得模型在四个下游任务中展现出强大的分类准确性，同时支持灵活、开放式的对话。

Conclusion: 该方法为神经科学研究和通用EEG模型开发提供了有价值的见解。

Abstract: Electroencephalography (EEG) interpretation using multimodal large language
models (MLLMs) offers a novel approach for analyzing brain signals. However,
the complex nature of brain activity introduces critical challenges: EEG
signals simultaneously encode both cognitive processes and intrinsic neural
states, creating a mismatch in EEG paired-data modality that hinders effective
cross-modal representation learning. Through a pivot investigation, we uncover
complementary relationships between these modalities. Leveraging this insight,
we propose mapping EEG signals and their corresponding modalities into a
unified semantic space to achieve generalized interpretation. To fully enable
conversational capabilities, we further introduce WaveMind-Instruct-338k, the
first cross-task EEG dataset for instruction tuning. The resulting model
demonstrates robust classification accuracy while supporting flexible,
open-ended conversations across four downstream tasks, thereby offering
valuable insights for both neuroscience research and the development of
general-purpose EEG models.

</details>


### [9] [Standardized Machine-Readable Point-Data Format for Consolidating Wireless Propagation Across Environments, Frequencies, and Institutions](https://arxiv.org/abs/2510.00141)
*Dipankar Shakya,Naveed A. Abbasi,Mingjun Ying,Isha Jariwala,Jason J. Qin,Ishaan S. Gupte,Bridget Meier,Guanyue Qian,Daniel Abraham,Theodore S. Rappaport,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 本文提出了一种用于无线电传播测量的标准化点数据格式，旨在解决不同机构间测量数据格式不统一的问题，促进全球标准化和数据共享。


<details>
  <summary>Details</summary>
Motivation: 6G新频谱需求推动了全球对新兴频段无线电传播测量的兴趣，但缺乏标准化的机器可读数据格式来整合不同机构和频率的测量结果，阻碍了全球标准化进程。

Method: 引入标准化的点数据格式，结合环境地图和测量摘要元数据表，使用关键参数的结构化表示来整合来自不同来源的数据。

Result: 使用纽约大学142GHz和南加州大学145GHz两个独立亚太赫兹城市微蜂窝测量数据验证了该标准的有效性，通过联合路径损耗分析获得了更精确的路径损耗指数估计。

Conclusion: 采用这种简单统一的格式将加速信道模型开发，建立多机构数据集，并为AI/ML应用提供来自多个来源的可靠训练数据。

Abstract: The necessity of new spectrum for 6G has intensified global interest in radio
propagation measurements across emerging frequency bands, use cases, and
antenna types. These measurements are vital for understanding radio channel
properties in diverse environments, and involve time-consuming and expensive
campaigns. A major challenge for the effective utilization of propagation
measurement data has been the lack of a standardized format for reporting and
archiving results. Although organizations such as NIST, NGA, and 3GPP have made
commendable efforts for data pooling, a unified machine-readable data format
for consolidating measurements across different institutions and frequencies
remains a missing piece in advancing global standardization efforts. This paper
introduces a standardized point-data format for radio propagation measurements
and demonstrates how institutions may merge disparate campaigns into a common
format. This data format, alongside an environmental map and a measurement
summary metadata table, enables integration of data from disparate sources by
using a structured representation of key parameters. Here, we show the efficacy
of the point-data format standard using data gathered from two independent
sub-THz urban microcell (UMi) campaigns: 142 GHz measurements at New York
University (NYU) and 145 GHz measurements at the University of Southern
California (USC). A joint path loss analysis using the close-in path loss model
(1 m ref. distance) yields a refined estimate of the path loss exponent (PLE)
employing the proposed standard to pool measurements. Other statistics such as
RMS delay spread and angular spread are also determined using a joint
point-data table. Adopting this simple, unified format will accelerate channel
model development, build multi-institutional datasets, and feed AI/ML
applications with reliable training data in a common format from many sources.

</details>


### [10] [Site-Specific Beam Learning for Full-Duplex Massive MIMO Wireless Systems](https://arxiv.org/abs/2510.00342)
*Samuel Li,Ian P. Roberts*

Main category: eess.SP

TL;DR: 提出了一种无需显式自干扰信道估计的波束学习框架，通过设计波束码本获取隐式信道知识，利用深度学习网络合成全双工操作的发射和接收波束。


<details>
  <summary>Details</summary>
Motivation: 现有基于波束成形的全双工解决方案需要显式估计自干扰信道，在毫米波和大规模MIMO系统中导频开销过高，限制了实际应用，特别是在快速衰落条件下。

Method: 设计波束码本获取隐式信道知识，然后通过深度学习网络处理这些知识来合成全双工操作的发射和接收波束。

Result: 仿真结果表明，该技术能使全双工基站构建低自干扰且高SNR的服务波束，相比显式自干扰信道估计减少了75-97%的测量次数。

Conclusion: 提出的波束学习框架有效解决了全双工系统中自干扰信道估计的高开销问题，为毫米波和大规模MIMO系统的全双工操作提供了实用解决方案。

Abstract: Existing beamforming-based full-duplex solutions for multi-antenna wireless
systems often rely on explicit estimation of the self-interference channel. The
pilot overhead of such estimation, however, can be prohibitively high in
millimeter-wave and massive MIMO systems, thus limiting the practicality of
existing solutions, especially in fast-fading conditions. In this work, we
present a novel beam learning framework that bypasses explicit
self-interference channel estimation by designing beam codebooks to efficiently
obtain implicit channel knowledge that can then be processed by a deep learning
network to synthesize transmit and receive beams for full-duplex operation.
Simulation results using ray-tracing illustrate that our proposed technique can
allow a full-duplex base station to craft serving beams that couple low
self-interference while delivering high SNR, with 75-97% fewer measurements
than would be required for explicit estimation of the self-interference
channel.

</details>


### [11] [A Point Process Model of Skin Conductance Responses in a Stroop Task for Predicting Depression and Suicidal Ideation](https://arxiv.org/abs/2510.00422)
*Kleanthis Avramidis,Myzelle Hughes,Idan A Blank,Dani Byrd,Assal Habibi,Takfarinas Medani,Richard M Leahy,Shrikanth Narayanan*

Main category: eess.SP

TL;DR: 使用皮肤电活动数据建模抑郁和自杀意念相关的交感神经唤醒动态，通过点过程模型提取特征，在抑郁症分类中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 准确识别心理健康生物标志物可以实现早期检测和客观评估精神健康问题，特别是抑郁和自杀意念。

Method: 分析情绪Stroop任务中的皮肤电活动，将皮肤电导反应时间建模为点过程，其条件强度受刺激效价、反应时间和准确率等任务变量调节，然后用机器学习分类器进行抑郁症分类。

Result: 模型参数编码了与抑郁症状相关的有意义的生理差异，在分类性能上优于传统的特征提取方法。

Conclusion: 基于点过程建模的方法能够有效捕捉抑郁相关的生理动态特征，为心理健康评估提供了更优的生物标志物。

Abstract: Accurate identification of mental health biomarkers can enable earlier
detection and objective assessment of compromised mental well-being. In this
study, we analyze electrodermal activity recorded during an Emotional Stroop
task to capture sympathetic arousal dynamics associated with depression and
suicidal ideation. We model the timing of skin conductance responses as a point
process whose conditional intensity is modulated by task-based covariates,
including stimulus valence, reaction time, and response accuracy. The resulting
subject-specific parameter vector serves as input to a machine learning
classifier for distinguishing individuals with and without depression. Our
results show that the model parameters encode meaningful physiological
differences associated with depressive symptomatology and yield superior
classification performance compared to conventional feature extraction methods.

</details>


### [12] [Investigation of Using Non-Contact Electrodes for Fetal ECG Monitoring](https://arxiv.org/abs/2510.00550)
*Tai Le,Hau Luu,Loan Pham-Nguyen,Hung Viet-Dao,Duc Nguyen Minh,Afshan B. Hameed,Hoang Nguyen,Liem Thanh Nguyen,Huy-Dung Han,Hung Cao*

Main category: eess.SP

TL;DR: 开发了一种使用新型非接触电极的胎儿心电图监测系统，可通过衣物记录胎儿/母亲心电图信号，提高测量舒适度，并集成在孕妇腰带中。


<details>
  <summary>Details</summary>
Motivation: 解决偏远和资源匮乏地区产前护理的挑战，包括医疗专业人员缺乏和可及性限制，同时提高测量舒适度。

Method: 使用新型非接触电极通过衣物记录胎儿/母亲心电图信号，系统集成在孕妇腰带中，包含数据采集和数据传输模块，并与传统湿电极进行性能比较。

Result: 新型非接触电极与传统湿电极性能相当，初步可行性研究（n=10，孕25-32周）证明了系统的性能、可用性和安全性。

Conclusion: 该系统为改善产前护理提供了可行的解决方案，特别是在资源有限的环境中，具有实际应用潜力。

Abstract: Regular physiological monitoring of maternal and fetal parameters is
indispensable for ensuring safe outcomes during pregnancy and parturition.
Fetal electrocardiogram (fECG) assessment is crucial to detect fetal distress
and developmental anomalies. Given challenges of prenatal care due to the lack
of medical professionals and the limit of accessibility, especially in remote
and resource-poor areas, we develop a fECG monitoring system using novel
non-contact electrodes (NCE) to record the fetal/maternal ECG (f/mECG) signals
through clothes, thereby improving the comfort during measurement. The system
is designed to be incorporated inside a maternity belt with data acquisition,
data transmission module as well as novel NCEs. Thorough characterizations were
carried out to evaluate the novel NCE against traditional wet electrodes (i.e.,
Ag/AgCl electrodes), showing comparable performance. A successful {preliminary
pilot feasibility study} conducted with pregnant women (n = 10) between 25 and
32 weeks of gestation demonstrates the system's performance, usability and
safety.

</details>


### [13] [Geometric Spatio-Spectral Total Variation for Hyperspectral Image Denoising and Destriping](https://arxiv.org/abs/2510.00562)
*Shingo Takemoto,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出了一种新的正则化方法GeoSSTV，用于高光谱图像去噪和去条纹，通过几何一致的总变分公式在保留圆形结构和斜边方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像常受各种噪声影响，现有基于总变分的方法存在阶梯伪影和缺乏旋转不变性的问题，难以准确恢复圆形结构和斜边。

Method: 引入几何一致的总变分公式，以欧几里得方式测量所有方向的变化，并基于预条件原始对偶分裂方法开发高效算法。

Result: 在受混合噪声污染的高光谱图像上的实验结果表明，该方法优于现有方法。

Conclusion: GeoSSTV方法能有效去除噪声同时保留图像结构特征，在高光谱图像处理中具有优越性能。

Abstract: This article proposes a novel regularization method, named Geometric
Spatio-Spectral Total Variation (GeoSSTV), for hyperspectral (HS) image
denoising and destriping. HS images are inevitably affected by various types of
noise due to the measurement equipment and environment. Total Variation
(TV)-based regularization methods that model the spatio-spectral piecewise
smoothness inherent in HS images are promising approaches for HS image
denoising and destriping. However, existing TV-based methods are based on
classical anisotropic and isotropic TVs, which cause staircase artifacts and
lack rotation invariance, respectively, making it difficult to accurately
recover round structures and oblique edges. To address this issue, GeoSSTV
introduces a geometrically consistent formulation of TV that measures
variations across all directions in a Euclidean manner. Through this
formulation, GeoSSTV removes noise while preserving round structures and
oblique edges. Furthermore, we formulate the HS image denoising problem as a
constrained convex optimization problem involving GeoSSTV and develop an
efficient algorithm based on a preconditioned primal-dual splitting method.
Experimental results on HS images contaminated with mixed noise demonstrate the
superiority of the proposed method over existing approaches.

</details>


### [14] [Radiation Pattern Reconfigurable FAS-Empowered Interference-Resilient UAV Communication](https://arxiv.org/abs/2510.00581)
*Zhuoran Li,Zhen Gao,Boyu Ning,Zhaocheng Wang*

Main category: eess.SP

TL;DR: 提出了一种基于辐射模式可重构流体天线系统的无人机抗干扰通信方案，通过可重构像素天线技术提高角度分辨率，提升频谱效率和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 无人机广泛应用推动了反制非法飞行的技术发展，但合法无人机对非法干扰的抵抗能力研究不足，需要提升无人机通信的抗干扰性能。

Method: 设计专用辐射模式，提出低存储开销的正交匹配追踪多测量向量算法进行到达角估计，利用傅里叶变换实现维度缩减，采用最大似然干扰到达角估计方法，并通过交替优化获得最优上行辐射模式和组合器。

Result: 综合仿真表明，所提方案在角度感知精度和频谱效率方面优于传统方法，存储需求降低1-2个数量级。

Conclusion: RPR-FAS方案能有效提升无人机通信的抗干扰能力和频谱效率，为合法无人机提供更好的干扰抵抗性能。

Abstract: The widespread use of uncrewed aerial vehicles (UAVs) has propelled the
development of advanced techniques on countering unauthorized UAV flights.
However, the resistance of legal UAVs to illegal interference remains
under-addressed. This paper proposes radiation pattern reconfigurable fluid
antenna systems (RPR-FAS)-empowered interference-resilient UAV communication
scheme. This scheme integrates the reconfigurable pixel antenna technology,
which provides each antenna with an adjustable radiation pattern. Therefore,
RPR-FAS can enhance the angular resolution of a UAV with a limited number of
antennas, thereby improving spectral efficiency (SE) and interference
resilience. Specifically, we first design dedicated radiation pattern adapted
from 3GPP-TR-38.901, where the beam direction and half power beamwidth are
tailored for UAV communications. Furthermore, we propose a low-storage-overhead
orthogonal matching pursuit multiple measurement vectors algorithm, which
accurately estimates the angle-of-arrival (AoA) of the communication link, even
in the single antenna case. Particularly, by utilizing the Fourier transform to
the radiation pattern gain matrix, we design a dimension-reduction technique to
achieve 1--2 order-of-magnitude reduction in storage requirements. Meanwhile,
we propose a maximum likelihood interference AoA estimation method based on the
law of large numbers, so that the SE can be further improved. Finally,
alternating optimization is employed to obtain the optimal uplink radiation
pattern and combiner, while an exhaustive search is applied to determine the
optimal downlink pattern, complemented by the water-filling algorithm for
beamforming. Comprehensive simulations demonstrate that the proposed schemes
outperform traditional methods in terms of angular sensing precision and
spectral efficiency.

</details>


### [15] [Machine Learning-based Path Loss Prediction in Suburban Environment in the Sub-6 GHz Band](https://arxiv.org/abs/2510.00696)
*Ferdaous Tarhouni,Muneer AlZubi,Mohamed-Slim Alouini*

Main category: eess.SP

TL;DR: 该论文研究使用机器学习模型预测路径损耗，在KAUST校园的sub-6 GHz频段验证了基于射线追踪的ML方法优于传统传播模型。


<details>
  <summary>Details</summary>
Motivation: 传统路径损耗预测方法缺乏灵活性和准确性，需要更有效的解决方案来支持无线通信系统的网络规划、天线设计和性能优化。

Method: 使用射线追踪技术生成合成数据集，训练多种机器学习模型（包括随机森林回归和K近邻算法），并与传统传播模型进行比较。

Result: 随机森林回归和K近邻算法在路径损耗预测中表现最佳，ML模型整体优于COST-231 Hata、Longley-Rice和Close-in等传统模型。

Conclusion: 基于射线追踪的机器学习方法为无线电波传播预测提供了一种有前景且经济高效的灵活解决方案。

Abstract: Accurate path loss (PL) prediction is crucial for successful network
planning, antenna design, and performance optimization in wireless
communication systems. Several conventional approaches for PL prediction have
been adopted, but they have been demonstrated to lack flexibility and accuracy.
In this work, we investigate the effectiveness of Machine Learning (ML) models
in predicting PL, particularly for the sub-6 GHz band in a suburban campus of
King Abdullah University of Science and Technology (KAUST). For training
purposes, we generate synthetic datasets using the ray-tracing simulation
technique. The feasibility and accuracy of the ML-based PL models are verified
and validated using both synthetic and measurement datasets. The random forest
regression (RFR) and the K-nearest neighbors (KNN) algorithms provide the best
PL prediction accuracy compared to other ML models. In addition, we compare the
performance of the developed ML-based PL models with the traditional
propagation models, including COST-231 Hata, Longley-Rice, and Close-in models.
The results show the superiority of the ML-based PL models compared to
conventional models. Therefore, the ML approach using the ray-tracing technique
can provide a promising and cost-effective solution for predicting and modeling
radio wave propagation in various scenarios in a flexible manner.

</details>


### [16] [Null-Shaping for Interference Mitigation in LEO Satellites Under Location Uncertainty](https://arxiv.org/abs/2510.00816)
*Fernando Moya Caceres,Akram Al-Hourani,Saman Atapattu,Kandeepan Sithamparanathan*

Main category: eess.SP

TL;DR: 本文提出了一种鲁棒零陷成形框架，通过将RFI位置不确定性的概率密度函数融入波束成形设计，增强LEO卫星通信对射频干扰的抑制能力。


<details>
  <summary>Details</summary>
Motivation: 随着频谱拥塞和地面干扰源位置不确定性的增加，射频干扰对低轨卫星通信上行链路的威胁日益严重，需要开发能应对位置不确定性的干扰抑制方法。

Method: 首先分析RFI位置地理不确定性如何转化为卫星观测的角度偏差，然后提出基于随机优化的鲁棒零陷成形框架，将RFI位置不确定性的概率密度函数融入波束成形设计。

Result: 通过包含真实卫星轨道动力学和各种RFI场景的广泛蒙特卡洛仿真，证明所提方法相比传统确定性设计显著提高了干扰抑制性能。

Conclusion: 所提出的鲁棒零陷成形框架能够有效应对RFI位置不确定性，显著提升LEO卫星通信系统的干扰抑制能力。

Abstract: Radio frequency interference (RFI) poses a growing challenge to satellite
communications, particularly in uplink channels of Low Earth Orbit (LEO)
systems, due to increasing spectrum congestion and uncertainty in the location
of terrestrial interferers. This paper addresses the impact of RFI source
position uncertainty on beamforming-based interference mitigation. First, we
analytically characterize how geographic uncertainty in RFI location translates
into angular deviation as observed from the satellite. Building on this, we
propose a robust null-shaping framework to increase resilience in the
communication links by incorporating the probability density function (PDF) of
the RFI location uncertainty into the beamforming design via stochastic
optimization. This allows adaptive shaping of the antenna array's nulling
pattern to enhance interference suppression under uncertainty. Extensive Monte
Carlo simulations, incorporating realistic satellite orbital dynamics and
various RFI scenarios, demonstrate that the proposed approach achieves
significantly improved mitigation performance compared to conventional
deterministic designs.

</details>


### [17] [Effectiveness of Reconfigurable Intelligent Surface in Multipath Fading Channel](https://arxiv.org/abs/2510.00838)
*Hasnul Hashim*

Main category: eess.SP

TL;DR: 提出了一种使用三个信道黑盒模拟单输入单输出可重构智能表面辅助信道的方法，通过射线追踪获得信道系数，验证了RIS性能随单元数量平方增长的理论模型。


<details>
  <summary>Details</summary>
Motivation: 需要开发一种准确模拟RIS辅助信道的方法，考虑地理地形、建筑形状和电磁特性，验证理论模型在实际场景中的适用性。

Method: 使用三个信道黑盒分别表示直接信号路径、发射到RIS路径和RIS反射路径，通过射线追踪获得复杂系数，考虑地面和建筑墙体的电磁特性，模拟反射和衍射射线。

Result: 接收功率呈现典型的多径衰落变化，在最佳位置RIS辅助信道仿真结果与理论模型吻合良好，性能随RIS单元数量平方增长，仿真结果验证了RIS靠近发射机或接收机部署的最佳位置。

Conclusion: 该方法能有效模拟RIS辅助信道，验证了理论模型的正确性，为RIS在实际部署中的位置优化提供了仿真依据。

Abstract: A method of simulating a single-input single-output reconfigurable
intelligent surface (RIS) assisted channel is presented using three channel
black boxes to represent the direct signal path, the transmit path to the RIS
and the reflected path from the RIS. The complex coefficients for each channel
box is obtained by ray tracing in a scenario with geographic terrain
information that also contains approximate building shapes. The electrical
characteristics of the ground and building walls were also accounted for in the
ray tracing function. Simulations were conducted with reflected rays only and
reflected rays together with diffracted rays. The received power exhibits
variations typical of multipath fading environments. In the best locations, the
RIS-assisted channel simulation result agrees well with theoretical models, the
performance increasing by the RIS size squared as the number of RIS elements is
increased. In the simplified theoretical model where the transmitter and
receiver are inline and the RIS orthogonal but much closer than the distance
between the former elements, the simulation results also corroborate best
deployment close the transmitter or the receiver with a U-shaped drop between
them.

</details>


### [18] [Agentic AI meets Neural Architecture Search: Proactive Traffic Prediction for AI-RAN](https://arxiv.org/abs/2510.00851)
*Abdelaziz Salama,Mohammed M. H. Qazzaz,Zeinab Nezami,Maryam Hafeez,Syed Ali Raza Zaidi*

Main category: eess.SP

TL;DR: 提出基于神经架构搜索的LSTM架构动态选择框架，用于O-RAN环境中的流量预测，实现计算复杂度降低70-75%的同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络需要智能流量预测来实现自主资源管理，O-RAN框架为嵌入机器学习智能提供了有前景的基础。

Method: 应用神经架构搜索框架，在O-RAN环境中动态选择和编排高效的LSTM架构，通过非实时RIC rApps进行架构优化，通过近实时RIC xApps进行实时推理。

Result: 轻量级模型在常规流量下达到R²≈0.91-0.93，复杂模型在关键场景下达到接近完美的精度（R²=0.989-0.996），NAS编排相比静态高性能模型减少70-75%计算复杂度。

Conclusion: 该方法能够在保持高预测精度的同时显著降低计算复杂度，支持在真实边缘环境中的可扩展部署。

Abstract: Next-generation wireless networks require intelligent traffic prediction to
enable autonomous resource management and handle diverse, dynamic service
demands. The Open Radio Access Network (O-RAN) framework provides a promising
foundation for embedding machine learning intelligence through its
disaggregated architecture and programmable interfaces. This work applies a
Neural Architecture Search (NAS)-based framework that dynamically selects and
orchestrates efficient Long Short-Term Memory (LSTM) architectures for traffic
prediction in O-RAN environments. Our approach leverages the O-RAN paradigm by
separating architecture optimisation (via non-RT RIC rApps) from real-time
inference (via near-RT RIC xApps), enabling adaptive model deployment based on
traffic conditions and resource constraints. Experimental evaluation across six
LSTM architectures demonstrates that lightweight models achieve $R^2 \approx
0.91$--$0.93$ with high efficiency for regular traffic, while complex models
reach near-perfect accuracy ($R^2 = 0.989$--$0.996$) during critical scenarios.
Our NAS-based orchestration achieves a 70-75\% reduction in computational
complexity compared to static high-performance models, while maintaining high
prediction accuracy when required, thereby enabling scalable deployment in
real-world edge environments.

</details>


### [19] [Graph Neural Networks in Large Scale Wireless Communication Networks: Scalability Across Random Geometric Graphs](https://arxiv.org/abs/2510.00896)
*Romina Garcia Camargo,Zhiyang Wang,Alejandro Ribeiro*

Main category: eess.SP

TL;DR: 该论文为图神经网络在无线网络中的可迁移性提供了理论保证，特别关注随机几何图模型，并通过功率分配任务验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 无线网络复杂性增加促使从传统方法转向基于学习的方法，图神经网络因其天然适合表示无线网络而受到关注。虽然实证研究表明GNN在无线策略中具有良好的可迁移性，但现有理论保证未能充分解释这一现象，特别是对于稀疏的无线网络图结构。

Method: 在随机几何图模型上建立形式化的理论框架，分析图神经网络的可迁移性特性，并通过功率分配任务的数值实验进行验证。

Result: 为图神经网络在无线网络中的可迁移性提供了理论保证，特别是在稀疏图结构条件下，并通过实验证实了理论分析的有效性。

Conclusion: 该研究填补了图神经网络在无线网络可迁移性理论分析的空白，为学习型无线网络策略的实际应用提供了理论基础。

Abstract: The growing complexity of wireless systems has accelerated the move from
traditional methods to learning-based solutions. Graph Neural Networks (GNNs)
are especially well-suited here, since wireless networks can be naturally
represented as graphs. A key property of GNNs is transferability: models
trained on one graph often generalize to much larger graphs with little
performance loss. While empirical studies have shown that GNN-based wireless
policies transfer effectively, existing theoretical guarantees do not capture
this phenomenon. Most works focus on dense graphs where node degrees scale with
network size, an assumption that fails in wireless systems. In this work, we
provide a formal theoretical foundation for transferability on Random Geometric
Graphs (RGGs), a sparse and widely used model of wireless networks. We further
validate our results through numerical experiments on power allocation, a
fundamental resource management task.

</details>


### [20] [A Robust Proactive Communication Strategy for Distributed Active Noise Control Systems](https://arxiv.org/abs/2510.00934)
*Junwei Ji,Dongyuan Shi,Zhengding Luo,Boxiang Wang,Ziyi Yang,Haowen Li,Woon-Seng Gan*

Main category: eess.SP

TL;DR: 提出了一种结合自适应-固定滤波器切换和混合梯度组合策略的鲁棒通信框架，用于分布式多通道有源噪声控制系统，在保持稳定性的同时实现接近集中式算法的降噪性能。


<details>
  <summary>Details</summary>
Motivation: 分布式多通道有源噪声控制系统将计算负载分配到多个处理节点，但通信开销会破坏算法稳定性和性能，需要解决这一挑战。

Method: 每个节点独立执行单通道FxLMS算法，监控降噪性能。当性能下降时，节点停止自适应算法，切换到固定滤波器并启动通信请求。交换的信息是当前控制滤波器与上次通信时滤波器之间的差异（即非通信期间的累积梯度总和）。接收到邻居累积梯度后，使用混合梯度组合方法更新控制滤波器，然后恢复自适应模式。

Result: 仿真结果表明，该方法在通信约束下实现了与集中式算法相当的降噪性能，同时保持了系统稳定性。

Conclusion: 所提出的主动通信策略和自适应-固定切换机制通过减轻通信问题引起的不稳定性风险，确保了系统鲁棒性，在真实分布式ANC场景中具有实际应用价值。

Abstract: Distributed multichannel active noise control (DMCANC) systems assign the
high computational load of conventional centralized algorithms across multiple
processing nodes, leveraging inter-node communication to collaboratively
suppress unwanted noise. However, communication overhead can undermine
algorithmic stability and degrade overall performance. To address this
challenge, we propose a robust communication framework that integrates
adaptive-fixed-filter switching and the mixed-gradient combination strategy. In
this approach, each node independently executes a single-channel filtered
reference least mean square (FxLMS) algorithm while monitoring real-time noise
reduction levels. When the current noise reduction performance degrades
compared to the previous state, the node halts its adaptive algorithm, switches
to a fixed filter, and simultaneously initiates a communication request. The
exchanged information comprises the difference between the current control
filter and the filter at the time of the last communication, equivalent to the
accumulated gradient sum during non-communication intervals. Upon receiving
neighboring cumulative gradients, the node employs a mixed-gradient combination
method to update its control filter, subsequently reverting to the adaptive
mode. This proactive communication strategy and adaptive-fixed switching
mechanism ensure system robustness by mitigating instability risks caused by
communication issues. Simulations demonstrate that the proposed method achieves
noise reduction performance comparable to centralized algorithms while
maintaining stability under communication constraints, highlighting its
practical applicability in real-world distributed ANC scenarios.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [21] [Enhancing Safety in Diabetic Retinopathy Detection: Uncertainty-Aware Deep Learning Models with Rejection Capabilities](https://arxiv.org/abs/2510.00029)
*Madhushan Ramalingam,Yaish Riaz,Priyanthi Rajamanoharan,Piyumi Dasanayaka*

Main category: eess.IV

TL;DR: 该论文研究糖尿病视网膜病变诊断中的不确定性感知深度学习模型，通过拒绝机制处理低置信度预测，在临床实践中实现延迟决策。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是主要致盲原因，深度学习模型在诊断中表现出色，但缺乏置信度指示会在临床环境中带来风险，需要不确定性感知模型来提高诊断可靠性。

Method: 采用变分贝叶斯模型，结合拒绝机制来拒绝低置信度预测，通过延迟决策在临床实践中实施。

Result: 结果显示预测覆盖率和覆盖可靠性之间存在权衡，变分贝叶斯模型在预测DR时采取更保守策略，拒绝不确定预测。模型在接受的预测上获得高准确率，但覆盖率降低。

Conclusion: 使用不确定性估计和选择性拒绝能够提高模型在安全关键诊断用例中的可靠性，在准确性和谨慎性之间存在明显权衡。

Abstract: Diabetic retinopathy (DR) is a major cause of visual impairment, and
effective treatment options depend heavily on timely and accurate diagnosis.
Deep learning models have demonstrated great success identifying DR from
retinal images. However, relying only on predictions made by models, without
any indication of model confidence, creates uncertainty and poses significant
risk in clinical settings. This paper investigates an alternative in
uncertainty-aware deep learning models, including a rejection mechanism to
reject low-confidence predictions, contextualized by deferred decision-making
in clinical practice. The results show there is a trade-off between prediction
coverage and coverage reliability. The Variational Bayesian model adopted a
more conservative strategy when predicting DR, subsequently rejecting the
uncertain predictions. The model is evaluated by means of important performance
metrics such as Accuracy on accepted predictions, the proportion of accepted
cases (coverage), the rejection-ratio, and Expected Calibration Error (ECE).
The findings also demonstrate a clear trade-off between accuracy and caution,
establishing that the use of uncertainty estimation and selective rejection
improves the model's reliability in safety-critical diagnostic use cases.

</details>


### [22] [Deep Learning-Based Pneumonia Detection from Chest X-ray Images: A CNN Approach with Performance Analysis and Clinical Implications](https://arxiv.org/abs/2510.00035)
*P K Dutta,Anushri Chowdhury,Anouska Bhattacharyya,Shakya Chakraborty,Sujatra Dey*

Main category: eess.IV

TL;DR: 该研究开发了一个基于卷积神经网络的深度学习系统，用于从胸部X光图像中自动检测肺炎，通过集成可分离卷积、批量归一化和dropout正则化等技术，实现了91%的准确率，并解决了临床实施中的数据隐私、模型可解释性等关键问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像系统中的集成已经改变了疾病检测和诊断过程，本研究旨在开发一个自动化的肺炎检测系统，提高诊断精度和速度。

Method: 使用卷积神经网络架构，集成可分离卷积、批量归一化和dropout正则化技术，应用数据增强和自适应学习率策略，在大量胸部X光图像上进行训练。

Result: 模型表现出卓越性能，准确率达到91%，并通过精度、召回率和F1分数等指标验证。

Conclusion: 该研究通过将机器学习输出与结构化医学知识框架集成，提高了AI诊断的可靠性，为临床环境中AI集成提供了更精确的自动化诊断方法。

Abstract: Deep learning integration into medical imaging systems has transformed
disease detection and diagnosis processes with a focus on pneumonia
identification. The study introduces an intricate deep learning system using
Convolutional Neural Networks for automated pneumonia detection from chest Xray
images which boosts diagnostic precision and speed. The proposed CNN
architecture integrates sophisticated methods including separable convolutions
along with batch normalization and dropout regularization to enhance feature
extraction while reducing overfitting. Through the application of data
augmentation techniques and adaptive learning rate strategies the model
underwent training on an extensive collection of chest Xray images to enhance
its generalization capabilities. A convoluted array of evaluation metrics such
as accuracy, precision, recall, and F1 score collectively verify the model
exceptional performance by recording an accuracy rate of 91. This study tackles
critical clinical implementation obstacles such as data privacy protection,
model interpretability, and integration with current healthcare systems beyond
just model performance. This approach introduces a critical advancement by
integrating medical ontologies with semantic technology to improve diagnostic
accuracy. The study enhances AI diagnostic reliability by integrating machine
learning outputs with structured medical knowledge frameworks to boost
interpretability. The findings demonstrate AI powered healthcare tools as a
scalable efficient pneumonia detection solution. This study advances AI
integration into clinical settings by developing more precise automated
diagnostic methods that deliver consistent medical imaging results.

</details>


### [23] [Deep Learning Approaches with Explainable AI for Differentiating Alzheimer Disease and Mild Cognitive Impairment](https://arxiv.org/abs/2510.00048)
*Fahad Mostafa,Kannon Hossain,Hafiz Khan*

Main category: eess.IV

TL;DR: 提出了一种混合深度学习集成框架，使用结构MRI进行阿尔茨海默病分类，在ADNI数据集上实现了99.21%的AD vs MCI准确率和91.0%的MCI vs NC准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期准确诊断对临床干预至关重要，特别是需要将其与轻度认知障碍区分开来。

Method: 使用灰质和白质切片作为输入，通过三个预训练CNN（ResNet50、NASNet、MobileNet）进行端到端微调，采用堆叠集成学习策略和元学习器进行模型组合优化。

Result: 在ADNI数据集上取得了最先进的性能：AD vs MCI准确率99.21%，MCI vs NC准确率91.0%，优于传统迁移学习和基线集成方法。

Conclusion: 该框架在神经退行性疾病诊断中具有稳健和可扩展的临床决策支持潜力，通过可解释AI技术提高了诊断的可解释性。

Abstract: Early and accurate diagnosis of Alzheimer Disease is critical for effective
clinical intervention, particularly in distinguishing it from Mild Cognitive
Impairment, a prodromal stage marked by subtle structural changes. In this
study, we propose a hybrid deep learning ensemble framework for Alzheimer
Disease classification using structural magnetic resonance imaging. Gray and
white matter slices are used as inputs to three pretrained convolutional neural
networks such as ResNet50, NASNet, and MobileNet, each fine tuned through an
end to end process. To further enhance performance, we incorporate a stacked
ensemble learning strategy with a meta learner and weighted averaging to
optimally combine the base models. Evaluated on the Alzheimer Disease
Neuroimaging Initiative dataset, the proposed method achieves state of the art
accuracy of 99.21% for Alzheimer Disease vs. Mild Cognitive Impairment and
91.0% for Mild Cognitive Impairment vs. Normal Controls, outperforming
conventional transfer learning and baseline ensemble methods. To improve
interpretability in image based diagnostics, we integrate Explainable AI
techniques by Gradient weighted Class Activation, which generates heatmaps and
attribution maps that highlight critical regions in gray and white matter
slices, revealing structural biomarkers that influence model decisions. These
results highlight the frameworks potential for robust and scalable clinical
decision support in neurodegenerative disease diagnostics.

</details>


### [24] [AI-Based Stroke Rehabilitation Domiciliary Assessment System with ST_GCN Attention](https://arxiv.org/abs/2510.00049)
*Suhyeon Lim,Ye-eun Kim,Andrew J. Choi*

Main category: eess.IV

TL;DR: 提出基于AI的家庭康复系统，通过RGB-D相机和可穿戴传感器捕捉中风患者动作，使用RAST-G@深度学习模型评估康复质量，提供个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 中风康复需要与日常生活结合的持续康复训练，现有家庭康复缺乏专业评估和反馈机制。

Method: 系统包含硬件采集设备、移动应用和AI服务器。使用ST-GCN提取骨骼特征，结合transformer时间注意力机制评估动作质量。构建NRC数据集，包含10种ADL和5种ROM活动。

Result: 在KIMORE和NRC数据集上，RAST-G@模型在MAD、RMSE和MAPE指标上优于基线方法。系统能提供以患者为中心的评估和监测反馈。

Conclusion: 该系统为家庭康复提供了可扩展的定量评估方法，支持一致的家庭康复监测。

Abstract: Effective stroke recovery requires continuous rehabilitation integrated with
daily living. To support this need, we propose a home-based rehabilitation
exercise and feedback system. The system consists of (1) hardware setup with
RGB-D camera and wearable sensors to capture Stroke movements, (2) a mobile
application for exercise guidance, and (3) an AI server for assessment and
feedback. When Stroke user exercises following the application guidance, the
system records skeleton sequences, which are then Assessed by the deep learning
model, RAST-G@. The model employs a spatio-temporal graph convolutional network
(ST-GCN) to extract skeletal features and integrates transformer-based temporal
attention to figure out action quality. For system implementation, we
constructed the NRC dataset, include 10 upper-limb activities of daily living
(ADL) and 5 range-of-motion (ROM) collected from stroke and non-disabled
participants, with Score annotations provided by licensed physiotherapists.
Results on the KIMORE and NRC datasets show that RAST-G@ improves over baseline
in terms of MAD, RMSE, and MAPE. Furthermore, the system provides user feedback
that combines patient-centered assessment and monitoring. The results
demonstrate that the proposed system offers a scalable approach for
quantitative and consistent domiciliary rehabilitation assessment.

</details>


### [25] [Latent Representation Learning from 3D Brain MRI for Interpretable Prediction in Multiple Sclerosis](https://arxiv.org/abs/2510.00051)
*Trinh Ngoc Huynh,Nguyen Duc Kien,Nguyen Hai Anh,Dinh Tran Hiep,Manuela Vaneckova,Tomas Uher,Jeroen Van Schependom,Stijn Denissen,Tran Quoc Long,Nguyen Linh Trung,Guy Nagels*

Main category: eess.IV

TL;DR: InfoVAE-Med3D是一种用于3D脑MRI的潜在表示学习方法，通过最大化图像与潜在变量之间的互信息，产生紧凑、结构化的嵌入，保留临床有意义的内容，在脑年龄和认知功能预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准统计模型和浅层机器学习方法缺乏能力，而大多数深度学习方法表现为黑盒，需要一种既能保持预测性能又具有可解释性的方法来分析认知衰退的生物标志物。

Method: 扩展InfoVAE方法，明确最大化图像与潜在变量之间的互信息，在两个队列上评估：大型健康对照组（n=6527）和临床多发性硬化数据集（n=904）。

Result: 学习的潜在变量支持准确的脑年龄和SDMT回归，保留关键医学属性，形成直观的聚类，在重建和下游预测任务中始终优于其他VAE变体。

Conclusion: InfoVAE-Med3D通过结合预测性能和可解释性，为基于MRI的生物标志物和神经系统疾病认知衰退的透明分析提供了实用路径。

Abstract: We present InfoVAE-Med3D, a latent-representation learning approach for 3D
brain MRI that targets interpretable biomarkers of cognitive decline. Standard
statistical models and shallow machine learning often lack power, while most
deep learning methods behave as black boxes. Our method extends InfoVAE to
explicitly maximize mutual information between images and latent variables,
producing compact, structured embeddings that retain clinically meaningful
content. We evaluate on two cohorts: a large healthy-control dataset (n=6527)
with chronological age, and a clinical multiple sclerosis dataset from Charles
University in Prague (n=904) with age and Symbol Digit Modalities Test (SDMT)
scores. The learned latents support accurate brain-age and SDMT regression,
preserve key medical attributes, and form intuitive clusters that aid
interpretation. Across reconstruction and downstream prediction tasks,
InfoVAE-Med3D consistently outperforms other VAE variants, indicating stronger
information capture in the embedding space. By uniting predictive performance
with interpretability, InfoVAE-Med3D offers a practical path toward MRI-based
biomarkers and more transparent analysis of cognitive deterioration in
neurological disease.

</details>


### [26] [DPsurv: Dual-Prototype Evidential Fusion for Uncertainty-Aware and Interpretable Whole-Slide Image Survival Prediction](https://arxiv.org/abs/2510.00053)
*Yucheng Xing,Ling Huang,Jingying Ma,Ruping Hong,Jiangdong Qiu,Pei Liu,Kai He,Huazhu Fu,Mengling Feng*

Main category: eess.IV

TL;DR: DPsurv是一个双原型全切片图像证据融合网络，用于癌症生存分析，提供不确定性感知的生存区间预测，并通过补丁原型分配图、组件原型和组件相对风险聚合实现预测可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有WSI生存分析方法存在可解释性有限和忽略异质性切片图像中预测不确定性的问题。

Method: 提出DPsurv网络，采用双原型设计和证据融合机制，输出不确定性感知的生存区间，并通过多种可视化工具实现预测解释。

Result: 在五个公开数据集上获得最高的平均一致性指数和最低的平均集成Brier分数，验证了方法的有效性和可靠性。

Conclusion: DPsurv在特征、推理和决策层面提供透明度，增强了模型的可信度和可解释性。

Abstract: Pathology whole-slide images (WSIs) are widely used for cancer survival
analysis because of their comprehensive histopathological information at both
cellular and tissue levels, enabling quantitative, large-scale, and
prognostically rich tumor feature analysis. However, most existing methods in
WSI survival analysis struggle with limited interpretability and often overlook
predictive uncertainty in heterogeneous slide images. In this paper, we propose
DPsurv, a dual-prototype whole-slide image evidential fusion network that
outputs uncertainty-aware survival intervals, while enabling interpretation of
predictions through patch prototype assignment maps, component prototypes, and
component-wise relative risk aggregation. Experiments on five publicly
available datasets achieve the highest mean concordance index and the lowest
mean integrated Brier score, validating the effectiveness and reliability of
DPsurv. The interpretation of prediction results provides transparency at the
feature, reasoning, and decision levels, thereby enhancing the trustworthiness
and interpretability of DPsurv.

</details>


### [27] [Adapting Large Language Models to Mitigate Skin Tone Biases in Clinical Dermatology Tasks: A Mixed-Methods Study](https://arxiv.org/abs/2510.00055)
*Kiran Nijjer,Ryan Bui,Derek Jiu,Adnan Ahmed,Peter Wang,Benjamin Liu,Kevin Zhu,Lilly Zhu*

Main category: eess.IV

TL;DR: SkinGPT-4在深色皮肤上的诊断准确性受限，存在肤色偏见。通过微调模型和公平性分析，开发了在六种皮肤类型上表现公平的自定义皮肤疾病分类模型。


<details>
  <summary>Details</summary>
Motivation: 解决SkinGPT-4等大型视觉语言模型在深色皮肤上的诊断性能偏差问题，提升在医疗服务不足社区的临床工作流程公平性。

Method: 使用SCIN数据集评估SkinGPT-4在常见皮肤疾病上的性能偏差，基于SkinGPT-4骨干网络开发微调模型，采用公平性指标（人口统计均等、均等化几率）分析肤色间差异。

Result: SkinGPT-4在肤色间平均人口统计均等为0.10，最浅与最深肤色间差异达0.10-0.15。自定义模型在视觉相似疾病对上平均F1、精确度和AUROC分别为0.75、0.78、0.78，公平性分析显示平均人口统计均等为0.75。

Conclusion: 大型语言模型在深色皮肤上表现较弱，存在模型偏见和幻觉问题。通过现有骨干网络训练准确、公平的模型是有效的解决方案。

Abstract: SkinGPT-4, a large vision-language model, leverages annotated skin disease
images to augment clinical workflows in underserved communities. However, its
training dataset predominantly represents lighter skin tones, limiting
diagnostic accuracy for darker tones. Here, we evaluated performance biases in
SkinGPT-4 across skin tones on common skin diseases, including eczema,
allergic-contact dermatitis, and psoriasis using the open-sourced SCIN dataset.
We leveraged the SkinGPT-4 backbone to develop finetuned models for custom skin
disease classification tasks and explored bias mitigation strategies. Clinical
evaluation by board-certified dermatologists on six relevant skin diseases from
300 SCIN cases assessed images for diagnostic accuracy, informativity,
physician utility, and patient utility. Model fairness metrics, including
demographic parity and equalized odds, were calculated across skin tones.
SkinGPT-4 achieved an average demographic parity of 0.10 across Fitzpatrick
types, with notable differences of 0.10-0.15 between lightest and darkest tones
across evaluation metrics. Model hallucinations in artifacts and anatomy
occurred at a rate of 17.8. Our customized models achieved average F1,
precision, and AUROC of 0.75, 0.78, and 0.78 across visually similar disease
pairs. Fairness analysis showed an average demographic parity of 0.75, with a
maximum disparity of 0.21 across skin tones. The best model achieved parity
scores of 0.83, 0.83, 0.76, 0.89, 0.90, and 0.90 for Fitzpatrick I-VI,
indicating robust fairness. Large language models such as SkinGPT-4 showed
weaker performance on darker tones. Model biases exist across evaluation
criteria, and hallucinations may affect diagnostic efficacy. These findings
demonstrate the efficacy of training accurate, fair models using existing
backbones for custom skin disease classification.

</details>


### [28] [Variable Rate Image Compression via N-Gram Context based Swin-transformer](https://arxiv.org/abs/2510.00058)
*Priyanka Mudgal,Feng Liu*

Main category: eess.IV

TL;DR: 提出了一种基于N-gram上下文的Swin Transformer图像压缩方法，实现了单模型可变码率压缩，通过扩展感受野提升了高分辨率图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决Swin Transformer在高分辨率图像重建中由于感受野限制而忽略更大区域的问题，提升像素恢复的质量。

Method: 将N-gram上下文融入Swin Transformer，增强相邻窗口间的上下文感知能力，扩展像素恢复的考虑区域。

Result: 在现有可变码率学习图像压缩技术上BD-Rate提升了-5.86%，显著改善了感兴趣区域(ROI)的图像质量。

Conclusion: 该方法特别适用于制造和工业视觉系统等对象聚焦应用，通过增强上下文感知能力有效提升了图像压缩质量。

Abstract: This paper presents an N-gram context-based Swin Transformer for learned
image compression. Our method achieves variable-rate compression with a single
model. By incorporating N-gram context into the Swin Transformer, we overcome
its limitation of neglecting larger regions during high-resolution image
reconstruction due to its restricted receptive field. This enhancement expands
the regions considered for pixel restoration, thereby improving the quality of
high-resolution reconstructions. Our method increases context awareness across
neighboring windows, leading to a -5.86\% improvement in BD-Rate over existing
variable-rate learned image compression techniques. Additionally, our model
improves the quality of regions of interest (ROI) in images, making it
particularly beneficial for object-focused applications in fields such as
manufacturing and industrial vision systems.

</details>


### [29] [Survey of AI-Powered Approaches for Osteoporosis Diagnosis in Medical Imaging](https://arxiv.org/abs/2510.00061)
*Abdul Rahman,Bumshik Lee*

Main category: eess.IV

TL;DR: 这篇综述论文提出了一个三轴框架，将骨质疏松症的成像模态、临床任务和AI方法相结合，旨在统一该领域的研究现状。


<details>
  <summary>Details</summary>
Motivation: 骨质疏松症在全球范围内严重影响骨骼健康，早期检测可以预防脆性骨折。虽然AI方法已应用于常规医学影像分析，但相关文献分散，需要系统整合。

Method: 采用PRISMA指导的系统搜索策略，构建三轴分类框架（成像模态×临床任务×AI方法），涵盖传统机器学习、CNN、Transformer、自监督学习和可解释AI等方法。

Result: 通过跨研究综合分析，识别了数据稀缺性、外部验证和可解释性等关键问题，并提供了该领域的现状概述。

Conclusion: 本综述为AI科学家、医学影像研究人员和肌肉骨骼临床医生提供了清晰的指导，以加速骨质疏松护理中严谨、以患者为中心的创新。

Abstract: Osteoporosis silently erodes skeletal integrity worldwide; however, early
detection through imaging can prevent most fragility fractures. Artificial
intelligence (AI) methods now mine routine Dual-energy X-ray Absorptiometry
(DXA), X-ray, Computed Tomography (CT), and Magnetic Resonance Imaging (MRI)
scans for subtle, clinically actionable markers, but the literature is
fragmented. This survey unifies the field through a tri-axial framework that
couples imaging modalities with clinical tasks and AI methodologies (classical
machine learning, convolutional neural networks (CNNs), transformers,
self-supervised learning, and explainable AI). Following a concise clinical and
technical primer, we detail our Preferred Reporting Items for Systematic
Reviews and Meta-Analyses (PRISMA)-guided search strategy, introduce the
taxonomy via a roadmap figure, and synthesize cross-study insights on data
scarcity, external validation, and interpretability. By identifying emerging
trends, open challenges, and actionable research directions, this review
provides AI scientists, medical imaging researchers, and musculoskeletal
clinicians with a clear compass to accelerate rigorous, patient-centered
innovation in osteoporosis care. The project page of this survey can also be
found on Github.

</details>


### [30] [Observer-Usable Information as a Task-specific Image Quality Metric](https://arxiv.org/abs/2510.00298)
*Changjie Lu,Sourya Sengupta,Hua Li,Mark A. Anastasio*

Main category: eess.IV

TL;DR: 本文提出并研究了预测性V信息作为客观、任务特定的图像质量度量，用于医学成像技术评估。V信息能够量化图像在考虑特定次优观察者家族时的任务相关信息效用。


<details>
  <summary>Details</summary>
Motivation: 传统任务特定信息(TSI)无法量化次优观察者能够利用的图像任务相关信息量，需要一种能够考虑特定观察者家族的新度量方法。

Method: 提出预测性V信息作为新的图像质量度量，并在磁共振图像恢复问题中验证其有效性，用于量化信号检测或区分性能。

Result: V信息与二元任务的ROC曲线下面积相关，同时适用于多类任务；在传统度量饱和的场景中表现出更高的灵敏度。

Conclusion: V信息代表了一种新的客观图像质量度量，可以补充传统的基于信号检测理论的度量方法。

Abstract: Objective, task-based, measures of image quality (IQ) have been widely
advocated for assessing and optimizing medical imaging technologies. Besides
signal detection theory-based measures, information-theoretic quantities have
been proposed to quantify task-based IQ. For example, task-specific information
(TSI), defined as the mutual information between an image and task variable,
represents an optimal measure of how informative an image is for performing a
specified task. However, like the ideal observer from signal detection theory,
TSI does not quantify the amount of task-relevant information in an image that
can be exploited by a sub-ideal observer. A recently proposed relaxation of
TSI, termed predictive V-information (V-info), removes this limitation and can
quantify the utility of an image with consideration of a specified family of
sub-ideal observers. In this study, for the first time, V-info is proposed and
investigated as an objective, task-specific, IQ metric. To corroborate its
usefulness, a stylized magnetic resonance image restoration problem is
considered in which V-info is employed to quantify signal detection or
discrimination performance. The presented results show that V-info correlates
with area under the receiver operating characteristic (ROC) curve for binary
tasks, while being readily applicable to multi-class (>2) tasks where ROC
analysis is challenging. Notably, V-info exhibits greater sensitivity in
scenarios where conventional metrics saturate. These findings demonstrate that
V-info represents a new objective IQ measure that can complement conventional
signal detection theory-based ones.

</details>


### [31] [Improving Virtual Contrast Enhancement using Longitudinal Data](https://arxiv.org/abs/2510.00418)
*Pierre Fayolle,Alexandre Bône,Noëlie Debs,Pihlippe Robert,Pascal Bourdon,Remy Guillevin,David Helbert*

Main category: eess.IV

TL;DR: 提出一种深度学习框架，利用患者先前的全剂量MRI检查信息，从低剂量采集虚拟增强生成全剂量对比后T1加权MRI图像，以减少钆基对比剂的使用。


<details>
  <summary>Details</summary>
Motivation: 钆基对比剂在脑组织中残留和积累的问题，特别是对于需要频繁监测和注射对比剂的疾病，需要减少剂量使用的策略。

Method: 开发深度学习框架，利用纵向信息（患者先前的全剂量MRI检查）来增强低剂量采集的图像质量。

Result: 与单次会话模型相比，纵向方法显著提高了多个重建指标下的图像质量，且在模拟不同对比剂量下表现出鲁棒性。

Conclusion: 将先前的成像历史整合到基于深度学习的虚拟对比增强流程中，可以在不影响诊断效用的前提下减少钆基对比剂使用，为临床MRI实践提供更安全、可持续的纵向监测方法。

Abstract: Gadolinium-based contrast agents (GBCAs) are widely used in magnetic
resonance imaging (MRI) to enhance lesion detection and characterisation,
particularly in the field of neuro-oncology. Nevertheless, concerns regarding
gadolinium retention and accumulation in brain and body tissues, most notably
for diseases that require close monitoring and frequent GBCA injection, have
led to the need for strategies to reduce dosage. In this study, a deep learning
framework is proposed for the virtual contrast enhancement of full-dose
post-contrast T1-weighted MRI images from corresponding low-dose acquisitions.
The contribution of the presented model is its utilisation of longitudinal
information, which is achieved by incorporating a prior full-dose MRI
examination from the same patient. A comparative evaluation against a
non-longitudinal single session model demonstrated that the longitudinal
approach significantly improves image quality across multiple reconstruction
metrics. Furthermore, experiments with varying simulated contrast doses
confirmed the robustness of the proposed method. These results emphasize the
potential of integrating prior imaging history into deep learning-based virtual
contrast enhancement pipelines to reduce GBCA usage without compromising
diagnostic utility, thus paving the way for safer, more sustainable
longitudinal monitoring in clinical MRI practice.

</details>


### [32] [A Fast and Precise Method for Searching Rectangular Tumor Regions in Brain MR Images](https://arxiv.org/abs/2510.00505)
*Hidenori Takeshima,Shuki Maruyama*

Main category: eess.IV

TL;DR: 提出了一种快速精确的脑肿瘤图像矩形区域搜索方法，结合分割网络和快速搜索算法，显著提升搜索速度并改善区域质量


<details>
  <summary>Details</summary>
Motivation: 开发快速精确的脑肿瘤图像矩形区域搜索方法，以辅助脑肿瘤MRI诊断

Method: 使用基于EfficientNet编码器的U-Net作为分割网络，采用求和面积表加速三维矩形区域搜索，设计用户可控的搜索度量标准

Result: 提出的计算方法比传统方法快100-500倍（8秒 vs 11-40分钟），搜索度量获得的肿瘤分数更高，且更偏好立方体而非细长形状

Conclusion: 该方法有望实现快速精确的矩形肿瘤区域搜索，对脑肿瘤MRI诊断具有实用价值，显著减少了处理时间并改善了区域质量

Abstract: Purpose: To develop a fast and precise method for searching rectangular
regions in brain tumor images. Methods: The authors propose a new method for
searching rectangular tumor regions in brain MR images. The proposed method
consisted of a segmentation network and a fast search method with a
user-controllable search metric. As the segmentation network, the U-Net whose
encoder was replaced by the EfficientNet was used. In the fast search method,
summed-area tables were used for accelerating sums of voxels in rectangular
regions. Use of the summed-area tables enabled exhaustive search of the 3D
offset (3D full search). The search metric was designed for giving priority to
cubes over oblongs, and assigning better values for higher tumor fractions even
if they exceeded target tumor fractions. The proposed computation and metric
were compared with those used in a conventional method using the Brain Tumor
Image Segmentation dataset. Results: When the 3D full search was used, the
proposed computation (8 seconds) was 100-500 times faster than the conventional
computation (11-40 minutes). When the user-controllable parts of the search
metrics were changed variously, the tumor fractions of the proposed metric were
higher than those of the conventional metric. In addition, the conventional
metric preferred oblongs whereas the proposed metric preferred cubes.
Conclusion: The proposed method is promising for implementing fast and precise
search of rectangular tumor regions, which is useful for brain tumor diagnosis
using MRI systems. The proposed computation reduced processing times of the 3D
full search, and the proposed metric improved the quality of the assigned
rectangular tumor regions.

</details>


### [33] [U-DFA: A Unified DINOv2-Unet with Dual Fusion Attention for Multi-Dataset Medical Segmentation](https://arxiv.org/abs/2510.00585)
*Zulkaif Sajjad,Furqan Shaukat,Junaid Mir*

Main category: eess.IV

TL;DR: 提出U-DFA模型，通过新颖的局部-全局融合适配器(LGFA)将CNN空间特征注入冻结的DINOv2模块，在医学图像分割任务上取得SOTA性能，参数量仅需33%。


<details>
  <summary>Details</summary>
Motivation: 解决CNN模型感受野有限无法捕获全局上下文，以及现有CNN-Transformer融合方法无法有效整合局部和全局特征的问题。同时避免VLM模型存在的领域差距和高计算成本。

Method: U-DFA统一架构，包含DINOv2-Unet编码器-解码器，通过LGFA模块将基于CNN的空间模式适配器(SPA)的空间特征注入到冻结的DINOv2块中，实现高层语义和空间特征的有效融合。

Result: 在Synapse和ACDC数据集上达到最先进性能，仅需33%的可训练参数量。

Conclusion: U-DFA是一个鲁棒且可扩展的医学图像分割框架，适用于多种模态。

Abstract: Accurate medical image segmentation plays a crucial role in overall diagnosis
and is one of the most essential tasks in the diagnostic pipeline. CNN-based
models, despite their extensive use, suffer from a local receptive field and
fail to capture the global context. A common approach that combines CNNs with
transformers attempts to bridge this gap but fails to effectively fuse the
local and global features. With the recent emergence of VLMs and foundation
models, they have been adapted for downstream medical imaging tasks; however,
they suffer from an inherent domain gap and high computational cost. To this
end, we propose U-DFA, a unified DINOv2-Unet encoder-decoder architecture that
integrates a novel Local-Global Fusion Adapter (LGFA) to enhance segmentation
performance. LGFA modules inject spatial features from a CNN-based Spatial
Pattern Adapter (SPA) module into frozen DINOv2 blocks at multiple stages,
enabling effective fusion of high-level semantic and spatial features. Our
method achieves state-of-the-art performance on the Synapse and ACDC datasets
with only 33\% of the trainable model parameters. These results demonstrate
that U-DFA is a robust and scalable framework for medical image segmentation
across multiple modalities.

</details>
