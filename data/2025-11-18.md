<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 19]
- [eess.SP](#eess.SP) [Total: 23]
- [cs.IT](#cs.IT) [Total: 9]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Slow - Motion Video Synthesis for Basketball Using Frame Interpolation](https://arxiv.org/abs/2511.11644)
*Jiantang Huang*

Main category: eess.IV

TL;DR: 提出一个实时慢动作合成系统，通过微调RIFE网络在篮球视频上，实现高质量的4倍慢动作生成，在PSNR和SSIM指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统篮球转播帧率有限（30-60fps），无法充分展示快速动作如扣篮和变向，需要更好的慢动作合成技术。

Method: 在SportsSloMo数据集的篮球子集上微调RIFE网络，采用人类感知的随机裁剪策略，构建端到端的慢动作生成系统。

Result: 微调后的RIFE模型达到平均PSNR 34.3 dB和SSIM 0.949，分别比Super SloMo高2.1 dB，比基线RIFE高1.3 dB，在RTX 4070 Ti Super上实现约30 fps的实时处理。

Conclusion: 任务特定的适应对体育慢动作至关重要，RIFE在准确性和速度之间提供了良好的权衡，适合消费级应用。

Abstract: Basketball broadcast footage is traditionally captured at 30-60 fps, limiting viewers' ability to appreciate rapid plays such as dunks and crossovers. We present a real-time slow-motion synthesis system that produces high-quality basketball-specific interpolated frames by fine-tuning the recent Real-Time Intermediate Flow Estimation (RIFE) network on the SportsSloMo dataset. Our pipeline isolates the basketball subset of SportsSloMo, extracts training triplets, and fine-tunes RIFE with human-aware random cropping. We compare the resulting model against Super SloMo and the baseline RIFE model using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity (SSIM) on held-out clips. The fine-tuned RIFE attains a mean PSNR of 34.3 dB and SSIM of 0.949, outperforming Super SloMo by 2.1 dB and the baseline RIFE by 1.3 dB. A lightweight Gradio interface demonstrates end-to-end 4x slow-motion generation on a single RTX 4070 Ti Super at approximately 30 fps. These results indicate that task-specific adaptation is crucial for sports slow-motion, and that RIFE provides an attractive accuracy-speed trade-off for consumer applications.

</details>


### [2] [Weyl-Heisenberg Transform Capabilities in JPEG Compression Standard](https://arxiv.org/abs/2511.11766)
*V. Asiryan,V. Volchkov,N. Papulovskaya*

Main category: eess.IV

TL;DR: 提出基于Weyl-Heisenberg基的新压缩技术来改进JPEG标准，用二维离散正交Weyl-Heisenberg变换(DWHT)替代DCT，实现更高效的图像压缩。


<details>
  <summary>Details</summary>
Motivation: JPEG压缩算法存在效率提升的限制，需要克服DCT在变换编码阶段的局限性。

Method: 在变换编码阶段使用二维离散正交Weyl-Heisenberg变换(DWHT)替代离散余弦变换(DCT)，利用其块结构和时频域良好局部化的特性。

Result: 实验研究证实提出的算法比JPEG标准具有更高的压缩效率。

Conclusion: 基于DWHT的JPEG改进算法能更有效地进行去相关和压缩，在量化编码阶段能更高效地筛选不显著元素。

Abstract: This paper is devoted to the development and research of a new compression technology based on Weyl-Heisenberg bases (WH-technology) for modifying the JPEG compression standard and improving its characteristics. For this purpose, the paper analyzes the main stages of the JPEG compression algorithm, notes its key features and problems that limit further enhancement of its efficiency. To overcome these limitations, it is proposed to use the real version of the two-dimensional discrete orthogonal Weyl-Heisenberg transform (DWHT) instead of the discrete cosine transform (DCT) at the stage of transformation coding. This transformation, unlike DCT, initially has a block structure and is built on the basis of the Weyl-Heisenberg optimal signal basis, the functions of which are orthogonal and well localized both in the frequency and time domains. This feature of DWHT allows for more efficient decorrelation and compression of element values in each block of the image after transformation coding. As a result, it is possible to obtain more efficient selection and screening of insignificant elements at the subsequent stages of quantization and information coding. Based on DWHT, a new version of the JPEG compression algorithm was developed, and convenient criteria for evaluating the compression efficiency and metrics of quality losses were proposed. The results of an experimental study are presented, confirming the higher compression efficiency of the proposed algorithm in comparison with the JPEG compression standard.

</details>


### [3] [A Deep Learning Framework for Thyroid Nodule Segmentation and Malignancy Classification from Ultrasound Images](https://arxiv.org/abs/2511.11937)
*Omar Abdelrazik,Mohamed Elsayed,Noorul Wahab,Nasir Rajpoot,Adam Shephard*

Main category: eess.IV

TL;DR: 提出一个完全自动化的两阶段框架，用于甲状腺结节超声图像的可解释恶性预测，通过强制模型仅关注临床相关区域实现可解释性。


<details>
  <summary>Details</summary>
Motivation: 甲状腺结节超声风险分层存在高观察者间变异性，而许多深度学习模型是"黑箱"，需要可解释的自动化方法。

Method: 使用TransUNet自动分割甲状腺结节，然后用分割掩码创建感兴趣区域，将局部化图像输入ResNet-18分类器进行恶性预测。

Result: 在349张临床图像上通过5折交叉验证获得0.852的F1分数，优于使用手工形态特征的随机森林基线（F1=0.829）。

Conclusion: 这是首个完全自动化的端到端管道，既能检测甲状腺结节又能预测恶性，学习到的隐式视觉特征比显式形状特征更具预测性。

Abstract: Ultrasound-based risk stratification of thyroid nodules is a critical clinical task, but it suffers from high inter-observer variability. While many deep learning (DL) models function as "black boxes," we propose a fully automated, two-stage framework for interpretable malignancy prediction. Our method achieves interpretability by forcing the model to focus only on clinically relevant regions. First, a TransUNet model automatically segments the thyroid nodule. The resulting mask is then used to create a region of interest around the nodule, and this localised image is fed directly into a ResNet-18 classifier. We evaluated our framework using 5-fold cross-validation on a clinical dataset of 349 images, where it achieved a high F1-score of 0.852 for predicting malignancy. To validate its performance, we compared it against a strong baseline using a Random Forest classifier with hand-crafted morphological features, which achieved an F1-score of 0.829. The superior performance of our DL framework suggests that the implicit visual features learned from the localised nodule are more predictive than explicit shape features alone. This is the first fully automated end-to-end pipeline for both detecting thyroid nodules on ultrasound images and predicting their malignancy.

</details>


### [4] [Noisy MRI Reconstruction via MAP Estimation with an Implicit Deep-Denoiser Prior](https://arxiv.org/abs/2511.11963)
*Nikola Janjušević,Amirhossein Khalilian-Gourtani,Yao Wang,Li Feng*

Main category: eess.IV

TL;DR: ImMAP是一个基于扩散模型的MRI重建框架，通过将采集噪声模型直接整合到最大后验概率(MAP)公式中，在真实噪声条件下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在MRI重建中缺乏与MRI物理的明确联系，且参数对测量噪声敏感，限制了实际应用的可靠性。

Method: 基于Kadkhodaie等人的随机上升方法，将其推广到处理MRI编码算子和真实测量噪声，构建了集成噪声模型的MAP公式。

Result: 在模拟和真实噪声数据集上，ImMAP始终优于最先进的深度学习和扩散基方法(LPDSNet和DDS)。

Conclusion: 通过阐明扩散模型在真实噪声条件下的实际行为和局限性，ImMAP建立了更可靠和可解释的MRI重建框架。

Abstract: Accelerating magnetic resonance imaging (MRI) remains challenging, particularly under realistic acquisition noise. While diffusion models have recently shown promise for reconstructing undersampled MRI data, many approaches lack an explicit link to the underlying MRI physics, and their parameters are sensitive to measurement noise, limiting their reliability in practice. We introduce Implicit-MAP (ImMAP), a diffusion-based reconstruction framework that integrates the acquisition noise model directly into a maximum a posteriori (MAP) formulation. Specifically, we build on the stochastic ascent method of Kadkhodaie et al. and generalize it to handle MRI encoding operators and realistic measurement noise. Across both simulated and real noisy datasets, ImMAP consistently outperforms state-of-the-art deep learning (LPDSNet) and diffusion-based (DDS) methods. By clarifying the practical behavior and limitations of diffusion models under realistic noise conditions, ImMAP establishes a more reliable and interpretable

</details>


### [5] [Volumetric Ultrasound via 3D Null Subtraction Imaging with Circular and Spiral Apertures](https://arxiv.org/abs/2511.12126)
*Bingze Dai,Xi Zhang,Wei-Ning Lee*

Main category: eess.IV

TL;DR: 三维零减成像（3D NSI）是一种非线性波束成形框架，通过结合计算高效的零减过程与矩阵阵列上的复用感知稀疏孔径设计，解决了体积超声成像在图像质量、帧率和硬件复杂度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决体积超声成像在图像质量、帧率和硬件复杂度之间的基本权衡问题，特别是在矩阵阵列与低通道数超声系统复用时面临的通道共享约束。

Method: 提出3D NSI框架，结合零减过程和复用感知稀疏孔径设计。评估三种孔径配置：全寻址圆形孔径和两种费马螺旋稀疏孔径。特别提出螺旋"无复用"孔径设计，在发射-接收事件间强制非重叠元件集以解决复用冲突。

Result: 在计算机模拟和组织模拟体模实验中，3D NSI相比传统延迟求和波束成形器，在匹配的发射/接收配置下，方位角和仰角分辨率平均提高36%，对比度比提高约20%。使用螺旋无复用孔径时，3D NSI框架实现了每秒超过1000个体积的采集速率，计算负载不到DAS的三倍。

Conclusion: 3D NSI框架为实时4D成像提供了一个实用解决方案，能够在仅使用240个活动元件（在1024元件探头上）的情况下实现高达16倍的采集体积率提升，同时保持合理的计算复杂度。

Abstract: Volumetric ultrasound imaging faces a fundamental trade-off among image quality, frame rate, and hardware complexity. This study introduces three-dimensional Null Subtraction Imaging (3D NSI), a nonlinear beamforming framework that addresses this trade-off by combining computationally efficient null-subtraction process with multiplexing-aware sparse aperture designs on matrix arrays. We evaluate three apodization configurations: a fully addressed circular aperture and two Fermat's spiral sparse apertures. To overcome channel-sharing constraints common in matrix arrays multiplexed with low-channel-count ultrasound systems, we propose a spiral "no-reuse" apodization that enforces non-overlapping element sets across transmit-receive events. This design resolves multiplexing conflicts and enables up to a 16-fold increase in acquisition volume rate using only 240 active elements on a 1024-element probe. In computer simulations and tissue-mimicking phantom experiments, 3D NSI achieved an average improvement of 36% in azimuthal and elevational resolutions, along with an approximately 20% higher contrast ratio, compared to the conventional Delay-and-Sum (DAS) beamformer under matched transmit/receive configurations. When implemented with the spiral no-reuse aperture, the 3D NSI framework achieved over 1000 volumes per second with a computational load less than three times that of DAS, making it a practical solution for real-time 4D imaging.

</details>


### [6] [Recursive Threshold Median Filter and Autoencoder for Salt-and-Pepper Denoising: SSIM analysis of Images and Entropy Maps](https://arxiv.org/abs/2511.12212)
*Petr Boriskov,Kirill Rudkovskii,Andrei Velichko*

Main category: eess.IV

TL;DR: 本文研究了使用中值滤波器和简单三层自编码器在递归阈值算法中去除图像椒盐噪声的方法，提出了两种可扩展方案并验证了新的SSIMMap评估指标的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究图像去噪方法，特别是针对椒盐噪声的去除，并开发更敏感的评估指标来补充传统的SSIMImg指标。

Method: 使用中值滤波器和简单三层自编码器结合递归阈值算法，提出了2MF和MFs-AE两种可扩展方案。

Result: 递归阈值中值滤波器在强噪声（50-60%）下仍能稳健恢复图像，而简单自编码器仅适用于低噪声水平（<30%）。SSIMMap指标对模糊和局部强度变化更敏感。

Conclusion: 中值滤波器因其简单性和计算效率在资源受限平台上更适用，而自编码器在没有预去噪的情况下表现不佳。SSIMMap在客观模糊评估和去噪参数调优中具有实用价值。

Abstract: This paper studies the removal of salt-and-pepper noise from images using median filter (MF) and simple three-layer autoencoder (AE) within recursive threshold algorithm. The performance of denoising is assessed with two metrics: the standard Structural Similarity Index SSIMImg of restored and clean images and a newly applied metric SSIMMap - the SSIM of entropy maps of these images computed via 2D Sample Entropy in sliding windows. We shown that SSIMMap is more sensitive to blur and local intensity transitions and complements SSIMImg. Experiments on low- and high-resolution grayscales images demonstrate that recursive threshold MF robustly restores images even under strong noise (50-60 %), whereas simple AE is only capable of restoring images with low levels of noise (<30 %). We propose two scalable schemes: (i) 2MF, which uses two MFs with different window sizes and a final thresholding step, effective for highlighting sharp local details at low resolution; and (ii) MFs-AE, which aggregates features from multiple MFs via an AE and is beneficial for restoring the overall scene structure at higher resolution. Owing to its simplicity and computational efficiency, MF remains preferable for deployment on resource-constrained platforms (edge/IoT), whereas AE underperforms without prior denoising. The results also validate the practical value of SSIMMap for objective blur assessment and denoising parameter tuning.

</details>


### [7] [Deep Unfolded BM3D: Unrolling Non-local Collaborative Filtering into a Trainable Neural Network](https://arxiv.org/abs/2511.12248)
*Kerem Basim,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: eess.IV

TL;DR: 提出了DU-BM3D，一种将传统BM3D算法展开为可训练架构的混合框架，用可学习的U-Net去噪器替代固定协作滤波，在低剂量CT去噪任务中表现优于传统BM3D和独立U-Net。


<details>
  <summary>Details</summary>
Motivation: BM3D利用非局部自相似性先验进行去噪但依赖固定参数，而深度学习模型如U-Net更灵活但缺乏可解释性且难以跨噪声域泛化。

Method: 将BM3D展开为可训练架构，用可学习的U-Net去噪器替代其固定的协作滤波，保留BM3D的非局部结构先验同时支持端到端优化。

Result: 在低剂量CT去噪任务中，DU-BM3D在不同噪声水平下均优于经典BM3D和独立U-Net，尤其在强噪声条件下获得更高的PSNR和SSIM。

Conclusion: DU-BM3D成功结合了传统方法的可解释性和深度学习模型的灵活性，在医学图像去噪任务中表现出色。

Abstract: Block-Matching and 3D Filtering (BM3D) exploits non-local self-similarity priors for denoising but relies on fixed parameters. Deep models such as U-Net are more flexible but often lack interpretability and fail to generalize across noise regimes. In this study, we propose Deep Unfolded BM3D (DU-BM3D), a hybrid framework that unrolls BM3D into a trainable architecture by replacing its fixed collaborative filtering with a learnable U-Net denoiser. This preserves BM3D's non-local structural prior while enabling end-to-end optimization. We evaluate DU-BM3D on low-dose CT (LDCT) denoising and show that it outperforms classic BM3D and standalone U-Net across simulated LDCT at different noise levels, yielding higher PSNR and SSIM, especially in high-noise conditions.

</details>


### [8] [Multimodal RGB-HSI Feature Fusion with Patient-Aware Incremental Heuristic Meta-Learning for Oral Lesion Classification](https://arxiv.org/abs/2511.12268)
*Rupam Mukherjee,Rajkumar Daniel,Soujanya Hazra,Shirin Dasgupta,Subhamoy Mandal*

Main category: eess.IV

TL;DR: 提出了一种统一的四类口腔病变分类器，结合深度RGB嵌入、高光谱重建、手工光谱纹理描述符和人口统计学元数据，用于低资源环境下的口腔癌早期检测。


<details>
  <summary>Details</summary>
Motivation: 在低资源环境中，由于标注数据有限，口腔癌和潜在恶性病变的早期检测具有挑战性。

Method: 使用微调的ConvNeXt-v2编码器处理口腔图像，进行RGB到HSI重建生成31波段高光谱立方体，提取血红蛋白敏感指数、纹理特征和光谱形状度量，与深度和临床特征融合，并引入增量启发式元学习器（IHML）通过概率堆叠和患者级后验平滑结合校准的基础分类器。

Result: 在未见过的患者分割上，该框架实现了66.23%的宏观F1分数和64.56%的准确率。

Conclusion: 高光谱重建和不确定性感知元学习显著提高了真实世界口腔病变筛查的鲁棒性。

Abstract: Early detection of oral cancer and potentially malignant disorders is challenging in low-resource settings due to limited annotated data. We present a unified four-class oral lesion classifier that integrates deep RGB embeddings, hyperspectral reconstruction, handcrafted spectral-textural descriptors, and demographic metadata. A pathologist-verified subset of oral cavity images was curated and processed using a fine-tuned ConvNeXt-v2 encoder, followed by RGB-to-HSI reconstruction into 31-band hyperspectral cubes. Haemoglobin-sensitive indices, texture features, and spectral-shape measures were extracted and fused with deep and clinical features. Multiple machine-learning models were assessed with patient-wise validation. We further introduce an incremental heuristic meta-learner (IHML) that combines calibrated base classifiers through probabilistic stacking and patient-level posterior smoothing. On an unseen patient split, the proposed framework achieved a macro F1 of 66.23% and an accuracy of 64.56%. Results demonstrate that hyperspectral reconstruction and uncertainty-aware meta-learning substantially improve robustness for real-world oral lesion screening.

</details>


### [9] [RAA-MIL: A Novel Framework for Classification of Oral Cytology](https://arxiv.org/abs/2511.12269)
*Rupam Mukherjee,Rajkumar Daniel,Soujanya Hazra,Shirin Dasgupta,Subhamoy Mandal*

Main category: eess.IV

TL;DR: 首个弱监督深度学习框架用于口腔细胞学全玻片图像的病人级别诊断，通过多实例学习和区域亲和力注意力机制提升诊断性能


<details>
  <summary>Details</summary>
Motivation: 手动检查口腔细胞学全玻片图像速度慢、主观性强且依赖专家病理学家，需要AI辅助的自动化诊断方法

Method: 提出区域亲和力注意力多实例学习(RAA-MIL)框架，建模玻片内区域间的空间关系，使用病人级别的弱标签进行训练

Result: RAA-MIL在未见测试集上达到72.7%的平均准确率和0.69的加权F1分数，优于基线模型

Conclusion: 本研究建立了首个口腔细胞学病人级别弱监督基准，推动了可靠的AI辅助数字病理学发展

Abstract: Cytology is a valuable tool for early detection of oral squamous cell carcinoma (OSCC). However, manual examination of cytology whole slide images (WSIs) is slow, subjective, and depends heavily on expert pathologists. To address this, we introduce the first weakly supervised deep learning framework for patient-level diagnosis of oral cytology whole slide images, leveraging the newly released Oral Cytology Dataset [1], which provides annotated cytology WSIs from ten medical centres across India. Each patient case is represented as a bag of cytology patches and assigned a diagnosis label (Healthy, Benign, Oral Potentially Malignant Disorders (OPMD), OSCC) by an in-house expert pathologist. These patient-level weak labels form a new extension to the dataset. We evaluate a baseline multiple-instance learning (MIL) model and a proposed Region-Affinity Attention MIL (RAA-MIL) that models spatial relationships between regions within each slide. The RAA-MIL achieves an average accuracy of 72.7%, weighted F1-score of 0.69 on an unseen test set, outperforming the baseline. This study establishes the first patient-level weakly supervised benchmark for oral cytology and moves toward reliable AI-assisted digital pathology.

</details>


### [10] [MTMed3D: A Multi-Task Transformer-Based Model for 3D Medical Imaging](https://arxiv.org/abs/2511.12373)
*Fan Li,Arun Iyengar,Lanyu Xu*

Main category: eess.IV

TL;DR: 提出了MTMed3D，一种基于Transformer的多任务学习模型，在3D医学影像中同时执行检测、分割和分类任务，显著提高了计算效率并保持可比性能。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像AI主要使用单任务模型，忽略了任务间的共享信息，导致实际应用效率低下。多任务学习可以充分利用任务间的相关性来提高效率。

Method: 使用Transformer作为共享编码器生成多尺度特征，然后使用基于CNN的任务特定解码器。在BraTS 2018和2019数据集上评估，并与单任务模型变体进行比较。

Result: 在三个任务上都取得了有希望的结果，特别是在检测任务上优于先前工作。多任务模型显著降低了计算成本，推理速度更快，同时保持了与单任务模型相当的性能。

Conclusion: 这是首个在3D医学影像中利用Transformer同时处理检测、分割和分类任务的多任务学习工作，展示了其在提升诊断流程效率方面的潜力。

Abstract: In the field of medical imaging, AI-assisted techniques such as object detection, segmentation, and classification are widely employed to alleviate the workload of physicians and doctors. However, single-task models are predominantly used, overlooking the shared information across tasks. This oversight leads to inefficiencies in real-life applications. In this work, we propose MTMed3D, a novel end-to-end Multi-task Transformer-based model to address the limitations of single-task models by jointly performing 3D detection, segmentation, and classification in medical imaging. Our model uses a Transformer as the shared encoder to generate multi-scale features, followed by CNN-based task-specific decoders. The proposed framework was evaluated on the BraTS 2018 and 2019 datasets, achieving promising results across all three tasks, especially in detection, where our method achieves better results than prior works. Additionally, we compare our multi-task model with equivalent single-task variants trained separately. Our multi-task model significantly reduces computational costs and achieves faster inference speed while maintaining comparable performance to the single-task models, highlighting its efficiency advantage. To the best of our knowledge, this is the first work to leverage Transformers for multi-task learning that simultaneously covers detection, segmentation, and classification tasks in 3D medical imaging, presenting its potential to enhance diagnostic processes. The code is available at https://github.com/fanlimua/MTMed3D.git.

</details>


### [11] [DEMIST: \underline{DE}coupled \underline{M}ulti-stream latent d\underline{I}ffusion for Quantitative Myelin Map \underline{S}yn\underline{T}hesis](https://arxiv.org/abs/2511.12396)
*Jiacheng Wang,Hao Li,Xing Yao,Ahmad Toubasi,Taegan Vinarsky,Caroline Gheen,Joy Derwenskus,Chaoyang Jin,Richard Dortch,Junzhong Xu,Francesca Bagnato,Ipek Oguz*

Main category: eess.IV

TL;DR: DEMIST方法使用3D潜在扩散模型从标准T1w和FLAIR图像合成定量磁化转移成像的PSR图，通过三种互补条件机制实现高效合成。


<details>
  <summary>Details</summary>
Motivation: 传统qMT成像需要20-30分钟的专业扫描，耗时较长。研究旨在从常规MRI序列快速合成PSR图，用于多发性硬化评估。

Method: 采用两阶段方法：先训练PSR和解剖图像的自编码器学习对齐潜在表示，然后在潜在空间训练条件扩散模型，包含语义标记、空间残差提示和自适应LoRA调制三种条件机制。

Result: 在163个扫描的5折交叉验证中，方法在多个指标上优于VAE、GAN和扩散基线，产生更清晰的边界和更好的定量一致性。

Conclusion: DEMIST能够从标准MRI序列高效合成高质量的PSR图，为多发性硬化评估提供实用工具。

Abstract: Quantitative magnetization transfer (qMT) imaging provides myelin-sensitive biomarkers, such as the pool size ratio (PSR), which is valuable for multiple sclerosis (MS) assessment. However, qMT requires specialized 20-30 minute scans. We propose DEMIST to synthesize PSR maps from standard T1w and FLAIR images using a 3D latent diffusion model with three complementary conditioning mechanisms. Our approach has two stages: first, we train separate autoencoders for PSR and anatomical images to learn aligned latent representations. Second, we train a conditional diffusion model in this latent space on top of a frozen diffusion foundation backbone. Conditioning is decoupled into: (i) \textbf{semantic} tokens via cross-attention, (ii) \textbf{spatial} per-scale residual hints via a 3D ControlNet branch, and (iii) \textbf{adaptive} LoRA-modulated attention. We include edge-aware loss terms to preserve lesion boundaries and alignment losses to maintain quantitative consistency, while keeping the number of trainable parameters low and retaining the inductive bias of the pretrained model. We evaluate on 163 scans from 99 subjects using 5-fold cross-validation. Our method outperforms VAE, GAN and diffusion baselines on multiple metrics, producing sharper boundaries and better quantitative agreement with ground truth. Our code is publicly available at https://github.com/MedICL-VU/MS-Synthesis-3DcLDM.

</details>


### [12] [A Multicollinearity-Aware Signal-Processing Framework for Cross-$β$ Identification via X-ray Scattering of Alzheimer's Tissue](https://arxiv.org/abs/2511.12451)
*Abdullah Al Bashit,Prakash Nepal,Lee Makowski*

Main category: eess.IV

TL;DR: 开发了一个三阶段分类框架，用于在X射线散射数据中检测阿尔茨海默病的交叉β结构包涵体，通过贝叶斯分类、相关性剪枝和紧凑神经网络实现高效分类。


<details>
  <summary>Details</summary>
Motivation: X射线散射测量中的人脑组织数据包含病理交叉β包涵体的结构特征，但由于基底污染、强特征相关性和有限样本量，自动化检测面临挑战。

Method: 三阶段框架：1) 贝叶斯最优分类器分离基底和组织区域；2) 多共线性感知的相关性剪枝方案；3) 在剪枝特征集上训练紧凑神经网络检测交叉β纤维有序性。

Result: 最佳模型使用11个候选特征中的11个和174个可训练参数，在测试集上达到84.30%的F1分数。

Conclusion: 该框架为数据有限、涉及相关高维实验测量的分类问题提供了可解释的理论基础策略，特别适用于神经退行性组织X射线散射分析。

Abstract: X-ray scattering measurements of in situ human brain tissue encode structural signatures of pathological cross-$β$ inclusions, yet systematic exploitation of these data for automated detection remains challenging due to substrate contamination, strong inter-feature correlations, and limited sample sizes. This work develops a three-stage classification framework for identifying cross-$β$ structural inclusions-a hallmark of Alzheimer's disease-in X-ray scattering profiles of post-mortem human brain. Stage 1 employs a Bayes-optimal classifier to separate mica substrate from tissue regions on the basis of their distinct scattering signatures. Stage 2 introduces a multicollinearityaware, class-conditional correlation pruning scheme with formal guarantees on the induced Bayes risk and approximation error, thereby reducing redundancy while retaining class-discriminative information. Stage 3 trains a compact neural network on the pruned feature set to detect the presence or absence of cross-$β$ fibrillar ordering. The top-performing model, optimized with a composite loss combining Focal and Dice objectives, attains a test F1-score of 84.30% using 11 of 211 candidate features and 174 trainable parameters. The overall framework yields an interpretable, theory-grounded strategy for data-limited classification problems involving correlated, high-dimensional experimental measurements, exemplified here by X-ray scattering profiles of neurodegenerative tissue.

</details>


### [13] [Diffusion Algorithm for Metalens Optical Aberration Correction](https://arxiv.org/abs/2511.12689)
*Harshana Weligampola,Yuanrui Chen,Abhiram Gnanasambandam,Weiheng Tang,Dilshan Godaliyadda,Hamid R. Sheikh,Qi Guo,Stanley H. Chan*

Main category: eess.IV

TL;DR: 提出一种基于双分支扩散模型的算法，从金属透镜系统捕获的锐利灰度结构图像和失真的颜色线索图像中重建清晰的全彩图像。


<details>
  <summary>Details</summary>
Motivation: 金属透镜虽然能实现超薄光学系统，但存在严重的光学像差（特别是色差），使得图像重建成为重大挑战。

Method: 基于预训练的Stable Diffusion XL框架构建双分支扩散模型，融合结构图像和颜色线索图像的信息。

Result: 通过定量和定性比较证明，该方法显著优于现有的去模糊和全色锐化方法，能有效恢复高频细节并准确着色。

Conclusion: 该算法成功解决了金属透镜系统的色差问题，实现了高质量的全彩图像重建。

Abstract: Metalenses offer a path toward creating ultra-thin optical systems, but they inherently suffer from severe, spatially varying optical aberrations, especially chromatic aberration, which makes image reconstruction a significant challenge. This paper presents a novel algorithmic solution to this problem, designed to reconstruct a sharp, full-color image from two inputs: a sharp, bandpass-filtered grayscale ``structure image'' and a heavily distorted ``color cue'' image, both captured by the metalens system. Our method utilizes a dual-branch diffusion model, built upon a pre-trained Stable Diffusion XL framework, to fuse information from the two inputs. We demonstrate through quantitative and qualitative comparisons that our approach significantly outperforms existing deblurring and pansharpening methods, effectively restoring high-frequency details while accurately colorizing the image.

</details>


### [14] [Improving the Generalisation of Learned Reconstruction Frameworks](https://arxiv.org/abs/2511.12730)
*Emilien Valat,Ozan Öktem*

Main category: eess.IV

TL;DR: 本文提出了一种用于CT成像的混合神经网络架构GLM，通过图数据结构表示CT采集几何和层析数据，结合图卷积和网格卷积处理层析数据，相比传统CNN在性能、参数效率、训练时间和泛化能力方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在CT成像中存在局限性，因为它们将基于网格的卷积应用于正弦图数据，而正弦图本质上位于线流形上而非规则网格。CNN不了解几何结构，需要从数据中推断测量关系，导致参数过多且泛化能力差。

Method: 引入图数据结构表示CT采集几何和层析数据，提出GLM混合神经网络架构，结合图卷积和网格卷积处理层析数据。

Result: GLM在结构相似性和峰值信噪比方面优于CNN，仅使用一小部分可训练参数。相比CNN，GLM训练时间和内存需求显著减少，内存需求扩展性更好。GLM对采集几何的未见变化具有鲁棒泛化能力。

Conclusion: GLM架构通过结合图卷积和网格卷积，有效解决了CT成像中传统CNN的几何感知不足问题，在性能、效率和泛化能力方面都取得了显著改进。

Abstract: Ensuring proper generalization is a critical challenge in applying data-driven methods for solving inverse problems in imaging, as neural networks reconstructing an image must perform well across varied datasets and acquisition geometries. In X-ray Computed Tomography (CT), convolutional neural networks (CNNs) are widely used to filter the projection data but are ill-suited for this task as they apply grid-based convolutions to the sinogram, which inherently lies on a line manifold, not a regular grid. The CNNs, unaware of the geometry, are implicitly tied to it and require an excessive amount of parameters as they must infer the relations between measurements from the data rather than from prior information.
  The contribution of this paper is twofold. First, we introduce a graph data structure to represent CT acquisition geometries and tomographic data, providing a detailed explanation of the graph's structure for circular, cone-beam geometries. Second, we propose GLM, a hybrid neural network architecture that leverages both graph and grid convolutions to process tomographic data.
  We demonstrate that GLM outperforms CNNs when performance is quantified in terms of structural similarity and peak signal-to-noise ratio, despite the fact that GLM uses only a fraction of the trainable parameters. Compared to CNNs, GLM also requires significantly less training time and memory, and its memory requirements scale better. Crucially, GLM demonstrates robust generalization to unseen variations in the acquisition geometry, like when training only on fully sampled CT data and then testing on sparse-view CT data.

</details>


### [15] [BrainNormalizer: Anatomy-Informed Pseudo-Healthy Brain Reconstruction from Tumor MRI via Edge-Guided ControlNet](https://arxiv.org/abs/2511.12853)
*Min Gu Kwak,Yeonju Lee,Hairong Wang,Jing Li*

Main category: eess.IV

TL;DR: BrainNormalizer是一个基于扩散模型的框架，能够从肿瘤MRI直接重建伪健康MRI，为临床治疗规划提供解剖学参考。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤会导致显著的解剖变形，但临床上无法获得无肿瘤的个体特异性参考图像，这给诊断和治疗规划带来困难。

Method: 采用边界引导的扩散框架，通过两阶段训练策略：首先进行基于修复的微调，然后训练边缘图引导的ControlNet分支，在推理时利用镜像对侧边缘图和错位策略。

Result: 在BraTS2020数据集上，BrainNormalizer实现了强大的定量性能，并在肿瘤区域产生解剖学上合理的重建，同时保持整体结构一致性。

Conclusion: BrainNormalizer为治疗规划提供临床可靠的解剖参考，并支持反事实建模和肿瘤诱导变形分析的新研究方向。

Abstract: Brain tumors are among the most clinically significant neurological diseases and remain a major cause of morbidity and mortality due to their aggressive growth and structural heterogeneity. As tumors expand, they induce substantial anatomical deformation that disrupts both local tissue organization and global brain architecture, complicating diagnosis, treatment planning, and surgical navigation. Yet a subject-specific reference of how the brain would appear without tumor-induced changes is fundamentally unobtainable in clinical practice. We present BrainNormalizer, an anatomy-informed diffusion framework that reconstructs pseudo-healthy MRIs directly from tumorous scans by conditioning the generative process on boundary cues extracted from the subject's own anatomy. This boundary-guided conditioning enables anatomically plausible pseudo-healthy reconstruction without requiring paired non-tumorous and tumorous scans. BrainNormalizer employs a two-stage training strategy. The pretrained diffusion model is first adapted through inpainting-based fine-tuning on tumorous and non-tumorous scans. Next, an edge-map-guided ControlNet branch is trained to inject fine-grained anatomical contours into the frozen decoder while preserving learned priors. During inference, a deliberate misalignment strategy pairs tumorous inputs with non-tumorous prompts and mirrored contralateral edge maps, leveraging hemispheric correspondence to guide reconstruction. On the BraTS2020 dataset, BrainNormalizer achieves strong quantitative performance and qualitatively produces anatomically plausible reconstructions in tumor-affected regions while retaining overall structural coherence. BrainNormalizer provides clinically reliable anatomical references for treatment planning and supports new research directions in counterfactual modeling and tumor-induced deformation analysis.

</details>


### [16] [cryoSENSE: Compressive Sensing Enables High-throughput Microscopy with Sparse and Generative Priors on the Protein Cryo-EM Image Manifold](https://arxiv.org/abs/2511.12931)
*Zain Shabeeb,Daniel Saeedi,Darin Tsui,Vida Jamali,Amirali Aghazadeh*

Main category: eess.IV

TL;DR: cryoSENSE是一个硬件-软件协同设计的压缩感知框架，通过利用冷冻电镜图像的低维流形特性，在空间域和傅里叶域进行欠采样，实现高达2.5倍的采集吞吐量提升，同时保持原始3D分辨率。


<details>
  <summary>Details</summary>
Motivation: 现代直接探测器产生的冷冻电镜数据量远超存储和传输带宽限制，制约了实际采集效率。需要开发压缩感知方法来减少数据量同时保持结构分辨率。

Method: 利用蛋白质冷冻电镜图像的低维流形特性，在预定义基上使用稀疏先验和通过去噪扩散模型捕获的生成先验，从空间域和傅里叶域的欠采样测量中重建图像。

Result: cryoSENSE实现了高达2.5倍的采集吞吐量提升，同时保持原始3D分辨率。稀疏先验在傅里叶域测量和中等压缩下表现更好，而生成扩散先验在像素域测量和更严重欠采样下实现准确恢复。

Conclusion: cryoSENSE通过压缩感知方法有效解决了冷冻电镜数据存储和传输瓶颈，为高分辨率结构生物学提供了实用的高通量解决方案。

Abstract: Cryo-electron microscopy (cryo-EM) enables the atomic-resolution visualization of biomolecules; however, modern direct detectors generate data volumes that far exceed the available storage and transfer bandwidth, thereby constraining practical throughput. We introduce cryoSENSE, the computational realization of a hardware-software co-designed framework for compressive cryo-EM sensing and acquisition. We show that cryo-EM images of proteins lie on low-dimensional manifolds that can be independently represented using sparse priors in predefined bases and generative priors captured by a denoising diffusion model. cryoSENSE leverages these low-dimensional manifolds to enable faithful image reconstruction from spatial and Fourier-domain undersampled measurements while preserving downstream structural resolution. In experiments, cryoSENSE increases acquisition throughput by up to 2.5$\times$ while retaining the original 3D resolution, offering controllable trade-offs between the number of masked measurements and the level of downsampling. Sparse priors favor faithful reconstruction from Fourier-domain measurements and moderate compression, whereas generative diffusion priors achieve accurate recovery from pixel-domain measurements and more severe undersampling. Project website: https://cryosense.github.io.

</details>


### [17] [Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation](https://arxiv.org/abs/2511.12961)
*Pritam P. Karmokar,William J. Beksi*

Main category: eess.IV

TL;DR: 提出了一种基于对比度最大化的生物启发混合方法，结合视觉和惯性运动线索来估计事件相机的光流，通过方向图引导优化过程提高鲁棒性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 事件相机直接编码场景中的运动，但事件数据在时间上密集而空间上稀疏的特性给光流估计带来挑战。对比度最大化方法虽然有效，但仍是一个高度非凸优化问题。

Method: 提出混合对比度最大化方法，使用从相机3D速度导出的方向图作为先验来引导对比度最大化过程，为运动轨迹估计提供方向指导和约束。

Result: 在MVSEC、DSEC和ECD数据集上的评估显示，该方法在精度上优于现有最先进方法。

Conclusion: 方向图引导的对比度最大化方法显著提高了事件相机光流估计的鲁棒性和收敛性，取得了优越的精度表现。

Abstract: Event cameras, by virtue of their working principle, directly encode motion within a scene. Many learning-based and model-based methods exist that estimate event-based optical flow, however the temporally dense yet spatially sparse nature of events poses significant challenges. To address these issues, contrast maximization (CM) is a prominent model-based optimization methodology that estimates the motion trajectories of events within an event volume by optimally warping them. Since its introduction, the CM framework has undergone a series of refinements by the computer vision community. Nonetheless, it remains a highly non-convex optimization problem. In this paper, we introduce a novel biologically-inspired hybrid CM method for event-based optical flow estimation that couples visual and inertial motion cues. Concretely, we propose the use of orientation maps, derived from camera 3D velocities, as priors to guide the CM process. The orientation maps provide directional guidance and constrain the space of estimated motion trajectories. We show that this orientation-guided formulation leads to improved robustness and convergence in event-based optical flow estimation. The evaluation of our approach on the MVSEC, DSEC, and ECD datasets yields superior accuracy scores over the state of the art.

</details>


### [18] [PyPeT: A Python Perfusion Tool for Automated Quantitative Brain CT and MR Perfusion Analysis](https://arxiv.org/abs/2511.13310)
*Marijn Borghouts,Ruisheng Su*

Main category: eess.IV

TL;DR: PyPeT是一个开源的Python脑灌注处理工具，用于CT和MR灌注数据的分析，能够生成多种脑血流动力学参数图，并与FDA批准的商业软件具有良好相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的商业灌注分析软件成本高、闭源且缺乏可定制性，限制了灌注研究的可及性和灵活性。

Method: 开发了一个统一的Python框架，支持CT和MR灌注数据处理，强调模块化、低计算负担和详细的内联文档，包含广泛的调试模式进行验证。

Result: 与三种FDA批准的商业灌注工具和研究工具进行视觉和定量比较，显示平均SSIM约为0.8，表明与FDA批准工具有良好的稳定相关性。

Conclusion: PyPeT提供了一个可访问、可定制的开源解决方案，使灌注研究更加民主化，代码已在GitHub上公开可用。

Abstract: Computed tomography perfusion (CTP) and magnetic resonance perfusion (MRP) are widely used in acute ischemic stroke assessment and other cerebrovascular conditions to generate quantitative maps of cerebral hemodynamics. While commercial perfusion analysis software exists, it is often costly, closed source, and lacks customizability. This work introduces PyPeT, an openly available Python Perfusion Tool for head CTP and MRP processing. PyPeT is capable of producing cerebral blood flow (CBF), cerebral blood volume (CBV), mean transit time (MTT), time-to-peak (TTP), and time-to-maximum (Tmax) maps from raw four-dimensional perfusion data. PyPeT aims to make perfusion research as accessible and customizable as possible. This is achieved through a unified framework in which both CTP and MRP data can be processed, with a strong focus on modularity, low computational burden, and significant inline documentation. PyPeT's outputs can be validated through an extensive debug mode in which every step of the process is visualized. Additional validation was performed via visual and quantitative comparison with reference perfusion maps generated by three FDA-approved commercial perfusion tools and a research tool. These comparisons show a mean SSIM around 0.8 for all comparisons, indicating a good and stable correlation with FDA-approved tools. The code for PyPeT is openly available at our GitHub https://github.com/Marijn311/CT-and-MR-Perfusion-Tool

</details>


### [19] [Smooth Total variation Regularization for Interference Detection and Elimination (STRIDE) for MRI](https://arxiv.org/abs/2511.13628)
*Alexander Mertens,Diego Martinez,Amgad Louka,Ying Yang,Chad Harris,Ian Connell*

Main category: eess.IV

TL;DR: STRIDE方法通过利用MRI图像的总变分平滑性来改进外部传感器电磁干扰去除，在0.5T扫描仪上测试显示比标准方法更好的EMI去除效果。


<details>
  <summary>Details</summary>
Motivation: MRI需要能够在发射动态电磁干扰的电子设备附近工作，因此需要改进现有的外部传感器EMI去除方法。

Method: STRIDE方法同时测量EMI检测器和主要MR成像线圈的数据，将数据转换到图像域，对每个图像阵列列结合并减去EMI检测器数据，以优化总变分平滑性。

Result: 在体模和体内数据集上测试显示，STRIDE在视觉EMI去除、时间信噪比、EMI去除百分比和RMSE方面均优于标准实现。

Conclusion: STRIDE是一种鲁棒技术，利用固有的MR图像特性提供比标准算法更好的EMI去除性能，特别适用于时变噪声源。

Abstract: MRI is increasingly desired to function near electronic devices that emit potentially dynamic electromagnetic interference (EMI). To accommodate for this, we propose the STRIDE method, which improves on previous external-sensor-based EMI removal methods by exploiting inherent MR image smoothness in its total variation. STRIDE measures data from both EMI detectors and primary MR imaging coils, transforms this data into the image domain, and for each column of the resulting image array, combines and subtracts data from the EMI detectors in a way that optimizes for total-variation smoothness. Performance was tested on phantom and in-vivo datasets with a 0.5T scanner. STRIDE resulted in visually better EMI removal, higher temporal SNR, larger EMI removal percentage, and lower RMSE than standard implementations. STRIDE is a robust technique that leverages inherent MR image properties to provide improved EMI removal performance over standard algorithms, particularly for time-varying noise sources.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [20] [Inverted C-Shaped Slots Loaded Exponential Tapered Triple Band Notched Ultra Wideband (UWB) Antenna](https://arxiv.org/abs/2511.11844)
*Olaoluwa A. Adegboye,Kufre M. Udofia,Akaninyene Obot*

Main category: eess.SP

TL;DR: 提出一种指数锥形三陷波超宽带天线设计策略，通过在辐射贴片上切割两个倒C形槽和在馈线上蚀刻U形槽，实现对Wi-MAX、WLAN和X波段三个频段的频率抑制。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够有效抑制特定干扰频段的超宽带天线，解决Wi-MAX、WLAN和X波段等频段对超宽带系统的干扰问题。

Method: 使用指数锥形变换器匹配微带线馈电和辐射贴片，在辐射贴片上切割两个倒C形槽抑制Wi-MAX和WLAN频段，在馈线上蚀刻U形槽抑制X波段，并最小化交叉耦合效应。

Result: 天线成功抑制了3.5GHz(Wi-MAX)、5.5GHz(WLAN)和7.5GHz(X波段)三个频段，测量结果和图表显示设计可靠，满足超宽带设计要求。

Conclusion: 所提出的指数锥形三陷波超宽带天线设计策略有效可行，能够同时抑制多个干扰频段，为超宽带系统提供了可靠的抗干扰解决方案。

Abstract: This research presents a simple strategy for designing an exponentially tapered, triple-notched ultrawideband antenna. The antenna's microstrip line feed and radiating patch are matched using an exponential tapered transformer. This method inserts antenna notch elements, by cutting two inverted C-shaped slots in the radiating patch; frequency rejection can be achieved for WI-MAX and wireless LAN. The X-band is rejected by etching a U-shaped slot in the feedline. When embedding the notch elements, cross-coupling was minimized. The desired antenna was designed, simulated, and measured. The measured results and graphs show that our proposed design is reliable. This band notched antenna rejects 3.5 GHz (Wi-MAX band, 3.3 to 3.7 GHz), 5.5 GHz (WLAN 2 band, 5.15 to 5.825 GHz), and 7.5 GHz (for satellite downlink X - band-7.25 GHz to 7.75 GHz). The proposed antenna meets UWB design requirements.

</details>


### [21] [AI-Open-RAN for Non-Terrestrial Networks](https://arxiv.org/abs/2511.11947)
*Tri Nhu Do*

Main category: eess.SP

TL;DR: 提出了AIO-RAN-NTN概念，这是一个基于开放架构和人工智能的统一非地面网络无线接入网络，通过AI驱动的KPI预测来缓解移动性影响。


<details>
  <summary>Details</summary>
Motivation: 推动下一代电信网络的互操作性、灵活性和智能化，特别是在非地面网络环境中。

Method: 开发了集成AIO-RAN-NTN蓝图，使用OpenAirInterface平台实现5G独立组网系统测试床，并训练AI模型预测关键性能指标。

Result: 实验表明基于AIO的独立架构对移动性敏感，即使低速移动也会受影响，但通过AI驱动的KPI预测可以缓解这一限制。

Conclusion: AIO-RAN-NTN架构能够有效提升非地面网络的性能，AI技术是解决移动性问题的关键手段。

Abstract: In this paper, we propose the concept of AIO-RAN-NTN, a unified all-in-one Radio Access Network (RAN) for Non-Terrestrial Networks (NTNs), built on an open architecture that leverages open interfaces and artificial intelligence (AI)-based functionalities. This approach advances interoperability, flexibility, and intelligence in next-generation telecommunications. First, we provide a concise overview of the state-of-the-art architectures for Open-RAN and AI-RAN, highlighting key network functions and infrastructure elements. Next, we introduce our integrated AIO-RAN-NTN blueprint, emphasizing how internal and air interfaces from AIO-RAN and the 3rd Generation Partnership Project (3GPP) can be applied to emerging environments such as NTNs. To examine the impact of mobility on AIO-RAN, we implement a testbed transmission using the OpenAirInterface platform for a standalone (SA) New Radio (NR) 5G system. We then train an AI model on realistic data to forecast key performance indicators (KPIs). Our experiments demonstrate that the AIO-based SA architecture is sensitive to mobility, even at low speeds, but this limitation can be mitigated through AI-driven KPI forecasting.

</details>


### [22] [Temporal Micro-Doppler Spectrogram-based ViT Multiclass Target Classification](https://arxiv.org/abs/2511.11951)
*Nghia Thinh Nguyen,Tri Nhu Do*

Main category: eess.SP

TL;DR: 提出了一种基于Transformer的T-MDS-ViT模型，用于毫米波FMCW雷达微多普勒谱图的多目标分类，通过跨轴注意力机制处理时空张量，在分类准确率和实时部署方面优于现有CNN方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的方法在处理雷达微多普勒谱图时存在局限性，需要一种能够显式建模MDS数据时序特性并处理目标重叠和部分遮挡的架构。

Method: 设计Transformer架构处理堆叠的RVA时空张量，使用补丁嵌入和跨轴注意力机制，在注意力层中利用移动感知约束保持目标可分性。

Result: 提出的框架在分类准确率上优于现有CNN方法，同时具有更好的数据效率和实时部署能力。

Conclusion: T-MDS-ViT通过注意力机制有效建模MDS数据的时空特性，为雷达目标分类提供了更优的解决方案。

Abstract: In this paper, we propose a new Temporal MDS-Vision Transformer (T-MDS-ViT) for multiclass target classification using millimeter-wave FMCW radar micro-Doppler spectrograms. Specifically, we design a transformer-based architecture that processes stacked range-velocity-angle (RVA) spatiotemporal tensors via patch embeddings and cross-axis attention mechanisms to explicitly model the sequential nature of MDS data across multiple frames. The T-MDS-ViT exploits mobility-aware constraints in its attention layer correspondences to maintain separability under target overlaps and partial occlusions. Next, we apply an explainable mechanism to examine how the attention layers focus on characteristic high-energy regions of the MDS representations and their effect on class-specific kinematic features. We also demonstrate that our proposed framework is superior to existing CNN-based methods in terms of classification accuracy while achieving better data efficiency and real-time deployability.

</details>


### [23] [Resource Allocation for Transmissive RIS Transceiver Enabled SWIPT Systems](https://arxiv.org/abs/2511.11980)
*Yuan Guo,Wen Chen,Xudong Bai,Chong He,Qiong Wu*

Main category: eess.SP

TL;DR: 提出了一种新型透射式可重构智能表面(TRIS)收发器赋能的SWIPT框架，通过优化TRIS收发器的波束成形来最大化信息解码用户的速率和，同时满足能量收集用户的收获质量和每天线功率约束。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统SWIPT系统中信息传输和能量收集之间的权衡问题，利用TRIS技术实现更高效的同时无线信息和能量传输。

Method: 将原始非凸问题重构为半定规划问题，然后使用逐次凸逼近与基于惩罚的方法相结合的高效优化算法进行求解。

Result: 数值结果验证了所提出算法的有效性。

Conclusion: TRIS收发器赋能的SWIPT框架能够有效提升信息解码用户的性能，同时满足能量收集用户的需求。

Abstract: A novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) framework is proposed. The sum-rate of the information decoding (ID) users is maximized by optimizing the TRIS transceiver's beamforming, subject to the energy harvesting (EH) users' quality-of-harvest and the per-antenna power constraints. To solve this non-convex problem, we develop an efficient optimization algorithm. First, the original problem is reformulated as a semi-definite programming (SDP) problem. The resulting SDP problem is then addressed using successive convex approximation (SCA) combined with a penalty-based method. Numerical results demonstrate the effectiveness of the algorithm.

</details>


### [24] [Beamforming for Transmissive RIS Transmitter Enabled Simultaneous Wireless Information and Power Transfer Systems](https://arxiv.org/abs/2511.11985)
*Yuan Guo,Wen Chen,Yanze Zhu,Zhendong Li,Qiong Wu,Kunlun Wang*

Main category: eess.SP

TL;DR: 本文研究了一种新型透射式可重构智能表面(TRIS)收发器赋能的SWIPT系统，通过WMMSE和MM方法开发了SOCP算法，并使用ADMM方法处理功率约束，实现了高效并行计算。


<details>
  <summary>Details</summary>
Motivation: 在具有多个信息解码和能量收集用户的SWIPT系统中，传统方法难以处理非凸目标函数和能量收集约束，特别是存在大量单元功率约束时计算复杂度高。

Method: 采用WMMSE框架和MM方法提出SOCP算法，并应用ADMM方法处理单元功率约束，开发了计算高效且高度并行的算法。

Result: 数值结果验证了所提算法的收敛性和有效性，低复杂度算法在保持性能的同时显著降低了计算复杂度。

Conclusion: 成功解决了TRIS收发器赋能的SWIPT系统优化问题，提出的算法在性能和计算效率方面均表现优异。

Abstract: This paper investigates a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) system with multiple information decoding (ID) and energy harvesting (EH) users. Under the considered system model, we formulate an optimization problem that maximizes the sum-rate of all ID users via the design of the TRIS transceiver's active beamforming. The design is constrained by per-antenna power limits at the TRIS transceiver and by the minimum harvested energy demand of all EH users. Due to the non-convexity of the objective function and the energy harvesting constraint, the sum-rate problem is difficult to tackle. To solve this challenging optimization problem, by leveraging the weighted minimum mean squared error (WMMSE) framework and the majorization-minimization (MM) method, we propose a second-order cone programming (SOCP)-based algorithm. Per-element power constraints introduce a large number of constraints, making the problem considerably more difficult. By applying the alternating direction method of multipliers (ADMM) method, we successfully develop an analytical, computationally efficient, and highly parallelizable algorithm to address this challenge. Numerical results are provided to validate the convergence and effectiveness of the proposed algorithms. Furthermore, the low-complexity algorithm significantly reduces computational complexity without performance degradation.

</details>


### [25] [MUSTEM: A Dual-Modality System for Vibrotactile and Visual Translation of Music as an Assistive Technology](https://arxiv.org/abs/2511.12045)
*Paloma Sette,Maria Werneck,William Barbosa,Ana Loubacker*

Main category: eess.SP

TL;DR: MUSTEM系统通过振动触觉和视觉界面将音乐转化为多感官体验，帮助聋人和听力障碍者感受音乐的情感和结构。


<details>
  <summary>Details</summary>
Motivation: 解决聋人和听力障碍群体在音乐情感和结构体验方面的可访问性挑战。

Method: 采用双模态方法：1) 低成本便携硬件原型，实时分析音频并将不同频段映射到四通道振动触觉系统；2) 高保真软件模拟，将音乐元素解码为直观的视觉界面。

Result: 初步反馈显示7名聋人用户认为系统的空间振动触觉映射可感知且引人入胜。所有源代码和硬件设计已开源。

Conclusion: MUSTEM为感官替代提供了全面框架，为聋人社区提供了一种可行的途径，让他们不仅能感受振动，还能体验结构化和情感共鸣的视觉触觉语言。

Abstract: The emotional and structural experience of music remains a significant accessibility challenge for the deaf and hard of hearing community. This paper introduces MUSTEM (Multisensorial Emotional Translation), a novel system designed to translate music into a rich, coherent, and scientifically-grounded sensory experience. We present a dual-modality approach addressing this challenge through two interconnected components. First, a low-cost, portable hardware prototype that performs real-time audio analysis, mapping distinct frequency bands (sub-bass, bass, mid-range, treble) to a four-channel vibrotactile system, allowing users to feel the music's rhythmic and foundational structure. Second, to overcome the processing limitations of embedded hardware, we developed a high-fidelity software simulation that demonstrates the full potential of the visual translation. This assistive dashboard decodes musical components - such as rhythm, harmony, and frequency spectrum - into an intuitive and educational visual interface. MUSTEM offers a comprehensive framework for sensory substitution, presenting a viable and accessible pathway for the deaf community to experience music not just as vibration, but as a structured, substantiated and emotionally resonant visual and tactile language. Preliminary feedback from seven deaf users suggests the system's spatial vibrotactile mapping is perceptible and engaging. All source code and hardware designs are released as open-source. Video demonstrations and open-source code are available on the project's official channel.

</details>


### [26] [Near-Real-Time InSAR Phase Estimation for Large-Scale Surface Displacement Monitoring](https://arxiv.org/abs/2511.12051)
*Scott Staniewicz,Sara Mirzaee,Heresh Fattahi,Talib Oliver-Cabrera,Emre Havazli,Geoffrey Gunter,Se-Yeon Jeon,Mary Grace Bato,Jinwoo Kim,Simran S. Sangha,Bruce Chapman,Alexander L. Handwerger,Marin Govorcin,Piyush Agram,David Bekaert*

Main category: eess.SP

TL;DR: 提出了一种用于近实时InSAR地表形变监测的序列相位连接方法，能够在新数据采集后几小时内生成位移估计，无需重新处理历史数据。


<details>
  <summary>Details</summary>
Motivation: 实现近实时的InSAR地表形变监测需要能够高效整合新采集数据而无需重新处理历史档案的处理算法。

Method: 使用压缩单视复图像(SLCs)的序列相位连接方法，采用迷你堆栈参考方案保持跨处理批次的相位一致性，包含在线持久和分布式散射体识别方法，以及L1范数网络反演限制解缠误差传播。

Result: 成功应用于OPERA地表位移产品，验证显示与GPS测量和InSAR残差分析在毫米级速度估计上一致，成功恢复了基拉韦厄火山2018年喷发期间的米级同喷发位移，并在三姐妹火山检测到微弱抬升。

Conclusion: 该方法为开放科学界在云环境中处理大型InSAR数据集提供了显著进步，所有软件已作为开源库提供。

Abstract: Operational near-real-time monitoring of Earth's surface deformation using Interferometric Synthetic Aperture Radar (InSAR) requires processing algorithms that efficiently incorporate new acquisitions without reprocessing historical archives. We present sequential phase linking approach using compressed single-look-complex images (SLCs) capable of producing surface displacement estimates within hours of the time of a new acquisition. Our key algorithmic contribution is a mini-stack reference scheme that maintains phase consistency across processing batches without adjusting or re-estimating previous time steps, enabling straightforward operational deployment. We introduce online methods for persistent and distributed scatterer identification that adapt to temporal changes in surface properties through incremental amplitude statistics updates. The processing chain incorporates multiple complementary metrics for pixel quality that are reliable for small SLC stack sizes, and an L1-norm network inversion to limit propagation of unwrapping errors across the time series. We use our algorithm to produce OPERA Surface Displacement from Sentinel-1 product, the first continental-scale surface displacement product over North America. Validation against GPS measurements and InSAR residual analysis demonstrates millimeter-level agreement in velocity estimates in varying environmental conditions. We demonstrate our algorithm's capabilities with a successful recovery of meter-scale co-eruptive displacement at Kilauea volcano during the 2018 eruption, as well as detection of subtle uplift at Three Sisters volcano, Oregon- a challenging environment for C-band InSAR due to dense vegetation and seasonal snow. We have made all software available as open source libraries, providing a significant advancement to the open scientific community's ability to process large InSAR data sets in a cloud environment.

</details>


### [27] [Informed Bootstrap Augmentation Improves EEG Decoding](https://arxiv.org/abs/2511.12073)
*Woojae Jeong,Wenhui Cui,Kleanthis Avramidis,Takfarinas Medani,Shrikanth Narayanan,Richard Leahy*

Main category: eess.SP

TL;DR: 提出了一种基于可靠性的加权自举方法，通过优先选择信息量更大的试验样本来生成更高质量的EEG数据增强样本，在句子评估范式中显著提升了解码性能。


<details>
  <summary>Details</summary>
Motivation: 传统EEG数据增强方法采用均匀平均，忽视了不同试验样本的信息价值差异，可能导致表征质量下降。需要一种能够识别并优先使用更可靠试验的方法来改善特征表示。

Method: 开发了加权自举方法，基于相对ERP差异计算试验权重，在概率采样和平均过程中优先选择更可靠的试验来生成增强样本。

Result: 在句子评估范式中，加权自举方法相比未加权方法显著提升了解码准确率（从68.35%提升至71.25%），表明强调可靠试验能够增强表征质量。

Conclusion: 基于可靠性的数据增强方法能够产生更鲁棒和更具区分度的EEG表征，为数据受限或复杂范式下的神经解码提供了有效解决方案。

Abstract: Electroencephalography (EEG) offers detailed access to neural dynamics but remains constrained by noise and trial-by-trial variability, limiting decoding performance in data-restricted or complex paradigms. Data augmentation is often employed to enhance feature representations, yet conventional uniform averaging overlooks differences in trial informativeness and can degrade representational quality. We introduce a weighted bootstrapping approach that prioritizes more reliable trials to generate higher-quality augmented samples. In a Sentence Evaluation paradigm, weights were computed from relative ERP differences and applied during probabilistic sampling and averaging. Across conditions, weighted bootstrapping improved decoding accuracy relative to unweighted (from 68.35% to 71.25% at best), demonstrating that emphasizing reliable trials strengthens representational quality. The results demonstrate that reliability-based augmentation yields more robust and discriminative EEG representations. The code is publicly available at https://github.com/lyricists/NeuroBootstrap.

</details>


### [28] [Bayesian Learning Aided Simultaneous Sparse Estimation of Dual-Wideband THz Channels in Multi-User Hybrid MIMO Systems](https://arxiv.org/abs/2511.12102)
*Abhisha Garg,Akash Kumar,Suraj Srivastava,Nimish Yadav,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出贝叶斯群稀疏回归方法用于太赫兹混合MIMO系统中的双宽带信道估计，结合低分辨率ADC和贝叶斯克拉美罗界分析性能。


<details>
  <summary>Details</summary>
Motivation: 太赫兹大规模MIMO系统需要处理高采样率和大量天线带来的功耗与硬件复杂度问题，同时需要准确估计空间和频率双宽带信道。

Method: 开发实用的双宽带太赫兹信道模型，采用低分辨率ADC，使用Bussgang分解线性化量化模型，提出贝叶斯群稀疏回归框架进行信道学习。

Result: 通过广泛仿真验证，所提BGSR方法在归一化均方误差和误码率性能上优于其他稀疏估计技术。

Conclusion: BGSR方法能有效解决太赫兹双宽带MIMO系统的信道估计问题，在性能提升和复杂度控制方面具有优势。

Abstract: This work conceives the Bayesian Group-Sparse Regression (BGSR) for the estimation of a spatial and frequency wideband, i.e., a dual wideband channel in Multi-User (MU) THz hybrid MIMO scenarios. We develop a practical dual wideband THz channel model that incorporates absorption losses, reflection losses, diffused ray modeling and angles of arrival/departure (AoAs/AoDs) using a Gaussian Mixture Model (GMM). Furthermore, a low-resolution analog-to-digital converter (ADC) is employed at each RF chain, which is crucial for wideband THz massive MIMO systems to reduce power consumption and hardware complexity, given the high sampling rates and large number of antennas involved. The quantized MU THz MIMO model is linearized using the popular Bussgang decomposition followed by BGSR based channel learning framework that results in sparsity across different subcarriers, where each subcarrier has its unique dictionary matrix. Next, the Bayesian Cramér Rao Bound (BCRB) is devised for bounding the normalized mean square error (NMSE) performance. Extensive simulations were performed to assess the performance improvements achieved by the proposed BGSR method compared to other sparse estimation techniques. The metrics considered for quantifying the performance improvements include the NMSE and bit error rate (BER).

</details>


### [29] [A 24-GHz CMOS Transformer-Based Three-Tline Series Doherty Power Amplifier Achieving 39% PAE](https://arxiv.org/abs/2511.12137)
*Zheng Wang,Yifu Li,Yuchao Mei,Xinyu Sui,Qingbin Li,Xu Luo,Rui Wang,Dongxin Ni,Jian Pang*

Main category: eess.SP

TL;DR: 基于变压器的三传输线级联Doherty功率放大器，采用65nm CMOS工艺，针对宽带K/Ka波段应用，通过阻抗缩放网络实现有效负载调制和降低阻抗变换比。


<details>
  <summary>Details</summary>
Motivation: 针对下一代无线系统中毫米波相控阵发射机对高效率宽带功率放大器的需求，开发适用于K/Ka波段的Doherty功率放大器。

Method: 采用变压器基三传输线级联结构，在输出匹配结构中集成阻抗缩放网络，使用堆叠共源共栅晶体管，实现负载调制和降低功率回退时的阻抗变换比。

Result: 小信号增益带宽22-32.5GHz，饱和输出功率21.6dBm，峰值功率附加效率39%，6dB回退时效率仍高于24%。

Conclusion: 该设计验证了其在下一代无线系统毫米波相控阵发射机中的适用性，实现了宽带高效率性能。

Abstract: This paper presents a transformer-based three- transmission-line (Tline) series Doherty power amplifier (PA) implemented in 65-nm CMOS, targeting broadband K/Ka-band applications. By integrating an impedance-scaling network into the output matching structure, the design enables effective load modulation and reduced impedance transformation ratio (ITR) at power back-off when employing stacked cascode transistors. The PA demonstrates a -3-dB small-signal gain bandwidth from 22 to 32.5 GHz, a saturated output power (Psat) of 21.6 dBm, and a peak power-added efficiency (PAE) of 39%. At 6dB back-off, the PAE remains above 24%, validating its suitability for high- efficiency mm-wave phased-array transmitters in next-generation wireless systems.

</details>


### [30] [A Linear Implementation of an Analog Resonate-and-Fire Neuron](https://arxiv.org/abs/2511.12297)
*Angqi Liu,Filippo Moro,Sebastian Billaudelle,Melika Payvand*

Main category: eess.SP

TL;DR: 提出了一种基于22nm FD-SOI技术的共振放电神经元，该神经元符合状态空间模型原理，同时保持了基于脉冲通信的效率，在关键词识别任务中表现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 将振荡动力学与状态空间模型相结合，利用共振放电神经元的稀疏事件通信优势，开发更高效的神经形态硬件计算原语。

Method: 在22nm FD-SOI技术中构建共振放电神经元，分析其动力学特性、线性度以及对PVT变化的鲁棒性，并评估其功耗、性能和面积权衡。

Result: 电路特性被映射到系统级仿真中，在关键词识别任务中显示其非理想性不会影响性能，RAF神经元被证明是稳健且节能的计算原语。

Conclusion: RAF神经元作为稳健、节能的神经形态硬件计算原语具有良好前景，其非理想性在实际应用中不会显著影响性能。

Abstract: Oscillatory dynamics have recently proven highly effective in machine learning (ML), particularly through State-Space-Models (SSM) that leverage structured linear recurrences for long-range temporal processing. Resonate-and-Fire neurons capture such oscillatory behavior in a spiking framework, offering strong expressivity with sparse event-based communication. While early analog RAF circuits employed nonlinear coupling and suffered from process sensitivity, modern ML practice favors linear recurrence. In this work, we introduce a resonate-and-fire (RAF) neuron, built in 22nm Fully-Depleted Silicon-on-Insulator technology, that aligns with SSM principles while retaining the efficiency of spike-based communication. We analyze its dynamics, linearity, and resilience to Process, Voltage, and Temperature variations, and evaluate its power, performance, and area trade-offs. We map the characteristics of our circuit into a system-level simulation where our RAF neuron is utilized in a keyword-spotting task, showing that its non-idealities do not hinder performance. Our results establish RAF neurons as robust, energy-efficient computational primitives for neuromorphic hardware.

</details>


### [31] [ISAC with Affine Frequency Division Multiplexing: An FMCW-Based Signal Processing Perspective](https://arxiv.org/abs/2511.12308)
*Jiajun Zhu,Yanqun Tang,Cong Yi,Haoran Yin,Yuanhan Ni,Fan Liu,Zhiqiang Wei,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本文从雷达波形角度研究AFDM在高移动性ISAC中的感知潜力，提出参数选择准则建立AFDM子载波与FMCW的数学等价性，开发DD-DAFT域输入输出模型，设计两种匹配滤波感知算法，实现无导频感知并展示性能权衡。


<details>
  <summary>Details</summary>
Motivation: 研究AFDM在高移动性集成感知与通信中的感知能力，从雷达波形角度探索其物理机制，解决传统方法在高速移动场景下的局限性。

Method: 提出参数选择准则建立AFDM子载波与FMCW的数学等价性；开发DD-DAFT域输入输出模型揭示啁啾-信道交互产生的DD耦合效应；设计时频域和DD-DAFT域两种匹配滤波感知算法。

Result: 仿真显示算法实现有效无导频感知，在多数场景下优于经典AFDM和其他变体，揭示了感知性能、通信开销和计算复杂度之间的基本权衡关系。

Conclusion: AFDM在高移动性ISAC中具有优越的感知潜力，所提方法为理解AFDM感知机制提供了新视角，并实现了性能提升。

Abstract: This paper investigates the sensing potential of affine frequency division multiplexing (AFDM) in high-mobility integrated sensing and communication (ISAC) from the perspective of radar waveforms. We introduce an innovative parameter selection criterion that establishes a precise mathematical equivalence between AFDM subcarriers and Nyquist-sampled frequency-modulated continuous-wave (FMCW). This connection not only provides a clear physical insight into AFDM's sensing mechanism but also enables a direct mapping from the DAFT index to delay-Doppler (DD) parameters of wireless channels. Building on this, we develop a novel input-output model in a DD-parameterized DAFT (DD-DAFT) domain for AFDM, which explicitly reveals the inherent DD coupling effect arising from the chirp-channel interaction. Subsequently, we design two matched-filtering sensing algorithms. The first is performed in the time-frequency domain with low complexity, while the second is operated in the DD-DAFT domain to precisely resolve the DD coupling. Simulations show that our algorithms achieve effective pilot-free sensing and demonstrate a fundamental trade-off between sensing performance, communication overhead, and computational complexity. The proposed AFDM outperforms classical AFDM and other variants in most scenarios.

</details>


### [32] [Toward ISAC-empowered subnetworks: Cooperative localization and iterative node selection](https://arxiv.org/abs/2511.12348)
*Mostafa Nozari,Israel Leyva-Mayorga,Fabio Saggese,Gilberto Berardinelli*

Main category: eess.SP

TL;DR: 提出一种低复杂度迭代节点选择算法，用于ISAC子网络中的单站目标定位，在资源受限条件下最大化定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决集成感知与通信(ISAC)子网络中感知与通信之间的权衡问题，特别是在单站目标定位场景下。

Method: 利用子网络部署的空间多样性，动态优化感知子网络集合，采用低复杂度迭代节点选择算法。

Result: 在AWGN信道中仅需3次迭代即可实现亚7厘米精度，相比最佳基准方法在相同感知预算下提升97%以上。增加空间多样性可增强感知鲁棒性。

Conclusion: 减少感知迭代次数和感知子网络数量可提高吞吐量，但会降低定位精度，量化了感知-通信权衡关系。

Abstract: This paper tackles the sensing-communication trade-off in integrated sensing and communication (ISAC)-empowered subnetworks for mono-static target localization. We propose a low-complexity iterative node selection algorithm that exploits the spatial diversity of subnetwork deployments and dynamically refines the set of sensing subnetworks to maximize localization accuracy under tight resource constraints. Simulation results show that our method achieves sub-7 cm accuracy in additive white Gaussian noise (AWGN) channels within only three iterations, yielding over 97% improvement compared to the best-performing benchmark under the same sensing budget. We further demonstrate that increasing spatial diversity through additional antennas and subnetworks enhances sensing robustness, especially in fading channels. Finally, we quantify the sensing-communication trade-off, showing that reducing sensing iterations and the number of sensing subnetworks improves throughput at the cost of reduced localization precision.

</details>


### [33] [Cross-Layer Design for Near-Field mmWave Beam Management and Scheduling under Delay-Sensitive Traffic](https://arxiv.org/abs/2511.12470)
*Zijun Wang,Anjali Omer,Jacob Chakareski,Nicholas Mastronarde,Rui Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种跨层控制方法，将物理层波束管理与MAC层服务相结合，通过深度强化学习优化近场波束训练策略，在保证服务质量的同时显著降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络使用毫米波/太赫兹频谱和超大天线阵列，使系统工作在近场区域，传统远场波束管理性能下降，波束训练成本增加且需要更频繁执行，需要平衡训练开销与数据传输效率。

Method: 将问题建模为部分可观测马尔可夫决策过程，使用深度强化学习求解，控制器决策何时重新训练、训练强度（导频数量和稀疏度）以及发射功率分配。

Result: 在真实近场信道和不同移动性、流量负载的仿真中，学习策略比5G-NR风格基线表现更好：吞吐量比DFT扫描高85.5%，溢出率降低78%，能耗相当。

Conclusion: 该方法为开销感知、流量自适应的近场波束管理提供了实用路径，对数字孪生、空间计算和沉浸式通信等低延迟、高速率应用具有重要意义。

Abstract: Next-generation wireless networks will rely on mmWave/sub-THz spectrum and extremely large antenna arrays (ELAAs). This will push their operation into the near field where far-field beam management degrades and beam training becomes more costly and must be done more frequently. Because ELAA training and data transmission consume energy and training trades off with service time, we pose a cross-layer control problem that couples PHY-layer beam management with MAC-layer service under delay-sensitive traffic. The controller decides when to retrain and how aggressively to train (pilot count and sparsity) while allocating transmit power, explicitly balancing pilot overhead, data-phase rate, and energy to reduce the queueing delay of MAC-layer frames/packets to be transmitted. We model the problem as a partially observable Markov decision process and solve it with deep reinforcement learning. In simulations with a realistic near-field channel and varying mobility and traffic load, the learned policy outperforms strong 5G-NR--style baselines at a comparable energy: it achieves 85.5% higher throughput than DFT sweeping and reduces the overflow rate by 78%. These results indicate a practical path to overhead-aware, traffic-adaptive near-field beam management with implications for emerging low-latency, high-rate next-generation applications such as digital twin, spatial computing, and immersive communication.

</details>


### [34] [Lightweight Deep Autoencoder for ECG Denoising with Morphology Preservation and Near Real-Time Hardware Deployment](https://arxiv.org/abs/2511.12478)
*Mahdi Pirayesh Shirazi Nejad,David Hicks,Matt Valentine,Ki H. Chon*

Main category: eess.SP

TL;DR: 提出了一种轻量级深度学习去噪框架，采用紧凑自编码器架构，在-5 dB强噪声条件下训练，在多种噪声配置和SNR水平下均表现稳定，能有效抑制噪声同时保持心电图形态完整性，并在树莓派4上验证了边缘部署可行性。


<details>
  <summary>Details</summary>
Motivation: 心电图信号常受基线漂移、运动伪影和肌电干扰等多种噪声污染，严重影响临床诊断准确性，需要开发轻量级且能保持波形形态的去噪方法。

Method: 构建紧凑自编码器架构，在-5 dB强噪声条件下训练，使用严格划分的数据集防止数据泄漏，在七种噪声配置和三个SNR水平(-5 dB、0 dB、+5 dB)下进行广泛评估。

Result: 模型在所有测试条件下均表现一致的去噪性能，对心室心动过速和心室颤动等关键心律能有效抑制噪声而不改变诊断必需的节律特征，在树莓派4上推理延迟仅为1.41秒/14秒ECG段。

Conclusion: 该研究提供了一种轻量级、硬件验证且形态可靠的ECG去噪解决方案，适合集成到便携式或可穿戴医疗系统中。

Abstract: Electrocardiogram (ECG) signals are often degraded by various noise sources such as baseline wander, motion artifacts, and electromyographic interference, posing a major challenge in clinical settings. This paper presents a lightweight deep learning-based denoising framework, forming a compact autoencoder architecture. The model was trained under severe noise conditions (-5 dB signal-to-noise ratio (SNR)) using a rigorously partitioned dataset to ensure no data leakage and robust generalization. Extensive evaluations were conducted across seven noise configurations and three SNR levels (-5 dB, 0 dB, and +5 dB), showing consistent denoising performance with minimal morphological distortion, critical for maintaining diagnostic integrity. In particular, tests on clinically vital rhythms such as ventricular tachycardia (VT) and ventricular fibrillation (VF) confirm that the proposed model effectively suppresses noise without altering arrhythmic features essential for diagnosis. Visual and quantitative assessments, including SNR improvement, RMSE, and correlation metrics, validate the model's efficacy in preserving waveform fidelity. To demonstrate real-world applicability, the model was deployed on a Raspberry Pi 4 using TensorFlow Lite with float16 precision. Inference latency was measured at just 1.41 seconds per 14-second ECG segment, indicating feasibility for near-real-time use in edge devices. Overall, this study introduces a lightweight, hardware-validated, and morphologically reliable ECG denoising solution suitable for integration into portable or wearable healthcare systems.

</details>


### [35] [Robust Radar HRRP Recognition under Non-uniform Jamming Based on Complex-valued Frequency Attention Network](https://arxiv.org/abs/2511.12508)
*Yanhao Wang,Lei Wang,Jie Wang,Yimin Liu*

Main category: eess.SP

TL;DR: 提出一种端到端训练的雷达目标识别网络，通过CFA模块在复数频谱上生成自适应滤波器，抑制强干扰频段并保留目标信息，在严重干扰环境下比传统方法识别准确率提高近9%。


<details>
  <summary>Details</summary>
Motivation: 复杂电磁环境中多种干扰源导致频谱功率不均匀，严重扭曲目标高分辨率距离像(HRRP)，影响传统HRRP目标识别方法的性能和可靠性。

Method: 设计CFA模块直接在接收回波的复数频谱上操作，学习生成自适应频域滤波器，对强干扰频段赋予较低权重，同时保留干净频段中的关键目标信息，滤波后的频谱送入分类器进行识别。

Result: 在包含多种干扰组合的模拟HRRP数据上的实验结果表明，该方法在严重干扰条件下比传统基于模型的方法识别准确率提高近9%，且计算开销可忽略不计。

Conclusion: 该方法在挑战性干扰环境中展现出卓越的性能和鲁棒性，为复杂电磁环境下的雷达目标识别提供了有效解决方案。

Abstract: Complex electromagnetic environments, often containing multiple jammers with different jamming patterns, produce non-uniform jamming power across the frequency spectrum. This spectral non-uniformity directly induces severe distortion in the target's HRRP, consequently compromising the performance and reliability of conventional HRRP-based target recognition methods. This paper proposes a novel, end-to-end trained network for robust radar target recognition. The core of our model is a CFA module that operates directly on the complex spectrum of the received echo. The CFA module learns to generate an adaptive frequency-domain filter, assigning lower weights to bands corrupted by strong jamming while preserving critical target information in cleaner bands. The filtered spectrum is then fed into a classifier backbone for recognition. Experimental results on simulated HRRP data with various jamming combinations demonstrate our method's superiority. Notably, under severe jamming conditions, our model achieves a recognition accuracy nearly 9% higher than traditional model-based approaches, all while introducing negligible computational overhead. This highlights its exceptional performance and robustness in challenging jamming environments.

</details>


### [36] [A mixed-signal analogue front-end for brain-implantable neural interfaces using a digital fixed-point IIR filter and bulk offset cancellation](https://arxiv.org/abs/2511.12540)
*Dimitris Antoniadis,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 本文提出了一种混合信号模拟前端，用于同时记录细胞外动作电位和局部场电位，集成了低噪声放大器、SAR ADC和反馈路径的IIR滤波器，实现了低功耗、小面积的高性能神经信号监测。


<details>
  <summary>Details</summary>
Motivation: 随着微型植入式神经电子设备的发展，脑机接口在运动障碍、癫痫等神经系统疾病的治疗中展现出临床潜力，需要能够同时记录不同类型神经信号的高性能模拟前端。

Method: 采用混合信号设计，前向路径包含低噪声放大器和逐次逼近寄存器ADC，反馈路径使用固定点无限脉冲响应切比雪夫II型低通滤波器，通过R-2R伪电阻DAC控制LNA输入差分对来抑制亚毫赫兹分量。

Result: 该模拟前端实现了41.42dB增益，每通道功耗2.178μA，面积0.198mm²，支持0.1Hz至10kHz的神经信号监测，输入参考积分噪声为3.59μVrms。

Conclusion: 所提出的模拟前端设计在功耗、面积和性能方面表现出色，为植入式脑机接口应用提供了可行的解决方案。

Abstract: Advances in miniaturised implantable neural electronics have paved the way for therapeutic brain-computer interfaces with clinical potential for movement disorders, epilepsy, and broader neurological applications. This paper presents a mixed-signal analogue front end (AFE) designed to record both extracellular action potentials (EAPs) and local field potentials (LFPs). The feedforward path integrates a low-noise amplifier (LNA) and a successive-approximation-register (SAR) analogue-to-digital converter (ADC), while the feedback path employs a fixed-point infinite-impulse-response (IIR) Chebyshev Type II low-pass filter to suppress sub-mHz components via bulk-voltage control of the LNA input differential pair using two R-2R pseudo-resistor digital-to-analogue converters (DACs). The proposed AFE achieves up to 41.42dB gain, consumes 2.178uA per channel, occupies 0.198mm2 per channel, and supports neural signal monitoring from 0.1Hz to 10kHz with 3.59uVrms input-referred integrated noise.

</details>


### [37] [Near Field Tapering with Slepian Window: Balancing the Range Angle Sidelobe Trade off](https://arxiv.org/abs/2511.12733)
*Ahmed Hussain,Ahmed Sultan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 提出了一种基于Slepian的幅度锥削方法，用于近场波束成形，能同时抑制轴向和横向旁瓣，相比传统均匀窗口在横向和轴向分别实现了约24dB和10dB的峰值旁瓣抑制提升。


<details>
  <summary>Details</summary>
Motivation: 近场波束成形能在距离（轴向）和角度（横向）维度实现目标识别，但任一维度的过高旁瓣会增加干扰敏感性并降低检测性能。传统的幅度锥削技术设计用于远场场景，无法同时抑制近场中的轴向和横向旁瓣。

Method: 提出基于Slepian的幅度锥削方法，通过最大化主瓣能量集中度来实现两个维度的显著旁瓣抑制。

Result: 数值结果显示，与传统均匀窗口相比，所提出的锥削方法在横向域改善了约24dB的峰值旁瓣抑制，在轴向域改善了约10dB的峰值旁瓣抑制。

Conclusion: Slepian-based幅度锥削方法能有效同时抑制近场波束成形中的轴向和横向旁瓣，显著提升检测性能。

Abstract: Near-field beamforming enables target discrimination in both range (axial) and angle (lateral) dimensions. Elevated sidelobes along either dimension, however, increase susceptibility to interference and degrade detection performance. Conventional amplitude tapering techniques, designed for far-field scenarios, cannot simultaneously suppress axial and lateral sidelobes in near-field. In this letter, we propose a Slepian-based amplitude tapering approach that maximizes mainlobe energy concentration, achieving significant sidelobe reduction in both dimensions. Numerical results show that the proposed taper improves peak sidelobe suppression by approximately 24 dB in the lateral domain and 10 dB in the axial domain compared to a conventional uniform window.

</details>


### [38] [Uniform Circular Arrays in Near-Field: Omnidirectional Coverage with Limited Capacity](https://arxiv.org/abs/2511.12750)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 本文研究了均匀圆形阵列(UCA)与均匀线性阵列(ULA)在空间复用性能方面的比较，引入了有效波束聚焦瑞利距离(EBRD)来更准确界定近场区域。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明UCA可以扩展辐射近场区域的角覆盖范围，本文旨在探究这种增强的角覆盖是否能转化为比ULA更好的空间复用性能。

Method: 引入了角度相关的有效波束聚焦瑞利距离(EBRD)指标，推导了UCA的波束深度和EBRD的闭式表达式，并通过仿真比较两种阵列的性能。

Result: 在固定天线元素数量下，ULA实现更窄的波束深度和更长的EBRD；在固定孔径长度下，UCA提供稍窄的波束深度和略长的EBRD。ULA在固定元素约束下获得更高和速率，UCA在固定孔径约束下仅有边际性能提升。

Conclusion: UCA在扩展角覆盖方面的优势并不能直接转化为显著的空间复用性能提升，阵列选择应根据具体约束条件决定。

Abstract: Recent studies suggest that uniform circular arrays (UCAs) can extend the angular coverage of the radiative near field region. This work investigates whether such enhanced angular coverage translates into improved spatial multiplexing performance when compared to uniform linear arrays (ULAs). To more accurately delineate the effective near field region, we introduce the effective beamfocusing Rayleigh distance (EBRD), an angle dependent metric that bounds the spatial region where beamfocusing remains effective. Closed form expressions for both beamdepth and EBRD are derived for UCAs. Our analysis shows that, under a fixed antenna element count, ULAs achieve narrower beamdepth and a longer EBRD than UCAs. Conversely, under a fixed aperture length, UCAs provide slightly narrower beamdepth and a marginally longer EBRD. Simulation results further confirm that ULAs achieve higher sum rate under the fixed element constraint, while UCAs offer marginal performance gain under the fixed aperture constraint.

</details>


### [39] [Distributed Multisensor ISAC](https://arxiv.org/abs/2511.13104)
*Reiner Thomä,Michael Döbereiner,Reza Faramarzahangari,Jonas Gedschold. Marc Francisco Colaco Miranda,Saw James Myint,Steffen Schieler,Christian Schneider,Sebastian Semper,Carsten Smeenk,Gerd Sommerkorn,Zhixiang Zhao*

Main category: eess.SP

TL;DR: 本文提出了多传感器集成感知与通信(MS-ISAC)的基本原理，将其与分布式MIMO雷达相关联，并开发了架构原则、协调方案和分布式数据融合方法。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)将成为未来移动通信网络的服务，通过重用移动网络和无线接入资源实现被动对象和环境的检测识别，构建分布式、无处不在的感知网络。

Method: 开发MS-ISAC架构原则，提出多链路接入、协调、预编码和链路适配方案，使用基于模型的延迟/多普勒估计与跟踪，采用协作被动相干定位(CPCL)进行双站相关和同步。

Result: 建立了MS-ISAC的基本框架，将多用户MIMO通信与分布式MIMO雷达概念相结合，解决了多传感器节点同步和分布式数据融合问题。

Conclusion: MS-ISAC为实现分布式、自适应的无线感知任务和服务提供了理论基础和技术方案，为未来移动网络中的集成感知应用奠定了基础。

Abstract: Integrated Sensing and Communications (ISAC) will become a service in future mobile communication networks. It enables the detection and recognition of passive objects and environments using radar-like sensing. The ultimate advantage is the reuse of the mobile network and radio access resources for scene illumination, sensing, data transportation, computation, and fusion. It enables building a distributed, ubiquitous sensing network that can be adapted for a variety of radio sensing tasks and services.
  In this article, we develop the principles of multi-sensor ISAC (MS-ISAC). MS-ISAC corresponds to multi-user MIMO communication, which in radar terminology is known as distributed MIMO radar. \ First, we develop basic architectural principles for MS-ISAC and link them to example use cases. We then propose a generic MS-ISAC architecture. After a brief reference to multipath propagation and multistatic target reflectivity issues, we outline multilink access, coordination, precoding and link adaptation schemes for MS-ISAC. Moreover, we review model-based estimation and tracking of delay~/~Doppler from sparse OFDMA~/~TDMA frames. We emphasize Cooperative Passive Coherent Location (CPCL) for bistatic correlation and synchronization. Finally, issues of multisensor node synchronization and distributed data fusion are addressed.

</details>


### [40] [Autonomous Sensing UAV for Accurate Multi-User Identification and Localization in Cellular Networks](https://arxiv.org/abs/2511.13171)
*Niccolò Paglierani,Francesco Linsalata,Vineeth Teeda,Davide Scazzoli,Maurizio Magarini*

Main category: eess.SP

TL;DR: 提出了一种使用无人机在5G网络中被动感知并定位多个用户的自主框架，无需与网络基础设施协调，通过捕获上行链路参考信号实现用户识别和定位。


<details>
  <summary>Details</summary>
Motivation: 传统空中服务节点需要与网络基础设施协调，而该研究旨在开发一种独立于基础设施的被动感知无人机，支持低空经济中的态势感知和紧急部署。

Method: 开发了完整的信号处理链，包括同步、用户识别和定位，所有处理都在无人机上实时执行，并自主规划和调整任务工作流程。

Result: 在农村实地测试中定位误差低于3米，在城市模拟场景中低于8米，同时可靠识别每个用户。

Conclusion: 验证了独立于基础设施的感知无人机作为新兴低空经济核心元素的可行性，支持紧急或连接受限环境中的态势感知和快速部署。

Abstract: This paper presents an autonomous sensing frame- work for identifying and localizing multiple users in Fifth Generation (5G) networks using an Unmanned Aerial Vehicle (UAV) that is not part of the serving access network. Unlike conventional aerial serving nodes, the proposed UAV operates passively and is dedicated solely to sensing. It captures Uplink (UL) Sounding Reference Signals (SRS), and requires virtually no coordination with the network infrastructure. A complete signal processing chain is proposed and developed, encompassing synchronization, user identification, and localization, all executed onboard UAV during flight. The system autonomously plans and adapts its mission workflow to estimate multiple user positions within a single deployment, integrating flight control with real-time sensing. Extensive simulations and a full-scale low- altitude experimental campaign validate the approach, showing localization errors below 3 m in rural field tests and below 8 m in urban simulation scenarios, while reliably identifying each user. The results confirm the feasibility of infrastructure-independent sensing UAVs as a core element of the emerging Low Altitude Economy (LAE), supporting situational awareness and rapid deployment in emergency or connectivity-limited environments.

</details>


### [41] [Pinching-Antenna-Enabled Cognitive Radio Networks](https://arxiv.org/abs/2511.13272)
*Zeyang Sun,Xidong Mu,Shuai Han,Sai Xu,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文研究了基于夹持天线的认知无线电网络，通过优化夹持波束成形和功率控制实现主次网络频谱共享，显著提升了频谱效率。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线在认知无线电网络中频谱效率有限，需要开发新的天线技术来改善主次网络间的频谱共享性能。

Method: 提出三阶段优化算法：首先在波导级确定PA粗位置，然后进行波长级精化实现信号建设性组合，最后推导闭式功率控制解。

Result: 仿真结果表明：PA相比传统天线显著提升频谱效率；夹持波束成形设计有效抑制干扰；三阶段优化算法实现主次网络近乎正交传输。

Conclusion: 夹持天线技术结合提出的优化算法能够有效提升认知无线电网络的频谱效率和干扰管理能力。

Abstract: This paper investigates a pinching-antenna (PA)-enabled cognitive radio network, where both the primary transmitter (PT) and secondary transmitter (ST) are equipped with a single waveguide and multiple PAs to facilitate simultaneous spectrum sharing. Under a general Ricean fading channel model, a closed-form analytical expression for the average spectral efficiency (SE) achieved by PAs is first derived. Based on this, a sum-SE maximization problem is formulated to jointly optimize the primary and secondary pinching beamforming, subject to system constraints on the transmission power budgets, minimum antenna separation requirements, and feasible PA deployment regions. To address this non-convex problem, a three-stage optimization algorithm is developed to sequentially optimize both the PT and ST pinching beamforming, and the ST power control. For the PT and ST pinching beamforming optimization, the coarse positions of PA are first determined at the waveguide-level. Then, wavelength-level refinements achieve constructive signal combination at the intended user and destructive superposition at the unintended user. For the ST power control, a closed-form solution is derived. Simulation results demonstrate that i) PAs can achieve significant SE improvements over conventional fixed-position antennas; ii) the proposed pinching beamforming design achieves effective interference suppression and superior performance for both even and odd numbers of PAs; and iii) the developed three-stage optimization algorithm enables nearly orthogonal transmission between the primary and secondary networks.

</details>


### [42] [Sensing-enabled Secure Rotatable Array System Enhanced by Multi-Layer Transmitting RIS](https://arxiv.org/abs/2511.13336)
*Maolin Li,Feng Shu,Minghao Chen,Cunhua Pan,Fuhui Zhou,Yongpeng Wu,Liang Yang*

Main category: eess.SP

TL;DR: 提出了一种基于可旋转阵列系统的安全通信方案，采用双基站架构协同执行窃听者感知和通信任务，通过优化阵列姿态、天线分布、RIS相位矩阵和波束成形矩阵来最大化保密率。


<details>
  <summary>Details</summary>
Motivation: 可编程超表面和可调天线是前景技术，但传统方案在感知目标位于主通信链路上时存在安全挑战，需要解决这一安全漏洞。

Method: 采用双基站架构，提出基于广义瑞利商的两阶段在线算法和基于多智能体深度确定性策略梯度的离线算法，联合优化阵列姿态、天线分布、多层发射RIS相位矩阵和波束成形矩阵。

Result: 仿真结果表明，与传统无阵列姿态调整方案相比，所提方法实现了约22%的保密率提升，且阵列旋转比位置变化提供更高的性能增益。

Conclusion: 可旋转阵列系统能有效提升通信安全性，阵列姿态优化对性能提升至关重要，所提算法能有效解决非凸优化问题。

Abstract: Programmable metasurfaces and adjustable antennas are promising technologies. The security of a rotatable array system is investigated in this paper. A dual-base-station (BS) architecture is adopted, in which the BSs collaboratively perform integrated sensing of the eavesdropper (the target) and communication tasks. To address the security challenge when the sensing target is located on the main communication link, the problem of maximizing the secrecy rate (SR) under sensing signal-to-interference-plus-noise ratio requirements and discrete constraints is formulated. This problem involves the joint optimization of the array pose, the antenna distribution on the array surface, the multi-layer transmitting RIS phase matrices, and the beamforming matrices, which is non-convex. To solve this challenge, an two-stage online algorithm based on the generalized Rayleigh quotient and an offline algorithm based on the Multi-Agent Deep Deterministic Policy Gradient are proposed. Simulation results validate the effectiveness of the proposed algorithms. Compared to conventional schemes without array pose adjustment, the proposed approach achieves approximately 22\% improvement in SR. Furthermore, array rotation provides higher performance gains than position changes.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Guessing Decoding of Short Blocklength Codes](https://arxiv.org/abs/2511.12108)
*Qianfan Wang,Jifan Liang,Peihong Yuan,Ken R. Duffy,Muriel Médard,Xiao Ma*

Main category: cs.IT

TL;DR: 该论文对两种主要的猜测解码方法（GRAND和GCD）进行了统一分析，包括算法实现、ML最优性证明、复杂度分析和性能比较，为下一代短码通信提供理论指导和实践建议。


<details>
  <summary>Details</summary>
Motivation: 未来5G和6G系统需要超可靠、低延迟的短码通信，这推动了通用解码算法的发展。猜测解码为短码提供了一种通用框架。

Method: 对GRAND和GCD两种猜测解码方法进行统一处理，包括算法实现、排序策略、ML最优性证明、鞍点近似复杂度分析，并通过仿真验证理论预测。

Result: 证明了两种方法在适当停止准则下的ML最优性，分析了有限搜索预算下的性能下降，比较了关键指标（最坏情况和平均复杂度、硬件考虑），并阐明了各自的优势工作区间。

Conclusion: 该工作为在下一代短码通信中部署通用猜测解码器提供了理论见解和实践指南，展示了GRAND和GCD在不同工作区间的优越性能。

Abstract: Future beyond-5G and 6G systems demand ultra-reliable, low-latency communication with short blocklengths, motivating the development of universal decoding algorithms. Guessing decoding, which infers the noise or codeword candidate in order of decreasing (exact or approximate) likelihood, offers a universal framework applicable to short codes. In this paper, we present a unified treatment of two prominent recent families of guessing decoding: guessing random additive noise decoding (GRAND) and guessing codeword decoding (GCD). For each, we (i) present algorithmic implementations and ordering strategies; (ii) prove maximum-likelihood (ML) optimality under appropriate stopping criteria; (iii) derive saddle-point approximations for the average number of queries; and (iv) validate theoretical predictions with simulations. We further analyze the performance degradation due to limited search budgets relative to ML performance, compare key metrics (worst-case and average complexity, hardware considerations), and highlight how advances in one approach transfer naturally to the other. Our results clarify the operating regimes where GRAND and GCD demonstrate superior performance. This work provides both theoretical insights and practical guidelines for deploying universal guessing decoders in next-generation short-blocklength communications.

</details>


### [44] [Tight Lower Bounds on the Bandwidth Cost of MDS Convertible Codes in the Split Regime](https://arxiv.org/abs/2511.12279)
*Shubhransh Singhvi,Saransh Chopra,K. V. Rashmi*

Main category: cs.IT

TL;DR: 本文研究了分布式存储系统中可转换码在拆分机制下的带宽成本基本限制，提出了新的信息论框架，改进了现有下界，并在更广泛的参数范围内实现了紧致性。


<details>
  <summary>Details</summary>
Motivation: 随着分布式存储系统中擦除编码的发展，根据磁盘故障率调整冗余度可以显著节省存储空间。这种调整需要代码转换，而现有转换方法可能资源密集。可转换码旨在高效实现这种转换同时保持MDS属性。

Method: 采用新颖的信息论框架，仅假设初始和最终代码是系统性的，不依赖线性假设或均匀性假设。研究拆分机制下的系统MDS可转换码带宽成本。

Result: 推导出了拆分机制下所有参数的系统MDS可转换码带宽成本下界，这些下界在更广泛的参数范围（r^F ≥ k^F 或 r^I ≤ k^F）内是紧致的，部分解决了Maturana和Rashmi提出的猜想。

Conclusion: 提出的信息论框架能够在不依赖均匀性假设的情况下获得紧致的带宽成本下界，扩展了现有结果的应用范围，为可转换码的设计提供了理论基础。

Abstract: Recent advances in erasure coding for distributed storage systems have demonstrated that adapting redundancy to varying disk failure rates can lead to substantial storage savings. Such adaptation requires code conversion, wherein data encoded under an initial $[k^I + r^I, k^I]$ code is transformed into data encoded under a final $[k^F + r^F, k^F]$ code - an operation that can be resource-intensive. Convertible codes are a class of codes designed to facilitate this transformation efficiently while preserving desirable properties such as the MDS property. In this work, we investigate the fundamental limits on the bandwidth cost of conversion (total amount of data transferred between the storage nodes during conversion) for systematic MDS convertible codes. Specifically, we study the subclass of conversions known as the split regime (a single initial codeword is converted into multiple final codewords).
  In this setting, prior to this work, the best known lower bounds on the bandwidth cost of conversion for all parameters were derived by Maturana and Rashmi under certain uniformity assumptions on the number of symbols downloaded from each node. Further, these bounds were shown to be tight for the parameter regime where $r^F \geq k^F$ or $r^I \leq r^F$. In this work, we derive lower bounds on the bandwidth cost of systematic MDS convertible codes for all parameters in the split regime without the uniformity assumption. Moreover, our bounds are tight for the broader parameter regime where $r^F \geq k^F$ or $r^I \leq k^F$. Subsequently, our bounds also partially resolve the conjecture proposed by Maturana and Rashmi. We employ a novel information-theoretic framework, which assumes only that the initial and final codes are systematic and does not rely on any linearity assumptions or the aforementioned uniformity assumptions.

</details>


### [45] [Integration of Navigation and Remote Sensing in LEO Satellite Constellations](https://arxiv.org/abs/2511.12430)
*Qi Wang,Xiaoming Chen,Qiao Qi,Zhaolin Wang,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出一种新型双功能LEO卫星星座帧结构，有效整合导航和遥感功能，基于CRB推导PVT误差和SAINR作为性能指标，并设计联合波束成形方案。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星星座正成为下一代卫星网络的核心，需要实现全球高精度导航和高质量遥感的多功能集成。

Method: 提出双功能LEO卫星星座帧结构，推导基于CRB的PVT误差和SAINR性能指标，设计最小化导航用户平均加权PVT误差同时保证遥感SAINR要求的联合波束成形方案。

Result: 仿真结果验证了所提出的多卫星协作波束成形设计的有效性，证明了其作为下一代多功能LEO卫星星座集成解决方案的可行性。

Conclusion: 该研究为下一代多功能LEO卫星星座提供了一种有效的集成解决方案，通过联合波束成形设计实现了导航和遥感功能的协同优化。

Abstract: Low earth orbit (LEO) satellite constellations are becoming a cornerstone of next-generation satellite networks, enabling worldwide high-precision navigation and high-quality remote sensing. This paper proposes a novel dual-function LEO satellite constellation frame structure that effectively integrating navigation and remote sensing. Then, the Cramer-Rao bound (CRB)-based positioning, velocity measurement, and timing (PVT) error and the signal-to-ambiguity-interference-noise ratio (SAINR) are derived as performance metrics for navigation and remote sensing, respectively. Based on it, a joint beamforming design is proposed by minimizing the average weighted PVT error for navigation user equipments (UEs) while ensuring SAINR requirement for remote sensing. Simulation results validate the proposed multi-satellite cooperative beamforming design, demonstrating its effectiveness as an integrated solution for next-generation multi-function LEO satellite constellations.

</details>


### [46] [Metasurface-Enabled Superheterodyne Transmitter With Decoupled Harmonic-Free Signal Generation and Precoding](https://arxiv.org/abs/2511.12469)
*Xuehui Dong,Miyu Feng,Chen Shao,Bokai Lai,Jianan Zhang,Rujing Xiong,Kai Wan,Tiebin Mi,Robert Caiming Qiu*

Main category: cs.IT

TL;DR: 提出了一种新型超外差架构的可编程超表面发射机，解决了传统架构中调制阶数受限、空间不一致和谐波干扰等问题，实现了谐波自由波形生成与空间预编码的解耦。


<details>
  <summary>Details</summary>
Motivation: 传统可编程超表面发射机架构存在基本限制：调制阶数受限、符号级空间不一致性和显著谐波干扰，这些问题源于基带信号处理与射频波束成形的内在耦合。

Method: 采用超外差架构，包含数字上变频模块进行I/Q调制和基带到中频转换、预编码模块以及定制的幅度-相位解耦超表面作为可重构反射混频器阵列。

Result: 实验验证了系统性能：生成任意阶QAM调制的空间各向同性星座图，确保多普勒欺骗等应用的一致时频特征，在线性工作区域内实现高达20 Mbps的数据速率，并首次在PM发射机中展示了空间多样性和多流干扰消除能力。

Conclusion: MSA架构从根本上解决了现有方法的缺点，为下一代无线系统提供了高性能的可编程超表面发射解决方案。

Abstract: The evolution of programmable metasurfaces (PM) from passive beamforming to active information transmission marks a paradigm shift for next-generation wireless systems. However, this transition is hindered by fundamental limitations in conventional metasurface transmitter architectures, including restricted modulation orders, symbol-level spatial inconsistency, and significant harmonic interference. These issues stem from the intrinsic coupling between baseband signal processing and radio-frequency beamforming in monolithic designs reliant on simplistic switching mechanisms. This paper proposes a novel metasurface-enabled superheterodyne architecture (MSA) that fundamentally decouples these functionalities. The MSA introduces a dual-stage up-conversion process, comprising a digital up-conversion module for in-phase/quadrature modulation and baseband-to-intermediate frequency conversion, a precoder module for precoding, and a custom-designed magnitude-phase-decoupled metasurface that acts as a reconfigurable reflective mixer array. This decoupling of harmonic-free waveform generation from spatial precoding overcomes the critical drawbacks of existing approaches. Experimental results from a 5.8 GHz proof-of-concept prototype system validate the MSA's superior performance. The system generates spatially isotropic constellations for arbitrary-order QAM modulations, ensures consistent time-frequency signatures for applications like Doppler-spoofing, and achieves data rates up to 20 Mbps within a linear operating region that minimizes nonlinear distortion. The capability of employing spatial diversity and multi-stream interference cancellation has been demonstrated for the first time in a PM-based transmitter.

</details>


### [47] [Leave-One-Out Learning with Log-Loss](https://arxiv.org/abs/2511.12718)
*Yaniv Fogel,Meir Feder*

Main category: cs.IT

TL;DR: 该论文研究了在个体确定性设置下的批量学习问题，提出了基于留一法遗憾的自然准则，并分析了多个假设类的最小最大遗憾值。


<details>
  <summary>Details</summary>
Motivation: 在个体设置中，由于结果序列是确定性的，经验统计量不直接适用，因此批量学习的遗憾保证一直是一个基本挑战。

Method: 提出了基于留一法遗憾的准则，分析了多类假设类的最小最大遗憾值，包括多项单纯形和VC维假设类。

Result: 对于m个符号的多项单纯形，最小最大遗憾为(m-1)/N + o(1/N)；对于VC维为d的假设类，遗憾上界为d log(N)/N + o(log(N)/N)，并建立了匹配下界。

Conclusion: 这些结果首次证明在个体设置下，使用对数损失的通用批量学习是可能的。

Abstract: We study batch learning with log-loss in the individual setting, where the outcome sequence is deterministic. Because empirical statistics are not directly applicable in this regime, obtaining regret guarantees for batch learning has long posed a fundamental challenge. We propose a natural criterion based on leave-one-out regret and analyze its minimax value for several hypothesis classes. For the multinomial simplex over $m$ symbols, we show that the minimax regret is $\frac{m-1}{N} + o\!\left(\frac{1}{N}\right)$, and compare it to the stochastic realizable case where it is $\frac{m-1}{2N} + o\!\left(\frac{1}{N}\right)$. More generally, we prove that every hypothesis class of VC dimension $d$ is learnable in the individual batch-learning problem, with regret at most $\frac{d\log(N)}{N} + o\!\left(\frac{\log(N)}{N}\right)$, and we establish matching lower bounds for certain classes. We further derive additional upper bounds that depend on structural properties of the hypothesis class. These results establish, for the first time, that universal batch learning with log-loss is possible in the individual setting.

</details>


### [48] [Finite-Horizon Quickest Change Detection Balancing Latency with False Alarm Probability](https://arxiv.org/abs/2511.12803)
*Yu-Han Huang,Venugopal V. Veeravalli*

Main category: cs.IT

TL;DR: 本文研究了有限时间范围内的快速变化检测问题，针对非平稳环境中的学习应用。在给定误报概率和延迟水平约束下，推导了延迟的通用下界，并开发了在时间范围上达到阶数最优的检测器。


<details>
  <summary>Details</summary>
Motivation: 研究非平稳环境中有限时间范围内的变化检测问题，这对于实际应用中的学习算法具有重要意义，需要在有限时间内快速准确地检测分布变化。

Method: 首先考虑已知变化前后分布的情况，然后推广到非参数情况（仅知分布为亚高斯且均值不同）。推导了延迟的通用下界，并开发了在时间范围上阶数最优的检测器。

Result: 理论分析表明所提出的检测器在有限时间范围内达到阶数最优性能，仿真结果验证了理论分析的正确性。

Conclusion: 本文为有限时间范围内的快速变化检测问题提供了理论框架和实用检测器，在给定误报和延迟约束下实现了最优性能，适用于非平稳环境中的学习应用。

Abstract: A finite-horizon variant of the quickest change detection (QCD) problem that is of relevance to learning in non-stationary environments is studied. The metric characterizing false alarms is the probability of a false alarm occurring before the horizon ends. The metric that characterizes the delay is \emph{latency}, which is the smallest value such that the probability that detection delay exceeds this value is upper bounded to a predetermined latency level. The objective is to minimize the latency (at a given latency level), while maintaining a low false alarm probability. Under the pre-specified latency and false alarm levels, a universal lower bound on the latency, which any change detection procedure needs to satisfy, is derived. Change detectors are then developed, which are order-optimal in terms of the horizon. The case where the pre- and post-change distributions are known is considered first, and then the results are generalized to the non-parametric case when they are unknown except that they are sub-Gaussian with different means. Simulations are provided to validate the theoretical results.

</details>


### [49] [Joint Transmit Beamforming and Reflection Optimization for Beyond Diagonal RIS Aided Multi-Cell MIMO Communication](https://arxiv.org/abs/2511.13347)
*Shuo Zheng,Shuowen Zhang*

Main category: cs.IT

TL;DR: 本文研究了BD-RIS辅助的多小区多用户MIMO通信系统，通过联合优化基站发射波束成形和BD-RIS反射矩阵来最大化加权和速率，有效抑制小区间干扰。


<details>
  <summary>Details</summary>
Motivation: 6G网络采用超密集多小区部署，但频率复用导致严重的小区间干扰，特别是对小区边缘用户。需要新方法来增强期望信号并抑制干扰。

Method: 使用WMMSE方法将问题转化为等价可处理形式，提出基于交替优化的算法，结合拉格朗日对偶理论和流形优化迭代更新发射波束成形和BD-RIS反射。

Result: 数值结果表明所提设计优于多种基准方案，并为多小区系统中BD-RIS部署策略提供了实用见解。

Conclusion: BD-RIS能有效提升多小区系统的通信性能，所提算法在抑制干扰和提升和速率方面表现优越。

Abstract: The sixth-generation (6G) wireless networks will rely on ultra-dense multi-cell deployment to meet the high rate and connectivity demands. However, frequency reuse leads to severe inter-cell interference, particularly for cell-edge users, which limits the communication performance. To overcome this challenge, we investigate a beyond diagonal reconfigurable intelligent surface (BD-RIS) aided multi-cell multi-user downlink MIMO communication system, where a BD-RIS is deployed to enhance desired signals and suppress both intra-cell and inter-cell interference.We formulate the joint optimization problem of the transmit beamforming matrices at the BSs and the BD-RIS reflection matrix to maximize the weighted sum rate of all users, subject to the challenging unitary constraint of the BD-RIS reflection matrix and transmit power constraints at the BSs. To tackle this non-convex and difficult problem, we apply the weighted minimum mean squared error (WMMSE) method to transform the problem into an equivalent tractable form, and propose an efficient alternating optimization (AO) based algorithm to iteratively update the transmit beamforming and BD-RIS reflection using Lagrange duality theory and manifold optimization. Numerical results demonstrate the superiority of the proposed design over various benchmark schemes, and provide useful practical insights on the BD-RIS deployment strategy for multi-cell systems.

</details>


### [50] [On the Capacity of Pixel Antenna based MIMO Communication](https://arxiv.org/abs/2511.13482)
*Shenrui Lin,Shuowen Zhang*

Main category: cs.IT

TL;DR: 本文研究了配备像素天线的MIMO系统容量极限，通过联合优化发射协方差矩阵和收发两端的天线编码器来最大化系统容量，提出了三种不同复杂度的算法来解决这个混合整数非线性规划问题。


<details>
  <summary>Details</summary>
Motivation: 像素天线技术通过自适应重构天线辐射模式来提高无线通信数据速率，但在MIMO系统中联合优化发射协方差和天线编码器是一个具有挑战性的混合整数非线性规划问题，需要高效算法来解决。

Method: 提出了三种算法：1）穷举搜索法获得最优解；2）分支定界迭代算法在复杂度较低时获得高质量次优解；3）交替优化算法具有多项式复杂度。

Result: 数值结果表明所提算法在性能和复杂度之间实现了灵活权衡，配备像素天线可以增强MIMO通信的可实现速率。

Conclusion: 像素天线技术能够有效提升MIMO系统性能，所提出的算法为解决这类混合整数非线性规划问题提供了有效的解决方案。

Abstract: Pixel antenna is a promising technology to enhance the wireless communication data rate by adaptively reconfiguring each antenna's radiation pattern via a so-called antenna coding technique which controls the states of switches connected to multiple pixel ports. This paper studies a multiple-input multiple-output (MIMO) system where both the transmitter and the receiver are equipped with multiple pixel antennas. We aim to characterize the fundamental capacity limit of this MIMO system by jointly optimizing the transmit covariance matrix and the antenna coders at both the transmitter and the receiver. This problem is a mixed-integer non-linear program (MINLP) which is non-convex and particularly challenging to solve due to the binary-valued optimization variables corresponding to the antenna coders. We first propose an exhaustive search based method to obtain the optimal solution to this problem, which corresponds to the fundamental capacity limit. Then, we propose a branch-and-bound based iterative algorithm aiming to find a high-quality suboptimal solution with lower complexity than exhaustive search as the number of pixel ports becomes large. Finally, we devise an alternating optimization (AO) based algorithm with polynomial complexity. Numerical results show that our proposed algorithms achieve a flexible trade-off between performance and complexity. Moreover, equipping the transceivers with pixel antennas can enhance the achievable rate of MIMO communications.

</details>


### [51] [A Deterministic Dimension Property of Twisted Goppa Codes](https://arxiv.org/abs/2511.13601)
*Kai Wang*

Main category: cs.IT

TL;DR: 对扭曲Goppa码的维度特性进行了大规模计算研究，发现当有限域阶数q、扩展度m、Goppa多项式次数t、自同构平移参数b和变换阶数u固定时，码的维度k是确定不变的。


<details>
  <summary>Details</summary>
Motivation: 研究扭曲Goppa码的维度特性，探索其参数与维度之间的确定性关系。

Method: 通过分析超过50,000个参数集进行大规模计算研究，系统性地考察扭曲Goppa码的维度特性。

Result: 发现扭曲Goppa码的维度k由一组宏观参数(q,m,t,b,u)唯一确定，当这些参数固定时，生成的码的维度保持恒定。

Conclusion: 扭曲Goppa码的维度具有确定性规律，仅依赖于宏观参数(q,m,t,b,u)，这为码的设计和应用提供了理论基础。

Abstract: This paper presents a large-scale computational study on the dimensional properties of twisted Goppa codes. Through the systematic analysis of over 50,000 parameter sets, we uncover a remarkable deterministic regularity: the actual dimension k of a twisted Goppa code is uniquely determined by a set of macro-parameters (q,m,t,b,u). Specifically, when the order of the finite field q, the extension degree m, the degree t of the Goppa polynomial, the translation parameter b of the automorphism, and the order u of the transformation are fixed, the dimension k of the generated code remains constant.

</details>
