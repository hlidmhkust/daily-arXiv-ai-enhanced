<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 19]
- [eess.SP](#eess.SP) [Total: 27]
- [eess.IV](#eess.IV) [Total: 15]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [The Service Rate Region of Hamming Codes](https://arxiv.org/abs/2509.22898)
*Priyanka Choudhary,Maheshanand Bhaintwal*

Main category: cs.IT

TL;DR: 本文研究了系统汉明码的服务速率区域，利用超图理论推导了单个数据对象最大可达到服务速率的界限，并探讨了这些界限的可实现性。


<details>
  <summary>Details</summary>
Motivation: 研究编码分布式存储系统中服务速率区域的特性，特别是针对系统汉明码，以理解在容量约束下可实现的数据访问请求范围。

Method: 使用超图理论分析系统汉明码的服务速率区域，建立系统节点子集索引的数据符号服务速率之和的上界，并探索这些上界的可实现性。

Result: 对于系统二进制汉明码，建立了系统节点子集索引的数据符号服务速率之和的上界；对于非系统二进制汉明码，发现聚合服务速率受限于关联生成矩阵中奇权重列的数量。

Conclusion: 系统汉明码的服务速率区域可以通过超图理论进行有效分析，系统节点子集的服务速率之和存在明确的上界，而非系统汉明码的聚合服务速率受生成矩阵结构限制。

Abstract: The service rate region of a coded distributed storage system is the set of
all achievable data access requests under the capacity constraints. This paper
investigates the service rate regions of systematic Hamming codes using
hypergraph theory and derives bounds for the maximal achievable service rate of
individual data objects. We establish upper bounds on the sum of service rates
of data symbols indexed by a subset of systematic nodes in a systematic binary
Hamming code, and explore the achievability of these bounds. Additionally, for
non-systematic binary Hamming codes, we conclude that the aggregate service
rate is limited by the number of columns of odd weight in the associated
generator matrix.

</details>


### [2] [Multihead Finite-State Dimension](https://arxiv.org/abs/2509.22912)
*Xiang Huang,Xiaoyuan Li,Jack H. Lutz,Neil Lutz*

Main category: cs.IT

TL;DR: 本文提出了多头有限状态维度的概念，这是有限状态维度的推广，其中多个有限状态代理（头）通过单向移动规则协同工作，使领导者能够在无限数据流上进行投注。


<details>
  <summary>Details</summary>
Motivation: 为了扩展有限状态维度的理论框架，研究多个有限状态代理协同工作的计算能力，探索不同头数对投注策略性能的影响。

Method: 使用h头有限状态赌徒模型，其中多个有限状态头各自报告符号，领导者基于这些信息制定投注策略。通过gales策略量化资本增长率的极限。

Result: 证明了随着头数增加存在严格层次结构，给出了明确序列族分离h头和h+1头有限状态赌徒的盈利能力。多头有限状态维度在有限并集下稳定，但固定头数h>1的预维度缺乏稳定性。

Conclusion: 多头有限状态维度是有限状态维度的有效推广，头数增加确实带来更强的计算能力，且该理论框架具有良好的数学性质，但固定头数的预维度存在不稳定性。

Abstract: We introduce multihead finite-state dimension, a generalization of
finite-state dimension in which a group of finite-state agents (the heads) with
oblivious, one-way movement rules, each reporting only one symbol at a time,
enable their leader to bet on subsequent symbols in an infinite data stream. In
aggregate, such a scheme constitutes an $h$-head finite state gambler whose
maximum achievable growth rate of capital in this task, quantified using
betting strategies called gales, determines the multihead finite-state
dimension of the sequence. The 1-head case is equivalent to finite-state
dimension as defined by Dai, Lathrop, Lutz and Mayordomo (2004). In our main
theorem, we prove a strict hierarchy as the number of heads increases, giving
an explicit sequence family that separates, for each positive integer $h$, the
earning power of $h$-head finite-state gamblers from that of $(h+1)$-head
finite-state gamblers. We prove that multihead finite-state dimension is stable
under finite unions but that the corresponding quantity for any fixed number
$h>1$ of heads--the $h$-head finite-state predimension--lacks this stability
property.

</details>


### [3] [Zigzag Codes Revisited: From Optimal Rebuilding to Small Skip Cost and Small Fields](https://arxiv.org/abs/2509.23090)
*Wenqin Zhang,Han Mao Kiah,Son Hoang Dau*

Main category: cs.IT

TL;DR: 本文改进了zigzag阵列码，使其具有小域大小和低跳过成本两个新特性，同时保持单节点修复的最优访问和最优重建比。


<details>
  <summary>Details</summary>
Motivation: 现有zigzag码在域大小和跳过成本方面存在限制，本文旨在使其在理论和实践中更加灵活实用。

Method: 使用特征为二的域和Z_2^m群进行行索引，保证MDS特性；引入排序-子群框架实现修复传输方案，降低跳过成本和修复碎片比。

Result: 构建了零跳过成本且码率接近2/3的码族，以及有界跳过成本且码率接近3/4和4/5的码族。

Conclusion: zigzag码可以同时具备理论灵活性和实际部署价值，适用于现代分布式存储系统。

Abstract: We revisit zigzag array codes, a family of MDS codes known for achieving
optimal access and optimal rebuilding ratio in single-node repair. In this
work, we endow zigzag codes with two new properties: small field size and low
skip cost. First, we prove that when the row-indexing group is $\mathcal{G} =
\mathbb{Z}_2^m$ and the field has characteristic two, explicit coefficients
over any field with $|\mathcal{F}|\ge N$ guarantee the MDS property, thereby
decoupling the dependence among $p$, $k$, and $M$. Second, we introduce an
ordering-and-subgroup framework that yields repair-by-transfer schemes with
bounded skip cost and low repair-fragmentation ratio (RFR), while preserving
optimal access and optimal rebuilding ratio. Our explicit constructions include
families with zero skip cost whose rates approach $2/3$, and families with
bounded skip cost whose rates approach $3/4$ and $4/5$. These rates are
comparable to those of MDS array codes widely deployed in practice. Together,
these results demonstrate that zigzag codes can be made both more flexible in
theory and more practical for modern distributed storage systems.

</details>


### [4] [RIS- and Multi-Snapshot-Enabled SISO 3D Position and Velocity Estimation With Single Base Station](https://arxiv.org/abs/2509.23274)
*Yirun Wang,Yongqing Wang,Yuyao Shen,Gongpu Wang,Chintha Tellambura*

Main category: cs.IT

TL;DR: 该论文提出了一种在单基站SISO系统中使用可重构智能表面(RIS)进行三维位置和速度联合估计(3D-JPVE)的方法，通过结合RIS部署和多快照利用解决了单RIS或多快照单独使用时的不可行性问题。


<details>
  <summary>Details</summary>
Motivation: 在仅有单个基站的SISO系统中，仅依赖单个RIS或多个快照无法实现三维位置和速度联合估计，需要结合两者来克服这一限制。

Method: 开发了两阶段方法：首先通过张量分解将3D联合离开角和多普勒频移估计分解为两个可处理子问题，采用交替优化；然后基于信道参数估计设计了两阶段低复杂度3D-JPVE方法，包括差分测量的线性方程粗估计和原始测量的迭代精化。

Result: 仿真结果表明所提出的估计器具有统计效率，且主动RIS相比被动RIS能带来显著的3D-JPVE性能提升，所提方法接近Cramer-Rao下界精度。

Conclusion: 通过RIS部署与多快照利用的结合，成功实现了单基站SISO系统中的三维位置和速度联合估计，所提方法在性能和复杂度之间取得了良好平衡。

Abstract: Reconfigurable intelligent surface (RIS) panels can act as cost-effective
anchors for radio localization, complementing conventional base station (BS)
anchors. This paper investigates joint three-dimensional position and velocity
estimation (3D-JPVE) in single-input single-output (SISO) systems with only one
BS available. We first theoretically show that 3D-JPVE is infeasible when
relying solely on a single RIS or on multiple snapshots alone. To address this,
we propose combining RIS deployment with multi-snapshot utilization to enable
realizable 3D-JPVE. A two-stage method is developed for multi-snapshot channel
parameter estimation, comprising a tensor-based coarse estimation step followed
by a maximum likelihood refinement step. In particular, we introduce a
third-order tensor formulation to decompose the challenging 3D joint
angle-of-departure and Doppler shift estimation (3D-JADE) into two tractable
subproblems, which are jointly solved via a low-complexity alternating
optimization approach. Building on the channel parameter estimates, we further
design a two-stage low-complexity method for optimal 3D-JPVE: coarse estimation
is obtained from differential measurements through linear equations, and the
preliminary results are refined iteratively using the original measurements.
Moreover, we derive the closed-form Cramer-Rao lower bound (CRLB) and show that
the proposed 3D-JPVE method approaches CRLB-level accuracy. Simulation results
confirm the statistical efficiency of the proposed estimators and demonstrate
substantial 3D-JPVE performance gains when deploying active RIS compared to
passive RIS.

</details>


### [5] [RIS-Assisted XL-MIMO for Near-Field and Far-Field Communications](https://arxiv.org/abs/2509.23284)
*Xiaomin Cao,Mohammadali Mohammadi,Hien Quoc Ngo,Hyundong Shin,Michail Matthaiou*

Main category: cs.IT

TL;DR: 该论文研究了RIS辅助的XL-MIMO下行链路系统，为近场和远场用户提供通信服务，提出了三种预编码方案和相位设计算法，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 解决XL-MIMO系统中远场用户因阻塞而通信受限的问题，通过RIS辅助和优化预编码方案来提升系统整体性能。

Method: 采用CZF、LZF和MRT三种预编码方案，提出启发式可见区域选择算法降低复杂度，并设计两阶段相位偏移和功率控制算法。

Result: 相比等功率分配和随机相位设计，所提方案将加权最小频谱效率分别提升了31.9%(CZF)、37.8%(LZF)和119.2%(MRT)。CZF性能最佳，LZF复杂度低且性能相当。

Conclusion: CZF在平衡性能方面表现最佳，LZF在降低复杂度的同时保持了良好性能，特别适合优先考虑某一用户组的情况。

Abstract: We consider a reconfigurable intelligent surface (RIS)-assisted extremely
large-scale multiple-input multiple-output (XL-MIMO) downlink system, where an
XL-MIMO array serves two groups of single-antennas users, namely near-field
users (NFUEs) and far-field users (FFUEs). FFUEs are subject to blockage, and
their communication is facilitated through the RIS. We consider three precoding
schemes at the XL-MIMO array, namely central zero-forcing (CZF), local
zero-forcing (LZF) and maximum ratio transmission (MRT). Closed-form
expressions for the spectral efficiency (SE) of all users are derived for MRT
precoding, while statistical-form expressions are obtained for CZF and LZF
processing. A heuristic visibility region (VR) selection algorithm is also
introduced to help reduce the computational complexity of the precoding scheme.
Furthermore, we devise a two-stage phase shifts design and power control
algorithm to maximize the sum of weighted minimum SE of two groups of users
with CZF, LZF and MRT precoding schemes. The simulation results indicate that,
when equal priority is given to NFUEs and FFUEs, the proposed design improves
the sum of the weighted minimum SE by 31.9\%, 37.8\%, and 119.2\% with CZF,
LZF, and MRT, respectively, compared to the case with equal power allocation
and random phase shifts design. CZF achieves the best performance, while LZF
offers comparable results with lower complexity. When prioritizing NFUEs or
FFUEs, LZF achieves strong performance for the prioritized group, whereas CZF
ensures balanced performance between NFUEs and FFUEs.

</details>


### [6] [Absorbing Markov Chain-Based Analysis of Age of Information in Discrete-Time Dual-Queue Systems](https://arxiv.org/abs/2509.23360)
*Yifan Feng,Nail Akar,Zhengchuan Chen,Mehul Motani*

Main category: cs.IT

TL;DR: 本文构建了一个吸收马尔可夫链来精确建模双队列状态更新系统中的信息年龄，研究了传输冻结机制对降低平均AoI的影响，并分析了不同服务时间分布下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 为了及时收集传感信息，部署多个传感器/服务器以获得多样性增益被认为是一种有前景的解决方案。需要精确建模双队列状态更新系统中的信息年龄性能。

Method: 构建离散时间吸收马尔可夫链来建模具有GAW状态更新、DPH型分布服务时间和传输冻结的双队列系统。基于该模型推导AoI和峰值AoI的精确分布。

Result: 传输冻结的引入被证明对各种服务时间分布都能显著降低平均AoI。研究了服务时间统计参数和服务器异质性对冻结增益的影响。

Conclusion: 在双队列状态更新系统中引入传输冻结机制能有效降低平均信息年龄，且在不同服务时间分布下均表现出显著性能提升。

Abstract: Status update systems require the timely collection of sensing information
for which deploying multiple sensors/servers to obtain diversity gains is
considered as a promising solution. In this work, we construct an absorbing
Markov chain (AMC) to exactly model Age of Information (AoI) in a discretetime
dual-queue (DTDQ) status update system with generate at will (GAW) status
updates, discrete phase-type (DPH-type) distributed service times and
transmission freezing. Specifically, transmission is frozen for a certain
number of slots following the initiation of a transmission, after which one of
the two servers is allowed to simultaneously sample the monitored physical
process and transmit a status update packet, according to the availabilities
and priorities of the two servers. Based on the discrete-time AMC, we provide
the exact distributions of both AoI and peak AoI (PAoI), enabling the
derivation of arbitrary order moments. In addition, we analytically study the
role of freezing using several typical service time distributions, including
geometric, uniform, and triangular distributions. The introduction of freezing
for DTDQ systems is demonstrated to be significantly beneficial in reducing the
mean AoI for various service time distributions. Additionally, we study the
impact of the statistical parameters of the service times and heterogeneity
between the two servers on the freezing gain, i.e., reduction in mean AoI
attained with optimum freezing policies.

</details>


### [7] [Noise-Domain Non-Orthogonal Multiple Access for Three Users](https://arxiv.org/abs/2509.23407)
*Erkin Yapici,Yusuf Islam Tek,Ertugrul Basar*

Main category: cs.IT

TL;DR: 提出了一种新颖的三用户噪声域非正交多址接入方案，通过引入相关性作为新维度，在均值和方差基础上实现三用户同时通信。


<details>
  <summary>Details</summary>
Motivation: 扩展传统两用户ND-NOMA系统，利用相关性作为新维度，实现三用户同时通信，为物联网环境中的可扩展多用户通信铺平道路。

Method: 设计包含上行和下行链路场景的三用户ND-NOMA方案，开发解码器来提取嵌入在均值、方差和相关性中的信息。

Result: 在Rician衰落信道下的理论分析和仿真结果表明，该系统在保持ND-NOMA低功耗和低复杂度优势的同时，实现了良好的误码率性能。

Conclusion: 新的ND-NOMA设计通过不同维度实现三用户同时通信，为噪声域系统和物联网环境中的可扩展多用户通信开辟了新途径。

Abstract: In this study, we propose a novel three-user noise-domain non-orthogonal
multiple access (ND-NOMA) scheme by introducing the correlation as a new
dimension besides mean and variance quantities used in two-user ND-NOMA. The
new three-user ND-NOMA scheme includes both uplink and downlink scenarios, with
detectors designed to decode the information embedded in mean, variance, and
correlation. Our theoretical analysis and simulation results under Rician
fading channels show that the proposed system is capable of achieving promising
bit error rate (BER) performance while preserving the low power and low
complexity advantages of ND-NOMA. This new ND-NOMA design enables simultaneous
communication among three users using different dimensions, paving the way for
scalable multi-user communication in noise-domain systems and in the
Internet-of-things (IoT) environments.

</details>


### [8] [Fundamental Limits of Distributed Computing for Linearly Separable Functions](https://arxiv.org/abs/2509.23447)
*K. K. Krishnan Namboodiri,Elizabath Peter,Derya Malak,Petros Elia*

Main category: cs.IT

TL;DR: 本文研究了分布式计算线性可分函数的问题，通过创新的零空间设计方法建立了通信与计算之间的基本权衡关系，在特定条件下达到最优或接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决分布式计算中主节点利用多个服务器计算用户请求函数时的核心挑战：降低服务器计算负载和通信成本，同时确保对所有可能请求函数集合的恢复能力。

Method: 提出基于零空间的设计方法，联合控制任务分配和服务器传输，确保所有需求的确切可解码性。通过揭示零空间与稀疏矩阵分解之间的对偶关系，将分布式计算问题重新表述为等效的分解任务。

Result: 建立了任意K和L参数下的基本通信-计算权衡关系，在无子分组假设下，所提方法被证明要么精确最优，要么与最优解相差不超过3倍。

Conclusion: 通过零空间设计方法实现了分布式计算中任务分配和通信策略的联合优化，建立了信息论上的紧致下界，并为通信成本与覆盖数理论之间建立了新的联系。

Abstract: This work addresses the problem of distributed computation of linearly
separable functions, where a master node with access to $K$ datasets, employs
$N$ servers to compute $L$ user-requested functions, each defined over the
datasets. Servers are instructed to compute subfunctions of the datasets and
must communicate computed outputs to the user, who reconstructs the requested
outputs. The central challenge is to reduce the per-server computational load
and the communication cost from servers to the user, while ensuring recovery
for any possible set of $L$ demanded functions.
  We here establish the fundamental communication-computation tradeoffs for
arbitrary $K$ and $L$, through novel task-assignment and communication
strategies that, under the linear-encoding and no-subpacketization assumptions,
are proven to be either exactly optimal or within a factor of three from the
optimum. In contrast to prior approaches that relied on fixed assignments of
tasks -- either disjoint or cyclic assignments -- our key innovation is a
nullspace-based design that jointly governs task assignment and server
transmissions, ensuring exact decodability for all demands, and attaining
optimality over all assignment and delivery methods. To prove this optimality,
we here uncover a duality between nullspaces and sparse matrix factorizations,
enabling us to recast the distributed computing problem as an equivalent
factorization task and derive a sharp information-theoretic converse bound.
Building on this, we establish an additional converse that, for the first time,
links the communication cost to the covering number from the theory of general
covering designs.

</details>


### [9] [Post-disaster Max-Min Rate Optimization for Multi-UAV RSMA Network in Obstacle Environments](https://arxiv.org/abs/2509.23908)
*Qingyang Wang,Zhuohui Yao,Wenchi Cheng,Xiao Zheng*

Main category: cs.IT

TL;DR: 该论文提出了一种基于速率分割多址接入的无人机基站优化方案，用于灾后应急通信，通过交替优化方法最大化地面用户的最小可达速率。


<details>
  <summary>Details</summary>
Motivation: 解决灾后场景中存在障碍物时，如何通过无人机基站实现高效应急通信，确保所有地面用户都能获得公平的通信服务质量。

Method: 采用交替优化方法，结合块坐标下降和逐次凸逼近技术，通过惩罚项处理障碍物约束，迭代求解非凸优化问题。

Result: 仿真结果表明，所提方案在最小可达速率方面显著优于基准方法，验证了其有效性和优越性。

Conclusion: 提出的RSMA传输方案结合无人机基站优化定位，能够有效提升灾后应急通信系统的性能，特别是在存在障碍物的复杂环境中。

Abstract: This paper proposes a rate-splitting multiple access (RSMA) transmission
scheme to maximize the minimum achievable rate among ground users for emergency
communications in post-disaster scenarios with obstacles, with which the
optimal positioning of multiple unmanned aerial vehicle (UAV)-enabled base
stations can be achieved timely.To address the resulting non-convex and
intractable optimization problem, we design an alternating optimization
approach. Specifically, we relax obstacle-related constraints using penalty
terms. In each iteration, block coordinate descent (BCD) and successive convex
approximation (SCA) are applied alternately to obtain locally optimal
solutions, and penalty multipliers are updated to ensure convergence of the
relaxed problem to the original one. Simulation results demonstrate that the
proposed scheme significantly outperforms benchmark methods in terms of the
minimum achievable rate, verifying its effectiveness and superiority.

</details>


### [10] [Capacity-Achieving Codes for Noisy Insertion Channels](https://arxiv.org/abs/2509.24161)
*Hengfeng Liu,Chunming Tang,Cuiling Fan*

Main category: cs.IT

TL;DR: 该论文研究了DNA存储中的噪声插入信道，确定了信道容量并构建了渐近最优的纠错码。


<details>
  <summary>Details</summary>
Motivation: DNA存储是大规模和长期数据存储的有前景解决方案，其中插入错误是最常见的错误类型。插入符号通常与原始符号相同或互补，而实际实现中的噪声可能导致插入符号突变为随机符号，这对可靠数据恢复构成重大挑战。

Method: 研究了一种新的噪声插入信道模型，其中包含无限多个与原始符号相同或互补的符号插入，以及最多一个随机符号插入。确定了该噪声信道的编码容量，并构建了能够达到该编码容量的渐近最优纠错码。

Result: 确定了噪声插入信道的编码容量，并成功构建了能够达到该容量的渐近最优纠错码。

Conclusion: 该研究为DNA存储中的可靠数据恢复提供了理论支撑和实用编码方案，解决了插入错误带来的挑战。

Abstract: DNA storage has emerged as a promising solution for large-scale and long-term
data preservation. Among various error types, insertions are the most frequent
errors occurring in DNA sequences, where the inserted symbol is often identical
or complementary to the original, and in practical implementations, noise can
further cause the inserted symbol to mutate into a random one, which creates
significant challenges to reliable data recovery. In this paper, we investigate
a new noisy insertion channel, where infinitely many insertions of symbols
complement or identical to the original ones and up to one insertion of random
symbol may occur. We determine the coding capacity of the noisy channel and
construct asymptotically optimal error-correcting codes achieving the coding
capacity.

</details>


### [11] [Finite-blocklength Fluid Antenna Systems With Spatial Block-Correlation Channel Model](https://arxiv.org/abs/2509.24333)
*Zhentian Zhang,Kai-Kit Wong,David Morales-Jimenez,Hao Jiang,Pablo Ramírez-Espinosa,Chan-Byoung Chae,Christos Masouros*

Main category: cs.IT

TL;DR: 该论文分析了有限块长传输下流体天线系统的性能极限，提出了基于Gauss-Laguerre积分的简化方法，证明了FBL-FAS在短包通信中的优越性。


<details>
  <summary>Details</summary>
Motivation: 未来通信网络需要支持大规模连接、超低延迟和高可靠性，而有限块长传输下的性能分析至关重要。流体天线系统在短包通信场景中展现出优异的频谱和能量效率。

Method: 采用块相关信道建模方法，从统计角度严格分析FBL-FAS的性能极限，并提出了基于Gauss-Laguerre积分的新型复数积分简化方法。

Result: 数值结果验证了所提出分析的鲁棒性，并清楚证明了FBL-FAS在块错误率和中断概率方面优于传统固定天线布置的多天线系统。

Conclusion: FBL-FAS在有限块长传输场景下具有显著性能优势，为未来通信网络提供了有前景的技术方案。

Abstract: Massive connectivity with ultra-low latency and high reliability necessitates
fundamental advances in future communication networks operating under
finite-blocklength (FBL) transmission. Fluid antenna systems (FAS) have emerged
as a promising enabler, offering superior spectrum and energy efficiency in
short-packet/FBL scenarios. In this work, by leveraging the simplicity and
accuracy of block-correlation channel modeling, we rigorously bound the
performance limits of FBL-FAS from a statistical perspective, focusing on two
key performance metrics: block error rate (BLER) and outage probability (OP).
Furthermore, we introduce a novel complex-integral simplification method based
on Gauss-Laguerre quadrature, which achieves higher approximation accuracy
compared to existing Taylor-expansion-based approaches. Numerical results
validate the robustness of the proposed analysis and clearly demonstrate the
superiority of FBL-FAS over conventional multiple-antenna systems with fixed
antenna placement.

</details>


### [12] [Prediction-Powered Communication with Distortion Guarantees](https://arxiv.org/abs/2509.24373)
*Matteo Zecchin,Unnikrishnan Kunnath Ganesan,Giuseppe Durisi,Petar Popovski,Osvaldo Simeone*

Main category: cs.IT

TL;DR: 本文研究6G系统中的预测驱动通信，提出两种基于在线保形预测的零延迟压缩算法，能在有失真保证的情况下显著降低比特率。


<details>
  <summary>Details</summary>
Motivation: 随着6G系统和智能设备的发展，需要重新思考经典香农信息理论，转向语义和任务导向的范式。设备在零延迟约束下进行通信，需要严格的失真保证。

Method: 提出两种零延迟压缩算法，利用在线保形预测为重建序列提供失真保证。针对擦除信道，引入双重自适应保形更新来补偿信道引起的错误。

Result: 在语义文本压缩实验中，相比最先进的预测驱动压缩方法，在严格满足失真保证的同时显著降低了比特率。

Conclusion: 该方法为6G系统中的预测驱动通信提供了有效的解决方案，能够在保证失真约束的同时实现高效的压缩性能。

Abstract: The development of 6G wireless systems is taking place alongside the
development of increasingly intelligent wireless devices and network nodes. The
changing technological landscape is motivating a rethinking of classical
Shannon information theory that emphasizes semantic and task-oriented
paradigms. In this paper, we study a prediction-powered communication setting,
in which devices, equipped with artificial intelligence (AI)-based predictors,
communicate under zero-delay constraints with strict distortion guarantees. Two
classes of distortion measures are considered: (i) outage-based metrics,
suitable for tasks tolerating occasional packet losses, such as real-time
control or monitoring; and (ii) bounded distortion metrics, relevant to
semantic-rich tasks like text or video transmission. We propose two zero-delay
compression algorithms leveraging online conformal prediction to provide
per-sequence guarantees on the distortion of reconstructed sequences over
error-free and packet-erasure channels with feedback. For erasure channels, we
introduce a doubly-adaptive conformal update to compensate for channel-induced
errors and derive sufficient conditions on erasure statistics to ensure
distortion constraints. Experiments on semantic text compression validate the
approach, showing significant bit rate reductions while strictly meeting
distortion guarantees compared to state-of-the-art prediction-powered
compression methods.

</details>


### [13] [Energy-Efficient Movable Antennas: Mechanical Power Modeling and Performance Optimization](https://arxiv.org/abs/2509.24433)
*Xin Wei,Weidong Mei,Xuan Huang,Zhi Chen,Boyu Ning*

Main category: cs.IT

TL;DR: 本文研究了可移动天线系统的能效优化问题，考虑了天线移动带来的机械功耗，提出了功率消耗模型和优化算法来最大化能效。


<details>
  <summary>Details</summary>
Motivation: 可移动天线通过天线位置调整提供额外的空间自由度来提升通信性能，但天线移动需要机械功耗，这使得能效优化比传统固定天线系统更为重要。

Method: 基于电机理论建立了步进电机驱动的多可移动天线系统功率消耗模型，提出了两层优化框架（内层使用Dinkelbach算法优化波束成形，外层使用顺序更新算法优化天线位置），并为多用户场景设计了交替优化算法。

Result: 数值结果表明，尽管存在额外的机械功耗，所提出的算法在能效方面优于传统固定天线系统和其他现有的能效最大化基准方法。

Conclusion: 可移动天线系统通过适当的优化算法可以有效提升能效，即使考虑了天线移动的机械功耗，仍然能够超越传统固定天线系统的性能。

Abstract: Movable antennas (MAs) offer additional spatial degrees of freedom (DoFs) to
enhance communication performance through local antenna movement. However, to
achieve accurate and fast antenna movement, MA drivers entail non-negligible
mechanical power consumption, rendering energy efficiency (EE) optimization
more critical compared to conventional fixed-position antenna (FPA) systems. To
address this issue, we develop a fundamental power consumption model for
stepper motor-driven multi-MA systems based on electric motor theory. Based on
this model, we formulate an EE maximization problem from a multi-MA base
station (BS) to multiple single-FPA users. We aim to jointly optimize the MAs'
positions, moving speeds, and the BS's transmit precoding matrix subject to
collision-avoidance constraints during the multi-MA movements. However, this
problem is difficult to solve. To tackle this challenge, we first reveal that
the collision-avoidance constraints can always be relaxed without loss of
optimality by properly renumbering the MA indices. For the resulting relaxed
problem, we first consider a simplified single-user setup and uncover a hidden
monotonicity of the EE performance with respect to the MAs' moving speeds. To
solve the remaining optimization problem, we develop a two-layer optimization
framework. In the inner layer, the Dinkelbach algorithm is employed to derive
the optimal beamforming solution for any given MA positions. In the outer
layer, a sequential update algorithm is proposed to iteratively refine the MA
positions based on the optimal values obtained from the inner layer. Next, we
proceed to the general multi-user case and propose an alternating optimization
(AO) algorithm. Numerical results demonstrate that despite the additional
mechanical power consumption, the proposed algorithms can outperform both
conventional FPA systems and other existing EE maximization benchmarks

</details>


### [14] [Splitting Alternating Algorithms for Sparse Solutions of Linear Systems with Concatenated Orthogonal Matrices](https://arxiv.org/abs/2509.24558)
*Yun-Bin Zhao,Zhong-Feng Sun*

Main category: cs.IT

TL;DR: 提出了一种分裂交替算法（TSAA和MSAA）用于求解具有级联正交矩阵的线性系统的稀疏解，通过分解大系统为多个小子系统并组合其解来获得原始系统的稀疏解。


<details>
  <summary>Details</summary>
Motivation: 针对大规模线性系统求解稀疏解的问题，传统方法计算复杂度高，需要开发更高效的算法来分解系统并减少计算负担。

Method: 将大规模线性系统分解为两个或多个耦合的子系统，每个子系统远小于原系统，然后通过交替求解这些子系统并结合其解来获得原系统的稀疏解。算法仅涉及矩阵向量乘积和降维正交投影。

Result: 在满足相干性条件的情况下，算法全局收敛到稀疏解。数值实验表明，该算法比主流迭代方法需要更少的迭代次数，能快速准确地定位稀疏解。

Conclusion: 提出的分裂交替算法是求解具有级联正交矩阵的线性系统稀疏解的有效方法，具有全局收敛性和计算效率高的优点。

Abstract: A class of splitting alternating algorithms is proposed for finding the
sparse solution of linear systems with concatenated orthogonal matrices.
Depending on the number of matrices concatenated, the proposed algorithms are
classified into the two-block splitting alternating algorithm (TSAA) and the
multi-block splitting alternating algorithm (MSAA). These algorithms aim to
decompose a large-scale linear system into two or more coupled subsystems, each
significantly smaller than the original system, and then combine the solutions
of these subsystems to produce the sparse solution of the original system. The
proposed algorithms only involve matrix-vector products and reduced orthogonal
projections. It turns out that the proposed algorithms are globally convergent
to the sparse solution of a linear system if the matrix (along with the
sparsity level of the solution) satisfies a coherence-type condition. Numerical
experiments indicate that the proposed algorithms are very promising and can
quickly and accurately locate the sparse solution of a linear system with
significantly fewer iterations than several mainstream iterative methods.

</details>


### [15] [On the Performance of Amplitude-Based Models for Low-Rank Matrix Recovery](https://arxiv.org/abs/2509.24699)
*Huanmin Ge,Zhiqiang Xu*

Main category: cs.IT

TL;DR: 本文研究了低秩相位恢复问题，提出了基于秩约束和非凸优化的重建方法，并建立了相应的理论误差界。


<details>
  <summary>Details</summary>
Motivation: 相位恢复和低秩矩阵恢复是信号处理中的重要问题，但现有方法在处理低秩结构时存在理论空白。本文旨在统一这两个领域，为低秩相位恢复提供理论保证。

Method: 提出了秩约束非线性最小二乘模型和核范数约束的Lasso模型，引入了强限制等距性(SRIP)来分析线性映射的性质。

Result: 证明了在高斯测量下，重建误差满足$\min\{\|\hat{\mathbf{X}}-\mathbf{X}_0\|_F, \|\hat{\mathbf{X}}+\mathbf{X}_0\|_F\}\lesssim \frac{\|\boldsymbol{\eta}\|_2}{\sqrt{p}}$，且该误差界是最优的。

Conclusion: 本文为低秩相位恢复提供了统一的理论框架，扩展了相位恢复和低秩矩阵恢复的现有结果，建立了严格的理论保证。

Abstract: In this paper, we focus on low-rank phase retrieval, which aims to
reconstruct a matrix $\mathbf{X}_0\in \mathbb{R}^{n\times m}$ with ${\mathrm{
rank}}(\mathbf{X}_0)\le r$ from noise-corrupted amplitude measurements
$\mathbf{y}=|\mathcal{A}(\mathbf{X}_0)|+\boldsymbol{\eta}$, where
$\mathcal{A}:\mathbb{R}^{n\times m}\rightarrow \mathbb{R}^{p}$ is a linear map
and $\boldsymbol{\eta}\in \mathbb{R}^p$ is the noise vector. We first examine
the rank-constrained nonlinear least-squares model $\hat{\mathbf{X}}\in
\mathop{\mathrm{argmin}}\limits_{\substack{\mathbf{X}\in \mathbb{R}^{n\times
m},\mathrm{rank}(\mathbf{X})\le
r}}\||\mathcal{A}(\mathbf{X})|-\mathbf{y}\|_2^2$ to estimate $\mathbf{X}_0$,
and demonstrate that the reconstruction error satisfies
$\min\{\|\hat{\mathbf{X}}-\mathbf{X}_0\|_F,
\|\hat{\mathbf{X}}+\mathbf{X}_0\|_F\}\lesssim
\frac{\|\boldsymbol{\eta}\|_2}{\sqrt{p}}$ with high probability, provided
$\mathcal{A}$ is a Gaussian measurement ensemble and $p\gtrsim (m+n)r$. We also
prove that the error bound $\frac{\|\boldsymbol{\eta}\|_2}{\sqrt{p}}$ is tight
up to a constant. Furthermore, we relax the rank constraint to a nuclear-norm
constraint. Hence, we propose the Lasso model for low-rank phase retrieval,
i.e., the constrained nuclear-norm model and the unconstrained version. We also
establish comparable theoretical guarantees for these models. To achieve this,
we introduce a strong restricted isometry property (SRIP) for the linear map
$\mathcal{A}$, analogous to the strong RIP in phase retrieval. This work
provides a unified treatment that extends existing results in both phase
retrieval and low-rank matrix recovery from rank-one measurements.

</details>


### [16] [On the Error Rate of Binary BCH Codes under Error-and-erasure Decoding](https://arxiv.org/abs/2509.24794)
*Sisi Miao,Jonathan Mandelbaum,Holger Jäkel,Laurent Schmalen*

Main category: cs.IT

TL;DR: 本文针对二进制BCH码，推导了错误与擦除解码及其变种的精确错误概率闭式表达式，改进了传统的有限距离解码，并通过仿真验证了结果。


<details>
  <summary>Details</summary>
Motivation: 确定线性分组码的精确解码错误概率是一个重要问题。传统的有限距离解码(BDD)在许多应用中表现不足，需要改进的解码方法。

Method: 采用错误与擦除解码及其变种方法，推导了这些解码方案的错误概率闭式表达式，并通过仿真进行验证。

Result: 成功推导出错误与擦除解码及其变种的精确错误概率表达式，仿真结果验证了理论推导的正确性。

Conclusion: 所提出的解码方法优于传统BDD，可用于评估级联编码方案的性能，为实际应用提供了更准确的性能分析工具。

Abstract: Determining the exact decoding error probability of linear block codes is an
interesting problem. For binary BCH codes, McEliece derived methods to estimate
the error probability of a simple bounded distance decoding (BDD) for BCH
codes. However, BDD falls short in many applications. In this work, we consider
error-and-erasure decoding and its variants that improve upon BDD. We derive
closed-form expressions for their error probabilities and validate them through
simulations. Then, we illustrate their use in assessing concatenated coding
schemes.

</details>


### [17] [Physical Layer Security over Fluid Reconfigurable Intelligent Surface-assisted Communication Systems](https://arxiv.org/abs/2509.24845)
*Masoud Kaveh,Farshad Rostami Ghadi,Francisco Hernando-Gallego,Diego Martín,Kai-Kit Wong,Riku Jäntti*

Main category: cs.IT

TL;DR: 本文研究了流体可重构智能表面辅助的无线通信系统保密性能，通过推导保密中断概率和平均保密容量的上下界，证明了FRIS在空间相关性下能有效实现安全通信，且性能优于传统RIS。


<details>
  <summary>Details</summary>
Motivation: 传统RIS具有固定几何结构，而FRIS能根据实时信道条件动态选择反射单元，提供更好的空间多样性和适应性，特别是在存在窃听者的安全通信场景中。

Method: 建立了一个安全下行链路场景模型，基站通过有限ON状态元素的FRIS与合法用户通信，在空间相关性下推导了保密中断概率的下界和平均保密容量的上界。

Result: FRIS即使在部分激活状态下，也能显著优于传统RIS，在不同部署密度和单元相关性条件下都能有效增强保密性能。

Conclusion: FRIS在空间相关性环境下能够有效实现安全通信，其动态元素选择机制相比传统RIS具有明显的保密性能优势。

Abstract: This letter investigates the secrecy performance of wireless communication
systems assisted by a fluid reconfigurable intelligent surface (FRIS). Unlike
conventional reconfigurable intelligent surfaces (RISs) with fixed geometries,
FRISs dynamically select a subset of reflective elements based on real-time
channel conditions, offering enhanced spatial diversity and adaptability. Using
this foundation, we model a secure downlink scenario where a base station
communicates with a legitimate user in the presence of an eavesdropper, and the
propagation is assisted by a FRIS with a limited number of elements set to the
ON state. We analyze the system's secrecy performance under spatial correlation
by deriving analytical lower and upper bounds for the secrecy outage
probability (SOP) and average secrecy capacity (ASC), respectively. Our results
demonstrate that FRIS effectively enables secure communication under spatial
correlation. Even with partial activation, FRIS significantly outperforms
conventional RISs in enhancing secrecy performance under varying deployment
densities and element correlations.

</details>


### [18] [Capacity Achieving Design for Hybrid Beamforming in Millimeter Wave Massive MIMO Systems](https://arxiv.org/abs/2509.25067)
*Rohollah Vahdani,S. Mohammad Razavizadeh*

Main category: cs.IT

TL;DR: 提出了一种基于发射信号协方差矩阵优化的混合波束成形新方法，通过BC-MAC对偶关系解决非凸问题，在多种场景下显著提升毫米波系统的下行链路和速率容量。


<details>
  <summary>Details</summary>
Motivation: 当前混合波束成形设计仅依赖信道信息，忽略了发射信号协方差矩阵结构的重要性，这限制了系统性能的进一步提升。

Method: 基于发射信号协方差矩阵优化的联合设计方法，利用广播信道(BC)和多址接入信道(MAC)之间的对偶关系来处理非凸优化问题。

Result: 在点对点MIMO、多用户MISO和MU-MIMO等多种场景下的仿真表明，所提方法优于传统设计，显著提升了系统性能。

Conclusion: 该方法为毫米波系统波束成形优化提供了有效且通用的解决方案，证明了考虑发射信号协方差矩阵结构的重要性。

Abstract: Hybrid digital and analog beamforming is a highly effective technique for
implementing beamforming methods in millimeter wave (mmWave) systems. It
provides a viable solution to replace the complex fully digital beamforming
techniques. However, the current design of precoding and combining matrices in
hybrid beamforming solely relies on the channel information, neglecting the
crucial consideration of the structure of covariance matrices of the transmit
signals. In this paper, we present a novel approach for the joint design of
hybrid beamforming matrices at the transmitter and receiver. This approach is
centered around the optimization of the covariance matrix of the transmitted
signals. Our goal is to maximize the downlink sum rate capacity of the system
by achieving an optimal design of the transmit covariance matrix. We tackle the
non-convex nature of this problem by leveraging the dual relationship between
the broadcast channel (BC) and the multiple access channel (MAC). Through
extensive simulations in various scenarios, including point-to-point
multi-input multi-output (MIMO), multi-user (MU) multi-input single-output
(MISO), and MU-MIMO, we demonstrate the superiority of our proposed method over
traditional designs. These results highlight the effectiveness and versatility
of our approach in optimizing beamforming for mmWave systems.

</details>


### [19] [Unsourced Random Access](https://arxiv.org/abs/2509.25074)
*Kirill Andreev,Pavel Rybin,Alexey Frolov*

Main category: cs.IT

TL;DR: 本文综述了无源随机接入(URA)范式，该范式通过设备共享编码器来优化机器类通信(MTC)中的短包传输，解决了传统基于授权的多址接入在延迟和效率方面的不足。


<details>
  <summary>Details</summary>
Motivation: 传统无线网络为人类用户优化频谱效率，但无法满足机器类通信(MTC)中大量设备产生的零星短包流量模式，现有基于授权的多址接入程序导致显著延迟和低效率。

Method: 提出无源随机接入(URA)范式，让设备共享公共编码器，简化接收过程，将随机接入视为编码问题，同时考虑媒体接入协议和物理层效应。

Result: URA范式解决了计算挑战，为MTC中的短包传输提供了更高效的解决方案。

Conclusion: URA是解决机器类通信中随机接入问题的有前景方法，本专著旨在解释主要思想而非列举所有现有解决方案。

Abstract: Current wireless networks are designed to optimize spectral efficiency for
human users, who typically require sustained connections for high-data-rate
applications like file transfers and video streaming. However, these networks
are increasingly inadequate for the emerging era of machine-type communications
(MTC). With a vast number of devices exhibiting sporadic traffic patterns
consisting of short packets, the grant-based multiple access procedures
utilized by existing networks lead to significant delays and inefficiencies. To
address this issue the unsourced random access (URA) paradigm has been
proposed. This paradigm assumes the devices to share a common encoder thus
simplifying the reception process by eliminating the identification procedure.
The URA paradigm not only addresses the computational challenges but it also
considers the random access (RA) as a coding problem, i.e., takes into account
both medium access protocols and physical layer effects. In this monograph we
provide a comprehensive overview of the URA problem in noisy channels, with the
main task being to explain the major ideas rather than to list all existing
solutions.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [20] [Generative Modeling and Decision Fusion for Unknown Event Detection and Classification Using Synchrophasor Data](https://arxiv.org/abs/2509.22795)
*Yi Hu,Zheyuan Cheng*

Main category: eess.SP

TL;DR: 提出了一种结合生成建模、滑动窗口处理和决策融合的电力系统事件检测与分类框架，能够识别已知事件并将未知扰动分类为新类别。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限标记数据集，难以泛化到罕见或未见过的电力系统扰动，需要更鲁棒的检测和分类方法。

Method: 使用变分自编码器-生成对抗网络建模正常运行状态，提取重构误差和判别器误差作为异常指标；开发阈值和凸包两种决策策略；通过滑动窗口机制组织时空检测和分类矩阵；集成多PMU输出进行决策融合。

Result: 实验结果表明该方法达到最先进精度，超越机器学习、深度学习和基于包络线的基准方法，能够识别未知事件。

Conclusion: 该框架具有适应性和实用价值，能够解决监督分类器的关键限制，适用于现代电力系统的广域事件分析。

Abstract: Reliable detection and classification of power system events are critical for
maintaining grid stability and situational awareness. Existing approaches often
depend on limited labeled datasets, which restricts their ability to generalize
to rare or unseen disturbances. This paper proposes a novel framework that
integrates generative modeling, sliding-window temporal processing, and
decision fusion to achieve robust event detection and classification using
synchrophasor data. A variational autoencoder-generative adversarial network is
employed to model normal operating conditions, where both reconstruction error
and discriminator error are extracted as anomaly indicators. Two complementary
decision strategies are developed: a threshold-based rule for computational
efficiency and a convex hull-based method for robustness under complex error
distributions. These features are organized into spatiotemporal detection and
classification matrices through a sliding-window mechanism, and an
identification and decision fusion stage integrates the outputs across PMUs.
This design enables the framework to identify known events while systematically
classifying previously unseen disturbances into a new category, addressing a
key limitation of supervised classifiers. Experimental results demonstrate
state-of-the-art accuracy, surpassing machine learning, deep learning, and
envelope-based baselines. The ability to recognize unknown events further
highlights the adaptability and practical value of the proposed approach for
wide-area event analysis in modern power systems.

</details>


### [21] [Introducing Multimodal Paradigm for Learning Sleep Staging PSG via General-Purpose Model](https://arxiv.org/abs/2509.22810)
*Jianheng Zhou,Chenyu Liu,Jinan Zhou,Yi Ding,Yang Liu,Haoran Luo,Ziyu Jia,Xinliang Zhou*

Main category: eess.SP

TL;DR: 提出了一种新的睡眠分期方法，将一维PSG信号转换为二维波形图像，然后微调多模态大模型进行睡眠分期，在三个公开数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动睡眠分期方法通常从复杂的PSG信号中提取特征并训练领域特定模型，缺乏直观性且需要大量专业数据集。

Method: 将原始一维PSG时间序列转换为直观的二维波形图像，然后微调多模态大模型学习这些表示。

Result: 在ISRUC、MASS、SHHS三个数据集上的实验表明，该方法使通用模型能够获得鲁棒的分期能力，且解释分析显示模型学会了模仿人类专家基于PSG图像的视觉诊断流程。

Conclusion: 该方法在准确性和鲁棒性上一致优于最先进的基线方法，突显了其在医疗应用中的效率和实用价值。

Abstract: Sleep staging is essential for diagnosing sleep disorders and assessing
neurological health. Existing automatic methods typically extract features from
complex polysomnography (PSG) signals and train domain-specific models, which
often lack intuitiveness and require large, specialized datasets. To overcome
these limitations, we introduce a new paradigm for sleep staging that leverages
large multimodal general-purpose models to emulate clinical diagnostic
practices. Specifically, we convert raw one-dimensional PSG time-series into
intuitive two-dimensional waveform images and then fine-tune a multimodal large
model to learn from these representations. Experiments on three public datasets
(ISRUC, MASS, SHHS) demonstrate that our approach enables general-purpose
models, without prior exposure to sleep data, to acquire robust staging
capabilities. Moreover, explanation analysis reveals our model learned to mimic
the visual diagnostic workflow of human experts for sleep staging by PSG
images. The proposed method consistently outperforms state-of-the-art baselines
in accuracy and robustness, highlighting its efficiency and practical value for
medical applications. The code for the signal-to-image pipeline and the PSG
image dataset will be released.

</details>


### [22] [Scalable Wi-Fi RSS-Based Indoor Localization via Automatic Vision-Assisted Calibration](https://arxiv.org/abs/2509.22869)
*Abdulkadir Bilge,Erdem Ergen,Burak Soner,Sinem Coleri*

Main category: eess.SP

TL;DR: 提出了一种轻量级框架，通过摄像头辅助的短时校准阶段自动收集高分辨率同步的RSS-位置数据，用于训练可移动部署的Wi-Fi定位算法，避免了持续视频监控的隐私问题。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi定位在室内环境中具有可扩展性和隐私保护优势，但RSS方法易受多径、信道变化和接收器特性影响。监督学习方法需要大量标注数据，成本高昂。

Method: 使用一次性标定的顶置摄像头跟踪设备，收集附近接入点广播包的RSS数据，生成(x, y, RSS)数据集，自动训练移动可部署的定位算法。

Result: 量化了视觉辅助RSS数据收集在跟踪精度和标签同步等关键因素下的精度限制，在不同信号条件和设备类型下测试了传统和监督学习方法，展示了改进的准确性和泛化能力。

Conclusion: 该框架在实际应用中具有实用价值，所有代码、工具和数据集均已开源发布。

Abstract: Wi-Fi-based positioning promises a scalable and privacy-preserving solution
for location-based services in indoor environments such as malls, airports, and
campuses. RSS-based methods are widely deployable as RSS data is available on
all Wi-Fi-capable devices, but RSS is highly sensitive to multipath, channel
variations, and receiver characteristics. While supervised learning methods
offer improved robustness, they require large amounts of labeled data, which is
often costly to obtain. We introduce a lightweight framework that solves this
by automating high-resolution synchronized RSS-location data collection using a
short, camera-assisted calibration phase. An overhead camera is calibrated only
once with ArUco markers and then tracks a device collecting RSS data from
broadcast packets of nearby access points across Wi-Fi channels. The resulting
(x, y, RSS) dataset is used to automatically train mobile-deployable
localization algorithms, avoiding the privacy concerns of continuous video
monitoring. We quantify the accuracy limits of such vision-assisted RSS data
collection under key factors such as tracking precision and label
synchronization. Using the collected experimental data, we benchmark
traditional and supervised learning approaches under varying signal conditions
and device types, demonstrating improved accuracy and generalization,
validating the utility of the proposed framework for practical use. All code,
tools, and datasets are released as open source.

</details>


### [23] [Time-Frequency Analysis of Non-Uniformly Sampled Signals via Sample Density Adaptation](https://arxiv.org/abs/2509.22891)
*Ashwini Kulkarni,Santosh Nannuru*

Main category: eess.SP

TL;DR: 提出了一种针对非均匀采样数据的时频分析方法——非均匀Stockwell变换(NUST)，该方法使用双重自适应窗口，在频率和局部数据密度上调整窗口宽度，能够同时检测瞬态和持续信号。


<details>
  <summary>Details</summary>
Motivation: 传统方法如广义Lomb-Scargle周期图对瞬态事件不敏感，而现有的时频方法通常依赖固定时长窗口或插值，对非均匀采样数据效果不佳。

Method: NUST方法直接对非均匀采样数据应用局部密度自适应谱分析，采用基于频率和局部数据密度的双重自适应窗口。

Result: 在多个非均匀采样合成信号上验证了NUST的优越时域定位性能，并在HD 10180多行星系统的HARPS径向速度数据中成功区分了行星信号和恒星活动。

Conclusion: NUST为非均匀采样数据的时频分析提供了一个有效的框架，能够同时处理瞬态和持续信号，在行星探测和恒星活动分析中具有重要应用价值。

Abstract: The analysis of non-stationary signals in non-uniformly sampled data is a
challenging task. Time-integrated methods, such as the generalised Lomb-Scargle
(GLS) periodogram, provide a robust statistical assessment of persistent
periodicities but are insensitive to transient events. Conversely, existing
time-frequency methods often rely on fixed-duration windows or interpolation,
which can be suboptimal for non-uniform data. We introduce the non-uniform
Stockwell-transform (NUST), a time-frequency framework that applies a localized
density adaptive spectral analysis directly to non-uniformly sampled data. NUST
employs a doubly adaptive window that adjusts its width based on both frequency
and local data density, providing detailed time-frequency information for both
transient and persistent signals. We validate the NUST on numerous
non-uniformly sampled synthetic signals, demonstrating its superior
time-localization performance compared to GLS. Furthermore, we apply NUST to
HARPS radial velocity data of the multi-planetary system HD 10180, successfully
distinguishing coherent planetary signals from stellar activity.

</details>


### [24] [Resource Allocation in Cooperative Mid-band/THz Networks in the Presence of Mobility](https://arxiv.org/abs/2509.23065)
*Mohammad Amin Saeidi,Hina Tabassum*

Main category: eess.SP

TL;DR: 该论文开发了一个综合框架来优化多频段协作网络的下行性能，结合了上中频和太赫兹频段，考虑了近场信道建模、天线架构和用户移动性，提出了联合用户关联和混合波束成形优化算法以及切换感知的资源分配方法。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信向更高频段发展，需要解决多频段协作网络中的性能优化问题，特别是在上中频和太赫兹频段协作场景下，需要处理复杂的近场信道效应、用户移动性和切换管理等挑战。

Method: 采用分数规划和主化最小化技术解决非凸优化问题；使用Jensen不等式和对数函数特性将非凸问题近似为凸问题；提出两种切换感知的资源分配方法：一种是最大化切换感知系统总速率，另一种是多目标优化同时最大化系统总速率和最小化切换次数。

Result: 数值结果表明所提算法有效，协作UMB/THz网络优于独立THz网络，准确近场建模在超大天线阵列中至关重要，切换感知资源分配方法能有效减轻切换影响。

Conclusion: 提出的框架和算法成功解决了多频段协作网络中的关键挑战，证明了协作UMB/THz网络的优越性，并为未来高频段无线通信系统设计提供了重要指导。

Abstract: This paper develops a comprehensive framework to investigate and optimize the
downlink performance of cooperative multi-band networks (MBNs) operating on
upper mid-band (UMB) and terahertz (THz) frequencies, where base stations (BSs)
in each band cooperatively serve users. The framework captures sophisticated
features such as near-field channel modeling, fully and partially connected
antenna architectures, and users' mobility. First, we consider joint user
association and hybrid beamforming optimization to maximize the system
sum-rate, subject to power constraints, maximum cluster size of cooperating
BSs, and users' quality-of-service (QoS) constraints. By leveraging fractional
programming FP and majorization-minimization techniques, an iterative algorithm
is proposed to solve the non-convex optimization problem. We then consider
handover (HO)-aware resource allocation for moving users in a cooperative
UMB/THz MBN. Two HO-aware resource allocation methods are proposed. The first
method focuses on maximizing the HO-aware system sum-rate subject to HO-aware
QoS constraints. Using Jensen's inequality and properties of logarithmic
functions, the non-convex optimization problem is tightly approximated with a
convex one and solved. The second method addresses a multi-objective
optimization problem to maximize the system sum-rate, while minimizing the
total number of HOs. Numerical results demonstrate the efficacy of the proposed
algorithms, cooperative UMB/THz MBN over stand-alone THz networks, as well as
the critical importance of accurate near-field modeling in extremely large
antenna arrays. Moreover, the proposed HO-aware resource allocation methods
effectively mitigate the impact of HOs, enhancing performance in the considered
system.

</details>


### [25] [Dual-Function Beam Pattern Design for Multi-Target ISAC Systems: A Decoupled Approach](https://arxiv.org/abs/2509.23302)
*Wilson de Souza Junior,Taufik Abrao,Amine Mezghani,Ekram Hossain*

Main category: eess.SP

TL;DR: 提出了一种用于单基地多用户多点目标集成感知与通信系统的波束模式设计方法，通过分解感知问题并利用波束模式的物理特性，在保证通信性能的同时提高多目标估计精度。


<details>
  <summary>Details</summary>
Motivation: 在ISAC系统中，感知和通信竞争资源，传统联合优化方法忽略了这种权衡，导致通信需求增加时波束模式重塑可能降低DoA感知精度。

Method: 将感知问题分解为两个子问题，提出SGCDF波束模式设计，并开发基于黎曼流形优化和凸闭集投影的低复杂度扩展版本。

Result: 仿真结果表明，相比传统联合优化策略，所提方法通过保持波束模式提高了多目标估计精度，低复杂度版本在显著降低计算成本的同时保持高精度。

Conclusion: 所提出的SGCDF方法有效解决了ISAC系统中感知与通信的权衡问题，低复杂度版本提供了优异的性能-复杂度权衡。

Abstract: We investigate the beampattern design problem for mono-static multi-user (MU)
multi-point-target integrated sensing and communication (ISAC) systems, where a
dual-function multiple-input multiple-output (DF-MIMO) base station (BS)
performs downlink communication and radar sensing simultaneously. In ISAC
systems, sensing and communication inherently compete for resources. As
communication demand increases, the beam pattern is reshaped, which might
degrade the direction of arrival (DoA) sensing accuracy, measured in terms of
mean-squared error (MSE) and lower-bounded by the Cramer-Rao lower bound
(CRLB). Since conventional joint formulations of the sensing-based problem
often overlook this trade-off, our work addresses it by decomposing the
sensing-based problem into two subproblems (SPs). This decomposition enables a
more effective exploitation of the beam pattern's physical properties, which we
refer to as the Sensing-Guided Communication Dual-Function (SGCDF) beam pattern
design. We further develop a low-complexity extension using the Riemannian
Manifold Optimization (RMO) and convex closed-set projection. Simulation
results confirm that the proposed method improves multi-target estimation
accuracy, compared to traditional joint optimization strategies, by preserving
the beam pattern, while the low-complexity version offers an excellent
performance-complexity tradeoff, maintaining high accuracy with significantly
reduced computational cost.

</details>


### [26] [HoloTrace: a Location Privacy Preservation Solution for mmWave MIMO-OFDM Systems](https://arxiv.org/abs/2509.23444)
*Lorenzo Italiano,Alireza Pourafzal,Hui Chen,Mattia Brambilla,Gonzalo Seco-Granados,Monica Nicoli,Henk Wymeersch*

Main category: eess.SP

TL;DR: HoloTrace是一个信号级隐私保护框架，通过在用户端欺骗定位相关特征来防止基站从毫米波MIMO-OFDM信号中提取精确位置信息。


<details>
  <summary>Details</summary>
Motivation: 6G蜂窝网络的技术创新带来了前所未有的用户设备定位能力，但同时也引发了物理层位置隐私的严重担忧。

Method: 用户端对到达角、离开角和时间差等定位参数进行欺骗，通过战略性地扰动导频传输来防止基站执行非自愿的用户定位，无需协议修改或网络侧支持。

Result: 仿真结果表明，该方法能够欺骗基站，诱导显著的位置定位误差，而对链路容量的影响取决于欺骗的位置。

Conclusion: HoloTrace被确立为未来6G网络中实用且强大的隐私保护解决方案。

Abstract: The technological innovation towards 6G cellular networks introduces
unprecedented capabilities for user equipment (UE) localization, but it also
raises serious concerns about physical layer location privacy. This paper
introduces HoloTrace, a signal-level privacy preservation framework that relies
on user-side spoofing of localization-relevant features to prevent the
extraction of precise location information from the signals received by a base
station (BS) in a mmWave MIMO-OFDM system. Spoofing is performed by the user on
location parameters such as angle of arrival (AoA), angle of departure (AoD),
and time difference of arrival (TDoA). Without requiring any protocol
modification nor network-side support, our method strategically perturbs pilot
transmissions to prevent a BS from performing non-consensual UE localization.
The methodology allows the UE to spoof its position, keeping the precoder
unchanged. We formulate spoofing as a unified rank-constrained projection
problem, and provide closed-form solutions under varying levels of channel
state information (CSI) at the UE, including scenarios with and without CSI
knowledge. Simulation results confirm that the proposed approach enables the UE
to deceive the BS, inducing significant localization errors, while the impact
on link capacity varies depending on the spoofed position. Our findings
establish HoloTrace as a practical and robust privacy-preserving solution for
future 6G networks.

</details>


### [27] [Theoretical framework of passive ME antenna arrays enabling in-vivo monitoring: A pathway to smart implants](https://arxiv.org/abs/2509.23520)
*Kalpesh Jaykar,Prasanth Velvaluri,Nian X. Sun,Richard D. James*

Main category: eess.SP

TL;DR: 提出使用磁电天线阵列增强血管内脑机接口设备的信号传输能力，通过相位同步和空间优化实现高增益性能


<details>
  <summary>Details</summary>
Motivation: 传统Stentrode脑机接口设备存在电池和电子线路可能导致的损伤风险，且单个磁电天线因磁致伸缩材料体积限制导致输出增益较低

Method: 开发数学模型表示天线阵列，优化空间排列和相位同步，通过相位操控在指定远场点产生相长干涉

Result: 基于模型的仿真显示，在规定的远场位置通过相位操控实现了有前景的高增益性能

Conclusion: 磁电天线阵列能够有效解决血管内植入设备中单个天线的增益限制问题，为微创监测和通信提供了可行方案

Abstract: A new brain-computer interface (BCI) technology, deployed through minimally
invasive surgery, is changing the way we think about treating severe
neurological conditions. The central idea is to place a device called Stentrode
in the brain's vasculature, which enables neuromodulation and helps patients
regain the ability to communicate. However, in such devices, the battery and
electronics are wired and could introduce damage or implant malfunction. In
these cases, a Stentrode integrated with magnetoelectric (ME) antennas could be
of great interest. ME antennas offer significant advantages over traditional
antennas, leveraging acoustic resonance rather than electromagnetic resonance
to achieve a size reduction of up to five orders of magnitude. In addition to
their compactness and immunity to ground-plane interference, ME antennas could
be adopted for use in vascular implants, such as coronary stents, potentially
enabling minimally invasive monitoring and communication. Despite these
advantages, a single antenna embedded in the implant may be constrained by the
limited volume of magnetostrictive material, which could result in low output
gain. To address this gain limitation, we propose using antenna arrays designed
to produce constructive interference at a designated far-field point, ideally
located outside the patient, to enhance signal transmission and receiving
capabilities. We develop a mathematical model to represent the antennas and
optimize their spatial arrangement and phase synchronization. Simulations based
on this model demonstrate promising high-gain performance at the prescribed
far-field location through phase manipulation.

</details>


### [28] [Learnable Kernels for FRI -- Joint Kernel Encoder Optimization and Hardware Validation](https://arxiv.org/abs/2509.23644)
*Omkar Nitsure,Sampath Kumar Dondapati,Satish Mulleti*

Main category: eess.SP

TL;DR: 提出了一种基于可学习核的FRI采样重构框架，通过优化采样核和重构编码器，在降低采样率的同时提高了分辨率和噪声鲁棒性，并实现了硬件实现。


<details>
  <summary>Details</summary>
Motivation: 传统FRI重构方法严重依赖预定义核，限制了硬件实现和在噪声条件下的重构精度。

Method: 使用可截断高斯和高斯对等固定核进行重构，然后通过联合优化采样核和重构编码器获得自适应核，最后用两个指数衰减信号的和表示核以实现硬件实现。

Result: 在硬件实现中使用Sallen-Key模拟滤波器实现了准确的真实信号恢复，基于CNN的编码器显著降低了计算复杂度，在参数更少的情况下表现出竞争力。

Conclusion: 该方法特别适合资源受限的边缘部署场景，提供了稳健、灵活且可实际实现的FRI重构框架。

Abstract: Finite Rate of Innovation (FRI) sampling techniques provide efficient
frameworks for reconstructing signals with inherent sparsity at rates below
Nyquist. However, traditional FRI reconstruction methods rely heavily on
pre-defined kernels, often limiting hardware implementation and reconstruction
accuracy under noisy conditions. In this paper, we propose a robust, flexible,
and practically implementable framework for FRI reconstruction by introducing
novel learnable kernel strategies. First, we demonstrate effective
reconstruction using known, fixed kernels such as truncated Gaussian and
Gaussian pair kernels, which mitigate the requirement that the samples should
have a sum-of-exponentials (SoE) form. Next, we extend this concept by jointly
optimizing both the sampling kernel and reconstruction encoder through a
unified learning approach, yielding adaptive kernels that significantly
outperform traditional methods in resolution and noise robustness, with reduced
sampling rates. Furthermore, we propose a practical hardware realization by
representing kernels as sums of two exponential decay signals with jointly
optimized poles, facilitating compact, efficient analog implementations. Our
approach is validated experimentally through hardware implementations using a
unity-gain Sallen-Key analog filter, achieving accurate real-world signal
recovery. The developed convolutional neural network-based encoder
substantially reduces computational complexity, demonstrating competitive
performance with fewer parameters, making our method particularly suitable for
resource-constrained, edge-based deployments.

</details>


### [29] [Joint Hybrid Beamforming and Artificial Noise Design for Secure Multi-UAV ISAC Networks](https://arxiv.org/abs/2509.23687)
*Runze Dong,Buhong Wang,Cunqian Feng,Jiang Weng,Chen Han,Jiwei Tian*

Main category: eess.SP

TL;DR: 提出了一种用于多无人机网络的安全高效ISAC框架，采用两阶段优化方法联合设计混合波束成形、人工噪声注入和无人机轨迹，以最大化总保密率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要将无人机视为空中基站，忽视了其作为ISAC用户的角色，且未能利用地面基站的大规模天线阵列来增强安全性和频谱效率。

Method: 两阶段优化方法：第一阶段使用PPO算法优化数字波束成形器和轨迹；第二阶段通过低复杂度矩阵分解将数字解分解为模拟和数字分量。

Result: 仿真结果表明，与基准方案相比，所提框架具有显著的有效性。

Conclusion: 该框架成功解决了多无人机网络中ISAC的安全性和频谱效率问题，为下一代应用提供了可靠解决方案。

Abstract: Integrated sensing and communication (ISAC) emerges as a key enabler for
next-generation applications such as smart cities and autonomous systems. Its
integration with unmanned aerial vehicles (UAVs) unlocks new potentials for
reliable communication and precise sensing in dynamic aerial environments.
However, existing research predominantly treats UAVs as aerial base stations,
overlooking their role as ISAC users, and fails to leverage large-scale antenna
arrays at terrestrial base stations to enhance security and spectral
efficiency. This paper propose a secure and spectral efficient ISAC framework
for multi-UAV networks, and a two-stage optimization approach is developed to
jointly design hybrid beamforming (HBF), artificial noise (AN) injection, and
UAV trajectories. Aiming at maximizing the sum secrecy rate, the first stage
employs Proximal Policy Optimization (PPO) to optimize digital beamformers and
trajectories, and the second stage decomposes the digital solution into analog
and digital components via low-complexity matrix factorization. Simulation
results demonstrate the effectiveness of the proposed framework compared to
benchmark schemes.

</details>


### [30] [Expectation Propagation-Based Signal Detection for Highly Correlated MIMO Systems](https://arxiv.org/abs/2509.23792)
*Kabuto Arai,Takumi Yoshida,Takumi Takahashi,Koji Ishibashi*

Main category: eess.SP

TL;DR: 提出了一种基于期望传播的重叠块分区检测器(OvEP)，用于解决大规模MIMO系统中信道矩阵高度相关导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统在密集阵列部署和有限散射环境下，信道矩阵高度相关且病态，严重降低了基于消息传递的检测器性能。

Method: 将大规模测量向量划分为部分重叠的块，为每个块及其重叠部分设计低复杂度LMMSE滤波器，通过减去重叠部分输出来减轻块间相关性影响。

Result: 该算法在数值模拟中实现了接近传统LMMSE-EP的性能，但计算复杂度更低。

Conclusion: OvEP算法在EP框架下一致推导，其固定点理论上与松弛KL最小化问题的驻点重合，有效解决了高空间相关性带来的性能问题。

Abstract: Large-scale multiple-input-multiple-output (MIMO) systems typically operate
in dense array deployments with limited scattering environments, leading to
highly correlated and ill-conditioned channel matrices that severely degrade
the performance of message-passing-based detectors. To tackle this issue, this
paper proposes an expectation propagation (EP)-based detector, termed
overlapping block partitioning EP (OvEP). In OvEP, the large-scale measurement
vector is partitioned into partially overlapping blocks. For each block and its
overlapping part, a low-complexity linear minimum mean square error
(LMMSE)-based filter is designed according to the partitioned structure. The
resulting LMMSE outputs are then combined to generate the input to the
denoiser. In this combining process, subtracting the overlapping-part outputs
from the block outputs effectively mitigates the adverse effects of inter-block
correlation induced by high spatial correlation. The proposed algorithm is
consistently derived within the EP framework, and its fixed point is
theoretically proven to coincide with the stationary point of a relaxed
Kullback- Leibler (KL) minimization problem. The mechanisms underlying the
theoretically predicted performance improvement are further clarified through
numerical simulations. The proposed algorithm achieves performance close to
conventional LMMSE-EP with lower computational complexity.

</details>


### [31] [Online Specific Emitter Identification via Collision-Alleviated Signal Hash](https://arxiv.org/abs/2509.23807)
*Hongyu Wang,Wenjia Xu,Guangzuo Li,Siyuan Wan,Yaohua Sun,Jiuniu Wang,Mugen Peng*

Main category: eess.SP

TL;DR: 本文提出了在线特定发射器识别（OSEI）任务，解决传统SEI方法无法识别未见发射器的问题。作者开发了CASH模型，通过两阶段哈希编码方法，在真实信号数据集上取得了优于现有方法6.08%-8.55%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现实场景中需要识别来自未见发射器的信号，而现有模型由于缺乏先验样本，难以在线识别这些新发射器，且容易偏向已见发射器的分布。

Method: 提出CASH模型，包含两个步骤：1) 已见发射器识别步骤，使用信号编码器和识别器判断信号是否来自已见发射器；2) 信号哈希编码步骤，为每个信号样本分配哈希码以识别其特定发射器。

Result: 在ADSB和ORACLE真实信号数据集上的实验表明，该方法能够准确在线识别来自已见和未见发射器的信号，在小样本学习和广义零样本学习任务中分别比现有方法至少提高6.08%和8.55%的准确率。

Conclusion: CASH模型为OSEI任务提供了统一的解决方案，有效缓解了对已见发射器分布的偏向问题，实现了对未见发射器的在线识别。

Abstract: Specific Emitter Identification (SEI) has been widely studied, aiming to
distinguish signals from different emitters given training samples from those
emitters. However, real-world scenarios often require identifying signals from
novel emitters previously unseen. Since these novel emitters only have a few or
no prior samples, existing models struggle to identify signals from novel
emitters online and tend to bias toward the distribution of seen emitters. To
address these challenges, we propose the Online Specific Emitter Identification
(OSEI) task, comprising both online \revise{few-shot and generalized zero-shot}
learning tasks. It requires constructing models using signal samples from seen
emitters and then identifying new samples from seen and novel emitters online
during inference. We propose a novel hash-based model, Collision-Alleviated
Signal Hash (CASH), providing a unified approach for addressing the OSEI task.
The CASH operates in two steps: in the seen emitters identifying step, a signal
encoder and a seen emitters identifier determine whether the signal sample is
from seen emitters, mitigating the model from biasing toward seen emitters
distribution. In the signal hash coding step, an online signal hasher assigns a
hash code to each signal sample, identifying its specific emitter. Experimental
results on real-world signal datasets (i.e., ADSB and ORACLE) demonstrate that
our method accurately identifies signals from both seen and novel emitters
online. This model outperforms existing methods by a minimum of 6.08\% and
8.55\% in accuracy for the few-shot and \revise{generalized zero-shot learning
}tasks, respectively. The code will be open-sourced at
\href{https://github.com/IntelliSensing/OSEI-CASH}{https://github.com/IntelliSensing/OSEI-CASH}.

</details>


### [32] [Asymptotic Expansion for Nonlinear Filtering in the Small System Noise Regime](https://arxiv.org/abs/2509.23920)
*Masahiro Kurisaki*

Main category: eess.SP

TL;DR: 提出一种基于系统噪声小参数的非线性滤波渐近展开方法，通过将条件期望展开为噪声水平的幂级数，每个系数通过求解常微分方程组计算，在计算效率和精度之间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法如高斯近似和粒子滤波在计算效率和精度之间的权衡问题，同时捕捉条件分布的复杂特征如多峰性。

Method: 基于系统噪声小参数的渐近展开方法，将条件期望展开为噪声水平的幂级数，每个系数通过求解常微分方程组计算，并引入Edgeworth型展开。

Result: 该方法能够以显著低于传统滤波算法的计算成本捕捉条件分布的复杂特征，如多峰性。

Conclusion: 提出的渐近展开方法在非线性滤波中实现了计算效率和精度的更好平衡，能够有效处理条件分布的复杂特征。

Abstract: We propose a new asymptotic expansion method for nonlinear filtering, based
on a small parameter in the system noise. The conditional expectation is
expanded as a power series in the noise level, with each coefficient computed
by solving a system of ordinary differential equations. This approach mitigates
the trade-off between computational efficiency and accuracy inherent in
existing methods such as Gaussian approximations and particle filters.
Moreover, by incorporating an Edgeworth-type expansion, our method captures
complex features of the conditional distribution, such as multimodality, with
significantly lower computational cost than conventional filtering algorithms.

</details>


### [33] [Wideband Integrated Sensing and Communications: Spectral Efficiency and Signaling Design](https://arxiv.org/abs/2509.24097)
*Henglin Pu,Zhu Han,Athina P. Petropulu,Husheng Li*

Main category: eess.SP

TL;DR: 该论文研究了6G网络中集成感知与通信(ISAC)的波形设计问题，提出了在宽带OFDM系统中通过功率谱密度(PSD)整形来优化感知性能，同时保持相位用于通信调制的方法。


<details>
  <summary>Details</summary>
Motivation: 6G网络中集成感知与通信的主要挑战在于如何在同一个波形中整合两种不同功能。宽带分析可以简化问题，并且毫米波或更高频段的使用使得宽带分析具有实际意义。

Method: 采用标准OFDM信号，通过控制功率谱密度(PSD)来优化感知性能，同时保持子载波相位用于通信调制。还揭示了PSD整形规则与OTFS波形之间的对偶关系，并提出了具有PSD平坦度约束的低复杂度水填充式分配器。

Result: 通过数值仿真和硬件实验验证了所提出的宽带ISAC方案的性能，表明PSD控制可以有效降低延迟-多普勒域中的积分旁瓣水平(ISL)。

Conclusion: 提出的宽带ISAC方案能够在频率选择性信道上平衡通信和感知性能，通过PSD整形实现了感知性能的优化，同时保持了通信能力。

Abstract: In integrated sensing and communications (ISAC), a distinguishing feature of
6G wireless networks, the main challenge lies in integrating the two distinct
functions of sensing and communication within the same waveform. In this paper,
the ISAC waveform synthesis is studied in the wideband regime, since a large
bandwidth can simplify the analysis and is justified by the employment of
millimeter wave or higher frequency band. Standard orthogonal frequency
division multiplexing (OFDM) signaling is assumed, and the wideband analysis of
sensing is a counterpart of the existing studies on wideband communications. It
is proposed that the phase over such OFDM subcarriers is for modulating
communication messages while the power spectral density (PSD) is shaped for the
sensing performance. Beyond OFDM, we further reveal a duality between the
proposed PSD-shaping rule and the orthogonal time frequency space (OTFS)
waveform. Flattening the OTFS delay-axis PSD produces the same integrated
sidelobe level (ISL) reduction effect in the delay-Doppler domain as PSD
control achieves for OFDM in the frequency domain. To balance communication and
sensing performance over frequency-selective channels, we propose a
low-complexity, water-filling-like allocator with an explicit PSD-flatness
(variance) constraint. The performance of the proposed wideband ISAC scheme is
demonstrated using both numerical simulations and hardware experiments.

</details>


### [34] [BladderFormer: A Streaming Transformer for Real-Time Urological State Monitoring](https://arxiv.org/abs/2509.24178)
*Chengwei Zhou,Steve Majerus,Gourav Datta*

Main category: eess.SP

TL;DR: 提出一种用于膀胱压力状态实时分类的单层流式Transformer模型，该模型基于小波变换的时间序列数据，具有高效在线推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有膀胱压力监测系统依赖手工特征和浅层分类器，难以适应复杂信号动态变化，需要更灵活高效的实时分类方法。

Method: 使用单层流式Transformer模型，结合时间多头自注意力机制和状态缓存，对小波变换后的原始时间序列数据进行实时分类。

Result: 在91名患者数据集（每人20000-80000个样本）上训练，模型表现出更高的准确性、能效和延迟效率。

Conclusion: 该方法在膀胱压力状态分类方面优于传统方法，并讨论了在低功耗边缘硬件上的部署可行性。

Abstract: Bladder pressure monitoring systems are increasingly vital in diagnosing and
managing urinary tract dysfunction. Existing solutions rely heavily on
hand-crafted features and shallow classifiers, limiting their adaptability to
complex signal dynamics. We propose a one-layer streaming transformer model for
real-time classification of bladder pressure states, operating on
wavelet-transformed representations of raw time-series data. Our model
incorporates temporal multi-head self-attention and state caching, enabling
efficient online inference with high adaptability. Trained on a dataset of 91
patients with 20,000-80,000 samples each, our method demonstrates improved
accuracy, higher energy- and latency-efficiency. Implementation considerations
for edge deployment on low-power hardware, such as edge graphical processing
units (GPU) and micro-controllers, are also discussed.

</details>


### [35] [Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning](https://arxiv.org/abs/2509.24222)
*Zhisheng Chen,Yingwei Zhang,Qizhen Lan,Tianyu Liu,Huacan Wang,Yi Ding,Ziyu Jia,Ronghao Chen,Kun Wang,Xinliang Zhou*

Main category: eess.SP

TL;DR: Uni-NTFM是一种基于神经科学原理设计的统一神经拓扑基础模型，专门用于处理脑电图信号，通过解耦架构、拓扑嵌入机制和专家混合Transformer解决了现有方法在时间-频率特征、电极空间拓扑和模型灵活性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本或图像架构的脑基础模型在处理脑电图信号时存在三个主要问题：混淆时域波形和频域节律特征、忽略电极空间拓扑结构、以及使用不灵活的密集网络处理功能不同的EEG模式。

Method: Uni-NTFM包含三个核心创新：1）解耦架构并行编码时间、频率和原始信号表示后进行跨域特征整合；2）拓扑嵌入机制统一不同国际标准的电极并生成脑区域的结构化输入序列；3）专家混合神经Transformer通过将信号模式路由到专门子网络来高效扩展模型容量。

Result: Uni-NTFM_large模型拥有创纪录的19亿参数，在超过28,000小时的多样化EEG数据上预训练，在九个不同的下游任务中显著优于现有的任务特定方法和基础模型，在线性探测和微调设置下均表现出学习大脑活动通用表示的卓越能力。

Conclusion: Uni-NTFM通过神经科学指导的设计成功解决了EEG基础模型的关键挑战，证明了其在学习大脑活动通用表示方面的优越性，为脑电图分析提供了强大的基础模型解决方案。

Abstract: Foundation models pretrained on various and unlabeled data have demonstrated
significant success in natural language and vision, but their application to
electroencephalography (EEG) remains challenged due to the signal's unique
properties. Existing brain foundation models that inherit architectures
designed for text or images lead to three limitations in pre-training: 1)
conflating time-domain waveform patterns with frequency-domain rhythmic
features in a single processing stream, 2) ignoring the critical spatial
topology of electrodes with different standards, and 3) reliance on the
inflexible, dense network to process functionally distinct EEG patterns. To
address these challenges, we introduce the Unified Neural Topological
Foundation Model (Uni-NTFM), which is designed based on neuroscience principles
to produce universal and interpretable representations. Uni-NTFM integrates
three core innovations: 1) a decoupled architecture parallelly encodes time,
frequency, and raw signal representations before performing cross-domain
feature integration; 2) a topological embedding mechanism to unify electrodes
from different international standards and generate structured input sequences
for brain regions; and 3) a Mixture-of-Experts neural Transformer that
efficiently scales model capacity by routing signal patterns to specialized
subnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B
parameters and was pretrained on over 28,000 hours of diverse EEG data via a
dual-domain masked reconstruction objective. Uni-NTFM significantly outperforms
existing task-specific methods and foundation models across nine distinct
downstream tasks under both linear probing and fine-tuning settings,
demonstrating a superior ability to learn universal representations of brain
activity.

</details>


### [36] [YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform](https://arxiv.org/abs/2509.03070)
*Po-Heng Chou,Wei-Lung Mao,Ru-Ping Lin*

Main category: eess.SP

TL;DR: 提出基于YOLO的轴承故障诊断框架，使用连续小波变换将振动信号转换为时频谱图，通过YOLOv9/v10/v11模型分类故障类型，在多个数据集上取得高精度和可视化故障定位能力。


<details>
  <summary>Details</summary>
Motivation: 传统故障诊断方法难以有效捕捉瞬态故障特征，且缺乏直观的故障定位可视化能力，需要开发更准确、可解释的智能诊断方法。

Method: 使用Morlet小波将一维振动信号转换为时频谱图，利用YOLO系列模型进行故障分类和定位，通过区域感知检测机制实现故障位置可视化。

Result: 在CWRU、PU和IMS三个基准数据集上，YOLOv11分别达到99.4%、97.8%和99.5%的mAP分数，显著优于基线MCNN-LSTM模型。

Conclusion: CWT-YOLO框架在轴承故障诊断中表现出高精度、强泛化性和直观的故障定位能力，为旋转机械状态监测提供了实用解决方案。

Abstract: This letter proposes a YOLO-based framework for spatial bearing fault
diagnosis using time-frequency spectrograms derived from continuous wavelet
transform (CWT). One-dimensional vibration signals are first transformed into
time-frequency spectrograms using Morlet wavelets to capture transient fault
signatures. These spectrograms are then processed by YOLOv9, v10, and v11
models to classify fault types. Evaluated on three benchmark datasets,
including Case Western Reserve University (CWRU), Paderborn University (PU),
and Intelligent Maintenance System (IMS), the proposed CWT-YOLO pipeline
achieves significantly higher accuracy and generalizability than the baseline
MCNN-LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%
(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism
enables direct visualization of fault locations in spectrograms, offering a
practical solution for condition monitoring in rotating machinery.

</details>


### [37] [DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift](https://arxiv.org/abs/2507.02824)
*Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang*

Main category: eess.SP

TL;DR: 本文研究了毫米波MIMO系统中使用可重构智能表面(RIS)增强传输性能的预编码设计，提出用深度神经网络(DNN)替代传统穷举搜索来降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 毫米波MIMO系统中直接通信路径被遮挡时，传统穷举搜索最优码字计算复杂度高、耗时严重，需要更高效的解决方案。

Method: 采用训练好的深度神经网络(DNN)进行码字选择，替代传统的穷举搜索和基于离散傅里叶变换向量的码本设计方法。

Result: 仿真结果表明，DNN在测试阶段即使终端用户与RIS之间距离发生变化，仍能保持次优的频谱效率性能。

Conclusion: DNN在RIS辅助系统中具有巨大潜力，能够有效降低计算复杂度同时保持良好的系统性能。

Abstract: In this paper, the precoding design is investigated for maximizing the
throughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO)
systems with obstructed direct communication paths. In particular, a
reconfigurable intelligent surface (RIS) is employed to enhance MIMO
transmissions, considering mmWave characteristics related to line-of-sight
(LoS) and multipath effects. The traditional exhaustive search (ES) for optimal
codewords in the continuous phase shift is computationally intensive and
time-consuming. To reduce computational complexity, permuted discrete Fourier
transform (DFT) vectors are used for finding codebook design, incorporating
amplitude responses for practical or ideal RIS systems. However, even if the
discrete phase shift is adopted in the ES, it results in significant
computation and is time-consuming. Instead, the trained deep neural network
(DNN) is developed to facilitate faster codeword selection. Simulation results
show that the DNN maintains sub-optimal spectral efficiency even as the
distance between the end-user and the RIS has variations in the testing phase.
These results highlight the potential of DNN in advancing RIS-aided systems.

</details>


### [38] [N78 Frequency Band Modular RIS Design and Implementation](https://arxiv.org/abs/2509.24355)
*Sefa Kayraklık,Recep Baş,Hasan Oğuzhan Çalışkan,Samed Şahinoğlu,Sercan Erdoğan,İlhami Ünal,İbrahim Hökelek,Kıvanç Nurdan,Ali Görçin*

Main category: eess.SP

TL;DR: 本文提出了一个工作在n78频段的模块化可重构智能表面(RIS)原型设计流程，包括仿真、原型开发和测试。原型由一个主控模块和最多16个从属模块组成，每个模块包含8×8反射单元和控制器板，通过PIN二极管控制180°相位差。测试显示在n78频段接收信号功率提升超过15dB。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)能够动态控制无线传播特性，是增强下一代无线网络信号覆盖和改善终端用户连接性的有前景技术。

Method: 采用模块化设计，每个RIS模块包含8×8反射单元阵列，使用PIN二极管控制每个单元的相位响应，形成ON和OFF状态间的180°相位差。原型包括一个主控模块和最多16个从属模块。

Result: 使用两个RIS模块、喇叭天线和矢量网络分析仪的测量实验表明，在n78频段内，对于给定的布局，接收信号功率的提升超过15dB。

Conclusion: 该模块化RIS原型设计成功验证了在n78频段显著增强信号接收功率的能力，为下一代无线网络中的RIS应用提供了可行的硬件实现方案。

Abstract: Reconfigurable intelligent surface (RIS), capable of dynamically controlling
wireless propagation characteristics using reflecting antenna elements, is a
promising technology for enhancing signal coverage and improving end-user
connectivity in next-generation wireless networks. This paper presents a
complete design flow of a modular RIS prototype operating at the n78 frequency
band, starting from the simulations to the prototype development and testing.
An RIS prototype includes one master and up to sixteen slave blocks, each of
which has an identical hardware structure with $8\times 8$ reflecting surface
elements and a controller board. The phase shift response of each unit element
is controlled with a PIN diode to form a $180^\circ$ phase difference between
the ON and OFF states. The measurement experiment using two RIS blocks, horn
antennas, and a vector network analyzer showed that the improvement of the
received signal power is more than $15$ dB across the n78 frequency band for a
given placement.

</details>


### [39] [Strong Basin of Attraction for Unmixing Kernels With the Variable Projection Method](https://arxiv.org/abs/2509.24428)
*Santos Michelena,Maxime Ferreira Da Costa,José Picheral*

Main category: eess.SP

TL;DR: 研究在已知尖峰位置条件下，从参数流形上不同点扩散函数卷积的混合尖峰信号中恢复信号的问题。提出了投影非线性最小二乘估计器，建立了强凸区域半径的下界，并在真实激光诱导击穿光谱数据上验证了方法的实用性。


<details>
  <summary>Details</summary>
Motivation: 解决在参数流形上不同点扩散函数卷积的混合尖峰信号恢复问题，特别是在已知尖峰位置的情况下，旨在开发无需手动校准的实用方法。

Method: 将PSF解混问题表述为投影非线性最小二乘估计器，建立了强凸区域半径的下界作为流形相干性和Lipschitz性质的函数，保证了优化程序的收敛性和稳定性。

Result: 数值实验显示了PSF类别在问题条件数中的快速衰减速度，并验证了理论发现。在真实激光诱导击穿光谱数据上的应用证明了方法的实际相关性。

Conclusion: 提出的估计器在存在噪声的情况下能够保证收敛和稳定性，成功应用于真实世界光谱数据，消除了手动校准的需求，具有实际应用价值。

Abstract: The problem of recovering a mixture of spike signals convolved with distinct
point spread functions (PSFs) lying on a parametric manifold, under the
assumption that the spike locations are known, is studied. The PSF unmixing
problem is formulated as a projected non-linear least squares estimator. A
lower bound on the radius of the region of strong convexity is established in
the presence of noise as a function of the manifold coherence and Lipschitz
properties, guaranteeing convergence and stability of the optimization program.
Numerical experiments highlight the speed of decay of the PSF class in the
problem's conditioning and confirm theoretical findings. Finally, the proposed
estimator is deployed on real-world spectroscopic data from laser-induced
breakdown spectroscopy (LIBS), removing the need for manual calibration and
validating the method's practical relevance.

</details>


### [40] [RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off](https://arxiv.org/abs/2509.24805)
*Andriy Enttsel,Alex Marchioni,Andrea Zanellini,Mauro Mangia,Gianluca Setti,Riccardo Rovatti*

Main category: eess.SP

TL;DR: 该论文扩展了信息论框架，同时处理压缩效率、失真度和压缩后正常与异常信号可区分性之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 监控系统产生的压缩数据在云端处理时，压缩可能导致信息丢失，从而影响异常检测器区分正常和异常模式的能力。

Method: 利用高斯假设，通过Pareto曲面分析来管理压缩效率、失真度和信号可区分性之间的权衡，优于仅依赖最优率失真压缩的方法。

Result: 通过绘制曲线展示了在Pareto曲面上移动如何更好地管理这三个特征之间的权衡关系。

Conclusion: 提出的框架能够同时优化压缩效率、失真度和信号可区分性，比单纯依赖最优率失真压缩的方法更有效。

Abstract: Extensive monitoring systems generate data that is usually compressed for
network transmission. This compressed data might then be processed in the cloud
for tasks such as anomaly detection. However, compression can potentially
impair the detector's ability to distinguish between regular and irregular
patterns due to information loss. Here we extend the information-theoretic
framework introduced in [1] to simultaneously address the trade-off between the
three features on which the effectiveness of the system depends: the
effectiveness of compression, the amount of distortion it introduces, and the
distinguishability between compressed normal signals and compressed anomalous
signals. We leverage a Gaussian assumption to draw curves showing how moving on
a Pareto surface helps administer such a trade-off better than simply relying
on optimal rate-distortion compression and hoping that compressed signals can
be distinguished from each other.

</details>


### [41] [Low-Complexity Wireless Multi-Port Sensing by Multiplexed De-Embedding of an Over-the-Air Fixture](https://arxiv.org/abs/2509.24537)
*Philipp del Hougne*

Main category: eess.SP

TL;DR: 本文提出了一种无线多端口传感方法，通过使用可编程夹具提供测量多样性，解决了当单个夹具配置无法解嵌入时的问题。该方法通过多个夹具实现的联合解嵌入，实现了对不可直接访问天线的多端口设备散射矩阵的远程估计。


<details>
  <summary>Details</summary>
Motivation: 解决无线多端口传感中当可访问天线的独立测量数量不足时，无法解嵌入OTA夹具特性的问题。通过增加测量多样性来克服硬件限制，实现低复杂度的无线多端口传感。

Method: 使用可调负载网络连接OTA夹具，形成可编程夹具。当单个夹具配置无法识别DUT特性时，通过多个夹具实现提供测量多样性。采用"多路解嵌入"方法对夹具实现集合进行联合解嵌入。

Result: 实验成功远程估计了一个互易非酉4端口DUT的散射矩阵（10个复值未知数），仅基于两个可访问天线之间单一传输系数的测量，在30个不同夹具实现下完成。

Conclusion: 多路解嵌入方法为在RFID和无线生物电子学等领域实现低硬件复杂度的无线多端口传感铺平了道路，系统研究了可访问天线独立测量数量与夹具实现数量之间的权衡关系。

Abstract: Wireless multi-port sensing remotely retrieves the scattering matrix of a
multi-port device under test (DUT) connected to a set of
not-directly-accessible (NDA) antennas that couple over-the-air (OTA) to a set
of accessible antennas. If (i) the OTA fixture characteristics are known, and
(ii) the number of independent measurements at the accessible antennas is
sufficient, the OTA fixture can be de-embedded to recover the DUT
characteristics. In recent prior work, we solved (i) by connecting the NDA
antennas to a specific known tunable load network (TLN). Here, we tackle (ii)
by additionally using the TLN to provide measurement diversity. The connection
between OTA fixture and TLN constitutes a programmable fixture (PF). When the
DUT characteristics cannot be identified based on a single PF realization, we
add measurement diversity with multiple PF realizations. The underlying
"multiplexed de-embedding" achieves the joint de-embedding of an ensemble of PF
realizations when a single PF realization cannot be de-embedded. We
experimentally demonstrate our concept by remotely estimating the scattering
matrix of a reciprocal, non-unitary 4-port DUT (10 complex-valued unknowns) via
a rich-scattering OTA fixture purely based on measurements of a single
transmission coefficient between two accessible antennas across 30 different PF
realizations. We systematically study the trade-off between the number of
independent measurements at the accessible antennas and the number of PF
realizations. Multiplexed de-embedding of the OTA fixture paves the path to
implementing wireless multi-port sensing with low hardware complexity in areas
like RFID and wireless bioelectronics.

</details>


### [42] [BARProp: Fast-Converging and Memory-Efficient RSS-Based Localization Algorithm for IoT](https://arxiv.org/abs/2509.24588)
*Luis F. Abanto-Leon,Muhammad Salman,Lismer Andres Caceres-Najarro*

Main category: eess.SP

TL;DR: 提出BARProp算法，一种用于RSS室内定位的快速内存高效方法，通过动态调整衰减因子来加速收敛并增强稳定性，内存使用减少85%，收敛速度提升4倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有RSS定位方法依赖复杂算法或专用硬件，不适合低成本接入点。需要开发既快速又内存高效的定位算法。

Method: BARProp算法通过监控存储在缓冲区中最近梯度的能量变化来动态调整衰减因子，实现加速收敛和增强稳定性。

Result: 在真实数据评估中，BARProp不仅达到更高的定位精度，而且收敛速度比现有基准方法至少快4倍，内存使用减少85%。

Conclusion: BARProp为RSS室内定位提供了一种高效实用的解决方案，特别适合资源受限的低成本设备。

Abstract: Leveraging received signal strength (RSS) measurements for indoor
localization is highly attractive due to their inherent availability in
ubiquitous wireless protocols. However, prevailing RSS-based methods often
depend on complex computational algorithms or specialized hardware, rendering
them impractical for low-cost access points. To address these challenges, this
paper introduces buffer-aided RMSProp (BARProp), a fast and memory-efficient
localization algorithm specifically designed for RSS-based tasks. The key
innovation of BARProp lies in a novel mechanism that dynamically adapts the
decay factor by monitoring the energy variations of recent gradients stored in
a buffer, thereby achieving both accelerated convergence and enhanced
stability. Furthermore, BARProp requires less than 15% of the memory used by
state-of-the-art methods. Extensive evaluations with real-world data
demonstrate that BARProp not only achieves higher localization accuracy but
also delivers at least a fourfold improvement in convergence speed compared to
existing benchmarks.

</details>


### [43] [Impedance Modeling of Magnetometers: A Path Toward Low-Noise Readout Circuits](https://arxiv.org/abs/2509.24683)
*Johan Arbustini,Eric Elzenheimer,Elizaveta Spetzler,Pablo Mendoza,Daniel Fernández,Jordi Madrenas,Jeffrey McCord,Michael Höft,Robert Rieger,Andreas Bahr*

Main category: eess.SP

TL;DR: 提出了一种新型二端口阻抗模型来估计逆磁电传感器行为，通过MATLAB和LTSpice仿真验证模型，优化系统模拟电路部分的噪声性能。


<details>
  <summary>Details</summary>
Motivation: 优化开环和闭环实现的传感器读出方案和集成电路设计需要精确的建模和仿真策略，需要为逆磁电传感器开发精确的行为模型。

Method: 使用阻抗分析仪测量常见S参数并转换为Z参数，创建系统级仿真的传递函数，通过MATLAB和LTSpice进行噪声分析验证模型。

Result: 仿真结果与实验测量结果一致，成功推导出磁力计的噪声考虑和传递函数，为混合信号电路设计提供关键信息。

Conclusion: 该方法能够设计低噪声电子设备并扩展到其他传感器接口电子设备，拓宽了其在高性能磁传感中的应用范围。

Abstract: Optimizing sensor readout schemes and integrated circuit designs for both
open-loop and closed-loop implementations requires precise modeling and
simulation strategies. This study introduces a novel two-port impedance model
to estimate the behavior of a converse Magnetoelectric (cME) sensor. This model
provides a possible framework for calculating transfer functions and simulating
magnetometer behavior in both continuous- and discrete-time simulation
environments, and it is also possibly transferable to other magnetometer types.
Common S-parameters were measured experimentally using an impedance analyzer
and converted to Z-parameters to create a transfer function for system-level
simulations. The model was validated through an analysis of output-related
noise using MATLAB and LTSpice simulations to optimize the noise of the analog
circuit parts of the system. The simulation results were compared with
experimental measurements using a Zurich Instruments lock-in amplifier and the
custom-designed low-noise printed circuit board (PCB) under model
considerations. The proposed methodology derives noise considerations and the
transfer function of a magnetometer. These are essential for readout schemes
for mixed-signal circuit design. This allows low-noise electronics to be
designed and extended to other sensor interface electronics, broadening their
applicability in high-performance magnetic sensing.

</details>


### [44] [Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2509.24819)
*Kunyu Wu,Qiushi Zhao,Zihan Feng,Yunxi Mu,Hao Qin,Xinyu Zhang,Xingqi Zhang*

Main category: eess.SP

TL;DR: 提出了一种结合抛物波方程信道建模、条件生成对抗网络数据增强和决斗深度Q网络的深度强化学习框架，用于优化隧道中接入点的部署，提高无线覆盖质量并降低部署成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于经验模型的优化算法需要大量测量且解质量不佳，而机器学习方法在复杂隧道环境中表现不佳，因此需要一种更高效、准确的接入点部署优化方法。

Method: 使用抛物波方程生成部分接入点位置的高保真路径损耗分布，通过条件生成对抗网络扩展到所有候选位置，然后采用决斗深度Q网络进行接入点位置优化。

Result: 相比传统Hooke Jeeves优化器和传统DQN，该方法能提供更高的平均接收功率、更好的最差情况覆盖和更高的计算效率。

Conclusion: 该工作整合了高保真电磁仿真、生成建模和AI驱动优化，为复杂隧道环境中的下一代CBTC系统提供了可扩展且数据高效的解决方案。

Abstract: Urban railway systems increasingly rely on communication based train control
(CBTC) systems, where optimal deployment of access points (APs) in tunnels is
critical for robust wireless coverage. Traditional methods, such as empirical
model-based optimization algorithms, are hindered by excessive measurement
requirements and suboptimal solutions, while machine learning (ML) approaches
often struggle with complex tunnel environments. This paper proposes a deep
reinforcement learning (DRL) driven framework that integrates parabolic wave
equation (PWE) channel modeling, conditional generative adversarial network
(cGAN) based data augmentation, and a dueling deep Q network (Dueling DQN) for
AP placement optimization. The PWE method generates high-fidelity path loss
distributions for a subset of AP positions, which are then expanded by the cGAN
to create high resolution path loss maps for all candidate positions,
significantly reducing simulation costs while maintaining physical accuracy. In
the DRL framework, the state space captures AP positions and coverage, the
action space defines AP adjustments, and the reward function encourages signal
improvement while penalizing deployment costs. The dueling DQN enhances
convergence speed and exploration exploitation balance, increasing the
likelihood of reaching optimal configurations. Comparative experiments show
that the proposed method outperforms a conventional Hooke Jeeves optimizer and
traditional DQN, delivering AP configurations with higher average received
power, better worst-case coverage, and improved computational efficiency. This
work integrates high-fidelity electromagnetic simulation, generative modeling,
and AI-driven optimization, offering a scalable and data-efficient solution for
next-generation CBTC systems in complex tunnel environments.

</details>


### [45] [Low-Complexity Receiver Design for Multicarrier CAPA-based Systems in Doubly-Dispersive Channels](https://arxiv.org/abs/2509.24941)
*Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种用于多载波连续孔径阵列系统的低复杂度接收机设计，基于高斯置信传播框架，在双弥散信道下显著提升性能并保持低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 针对多载波连续孔径阵列系统在双弥散信道下的检测问题，需要设计低复杂度且高性能的接收机方案。

Method: 采用基于高斯置信传播的框架，仅使用元素级标量运算进行符号检测，适用于OFDM、OTFS和AFDM等多种波形。

Result: 仿真结果显示，与传统离散天线阵列系统相比，在未编码误码率方面获得显著性能提升，同时保持极低计算复杂度。

Conclusion: 所提出的GaBP接收机设计为多载波连续孔径阵列系统提供了一种高效的低复杂度解决方案，在双弥散信道下具有优越性能。

Abstract: We propose a novel low-complexity receiver design for multicarrier continuous
aperture array (CAPA) systems operating over doubly-dispersive (DD) channels.
The receiver leverages a Gaussian Belief Propagation (GaBP)-based framework
that hinges only on element-wise scalar operations for the detection of the
transmitted symbols. Simulation results for the orthogonal frequency division
multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine
frequency division multiplexing (AFDM) waveforms demonstrate significant
performance improvements in terms of uncoded bit error rate (BER) compared to
conventional discrete antenna array systems, while maintaining very low
computational complexity.

</details>


### [46] [Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks](https://arxiv.org/abs/2509.25095)
*M A Al-Masud,Juan Miguel Lopez Alcaraz,Nils Strodthoff*

Main category: eess.SP

TL;DR: 对8个ECG基础模型在26个临床任务上进行基准测试，发现在成人ECG解读领域表现良好，但在其他领域存在明显差距。ECG-CPC模型在多个类别中表现突出，且计算资源消耗极低。


<details>
  <summary>Details</summary>
Motivation: ECG机器学习应用仍处于碎片化状态，基础模型的跨任务泛化能力尚未得到充分理解，需要系统性评估其在多样化ECG任务中的表现。

Method: 使用12个公共数据集（包含1,650个回归和分类目标）对8个ECG基础模型进行基准测试，在微调和冻结设置下评估，并进行数据集规模的扩展分析。

Result: 在成人ECG解读领域，三个基础模型持续优于强监督基线；ECG-CPC在其他类别中表现突出，而大多数基础模型未能超越监督学习。模型在不同数据集规模下显示出不同的扩展行为。

Conclusion: 基础模型在成人ECG分析中显示潜力，但在心脏结构、结果预测和患者特征化方面存在显著差距。ECG-CPC的优异表现表明ECG基础模型仍有巨大发展空间。

Abstract: The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yet
machine learning for ECG interpretation remains fragmented, often limited to
narrow tasks or datasets. Foundation models promise broader adaptability, but
their generalization across diverse ECG tasks is not well understood. We
benchmarked eight ECG foundation models on 26 clinically relevant tasks using
12 public datasets comprising 1,650 regression and classification targets.
Models were evaluated under fine-tuning and frozen settings, with scaling
analyses across dataset sizes. Results show heterogeneous performance across
domains: in the most widely studied domain, adult ECG interpretation, three
foundation models consistently outperformed strong supervised baselines. In
contrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,
dominated other categories where most foundation models failed to surpass
supervised learning. Foundation models also displayed distinct scaling
behaviors with dataset size, which are critical for small-scale clinical
applications. Overall, while foundation models show promise for adult ECG
analysis, substantial gaps remain in cardiac structure, outcome prediction, and
patient characterization. Notably, ECG-CPC's strong performance despite being
orders of magnitude smaller and consuming minimal computational resources
highlights untapped opportunities for advancing ECG foundation models.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [47] [VIRTUS-FPP: Virtual Sensor Modeling for Fringe Projection Profilometry in NVIDIA Isaac Sim](https://arxiv.org/abs/2509.22685)
*Adam Haroon,Anush Lakshman,Badrinath Balasubramaniam,Beiwen Li*

Main category: eess.IV

TL;DR: 提出了VIRTUS-FPP，首个基于物理的虚拟传感器建模框架，用于条纹投影轮廓术(FPP)，在NVIDIA Isaac Sim中构建，能够实现从标定到重建的端到端建模。


<details>
  <summary>Details</summary>
Motivation: 传统FPP技术面临复杂标定要求、系统体积庞大和对环境条件敏感等限制，需要一种更灵活的虚拟建模方法。

Method: 利用NVIDIA Isaac Sim的物理渲染和可编程感知能力，构建基于物理的虚拟传感器模型，实现从标定到重建的完整数学保真度建模。

Result: 通过虚拟标定和与真实几何的定量比较验证了重建精度，能够准确建模FPP关键光学现象，结果与真实系统相当。

Conclusion: 该框架显著加速了真实世界FPP系统的开发，在物理实施前实现快速虚拟原型设计，提供前所未有的系统配置、传感器原型设计和环境控制灵活性。

Abstract: Fringe projection profilometry (FPP) has been established as a high-accuracy
3D reconstruction method capable of achieving sub-pixel accuracy. However, this
technique faces significant constraints due to complex calibration
requirements, bulky system footprint, and sensitivity to environmental
conditions. To address these limitations, we present VIRTUS-FPP, the first
comprehensive physics-based virtual sensor modeling framework for FPP built in
NVIDIA Isaac Sim. By leveraging the physics-based rendering and programmable
sensing capabilities of simulation, our framework enables end-to-end modeling
from calibration to reconstruction with full mathematical fidelity to the
underlying principles of structured light. We conduct comprehensive virtual
calibration and validate our system's reconstruction accuracy through
quantitative comparison against ground truth geometry. Additionally, we
demonstrate the ability to model the virtual system as a digital twin by
replicating a physical FPP system in simulation and validating correspondence
between virtual and real-world measurements. Experimental results demonstrate
that VIRTUS-FPP accurately models optical phenomena critical to FPP and
achieves results comparable to real-world systems while offering unprecedented
flexibility for system configuration, sensor prototyping, and environmental
control. This framework significantly accelerates the development of real-world
FPP systems by enabling rapid virtual prototyping before physical
implementation.

</details>


### [48] [Explainable Deep Learning for Cataract Detection in Retinal Images: A Dual-Eye and Knowledge Distillation Approach](https://arxiv.org/abs/2509.22696)
*MohammadReza Abbaszadeh Bavil Soflaei,Karim SamadZamini*

Main category: eess.IV

TL;DR: 开发了一个用于白内障分类的深度学习流程，使用Swin-Base Transformer达到98.58%准确率，并通过知识蒸馏获得轻量级模型，在保持高精度的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 白内障是全球视力障碍的主要原因，早期检测对于及时干预至关重要，特别是在资源有限的环境中。

Method: 使用Ocular Disease Recognition数据集的5000名患者眼底照片，评估了CNN、transformer、轻量级架构和知识蒸馏模型，并提出了双眼Siamese变体。

Result: Swin-Base Transformer达到98.58%准确率和0.9836 F1分数；蒸馏的MobileNetV3达到98.42%准确率；双眼Siamese模型达到98.21%准确率。

Conclusion: 即使使用轻量级模型也能实现准确、可解释的白内障检测，支持在资源有限环境中的临床集成。

Abstract: Cataract remains a leading cause of visual impairment worldwide, and early
detection from retinal imaging is critical for timely intervention. We present
a deep learning pipeline for cataract classification using the Ocular Disease
Recognition dataset, containing left and right fundus photographs from 5000
patients. We evaluated CNNs, transformers, lightweight architectures, and
knowledge-distilled models. The top-performing model, Swin-Base Transformer,
achieved 98.58% accuracy and an F1-score of 0.9836. A distilled MobileNetV3,
trained with Swin-Base knowledge, reached 98.42% accuracy and a 0.9787 F1-score
with greatly reduced computational cost. The proposed dual-eye Siamese variant
of the distilled MobileNet, integrating information from both eyes, achieved an
accuracy of 98.21%. Explainability analysis using Grad-CAM demonstrated that
the CNNs concentrated on medically significant features, such as lens opacity
and central blur. These results show that accurate, interpretable cataract
detection is achievable even with lightweight models, supporting potential
clinical integration in resource-limited settings

</details>


### [49] [Achieving Fair Skin Lesion Detection through Skin Tone Normalization and Channel Pruning](https://arxiv.org/abs/2509.22712)
*Zihan Wei,Tapabrata Chakraborti*

Main category: eess.IV

TL;DR: 提出一种基于个体类型角度的肤色归一化和数据增强方法，结合元学习联合通道剪枝框架，在ISIC2019数据集上同时提升模型在多个敏感属性上的公平性，且不显著降低准确率。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习皮肤病变图像分类模型在非平衡数据集上训练时会对种族、年龄、性别等受保护属性产生偏见。现有偏见缓解方法要么以准确率下降为代价实现公平性，要么只能改善单个属性的公平性，且大多通过数据预处理或后处理而非集成到模型学习本身。

Method: 使用ITA损失进行肤色归一化和数据增强，结合可适应的元学习联合通道剪枝框架。肤色归一化使用ITA估计肤色类型并自动调整到目标色调以平衡数据集。联合通道剪枝框架采用两个嵌套优化循环：内循环通过加权软最近邻损失找到并剪枝局部关键通道，外循环通过元集上的组间方差损失更新每个属性的权重。

Result: 在ISIC2019数据集上的实验验证了该方法能同时提升模型在多个敏感属性上的公平性，且不显著降低准确率。

Conclusion: 该方法有效解决了现有偏见缓解方法的局限性，虽然剪枝机制在训练阶段增加了计算成本，但训练通常是离线进行的。

Abstract: Recent works have shown that deep learning based skin lesion image
classification models trained on unbalanced dataset can exhibit bias toward
protected demographic attributes such as race, age,and gender. Current bias
mitigation methods usually either achieve high level of fairness with the
degradation of accuracy, or only improve the model fairness on a single
attribute. Additionally usually most bias mitigation strategies are either pre
hoc through data processing or post hoc through fairness evaluation, instead of
being integrated into the model learning itself. To solve these existing
drawbacks, we propose a new Individual Typology Angle (ITA) Loss-based skin
tone normalization and data augmentation method that directly feeds into an
adaptable meta learning-based joint channel pruning framework. In skin tone
normalization, ITA is used to estimate skin tone type and adjust automatically
to target tones for dataset balancing. In the joint channel pruning framework,
two nested optimization loops are used to find critical channels.The inner
optimization loop finds and prunes the local critical channels by weighted soft
nearest neighbor loss, and the outer optimization loop updates the weight of
each attribute using group wise variance loss on meta-set. Experiments
conducted in the ISIC2019 dataset validate the effectiveness of our method in
simultaneously improving the fairness of the model on multiple sensitive
attributes without significant degradation of accuracy. Finally, although the
pruning mechanism adds some computational cost during training phase, usually
training is done off line. More importantly,

</details>


### [50] [Consistency Models as Plug-and-Play Priors for Inverse Problems](https://arxiv.org/abs/2509.22736)
*Merve Gülle,Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 提出了PnP-CM方法，将一致性模型重新解释为先验的邻近算子，集成到plug-and-play框架中，通过PnP-ADMM和共轭梯度方法实现快速收敛，在仅需2-4次函数评估的情况下解决各种逆问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于一致性模型的逆问题求解器要么需要额外的任务特定训练，要么使用收敛缓慢的数据保真度操作，不适合大规模问题。

Method: 将一致性模型重新解释为先验的邻近算子，集成到PnP-ADMM框架中，利用共轭梯度方法实现快速收敛，并通过噪声注入和动量进一步加速。

Result: 在修复、超分辨率、高斯去模糊和MRI重建等逆问题上，PnP-CM在仅需4次函数评估时就能获得高质量重建，甚至在2步内产生有意义的结果，优于可比较的基于一致性模型的方法。

Conclusion: PnP-CM是第一个为MRI数据集训练的一致性模型，在真实世界逆问题中表现出高效性，同时保持了基线PnP-ADMM的收敛特性。

Abstract: Diffusion models have found extensive use in solving numerous inverse
problems. Such diffusion inverse problem solvers aim to sample from the
posterior distribution of data given the measurements, using a combination of
the unconditional score function and an approximation of the posterior related
to the forward process. Recently, consistency models (CMs) have been proposed
to directly predict the final output from any point on the diffusion ODE
trajectory, enabling high-quality sampling in just a few NFEs. CMs have also
been utilized for inverse problems, but existing CM-based solvers either
require additional task-specific training or utilize data fidelity operations
with slow convergence, not amenable to large-scale problems. In this work, we
reinterpret CMs as proximal operators of a prior, enabling their integration
into plug-and-play (PnP) frameworks. We propose a solver based on PnP-ADMM,
which enables us to leverage the fast convergence of conjugate gradient method.
We further accelerate this with noise injection and momentum, dubbed PnP-CM,
and show it maintains the convergence properties of the baseline PnP-ADMM. We
evaluate our approach on a variety of inverse problems, including inpainting,
super-resolution, Gaussian deblurring, and magnetic resonance imaging (MRI)
reconstruction. To the best of our knowledge, this is the first CM trained for
MRI datasets. Our results show that PnP-CM achieves high-quality
reconstructions in as few as 4 NFEs, and can produce meaningful results in 2
steps, highlighting its effectiveness in real-world inverse problems while
outperforming comparable CM-based approaches.

</details>


### [51] [Untangling Vascular Trees for Surgery and Interventional Radiology](https://arxiv.org/abs/2509.23165)
*Guillaume Houry,Tom Boeken,Stéphanie Allassonnière,Jean Feydy*

Main category: eess.IV

TL;DR: 提出了一种用于血管树的平面表示方法，可快速生成保留拓扑、长度和曲率特性的二维血管图，辅助血管内介入手术的导管导航。


<details>
  <summary>Details</summary>
Motivation: 微创血管内介入手术的普及需要开发能够可视化复杂血管网络的方法，以简化术前设备选择和术中导航，降低手术失败风险。

Method: 基于三维数字血管造影图像，采用优化的形态学滤波器和新的递归嵌入算法，在几秒内生成保留血管网络全局方向的二维平面图。

Result: 方法在脑部、盆腔和膝关节动脉网络的术中图像上得到验证，能够准确显示血管分支模式和迂曲度。

Conclusion: 该方法不仅有助于临床手术规划和导航，还为大规模人群血管分支模式研究提供了可能，代码已开源发布。

Abstract: The diffusion of minimally invasive, endovascular interventions motivates the
development of visualization methods for complex vascular networks. We propose
a planar representation of blood vessel trees which preserves the properties
that are most relevant to catheter navigation: topology, length and curvature.
Taking as input a three-dimensional digital angiography, our algorithm produces
a faithful two-dimensional map of the patient's vessels within a few seconds.
To this end, we propose optimized implementations of standard morphological
filters and a new recursive embedding algorithm that preserves the global
orientation of the vascular network. We showcase our method on peroperative
images of the brain, pelvic and knee artery networks. On the clinical side, our
method simplifies the choice of devices prior to and during the intervention.
This lowers the risk of failure during navigation or device deployment and may
help to reduce the gap between expert and common intervention centers. From a
research perspective, our method simulates the cadaveric display of artery
trees from anatomical dissections. This opens the door to large population
studies on the branching patterns and tortuosity of fine human blood vessels.
Our code is released under the permissive MIT license as part of the
scikit-shapes Python library (https://scikit-shapes.github.io ).

</details>


### [52] [Enhanced Quality Aware-Scalable Underwater Image Compression](https://arxiv.org/abs/2509.23200)
*Linwei Zhu,Junhao Zhu,Xu Zhang,Huan Zhang,Ye Li,Runmin Cong,Sam Kwong*

Main category: eess.IV

TL;DR: 提出了一种增强质量感知的可扩展水下图像压缩框架，通过基础层和增强层同时实现图像压缩和增强，在压缩比特节省的同时提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 水下成像在海洋探索和生态监测中至关重要，但面临传输带宽有限和水下环境严重失真的挑战，需要同时实现图像压缩和增强。

Method: 框架包含基础层和增强层：基础层使用可控数量的非零稀疏系数表示图像以节省编码比特，并利用共享稀疏系数推导增强字典；增强层设计包含粗糙滤波和细节精炼分支的双分支滤波器，生成伪增强版本以去除残差冗余。

Result: 在五个大规模水下图像数据集上的实验结果表明，该方法在UIQM指标上优于现有最先进方法。

Conclusion: 提出的可扩展水下图像压缩框架能够有效同时实现图像压缩和增强，在水下图像质量评估指标上表现优异。

Abstract: Underwater imaging plays a pivotal role in marine exploration and ecological
monitoring. However, it faces significant challenges of limited transmission
bandwidth and severe distortion in the aquatic environment. In this work, to
achieve the target of both underwater image compression and enhancement
simultaneously, an enhanced quality-aware scalable underwater image compression
framework is presented, which comprises a Base Layer (BL) and an Enhancement
Layer (EL). In the BL, the underwater image is represented by controllable
number of non-zero sparse coefficients for coding bits saving. Furthermore, the
underwater image enhancement dictionary is derived with shared sparse
coefficients to make reconstruction close to the enhanced version. In the EL, a
dual-branch filter comprising rough filtering and detail refinement branches is
designed to produce a pseudo-enhanced version for residual redundancy removal
and to improve the quality of final reconstruction. Extensive experimental
results demonstrate that the proposed scheme outperforms the state-of-the-art
works under five large-scale underwater image datasets in terms of Underwater
Image Quality Measure (UIQM).

</details>


### [53] [On the Impact of LiDAR Point Cloud Compression on Remote Semantic Segmentation](https://arxiv.org/abs/2509.23341)
*Tiago de S. Fernandes,Ricardo L. de Queiroz*

Main category: eess.IV

TL;DR: 研究分析了点云压缩对自动驾驶车辆远程语义分割性能的影响，评估了两种MPEG压缩算法(GPCC和L3C2)和两种分割算法(2DPASS和PVKD)在Semantic KITTI数据集上的表现，确定了保持高质量分割所需的带宽要求。


<details>
  <summary>Details</summary>
Motivation: 在智慧城市框架下，理解传输压缩对远程云分割（而非本地处理）的影响，评估点云压缩对语义分割性能的影响并估算必要的带宽需求。

Method: 开发了新的失真度量标准来评估影响，测试了两种MPEG压缩算法(GPCC和L3C2)和两种领先的语义分割算法(2DPASS和PVKD)在Semantic KITTI数据集上的表现。

Result: 结果表明，高质量分割需要约0.6 MB/s的通信吞吐量（G-PCC）和2.8 MB/s（L3C2）。

Conclusion: 这些结果对于规划自动驾驶导航的基础设施资源具有重要意义。

Abstract: Autonomous vehicles rely on LiDAR sensors to generate 3D point clouds for
accurate segmentation and object detection. In a context of a smart city
framework, we would like to understand the effect that transmission
(compression) can have on remote (cloud) segmentation, instead of local
processing. In this short paper, we try to understand the impact of point cloud
compression on semantic segmentation performance and to estimate the necessary
bandwidth requirements. We developed a new (suitable) distortion metric to
evaluate such an impact. Two of MPEG's compression algorithms (GPCC and L3C2)
and two leading semantic segmentation algorithms (2DPASS and PVKD) were tested
over the Semantic KITTI dataset. Results indicate that high segmentation
quality requires communication throughput of approximately 0.6 MB/s for G-PCC
and 2.8 MB/s for L3C2. These results are important in order to plan
infrastructure resources for autonomous navigation.

</details>


### [54] [S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network](https://arxiv.org/abs/2509.23442)
*Md. Saiful Bari Siddiqui,Mohammed Imamul Hassan Bhuiyan*

Main category: eess.IV

TL;DR: 提出了S$^3$F-Net双分支网络，同时学习空间和频域特征，在四个医学影像数据集上显著优于仅使用空间特征的基线模型，准确率提升最高达5.13%。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络主要关注单一空间域特征，无法有效捕捉全局模式和频域特征，限制了医学图像分析的性能。

Method: 采用双分支框架：深度空间CNN分支和浅层频域编码器SpectraNet分支。SpectraNet包含SpectralFilter层，利用卷积定理在傅里叶频谱上应用可学习滤波器，实现全局感受野。

Result: 在BRISC2025数据集上达到98.76%的SOTA竞争性准确率，在胸部X光肺炎数据集上达到93.11%准确率，超越了许多更深层的模型。

Conclusion: 双域方法是一种强大且可泛化的医学图像分析范式，能够根据输入病理动态调整对两个分支的依赖。

Abstract: Convolutional Neural Networks have become a cornerstone of medical image
analysis due to their proficiency in learning hierarchical spatial features.
However, this focus on a single domain is inefficient at capturing global,
holistic patterns and fails to explicitly model an image's frequency-domain
characteristics. To address these challenges, we propose the Spatial-Spectral
Summarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns
from both spatial and spectral representations simultaneously. The S$^3$F-Net
performs a fusion of a deep spatial CNN with our proposed shallow spectral
encoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,
which leverages the Convolution Theorem by applying a bank of learnable filters
directly to an image's full Fourier spectrum via a computation-efficient
element-wise multiplication. This allows the SpectralFilter layer to attain a
global receptive field instantaneously, with its output being distilled by a
lightweight summarizer network. We evaluate S$^3$F-Net across four medical
imaging datasets spanning different modalities to validate its efficacy and
generalizability. Our framework consistently and significantly outperforms its
strong spatial-only baseline in all cases, with accuracy improvements of up to
5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive
accuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs
better on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%
accuracy, surpassing many top-performing, much deeper models. Our
explainability analysis also reveals that the S$^3$F-Net learns to dynamically
adjust its reliance on each branch based on the input pathology. These results
verify that our dual-domain approach is a powerful and generalizable paradigm
for medical image analysis.

</details>


### [55] [Foundation Model-Based Adaptive Semantic Image Transmission for Dynamic Wireless Environments](https://arxiv.org/abs/2509.23590)
*Fangyu Liu,Peiwen Jiang,Wenjin Wang,Chao-Kai Wen,Shi Jin,Jun Zhang*

Main category: eess.IV

TL;DR: 提出基于基础模型的自适应语义图像传输系统，通过语义分割和压缩表示实现任务感知的优先级分配，结合场景自适应信道估计和扩散模型重建，在动态无线环境中实现鲁棒的语义传输。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要局限：(i) 忽视语义组件对特定下游任务的重要性差异，(ii) 未能充分利用无线领域知识，导致在动态信道条件下鲁棒性有限。

Method: 系统将图像分解为语义分割图和压缩表示；采用任务自适应预编码机制根据语义重要性分配无线资源；构建信道估计知识图(CEKM)，使用条件扩散模型整合用户位置、速度和稀疏信道样本来训练场景特定的轻量级估计器；接收端使用条件扩散模型从接收的语义特征重建高质量图像。

Result: 在BDD100K数据集和QuaDRiGa生成的多场景信道上的仿真结果表明，该方法在感知质量(SSIM、LPIPS、FID)、任务特定精度(IoU)和传输效率方面优于现有方法。

Conclusion: 通过集成任务感知语义分解、场景自适应信道估计和基于扩散的重建，在动态无线环境中实现了有效的鲁棒语义传输。

Abstract: Foundation model-based semantic transmission has recently shown great
potential in wireless image communication. However, existing methods exhibit
two major limitations: (i) they overlook the varying importance of semantic
components for specific downstream tasks, and (ii) they insufficiently exploit
wireless domain knowledge, resulting in limited robustness under dynamic
channel conditions. To overcome these challenges, this paper proposes a
foundation model-based adaptive semantic image transmission system for dynamic
wireless environments, such as autonomous driving. The proposed system
decomposes each image into a semantic segmentation map and a compressed
representation, enabling task-aware prioritization of critical objects and
fine-grained textures. A task-adaptive precoding mechanism then allocates radio
resources according to the semantic importance of extracted features. To ensure
accurate channel information for precoding, a channel estimation knowledge map
(CEKM) is constructed using a conditional diffusion model that integrates user
position, velocity, and sparse channel samples to train scenario-specific
lightweight estimators. At the receiver, a conditional diffusion model
reconstructs high-quality images from the received semantic features, ensuring
robustness against channel impairments and partial data loss. Simulation
results on the BDD100K dataset with multi-scenario channels generated by
QuaDRiGa demonstrate that the proposed method outperforms existing approaches
in terms of perceptual quality (SSIM, LPIPS, FID), task-specific accuracy
(IoU), and transmission efficiency. These results highlight the effectiveness
of integrating task-aware semantic decomposition, scenario-adaptive channel
estimation, and diffusion-based reconstruction for robust semantic transmission
in dynamic wireless environments.

</details>


### [56] [A University of Texas Medical Branch Case Study on Aortic Calcification Detection](https://arxiv.org/abs/2509.23930)
*Eric Walser,Peter McCaffrey,Kal Clark,Nicholas Czarnek*

Main category: eess.IV

TL;DR: UTMB与Zauron Labs合作，使用AI技术检测胸片中主动脉钙化，发现12.4%的编码错误率和2.1%的漏诊率，潜在影响患者护理并挽回31.4万美元年收入。


<details>
  <summary>Details</summary>
Motivation: 主动脉钙化具有重要的心血管疾病预后价值，但经常被漏报，UTMB希望通过AI技术提高检测和编码准确性。

Method: 使用高性能图像模型(AUC=0.938)和基于Meta Llama 3.2的微调语言模型，回顾性分析影像和报告数据。

Result: 在3,988名患者中发现495名(12.4%)编码错误，84名(2.1%)漏诊，潜在挽回31.4万美元年收入。

Conclusion: UTMB决定在全系统采用Zauron的Guardian Pro软件，通过AI增强同行评审和编码，改善患者护理和财务稳定性。

Abstract: This case study details The University of Texas Medical Branch (UTMB)'s
partnership with Zauron Labs, Inc. to enhance detection and coding of aortic
calcifications (ACs) using chest radiographs. ACs are often underreported
despite their significant prognostic value for cardiovascular disease, and UTMB
partnered with Zauron to apply its advanced AI tools, including a
high-performing image model (AUC = 0.938) and a fine-tuned language model based
on Meta's Llama 3.2, to retrospectively analyze imaging and report data. The
effort identified 495 patients out of 3,988 unique patients assessed (5,000
total exams) whose reports contained indications of aortic calcifications that
were not properly coded for reimbursement (12.4% miscode rate) as well as an
additional 84 patients who had aortic calcifications that were missed during
initial review (2.1% misdiagnosis rate). Identification of these patients
provided UTMB with the potential to impact clinical care for these patients and
pursue $314k in missed annual revenue. These findings informed UTMB's decision
to adopt Zauron's Guardian Pro software system-wide to ensure accurate,
AI-enhanced peer review and coding, improving both patient care and financial
solvency. This study is covered under University of Texas Health San Antonio's
Institutional Review Board Study ID 00001887.

</details>


### [57] [Non-Invasive Detection of PROState Cancer with Novel Time-Dependent Diffusion MRI and AI-Enhanced Quantitative Radiological Interpretation: PROS-TD-AI](https://arxiv.org/abs/2509.24227)
*Baltasar Ramos,Cristian Garrido,Paulette Narv'aez,Santiago Gelerstein Claro,Haotian Li,Rafael Salvador,Constanza V'asquez-Venegas,Iv'an Gallegos,Yi Zhang,V'ictor Casta~neda,Cristian Acevedo,Dan Wu,Gonzalo C'ardenas,Camilo G. Sotomayor*

Main category: eess.IV

TL;DR: 该研究方案旨在评估一种新型AI增强的时变扩散MRI软件(PROSTDAI)在前列腺癌诊断中的价值，与传统PI-RADS v2.1标准对比，并以MRI引导前列腺活检为金标准进行验证。


<details>
  <summary>Details</summary>
Motivation: 多参数MRI在前列腺癌诊断中存在假阳性、假阴性以及观察者间一致性中等的问题，需要更准确的诊断工具来区分临床显著性和非显著性前列腺癌。

Method: 开发AI增强的时变扩散MRI软件(PROSTDAI)，结合机器学习算法分析TDD衍生指标，在常规诊断护理中进行前瞻性评估。

Result: 研究方案已制定，但具体结果尚未获得，因为这是一项研究方案的描述。

Conclusion: AI增强的TDD-MRI有望提供更准确、区域特异性的风险预测，减少对阅片者培训的依赖，提高前列腺癌诊断准确性。

Abstract: Prostate cancer (PCa) is the most frequently diagnosed malignancy in men and
the eighth leading cause of cancer death worldwide. Multiparametric MRI (mpMRI)
has become central to the diagnostic pathway for men at intermediate risk,
improving de-tection of clinically significant PCa (csPCa) while reducing
unnecessary biopsies and over-diagnosis. However, mpMRI remains limited by
false positives, false negatives, and moderate to substantial interobserver
agreement. Time-dependent diffusion (TDD) MRI, a novel sequence that enables
tissue microstructure characterization, has shown encouraging preclinical
performance in distinguishing clinically significant from insignificant PCa.
Combining TDD-derived metrics with machine learning may provide robust,
zone-specific risk prediction with less dependence on reader training and
improved accuracy compared to current standard-of-care. This study protocol
out-lines the rationale and describes the prospective evaluation of a
home-developed AI-enhanced TDD-MRI software (PROSTDAI) in routine diagnostic
care, assessing its added value against PI-RADS v2.1 and validating results
against MRI-guided prostate biopsy.

</details>


### [58] [Adaptive Source-Channel Coding for Multi-User Semantic and Data Communications](https://arxiv.org/abs/2509.24247)
*Kai Yuan,Dongxu Li,Jianhao Huang,Han Zhang,Chuan Huang*

Main category: eess.IV

TL;DR: 提出了一个多用户自适应源信道编码框架，用于同时服务具有不同语义和数据任务的用户，通过联合优化源编码、信道编码和功率分配来改善系统性能。


<details>
  <summary>Details</summary>
Motivation: 多用户语义和数据通信系统中存在异构通信任务、多样化信道条件和数字兼容性要求的挑战，需要高效的系统设计方法。

Method: 使用数据回归方法近似端到端失真，提出加权和失真最小化问题，并采用交替优化框架结合子梯度下降和上下行链路对偶技术进行联合优化。

Result: 与传统的分离源信道编码和深度联合源信道编码方案相比，所提方法在数据恢复和语义任务性能上均实现了同时改进。

Conclusion: 多用户自适应源信道编码框架能够有效解决多用户语义数据通信系统的挑战，提升整体系统性能。

Abstract: This paper considers a multi-user semantic and data communication
(MU-SemDaCom) system, where a base station (BS) simultaneously serves users
with different semantic and data tasks through a downlink multi-user
multiple-input single-output (MU-MISO) channel. The coexistence of
heterogeneous communication tasks, diverse channel conditions, and the
requirements for digital compatibility poses significant challenges to the
efficient design of MU-SemDaCom systems. To address these issues, we propose a
multi-user adaptive source-channel coding (MU-ASCC) framework that adaptively
optimizes deep neural network (DNN)-based source coding, digital channel
coding, and superposition broadcasting. First, we employ a data-regression
method to approximate the end-to-end (E2E) semantic and data distortions, for
which no closed-form expressions exist. The obtained logistic formulas
decompose the E2E distortion as the addition of the source and channel
distortion terms, in which the logistic parameter variations are task-dependent
and jointly determined by both the DNN and channel parameters. Then, based on
the derived formulas, we formulate a weighted-sum E2E distortion minimization
problem that jointly optimizes the source-channel coding rates, power
allocation, and beamforming vectors for both the data and semantic users.
Finally, an alternating optimization (AO) framework is developed, where the
adaptive rate optimization is solved using the subgradient descent method,
while the joint power and beamforming is addressed via the uplink-downlink
duality (UDD) technique. Simulation results demonstrate that, compared with the
conventional separate source-channel coding (SSCC) and deep joint
source-channel coding (DJSCC) schemes that are designed for a single task, the
proposed MU-ASCC scheme achieves simultaneous improvements in both the data
recovery and semantic task performance.

</details>


### [59] [ReCon-GS: Continuum-Preserved Guassian Streaming for Fast and Compact Reconstruction of Dynamic Scenes](https://arxiv.org/abs/2509.24325)
*Jiaye Fu,Qiankun Gao,Chengxiang Wen,Yanmin Wu,Siwei Ma,Jiaqi Zhang,Jian Zhang*

Main category: eess.IV

TL;DR: ReCon-GS是一个存储感知的在线自由视点视频重建框架，通过动态多级锚点高斯分布、层次重构策略和存储感知优化，实现了高效训练、高质量渲染和大幅内存节省。


<details>
  <summary>Details</summary>
Motivation: 解决在线自由视点视频重建中的三大挑战：逐帧优化速度慢、运动估计不一致、存储需求不可持续。

Method: 1) 密度自适应动态分配多级锚点高斯分布来捕捉帧间几何变形；2) 动态层次重构策略保持局部运动表达能力；3) 存储感知优化机制灵活调整不同层次锚点密度。

Result: 在三个数据集上的实验表明：训练效率提升约15%，渲染质量优于现有方法，内存需求减少超过50%。

Conclusion: ReCon-GS在保持高质量渲染的同时，显著提升了训练效率和存储效率，为在线自由视点视频重建提供了有效的解决方案。

Abstract: Online free-viewpoint video (FVV) reconstruction is challenged by slow
per-frame optimization, inconsistent motion estimation, and unsustainable
storage demands. To address these challenges, we propose the Reconfigurable
Continuum Gaussian Stream, dubbed ReCon-GS, a novel storage-aware framework
that enables high fidelity online dynamic scene reconstruction and real-time
rendering. Specifically, we dynamically allocate multi-level Anchor Gaussians
in a density-adaptive fashion to capture inter-frame geometric deformations,
thereby decomposing scene motion into compact coarse-to-fine representations.
Then, we design a dynamic hierarchy reconfiguration strategy that preserves
localized motion expressiveness through on-demand anchor re-hierarchization,
while ensuring temporal consistency through intra-hierarchical deformation
inheritance that confines transformation priors to their respective hierarchy
levels. Furthermore, we introduce a storage-aware optimization mechanism that
flexibly adjusts the density of Anchor Gaussians at different hierarchy levels,
enabling a controllable trade-off between reconstruction fidelity and memory
usage. Extensive experiments on three widely used datasets demonstrate that,
compared to state-of-the-art methods, ReCon-GS improves training efficiency by
approximately 15% and achieves superior FVV synthesis quality with enhanced
robustness and stability. Moreover, at equivalent rendering quality, ReCon-GS
slashes memory requirements by over 50% compared to leading state-of-the-art
methods.

</details>


### [60] [Wavelet-Assisted Mamba for Satellite-Derived Sea Surface Temperature Super-Resolution](https://arxiv.org/abs/2509.24334)
*Wankun Chen,Feng Gao,Yanhai Gan,Jingchao Cao,Junyu Dong,Qian Du*

Main category: eess.IV

TL;DR: 提出了Wavelet-assisted Mamba Super-Resolution (WMSR)框架，用于卫星海表温度数据的超分辨率重建，结合低频状态空间模块和高频增强模块，在三个SST数据集上表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 获取高分辨率海表温度数据具有挑战性，而基于Mamba的状态空间模型在长距离依赖建模方面显示巨大潜力，但在SST数据超分辨率中的应用尚未充分探索。

Method: WMSR框架包含两个关键组件：低频状态空间模块(LFSSM)使用2D-SSM捕捉输入数据的全局信息，高频增强模块(HFEM)使用像素差异卷积匹配和校正高频特征。

Result: 在三个SST数据集上的综合实验表明，WMSR在性能上优于最先进的方法。

Conclusion: WMSR框架通过结合状态空间模型和小波辅助方法，为卫星SST数据超分辨率提供了一种有效的解决方案，代码和数据集将公开提供。

Abstract: Sea surface temperature (SST) is an essential indicator of global climate
change and one of the most intuitive factors reflecting ocean conditions.
Obtaining high-resolution SST data remains challenging due to limitations in
physical imaging, and super-resolution via deep neural networks is a promising
solution. Recently, Mamba-based approaches leveraging State Space Models (SSM)
have demonstrated significant potential for long-range dependency modeling with
linear complexity. However, their application to SST data super-resolution
remains largely unexplored. To this end, we propose the Wavelet-assisted Mamba
Super-Resolution (WMSR) framework for satellite-derived SST data. The WMSR
includes two key components: the Low-Frequency State Space Module (LFSSM) and
High-Frequency Enhancement Module (HFEM). The LFSSM uses 2D-SSM to capture
global information of the input data, and the robust global modeling
capabilities of SSM are exploited to preserve the critical temperature
information in the low-frequency component. The HFEM employs the pixel
difference convolution to match and correct the high-frequency feature,
achieving accurate and clear textures. Through comprehensive experiments on
three SST datasets, our WMSR demonstrated superior performance over
state-of-the-art methods. Our codes and datasets will be made publicly
available at https://github.com/oucailab/WMSR.

</details>


### [61] [A Novel Preprocessing Unit for Effective Deep Learning based Classification and Grading of Diabetic Retinopathy](https://arxiv.org/abs/2509.24497)
*Pranoti Nage,Sanjay Shitole*

Main category: eess.IV

TL;DR: 提出了一种用于早期检测糖尿病视网膜病变(DR)和糖尿病黄斑水肿(DME)的三阶段框架，包括预处理、分割、特征提取和分类。


<details>
  <summary>Details</summary>
Motivation: 早期检测糖尿病视网膜病变至关重要，可以及时干预，预防视力丧失并有效管理糖尿病并发症。

Method: 三阶段框架：预处理阶段使用模糊滤波去噪、非线性扩散滤波去除伪影、AVDS滤波器增强对比度；分割阶段使用改进的Mask RCNN；分类阶段使用自空间注意力融合的VGG-16(SSA-VGG-16)。

Result: 在IDRiD和MESSIDOR两个数据集上评估了方法的有效性，汉明距离方法在对比度方面表现更好，欧几里得距离显示较低的误差值和高PSNR。

Conclusion: 提出的方法能够有效捕捉视网膜图像中的全局上下文关系和关键空间区域，提高了DR和DME检测和分级的准确性和鲁棒性。

Abstract: Early detection of diabetic retinopathy (DR) is crucial as it allows for
timely intervention, preventing vision loss and enabling effective management
of diabetic complications. This research performs detection of DR and DME at an
early stage through the proposed framework which includes three stages:
preprocessing, segmentation, feature extraction, and classification. In the
preprocessing stage, noise filtering is performed by fuzzy filtering, artefact
removal is performed by non-linear diffusion filtering, and the contrast
improvement is performed by a novel filter called Adaptive Variable Distance
Speckle (AVDS) filter. The AVDS filter employs four distance calculation
methods such as Euclidean, Bhattacharya, Manhattan, and Hamming. The filter
adaptively chooses a distance method which produces the highest contrast value
amongst all 3 methods. From the analysis, hamming distance method was found to
achieve better results for contrast and Euclidean distance showing less error
value with high PSNR. The segmentation stage is performed using Improved
Mask-Regional Convolutional Neural Networks (Mask RCNN). In the final stage,
feature extraction and classification using novel Self-Spatial Attention
infused VGG-16 (SSA-VGG-16), which effectively captures both global contextual
relationships and critical spatial regions within retinal images, thereby
improving the accuracy and robustness of DR and DME detection and grading. The
effectiveness of the proposed method is assessed using two distinct datasets:
IDRiD and MESSIDOR.

</details>
