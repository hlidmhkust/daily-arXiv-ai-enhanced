{"id": "2510.12065", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.12065", "abs": "https://arxiv.org/abs/2510.12065", "authors": ["Soma Furusawa", "Taisei Kato", "Ryo Hayakawa", "Kazunori Hayashi"], "title": "Approximate Proximal Operators for Analog Compressed Sensing Using PN-junction Diode", "comment": null, "summary": "In order to realize analog compressed sensing, the paper considers\napproximate proximal operators of the $\\ell_1$ and minimax concave penalty\n(MCP) regularization functions. Specifically, we propose to realize the\napproximate functions by an electric analog circuit using forward\nvoltage-current (V-I) characteristics of the PN-junction diodes. To confirm the\nvalidity of the proposed approach, we employ the proposed approximate proximal\noperators for the $\\ell_1$ and MCP regularization functions in compressed\nsensing with the proximal gradient method. The sparse reconstruction\nperformance of the algorithms using the proposed approximate proximal operators\nis demonstrated via computer simulations taking into account the impact of\nadditive noise introduced by analog devices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528PN\u7ed3\u4e8c\u6781\u7ba1\u7684\u6b63\u5411\u7535\u538b-\u7535\u6d41\u7279\u6027\u5b9e\u73b0\u2113\u2081\u548cMCP\u6b63\u5219\u5316\u51fd\u6570\u7684\u8fd1\u4f3c\u8fd1\u7aef\u7b97\u5b50\uff0c\u7528\u4e8e\u6a21\u62df\u538b\u7f29\u611f\u77e5\u3002\u901a\u8fc7\u8ba1\u7b97\u673a\u4eff\u771f\u9a8c\u8bc1\u4e86\u5728\u8003\u8651\u6a21\u62df\u5668\u4ef6\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u8fd9\u4e9b\u8fd1\u4f3c\u8fd1\u7aef\u7b97\u5b50\u7684\u7a00\u758f\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u6a21\u62df\u538b\u7f29\u611f\u77e5\uff0c\u9700\u8981\u627e\u5230\u2113\u2081\u548cMCP\u6b63\u5219\u5316\u51fd\u6570\u7684\u8fd1\u4f3c\u8fd1\u7aef\u7b97\u5b50\u7684\u5b9e\u9645\u5b9e\u73b0\u65b9\u6cd5\u3002", "method": "\u5229\u7528PN\u7ed3\u4e8c\u6781\u7ba1\u7684\u6b63\u5411\u7535\u538b-\u7535\u6d41\u7279\u6027\u8bbe\u8ba1\u7535\u5b50\u6a21\u62df\u7535\u8def\uff0c\u5b9e\u73b0\u2113\u2081\u548cMCP\u6b63\u5219\u5316\u51fd\u6570\u7684\u8fd1\u4f3c\u8fd1\u7aef\u7b97\u5b50\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u8fd1\u7aef\u68af\u5ea6\u6cd5\u7684\u538b\u7f29\u611f\u77e5\u4e2d\u3002", "result": "\u901a\u8fc7\u8ba1\u7b97\u673a\u4eff\u771f\u8868\u660e\uff0c\u4f7f\u7528\u63d0\u51fa\u7684\u8fd1\u4f3c\u8fd1\u7aef\u7b97\u5b50\u7684\u7b97\u6cd5\u5177\u6709\u826f\u597d\u7684\u7a00\u758f\u91cd\u5efa\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u8003\u8651\u6a21\u62df\u5668\u4ef6\u5f15\u5165\u7684\u52a0\u6027\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8ePN\u7ed3\u4e8c\u6781\u7ba1\u7279\u6027\u7684\u8fd1\u4f3c\u8fd1\u7aef\u7b97\u5b50\u5b9e\u73b0\u65b9\u6cd5\u662f\u6709\u6548\u7684\uff0c\u53ef\u7528\u4e8e\u6a21\u62df\u538b\u7f29\u611f\u77e5\u7cfb\u7edf\u3002"}}
{"id": "2510.12078", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.12078", "abs": "https://arxiv.org/abs/2510.12078", "authors": ["Sijing Xie", "Dingzhu Wen", "Changsheng You", "Qimei Chen", "Mehdi Bennis", "Kaibin Huang"], "title": "FedLoDrop: Federated LoRA with Dropout for Generalized LLM Fine-tuning", "comment": null, "summary": "Fine-tuning (FT) large language models (LLMs) is crucial for adapting\ngeneral-purpose models to specific tasks, enhancing accuracy and relevance with\nminimal resources. To further enhance generalization ability while reducing\ntraining costs, this paper proposes Federated LoRA with Dropout (FedLoDrop), a\nnew framework that applies dropout to the rows and columns of the trainable\nmatrix in Federated LoRA. A generalization error bound and convergence analysis\nunder sparsity regularization are obtained, which elucidate the fundamental\ntrade-off between underfitting and overfitting. The error bound reveals that a\nhigher dropout rate increases model sparsity, thereby lowering the upper bound\nof pointwise hypothesis stability (PHS). While this reduces the gap between\nempirical and generalization errors, it also incurs a higher empirical error,\nwhich, together with the gap, determines the overall generalization error. On\nthe other hand, though dropout reduces communication costs, deploying FedLoDrop\nat the network edge still faces challenges due to limited network resources. To\naddress this issue, an optimization problem is formulated to minimize the upper\nbound of the generalization error, by jointly optimizing the dropout rate and\nresource allocation subject to the latency and per-device energy consumption\nconstraints. To solve this problem, a branch-and-bound (B\\&B)-based method is\nproposed to obtain its globally optimal solution. Moreover, to reduce the high\ncomputational complexity of the B\\&B-based method, a penalized successive\nconvex approximation (P-SCA)-based algorithm is proposed to efficiently obtain\nits high-quality suboptimal solution. Finally, numerical results demonstrate\nthe effectiveness of the proposed approach in mitigating overfitting and\nimproving the generalization capability.", "AI": {"tldr": "\u63d0\u51fa\u4e86FedLoDrop\u6846\u67b6\uff0c\u5728\u8054\u90a6LoRA\u4e2d\u5bf9\u53ef\u8bad\u7ec3\u77e9\u9635\u7684\u884c\u5217\u5e94\u7528dropout\uff0c\u901a\u8fc7\u4f18\u5316dropout\u7387\u548c\u8d44\u6e90\u5206\u914d\u6765\u6700\u5c0f\u5316\u6cdb\u5316\u8bef\u5dee\u4e0a\u754c\uff0c\u89e3\u51b3\u8fc7\u62df\u5408\u95ee\u9898\u5e76\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u5728\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u7684\u540c\u65f6\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u8fc7\u62df\u5408\u548c\u6709\u9650\u7f51\u7edc\u8d44\u6e90\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faFedLoDrop\u6846\u67b6\uff0c\u5bf9\u8054\u90a6LoRA\u7684\u53ef\u8bad\u7ec3\u77e9\u9635\u884c\u5217\u5e94\u7528dropout\uff1b\u5efa\u7acb\u6cdb\u5316\u8bef\u5dee\u754c\u548c\u6536\u655b\u6027\u5206\u6790\uff1b\u901a\u8fc7\u5206\u652f\u5b9a\u754c\u6cd5\u548c\u60e9\u7f5a\u6027\u9010\u6b21\u51f8\u8fd1\u4f3c\u7b97\u6cd5\u4f18\u5316dropout\u7387\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u8fc7\u62df\u5408\u5e76\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002", "conclusion": "FedLoDrop\u901a\u8fc7dropout\u548c\u8d44\u6e90\u8054\u5408\u4f18\u5316\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u4e3a\u8fb9\u7f18\u7f51\u7edc\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12406", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.12406", "abs": "https://arxiv.org/abs/2510.12406", "authors": ["Zahra Mobini", "Hien Quoc Ngo", "Ardavan Rahimian", "Anvar Tukmanov", "David Townend", "Michail Matthaiou", "Simon L. Cotton"], "title": "Hybrid centralized-distributed precoding in fronthaul-constrained CF-mMIMO systems", "comment": null, "summary": "We investigate a fronthaul-limited cell-free massive multiple-input\nmultiple-output (CF-mMIMO) system and propose a hybrid centralized-distributed\nprecoding strategy that dynamically adapts to varying fronthaul and spectral\nefficiency (SE) requirements. The proposed approach divides users into two\ngroups: one served by centralized precoding and the other by distributed\nprecoding. We formulate a novel optimization problem for user grouping and\npower control aimed at maximizing the sum SE, subject to fronthaul and\nper-access point (AP) power constraints. To tackle the problem, we transform it\ninto a tractable form and propose efficient solution algorithms. Numerical\nresults confirm the hybrid scheme's versatility and superior performance,\nconsistently outperforming fully centralized and distributed approaches across\ndiverse system configurations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u96c6\u4e2d-\u5206\u5e03\u5f0f\u9884\u7f16\u7801\u7b56\u7565\uff0c\u7528\u4e8e\u524d\u4f20\u53d7\u9650\u7684\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u7528\u6237\u5206\u7ec4\u548c\u529f\u7387\u63a7\u5236\u6765\u6700\u5927\u5316\u603b\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u524d\u4f20\u5bb9\u91cf\u53d7\u9650\u7684\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u9891\u8c31\u6548\u7387\u4e0e\u524d\u4f20\u9700\u6c42\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u7cfb\u7edf\u914d\u7f6e\u7684\u7075\u6d3b\u9884\u7f16\u7801\u65b9\u6848\u3002", "method": "\u5c06\u7528\u6237\u5206\u4e3a\u4e24\u7ec4\uff1a\u4e00\u7ec4\u91c7\u7528\u96c6\u4e2d\u5f0f\u9884\u7f16\u7801\uff0c\u53e6\u4e00\u7ec4\u91c7\u7528\u5206\u5e03\u5f0f\u9884\u7f16\u7801\u3002\u901a\u8fc7\u4f18\u5316\u7528\u6237\u5206\u7ec4\u548c\u529f\u7387\u63a7\u5236\u6765\u6700\u5927\u5316\u603b\u9891\u8c31\u6548\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u524d\u4f20\u5bb9\u91cf\u548c\u63a5\u5165\u70b9\u529f\u7387\u7ea6\u675f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6848\u5728\u5404\u79cd\u7cfb\u7edf\u914d\u7f6e\u4e0b\u5747\u4f18\u4e8e\u5b8c\u5168\u96c6\u4e2d\u5f0f\u548c\u5b8c\u5168\u5206\u5e03\u5f0f\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u6df7\u5408\u96c6\u4e2d-\u5206\u5e03\u5f0f\u9884\u7f16\u7801\u7b56\u7565\u4e3a\u524d\u4f20\u53d7\u9650\u7684\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5e73\u8861\u9891\u8c31\u6548\u7387\u548c\u524d\u4f20\u9700\u6c42\u3002"}}
{"id": "2510.12427", "categories": ["cs.IT", "math.IT", "94A15, 94A40"], "pdf": "https://arxiv.org/pdf/2510.12427", "abs": "https://arxiv.org/abs/2510.12427", "authors": ["Jonas Stapmanns", "Catarina Dias", "Luke Eilers", "Tobias K\u00fchn", "Jean-Pascal Pfister"], "title": "Phase Transitions of the Additive Uniform Noise Channel with Peak Amplitude and Cost Constraint", "comment": "This work was presented in part at the IEEE International Symposium\n  on Information Theory (ISIT) 2025. 18 pages, 8 figures", "summary": "Under which condition is quantization optimal? We address this question in\nthe context of the additive uniform noise channel under peak amplitude and cost\nconstraints. We compute analytically the capacity-achieving input distribution\nas a function of the noise level, the average cost constraint, and the\ncurvature of the cost function. We find that when the cost function is concave,\nthe capacity-achieving input distribution is discrete, whereas when the cost\nfunction is convex and the cost constraint is active, the support of the\ncapacity-achieving input distribution spans the entire interval. For the cases\nof a discrete capacity-achieving input distribution, we derive the analytical\nexpressions for the capacity of the channel.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u52a0\u6027\u5747\u5300\u566a\u58f0\u4fe1\u9053\u4e0b\uff0c\u91cf\u5316\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0b\u662f\u6700\u4f18\u7684\u3002\u901a\u8fc7\u5206\u6790\u5bb9\u91cf\u5b9e\u73b0\u8f93\u5165\u5206\u5e03\u4e0e\u566a\u58f0\u6c34\u5e73\u3001\u5e73\u5747\u6210\u672c\u7ea6\u675f\u548c\u6210\u672c\u51fd\u6570\u66f2\u7387\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u5f53\u6210\u672c\u51fd\u6570\u4e3a\u51f9\u51fd\u6570\u65f6\uff0c\u6700\u4f18\u8f93\u5165\u5206\u5e03\u662f\u79bb\u6563\u7684\uff1b\u5f53\u6210\u672c\u51fd\u6570\u4e3a\u51f8\u51fd\u6570\u4e14\u6210\u672c\u7ea6\u675f\u6709\u6548\u65f6\uff0c\u6700\u4f18\u8f93\u5165\u5206\u5e03\u652f\u6491\u6574\u4e2a\u533a\u95f4\u3002", "motivation": "\u63a2\u7a76\u5728\u52a0\u6027\u5747\u5300\u566a\u58f0\u4fe1\u9053\u4e2d\uff0c\u91cf\u5316\u6210\u4e3a\u6700\u4f18\u7f16\u7801\u7b56\u7565\u7684\u5177\u4f53\u6761\u4ef6\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u4fe1\u9053\u5bb9\u91cf\u5b9e\u73b0\u673a\u5236\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5728\u5cf0\u503c\u5e45\u5ea6\u548c\u6210\u672c\u7ea6\u675f\u4e0b\uff0c\u5206\u6790\u52a0\u6027\u5747\u5300\u566a\u58f0\u4fe1\u9053\u7684\u5bb9\u91cf\u5b9e\u73b0\u8f93\u5165\u5206\u5e03\uff0c\u8003\u8651\u566a\u58f0\u6c34\u5e73\u3001\u5e73\u5747\u6210\u672c\u7ea6\u675f\u548c\u6210\u672c\u51fd\u6570\u66f2\u7387\u7684\u5f71\u54cd\u3002", "result": "\u5f53\u6210\u672c\u51fd\u6570\u4e3a\u51f9\u51fd\u6570\u65f6\uff0c\u5bb9\u91cf\u5b9e\u73b0\u8f93\u5165\u5206\u5e03\u662f\u79bb\u6563\u7684\uff1b\u5f53\u6210\u672c\u51fd\u6570\u4e3a\u51f8\u51fd\u6570\u4e14\u6210\u672c\u7ea6\u675f\u6709\u6548\u65f6\uff0c\u5bb9\u91cf\u5b9e\u73b0\u8f93\u5165\u5206\u5e03\u652f\u6491\u6574\u4e2a\u533a\u95f4\u3002\u5bf9\u4e8e\u79bb\u6563\u6700\u4f18\u8f93\u5165\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u63a8\u5bfc\u51fa\u4e86\u4fe1\u9053\u5bb9\u91cf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u91cf\u5316\u6700\u4f18\u6027\u53d6\u51b3\u4e8e\u6210\u672c\u51fd\u6570\u7684\u66f2\u7387\u7279\u6027\uff1a\u51f9\u6210\u672c\u51fd\u6570\u5bfc\u81f4\u79bb\u6563\u6700\u4f18\u8f93\u5165\u5206\u5e03\uff0c\u51f8\u6210\u672c\u51fd\u6570\u5bfc\u81f4\u8fde\u7eed\u6700\u4f18\u8f93\u5165\u5206\u5e03\uff0c\u8fd9\u4e3a\u4fe1\u9053\u7f16\u7801\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2510.11867", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.11867", "abs": "https://arxiv.org/abs/2510.11867", "authors": ["Zelin Gan", "Henrique Buglia", "Romulo Aparecido", "Mindaugas Jarmolovi\u010dius", "Eric Sillekens", "Jiaqian Yang", "Ronit Sohanpal", "Robert I. Killey", "Polina Bayvel"], "title": "A Closed-form Expression of the Gaussian Noise Model Supporting O-Band Transmission", "comment": "13 pages, 10 figures", "summary": "We present a novel closed-form model for nonlinear interference (NLI)\nestimation in low-dispersion O-band transmission systems. The formulation\nincorporates the four-wave mixing (FWM) efficiency term as well as the coherent\ncontributions of self- and cross-phase modulation (SPM/XPM) across multiple\nidentical spans. This extension enables accurate evaluation of the NLI in\nscenarios where conventional closed-form Gaussian Noise (GN) models are\nlimited. The proposed model is validated against split-step Fourier method\n(SSFM) simulations and numerical integration across 41-161 channels, with a 96\nGBaud symbol rate, bandwidths of up to 16.1 THz, and transmission distances\nfrom 80 to 800 km. Results show a mean absolute error of the NLI\nsignal-to-noise ratio (SNR) below 0.22 dB. The proposed closed-form model\noffers an efficient and accurate tool for system optimisation in O-band\ncoherent transmission.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eO\u6ce2\u6bb5\u4f4e\u8272\u6563\u4f20\u8f93\u7cfb\u7edf\u4e2d\u975e\u7ebf\u6027\u5e72\u6270\u4f30\u8ba1\u7684\u95ed\u5f0f\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u56db\u6ce2\u6df7\u9891\u6548\u7387\u9879\u4ee5\u53ca\u591a\u8de8\u8ddd\u4e2d\u81ea\u76f8\u4f4d\u8c03\u5236\u548c\u4ea4\u53c9\u76f8\u4f4d\u8c03\u5236\u7684\u76f8\u5e72\u8d21\u732e\uff0c\u76f8\u6bd4\u4f20\u7edf\u9ad8\u65af\u566a\u58f0\u6a21\u578b\u66f4\u51c6\u786e\u3002", "motivation": "\u4f20\u7edf\u95ed\u5f0f\u9ad8\u65af\u566a\u58f0\u6a21\u578b\u5728\u4f4e\u8272\u6563O\u6ce2\u6bb5\u4f20\u8f93\u7cfb\u7edf\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u51c6\u786e\u7684\u975e\u7ebf\u6027\u5e72\u6270\u4f30\u8ba1\u6a21\u578b\u6765\u652f\u6301\u7cfb\u7edf\u4f18\u5316\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u56db\u6ce2\u6df7\u9891\u6548\u7387\u9879\u4ee5\u53ca\u81ea\u76f8\u4f4d\u8c03\u5236\u548c\u4ea4\u53c9\u76f8\u4f4d\u8c03\u5236\u7684\u76f8\u5e72\u8d21\u732e\uff0c\u6269\u5c55\u4e86\u95ed\u5f0f\u6a21\u578b\uff0c\u5e76\u572841-161\u4e2a\u4fe1\u9053\u300196 GBaud\u7b26\u53f7\u7387\u3001\u6700\u9ad816.1 THz\u5e26\u5bbd\u300180-800 km\u4f20\u8f93\u8ddd\u79bb\u6761\u4ef6\u4e0b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u4e0e\u5206\u6b65\u5085\u91cc\u53f6\u65b9\u6cd5\u548c\u6570\u503c\u79ef\u5206\u76f8\u6bd4\uff0c\u975e\u7ebf\u6027\u5e72\u6270\u4fe1\u566a\u6bd4\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f4e\u4e8e0.22 dB\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u95ed\u5f0f\u6a21\u578b\u4e3aO\u6ce2\u6bb5\u76f8\u5e72\u4f20\u8f93\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5de5\u5177\u3002"}}
{"id": "2510.11964", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.11964", "abs": "https://arxiv.org/abs/2510.11964", "authors": ["Brett Levac", "Jon Tamir", "Marcelo Pereyra", "Julian Tachella"], "title": "Normalization-equivariant Diffusion Models: Learning Posterior Samplers From Noisy And Partial Measurements", "comment": null, "summary": "Diffusion models (DMs) have rapidly emerged as a powerful framework for image\ngeneration and restoration. However, existing DMs are primarily trained in a\nsupervised manner by using a large corpus of clean images. This reliance on\nclean data poses fundamental challenges in many real-world scenarios, where\nacquiring noise-free data is hard or infeasible, and only noisy and potentially\nincomplete measurements are available. While some methods can train DMs using\nnoisy data, they are generally effective only when the amount of noise is very\nmild or when some additional noise-free data is available. In addition,\nexisting methods for training DMs from incomplete measurements require access\nto multiple complementary acquisition processes, an assumption that poses a\nsignificant practical limitation. Here we introduce the first approach for\nlearning DMs for image restoration using only noisy measurement data from a\nsingle operator. As a first key contribution, we show that DMs, and more\nbroadly minimum mean squared error denoisers, exhibit a weak form of scale\nequivariance linking rescaling in signal amplitude to changes in noise\nintensity. We then leverage this theoretical insight to develop a denoising\nscore-matching strategy that generalizes robustly to noise levels lower than\nthose present in the training data, thereby enabling the learning of DMs from\nnoisy measurements. To further address the challenges of incomplete and noisy\ndata, we integrate our method with equivariant imaging, a complementary\nself-supervised learning framework that exploits the inherent invariants of\nimaging problems, to train DMs for image restoration from single-operator\nmeasurements that are both incomplete and noisy. We validate the effectiveness\nof our approach through extensive experiments on image denoising, demosaicing,\nand inpainting, along with comparisons with the state of the art.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u4ec5\u4f7f\u7528\u5355\u64cd\u4f5c\u5668\u566a\u58f0\u6d4b\u91cf\u6570\u636e\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u8fdb\u884c\u56fe\u50cf\u6062\u590d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c3a\u5ea6\u7b49\u53d8\u6027\u7406\u8bba\u5b9e\u73b0\u4ece\u566a\u58f0\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u65e0\u9700\u5e72\u51c0\u56fe\u50cf\u6216\u4e92\u8865\u91c7\u96c6\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u4f9d\u8d56\u5e72\u51c0\u56fe\u50cf\u8bad\u7ec3\uff0c\u4f46\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u83b7\u53d6\u65e0\u566a\u58f0\u6570\u636e\u56f0\u96be\u6216\u4e0d\u73b0\u5b9e\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u6e29\u548c\u566a\u58f0\u6216\u989d\u5916\u65e0\u566a\u58f0\u6570\u636e\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u53d1\u73b0\u6269\u6563\u6a21\u578b\u5177\u6709\u5f31\u5c3a\u5ea6\u7b49\u53d8\u6027\uff0c\u636e\u6b64\u5f00\u53d1\u4e86\u53bb\u566a\u5206\u6570\u5339\u914d\u7b56\u7565\uff0c\u53ef\u6cdb\u5316\u5230\u6bd4\u8bad\u7ec3\u6570\u636e\u66f4\u4f4e\u566a\u58f0\u6c34\u5e73\uff1b\u7ed3\u5408\u7b49\u53d8\u6210\u50cf\u6846\u67b6\u5904\u7406\u4e0d\u5b8c\u6574\u548c\u566a\u58f0\u6570\u636e\u3002", "result": "\u5728\u56fe\u50cf\u53bb\u566a\u3001\u53bb\u9a6c\u8d5b\u514b\u548c\u4fee\u590d\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5b9e\u73b0\u4e86\u4ec5\u4f7f\u7528\u5355\u64cd\u4f5c\u5668\u566a\u58f0\u6d4b\u91cf\u6570\u636e\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u8fdb\u884c\u56fe\u50cf\u6062\u590d\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u5e72\u51c0\u6570\u636e\u6216\u4e92\u8865\u91c7\u96c6\u8fc7\u7a0b\u7684\u4f9d\u8d56\u3002"}}
{"id": "2510.12739", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.12739", "abs": "https://arxiv.org/abs/2510.12739", "authors": ["Mohanad Obeed", "Ming Jian"], "title": "CoNet-Rx: Collaborative Neural Networks for OFDM Receivers", "comment": null, "summary": "Deep learning (DL) based methods for orthogonal frequency division\nmultiplexing (OFDM) radio receivers demonstrated higher signal detection\nperformance compared to the traditional receivers. However, the existing\nDL-based models, usually adapted from computer vision, aren't well suited for\nwireless communications. These models require high computational resources and\nmemory, and have significant inference delays, limiting their use in\nresource-constrained settings. Additionally, reducing network size to ease\nresource demands often leads to notable performance degradation. This paper\nintroduces collaborative networks (CoNet), a novel neural network (NN)\narchitecture designed for OFDM receivers. CoNet uses multiple small ResNet or\nCNN subnetworks to simultaneously process signal features from different\nperspectives like capturing channel correlations and interference patterns.\nThese subnetworks fuse their outputs through interaction operations (e.g.,\nelement-wise multiplication), significantly enhancing detection performance.\nSimulation results show CoNet significantly outperforms traditional\narchitectures like residual networks (ResNets) in bit error rate (BER) and\nreduces inference delay when both nets have the same size and the same\ncomputational complexity.", "AI": {"tldr": "\u63d0\u51fa\u534f\u4f5c\u7f51\u7edc(CoNet)\u7528\u4e8eOFDM\u63a5\u6536\u673a\uff0c\u901a\u8fc7\u591a\u4e2a\u5c0f\u578b\u5b50\u7f51\u7edc\u4ece\u4e0d\u540c\u89d2\u5ea6\u5904\u7406\u4fe1\u53f7\u7279\u5f81\uff0c\u76f8\u6bd4\u4f20\u7edfResNet\u5728\u76f8\u540c\u590d\u6742\u5ea6\u4e0b\u663e\u8457\u964d\u4f4e\u8bef\u7801\u7387\u548c\u63a8\u7406\u5ef6\u8fdf", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684OFDM\u63a5\u6536\u673a\u6a21\u578b\u901a\u5e38\u4ece\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6539\u7f16\uff0c\u4e0d\u9002\u5408\u65e0\u7ebf\u901a\u4fe1\u573a\u666f\uff0c\u5b58\u5728\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\u3001\u5185\u5b58\u5360\u7528\u5927\u3001\u63a8\u7406\u5ef6\u8fdf\u663e\u8457\u7b49\u95ee\u9898\uff0c\u4e14\u7f29\u5c0f\u7f51\u7edc\u89c4\u6a21\u4f1a\u5bfc\u81f4\u6027\u80fd\u660e\u663e\u4e0b\u964d", "method": "\u8bbe\u8ba1\u534f\u4f5c\u7f51\u7edc\u67b6\u6784\uff0c\u4f7f\u7528\u591a\u4e2a\u5c0f\u578bResNet\u6216CNN\u5b50\u7f51\u7edc\u540c\u65f6\u5904\u7406\u4fe1\u53f7\u7684\u4e0d\u540c\u7279\u5f81\uff08\u5982\u4fe1\u9053\u76f8\u5173\u6027\u548c\u5e72\u6270\u6a21\u5f0f\uff09\uff0c\u901a\u8fc7\u5143\u7d20\u7ea7\u4e58\u6cd5\u7b49\u4ea4\u4e92\u64cd\u4f5c\u878d\u5408\u5b50\u7f51\u7edc\u8f93\u51fa", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793aCoNet\u5728\u76f8\u540c\u7f51\u7edc\u89c4\u6a21\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0b\uff0c\u76f8\u6bd4\u4f20\u7edfResNet\u67b6\u6784\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u7801\u7387(BER)\u548c\u63a8\u7406\u5ef6\u8fdf", "conclusion": "CoNet\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684OFDM\u63a5\u6536\u673a\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u9700\u6c42"}}
{"id": "2510.11891", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.11891", "abs": "https://arxiv.org/abs/2510.11891", "authors": ["Haoran He"], "title": "Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems", "comment": "4 pages, 8 figures, ISCIPT 2025", "summary": "This paper proposes a machine learning-assisted channel estimation approach\nfor massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE\nmethods. In 5G and beyond, accurate channel estimation mitigates pilot\ncontamination and high mobility issues that harm system reliability. The\nproposed DNN architecture includes multi-layer perceptrons with ReLU\nactivation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam\noptimizer (learning rate 1e-4) and MSE loss function. It learns from pilot\nsignals to predict channel matrices, achieving lower NMSE and BER across\ndifferent SNR levels. Simulations use the COST 2100 public standard dataset (a\nwell-recognized MIMO channel dataset for 5G, not synthetic datasets) with\n10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show\nthe DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust\nperformance in high-mobility scenarios. The study evaluates metrics like NMSE\nvs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations,\nand computational complexity. The DNN has 2.3 GFlOPs computational complexity,\n15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying\ndeployment feasibility. This work advances ML integration in wireless\ncommunications, facilitating efficient resource allocation and improved\nspectral efficiency in next-generation networks. Future work may use more\nreal-world datasets and hybrid architectures for better generalization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4fe1\u9053\u4f30\u8ba1\uff0c\u76f8\u6bd4\u4f20\u7edfLS\u548cMMSE\u65b9\u6cd5\u5728NMSE\u548cBER\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b35G\u53ca\u672a\u6765\u7f51\u7edc\u4e2d\u7531\u5bfc\u9891\u6c61\u67d3\u548c\u9ad8\u79fb\u52a8\u6027\u5bfc\u81f4\u7684\u4fe1\u9053\u4f30\u8ba1\u4e0d\u51c6\u786e\u95ee\u9898\uff0c\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668DNN\u67b6\u6784\uff0c\u5305\u542b3\u4e2a\u9690\u85cf\u5c42(256,128,64\u795e\u7ecf\u5143)\uff0cReLU\u6fc0\u6d3b\u51fd\u6570\uff0cAdam\u4f18\u5316\u5668\u548cMSE\u635f\u5931\u51fd\u6570\uff0c\u4ece\u5bfc\u9891\u4fe1\u53f7\u5b66\u4e60\u9884\u6d4b\u4fe1\u9053\u77e9\u9635\u3002", "result": "\u5728COST 2100\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cDNN\u65b9\u6cd5\u5728\u4e2d\u7b49SNR\u4e0b\u6bd4LS\u548cMMSE\u65b9\u6cd5NMSE\u6027\u80fd\u63d0\u53473-5dB\uff0c\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3a2.3 GFlOPs\uff0c\u63a8\u7406\u65f6\u95f41.8ms\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u673a\u5668\u5b66\u4e60\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u96c6\u6210\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8d44\u6e90\u5206\u914d\u548c\u9891\u8c31\u6548\u7387\u63d0\u5347\u65b9\u6848\u3002"}}
{"id": "2510.12379", "categories": ["eess.IV", "cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.12379", "abs": "https://arxiv.org/abs/2510.12379", "authors": ["Vibhoothi Vibhoothi", "Fran\u00e7ois Piti\u00e9", "Anil Kokaram"], "title": "LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications", "comment": "Accepted PCS 2025 Camera-Ready Version, 5 Pages", "summary": "In the last decade, video workflows in the cinema production ecosystem have\npresented new use cases for video streaming technology. These new workflows,\ne.g. in On-set Virtual Production, present the challenge of requiring precise\nquality control and energy efficiency. Existing approaches to transcoding often\nfall short of these requirements, either due to a lack of quality control or\ncomputational overhead. To fill this gap, we present a lightweight neural\nnetwork (LiteVPNet) for accurately predicting Quantisation Parameters for NVENC\nAV1 encoders that achieve a specified VMAF score. We use low-complexity\nfeatures, including bitstream characteristics, video complexity measures, and\nCLIP-based semantic embeddings. Our results demonstrate that LiteVPNet achieves\nmean VMAF errors below 1.2 points across a wide range of quality targets.\nNotably, LiteVPNet achieves VMAF errors within 2 points for over 87% of our\ntest corpus, c.f. approx 61% with state-of-the-art methods. LiteVPNet's\nperformance across various quality regions highlights its applicability for\nenhancing high-value content transport and streaming for more energy-efficient,\nhigh-quality media experiences.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edcLiteVPNet\uff0c\u7528\u4e8e\u9884\u6d4bNVENC AV1\u7f16\u7801\u5668\u7684\u91cf\u5316\u53c2\u6570\uff0c\u4ee5\u5b9e\u73b0\u6307\u5b9a\u7684VMAF\u8d28\u91cf\u5206\u6570\uff0c\u6ee1\u8db3\u7535\u5f71\u5236\u4f5c\u4e2d\u7cbe\u786e\u8d28\u91cf\u63a7\u5236\u548c\u80fd\u6548\u9700\u6c42\u3002", "motivation": "\u7535\u5f71\u5236\u4f5c\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u89c6\u9891\u5de5\u4f5c\u6d41\u7a0b\uff08\u5982\u73b0\u573a\u865a\u62df\u5236\u4f5c\uff09\u9700\u8981\u7cbe\u786e\u7684\u8d28\u91cf\u63a7\u5236\u548c\u80fd\u6548\uff0c\u73b0\u6709\u8f6c\u7801\u65b9\u6cd5\u5728\u8d28\u91cf\u63a7\u5236\u6216\u8ba1\u7b97\u5f00\u9500\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edcLiteVPNet\uff0c\u7ed3\u5408\u4f4e\u590d\u6742\u5ea6\u7279\u5f81\uff08\u5305\u62ec\u6bd4\u7279\u6d41\u7279\u6027\u3001\u89c6\u9891\u590d\u6742\u5ea6\u6d4b\u91cf\u548c\u57fa\u4e8eCLIP\u7684\u8bed\u4e49\u5d4c\u5165\uff09\u6765\u9884\u6d4b\u91cf\u5316\u53c2\u6570\u3002", "result": "LiteVPNet\u5728\u5e7f\u6cdb\u7684\u8d28\u91cf\u76ee\u6807\u8303\u56f4\u5185\u5b9e\u73b0\u5e73\u5747VMAF\u8bef\u5dee\u4f4e\u4e8e1.2\u5206\uff0c87%\u7684\u6d4b\u8bd5\u8bed\u6599VMAF\u8bef\u5dee\u57282\u5206\u4ee5\u5185\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u7ea661%\u3002", "conclusion": "LiteVPNet\u5728\u5404\u79cd\u8d28\u91cf\u533a\u57df\u7684\u8868\u73b0\u7a81\u51fa\u4e86\u5176\u5728\u589e\u5f3a\u9ad8\u4ef7\u503c\u5185\u5bb9\u4f20\u8f93\u548c\u6d41\u5a92\u4f53\u65b9\u9762\u7684\u9002\u7528\u6027\uff0c\u5b9e\u73b0\u66f4\u8282\u80fd\u3001\u9ad8\u8d28\u91cf\u7684\u5a92\u4f53\u4f53\u9a8c\u3002"}}
{"id": "2510.12366", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.12366", "abs": "https://arxiv.org/abs/2510.12366", "authors": ["Zheyu Wu", "Matteo Nerini", "Bruno Clerckx"], "title": "Beyond-Diagonal RIS Architecture Design and Optimization under Physics-Consistent Models", "comment": "13 pages, 5 figures, submitted for possible publication", "summary": "Reconfigurable intelligent surface (RIS) is a promising technology for future\nwireless communication systems. Conventional RIS is constrained to a diagonal\nscattering matrix, which limits its flexibility. Recently, beyond-diagonal RIS\n(BD-RIS) has been proposed as a more general RIS architecture class that allows\ninter-element connections and shows great potential for performance\nimprovement. Despite extensive progress on BD-RIS, most existing studies rely\non simplified channel models that ignore practical electromagnetic (EM) effects\nsuch as mutual coupling and impedance mismatching. To address this gap, this\npaper investigates the architecture design and optimization of BD-RIS under the\ngeneral physics-consistent model derived with multiport network theory in\nrecent literature. Building on a compact reformulation of this model, we show\nthat band-connected RIS achieves the same channel-shaping capability as\nfully-connected RIS, which extends existing results obtained for conventional\nchannel models. We then develop optimization methods under the general\nphysics-consistent model; specifically, we derive closed-form solutions for\nsingle-input single-output (SISO) systems, propose a globally optimal\nsemidefinite relaxation (SDR)-based algorithm for single-stream multi-input\nmulti-output (MIMO) systems, and design an efficient alternating direction\nmethod of multipliers (ADMM)-based algorithm for multiuser MIMO systems. Using\nthe proposed algorithms, we conduct comprehensive simulations to evaluate the\nimpact of various EM effects and approximations, including mutual coupling\namong RIS antennas and the commonly adopted unilateral approximation, on system\nperformance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u7269\u7406\u4e00\u81f4\u6a21\u578b\u7684\u5bf9\u89d2\u7ebf\u5916\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08BD-RIS\uff09\u67b6\u6784\u8bbe\u8ba1\u4e0e\u4f18\u5316\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u7535\u78c1\u6548\u5e94\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709BD-RIS\u7814\u7a76\u5927\u591a\u4f9d\u8d56\u7b80\u5316\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u5b9e\u9645\u7535\u78c1\u6548\u5e94\u5982\u4e92\u8026\u548c\u963b\u6297\u5931\u914d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u5728\u7269\u7406\u4e00\u81f4\u6a21\u578b\u4e0b\u7814\u7a76BD-RIS\u7684\u67b6\u6784\u8bbe\u8ba1\u4e0e\u4f18\u5316\u3002", "method": "\u57fa\u4e8e\u591a\u7aef\u53e3\u7f51\u7edc\u7406\u8bba\u6784\u5efa\u7269\u7406\u4e00\u81f4\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u591a\u79cd\u4f18\u5316\u65b9\u6cd5\uff1a\u9488\u5bf9SISO\u7cfb\u7edf\u7684\u95ed\u5f0f\u89e3\u3001\u9488\u5bf9\u5355\u6d41MIMO\u7cfb\u7edf\u7684SDR\u5168\u5c40\u6700\u4f18\u7b97\u6cd5\u3001\u9488\u5bf9\u591a\u7528\u6237MIMO\u7cfb\u7edf\u7684ADMM\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e26\u72b6\u8fde\u63a5RIS\u4e0e\u5168\u8fde\u63a5RIS\u5177\u6709\u76f8\u540c\u7684\u4fe1\u9053\u6574\u5f62\u80fd\u529b\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u4fe1\u9053\u6a21\u578b\u4e0b\u7684\u73b0\u6709\u7ed3\u679c\u3002\u901a\u8fc7\u4eff\u771f\u8bc4\u4f30\u4e86\u5404\u79cd\u7535\u78c1\u6548\u5e94\u548c\u8fd1\u4f3c\u65b9\u6cd5\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u5728\u7269\u7406\u4e00\u81f4\u6a21\u578b\u4e0b\uff0cBD-RIS\u67b6\u6784\u8bbe\u8ba1\u4e0e\u4f18\u5316\u80fd\u591f\u6709\u6548\u8003\u8651\u5b9e\u9645\u7535\u78c1\u6548\u5e94\uff0c\u63d0\u51fa\u7684\u4f18\u5316\u7b97\u6cd5\u5728\u4e0d\u540c\u7cfb\u7edf\u914d\u7f6e\u4e0b\u5747\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2510.11925", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.11925", "abs": "https://arxiv.org/abs/2510.11925", "authors": ["Yanan Du", "Zeyang Sun", "Yilan Zhang", "Sai Xu", "Beiyuan Liu"], "title": "Using STAR-IRS to Secure Indoor Communications Through Symbol-Level Random Phase Modulation", "comment": null, "summary": "This paper proposes a secure indoor communication scheme based on\nsimultaneous transmitting and reflecting intelligent reflecting surface\n(STAR-IRS). Specifically, a transmitter (Alice) sends confidential information\nto its intended user (Bob) indoors, while several eavesdroppers (Eves) lurk\noutside. To safeguard the transmission from eavesdropping, the STAR-IRS is\ndeployed on walls or windows. Upon impinging on the STAR-IRS, the incoming\nelectromagnetic wave is dynamically partitioned into two components, enabling\nboth transmission through and reflection from the surface. The reflected signal\nis controlled to enhance reception at Bob, while the transmitted signal is\nmodulated with symbol-level random phase shifts to degrade the signal quality\nat Eves. Based on such a setting, the secrecy rate maximization problem is\nformulated. To solve it, a graph neural network (GNN)-based scheme is\ndeveloped. Furthermore, a field-programmable gate array (FPGA)-based GNN\naccelerator is designed to reduce computational latency. Simulation results\ndemonstrate that the proposed strategy outperforms both the conventional scheme\nand the reflection-only scheme in terms of secrecy performance. Moreover, the\nGNN-based approach achieves superior results compared to benchmark techniques\nsuch as maximum ratio transmission (MRT), zero forcing (ZF), and minimum mean\nsquare error (MMSE) in solving the optimization problem. Finally, experimental\nevaluations confirm that the FPGA-based accelerator enables low inference\nlatency.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSTAR-IRS\u7684\u5b89\u5168\u5ba4\u5185\u901a\u4fe1\u65b9\u6848\uff0c\u4f7f\u7528GNN\u4f18\u5316\u4fdd\u5bc6\u7387\uff0c\u5e76\u901a\u8fc7FPGA\u52a0\u901f\u5668\u964d\u4f4e\u8ba1\u7b97\u5ef6\u8fdf", "motivation": "\u4fdd\u62a4\u5ba4\u5185\u7528\u6237\u4e0e\u53d1\u5c04\u5668\u4e4b\u95f4\u7684\u4fdd\u5bc6\u901a\u4fe1\uff0c\u9632\u6b62\u5ba4\u5916\u7a83\u542c\u8005\u7a83\u542c\u4fe1\u606f", "method": "\u90e8\u7f72STAR-IRS\u5728\u5899\u58c1\u6216\u7a97\u6237\u4e0a\uff0c\u5c06\u7535\u78c1\u6ce2\u52a8\u6001\u5206\u4e3a\u53cd\u5c04\u548c\u900f\u5c04\u4e24\u90e8\u5206\uff1a\u53cd\u5c04\u4fe1\u53f7\u589e\u5f3a\u76ee\u6807\u7528\u6237\u63a5\u6536\uff0c\u900f\u5c04\u4fe1\u53f7\u901a\u8fc7\u7b26\u53f7\u7ea7\u968f\u673a\u76f8\u4f4d\u8c03\u5236\u964d\u4f4e\u7a83\u542c\u8005\u4fe1\u53f7\u8d28\u91cf\uff1b\u4f7f\u7528GNN\u6c42\u89e3\u4fdd\u5bc6\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1FPGA\u52a0\u901f\u5668", "result": "\u4eff\u771f\u663e\u793a\u8be5\u65b9\u6848\u5728\u4fdd\u5bc6\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\u548c\u4ec5\u53cd\u5c04\u65b9\u6848\uff1bGNN\u65b9\u6cd5\u5728\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u65f6\u4f18\u4e8eMRT\u3001ZF\u548cMMSE\u57fa\u51c6\u6280\u672f\uff1bFPGA\u52a0\u901f\u5668\u5b9e\u73b0\u4e86\u4f4e\u63a8\u7406\u5ef6\u8fdf", "conclusion": "STAR-IRS\u7ed3\u5408GNN\u4f18\u5316\u548cFPGA\u52a0\u901f\u662f\u6709\u6548\u7684\u5b89\u5168\u5ba4\u5185\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u663e\u8457\u63d0\u5347\u4fdd\u5bc6\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u5ef6\u8fdf"}}
{"id": "2510.12380", "categories": ["eess.IV", "cs.MM", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12380", "abs": "https://arxiv.org/abs/2510.12380", "authors": ["Vibhoothi Vibhoothi", "Julien Zouein", "Shanker Shreejith", "Jean-Baptiste Kempf", "Anil Kokaram"], "title": "An Empirical Study of Reducing AV1 Decoder Complexity and Energy Consumption via Encoder Parameter Tuning", "comment": "Accepted Camera-Ready paper for PCS 2025, 5 Pages", "summary": "The widespread adoption of advanced video codecs such as AV1 is often\nhindered by their high decoding complexity, posing a challenge for\nbattery-constrained devices. While encoders can be configured to produce\nbitstreams that are decoder-friendly, estimating the decoding complexity and\nenergy overhead for a given video is non-trivial. In this study, we\nsystematically analyse the impact of disabling various coding tools and\nadjusting coding parameters in two AV1 encoders, libaom-av1 and SVT-AV1. Using\nsystem-level energy measurement tools like RAPL (Running Average Power Limit),\nIntel SoC Watch (integrated with VTune profiler), we quantify the resulting\ntrade-offs between decoding complexity, energy consumption, and compression\nefficiency for decoding a bitstream. Our results demonstrate that specific\nencoder configurations can substantially reduce decoding complexity with\nminimal perceptual quality degradation. For libaom-av1, disabling CDEF, an\nin-loop filter gives us a mean reduction in decoding cycles by 10%. For\nSVT-AV1, using the in-built, fast-decode=2 preset achieves a more substantial\n24% reduction in decoding cycles. These findings provide strategies for content\nproviders to lower the energy footprint of AV1 video streaming.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86AV1\u7f16\u7801\u5668\u4e2d\u7981\u7528\u4e0d\u540c\u7f16\u7801\u5de5\u5177\u548c\u8c03\u6574\u53c2\u6570\u5bf9\u89e3\u7801\u590d\u6742\u5ea6\u3001\u80fd\u8017\u548c\u538b\u7f29\u6548\u7387\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7279\u5b9a\u914d\u7f6e\u53ef\u663e\u8457\u964d\u4f4e\u89e3\u7801\u590d\u6742\u5ea6\u4e14\u5bf9\u611f\u77e5\u8d28\u91cf\u5f71\u54cd\u5f88\u5c0f\u3002", "motivation": "AV1\u7b49\u5148\u8fdb\u89c6\u9891\u7f16\u89e3\u7801\u5668\u7684\u9ad8\u89e3\u7801\u590d\u6742\u5ea6\u963b\u788d\u4e86\u5176\u5728\u7535\u6c60\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u627e\u5230\u964d\u4f4e\u89e3\u7801\u80fd\u8017\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528libaom-av1\u548cSVT-AV1\u4e24\u4e2aAV1\u7f16\u7801\u5668\uff0c\u7cfb\u7edf\u6027\u5730\u7981\u7528\u5404\u79cd\u7f16\u7801\u5de5\u5177\u5e76\u8c03\u6574\u7f16\u7801\u53c2\u6570\uff0c\u5229\u7528RAPL\u548cIntel SoC Watch\u7b49\u7cfb\u7edf\u7ea7\u80fd\u8017\u6d4b\u91cf\u5de5\u5177\u91cf\u5316\u89e3\u7801\u590d\u6742\u5ea6\u3001\u80fd\u8017\u548c\u538b\u7f29\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5bf9\u4e8elibaom-av1\uff0c\u7981\u7528CDEF\u73af\u8def\u6ee4\u6ce2\u5668\u53ef\u4f7f\u89e3\u7801\u5468\u671f\u5e73\u5747\u51cf\u5c1110%\uff1b\u5bf9\u4e8eSVT-AV1\uff0c\u4f7f\u7528\u5185\u7f6e\u7684fast-decode=2\u9884\u8bbe\u53ef\u5b9e\u73b0\u66f4\u663e\u8457\u768424%\u89e3\u7801\u5468\u671f\u51cf\u5c11\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5185\u5bb9\u63d0\u4f9b\u5546\u63d0\u4f9b\u4e86\u964d\u4f4eAV1\u89c6\u9891\u6d41\u5a92\u4f53\u80fd\u8017\u7684\u7b56\u7565\uff0c\u7279\u5b9a\u7f16\u7801\u5668\u914d\u7f6e\u53ef\u5927\u5e45\u964d\u4f4e\u89e3\u7801\u590d\u6742\u5ea6\u4e14\u5bf9\u611f\u77e5\u8d28\u91cf\u5f71\u54cd\u5f88\u5c0f\u3002"}}
{"id": "2510.11994", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.11994", "abs": "https://arxiv.org/abs/2510.11994", "authors": ["Yinan Wang", "Byeongjin Kim", "Nishanth Ravi", "Kapil Saha", "Supratik Dasgupta", "Vakhtang Chulukhadze", "Eugene Kwon", "Lezli Matto", "Pietro Simeoni", "Omar Barrera", "Ian Anderson", "Tzu-Hsuan Hsu", "Jue Hou", "Matteo Rinaldi", "Mark S. Goorsky", "Ruochen Lu"], "title": "62.6 GHz ScAlN Solidly Mounted Acoustic Resonators", "comment": "6 Pages, 7 Figures, 3 Tables", "summary": "We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator\n(SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N)\npiezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode,\npositioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2\nnm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and\npiezoelectric stack above are designed to confine a third-order\nthickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently\ntransducing with thickness-field excitation. The fabricated SMR exhibits an\nextracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode\nquality factor (Q) of 51 at 63 GHz, representing the highest operating\nfrequency reported for an SMR to date. These results establish a pathway toward\nmmWave SMR devices for filters and resonators in next-generation RF front ends.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u521b\u7eaa\u5f55\u768462.6 GHz\u56fa\u6001\u5b89\u88c5\u58f0\u5b66\u8c10\u632f\u5668\uff0c\u91c7\u752867.6 nm\u94aa\u94dd\u6c2e\u5316\u7269\u538b\u7535\u5c42\u548c40 nm\u94c2\u5e95\u7535\u6781\uff0c\u5728\u58f0\u5b66\u5e03\u62c9\u683c\u53cd\u5c04\u5668\u4e0a\u5b9e\u73b0\u7b2c\u4e09\u9636\u539a\u5ea6\u4f38\u7f29\u4f53\u58f0\u6ce2\u6a21\u5f0f\u3002", "motivation": "\u5f00\u53d1\u7528\u4e8e\u4e0b\u4e00\u4ee3\u5c04\u9891\u524d\u7aef\u7684\u6beb\u7c73\u6ce2SMR\u5668\u4ef6\uff0c\u4e3a\u6ee4\u6ce2\u5668\u548c\u8c10\u632f\u5668\u63d0\u4f9b\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u752867.6 nm Sc0.3Al0.7N\u538b\u7535\u5c42\u548c40 nm Pt\u5e95\u7535\u6781\uff0c\u57288.5\u5bf9\u4ea4\u66ffSiO2/Ta2O5\u5c42\u6784\u6210\u7684\u58f0\u5b66\u5e03\u62c9\u683c\u53cd\u5c04\u5668\u4e0a\u8bbe\u8ba1\u7b2c\u4e09\u9636\u539a\u5ea6\u4f38\u7f29\u4f53\u58f0\u6ce2\u6a21\u5f0f\u3002", "result": "\u5236\u9020\u7684SMR\u572863 GHz\u5904\u63d0\u53d6\u7684\u538b\u7535\u8026\u5408\u7cfb\u6570\u4e3a0.8%\uff0c\u6700\u5927Bode\u54c1\u8d28\u56e0\u5b50\u4e3a51\uff0c\u662f\u76ee\u524d\u62a5\u9053\u7684\u6700\u9ad8\u5de5\u4f5c\u9891\u7387SMR\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u6beb\u7c73\u6ce2SMR\u5668\u4ef6\u5728\u4e0b\u4e00\u4ee3\u5c04\u9891\u524d\u7aef\u4e2d\u7684\u5e94\u7528\u5efa\u7acb\u4e86\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2510.12479", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.12479", "abs": "https://arxiv.org/abs/2510.12479", "authors": ["Huu-Tai Phung", "Zong-Lin Gao", "Yi-Chen Yao", "Kuan-Wei Ho", "Yi-Hsin Chen", "Yu-Hsiang Lin", "Alessandro Gnutti", "Wen-Hsiao Peng"], "title": "MH-LVC: Multi-Hypothesis Temporal Prediction for Learned Conditional Residual Video Coding", "comment": null, "summary": "This work, termed MH-LVC, presents a multi-hypothesis temporal prediction\nscheme that employs long- and short-term reference frames in a conditional\nresidual video coding framework. Recent temporal context mining approaches to\nconditional video coding offer superior coding performance. However, the need\nto store and access a large amount of implicit contextual information extracted\nfrom past decoded frames in decoding a video frame poses a challenge due to\nexcessive memory access. Our MH-LVC overcomes this issue by storing multiple\nlong- and short-term reference frames but limiting the number of reference\nframes used at a time for temporal prediction to two. Our decoded frame buffer\nmanagement allows the encoder to flexibly utilize the long-term key frames to\nmitigate temporal cascading errors and the short-term reference frames to\nminimize prediction errors. Moreover, our buffering scheme enables the temporal\nprediction structure to be adapted to individual input videos. While this\nflexibility is common in traditional video codecs, it has not been fully\nexplored for learned video codecs. Extensive experiments show that the proposed\nmethod outperforms VTM-17.0 under the low-delay B configuration in terms of\nPSNR-RGB across commonly used test datasets, and performs comparably to the\nstate-of-the-art learned codecs (e.g.~DCVC-FM) while requiring less decoded\nframe buffer and similar decoding time.", "AI": {"tldr": "MH-LVC\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5047\u8bbe\u65f6\u95f4\u9884\u6d4b\u65b9\u6848\uff0c\u4f7f\u7528\u957f\u77ed\u65f6\u53c2\u8003\u5e27\u8fdb\u884c\u6761\u4ef6\u6b8b\u5dee\u89c6\u9891\u7f16\u7801\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5185\u5b58\u8bbf\u95ee\u8fc7\u591a\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6761\u4ef6\u89c6\u9891\u7f16\u7801\u65b9\u6cd5\u9700\u8981\u5b58\u50a8\u5927\u91cf\u9690\u5f0f\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u5185\u5b58\u8bbf\u95ee\u8fc7\u591a\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u591a\u5047\u8bbe\u65f6\u95f4\u9884\u6d4b\uff0c\u9650\u5236\u540c\u65f6\u4f7f\u7528\u7684\u53c2\u8003\u5e27\u6570\u91cf\u4e3a2\u4e2a\uff0c\u901a\u8fc7\u89e3\u7801\u5e27\u7f13\u51b2\u533a\u7ba1\u7406\u7075\u6d3b\u5229\u7528\u957f\u77ed\u65f6\u53c2\u8003\u5e27\u3002", "result": "\u5728\u4f4e\u5ef6\u8fdfB\u914d\u7f6e\u4e0b\uff0cPSNR-RGB\u6027\u80fd\u4f18\u4e8eVTM-17.0\uff0c\u4e0eDCVC-FM\u7b49\u5148\u8fdb\u5b66\u4e60\u7f16\u89e3\u7801\u5668\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u9700\u8981\u66f4\u5c11\u7684\u89e3\u7801\u5e27\u7f13\u51b2\u533a\u548c\u76f8\u4f3c\u7684\u89e3\u7801\u65f6\u95f4\u3002", "conclusion": "MH-LVC\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u6709\u6548\u51cf\u5c11\u4e86\u5185\u5b58\u9700\u6c42\uff0c\u4e3a\u5b66\u4e60\u89c6\u9891\u7f16\u89e3\u7801\u5668\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.12179", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12179", "abs": "https://arxiv.org/abs/2510.12179", "authors": ["Abdullahi Mohammad", "Bdah Eya", "Bassant Selim"], "title": "A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation", "comment": "6, 5", "summary": "Impulsive noise poses a significant challenge to the reliability of wireless\ncommunication systems, necessitating accurate estimation of its statistical\nparameters for effective mitigation. This paper introduces a multitask learning\n(MTL) framework based on a CNN-LSTM architecture enhanced with an attention\nmechanism for the joint estimation of impulsive noise parameters. The proposed\nmodel leverages a unified weighted-loss function to enable simultaneous\nlearning of multiple parameters within a shared representation space, improving\nlearning efficiency and generalization across related tasks. Experimental\nresults show that the proposed MTL framework achieves stable convergence,\nfaster training, and enhanced scalability with modest computational overhead.\nBenchmarking against conventional single-task learning (STL) models confirms\nits favorable complexity-performance trade-off and significant memory savings,\nindicating the effectiveness of the MTL approach for real-time impulsive noise\nparameter estimation in wireless systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCNN-LSTM\u67b6\u6784\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u8054\u5408\u4f30\u8ba1\u8109\u51b2\u566a\u58f0\u53c2\u6570\uff0c\u901a\u8fc7\u7edf\u4e00\u52a0\u6743\u635f\u5931\u51fd\u6570\u5b9e\u73b0\u591a\u53c2\u6570\u540c\u65f6\u5b66\u4e60\u3002", "motivation": "\u8109\u51b2\u566a\u58f0\u4e25\u91cd\u5f71\u54cd\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u5176\u7edf\u8ba1\u53c2\u6570\u4ee5\u5b9e\u73b0\u6709\u6548\u6291\u5236\u3002", "method": "\u4f7f\u7528CNN-LSTM\u67b6\u6784\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u96c6\u6210\u6ce8\u610f\u529b\u673a\u5236\uff0c\u91c7\u7528\u7edf\u4e00\u52a0\u6743\u635f\u5931\u51fd\u6570\u5728\u5171\u4eab\u8868\u793a\u7a7a\u95f4\u4e2d\u540c\u65f6\u5b66\u4e60\u591a\u4e2a\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u5b9e\u73b0\u7a33\u5b9a\u6536\u655b\u3001\u66f4\u5feb\u8bad\u7ec3\u548c\u589e\u5f3a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e0e\u5355\u4efb\u52a1\u5b66\u4e60\u6a21\u578b\u76f8\u6bd4\u5177\u6709\u66f4\u597d\u7684\u590d\u6742\u5ea6-\u6027\u80fd\u6743\u8861\u548c\u663e\u8457\u5185\u5b58\u8282\u7701\u3002", "conclusion": "\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u5728\u65e0\u7ebf\u7cfb\u7edf\u5b9e\u65f6\u8109\u51b2\u566a\u58f0\u53c2\u6570\u4f30\u8ba1\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002"}}
{"id": "2510.12754", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12754", "abs": "https://arxiv.org/abs/2510.12754", "authors": ["Diwakara Reddy", "Christian Herglotz", "Andr\u00e9 Kaup"], "title": "A High-Level Feature Model to Predict the Encoding Energy of a Hardware Video Encoder", "comment": "Accepted for Picture Coding Symposium (PCS) 2025", "summary": "In today's society, live video streaming and user generated content streamed\nfrom battery powered devices are ubiquitous. Live streaming requires real-time\nvideo encoding, and hardware video encoders are well suited for such an\nencoding task. In this paper, we introduce a high-level feature model using\nGaussian process regression that can predict the encoding energy of a hardware\nvideo encoder. In an evaluation setup restricted to only P-frames and a single\nkeyframe, the model can predict the encoding energy with a mean absolute\npercentage error of approximately 9%. Further, we demonstrate with an ablation\nstudy that spatial resolution is a key high-level feature for encoding energy\nprediction of a hardware encoder. A practical application of our model is that\nit can be used to perform a prior estimation of the energy required to encode a\nvideo at various spatial resolutions, with different coding standards and codec\npresets.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u9ad8\u5c42\u7279\u5f81\u6a21\u578b\u6765\u9884\u6d4b\u786c\u4ef6\u89c6\u9891\u7f16\u7801\u5668\u7684\u7f16\u7801\u80fd\u8017\uff0c\u5728\u4ec5\u4f7f\u7528P\u5e27\u548c\u5355\u4e2a\u5173\u952e\u5e27\u7684\u8bc4\u4f30\u4e2d\uff0c\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u7ea6\u4e3a9%\u3002", "motivation": "\u968f\u7740\u7535\u6c60\u4f9b\u7535\u8bbe\u5907\u7684\u5b9e\u65f6\u89c6\u9891\u76f4\u64ad\u548c\u7528\u6237\u751f\u6210\u5185\u5bb9\u666e\u53ca\uff0c\u9700\u8981\u5b9e\u65f6\u89c6\u9891\u7f16\u7801\uff0c\u800c\u786c\u4ef6\u7f16\u7801\u5668\u9002\u5408\u6b64\u7c7b\u4efb\u52a1\uff0c\u4f46\u9700\u8981\u9884\u6d4b\u5176\u7f16\u7801\u80fd\u8017\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6784\u5efa\u9ad8\u5c42\u7279\u5f81\u6a21\u578b\u6765\u9884\u6d4b\u786c\u4ef6\u89c6\u9891\u7f16\u7801\u5668\u7684\u7f16\u7801\u80fd\u91cf\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u7a7a\u95f4\u5206\u8fa8\u7387\u662f\u5173\u952e\u7279\u5f81\u3002", "result": "\u5728\u4ec5\u4f7f\u7528P\u5e27\u548c\u5355\u4e2a\u5173\u952e\u5e27\u7684\u9650\u5236\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\uff0c\u6a21\u578b\u9884\u6d4b\u7f16\u7801\u80fd\u91cf\u7684\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u7ea6\u4e3a9%\uff0c\u7a7a\u95f4\u5206\u8fa8\u7387\u88ab\u8bc1\u660e\u662f\u7f16\u7801\u80fd\u91cf\u9884\u6d4b\u7684\u5173\u952e\u7279\u5f81\u3002", "conclusion": "\u8be5\u6a21\u578b\u53ef\u7528\u4e8e\u5728\u5b9e\u9645\u7f16\u7801\u524d\u4f30\u7b97\u4e0d\u540c\u7a7a\u95f4\u5206\u8fa8\u7387\u3001\u7f16\u7801\u6807\u51c6\u548c\u7f16\u89e3\u7801\u5668\u9884\u8bbe\u4e0b\u89c6\u9891\u7f16\u7801\u6240\u9700\u7684\u80fd\u91cf\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.12204", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12204", "abs": "https://arxiv.org/abs/2510.12204", "authors": ["Zhen Du", "Jingjing Xu", "Yifeng Xiong", "Jie Wang", "Musa Furkan Keskin", "Henk Wymeersch", "Fan Liu", "Shi Jin"], "title": "Probabilistic Constellation Shaping for OFDM ISAC Signals Under Temporal-Frequency Filtering", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Integrated sensing and communications (ISAC) is considered an innovative\ntechnology in sixth-generation (6G) wireless networks, where utilizing\northogonal frequency division multiplexing (OFDM) communication signals for\nsensing provides a cost-effective solution for implementing ISAC. However, the\nsensing performance of matched and mismatched filtering schemes can be\nsignificantly deteriorated due to the signaling randomness induced by\nfinite-alphabet modulations with nonconstant modulus, such as quadrature\namplitude modulation (QAM) constellations. Therefore, improving sensing\nperformance without significantly compromising communication capability (i.e.,\nmaintaining randomness), remains a challenging task. To that end, we propose a\nunified probabilistic constellation shaping (PCS) framework that is compatible\nwith both matched and mismatched filtering schemes, by maximizing the\ncommunication rate while imposing constraints on mean square error (MSE) of\nsensing channel state information (CSI), power, and probability distribution.\nSpecifically, the MSE of sensing CSI is leveraged to optimize sensing\ncapability, which is illustrated to be a more comprehensive metric compared to\nthe output SNR after filtering (SNRout) and integrated sidelobes ratio (ISLR).\nAdditionally, the internal relationships among these three sensing metrics are\nexplicitly analyzed. Finally, both simulations and field measurements validate\nthe efficiency of proposed PCS approach in achieving a flexible S&C trade-off,\nas well as its credibility in enhancing 6G wireless transmission in real-world\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6982\u7387\u661f\u5ea7\u6574\u5f62\u6846\u67b6\uff0c\u7528\u4e8e\u57286G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5e73\u8861\u901a\u4fe1\u901f\u7387\u548c\u611f\u77e5\u6027\u80fd\uff0c\u901a\u8fc7\u4f18\u5316\u901a\u4fe1\u901f\u7387\u540c\u65f6\u7ea6\u675f\u611f\u77e5CSI\u7684\u5747\u65b9\u8bef\u5dee\u3001\u529f\u7387\u548c\u6982\u7387\u5206\u5e03\u6765\u5b9e\u73b0\u7075\u6d3b\u7684\u611f\u77e5\u4e0e\u901a\u4fe1\u6743\u8861\u3002", "motivation": "\u57286G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u4f7f\u7528OFDM\u901a\u4fe1\u4fe1\u53f7\u8fdb\u884c\u611f\u77e5\u867d\u7136\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u4f46\u6709\u9650\u5b57\u6bcd\u8c03\u5236\uff08\u5982QAM\uff09\u5f15\u5165\u7684\u968f\u673a\u6027\u4f1a\u663e\u8457\u964d\u4f4e\u5339\u914d\u548c\u4e0d\u5339\u914d\u6ee4\u6ce2\u65b9\u6848\u7684\u611f\u77e5\u6027\u80fd\uff0c\u9700\u8981\u5728\u4fdd\u6301\u901a\u4fe1\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u611f\u77e5\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u6982\u7387\u661f\u5ea7\u6574\u5f62\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u901a\u4fe1\u901f\u7387\u540c\u65f6\u7ea6\u675f\u611f\u77e5\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u5747\u65b9\u8bef\u5dee\u3001\u529f\u7387\u548c\u6982\u7387\u5206\u5e03\uff0c\u4f18\u5316\u611f\u77e5\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u517c\u5bb9\u5339\u914d\u548c\u4e0d\u5339\u914d\u6ee4\u6ce2\u65b9\u6848\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u611f\u77e5\u5ea6\u91cf\u4e4b\u95f4\u7684\u5185\u5728\u5173\u7cfb\u3002", "result": "\u4eff\u771f\u548c\u73b0\u573a\u6d4b\u91cf\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684PCS\u65b9\u6cd5\u5728\u5b9e\u73b0\u7075\u6d3b\u611f\u77e5\u4e0e\u901a\u4fe1\u6743\u8861\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u5728\u771f\u5b9e6G\u65e0\u7ebf\u4f20\u8f93\u573a\u666f\u4e2d\u589e\u5f3a\u6027\u80fd\u7684\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u8be5\u6982\u7387\u661f\u5ea7\u6574\u5f62\u6846\u67b6\u4e3a6G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u901a\u4fe1\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u611f\u77e5\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u9a8c\u8bc1\u8bc1\u660e\u4e86\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.12279", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12279", "abs": "https://arxiv.org/abs/2510.12279", "authors": ["Benedikt B\u00f6ck", "Amar Kasibovic", "Wolfgang Utschick"], "title": "Wireless Channel Modeling for Machine Learning -- A Critical View on Standardized Channel Models", "comment": null, "summary": "Standardized (link-level) channel models such as the 3GPP TDL and CDL models\nare frequently used to evaluate machine learning (ML)-based physical-layer\nmethods. However, in this work, we argue that a link-level perspective\nincorporates limiting assumptions, causing unwanted distributional shifts or\nnecessitating impractical online training. An additional drawback is that this\nperspective leads to (near-)Gaussian channel characteristics. Thus, ML-based\nmodels, trained on link-level channel data, do not outperform classical\napproaches for a variety of physical-layer applications. Particularly, we\ndemonstrate the optimality of simple linear methods for channel compression,\nestimation, and modeling, revealing the unsuitability of link-level channel\nmodels for evaluating ML models. On the upside, adopting a scenario-level\nperspective offers a solution to this problem and unlocks the relative gains\nenabled by ML.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa3GPP TDL\u548cCDL\u7b49\u6807\u51c6\u5316\u94fe\u8def\u7ea7\u4fe1\u9053\u6a21\u578b\u5728\u8bc4\u4f30\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7269\u7406\u5c42\u65b9\u6cd5\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f1a\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\u548c\u8fd1\u9ad8\u65af\u7279\u6027\uff0c\u4f7f\u5f97ML\u6a21\u578b\u65e0\u6cd5\u8d85\u8d8a\u7ecf\u5178\u65b9\u6cd5\u3002\u91c7\u7528\u573a\u666f\u7ea7\u89c6\u89d2\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6807\u51c6\u5316\u94fe\u8def\u7ea7\u4fe1\u9053\u6a21\u578b\u5728\u8bc4\u4f30ML\u7269\u7406\u5c42\u65b9\u6cd5\u65f6\u5b58\u5728\u9650\u5236\u6027\u5047\u8bbe\uff0c\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\u548c\u8fd1\u9ad8\u65af\u7279\u6027\uff0c\u4f7f\u5f97ML\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u597d\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u94fe\u8def\u7ea7\u4fe1\u9053\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u8bba\u8bc1\u7ebf\u6027\u65b9\u6cd5\u5728\u4fe1\u9053\u538b\u7f29\u3001\u4f30\u8ba1\u548c\u5efa\u6a21\u4e2d\u7684\u6700\u4f18\u6027\uff0c\u5e76\u63d0\u51fa\u91c7\u7528\u573a\u666f\u7ea7\u89c6\u89d2\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7814\u7a76\u8868\u660e\u5728\u94fe\u8def\u7ea7\u4fe1\u9053\u6a21\u578b\u4e0b\uff0cML\u6a21\u578b\u65e0\u6cd5\u8d85\u8d8a\u7ecf\u5178\u7ebf\u6027\u65b9\u6cd5\uff0c\u800c\u573a\u666f\u7ea7\u89c6\u89d2\u80fd\u591f\u89e3\u9501ML\u7684\u76f8\u5bf9\u589e\u76ca\u3002", "conclusion": "\u94fe\u8def\u7ea7\u4fe1\u9053\u6a21\u578b\u4e0d\u9002\u5408\u8bc4\u4f30ML\u6a21\u578b\uff0c\u5e94\u91c7\u7528\u573a\u666f\u7ea7\u89c6\u89d2\u6765\u5145\u5206\u53d1\u6325ML\u5728\u7269\u7406\u5c42\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.12315", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12315", "abs": "https://arxiv.org/abs/2510.12315", "authors": ["Piyush Priyanshu", "Sudhan Majhi", "Subhabrata Paul"], "title": "A New Method of Constructing Hadamard Matrices, Circulant Hadamard Matrices, CZCS, GCS, CCC, and CZCSS", "comment": null, "summary": "A Hadamard matrix $H$ is a square matrix of order $n$ with entries $\\pm 1$,\nsuch that $HH^\\top=nI_{n}$, where $I_n$ is an identity matrix of order $n$. A\ncirculant Hadamard matrix $H$ is a Hadamard matrix that has rows of entries in\ncyclic order. There exist only $8$ circulant Hadamard matrices of order 4, and\nhere, we provide a novel construction of all such $8$ circulant Hadamard\nmatrices using a linear operator and generalized Boolean function (GBF). The\nconstructed circulant Hadamard matrices are used recursively to construct a\nbinary cross Z-complementary set (CZCS) of all lengths with an even phase, a\nbinary Golay complementary set (GCS) of all lengths, and Hadamard matrices of\norder $2^{n+2}$, where $n\\geq1$. The construction of a binary CZCS covering all\nlengths was not available before. We also propose an alternative,\nlower-complexity construction of binary GCSs of all lengths and Hadamard\nmatrices of order $2^{a+1}10^b26^c$ using circulant matrices, where $ a,b,c\n\\geq 0$. The proposed binary GCS covers all lengths with a flexible flock size.\nThe constructions of GCS are further extended to form binary complete\ncomplementary code (CCC) of the parameter $(2N,2N,2N)-CCC$ where\n$N=2^a10^b26^c, a,b,c \\geq 0$. The constructed binary CCC provides a flexible\nflock size. The construction of CZCS is further extended to form a binary\noptimal cross-Z complementary sequence set (CZCSS) of the parameter $(2^{n+2},\n2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$, where $n\\geq1$. Finally, we provide a\nrelation between Hadamard matrices and GCS, which enables the study of the\nHadamard conjecture in a new direction. We also provided a few properties of\ncirculant matrices over aperiodic cross-correlation (ACCF) and aperiodic\nauto-correlation (AACF), which are used to prove the theorems. All proposed\nconstructions are novel, and their parameters are compared with the existing\nstate-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u7ebf\u6027\u7b97\u5b50\u548c\u5e7f\u4e49\u5e03\u5c14\u51fd\u6570\u6784\u9020\u6240\u67098\u4e2a4\u9636\u5faa\u73afHadamard\u77e9\u9635\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u77e9\u9635\u9012\u5f52\u6784\u9020\u4e86\u8986\u76d6\u6240\u6709\u957f\u5ea6\u7684\u4e8c\u8fdb\u5236\u4ea4\u53c9Z\u4e92\u8865\u96c6(CZCS)\u3001Golay\u4e92\u8865\u96c6(GCS)\u4ee5\u53caHadamard\u77e9\u9635\u3002", "motivation": "\u4e4b\u524d\u7f3a\u4e4f\u8986\u76d6\u6240\u6709\u957f\u5ea6\u7684\u4e8c\u8fdb\u5236CZCS\u6784\u9020\u65b9\u6cd5\uff0c\u4e14\u9700\u8981\u66f4\u7075\u6d3b\u7684GCS\u6784\u9020\u65b9\u6848\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u4e3aHadamard\u731c\u60f3\u7684\u7814\u7a76\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u7b97\u5b50\u548c\u5e7f\u4e49\u5e03\u5c14\u51fd\u6570\u6784\u9020\u5faa\u73afHadamard\u77e9\u9635\uff0c\u7136\u540e\u9012\u5f52\u6784\u9020CZCS\u3001GCS\u548cHadamard\u77e9\u9635\u3002\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u5faa\u73af\u77e9\u9635\u7684\u4f4e\u590d\u6742\u5ea6\u66ff\u4ee3\u6784\u9020\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u6784\u9020\u4e86\u6240\u67098\u4e2a4\u9636\u5faa\u73afHadamard\u77e9\u9635\uff0c\u5b9e\u73b0\u4e86\u8986\u76d6\u6240\u6709\u957f\u5ea6\u7684\u4e8c\u8fdb\u5236CZCS\uff08\u9996\u6b21\u5b9e\u73b0\uff09\u3001\u5177\u6709\u7075\u6d3b\u7fa4\u5927\u5c0f\u7684GCS\uff0c\u4ee5\u53ca\u53c2\u6570\u4e3a(2N,2N,2N)-CCC\u7684\u4e8c\u8fdb\u5236\u5b8c\u5168\u4e92\u8865\u7801\u548c(2^{n+2},2^{n+2},2^{n+2},2^{n+1})-CZCSS\u7684\u6700\u4f18\u4ea4\u53c9Z\u4e92\u8865\u5e8f\u5217\u96c6\u3002", "conclusion": "\u6240\u6709\u63d0\u51fa\u7684\u6784\u9020\u65b9\u6cd5\u90fd\u662f\u65b0\u9896\u7684\uff0c\u53c2\u6570\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u5efa\u7acb\u4e86Hadamard\u77e9\u9635\u4e0eGCS\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3aHadamard\u731c\u60f3\u7684\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.12515", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12515", "abs": "https://arxiv.org/abs/2510.12515", "authors": ["Zhige Chen", "Chengxuan Qin", "Wenlong You", "Rui Liu", "Congying Chu", "Rui Yang", "Kay Chen Tan", "Jibin Wu"], "title": "HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation", "comment": null, "summary": "Electroencephalography (EEG) is an essential technique for neuroscience\nresearch and brain-computer interface (BCI) applications. Recently, large-scale\nEEG foundation models have been developed, exhibiting robust generalization\ncapabilities across diverse tasks and subjects. However, the heterogeneity of\nEEG devices not only hinders the widespread adoption of these models but also\nposes significant challenges to their further scaling and development. In this\npaper, we introduce HEAR, the first EEG foundation model explicitly designed to\nsupport heterogeneous EEG devices, accommodating varying electrode layouts and\nelectrode counts. HEAR employs a learnable, coordinate-based spatial embedding\nto map electrodes with diverse layouts and varying counts into a unified\nrepresentational space. This unified spatial representation is then processed\nby a novel spatially-guided transformer, which effectively captures\nspatiotemporal dependencies across electrodes. To support the development of\nHEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data\ncollected from over 150 distinct electrode layouts with up to 1,132 electrodes.\nExperimental results demonstrate that HEAR substantially outperforms existing\nEEG foundation models in supporting heterogeneous EEG devices and generalizing\nacross diverse cognitive tasks and subjects.", "AI": {"tldr": "HEAR\u662f\u9996\u4e2a\u4e13\u95e8\u652f\u6301\u5f02\u6784EEG\u8bbe\u5907\u7684EEG\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u57fa\u4e8e\u5750\u6807\u7684\u7a7a\u95f4\u5d4c\u5165\u5c06\u4e0d\u540c\u7535\u6781\u5e03\u5c40\u548c\u6570\u91cf\u7684\u8bbe\u5907\u6620\u5c04\u5230\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\uff0c\u4f7f\u7528\u7a7a\u95f4\u5f15\u5bfctransformer\u6355\u83b7\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "EEG\u8bbe\u5907\u5f02\u6784\u6027\u963b\u788d\u4e86\u5927\u89c4\u6a21EEG\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u548c\u8fdb\u4e00\u6b65\u53d1\u5c55\uff0c\u9700\u8981\u89e3\u51b3\u4e0d\u540c\u7535\u6781\u5e03\u5c40\u548c\u7535\u6781\u6570\u91cf\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u57fa\u4e8e\u5750\u6807\u7684\u7a7a\u95f4\u5d4c\u5165\u7edf\u4e00\u4e0d\u540c\u7535\u6781\u5e03\u5c40\uff0c\u91c7\u7528\u7a7a\u95f4\u5f15\u5bfctransformer\u5904\u7406\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u6784\u5efa\u5305\u542b8,782\u5c0f\u65f6\u6570\u636e\u7684\u5927\u89c4\u6a21EEG\u6570\u636e\u96c6\u3002", "result": "HEAR\u5728\u652f\u6301\u5f02\u6784EEG\u8bbe\u5907\u548c\u8de8\u8ba4\u77e5\u4efb\u52a1\u3001\u8de8\u88ab\u8bd5\u6cdb\u5316\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709EEG\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "HEAR\u6210\u529f\u89e3\u51b3\u4e86EEG\u8bbe\u5907\u5f02\u6784\u6027\u95ee\u9898\uff0c\u4e3aEEG\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u548c\u8fdb\u4e00\u6b65\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12648", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12648", "abs": "https://arxiv.org/abs/2510.12648", "authors": ["Abdelali Arous", "Hamza Haif", "Arman Farhang", "Huseyin Arslan"], "title": "A Unified Framework for Adaptive Waveform Processing in Next Generation Wireless Networks", "comment": null, "summary": "The emergence of alternative multiplexing domains to the time-frequency\ndomains, e.g., the delay-Doppler and chirp domains, offers a promising approach\nfor addressing the challenges posed by complex propagation environments and\nnext-generation applications. Unlike the time and frequency domains, these\ndomains offer unique channel representations which provide additional degrees\nof freedom (DoF) for modeling, characterizing, and exploiting wireless channel\nfeatures. This article provides a comprehensive analysis of channel\ncharacteristics, including delay, Doppler shifts, and channel coefficients\nacross various domains, with an emphasis on their inter-domain relationships,\nshared characteristics, and domain-specific distinctions. We further evaluate\nthe comparative advantages of each domain under specific channel conditions.\nBuilding on this analysis, we propose a generalized and adaptive transform\ndomain framework that leverages the pre- and post-processing of the discrete\nFourier transform (DFT) matrix, to enable dynamic transitions between various\ndomains in response to the channel conditions and system requirements. Finally,\nseveral representative use cases are presented to demonstrate the applicability\nof the proposed cross-domain waveform processing framework in diverse\nscenarios, along with future directions and challenges.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u81ea\u9002\u5e94\u53d8\u6362\u57df\u6846\u67b6\uff0c\u901a\u8fc7DFT\u77e9\u9635\u7684\u524d\u540e\u5904\u7406\u5b9e\u73b0\u4e0d\u540c\u57df\u95f4\u7684\u52a8\u6001\u8f6c\u6362\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u4f20\u64ad\u73af\u5883\u548c\u4e0b\u4e00\u4ee3\u5e94\u7528\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u9891\u57df\u5728\u590d\u6742\u4f20\u64ad\u73af\u5883\u548c\u4e0b\u4e00\u4ee3\u5e94\u7528\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u800c\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u548c\u5541\u557e\u57df\u7b49\u65b0\u578b\u591a\u8def\u590d\u7528\u57df\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u81ea\u7531\u5ea6\u6765\u5efa\u6a21\u548c\u5229\u7528\u65e0\u7ebf\u4fe1\u9053\u7279\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362(DFT)\u77e9\u9635\u524d\u540e\u5904\u7406\u7684\u5e7f\u4e49\u81ea\u9002\u5e94\u53d8\u6362\u57df\u6846\u67b6\uff0c\u652f\u6301\u6839\u636e\u4fe1\u9053\u6761\u4ef6\u548c\u7cfb\u7edf\u9700\u6c42\u5728\u4e0d\u540c\u57df\u95f4\u52a8\u6001\u5207\u6362\u3002", "result": "\u5efa\u7acb\u4e86\u8de8\u57df\u6ce2\u5f62\u5904\u7406\u6846\u67b6\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u4fe1\u9053\u6761\u4ef6\uff0c\u5e76\u5728\u591a\u79cd\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u5176\u9002\u7528\u6027\u3002", "conclusion": "\u8de8\u57df\u6ce2\u5f62\u5904\u7406\u6846\u67b6\u4e3a\u89e3\u51b3\u590d\u6742\u65e0\u7ebf\u73af\u5883\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5b9e\u9645\u5e94\u7528\u548c\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2510.12651", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12651", "abs": "https://arxiv.org/abs/2510.12651", "authors": ["Axel Janson", "Joakim And\u00e9n"], "title": "Moment-based Posterior Sampling for Multi-reference Alignment", "comment": null, "summary": "We propose a Bayesian approach to the problem of multi-reference alignment --\nthe recovery of signals from noisy, randomly shifted observations. While\nexisting frequentist methods accurately recover the signal at arbitrarily low\nsignal-to-noise ratios, they require a large number of samples to do so. In\ncontrast, our proposed method leverages diffusion models as data-driven\nplug-and-play priors, conditioning these on the sample power spectrum (a\nshift-invariant statistic) enabling both accurate posterior sampling and\nuncertainty quantification. The use of an appropriate prior significantly\nreduces the required number of samples, as illustrated in simulation\nexperiments with comparisons to state-of-the-art methods such as\nexpectation--maximization and bispectrum inversion. These findings establish\nour approach as a promising framework for other orbit recovery problems, such\nas cryogenic electron microscopy (cryo-EM).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u65b9\u6cd5\u548c\u6269\u6563\u6a21\u578b\u7684\u591a\u53c2\u8003\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6837\u672c\u529f\u7387\u8c31\u4f5c\u4e3a\u6761\u4ef6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6240\u9700\u6837\u672c\u6570\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u51c6\u786e\u7684\u540e\u9a8c\u91c7\u6837\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u73b0\u6709\u9891\u7387\u65b9\u6cd5\u867d\u7136\u80fd\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u51c6\u786e\u6062\u590d\u4fe1\u53f7\uff0c\u4f46\u9700\u8981\u5927\u91cf\u6837\u672c\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u51cf\u5c11\u6240\u9700\u6837\u672c\u6570\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u5373\u63d2\u5373\u7528\u5148\u9a8c\uff0c\u4ee5\u6837\u672c\u529f\u7387\u8c31\uff08\u5e73\u79fb\u4e0d\u53d8\u7edf\u8ba1\u91cf\uff09\u4e3a\u6761\u4ef6\uff0c\u5b9e\u73b0\u540e\u9a8c\u91c7\u6837\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u671f\u671b\u6700\u5927\u5316\u3001\u53cc\u8c31\u53cd\u6f14\u7b49\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u6240\u9700\u6837\u672c\u6570\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5176\u4ed6\u8f68\u9053\u6062\u590d\u95ee\u9898\uff08\u5982\u51b7\u51bb\u7535\u955c\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u6846\u67b6\u3002"}}
{"id": "2510.12711", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12711", "abs": "https://arxiv.org/abs/2510.12711", "authors": ["Muhammad Talha", "Besma Smida", "David Gonz\u00e1lez G"], "title": "Enhanced Angle-Range Cluster Parameter Estimation in Full-Duplex ISAC Systems", "comment": "8 pages, 5 figures", "summary": "This work studies an integrated sensing and communication (ISAC) framework\nfor targets that are spread both in the angle and range domains. We model each\ntarget using a cluster of rays parameterized by a specific density function,\nand propose a truncated Multiple Signal Classification (MUSIC) spread (TMS)\nalgorithm to accurately estimate the parameters of the density function. Unlike\nthe conventional MUSIC spread (CMS), TMS restricts the signal subspace rank\nbased on the eigen decomposition of the received-signal autocorrelation. We\nalso propose a discrete Fourier transform (DFT) based algorithm for estimating\nthe distance and range spread of each target. Leveraging these estimates, we\nthen develop a dynamic transmit beamforming algorithm that successfully\nilluminates multiple targets while also serving multiple downlink (DL) users.\nSimulation results demonstrate the superiority of our proposed algorithms over\nbaseline schemes in both low and high signal-to-noise ratio (SNR) regimes as\nwell as under a wide angular spread regime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89d2\u5ea6\u548c\u8ddd\u79bb\u57df\u5206\u5e03\u76ee\u6807\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6846\u67b6\uff0c\u5305\u62ec\u622a\u65adMUSIC\u6269\u5c55\u7b97\u6cd5\u548c\u57fa\u4e8eDFT\u7684\u8ddd\u79bb\u4f30\u8ba1\u7b97\u6cd5\uff0c\u4ee5\u53ca\u52a8\u6001\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u5728\u89d2\u5ea6\u548c\u8ddd\u79bb\u57df\u5747\u6709\u5206\u5e03\u7684\u76ee\u6807\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u95ee\u9898\uff0c\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u76ee\u6807\u5bc6\u5ea6\u51fd\u6570\u53c2\u6570\u5e76\u540c\u65f6\u670d\u52a1\u591a\u4e2a\u4e0b\u884c\u7528\u6237\u3002", "method": "\u4f7f\u7528\u5c04\u7ebf\u7c07\u5efa\u6a21\u76ee\u6807\uff0c\u63d0\u51fa\u622a\u65adMUSIC\u6269\u5c55\u7b97\u6cd5\u4f30\u8ba1\u5bc6\u5ea6\u51fd\u6570\u53c2\u6570\uff0c\u57fa\u4e8eDFT\u7684\u7b97\u6cd5\u4f30\u8ba1\u8ddd\u79bb\u548c\u8303\u56f4\u6269\u5c55\uff0c\u5f00\u53d1\u52a8\u6001\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f4e\u9ad8\u4fe1\u566a\u6bd4\u548c\u5bbd\u89d2\u5ea6\u6269\u5c55\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u7b97\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6846\u67b6\u80fd\u6709\u6548\u4f30\u8ba1\u5206\u5e03\u76ee\u6807\u53c2\u6570\u5e76\u540c\u65f6\u670d\u52a1\u591a\u4e2a\u7528\u6237\uff0c\u5728\u5404\u79cd\u573a\u666f\u4e0b\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.12763", "categories": ["eess.SP", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.12763", "abs": "https://arxiv.org/abs/2510.12763", "authors": ["Saurabh Sihag", "Gonzalo Mateos", "Alejandro Ribeiro"], "title": "Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective", "comment": "Accepted for publication in IEEE Signal Processing Magazine", "summary": "Neurodegeneration, characterized by the progressive loss of neuronal\nstructure or function, is commonly assessed in clinical practice through\nreductions in cortical thickness or brain volume, as visualized by structural\nMRI. While informative, these conventional approaches lack the statistical\nsophistication required to fully capture the spatially correlated and\nheterogeneous nature of neurodegeneration, which manifests both in healthy\naging and in neurological disorders. To address these limitations, brain age\ngap has emerged as a promising data-driven biomarker of brain health. The brain\nage gap prediction (BAGP) models estimate the difference between a person's\npredicted brain age from neuroimaging data and their chronological age. The\nresulting brain age gap serves as a compact biomarker of brain health, with\nrecent studies demonstrating its predictive utility for disease progression and\nseverity. However, practical adoption of BAGP models is hindered by their\nmethodological obscurities and limited generalizability across diverse clinical\npopulations. This tutorial article provides an overview of BAGP and introduces\na principled framework for this application based on recent advancements in\ngraph signal processing (GSP). In particular, we focus on graph neural networks\n(GNNs) and introduce the coVariance neural network (VNN), which leverages the\nanatomical covariance matrices derived from structural MRI. VNNs offer strong\ntheoretical grounding and operational interpretability, enabling robust\nestimation of brain age gap predictions. By integrating perspectives from GSP,\nmachine learning, and network neuroscience, this work clarifies the path\nforward for reliable and interpretable BAGP models and outlines future research\ndirections in personalized medicine.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u56fe\u4fe1\u53f7\u5904\u7406\u7684\u5927\u8111\u5e74\u9f84\u5dee\u8ddd\u9884\u6d4b\u6a21\u578b\uff0c\u7279\u522b\u662f\u534f\u65b9\u5dee\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u795e\u7ecf\u9000\u884c\u6027\u53d8\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfMRI\u8bc4\u4f30\u795e\u7ecf\u9000\u884c\u6027\u53d8\u7684\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u8ba1\u590d\u6742\u6027\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349\u7a7a\u95f4\u76f8\u5173\u6027\u548c\u5f02\u8d28\u6027\u3002\u5927\u8111\u5e74\u9f84\u5dee\u8ddd\u4f5c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u751f\u7269\u6807\u5fd7\u7269\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5b58\u5728\u65b9\u6cd5\u4e0d\u900f\u660e\u548c\u6cdb\u5316\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u4fe1\u53f7\u5904\u7406\u7684\u6846\u67b6\uff0c\u91cd\u70b9\u4ecb\u7ecd\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u534f\u65b9\u5dee\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u7ed3\u6784MRI\u884d\u751f\u7684\u89e3\u5256\u534f\u65b9\u5dee\u77e9\u9635\u8fdb\u884c\u5927\u8111\u5e74\u9f84\u9884\u6d4b\u3002", "result": "\u534f\u65b9\u5dee\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u7406\u8bba\u57fa\u7840\u548c\u64cd\u4f5c\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u7a33\u5065\u5730\u4f30\u8ba1\u5927\u8111\u5e74\u9f84\u5dee\u8ddd\u9884\u6d4b\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u56fe\u4fe1\u53f7\u5904\u7406\u3001\u673a\u5668\u5b66\u4e60\u548c\u7f51\u7edc\u795e\u7ecf\u79d1\u5b66\u7684\u89c6\u89d2\uff0c\u4e3a\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u5927\u8111\u5e74\u9f84\u5dee\u8ddd\u9884\u6d4b\u6a21\u578b\u6307\u660e\u4e86\u524d\u8fdb\u65b9\u5411\uff0c\u5e76\u6982\u8ff0\u4e86\u4e2a\u6027\u5316\u533b\u7597\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
