<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 5]
- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 9]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [MRI Super-Resolution with Deep Learning: A Comprehensive Survey](https://arxiv.org/abs/2511.16854)
*Mohammad Khateri,Serge Vasylechko,Morteza Ghahremani,Liam Timms,Deniz Kocanaogullari,Simon K. Warfield,Camilo Jaimes,Davood Karimi,Alejandra Sierra,Jussi Tohka,Sila Kurugol,Onur Afacan*

Main category: eess.IV

TL;DR: 这篇综述论文回顾了磁共振成像超分辨率技术的最新进展，特别关注深度学习方法，涵盖了理论基础、架构设计、学习策略、基准数据集和性能指标，并提出了系统分类法来分类这些方法。


<details>
  <summary>Details</summary>
Motivation: 高分辨率磁共振成像在临床和研究应用中至关重要，但成本高昂且受技术限制。超分辨率作为一种计算方法是克服这些挑战的有前景途径，可以从更经济实惠的低分辨率扫描生成高分辨率图像。

Method: 从计算机视觉、计算成像、逆问题和磁共振物理学的角度审视基于深度学习的磁共振成像超分辨率方法，提出系统分类法，涵盖理论、架构、学习策略等。

Result: 论文提供了对磁共振成像超分辨率技术的全面调查，包括已建立和新兴的方法，并考虑了临床和研究环境中的独特挑战。

Conclusion: 论文强调了社区需要解决的开放挑战和方向，并提供了开源资源、工具和教程的集合，以促进该领域的发展。

Abstract: High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.
  IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.

</details>


### [2] [Avoiding Quality Saturation in UGC Compression Using Denoised References](https://arxiv.org/abs/2511.16876)
*Xin Xiong,Samuel Fernández-Menduiña,Eduardo Pavez,Antonio Ortega,Neil Birkbeck,Balu Adsumilli*

Main category: eess.IV

TL;DR: 提出了一种检测UGC压缩中质量饱和问题的高效方法，通过计算去噪UGC的MSE来识别失真饱和现象，避免在饱和区域进行编码，实现8%-20%的BD-rate节省。


<details>
  <summary>Details</summary>
Motivation: 传统编解码器在压缩用户生成内容时会产生质量饱和问题，即增加码率只能保留输入伪影而无法改善视觉质量。现有方法需要重复评估非参考指标，效率低下。

Method: 提出两种失真饱和检测方法：基于输入相关阈值的DSD和基于拉格朗日估计的RDSD，通过计算去噪UGC的MSE来识别饱和区域，避免在饱和点进行编码。

Result: 在AVC实验中，避免在饱和区域编码实现了8%-20%的BD-rate节省，相比忽略质量饱和的基准方法有显著改进。

Conclusion: 该方法能有效检测UGC压缩中的质量饱和问题，作为预处理步骤帮助标准编解码器避免在饱和区域编码，显著提升压缩效率。

Abstract: Video-sharing platforms must re-encode large volumes of noisy user-generated content (UGC) to meet streaming demands. However, conventional codecs, which aim to minimize the mean squared error (MSE) between the compressed and input videos, can cause quality saturation (QS) when applied to UGC, i.e., increasing the bitrate preserves input artifacts without improving visual quality. A direct approach to solve this problem is to detect QS by repeatedly evaluating a non-reference metric (NRM) on videos compressed with multiple codec parameters, which is inefficient. In this paper, we re-frame UGC compression and QS detection from the lens of noisy source coding theory: rather than using a NRM, we compute the MSE with respect to the denoised UGC, which serves as an alternative reference (D-MSE). Unlike MSE measured between the UGC input and the compressed UGC, D-MSE saturates at non-zero values as bitrates increase, a phenomenon we term distortion saturation (DS). Since D-MSE can be computed at the block level in the transform domain, we can efficiently detect D-MSE without coding and decoding with various parameters. We propose two methods for DS detection: distortion saturation detection (DSD), which relies on an input-dependent threshold derived from the D-MSE of the input UGC, and rate-distortion saturation detection (RDSD), which estimates the Lagrangian at the saturation point using a low-complexity compression method. Both methods work as a pre-processing step that can help standard-compliant codecs avoid QS in UGC compression. Experiments with AVC show that preventing encoding in the saturation region, i.e., avoiding encoding at QPs that result in QS according to our methods, achieves BD-rate savings of 8%-20% across multiple different NRMs, compared to a naïve baseline that encodes at the given input QP while ignoring QS.

</details>


### [3] [MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays](https://arxiv.org/abs/2511.17043)
*Rama Krishna Boya,Mohan Kireeti Magalanadu,Azaruddin Palavalli,Rupa Ganesh Tekuri,Amrit Pattanayak,Prasanthi Enuga,Vignesh Esakki Muthu,Vivek Aditya Boya*

Main category: eess.IV

TL;DR: 使用MedImageInsight基础模型对胸部X光片进行正常/异常二分类，微调方法在ROC-AUC上达到0.888，性能与CheXNet相当，可集成到临床工作流中辅助分诊。


<details>
  <summary>Details</summary>
Motivation: 胸部X光检查量增加和放射科医生工作负担加重，需要自动化工具来支持及时诊断。

Method: 评估两种方法：(1)微调MedImageInsight进行端到端分类；(2)使用模型作为特征提取器，结合传统机器学习分类器进行迁移学习。使用ChestX-ray14数据集和真实临床数据。

Result: 微调分类器表现最佳，ROC-AUC为0.888，校准性能优于迁移学习模型，性能与CheXNet相当。

Conclusion: 医学影像基础模型能有效减少特定任务的训练需求，同时保持诊断可靠性，未来将扩展到多标签病理分类。

Abstract: Chest radiography remains one of the most widely used imaging modalities for thoracic diagnosis, yet increasing imaging volumes and radiologist workload continue to challenge timely interpretation. In this work, we investigate the use of MedImageInsight, a medical imaging foundational model, for automated binary classification of chest X-rays into Normal and Abnormal categories. Two approaches were evaluated: (1) fine-tuning MedImageInsight for end-to-end classification, and (2) employing the model as a feature extractor for a transfer learning pipeline using traditional machine learning classifiers. Experiments were conducted using a combination of the ChestX-ray14 dataset and real-world clinical data sourced from partner hospitals. The fine-tuned classifier achieved the highest performance, with an ROC-AUC of 0.888 and superior calibration compared to the transfer learning models, demonstrating performance comparable to established architectures such as CheXNet. These results highlight the effectiveness of foundational medical imaging models in reducing task-specific training requirements while maintaining diagnostic reliability. The system is designed for integration into web-based and hospital PACS workflows to support triage and reduce radiologist burden. Future work will extend the model to multi-label pathology classification to provide preliminary diagnostic interpretation in clinical environments.

</details>


### [4] [OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation](https://arxiv.org/abs/2511.17126)
*Qi Jiang,Xiaolong Qian,Yao Gao,Lei Sun,Kailun Yang,Zhonghua Yi,Wenyong Li,Ming-Hsuan Yang,Luc Van Gool,Kaiwei Wang*

Main category: eess.IV

TL;DR: OmniLens++框架通过扩展设计规范增加镜头退化多样性，并引入潜在PSF表示作为光学退化先验指导，解决了现有镜头库预训练管道在数据可扩展性和先验指导方面的挑战，在盲像差校正中展现出最先进的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的镜头库预训练管道在泛化能力方面面临两个主要挑战：数据难以扩展和缺乏表征光学退化的先验指导，这限制了其在处理多样化未知光学退化时的效果。

Method: 1. 扩展设计规范增加镜头退化多样性，通过量化光学退化的空间变化模式和严重程度来采样更均匀的分布；2. 提出潜在PSF表示(LPR)，使用VQVAE框架学习镜头库PSF的潜在特征，并通过建模光学退化过程来约束退化先验的学习。

Result: 在真实世界镜头和合成镜头库的多样化像差实验中，OmniLens++在盲像差校正中展现出最先进的泛化能力。AODLibpro被验证为可扩展的基础，能在多样化像差中进行更有效的训练，LPR能进一步挖掘大规模镜头库的潜力。

Conclusion: OmniLens++通过解决数据可扩展性和先验指导问题，显著提升了盲镜头像差校正的泛化性能，为光学图像处理提供了有效的解决方案。

Abstract: Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.

</details>


### [5] [Learning Latent Transmission and Glare Maps for Lens Veiling Glare Removal](https://arxiv.org/abs/2511.17353)
*Xiaolong Qian,Qi Jiang,Lei Sun,Zongxi Yu,Kailun Yang,Peixuan Wu,Jiacheng Zhou,Yao Gao,Yaoguang Ma,Ming-Hsuan Yang,Kaiwei Wang*

Main category: eess.IV

TL;DR: 提出了VeilGen生成模型来模拟面纱眩光，以及DeVeiler恢复网络来去除眩光，解决了紧凑光学系统中光学像差和面纱眩光的复合退化问题。


<details>
  <summary>Details</summary>
Motivation: 紧凑光学系统（包括单透镜和超透镜）的成像性能常因非理想光学表面和涂层产生的杂散光散射而进一步降低，这种面纱眩光具有空间变化和深度无关的特性，传统散射模型难以拟合，且难以通过仿真准备高质量配对数据。

Method: 提出VeilGen生成模型，通过从目标图像中无监督学习估计光学透射率和眩光图，并利用Stable Diffusion先验进行正则化；进一步提出DeVeiler恢复网络，利用预测的潜在图指导学习散射模型的逆过程。

Result: 在具有挑战性的紧凑光学系统上的广泛实验表明，该方法在恢复质量和物理保真度方面优于现有方法，VeilGen能够可靠地合成真实的面纱眩光，其学习的潜在图能有效指导DeVeiler的恢复过程。

Conclusion: VeilGen能够可靠合成真实面纱眩光，其学习的潜在图有效指导DeVeiler的恢复过程，为解决紧凑光学系统中的复合退化问题提供了有效方案。

Abstract: Beyond the commonly recognized optical aberrations, the imaging performance of compact optical systems-including single-lens and metalens designs-is often further degraded by veiling glare caused by stray-light scattering from non-ideal optical surfaces and coatings, particularly in complex real-world environments. This compound degradation undermines traditional lens aberration correction yet remains underexplored. A major challenge is that conventional scattering models (e.g., for dehazing) fail to fit veiling glare due to its spatial-varying and depth-independent nature. Consequently, paired high-quality data are difficult to prepare via simulation, hindering application of data-driven veiling glare removal models. To this end, we propose VeilGen, a generative model that learns to simulate veiling glare by estimating its underlying optical transmission and glare maps in an unsupervised manner from target images, regularized by Stable Diffusion (SD)-based priors. VeilGen enables paired dataset generation with realistic compound degradation of optical aberrations and veiling glare, while also providing the estimated latent optical transmission and glare maps to guide the veiling glare removal process. We further introduce DeVeiler, a restoration network trained with a reversibility constraint, which utilizes the predicted latent maps to guide an inverse process of the learned scattering model. Extensive experiments on challenging compact optical systems demonstrate that our approach delivers superior restoration quality and physical fidelity compared with existing methods. These suggest that VeilGen reliably synthesizes realistic veiling glare, and its learned latent maps effectively guide the restoration process in DeVeiler. All code and datasets will be publicly released at https://github.com/XiaolongQian/DeVeiler.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [6] [Functional uniqueness and stability of Gaussian priors in optimal L1 estimation](https://arxiv.org/abs/2511.16864)
*Leighton Barnes,Alex Dytso*

Main category: cs.IT

TL;DR: 本文研究了高斯先验在最优L1估计中的函数唯一性和稳定性，建立了定量稳定性理论，证明高斯分布是唯一稳定的解。


<details>
  <summary>Details</summary>
Motivation: 虽然已知高斯先验在高斯噪声下唯一产生线性条件均值，但对于条件中位数（绝对误差损失下的最优估计器）的类似问题最近才得到解决。本文基于这一唯一性结果，旨在发展定量稳定性理论。

Method: 对于L2损失，推导了条件均值近似线性性意味着先验分布接近高斯分布的显式速率；对于L1损失，引入Hermite展开框架并分析线性性定义算子的伴随算子。

Result: 证明了高斯分布在L1和L2损失下都是唯一稳定的解，建立了先验分布与高斯分布在Lévy度量下的接近性关系。

Conclusion: 这些结果为高斯噪声下贝叶斯估计中的线性和稳定性提供了更完整的函数分析理解。

Abstract: This paper studies the functional uniqueness and stability of Gaussian priors in optimal $L^1$ estimation. While it is well known that the Gaussian prior uniquely induces linear conditional means under Gaussian noise, the analogous question for the conditional median (i.e., the optimal estimator under absolute-error loss) has only recently been settled. Building on the prior work establishing this uniqueness, we develop a quantitative stability theory that characterizes how approximate linearity of the optimal estimator constrains the prior distribution. For $L^2$ loss, we derive explicit rates showing that near-linearity of the conditional mean implies proximity of the prior to the Gaussian in the Lévy metric. For $L^1$ loss, we introduce a Hermite expansion framework and analyze the adjoint of the linearity-defining operator to show that the Gaussian remains the unique stable solution. Together, these results provide a more complete functional-analytic understanding of linearity and stability in Bayesian estimation under Gaussian noise.

</details>


### [7] [The Star Product of Uniformly Random Codes](https://arxiv.org/abs/2511.17236)
*Johan V. Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti,Benjamin Jany,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 本文研究了两个随机线性码星积的期望维度问题，通过建立星积与双线性形式评估的对应关系，给出了期望星积维度的下界，并证明在域大小和码维渐近情况下期望维度达到最大值。


<details>
  <summary>Details</summary>
Motivation: 研究随机线性码星积的期望维度对于理解编码理论中的组合性质具有重要意义，并在私有信息检索、安全分布式矩阵乘法、量子纠错码和密码分析等领域有应用价值。

Method: 通过建立星积与双线性形式评估的对应关系，利用这种对应关系推导期望星积维度的下界，并分析渐近行为。

Result: 证明了在域大小q和两个码的维度都趋于无穷大的渐近情况下，星积的期望维度达到其最大值。

Conclusion: 该研究为随机线性码星积的维度分析提供了理论框架，并在多个应用领域展示了其潜在价值。

Abstract: We consider the problem of determining the expected dimension of the star product of two uniformly random linear codes that are not necessarily of the same dimension. We achieve this by establishing a correspondence between the star product and the evaluation of bilinear forms, which we use to provide a lower bound on the expected star product dimension. We show that asymptotically in both the field size q and the dimensions of the two codes, the expected dimension reaches its maximum. Lastly, we discuss some implications related to private information retrieval, secure distributed matrix multiplication, quantum error correction, and the potential for exploiting the results in cryptanalysis.

</details>


### [8] [Structured Approximation of Toeplitz Matrices and Subspaces](https://arxiv.org/abs/2511.17239)
*Albert Fannjiang,Weilin Li*

Main category: cs.IT

TL;DR: 本文研究了两个结构化逼近问题：恢复损坏的低秩Toeplitz矩阵和从单次观测中恢复傅里叶矩阵的范围。通过应用Gradient-MUSIC谱估计算法，实现了高效且最优的解决方案。


<details>
  <summary>Details</summary>
Motivation: Toeplitz矩阵恢复和傅里叶矩阵范围恢复都是计算上具有挑战性的问题，因为结构约束难以直接实施。需要找到能够有效处理这些结构化逼近问题的方法。

Method: 使用Gradient-MUSIC谱估计算法来解决这两个问题。对于秩为r的Toeplitz矩阵，在满足正则性假设且被任意噪声矩阵E损坏的情况下，算法输出精确秩为r的Toeplitz矩阵估计。

Result: 算法输出的Toeplitz矩阵估计满足‖T-Ť‖₂ ≤ C√r‖E‖₂，其中C,α>0是绝对常数。该性能保证在n和‖E‖₂方面是最小最大最优的。对第二个问题也获得了最优结果。

Conclusion: Gradient-MUSIC算法能够高效且最优地解决这两个结构化逼近问题，建立了这些问题与谱估计之间的定量联系。结果同样适用于Hankel矩阵（只需稍作修改）。

Abstract: This paper studies two structured approximation problems: (1) Recovering a corrupted low-rank Toeplitz matrix and (2) recovering the range of a Fourier matrix from a single observation. Both problems are computationally challenging because the structural constraints are difficult to enforce directly. We show that both tasks can be solved efficiently and optimally by applying the Gradient-MUSIC algorithm for spectral estimation. For a rank $r$ Toeplitz matrix ${\boldsymbol T}\in {\mathbb C}^{n\times n}$ that satisfies a regularity assumption and is corrupted by an arbitrary ${\boldsymbol E}\in {\mathbb C}^{n\times n}$ such that $\|{\boldsymbol E}\|_2\leq αn$, our algorithm outputs a Toeplitz matrix $\widehat{\boldsymbol T}$ of rank exactly $r$ such that $\|{\boldsymbol T}-\widehat{\boldsymbol T}\|_2 \leq C \sqrt r \, \|{\boldsymbol E}\|_2$, where $C,α>0$ are absolute constants. This performance guarantee is minimax optimal in $n$ and $\|{\boldsymbol E}\|_2$. We derive optimal results for the second problem as well. Our analysis provides quantitative connections between these two problems and spectral estimation. Our results are equally applicable to Hankel matrices with superficial modifications.

</details>


### [9] [Fast Decoding for Non-Adaptive Learning of Erdős--Rényi Random Graphs](https://arxiv.org/abs/2511.17240)
*Hoang Ta,Jonathan Scarlett*

Main category: cs.IT

TL;DR: 本文提出了一种非自适应图学习算法，用于学习Erdős-Rényi随机图，使用O(\bar{k}\log n)次测试即可高概率恢复边集，解码时间为O(\bar{k}^{1+δ}\log n)。


<details>
  <summary>Details</summary>
Motivation: 现有方法在非自适应图学习中要么解码时间过高(Ω(n²))，要么测试次数过多(多出(\log \bar{k})(\log n)因子)。需要平衡测试次数和解码时间。

Method: 将非自适应群测试中的二分搜索方法扩展到ER图学习场景，设计高效的测试-解码方案。

Result: 算法使用O(\bar{k}\log n)次测试即可高概率恢复边集，解码时间为O(\bar{k}^{1+δ}\log n)，在测试次数和解码时间之间取得良好平衡。

Conclusion: 提出的方法在保持最优测试次数的同时，显著降低了解码时间，为ER图学习提供了实用的非自适应算法。

Abstract: We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \(n\) nodes and \(k\) edges is hard in the non-adaptive setting, requiring \(Ω\big(\min\{k^2\log n,\,n^2\}\big)\) tests even when a small error probability is allowed. We focus on learning Erdős--Rényi (ER) graphs \(G\sim\ER(n,q)\) in the non-adaptive setting, where the expected number of edges is \(\bar{k}=q\binom{n}{2}\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \(O(\bar{k}\log n)\) but incurs \(Ω(n^2)\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \((\log \bar{k})(\log n)\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \(O(\bar{k}\log n)\) tests while attaining decoding time \(O(\bar{k}^{1+δ}\log n)\) for any fixed \(δ>0\).

</details>


### [10] [Fluid Antenna System-Enabled UAV-to-Ground Communications](https://arxiv.org/abs/2511.17416)
*Xusheng Zhu,Kai-Kit Wong,Qingqing Wu,Hyundong Shin,Yangyang Zhang*

Main category: cs.IT

TL;DR: 本文分析了无人机到地面链路中采用流体天线系统的性能，推导了在双阴影衰落信道下的统计特性和性能指标，揭示了系统可获得M×d的乘性分集阶数。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统在紧凑尺寸内提供增强的空间分集，而无人机在未来网络中至关重要，需要能够同时捕获多径衰落和阴影的信道模型。

Method: 采用基于特征值的相关FAS端口近似方法，推导了端到端信噪比的累积分布函数和概率密度函数，并基于此给出了中断概率、平均误码率和平均信道容量的精确积分表达式。

Result: 为实用的双秩、独立但非同分布情况推导了新的闭式解，渐近分析表明系统可获得M×d的乘性分集阶数，仿真验证了理论框架的高精度。

Conclusion: 提出的理论框架准确分析了FAS在双阴影衰落信道下的性能，揭示了系统分集增益的乘法特性，为无人机通信系统设计提供了理论支撑。

Abstract: Fluid antenna systems (FAS) have emerged as a revolutionary technology offering enhanced spatial diversity within a compact form factor. Concurrently, unmanned aerial vehicles (UAVs) are integral to future networks, necessitating channel models that capture both multipath fading and shadowing. This letter presents a novel performance analysis of a UAV-to-ground link, where the receiver is equipped with an $N$-port FAS operating over the challenging double-shadowing fading channel. By adapting a tractable eigenvalue-based approximation for the correlated FAS ports, we derive new analytical expressions for the end-to-end signal-to-noise ratio statistics, namely the cumulative distribution function and the probability density function. Based on these statistics, we present exact integral expressions for the outage probability, average bit error rate, and average channel capacity. We further derive new, tractable closed-form solutions for the average bit error rate and capacity for the practical dual-rank, independent but non-identically distributed case. Finally, a key asymptotic analysis reveals that the system achieves a multiplicative diversity order of $G_d = M \times d$, which is precisely the product of the FAS spatial rank $M$ and the intrinsic channel diversity order $d$. Simulation results are provided to validate the high accuracy of our entire theoretical framework.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [11] [Line-of-Sight Probability in Macrocells: Framework, Statistical Models, and Parametrization from Massive Real World Datasets in the USA](https://arxiv.org/abs/2511.16827)
*Bassel Abou Ali Modad,Xin Yu,Yao-Yi Chiang,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 本文提出了一个从地理空间数据生成高精度LOS概率模型的框架，并创建了针对美国宏蜂窝的新LOS模型，比3GPP模型更准确地描述宏蜂窝部署。


<details>
  <summary>Details</summary>
Motivation: 精确的LOS概率建模对无线信道描述和覆盖规划至关重要，现有模型基于非常有限的数据集，需要更准确的建模方法。

Method: 建立从地理空间数据生成高精度LOS模型的框架，使用美国全国范围的13,000多个真实宏蜂窝位置数据集，创建完全参数化的新模型。

Result: 新模型比3GPP模型更好地描述了美国宏蜂窝部署，基于每个蜂窝的LOS概率建模和随机变量参数化方法能更准确地预测小区边缘的干扰。

Conclusion: LOS概率应在每个蜂窝基础上建模，模型参数应作为随机变量处理，这种新方法比基于平均的模型能更好地预测小区边缘干扰。

Abstract: Accurate modeling of line-of-sight (LOS) probability is crucial for wireless channel description and coverage planning. The presence of a LOS impacts other channel characteristics such as pathloss, fading depth, delay- and angular spread, etc.. Existing models, although useful, are based on very limited datasets. In this paper, we establish a framework to produce high accuracy LOS models from geospatial data in different environments, and apply it to create a LOS model for macrocells, using datasets of the United States (US) on a nationalscale, using more than 13, 000 locations of real-world macrocells. Based on this we create a new, fully parameterized model that better describes macrocell deployments in the US than the 3GPP model. We furthermore demonstrate that for improved accuracy the LOS probability should be modeled on a per cell basis, and the model parameters treated as random variables; we provide a full description and parameterization of this novel approach and by simulations show that it better predicts the inter-cell interference at the cell-edge than an average-based model.

</details>


### [12] [State-of-charge estimation of lithium-ion batteries using a tree seed and genetic algorithm-optimized generalized mixture minimum error entropy-based square root cubature Kalman filter](https://arxiv.org/abs/2511.16888)
*Haiquan Zhao,Xiong Yin,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出了一种基于广义混合最小误差熵的平方根容积卡尔曼滤波器(GMMEE-SRCKF)，通过混合树种子遗传算法(TSGA)优化核参数，在复杂噪声环境下实现更精确的SOC估计。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最小误差熵的容积卡尔曼滤波器(MEE-CKF)在复杂噪声环境下鲁棒性有限，需要更灵活的自适应方法。

Method: 结合平方根算法提高数值稳定性，使用具有两个灵活核的GMMEE准则适应非高斯噪声，并引入TSGA算法自动优化核参数。

Result: 实验结果表明，TSGA优化的GMMEE-SRCKF优于现有鲁棒滤波器，均方根误差小于0.5%。

Conclusion: 所提出的GMMEE-SRCKF方法在复杂噪声环境下具有更好的鲁棒性和估计精度，为SOC估计提供了有效解决方案。

Abstract: The cubature Kalman filter based on minimum error entropy (MEE-CKF) offers accurate and robust performance in state of charge (SOC) estimation. However, due to the inflexibility of the minimum error entropy (MEE), this algorithm demonstrates limited robustness when confronted with more complex noise environments. To address these limitations, this paper proposes a generalized mixture minimum error entropy-based (GMMEE) square-root cubature Kalman filter (GMMEE-SRCKF). The square-root algorithm ensures improved numerical stability and avoids covariance degeneration, while the GMMEE criterion with two flexible kernels adapts effectively to non-Gaussian noise. Moreover, a hybrid tree seed and genetic algorithm (TSGA) is introduced to optimize the kernel parameters automatically. Experimental results confirm that the TSGA-optimized GMMEE-SRCKF outperforms existing robust filters, achieving the root mean square error (RMSE) of less than 0.5%.

</details>


### [13] [Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking](https://arxiv.org/abs/2511.17007)
*Wangqian Chen,Junting Chen,Shuguang Cui*

Main category: eess.SP

TL;DR: 提出了一种从稀疏CSI测量序列中恢复位置标签的生成框架，无需显式位置标签即可构建无线电地图，通过双尺度特征提取和混合循环-卷积编码器学习移动模式，使用扩散生成解码器重建完整CSI。


<details>
  <summary>Details</summary>
Motivation: 现有基于ML的无线通信方法需要大量准确标注的位置数据，这些数据获取成本高且困难。本文旨在解决这一数据依赖问题，直接从稀疏CSI测量中恢复位置信息。

Method: 设计双尺度特征提取方案联合利用角度空间和相邻样本相关性；开发混合循环-卷积编码器学习移动模式；嵌入可学习无线电地图捕获位置信息；使用扩散生成解码器重建完整CSI。

Result: 数值实验表明，与基于模型的卡尔曼滤波方法相比，该模型在非视距场景下可将定位精度提高30%以上，并实现20%的容量增益。

Conclusion: 该生成框架能够有效从稀疏CSI测量中恢复位置信息，无需显式位置标签，在定位精度和系统容量方面均优于传统方法。

Abstract: Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches.

</details>


### [14] [Movable Intelligent Surface-Enabled Wireless Communications: Static Phase Shifts with Mechanical Reconfigurability](https://arxiv.org/abs/2511.17058)
*Ziyuan Zheng,Qingqing Wu,Wen Chen,Weiren Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 提出了一种新型可移动智能表面(MIS)架构，通过机械滑动预相位次级超表面层来切换波束模式，解决了现有可重构智能表面(RIS)和静态表面之间的成本与性能差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能表面设计存在两个极端：动态RIS提供精细波束控制但成本高昂，而低成本静态表面只能提供单一波束模式。在准静态环境(如工业物联网和智能农业)中，这两种方案都不够经济或灵活。

Method: 采用机械滑动预相位次级超表面层在静态主层上移动的方式切换波束模式，建立了MIS信号模型，提出了基于惩罚方法、块坐标下降和黎曼流形优化的高效算法来解决混合整数非凸优化问题。

Result: 仿真结果表明，MIS架构显著缩小了单层静态表面与动态RIS之间的性能差距，为准静态无线应用提供了实用且灵活的解决方案。

Conclusion: MIS架构通过机械方式实现波束模式切换，为准静态环境提供了一种成本效益高且灵活的表面控制方案，填补了现有技术之间的空白。

Abstract: Intelligent surfaces that reshape electromagnetic waves are regarded as disruptive technologies for wireless networks. However, existing designs sit at two costly extremes: dynamic reconfigurable intelligent surfaces (RISs) offer fine beam control but require dense cabling, continuous power consumption, and substantial signaling overhead, whereas low-cost static surfaces require no control lines or electronics but are limited to a single beam pattern. This disparity leaves a practical gap for quasi-static environments, such as industrial Internet-of-things and smart agriculture scenarios, where channels are stable with user demands changing only occasionally or periodically, and neither extreme is sufficiently economical or flexible. To bridge this gap, we propose a novel movable intelligent surface (MIS) architecture, whose beam patterns are switched not by electronic phase tuning but by mechanically sliding a small, pre-phased secondary metasurface layer across a larger, likewise static primary layer. We develop an MIS signal model that characterizes the interaction between static phase elements with dynamic geometry via binary selection matrices. Based on this model, we formulate a new type of optimization problems that jointly design static phase shifts and the overlapping position selection of MS2 (equal to beam pattern scheduling). Efficient algorithms based on the penalty method, block coordinate descent, and Riemannian manifold optimization are proposed to tackle these mixed-integer non-convex problems. Simulation results demonstrate that the proposed MIS architecture substantially narrows the performance gap between single-layer static surfaces and dynamic RISs, providing a practical and flexible solution for quasi-static wireless applications.

</details>


### [15] [Super-Resolution ISAC Receivers: An MCMC-Based Gridless Sparse Bayesian Learning Approach](https://arxiv.org/abs/2511.17062)
*Keying Zhu,Xingyu Zhou,Jie Yang,Le Liang,Shi Jin*

Main category: eess.SP

TL;DR: 提出了一种新颖的无网格稀疏贝叶斯学习框架，用于联合超分辨率多目标检测和高精度参数估计，解决了低空无线网络中感知精度与计算复杂度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 在低空无线网络中，安全关键应用对高精度感知的需求与传统方法在精度和复杂度之间的权衡存在矛盾，需要开发计算成本可控的高精度感知方法。

Method: 采用无网格稀疏贝叶斯学习框架，将目标参数视为连续变量以规避传统方法的网格限制，并开发了增强的基于梯度的马尔可夫链蒙特卡洛算法，整合了小批量采样和Adam优化器以确保计算效率和快速收敛。

Result: 仿真结果显示该方法具有卓越的超分辨率能力，成功分辨了距离、速度和角度分别仅为瑞利极限50%、17%和52%的多个目标。在20 dB信噪比下，多目标检测概率超过90%，同时实现了超高精度：距离、速度和角度的均方根误差分别为0.07 m、0.024 m/s和0.015度。

Conclusion: 该方法在强杂波环境下表现出稳健性能，展示了其在实用ISAC-LAWNs应用中的适用性。

Abstract: Integrated sensing and communication (ISAC) is crucial for low-altitude wireless networks (LAWNs), where the safety-critical demand for high-accuracy sensing creates a trade-off between precision and complexity for conventional methods. To address this, we propose a novel gridless sparse Bayesian learning (SBL) framework for joint super-resolution multi-target detection and high-accuracy parameter estimation with manageable computational cost. Our model treats target parameters as continuous variables to bypass the grid limitations of conventional approaches. This SBL formulation, however, transforms the estimation task into a challenging high-dimensional inference problem, which we address by developing an enhanced gradient-based Markov chain Monte Carlo algorithm. Our method integrates mini-batch sampling and the Adam optimizer to ensure computational efficiency and rapid convergence. Finally, we validate the framework's robustness in strong clutter and provide a theoretical benchmark by deriving the corresponding Bayesian Cramer-Rao bound. Simulation results demonstrate remarkable super-resolution capabilities, successfully resolving multiple targets separated by merely 50% of the Rayleigh limit in range, 17% in velocity, and 52% in angle. At a signal-to-noise ratio of 20 dB, the algorithm achieves a multi-target detection probability exceeding 90% while concurrently delivering ultra-high accuracy, with root mean square error of 0.07 m, 0.024 m/s, and 0.015 degree for range, velocity, and angle, respectively. This robust performance, demonstrated against strong clutter, showcases its suitability for practical ISAC-LAWNs applications.

</details>


### [16] [Distributed Cubature Kalman Filter based on MEEF with Adaptive Cauchy Kernel for State Estimation](https://arxiv.org/abs/2511.17066)
*Duc Viet Nguyen,Haiquan Zhao,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出了一种基于自适应最小误差熵的分布式容积卡尔曼滤波器（AMEEF-DCKF），用于解决多传感器网络中的非高斯噪声、异常数据和通信负担问题。


<details>
  <summary>Details</summary>
Motivation: 多传感器网络中的分布式容积卡尔曼滤波器面临非高斯噪声、异常数据和通信负担的挑战，需要开发更鲁棒和高效的算法。

Method: 设计了AMEEF优化准则（使用自适应带宽的柯西核）来处理非高斯噪声和异常数据，并构建了领导者-跟随者平均一致性（LFAC）算法来减轻通信负担。

Result: 通过10节点传感器网络验证，该算法在电力系统状态估计和复杂环境下的陆地车辆导航中表现出有效性。

Conclusion: AMEEF-DCKF算法成功解决了多传感器网络中的关键挑战，为非高斯噪声环境和通信受限场景提供了有效的状态估计解决方案。

Abstract: Nowadays, with the development of multi-sensor networks, the distributed cubature Kalman filter is one of the well-known existing schemes for state estimation, for which the influence of the non-Gaussian noise, abnormal data, and communication burden are urgent challenges. In this paper, a distributed cubature Kalman filter based on adaptive minimum error entropy with fiducial points (AMEEF) criterion (AMEEF-DCKF) is proposed to overcome the above limitations. Specifically, firstly, in order to solve the influence of various types of non-Gaussian noise and abnormal data, the AMEEF optimization criterion is designed, in which the kernels used are Cauchy kernels with adaptive bandwidth. At the same time, the designed optimization criterion has enhanced the numerical stability and optimized the kernel bandwidth value. Next, in order to address the communication burden problem in multi-sensor networks, where a leader and a follower are distinguished, a distributed algorithm is constructed to achieve an average consensus among these sensors, called leader-follower average consensus (LFAC). Additionally, the convergence proof of the average consensus algorithm and the computational complexity analysis of the AMEEF-DCKF algorithm are also presented. Finally, through a 10-node sensor network, the effectiveness of the proposed algorithm is demonstrated in estimating the state of the power system and navigating land vehicles in complex environments.

</details>


### [17] [Unleashing Sensor-Aided Environment Awareness for Beam Management in Beyond-5G Networks: An OpenAirInterface Experimental Platform](https://arxiv.org/abs/2511.17122)
*Aron Schott,Berk Acikgöz,Omar Massoud,Marina Petrova,Ljiljana Simić*

Main category: eess.SP

TL;DR: 提出了一个基于SDR的完整实验平台，集成低成本天线阵列收发器、波束扫描能力和模块化传感器框架，用于实时真实场景下的波束管理实验和数据集收集。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开放平台来收集用于训练基于机器学习的波束管理技术的数据集，以及在实时真实场景中评估新型波束管理方法。

Method: 基于OpenAirInterface开发SDR实验平台，集成低成本天线阵列收发器、波束扫描能力，以及高度模块化的传感器框架和相关接口。

Result: 成功构建了首个集成了这些组件的完整实验平台，能够在真实世界实时场景中进行波束管理实验。

Conclusion: 该平台为开发基于机器学习的波束管理协议提供了必要的数据集收集能力，并通过传感器模态实现了环境感知。

Abstract: Large antenna arrays and beamforming techniques are key components for exploiting the spectrum-rich FR2 bands in next-generation mobile communication networks. Given the site-specific spatio-temporal variations of the mm-wave channel, non-RF sensor inputs and environment awareness can be leveraged to greatly enhance beam management decisions, e.g. via machine learning (ML) techniques. However, the current literature lacks open platforms to gather datasets for the training of such ML techniques and to evaluate novel beam management approaches in real-time, real-world scenarios and full-stack endto-end networks. In this work, we present our SDR-based experimental platform based on OpenAirInterface and are the first to integrate popular low-cost antenna array transceivers, beam sweeping capabilities, and a highly-modular sensor framework and associated interfaces into such a full-stack experimental platform. This enables beam management experimentation in real-world, real-time scenarios and facilitates gathering datasets necessary for developing ML-based beam management protocols that incorporate environment awareness via sensor modalities.

</details>


### [18] [Teager-Kaiser Energy Methods For EEG Feature Extraction In Biomedical Applications](https://arxiv.org/abs/2511.17164)
*Ioanna Chourdaki,Kleanthis Avramidis,Christos Garoufis,Athanasia Zlatintsi,Petros Maragos*

Main category: eess.SP

TL;DR: 该论文研究了Teager-Kaiser能量算子(TKEO)在脑电图信号分析中的应用，通过Gabor滤波器组和能量分离算法提取能量描述符，在运动想象和癫痫检测任务中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 脑电图信号具有非线性、非平稳性和易受噪声影响的特点，提取判别性特征一直是挑战。本研究旨在探索TKEO算子对EEG信号能量动态建模的有效性。

Method: 使用Gabor滤波器组分离典型频带，然后应用能量分离算法将TKEO输出分解为幅度包络和瞬时频率分量，并基于此推导出一组能量描述符。

Result: TKEO特征在运动想象和癫痫检测任务中优于基线方法，在情绪识别任务中表现相当。

Conclusion: 基于TKEO的流程为提取EEG信号动态提供了一个直观的框架，在多个任务中显示出良好的性能。

Abstract: Electroencephalography (EEG) signals are inherently non-linear, non-stationary, and vulnerable to noise sources, making the extraction of discriminative features a long-standing challenge. In this work, we investigate the non-linear Teager-Kaiser Energy Operator (TKEO) for modeling the underlying energy dynamics of EEG in three representative tasks: motor imagery, emotion recognition, and epilepsy detection. To accommodate the narrowband nature of the operator, we employ Gabor filterbanks to isolate canonical frequency bands, followed by the Energy Separation Algorithm to decompose the TKEO output into amplitude envelope and instantaneous frequency components. We then derive a set of energy descriptors based on this demodulation and compare their classification performance against established signal energy and power spectrum features. TKEO features outperform the respective baselines in motor imagery and epilepsy detection, whereas they perform on par in emotion recognition. Our findings suggest that the proposed TKEO-based pipeline provides an intuitive framework for extracting EEG signal dynamics.

</details>


### [19] [Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities](https://arxiv.org/abs/2511.17440)
*Omar A. Alotaibi,Brian L. Mark,Mohammad Reza Fasihi*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯迁移学习的粒子滤波方法，用于处理双传感器系统中测量噪声强度不对称的非线性动态模型跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 在双跟踪系统中，当两个传感器的测量噪声强度不对称时，特别是主传感器噪声强度高于源传感器时，需要改进跟踪性能。

Method: 使用加权粒子之和来近似贝叶斯迁移学习的密度，将源传感器的信息迁移到主传感器以提升跟踪精度。

Result: 仿真结果表明，该方法相比孤立粒子滤波以及应用于无迹卡尔曼滤波和容积卡尔曼滤波的迁移学习方法更有效。增加粒子数量能显著提升性能，但会增加计算时间。性能提升与传感器噪声强度差异近似线性相关。

Conclusion: 贝叶斯迁移学习粒子滤波方法能有效提升双传感器系统中主传感器的跟踪性能，特别是在噪声强度不对称的情况下。

Abstract: Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system.

</details>
