{"id": "2508.11029", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11029", "abs": "https://arxiv.org/abs/2508.11029", "authors": ["Yuchen Zhang", "Francis Soualle", "Musa Furkan Keskin", "Yuan Liu", "Linlong Wu", "Jos\u00e9 A. del Peral-Rosado", "Bhavani Shankar M. R.", "Gonzalo Seco-Granados", "Henk Wymeersch", "Tareq Y. Al-Naffouri"], "title": "Distributed Integrated Sensing, Localization, and Communications over LEO Satellite Constellations", "comment": "This paper has been submitted to IEEE for possible publication", "summary": "Low Earth orbit (LEO) satellite constellations are rapidly becoming essential\nenablers of next-generation wireless systems, offering global broadband access,\nhigh-precision localization, and reliable sensing beyond terrestrial coverage.\nHowever, the inherent limitations of individual LEO satellites, including\nrestricted power, limited antenna aperture, and constrained onboard processing,\nhinder their ability to meet the growing demands of 6G applications. To address\nthese challenges, this article introduces the concept of distributed integrated\nsensing, localization, and communication (DISLAC) over LEO constellations,\ninspired by distributed multiple input multiple output architectures. By\nenabling inter-satellite cooperation through inter-satellite links, DISLAC can\nsubstantially improve throughput, positioning accuracy, and sensing robustness.\nWe present illustrative case studies that quantify these benefits and analyze\nkey system-level considerations, including synchronization, antenna\nreconfigurability, and ISL design. The article concludes by outlining open\nresearch directions to advance the practical deployment of DISLAC in future\nnon-terrestrial networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDISLAC\u7684\u5206\u5e03\u5f0f\u96c6\u6210\u611f\u77e5\u3001\u5b9a\u4f4d\u548c\u901a\u4fe1\u6982\u5ff5\uff0c\u901a\u8fc7LEO\u536b\u661f\u661f\u5ea7\u7684\u534f\u4f5c\u63d0\u53476G\u5e94\u7528\u7684\u6027\u80fd\u3002", "motivation": "LEO\u536b\u661f\u661f\u5ea7\u57286G\u5e94\u7528\u4e2d\u9762\u4e34\u529f\u7387\u3001\u5929\u7ebf\u5b54\u5f84\u548c\u673a\u8f7d\u5904\u7406\u7b49\u9650\u5236\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u591a\u8f93\u5165\u591a\u8f93\u51fa\u67b6\u6784\uff0c\u901a\u8fc7\u536b\u661f\u95f4\u94fe\u8def\u5b9e\u73b0\u534f\u4f5c\uff0c\u63d0\u5347\u541e\u5410\u91cf\u3001\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u611f\u77e5\u9c81\u68d2\u6027\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660eDISLAC\u80fd\u663e\u8457\u6539\u5584\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u540c\u6b65\u3001\u5929\u7ebf\u53ef\u91cd\u6784\u6027\u548cISL\u8bbe\u8ba1\u7b49\u5173\u952e\u95ee\u9898\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u4e86DISLAC\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u5176\u5728\u5b9e\u9645\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u7684\u90e8\u7f72\u3002"}}
{"id": "2508.11132", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.11132", "abs": "https://arxiv.org/abs/2508.11132", "authors": ["Sangwon Jo", "Seok-Hwan Park"], "title": "Multi-Satellite Cooperative MIMO Transmission: Statistical CSI-Aware RSMA Precoding Design", "comment": "accepted for publication in IEEE Wireless Communications Letters", "summary": "We investigate inter-satellite cooperative transmission in a multiple\nlow-Earth orbit (LEO) satellite communication system to enhance spectral\nefficiency. Specifically, we design multiple-input multipleoutput (MIMO)\nprecoding at LEO satellites for cooperative rate-splitting multiple access\n(RSMA). Given the difficulty of acquiring instantaneous channel state\ninformation (iCSI) due to long delays and Doppler effects, we formulate an\nergodic max-min fairness rate (MMFR) maximization problem based on statistical\nCSI (sCSI). To address the challenge of ergodic rate evaluation, we approximate\nthe problem using closed-form upper bounds and develop a weighted minimum mean\nsquared error-based algorithm to obtain a stationary point. Simulation results\ndemonstrate that the proposed sCSI-based RSMA scheme approaches iCSI-based\nperformance and significantly outperforms conventional space-division multiple\naccess.", "AI": {"tldr": "\u7814\u7a76\u4e86\u591a\u9897\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u95f4\u7684\u534f\u4f5c\u4f20\u8f93\u4ee5\u63d0\u9ad8\u9891\u8c31\u6548\u7387\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u7edf\u8ba1\u4fe1\u9053\u4fe1\u606f\u7684MIMO\u9884\u7f16\u7801\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u56e0\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u6548\u5e94\u5bfc\u81f4\u77ac\u65f6\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u96be\u4ee5\u83b7\u53d6\u7684\u95ee\u9898\uff0c\u63d0\u5347\u536b\u661f\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1CSI\u7684MIMO\u9884\u7f16\u7801\u65b9\u6848\uff0c\u901a\u8fc7\u95ed\u5f0f\u4e0a\u754c\u8fd1\u4f3c\u548c\u52a0\u6743\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u7b97\u6cd5\u6c42\u89e3\u95ee\u9898\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6848\u63a5\u8fd1\u77ac\u65f6CSI\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7a7a\u5206\u591a\u5740\u3002", "conclusion": "\u57fa\u4e8e\u7edf\u8ba1CSI\u7684RSMA\u65b9\u6848\u5728\u536b\u661f\u901a\u4fe1\u4e2d\u5177\u6709\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.11178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11178", "abs": "https://arxiv.org/abs/2508.11178", "authors": ["Yida Zhang", "Qiuyan Liu", "Qiang Wang", "Hongtao Luo", "Yuqi Xia"], "title": "Near-Field Variable-Width Beam Coverage and Codebook Design for XL-RIS", "comment": null, "summary": "To mitigate the issue of limited base station coverage caused by severe\nhigh-frequency electromagnetic wave attenuation, Extremely Large Reconfigurable\nIntelligent Surface (XL-RIS) has garnered significant attention due to its high\nbeam gain. However, XL-RIS exhibits a narrower beam width compared to\ntraditional RIS, which increases the complexity of beam alignment and\nbroadcast. To address this problem, we propose a variable-width beam generation\nalgorithm under the near-field assumption and apply it to the near-field\ncodebook design for XL-RIS. Our algorithm can achieve beam coverage for\narbitrarily shaped codeword regions and generate a joint codebook for the\nmulti-XL-RIS system. The simulation results demonstrate that our proposed\nscheme enables user equipment (UE) to achieve higher spectral efficiency and\nlower communication outage probability within the codeword region compared to\nexisting works. Furthermore, our scheme exhibits better robustness to codeword\nregion location and area variations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u53ef\u53d8\u5bbd\u5ea6\u6ce2\u675f\u751f\u6210\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3XL-RIS\u7a84\u6ce2\u675f\u5bbd\u5ea6\u5bfc\u81f4\u7684\u6ce2\u675f\u5bf9\u51c6\u548c\u5e7f\u64ad\u590d\u6742\u6027\u95ee\u9898\uff0c\u5e76\u5728\u8fd1\u573a\u7801\u672c\u8bbe\u8ba1\u4e2d\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3XL-RIS\u56e0\u7a84\u6ce2\u675f\u5bbd\u5ea6\u5e26\u6765\u7684\u6ce2\u675f\u5bf9\u51c6\u548c\u5e7f\u64ad\u590d\u6742\u6027\uff0c\u63d0\u5347\u8986\u76d6\u8303\u56f4\u548c\u901a\u4fe1\u6548\u7387\u3002", "method": "\u63d0\u51fa\u53ef\u53d8\u5bbd\u5ea6\u6ce2\u675f\u751f\u6210\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u8fd1\u573a\u7801\u672c\uff0c\u5e76\u5e94\u7528\u4e8e\u591aXL-RIS\u7cfb\u7edf\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0c\u8be5\u65b9\u6848\u80fd\u63d0\u9ad8\u7528\u6237\u8bbe\u5907\u7684\u9891\u8c31\u6548\u7387\uff0c\u964d\u4f4e\u901a\u4fe1\u4e2d\u65ad\u6982\u7387\uff0c\u5e76\u5bf9\u7801\u672c\u533a\u57df\u53d8\u5316\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86XL-RIS\u7684\u6ce2\u675f\u5bf9\u51c6\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2508.11186", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11186", "abs": "https://arxiv.org/abs/2508.11186", "authors": ["Mohammad Alikhani"], "title": "KAN-HAR: A Human activity recognition based on Kolmogorov-Arnold Network", "comment": null, "summary": "Human Activity Recognition (HAR) plays a critical role in numerous\napplications, including healthcare monitoring, fitness tracking, and smart\nenvironments. Traditional deep learning (DL) approaches, while effective, often\nrequire extensive parameter tuning and may lack interpretability. In this work,\nwe investigate the use of a single three-axis accelerometer and the\nKolmogorov--Arnold Network (KAN) for HAR tasks, leveraging its ability to model\ncomplex nonlinear relationships with improved interpretability and parameter\nefficiency. The MotionSense dataset, containing smartphone-based motion sensor\nsignals across various physical activities, is employed to evaluate the\nproposed approach. Our methodology involves preprocessing and normalization of\naccelerometer and gyroscope data, followed by KAN-based feature learning and\nclassification. Experimental results demonstrate that the KAN achieves\ncompetitive or superior classification performance compared to conventional\ndeep neural networks, while maintaining a significantly reduced parameter\ncount. This highlights the potential of KAN architectures as an efficient and\ninterpretable alternative for real-world HAR systems. The open-source\nimplementation of the proposed framework is available at the Project's GitHub\nRepository.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKolmogorov-Arnold Network (KAN)\u548c\u5355\u4e09\u8f74\u52a0\u901f\u5ea6\u8ba1\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53c2\u6570\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u4e2d\u9700\u8981\u5927\u91cf\u53c2\u6570\u8c03\u4f18\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0cKAN\u80fd\u66f4\u597d\u5730\u5efa\u6a21\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\u3002", "method": "\u4f7f\u7528MotionSense\u6570\u636e\u96c6\uff0c\u9884\u5904\u7406\u548c\u5f52\u4e00\u5316\u52a0\u901f\u5ea6\u8ba1\u548c\u9640\u87ba\u4eea\u6570\u636e\uff0c\u901a\u8fc7KAN\u8fdb\u884c\u7279\u5f81\u5b66\u4e60\u548c\u5206\u7c7b\u3002", "result": "KAN\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u6216\u4e0e\u4f20\u7edf\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\uff0c\u540c\u65f6\u53c2\u6570\u6570\u91cf\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "KAN\u67b6\u6784\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u7cfb\u7edf\u3002"}}
{"id": "2508.10941", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.10941", "abs": "https://arxiv.org/abs/2508.10941", "authors": ["Zhisen Hu", "David S. Johnson", "Aleksei Tiulpin", "Timothy F. Cootes", "Claudia Lindner"], "title": "The Role of Radiographic Knee Alignment in Knee Replacement Outcomes and Opportunities for Artificial Intelligence-Driven Assessment", "comment": null, "summary": "Prevalent knee osteoarthritis (OA) imposes substantial burden on health\nsystems with no cure available. Its ultimate treatment is total knee\nreplacement (TKR). Complications from surgery and recovery are difficult to\npredict in advance, and numerous factors may affect them. Radiographic knee\nalignment is one of the key factors that impacts TKR outcomes, affecting\noutcomes such as postoperative pain or function. Recently, artificial\nintelligence (AI) has been introduced to the automatic analysis of knee\nradiographs, for example, to automate knee alignment measurements. Existing\nreview articles tend to focus on knee OA diagnosis and segmentation of bones or\ncartilages in MRI rather than exploring knee alignment biomarkers for TKR\noutcomes and their assessment. In this review, we first examine the current\nscoring protocols for evaluating TKR outcomes and potential knee alignment\nbiomarkers associated with these outcomes. We then discuss existing AI-based\napproaches for generating knee alignment biomarkers from knee radiographs, and\nexplore future directions for knee alignment assessment and TKR outcome\nprediction.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u819d\u5173\u8282\u7f6e\u6362\u672f\uff08TKR\uff09\u7684\u9884\u540e\u4e0e\u819d\u5173\u8282\u5bf9\u9f50\u751f\u7269\u6807\u5fd7\u7269\u7684\u5173\u7cfb\uff0c\u63a2\u8ba8\u4e86AI\u5728\u819d\u5173\u8282\u5bf9\u9f50\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u819d\u5173\u8282\u9aa8\u5173\u8282\u708e\uff08OA\uff09\u7684\u6cbb\u7597\u4e3b\u8981\u4f9d\u8d56TKR\uff0c\u4f46\u624b\u672f\u6548\u679c\u96be\u4ee5\u9884\u6d4b\u3002\u819d\u5173\u8282\u5bf9\u9f50\u662f\u5f71\u54cdTKR\u9884\u540e\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\uff0c\u800c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8OA\u8bca\u65ad\u800c\u975e\u5bf9\u9f50\u751f\u7269\u6807\u5fd7\u7269\u3002", "method": "\u7efc\u8ff0\u4e86TKR\u9884\u540e\u8bc4\u5206\u6807\u51c6\u53ca\u819d\u5173\u8282\u5bf9\u9f50\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5e76\u8ba8\u8bba\u4e86AI\u5728\u819d\u5173\u8282\u5bf9\u9f50\u81ea\u52a8\u6d4b\u91cf\u4e2d\u7684\u5e94\u7528\u3002", "result": "AI\u5728\u819d\u5173\u8282\u5bf9\u9f50\u6d4b\u91cf\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8eOA\u8bca\u65ad\uff0c\u5bf9\u9f50\u751f\u7269\u6807\u5fd7\u7269\u4e0eTKR\u9884\u540e\u7684\u5173\u7cfb\u4ecd\u9700\u6df1\u5165\u63a2\u7d22\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u4e8e\u819d\u5173\u8282\u5bf9\u9f50\u751f\u7269\u6807\u5fd7\u7269\u7684\u5f00\u53d1\u53ca\u5176\u5bf9TKR\u9884\u540e\u7684\u9884\u6d4b\u4f5c\u7528\uff0cAI\u6280\u672f\u6709\u671b\u63a8\u52a8\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.11287", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.11287", "abs": "https://arxiv.org/abs/2508.11287", "authors": ["Xuran Liu", "Nan Xue", "Rui Bao", "Yaping Sun", "Zhiyong Chen", "Meixia Tao", "Xiaodong Xu", "Shuguang Cui"], "title": "CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems", "comment": "submitted to Journal of Communications and Information Networks", "summary": "While deploying large language models on edge devices promises low-latency\nand privacy-preserving AI services, it is hindered by limited device resources.\nAlthough pipeline parallelism facilitates distributed inference, existing\napproaches often ignore the cold-start latency caused by on-demand model\nloading. In this paper, we propose a latency-aware scheduling framework that\noverlaps model loading with computation and communication to minimize total\ninference latency. Based on device and model parameters, the framework\ndynamically adjusts layer partitioning and allocation to effectively hide\nloading time, thereby eliminating as many idle periods as possible. We\nformulate the problem as a Mixed-Integer Non-Linear Program and design an\nefficient dynamic programming algorithm to optimize model partitioning and\ndevice assignment. Experimental results show that the proposed method\nsignificantly reduces cold-start latency compared to baseline strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5ef6\u8fdf\u611f\u77e5\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u53e0\u6a21\u578b\u52a0\u8f7d\u4e0e\u8ba1\u7b97\u548c\u901a\u4fe1\u6765\u6700\u5c0f\u5316\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u6309\u9700\u6a21\u578b\u52a0\u8f7d\u5bfc\u81f4\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff0c\u4f18\u5316\u6a21\u578b\u5206\u533a\u548c\u8bbe\u5907\u5206\u914d\uff0c\u9690\u85cf\u52a0\u8f7d\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u51b7\u542f\u52a8\u5ef6\u8fdf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u63a8\u7406\u5ef6\u8fdf\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002"}}
{"id": "2508.11234", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11234", "abs": "https://arxiv.org/abs/2508.11234", "authors": ["Shengheng Liu", "Ningning Fu"], "title": "Enabling low-power massive MIMO with ternary ADCs for AIoT sensing", "comment": "Already published in ACM TOSN. 27 pages, 7 figures", "summary": "The proliferation of networked devices and the surging demand for ubiquitous\nintelligence have given rise to the artificial intelligence of things (AIoT).\nHowever, the utilization of high-resolution analog-to-digital converters (ADCs)\nand numerous radio frequency chains significantly raises power consumption.\nThis paper explores a cost-effective solution using ternary ADCs (T-ADCs) in\nmassive multiple-input-multiple-output (MIMO) systems for low-power AIoT and\nspecifically addresses channel sensing challenges. The channel is first\nestimated through a pilot-aided scheme and refined using a joint-pilot-and-data\n(JPD) approach. To assess the performance limits of this two-threshold ADC\nsystem, the analysis includes its hardware-ideal counterpart, the parallel\none-bit ADCs (PO-ADCs) and a realistic scenario where noise variance is unknown\nat the receiver is considered. Analytical findings indicate that the JPD scheme\neffectively mitigates performance degradation in channel estimation due to\ncoarse quantization effects under mild conditions, without necessitating\nadditional pilot overhead. For deterministic and random channels, we propose\nmodified expectation maximization (EM) and variational inference EM estimators,\nrespectively. Extensive simulations validate the theoretical results and\ndemonstrate the effectiveness of the proposed estimators in terms of mean\nsquare error and symbol error rate, which showcases the feasibility of\nimplementing T-ADCs and the associated JPD scheme for greener AIoT smart\nsensing.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u4f4e\u529f\u8017AIoT\u4e2d\u4f7f\u7528\u4e09\u5143ADC\uff08T-ADCs\uff09\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u5bfc\u9891\u4e0e\u6570\u636e\uff08JPD\uff09\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u8bbe\u5907\u7684\u666e\u53ca\u548c\u5bf9\u65e0\u5904\u4e0d\u5728\u667a\u80fd\u7684\u9700\u6c42\u589e\u957f\uff0cAIoT\u7684\u529f\u8017\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u5c24\u5176\u662f\u9ad8\u5206\u8fa8\u7387ADC\u548c\u591a\u5c04\u9891\u94fe\u7684\u9ad8\u529f\u8017\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e09\u5143ADC\uff08T-ADCs\uff09\u548cJPD\u65b9\u6848\u8fdb\u884c\u4fe1\u9053\u4f30\u8ba1\uff0c\u5206\u6790\u4e86\u5176\u6027\u80fd\u6781\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7684EM\u548c\u53d8\u5206\u63a8\u65adEM\u4f30\u8ba1\u5668\u3002", "result": "JPD\u65b9\u6848\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u6709\u6548\u7f13\u89e3\u4e86\u7c97\u91cf\u5316\u6548\u5e94\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u5728\u5747\u65b9\u8bef\u5dee\u548c\u7b26\u53f7\u9519\u8bef\u7387\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e09\u5143ADC\u548cJPD\u65b9\u6848\u5728\u4f4e\u529f\u8017AIoT\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u4e3a\u667a\u80fd\u611f\u77e5\u63d0\u4f9b\u4e86\u66f4\u73af\u4fdd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.11010", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11010", "abs": "https://arxiv.org/abs/2508.11010", "authors": ["Tausifa Jan Saleem", "Mohammad Yaqub"], "title": "Deep Learning-Based Automated Segmentation of Uterine Myomas", "comment": null, "summary": "Uterine fibroids (myomas) are the most common benign tumors of the female\nreproductive system, particularly among women of childbearing age. With a\nprevalence exceeding 70%, they pose a significant burden on female reproductive\nhealth. Clinical symptoms such as abnormal uterine bleeding, infertility,\npelvic pain, and pressure-related discomfort play a crucial role in guiding\ntreatment decisions, which are largely influenced by the size, number, and\nanatomical location of the fibroids. Magnetic Resonance Imaging (MRI) is a\nnon-invasive and highly accurate imaging modality commonly used by clinicians\nfor the diagnosis of uterine fibroids. Segmenting uterine fibroids requires a\nprecise assessment of both the uterus and fibroids on MRI scans, including\nmeasurements of volume, shape, and spatial location. However, this process is\nlabor intensive and time consuming and subjected to variability due to intra-\nand inter-expert differences at both pre- and post-treatment stages. As a\nresult, there is a critical need for an accurate and automated segmentation\nmethod for uterine fibroids. In recent years, deep learning algorithms have\nshown re-markable improvements in medical image segmentation, outperforming\ntraditional methods. These approaches offer the potential for fully automated\nsegmentation. Several studies have explored the use of deep learning models to\nachieve automated segmentation of uterine fibroids. However, most of the\nprevious work has been conducted using private datasets, which poses challenges\nfor validation and comparison between studies. In this study, we leverage the\npublicly available Uterine Myoma MRI Dataset (UMD) to establish a baseline for\nautomated segmentation of uterine fibroids, enabling standardized evaluation\nand facilitating future research in this domain.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5b50\u5bab\u808c\u7624\u7684\u81ea\u52a8\u5316\u5206\u5272\u9700\u6c42\uff0c\u5e76\u5229\u7528\u516c\u5f00\u6570\u636e\u96c6UMD\u5efa\u7acb\u57fa\u7ebf\uff0c\u4ee5\u4fc3\u8fdb\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u5b50\u5bab\u808c\u7624\u5bf9\u5973\u6027\u751f\u6b96\u5065\u5eb7\u9020\u6210\u91cd\u5927\u8d1f\u62c5\uff0c\u73b0\u6709MRI\u5206\u5272\u65b9\u6cd5\u8017\u65f6\u4e14\u6613\u53d7\u4e13\u5bb6\u5dee\u5f02\u5f71\u54cd\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u516c\u5f00\u6570\u636e\u96c6UMD\uff0c\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5b9e\u73b0\u5b50\u5bab\u808c\u7624\u7684\u81ea\u52a8\u5316\u5206\u5272\u3002", "result": "\u7814\u7a76\u4e3a\u5b50\u5bab\u808c\u7624\u7684\u81ea\u52a8\u5316\u5206\u5272\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u7ebf\u3002", "conclusion": "\u516c\u5f00\u6570\u636e\u96c6\u548c\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u7684\u7ed3\u5408\u4e3a\u5b50\u5bab\u808c\u7624\u5206\u5272\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.11291", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.11291", "abs": "https://arxiv.org/abs/2508.11291", "authors": ["Rui Bao", "Nan Xue", "Yaping Sun", "Zhiyong Chen"], "title": "Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks", "comment": "accepted by IEEE/CIC ICCC workshop", "summary": "The integration of wireless communications and Large Language Models (LLMs)\nis poised to unlock ubiquitous intelligent services, yet deploying them in\nwireless edge-device collaborative environments presents a critical trade-off\nbetween inference quality and end-to-end latency. A fundamental mismatch exists\nbetween task complexity and resource allocation: offloading simple queries\ninvites prohibitive latency, while on-device models lack the capacity for\ndemanding computations. To address this challenge, we propose a dynamic,\nquality-latency aware routing framework that orchestrates inference between a\nlightweight model on the mobile device and a powerful model on the edge server.\nOur framework employs two distinct cost models: for single-turn queries, it\nfuses a BERT-predicted semantic score with communication and computation\noverheads; for multi-turn dialogues, it further quantifies context-aware costs\narising from model switching and KV-cache management. While maintaining full\ninference quality, extensive experiments demonstrate that our framework cuts\naverage response latency by 5-15% and reduces large model invocations by 10-20%\nagainst competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u3001\u8d28\u91cf-\u5ef6\u8fdf\u611f\u77e5\u7684\u8def\u7531\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u79fb\u52a8\u8bbe\u5907\u548c\u8fb9\u7f18\u670d\u52a1\u5668\u4e4b\u95f4\u534f\u8c03\u63a8\u7406\u4efb\u52a1\uff0c\u4ee5\u5e73\u8861\u63a8\u7406\u8d28\u91cf\u548c\u5ef6\u8fdf\u3002", "motivation": "\u65e0\u7ebf\u901a\u4fe1\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7ed3\u5408\u6709\u671b\u5b9e\u73b0\u65e0\u5904\u4e0d\u5728\u7684\u667a\u80fd\u670d\u52a1\uff0c\u4f46\u5728\u65e0\u7ebf\u8fb9\u7f18\u8bbe\u5907\u534f\u4f5c\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\uff0c\u63a8\u7406\u8d28\u91cf\u4e0e\u7aef\u5230\u7aef\u5ef6\u8fdf\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u6743\u8861\u3002", "method": "\u6846\u67b6\u91c7\u7528\u4e24\u79cd\u6210\u672c\u6a21\u578b\uff1a\u5bf9\u4e8e\u5355\u8f6e\u67e5\u8be2\uff0c\u7ed3\u5408BERT\u9884\u6d4b\u7684\u8bed\u4e49\u5206\u6570\u4e0e\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\uff1b\u5bf9\u4e8e\u591a\u8f6e\u5bf9\u8bdd\uff0c\u8fdb\u4e00\u6b65\u91cf\u5316\u6a21\u578b\u5207\u6362\u548cKV\u7f13\u5b58\u7ba1\u7406\u5e26\u6765\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u5b8c\u6574\u63a8\u7406\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5e73\u5747\u54cd\u5e94\u5ef6\u8fdf\u964d\u4f4e\u4e865-15%\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51cf\u5c11\u4e8610-20%\u7684\u5927\u578b\u6a21\u578b\u8c03\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4efb\u52a1\u590d\u6742\u6027\u4e0e\u8d44\u6e90\u5206\u914d\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u534f\u4f5c\u73af\u5883\u4e2d\u7684\u667a\u80fd\u670d\u52a1\u63d0\u4f9b\u4e86\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2508.11259", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11259", "abs": "https://arxiv.org/abs/2508.11259", "authors": ["Ryosuke Isono", "Shunsuke Ono"], "title": "Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images", "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing.\n  arXiv admin note: text overlap with arXiv:2308.00500", "summary": "This paper proposes a novel spatiotemporal (ST) fusion framework for\nsatellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF).\nST fusion is a promising approach to address the trade-off between the spatial\nand temporal resolution of satellite images. In real-world scenarios, observed\nsatellite images are severely degraded by noise due to measurement equipment\nand environmental conditions. Consequently, some recent studies have focused on\nenhancing the robustness of ST fusion methods against noise. However, existing\nnoise-robust ST fusion approaches often fail to capture fine spatial structure,\nleading to oversmoothing and artifacts. To address this issue, TSSTF introduces\ntwo key mechanisms: Temporally-Guided Total Variation (TGTV) and\nTemporally-Guided Edge Constraint (TGEC). TGTV is a novel regularization\nfunction that promotes spatial piecewise smoothness while preserving structural\ndetails, guided by a reference high spatial resolution image acquired on a\nnearby date. TGEC enforces consistency in edge locations between two temporally\nadjacent images, while allowing for spectral variations. We formulate the ST\nfusion task as a constrained optimization problem incorporating TGTV and TGEC,\nand develop an efficient algorithm based on a preconditioned primal-dual\nsplitting method. Experimental results demonstrate that TSSTF performs\ncomparably to state-of-the-art methods under noise-free conditions and\noutperforms them under noisy conditions. Additionally, we provide a\ncomprehensive set of recommended parameter values that consistently yield high\nperformance across diverse target regions and noise conditions, aiming to\nenhance reproducibility and practical utility.", "AI": {"tldr": "TSSTF\u662f\u4e00\u79cd\u65b0\u7684\u65f6\u7a7a\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7TGTV\u548cTGEC\u673a\u5236\u63d0\u5347\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u56fe\u50cf\u878d\u5408\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u536b\u661f\u56fe\u50cf\u65f6\u7a7a\u5206\u8fa8\u7387\u6743\u8861\u95ee\u9898\uff0c\u5e76\u589e\u5f3a\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u5bfc\u81f4\u7684\u7ec6\u8282\u4e22\u5931\u548c\u4f2a\u5f71\u3002", "method": "\u5f15\u5165TGTV\u548cTGEC\u673a\u5236\uff0c\u5c06\u878d\u5408\u4efb\u52a1\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u9884\u6761\u4ef6\u539f\u59cb\u5bf9\u5076\u5206\u88c2\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "TSSTF\u5728\u65e0\u566a\u58f0\u6761\u4ef6\u4e0b\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u63d0\u4f9b\u4e86\u901a\u7528\u53c2\u6570\u63a8\u8350\u3002", "conclusion": "TSSTF\u5728\u566a\u58f0\u9c81\u68d2\u6027\u548c\u7ed3\u6784\u4fdd\u7559\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u5b9e\u7528\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2508.11181", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11181", "abs": "https://arxiv.org/abs/2508.11181", "authors": ["Faisal Ahmed"], "title": "HistoViT: Vision Transformer for Accurate and Scalable Histopathological Cancer Diagnosis", "comment": "13 pages, 3 Figures", "summary": "Accurate and scalable cancer diagnosis remains a critical challenge in modern\npathology, particularly for malignancies such as breast, prostate, bone, and\ncervical, which exhibit complex histological variability. In this study, we\npropose a transformer-based deep learning framework for multi-class tumor\nclassification in histopathological images. Leveraging a fine-tuned Vision\nTransformer (ViT) architecture, our method addresses key limitations of\nconventional convolutional neural networks, offering improved performance,\nreduced preprocessing requirements, and enhanced scalability across tissue\ntypes. To adapt the model for histopathological cancer images, we implement a\nstreamlined preprocessing pipeline that converts tiled whole-slide images into\nPyTorch tensors and standardizes them through data normalization. This ensures\ncompatibility with the ViT architecture and enhances both convergence stability\nand overall classification performance. We evaluate our model on four benchmark\ndatasets: ICIAR2018 (breast), SICAPv2 (prostate), UT-Osteosarcoma (bone), and\nSipakMed (cervical) dataset -- demonstrating consistent outperformance over\nexisting deep learning methods. Our approach achieves classification accuracies\nof 99.32%, 96.92%, 95.28%, and 96.94% for breast, prostate, bone, and cervical\ncancers respectively, with area under the ROC curve (AUC) scores exceeding 99%\nacross all datasets. These results confirm the robustness, generalizability,\nand clinical potential of transformer-based architectures in digital pathology.\nOur work represents a significant advancement toward reliable, automated, and\ninterpretable cancer diagnosis systems that can alleviate diagnostic burdens\nand improve healthcare outcomes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u75c5\u7406\u56fe\u50cf\u4e2d\u7684\u591a\u7c7b\u80bf\u7624\u5206\u7c7b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u764c\u75c7\u8bca\u65ad\u4e2d\u590d\u6742\u7ec4\u7ec7\u5b66\u53d8\u5f02\u6027\u7684\u6311\u6218\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u91c7\u7528\u5fae\u8c03\u7684Vision Transformer\u67b6\u6784\uff0c\u7b80\u5316\u9884\u5904\u7406\u6d41\u7a0b\uff0c\u5c06\u5168\u5207\u7247\u56fe\u50cf\u8f6c\u6362\u4e3aPyTorch\u5f20\u91cf\u5e76\u8fdb\u884c\u6807\u51c6\u5316\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u5747\u8d85\u8fc795%\uff0cAUC\u5f97\u5206\u5747\u9ad8\u4e8e99%\u3002", "conclusion": "Transformer\u67b6\u6784\u5728\u6570\u5b57\u75c5\u7406\u5b66\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u548c\u4e34\u5e8a\u6f5c\u529b\uff0c\u53ef\u63a8\u52a8\u81ea\u52a8\u5316\u764c\u75c7\u8bca\u65ad\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.11292", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.11292", "abs": "https://arxiv.org/abs/2508.11292", "authors": ["Xiaoqi Zhang", "Liang Liu", "Shuowen Zhang", "Haijun Zhang"], "title": "Beyond Diagonal Reconfigurable Intelligent Surface Enabled Sensing: Cramer-Rao Bound Optimization", "comment": "to appear in IEEE Wireless Communications Letters", "summary": "Recently, beyond diagonal reconfigurable intelligent surface (BD-RIS) has\nemerged as a more flexible solution to engineer the wireless propagation\nchannels, thanks to its non-diagonal reflecting matrix. Although the gain of\nthe BD-RIS over the conventional RIS in communication has been revealed in many\nworks, its gain in 6G sensing is still unknown. This motivates us to study the\nBD-RIS assisted sensing in this letter. Specifically, we derive the Cramer-Rao\nbound (CRB) for estimating the angle-of-arrival (AOA) from the target to the\nBD-RIS under the constraint that the BD-RIS scattering matrix is unitary. To\nminimize the CRB, we develop an optimization scheme based on an adaptive\nRiemannian steepest ascent algorithm that can satisfy the non-convex unitary\nconstraint. Numerical results demonstrate that the proposed BD-RIS-assisted\ntarget localization method achieves superior sensing performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u975e\u5bf9\u89d2\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08BD-RIS\uff09\u57286G\u611f\u77e5\u4e2d\u7684\u4f18\u52bf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u9ece\u66fc\u6700\u901f\u4e0a\u5347\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6848\uff0c\u4ee5\u6700\u5c0f\u5316CRB\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u7684\u611f\u77e5\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1BD-RIS\u5728\u901a\u4fe1\u4e2d\u7684\u4f18\u52bf\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u57286G\u611f\u77e5\u4e2d\u7684\u589e\u76ca\u5c1a\u4e0d\u660e\u786e\uff0c\u8fd9\u4fc3\u4f7f\u4f5c\u8005\u63a2\u7d22BD-RIS\u5728\u611f\u77e5\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4f5c\u8005\u63a8\u5bfc\u4e86\u5728BD-RIS\u6563\u5c04\u77e9\u9635\u4e3a\u9149\u77e9\u9635\u7ea6\u675f\u4e0b\u7684AOA\u4f30\u8ba1\u7684CRB\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u9ece\u66fc\u6700\u901f\u4e0a\u5347\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6848\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684BD-RIS\u8f85\u52a9\u76ee\u6807\u5b9a\u4f4d\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u611f\u77e5\u6027\u80fd\u3002", "conclusion": "BD-RIS\u57286G\u611f\u77e5\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5176\u4f18\u5316\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347\u76ee\u6807\u5b9a\u4f4d\u7684\u7cbe\u5ea6\u3002"}}
{"id": "2508.11211", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11211", "abs": "https://arxiv.org/abs/2508.11211", "authors": ["Zhenhao Li", "Long Yang", "Xiaojie Yin", "Haijun Yu", "Jiazhou Wang", "Hongbin Han", "Weigang Hu", "Yixing Huang"], "title": "Efficient Image-to-Image Schr\u00f6dinger Bridge for CT Field of View Extension", "comment": "10 pages", "summary": "Computed tomography (CT) is a cornerstone imaging modality for non-invasive,\nhigh-resolution visualization of internal anatomical structures. However, when\nthe scanned object exceeds the scanner's field of view (FOV), projection data\nare truncated, resulting in incomplete reconstructions and pronounced artifacts\nnear FOV boundaries. Conventional reconstruction algorithms struggle to recover\naccurate anatomy from such data, limiting clinical reliability. Deep learning\napproaches have been explored for FOV extension, with diffusion generative\nmodels representing the latest advances in image synthesis. Yet, conventional\ndiffusion models are computationally demanding and slow at inference due to\ntheir iterative sampling process. To address these limitations, we propose an\nefficient CT FOV extension framework based on the image-to-image Schr\\\"odinger\nBridge (I$^2$SB) diffusion model. Unlike traditional diffusion models that\nsynthesize images from pure Gaussian noise, I$^2$SB learns a direct stochastic\nmapping between paired limited-FOV and extended-FOV images. This direct\ncorrespondence yields a more interpretable and traceable generative process,\nenhancing anatomical consistency and structural fidelity in reconstructions.\nI$^2$SB achieves superior quantitative performance, with root-mean-square error\n(RMSE) values of 49.8\\,HU on simulated noisy data and 152.0HU on real data,\noutperforming state-of-the-art diffusion models such as conditional denoising\ndiffusion probabilistic models (cDDPM) and patch-based diffusion methods.\nMoreover, its one-step inference enables reconstruction in just 0.19s per 2D\nslice, representing over a 700-fold speedup compared to cDDPM (135s) and\nsurpassing diffusionGAN (0.58s), the second fastest. This combination of\naccuracy and efficiency makes I$^2$SB highly suitable for real-time or clinical\ndeployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSchr\u00f6dinger Bridge\u6269\u6563\u6a21\u578b\u7684\u9ad8\u6548CT\u89c6\u91ce\u6269\u5c55\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edfCT\u91cd\u5efa\u7b97\u6cd5\u5728\u89c6\u91ce\u8d85\u51fa\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u73b0\u6709\u6269\u6563\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u901f\u5ea6\u6162\u3002", "method": "\u91c7\u7528\u56fe\u50cf\u5230\u56fe\u50cf\u7684Schr\u00f6dinger Bridge\uff08I\u00b2SB\uff09\u6269\u6563\u6a21\u578b\uff0c\u76f4\u63a5\u5b66\u4e60\u6709\u9650\u89c6\u91ce\u4e0e\u6269\u5c55\u89c6\u91ce\u56fe\u50cf\u7684\u6620\u5c04\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6269\u6563\u6a21\u578b\uff0c\u91cd\u5efa\u901f\u5ea6\u663e\u8457\u63d0\u5347\uff080.19\u79d2/\u5207\u7247\uff09\u3002", "conclusion": "I\u00b2SB\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u5b9e\u65f6\u6216\u4e34\u5e8a\u90e8\u7f72\u3002"}}
{"id": "2508.11295", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.11295", "abs": "https://arxiv.org/abs/2508.11295", "authors": ["Xiaoqi Zhang", "Liang Liu", "Shuowen Zhang", "Weifeng Zhu", "Haijun Zhang"], "title": "Optimizing Rate-CRB Performance for Beyond Diagonal Reconfigurable Intelligent Surface Enabled ISAC", "comment": "to appear in IEEE Communications Letters", "summary": "This letter considers a beyond diagonal reconfigurable intelligent surface\n(BD-RIS) aided integrated sensing and communication (ISAC) system, where the\nBD-RIS can help a multi-antenna base station (BS) serve multiple user\nequipments (UEs) and localize a target simultaneously. We formulate an\noptimization problem that designs the BS beamforming matrix and the BD-RIS\nscattering matrix to maximize UEs' sum rate subject to a localization\nCramer-Rao bound (CRB) constraint and an additional unitary matrix constraint\nfor the scattering matrix. Because unitary matrices form a manifold, our\nproblem belongs to constrained manifold optimization. This letter proposes a\nlog-barrier based Riemannian steepest ascent method to solve this problem\neffectively. Numerical results verify the effectiveness of our algorithm and\nthe performance gain of the BD-RIS aided ISAC systems over the conventional RIS\naided ISAC systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBD-RIS\u7684ISAC\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316BS\u6ce2\u675f\u6210\u5f62\u77e9\u9635\u548cBD-RIS\u6563\u5c04\u77e9\u9635\uff0c\u5728\u6ee1\u8db3\u5b9a\u4f4d\u7cbe\u5ea6\u7ea6\u675f\u7684\u540c\u65f6\u6700\u5927\u5316\u7528\u6237\u603b\u901f\u7387\u3002\u91c7\u7528\u5bf9\u6570\u969c\u788d\u9ece\u66fc\u6700\u901f\u4e0a\u5347\u6cd5\u6c42\u89e3\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86BD-RIS\u4f18\u4e8e\u4f20\u7edfRIS\u7684\u6027\u80fd\u589e\u76ca\u3002", "motivation": "\u7814\u7a76BD-RIS\u5728ISAC\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u540c\u65f6\u63d0\u5347\u901a\u4fe1\u6027\u80fd\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u5bf9\u6570\u969c\u788d\u9ece\u66fc\u6700\u901f\u4e0a\u5347\u6cd5\uff0c\u4f18\u5316BS\u6ce2\u675f\u6210\u5f62\u77e9\u9635\u548cBD-RIS\u6563\u5c04\u77e9\u9635\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u7b97\u6cd5\u6709\u6548\uff0c\u4e14BD-RIS\u4f18\u4e8e\u4f20\u7edfRIS\u3002", "conclusion": "BD-RIS\u5728ISAC\u7cfb\u7edf\u4e2d\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\uff0c\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2508.11219", "categories": ["eess.IV", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.11219", "abs": "https://arxiv.org/abs/2508.11219", "authors": ["Tao Hong", "Umberto Villa", "Jeffrey A. Fessler"], "title": "A Convergent Generalized Krylov Subspace Method for Compressed Sensing MRI Reconstruction with Gradient-Driven Denoisers", "comment": "13 pages, 8 figures, 2 tables", "summary": "Model-based reconstruction plays a key role in compressed sensing (CS) MRI,\nas it incorporates effective image regularizers to improve the quality of\nreconstruction. The Plug-and-Play and Regularization-by-Denoising frameworks\nleverage advanced denoisers (e.g., convolutional neural network (CNN)-based\ndenoisers) and have demonstrated strong empirical performance. However, their\ntheoretical guarantees remain limited, as practical CNNs often violate key\nassumptions. In contrast, gradient-driven denoisers achieve competitive\nperformance, and the required assumptions for theoretical analysis are easily\nsatisfied. However, solving the associated optimization problem remains\ncomputationally demanding. To address this challenge, we propose a generalized\nKrylov subspace method (GKSM) to solve the optimization problem efficiently.\nMoreover, we also establish rigorous convergence guarantees for GKSM in\nnonconvex settings. Numerical experiments on CS MRI reconstruction with spiral\nand radial acquisitions validate both the computational efficiency of GKSM and\nthe accuracy of the theoretical predictions. The proposed optimization method\nis applicable to any linear inverse problem.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e7f\u4e49Krylov\u5b50\u7a7a\u95f4\u65b9\u6cd5\uff08GKSM\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u89e3\u51b3\u538b\u7f29\u611f\u77e5MRI\u91cd\u5efa\u4e2d\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u975e\u51f8\u8bbe\u7f6e\u4e0b\u7684\u4e25\u683c\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u53bb\u566a\u65b9\u6cd5\uff08\u5982CNN\uff09\u5728\u538b\u7f29\u611f\u77e5MRI\u91cd\u5efa\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff1b\u800c\u68af\u5ea6\u9a71\u52a8\u53bb\u566a\u65b9\u6cd5\u867d\u6ee1\u8db3\u7406\u8bba\u5206\u6790\u5047\u8bbe\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u5e7f\u4e49Krylov\u5b50\u7a7a\u95f4\u65b9\u6cd5\uff08GKSM\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u6c42\u89e3\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u975e\u51f8\u8bbe\u7f6e\u4e0b\u7684\u6536\u655b\u6027\u3002", "result": "\u5728\u87ba\u65cb\u548c\u5f84\u5411\u91c7\u96c6\u7684CS MRI\u91cd\u5efa\u5b9e\u9a8c\u4e2d\uff0cGKSM\u5c55\u793a\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u7406\u8bba\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "GKSM\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u4efb\u4f55\u7ebf\u6027\u9006\u95ee\u9898\u7684\u9ad8\u6548\u4f18\u5316\u65b9\u6cd5\uff0c\u517c\u5177\u8ba1\u7b97\u6548\u7387\u548c\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2508.11351", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11351", "abs": "https://arxiv.org/abs/2508.11351", "authors": ["Haonan Lu", "Rui Meng", "Xiaodong Xu", "Yiming Liu", "Ping Zhang", "Dusit Niyato"], "title": "Important Bit Prefix M-ary Quadrature Amplitude Modulation for Semantic Communications", "comment": null, "summary": "M-ary Quadrature Amplitude Modulation (MQAM) is a commonly used channel\nmodulation technology in wireless communication systems. To achieve dedicated\nchannel modulation for semantic communication (SemCom), we propose an\nImportant-Bit-Prefixed MQAM (IBP-MQAM) scheme and derive its approximate\nexpression of important symbol error rate (ISER) and unimportant symbol error\nrate (USER). By extracting and quantifying text semantics using Latent\nDirichlet Allocation (LDA), we verify that IBP-MQAM achieves improved\nperformance over MQAM in SemCom scenarios and further analyze the effects of\nkey system parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u8981\u4f4d\u524d\u7f00\u7684MQAM\u65b9\u6848\uff08IBP-MQAM\uff09\uff0c\u7528\u4e8e\u8bed\u4e49\u901a\u4fe1\uff0c\u5e76\u901a\u8fc7LDA\u91cf\u5316\u8bed\u4e49\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u8bed\u4e49\u901a\u4fe1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u4e3a\u8bed\u4e49\u901a\u4fe1\uff08SemCom\uff09\u8bbe\u8ba1\u4e13\u7528\u7684\u4fe1\u9053\u8c03\u5236\u6280\u672f\uff0c\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faIBP-MQAM\u65b9\u6848\uff0c\u63a8\u5bfc\u91cd\u8981\u7b26\u53f7\u9519\u8bef\u7387\uff08ISER\uff09\u548c\u975e\u91cd\u8981\u7b26\u53f7\u9519\u8bef\u7387\uff08USER\uff09\u7684\u8fd1\u4f3c\u8868\u8fbe\u5f0f\uff0c\u4f7f\u7528LDA\u63d0\u53d6\u548c\u91cf\u5316\u6587\u672c\u8bed\u4e49\u3002", "result": "IBP-MQAM\u5728\u8bed\u4e49\u901a\u4fe1\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfMQAM\uff0c\u5e76\u5206\u6790\u4e86\u5173\u952e\u7cfb\u7edf\u53c2\u6570\u7684\u5f71\u54cd\u3002", "conclusion": "IBP-MQAM\u4e3a\u8bed\u4e49\u901a\u4fe1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4fe1\u9053\u8c03\u5236\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.11331", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11331", "abs": "https://arxiv.org/abs/2508.11331", "authors": ["Xinyi Wang", "Smaranda Tasmoc", "Nantheera Anantrasirichai", "Angeliki Katsenou"], "title": "Guiding WaveMamba with Frequency Maps for Image Debanding", "comment": "5 pages, 2 figures", "summary": "Compression at low bitrates in modern codecs often introduces banding\nartifacts, especially in smooth regions such as skies. These artifacts degrade\nvisual quality and are common in user-generated content due to repeated\ntranscoding. We propose a banding restoration method that employs the Wavelet\nState Space Model and a frequency masking map to preserve high-frequency\ndetails. Furthermore, we provide a benchmark of open-source banding restoration\nmethods and evaluate their performance on two public banding image datasets.\nExperimentation on the available datasets suggests that the proposed\npost-processing approach effectively suppresses banding compared to the\nstate-of-the-art method (a DBI value of 0.082 on BAND-2k) while preserving\nimage textures. Visual inspections of the results confirm this. Code and\nsupplementary material are available at:\nhttps://github.com/xinyiW915/Debanding-PCS2025.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u9891\u7387\u63a9\u7801\u56fe\u7684\u9891\u5e26\u4fee\u590d\u65b9\u6cd5\uff0c\u6709\u6548\u6291\u5236\u4f4e\u7801\u7387\u538b\u7f29\u4e2d\u7684\u6761\u5e26\u4f2a\u5f71\uff0c\u5e76\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f4e\u7801\u7387\u538b\u7f29\u5e38\u5bfc\u81f4\u5e73\u6ed1\u533a\u57df\uff08\u5982\u5929\u7a7a\uff09\u51fa\u73b0\u6761\u5e26\u4f2a\u5f71\uff0c\u5f71\u54cd\u89c6\u89c9\u8d28\u91cf\uff0c\u5c24\u5176\u5728\u7528\u6237\u751f\u6210\u5185\u5bb9\u4e2d\u56e0\u591a\u6b21\u8f6c\u7801\u800c\u66f4\u5e38\u89c1\u3002", "method": "\u91c7\u7528\u5c0f\u6ce2\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u9891\u7387\u63a9\u7801\u56fe\uff0c\u4fdd\u7559\u9ad8\u9891\u7ec6\u8282\uff0c\u540c\u65f6\u63d0\u51fa\u5f00\u6e90\u9891\u5e26\u4fee\u590d\u65b9\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff08DBI\u503c\u4e3a0.082\uff09\uff0c\u4e14\u80fd\u4fdd\u7559\u56fe\u50cf\u7eb9\u7406\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6291\u5236\u6761\u5e26\u4f2a\u5f71\uff0c\u89c6\u89c9\u68c0\u67e5\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002\u4ee3\u7801\u548c\u8865\u5145\u6750\u6599\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.11457", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11457", "abs": "https://arxiv.org/abs/2508.11457", "authors": ["Hui Cao", "Rui Meng", "Xiaodong Xu", "Shujun Han", "Ping Zhang"], "title": "Importance-Aware Robust Semantic Transmission for LEO Satellite-Ground Communication", "comment": null, "summary": "Satellite-ground semantic communication is anticipated to serve a critical\nrole in the forthcoming 6G era. Nonetheless, task-oriented data transmission in\nsuch systems remains a formidable challenge, primarily due to the dynamic\nnature of signal-to-noise ratio (SNR) fluctuations and the stringent bandwidth\nlimitations inherent to low Earth orbit (LEO) satellite channels. In response\nto these constraints, we propose an importance-aware robust semantic\ntransmission (IRST) framework, specifically designed for scenarios\ncharacterized by bandwidth scarcity and channel variability. The IRST scheme\nbegins by applying a segmentation model enhancement algorithm to improve the\ngranularity and accuracy of semantic segmentation. Subsequently, a task-driven\nsemantic selection method is employed to prioritize the transmission of\nsemantically vital content based on real-time channel state information.\nFurthermore, the framework incorporates a stack-based, SNR-aware channel codec\ncapable of executing adaptive channel coding in alignment with SNR variations.\nComparative evaluations across diverse operating conditions demonstrate the\nsuperior performance and resilience of the IRST model relative to existing\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cd\u8981\u6027\u611f\u77e5\u7684\u9c81\u68d2\u8bed\u4e49\u4f20\u8f93\u6846\u67b6\uff08IRST\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u536b\u661f-\u5730\u9762\u8bed\u4e49\u901a\u4fe1\u4e2d\u7684\u52a8\u6001SNR\u6ce2\u52a8\u548c\u5e26\u5bbd\u9650\u5236\u95ee\u9898\u3002", "motivation": "6G\u65f6\u4ee3\u536b\u661f-\u5730\u9762\u8bed\u4e49\u901a\u4fe1\u9762\u4e34\u52a8\u6001SNR\u6ce2\u52a8\u548c\u5e26\u5bbd\u9650\u5236\u7684\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u4efb\u52a1\u5bfc\u5411\u6570\u636e\u4f20\u8f93\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5206\u5272\u6a21\u578b\u589e\u5f3a\u7b97\u6cd5\u63d0\u5347\u8bed\u4e49\u5206\u5272\u7cbe\u5ea6\uff0c\u91c7\u7528\u4efb\u52a1\u9a71\u52a8\u7684\u8bed\u4e49\u9009\u62e9\u65b9\u6cd5\u4f18\u5148\u4f20\u8f93\u5173\u952e\u5185\u5bb9\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u5806\u6808\u7684SNR\u611f\u77e5\u4fe1\u9053\u7f16\u89e3\u7801\u5668\u3002", "result": "IRST\u6846\u67b6\u5728\u591a\u79cd\u64cd\u4f5c\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "IRST\u6846\u67b6\u4e3a\u5e26\u5bbd\u7a00\u7f3a\u548c\u4fe1\u9053\u591a\u53d8\u7684\u536b\u661f-\u5730\u9762\u8bed\u4e49\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.11375", "categories": ["eess.IV", "cs.CV", "I.4.9"], "pdf": "https://arxiv.org/pdf/2508.11375", "abs": "https://arxiv.org/abs/2508.11375", "authors": ["Zonglin Wu", "Yule Xue", "Qianxiang Hu", "Yaoyao Feng", "Yuqi Ma", "Shanxiong Chen"], "title": "AnatoMaskGAN: GNN-Driven Slice Feature Fusion and Noise Augmentation for Medical Semantic Image Synthesis", "comment": "8 pages", "summary": "Medical semantic-mask synthesis boosts data augmentation and analysis, yet\nmost GAN-based approaches still produce one-to-one images and lack spatial\nconsistency in complex scans. To address this, we propose AnatoMaskGAN, a novel\nsynthesis framework that embeds slice-related spatial features to precisely\naggregate inter-slice contextual dependencies, introduces diverse\nimage-augmentation strategies, and optimizes deep feature learning to improve\nperformance on complex medical images. Specifically, we design a GNN-based\nstrongly correlated slice-feature fusion module to model spatial relationships\nbetween slices and integrate contextual information from neighboring slices,\nthereby capturing anatomical details more comprehensively; we introduce a\nthree-dimensional spatial noise-injection strategy that weights and fuses\nspatial features with noise to enhance modeling of structural diversity; and we\nincorporate a grayscale-texture classifier to optimize grayscale distribution\nand texture representation during generation. Extensive experiments on the\npublic L2R-OASIS and L2R-Abdomen CT datasets show that AnatoMaskGAN raises PSNR\non L2R-OASIS to 26.50 dB (0.43 dB higher than the current state of the art) and\nachieves an SSIM of 0.8602 on L2R-Abdomen CT--a 0.48 percentage-point gain over\nthe best model, demonstrating its superiority in reconstruction accuracy and\nperceptual quality. Ablation studies that successively remove the slice-feature\nfusion module, spatial 3D noise-injection strategy, and grayscale-texture\nclassifier reveal that each component contributes significantly to PSNR, SSIM,\nand LPIPS, further confirming the independent value of each core design in\nenhancing reconstruction accuracy and perceptual quality.", "AI": {"tldr": "AnatoMaskGAN\u662f\u4e00\u79cd\u65b0\u578b\u533b\u5b66\u56fe\u50cf\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u5207\u7247\u76f8\u5173\u7a7a\u95f4\u7279\u5f81\u3001\u591a\u6837\u5316\u56fe\u50cf\u589e\u5f3a\u7b56\u7565\u548c\u4f18\u5316\u6df1\u5ea6\u7279\u5f81\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u533b\u5b66\u56fe\u50cf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GAN\u65b9\u6cd5\u5728\u533b\u5b66\u56fe\u50cf\u5408\u6210\u4e2d\u7f3a\u4e4f\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u591a\u6837\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u626b\u63cf\u7684\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1GNN\u5207\u7247\u7279\u5f81\u878d\u5408\u6a21\u5757\u3001\u4e09\u7ef4\u7a7a\u95f4\u566a\u58f0\u6ce8\u5165\u7b56\u7565\u548c\u7070\u5ea6\u7eb9\u7406\u5206\u7c7b\u5668\uff0c\u4ee5\u589e\u5f3a\u7a7a\u95f4\u5173\u7cfb\u548c\u591a\u6837\u6027\u5efa\u6a21\u3002", "result": "\u5728L2R-OASIS\u548cL2R-Abdomen CT\u6570\u636e\u96c6\u4e0a\uff0cPSNR\u548cSSIM\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "AnatoMaskGAN\u7684\u6838\u5fc3\u8bbe\u8ba1\u5747\u5bf9\u91cd\u5efa\u7cbe\u5ea6\u548c\u611f\u77e5\u8d28\u91cf\u6709\u72ec\u7acb\u8d21\u732e\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.11459", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11459", "abs": "https://arxiv.org/abs/2508.11459", "authors": ["Tzu-Chi Liu", "Po-Lin Chen", "Yi-Chieh Chen", "Po-Hsun Tu", "Chih-Hua Yeh", "Mun-Chun Yeap", "Chiung-Chu Chen", "Hau-Tieng Wu"], "title": "Efficient Artifacts Removal for Adaptive Deep Brain Stimulation and a Temporal Event Localization Analysis", "comment": "This manuscript is under review at Journal of Neural Engineering", "summary": "Adaptive deep brain stimulation (aDBS) leverages symptom-related biomarkers\nto deliver personalized neuromodulation therapy, with the potential to improve\ntreatment efficacy and reduce power consumption compared to conventional DBS.\nHowever, stimulation-induced signal contamination remains a major technical\nbarrier to advancing its clinical application. Existing artifact removal\nstrategies, both front-end and back-end, face trade-offs between artifact\nsuppression and algorithmic flexibility. Among back-end algorithms, Shrinkage\nand Manifold-based Artifact Removal using Template Adaptation (SMARTA) has\nshown promising performance in mitigating stimulus artifacts with minimal\ndistortion to local field potentials (LFPs), but its high computational demand\nand inability to handle transient direct current (DC) artifacts limit its use\nin real-time applications. To address this, we developed SMARTA+, a\ncomputationally efficient extension of SMARTA capable of suppressing both\nstimulus and transient DC artifacts while supporting flexible algorithmic\ndesign. We evaluated SMARTA+ using semi-real aDBS data and real data from\nParkinson's disease patients. Compared to SMARTA and other established methods,\nSMARTA+ achieved comparable or superior artifact removal while significantly\nreducing computation time. It preserved spectral and temporal structures,\nranging from beta band to high-frequency oscillations, and demonstrated\nrobustness across diverse stimulation protocols. Temporal event localization\nanalysis further showed improved accuracy in detecting beta bursts. These\nfindings support SMARTA+ as a promising tool for advancing real-time,\nclosed-loop aDBS systems.", "AI": {"tldr": "SMARTA+\u662f\u4e00\u79cd\u9ad8\u6548\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3aDBS\u4e2d\u7684\u4fe1\u53f7\u6c61\u67d3\u95ee\u9898\uff0c\u6bd4SMARTA\u548c\u5176\u4ed6\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u4f20\u7edfaDBS\u5b58\u5728\u4fe1\u53f7\u6c61\u67d3\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6291\u5236\u4f2a\u8ff9\u548c\u7b97\u6cd5\u7075\u6d3b\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "method": "\u5f00\u53d1SMARTA+\uff0c\u6539\u8fdbSMARTA\u7b97\u6cd5\uff0c\u652f\u6301\u6291\u5236\u523a\u6fc0\u548c\u77ac\u6001DC\u4f2a\u8ff9\uff0c\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "SMARTA+\u5728\u4f2a\u8ff9\u53bb\u9664\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4fdd\u7559\u4fe1\u53f7\u9891\u8c31\u548c\u65f6\u95f4\u7ed3\u6784\u3002", "conclusion": "SMARTA+\u6709\u671b\u63a8\u52a8\u5b9e\u65f6\u95ed\u73afaDBS\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.11391", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11391", "abs": "https://arxiv.org/abs/2508.11391", "authors": ["Yinggan Tang", "Quanwei Hu"], "title": "LKFMixer: Exploring Large Kernel Feature For Efficient Image Super-Resolution", "comment": null, "summary": "The success of self-attention (SA) in Transformer demonstrates the importance\nof non-local information to image super-resolution (SR), but the huge computing\npower required makes it difficult to implement lightweight models. To solve\nthis problem, we propose a pure convolutional neural network (CNN) model,\nLKFMixer, which utilizes large convolutional kernel to simulate the ability of\nself-attention to capture non-local features. Specifically, we increase the\nkernel size to 31 to obtain the larger receptive field as possible, and reduce\nthe parameters and computations by coordinate decomposition. Meanwhile, a\nspatial feature modulation block (SFMB) is designed to enhance the focus of\nfeature information on both spatial and channel dimension. In addition, by\nintroducing feature selection block (FSB), the model can adaptively adjust the\nweights between local features and non-local features. Extensive experiments\nshow that the proposed LKFMixer family outperform other state-of-the-art (SOTA)\nmethods in terms of SR performance and reconstruction quality. In particular,\ncompared with SwinIR-light on Manga109 dataset, LKFMixer-L achieves 0.6dB PSNR\nimprovement at $\\times$4 scale, while the inference speed is $\\times$5 times\nfaster. The code is available at https://github.com/Supereeeee/LKFMixer.", "AI": {"tldr": "LKFMixer\u662f\u4e00\u79cd\u7eaf\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u901a\u8fc7\u5927\u5377\u79ef\u6838\u6a21\u62df\u81ea\u6ce8\u610f\u529b\u7684\u975e\u5c40\u90e8\u7279\u5f81\u6355\u83b7\u80fd\u529b\uff0c\u63d0\u5347\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u6027\u80fd\u3002", "motivation": "\u81ea\u6ce8\u610f\u529b\u5728Transformer\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8ba1\u7b97\u91cf\u5927\uff0c\u96be\u4ee5\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002", "method": "\u4f7f\u752831\u5927\u5c0f\u7684\u5377\u79ef\u6838\u6269\u5927\u611f\u53d7\u91ce\uff0c\u901a\u8fc7\u5750\u6807\u5206\u89e3\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\uff0c\u5f15\u5165SFMB\u548cFSB\u6a21\u5757\u4f18\u5316\u7279\u5f81\u63d0\u53d6\u3002", "result": "LKFMixer\u5728\u8d85\u5206\u8fa8\u7387\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6SOTA\u65b9\u6cd5\uff0cPSNR\u63d0\u53470.6dB\uff0c\u63a8\u7406\u901f\u5ea6\u5feb5\u500d\u3002", "conclusion": "LKFMixer\u901a\u8fc7\u5377\u79ef\u6838\u6a21\u62df\u81ea\u6ce8\u610f\u529b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9ad8\u6027\u80fd\u7684\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u3002"}}
{"id": "2508.11473", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11473", "abs": "https://arxiv.org/abs/2508.11473", "authors": ["Yuqin Liu", "Mona Jaber", "Yan Liu", "Arumugam Nallanathan"], "title": "Reducing AoI and Improving Throughput for NOMA-assisted SGF Systems: A Hierarchical Learning Approach", "comment": null, "summary": "A non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF)\nframework is proposed to enable channel access for grant-free users (GFUs) by\nusing residual resources from grant-based users. Under this framework, the\nproblem of joint beamforming design and transmission scheduling is formulated\nto improve the system throughput and reduce the age-of-information of GFUs. The\naforementioned problem is transferred into a Markov Decision Process to model\nthe changing environment with the transmission/ waiting/ retransmission of\nGFUs. In an effort to solve the pertinent problem, firstly, a deep\nreinforcement learning (DRL) based transmission scheduling approach is proposed\nfor determining the optimal transmission probability based on the available\ntransmission slots and transmission status of GFUs. Secondly, a hierarchical\nlearning algorithm is proposed to analyze the channel state information of GBUs\nand the transmission status of GFUs, and to train an upper-level policy based\non this analysis for beamforming to achieve efficient grant-based transmission,\nwhile a lower-level policy adapts to maximize the utilization of transmission\nslots allocated by the upper-level agent. The two policies interact to improve\nchannel access and avoid collisions. Numerical results reveal that 1) The DRL\nbased transmission scheduling outperforms existing adaptive and state-dependent\nbaselines in AoI reduction, where an average\nthree-time-slots-earlier-transmission can be obtained compared to the\nstate-dependent choice, and five time slots earlier can be achieved when\ncomparing to the adaptive choice; 2) The hierarchical learning algorithm is\nable to achieve approximately a 31.82% gain while maintaining the average AoI\nof GFUs within 1.5 time slots. 3) The effectiveness of the hierarchical\nlearning scheme in NOMA-assisted SGF system is validated across scenarios with\nGFUs counts from 1-5 times of GBUs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u6b63\u4ea4\u591a\u5740\uff08NOMA\uff09\u7684\u534a\u514d\u6388\u6743\uff08SGF\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u6388\u6743\u7528\u6237\u7684\u5269\u4f59\u8d44\u6e90\u4e3a\u514d\u6388\u6743\u7528\u6237\uff08GFUs\uff09\u63d0\u4f9b\u4fe1\u9053\u63a5\u5165\u3002\u901a\u8fc7\u8054\u5408\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u548c\u4f20\u8f93\u8c03\u5ea6\u4f18\u5316\u7cfb\u7edf\u541e\u5410\u91cf\u5e76\u964d\u4f4eGFUs\u7684\u4fe1\u606f\u65f6\u6548\u6027\uff08AoI\uff09\u3002\u95ee\u9898\u88ab\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u548c\u5206\u5c42\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDRL\u8c03\u5ea6\u5728AoI\u51cf\u5c11\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5206\u5c42\u5b66\u4e60\u7b97\u6cd5\u5728\u541e\u5410\u91cf\u63d0\u5347\u548cAoI\u63a7\u5236\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u514d\u6388\u6743\u7528\u6237\u5728\u4fe1\u9053\u63a5\u5165\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u541e\u5410\u91cf\u548c\u4fe1\u606f\u65f6\u6548\u6027\u3002", "method": "1. \u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff1b2. \u63d0\u51fa\u57fa\u4e8eDRL\u7684\u4f20\u8f93\u8c03\u5ea6\u65b9\u6cd5\uff1b3. \u8bbe\u8ba1\u5206\u5c42\u5b66\u4e60\u7b97\u6cd5\uff0c\u4e0a\u5c42\u7b56\u7565\u4f18\u5316\u6ce2\u675f\u6210\u5f62\uff0c\u4e0b\u5c42\u7b56\u7565\u6700\u5927\u5316\u4f20\u8f93\u65f6\u9699\u5229\u7528\u7387\u3002", "result": "1. DRL\u8c03\u5ea6\u5728AoI\u51cf\u5c11\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff1b2. \u5206\u5c42\u5b66\u4e60\u7b97\u6cd5\u63d0\u5347\u541e\u5410\u91cf31.82%\uff0c\u540c\u65f6\u5c06GFUs\u7684\u5e73\u5747AoI\u63a7\u5236\u57281.5\u65f6\u9699\u5185\uff1b3. \u65b9\u6cd5\u5728GFUs\u6570\u91cf\u4e3aGBUs\u76841-5\u500d\u65f6\u5747\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684NOMA\u8f85\u52a9SGF\u6846\u67b6\u53ca\u5206\u5c42\u5b66\u4e60\u7b97\u6cd5\u5728\u4f18\u5316\u4fe1\u9053\u63a5\u5165\u548cAoI\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u573a\u666f\u3002"}}
{"id": "2508.11450", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11450", "abs": "https://arxiv.org/abs/2508.11450", "authors": ["Augustine X. W. Lee", "Pak-Hei Yeung", "Jagath C. Rajapakse"], "title": "Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer", "comment": null, "summary": "Subcortical segmentation in neuroimages plays an important role in\nunderstanding brain anatomy and facilitating computer-aided diagnosis of\ntraumatic brain injuries and neurodegenerative disorders. However, training\naccurate automatic models requires large amounts of labelled data. Despite the\navailability of publicly available subcortical segmentation datasets for\nMagnetic Resonance Imaging (MRI), a significant gap exists for Computed\nTomography (CT). This paper proposes an automatic ensemble framework to\ngenerate high-quality subcortical segmentation labels for CT scans by\nleveraging existing MRI-based models. We introduce a robust ensembling pipeline\nto integrate them and apply it to unannotated paired MRI-CT data, resulting in\na comprehensive CT subcortical segmentation dataset. Extensive experiments on\nmultiple public datasets demonstrate the superior performance of our proposed\nframework. Furthermore, using our generated CT dataset, we train segmentation\nmodels that achieve improved performance on related segmentation tasks. To\nfacilitate future research, we make our source code, generated dataset, and\ntrained models publicly available at\nhttps://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation,\nmarking the first open-source release for CT subcortical segmentation to the\nbest of our knowledge.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u96c6\u6210\u6846\u67b6\uff0c\u5229\u7528MRI\u6a21\u578b\u4e3aCT\u626b\u63cf\u751f\u6210\u9ad8\u8d28\u91cf\u76ae\u5c42\u4e0b\u5206\u5272\u6807\u7b7e\uff0c\u586b\u8865CT\u6570\u636e\u7a7a\u767d\u3002", "motivation": "\u89e3\u51b3CT\u626b\u63cf\u4e2d\u76ae\u5c42\u4e0b\u5206\u5272\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4fc3\u8fdb\u8111\u90e8\u75be\u75c5\u8bca\u65ad\u3002", "method": "\u901a\u8fc7\u96c6\u6210MRI\u6a21\u578b\uff0c\u6784\u5efa\u9c81\u68d2\u7684\u96c6\u6210\u6d41\u7a0b\uff0c\u5e94\u7528\u4e8e\u672a\u6807\u6ce8\u7684MRI-CT\u914d\u5bf9\u6570\u636e\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u751f\u6210\u7684CT\u6570\u636e\u96c6\u63d0\u5347\u4e86\u5206\u5272\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u5f00\u6e90\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u63a8\u52a8CT\u76ae\u5c42\u4e0b\u5206\u5272\u7814\u7a76\u3002"}}
{"id": "2508.11489", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.11489", "abs": "https://arxiv.org/abs/2508.11489", "authors": ["Bowu Wang", "Mohamadreza Delbari", "Robin Neuder", "Alejandro Jim\u00e9nez-S\u00e1ez", "Vahid Jamali"], "title": "Liquid Crystal-Based RIS Loss-Trade-Off Analysis", "comment": null, "summary": "Liquid crystal (LC) technology has emerged as a promising solution for large\nreconfigurable intelligent surfaces (RISs) at millimeter wave (mmWave) bands,\noffering advantages such as low power consumption, scalability, and\ncontinuously tunable phase shifts. For LC-RIS based on the delay-line\narchitecture, i.e., with dedicated phase shifters, there exists a trade-off\nbetween the maximum achievable phase-shift range and the corresponding\ninsertion loss, which has not been studied for LC-RIS-assisted wireless systems\nyet. In this paper, we investigate this trade-off where a base station (BS) and\nan RIS are configured to minimize the transmit power while satisfying a given\nquality of service (QoS) for a number of users. Simulation results reveal a\nfundamental trade-off between the total transmit power and the achievable data\nrate as a function of the LC phase-shift range.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6db2\u6676\u6280\u672f\u7684\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u5728\u6beb\u7c73\u6ce2\u9891\u6bb5\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u76f8\u4f4d\u504f\u79fb\u8303\u56f4\u4e0e\u63d2\u5165\u635f\u8017\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u6db2\u6676\u6280\u672f\u56e0\u5176\u4f4e\u529f\u8017\u3001\u53ef\u6269\u5c55\u6027\u548c\u8fde\u7eed\u53ef\u8c03\u76f8\u4f4d\u504f\u79fb\u7b49\u4f18\u52bf\u6210\u4e3aRIS\u7684\u6709\u529b\u5019\u9009\uff0c\u4f46\u5176\u76f8\u4f4d\u504f\u79fb\u8303\u56f4\u4e0e\u63d2\u5165\u635f\u8017\u7684\u6743\u8861\u5c1a\u672a\u5728\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u914d\u7f6e\u57fa\u7ad9\u548cRIS\u4ee5\u6700\u5c0f\u5316\u53d1\u5c04\u529f\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u7528\u6237\u7684\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\uff0c\u7814\u7a76\u4e86LC-RIS\u7684\u76f8\u4f4d\u504f\u79fb\u8303\u56f4\u4e0e\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u7cfb\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u603b\u53d1\u5c04\u529f\u7387\u4e0e\u53ef\u8fbe\u5230\u7684\u6570\u636e\u901f\u7387\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u6743\u8861\uff0c\u8fd9\u4e00\u6743\u8861\u662fLC\u76f8\u4f4d\u504f\u79fb\u8303\u56f4\u7684\u51fd\u6570\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LC-RIS\u5728\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u9650\u5236\uff0c\u4e3a\u672a\u6765\u4f18\u5316\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2508.11511", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11511", "abs": "https://arxiv.org/abs/2508.11511", "authors": ["Siyamalan Manivannan"], "title": "Semi-Supervised Learning with Online Knowledge Distillation for Skin Lesion Classification", "comment": null, "summary": "Deep Learning has emerged as a promising approach for skin lesion analysis.\nHowever, existing methods mostly rely on fully supervised learning, requiring\nextensive labeled data, which is challenging and costly to obtain. To alleviate\nthis annotation burden, this study introduces a novel semi-supervised deep\nlearning approach that integrates ensemble learning with online knowledge\ndistillation for enhanced skin lesion classification. Our methodology involves\ntraining an ensemble of convolutional neural network models, using online\nknowledge distillation to transfer insights from the ensemble to its members.\nThis process aims to enhance the performance of each model within the ensemble,\nthereby elevating the overall performance of the ensemble itself.\nPost-training, any individual model within the ensemble can be deployed at test\ntime, as each member is trained to deliver comparable performance to the\nensemble. This is particularly beneficial in resource-constrained environments.\nExperimental results demonstrate that the knowledge-distilled individual model\nperforms better than independently trained models. Our approach demonstrates\nsuperior performance on both the \\emph{International Skin Imaging\nCollaboration} 2018 and 2019 public benchmark datasets, surpassing current\nstate-of-the-art results. By leveraging ensemble learning and online knowledge\ndistillation, our method reduces the need for extensive labeled data while\nproviding a more resource-efficient solution for skin lesion classification in\nreal-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u548c\u5728\u7ebf\u77e5\u8bc6\u84b8\u998f\u7684\u534a\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u76ae\u80a4\u75c5\u53d8\u5206\u7c7b\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5168\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u83b7\u53d6\u3002", "method": "\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u7ebf\u77e5\u8bc6\u84b8\u998f\u5c06\u96c6\u6210\u6a21\u578b\u7684\u6d1e\u5bdf\u4f20\u9012\u7ed9\u6210\u5458\u6a21\u578b\uff0c\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u7ed3\u679c\uff0c\u77e5\u8bc6\u84b8\u998f\u540e\u7684\u5355\u4e2a\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u72ec\u7acb\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u964d\u4f4e\u4e86\u6807\u6ce8\u6570\u636e\u9700\u6c42\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u76ae\u80a4\u75c5\u53d8\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
