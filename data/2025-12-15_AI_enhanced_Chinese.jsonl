{"id": "2512.11086", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.11086", "abs": "https://arxiv.org/abs/2512.11086", "authors": ["Randy Palamar", "Darren Dahunsi", "Tyler Henry", "Mohammad Rahim Sobhani", "Roger Zemp"], "title": "An Open Source Realtime GPU Beamformer for Row-Column and Top Orthogonal to Bottom Electrode (TOBE) Arrays", "comment": "17 pages, 11 figures. for mentioned datasets, videos, and files see: https://drive.google.com/drive/folders/1ZqfkJjFfx6JA0gwoHjLdohN1dp-p2Yfu?usp=sharing", "summary": "Research ultrasound platforms have enabled many next-generation imaging sequences but have lacked realtime navigation capabilities for emerging 2D arrays such as row-column arrays (RCAs). We present an open-source, GPU-accelerated reconstruction and rendering software suite integrated with a programmable ultrasound platform and novel electrostrictive Top-Orthogonal-to-Bottom-Electrode (TOBE) arrays. The system supports advanced real-time modes, including cross-plane aperture-encoded synthetic-aperture imaging and aperture-encoded volumetric scanning. TOBE-enabled methods demonstrate improved image quality and expanded field of view compared with conventional RCA techniques. The software implements beamforming and rendering kernels using OpenGL compute shaders and is designed for maximum data throughput helping to minimize stalls and latency. Accompanying sample datasets and example scripts for offline reconstruction are provided to facilitate external testing.", "AI": {"tldr": "\u5f00\u6e90GPU\u52a0\u901f\u8d85\u58f0\u91cd\u5efa\u6e32\u67d3\u8f6f\u4ef6\uff0c\u96c6\u6210\u53ef\u7f16\u7a0b\u8d85\u58f0\u5e73\u53f0\u4e0e\u65b0\u578b\u7535\u81f4\u4f38\u7f29TOBE\u9635\u5217\uff0c\u652f\u6301\u5b9e\u65f6\u5bfc\u822a\u548c\u5148\u8fdb\u6210\u50cf\u6a21\u5f0f\uff0c\u76f8\u6bd4\u4f20\u7edfRCA\u6280\u672f\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u548c\u89c6\u91ce\u3002", "motivation": "\u7814\u7a76\u578b\u8d85\u58f0\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u65b0\u51742D\u9635\u5217\uff08\u5982\u884c\u5217\u9635\u5217RCA\uff09\u7684\u5b9e\u65f6\u5bfc\u822a\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u652f\u6301\u5148\u8fdb\u5b9e\u65f6\u6210\u50cf\u6a21\u5f0f\u7684\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1\u5f00\u6e90GPU\u52a0\u901f\u91cd\u5efa\u6e32\u67d3\u8f6f\u4ef6\u5957\u4ef6\uff0c\u96c6\u6210\u53ef\u7f16\u7a0b\u8d85\u58f0\u5e73\u53f0\u548c\u65b0\u578b\u7535\u81f4\u4f38\u7f29TOBE\u9635\u5217\uff0c\u4f7f\u7528OpenGL\u8ba1\u7b97\u7740\u8272\u5668\u5b9e\u73b0\u6ce2\u675f\u6210\u5f62\u548c\u6e32\u67d3\u5185\u6838\uff0c\u6700\u5927\u5316\u6570\u636e\u541e\u5410\u91cf\u4ee5\u51cf\u5c11\u5ef6\u8fdf\u3002", "result": "TOBE\u652f\u6301\u7684\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edfRCA\u6280\u672f\u5c55\u73b0\u51fa\u6539\u8fdb\u7684\u56fe\u50cf\u8d28\u91cf\u548c\u6269\u5927\u7684\u89c6\u91ce\u8303\u56f4\uff0c\u7cfb\u7edf\u652f\u6301\u5305\u62ec\u8de8\u5e73\u9762\u5b54\u5f84\u7f16\u7801\u5408\u6210\u5b54\u5f84\u6210\u50cf\u548c\u5b54\u5f84\u7f16\u7801\u4f53\u79ef\u626b\u63cf\u5728\u5185\u7684\u5148\u8fdb\u5b9e\u65f6\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u5f00\u6e90\u8f6f\u4ef6\u5957\u4ef6\u4e3a2D\u9635\u5217\u8d85\u58f0\u6210\u50cf\u63d0\u4f9b\u4e86\u5b9e\u65f6\u5bfc\u822a\u80fd\u529b\uff0c\u901a\u8fc7GPU\u52a0\u901f\u548c\u65b0\u578bTOBE\u9635\u5217\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u7684\u5b9e\u65f6\u6210\u50cf\uff0c\u4e3a\u5916\u90e8\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6837\u672c\u6570\u636e\u96c6\u548c\u793a\u4f8b\u811a\u672c\u3002"}}
{"id": "2512.11195", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11195", "abs": "https://arxiv.org/abs/2512.11195", "authors": ["Zheng Wang", "Cong Ling", "Shi Jin", "Yongming Huang", "Feifei Gao"], "title": "Sphere Decoding Revisited", "comment": null, "summary": "In this paper, the paradigm of sphere decoding (SD) for solving the integer least square problem (ILS) is revisited, where extra degrees of freedom are introduced to exploit the decoding potential. Firstly, the equivalent sphere decoding (ESD) is proposed, which is essentially the same with the classic Fincke-Pohst sphere decoding but characterizes the sphere radius $D>0$ with two new parameters named as initial searching size $K>1$ and deviation factor $\u03c3>0$. By fixing $\u03c3$ properly, we show that given the sphere radius $D\\triangleq\u03c3\\sqrt{2\\ln K}$, the complexity of ESD in terms of the number of visited nodes is upper bounded by $|S|<nK$, thus resulting in an explicit and tractable decoding trade-off solely controlled by $K$. To the best of our knowledge, this is the first time that the complexity of sphere decoding is exactly specified, where considerable decoding potential can be explored from it. After that, two enhancement mechanisms named as normalized weighting and candidate protection are proposed to further upgrade the ESD algorithm. On one hand, given the same setups of $K$ and $\u03c3$, a larger sphere radius is achieved, indicating a better decoding trade-off. On the other hand, the proposed ESD algorithm is generalized, which bridges suboptimal and optimal decoding performance through the flexible choice of $K$. Finally, further performance optimization and complexity reduction with respect to ESD are also derived, and the introduced tractable and flexible decoding trade-off is verified through large-scale MIMO detection.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u7403\u9762\u89e3\u7801\u8303\u5f0f\uff0c\u63d0\u51fa\u7b49\u6548\u7403\u9762\u89e3\u7801(ESD)\uff0c\u901a\u8fc7\u5f15\u5165\u521d\u59cb\u641c\u7d22\u5927\u5c0fK\u548c\u504f\u5dee\u56e0\u5b50\u03c3\u4e24\u4e2a\u53c2\u6570\uff0c\u9996\u6b21\u7cbe\u786e\u6307\u5b9a\u4e86\u7403\u9762\u89e3\u7801\u7684\u590d\u6742\u5ea6\uff0c\u5e76\u8bc1\u660e\u590d\u6742\u5ea6\u4e0a\u754c\u4e3anK\uff0c\u5b9e\u73b0\u4e86\u53ef\u63a7\u7684\u89e3\u7801\u6743\u8861\u3002", "motivation": "\u4f20\u7edf\u7403\u9762\u89e3\u7801(Fincke-Pohst\u7b97\u6cd5)\u7684\u590d\u6742\u5ea6\u96be\u4ee5\u7cbe\u786e\u5206\u6790\u548c\u63a7\u5236\uff0c\u4f5c\u8005\u5e0c\u671b\u5f15\u5165\u989d\u5916\u81ea\u7531\u5ea6\u6765\u63a2\u7d22\u89e3\u7801\u6f5c\u529b\uff0c\u5efa\u7acb\u660e\u786e\u4e14\u53ef\u5904\u7406\u7684\u89e3\u7801\u6743\u8861\u673a\u5236\u3002", "method": "\u63d0\u51fa\u7b49\u6548\u7403\u9762\u89e3\u7801(ESD)\uff0c\u5f15\u5165\u521d\u59cb\u641c\u7d22\u5927\u5c0fK\u548c\u504f\u5dee\u56e0\u5b50\u03c3\u4e24\u4e2a\u65b0\u53c2\u6570\uff0c\u5c06\u7403\u534a\u5f84D\u5b9a\u4e49\u4e3a\u03c3\u221a(2lnK)\u3002\u968f\u540e\u63d0\u51fa\u5f52\u4e00\u5316\u52a0\u6743\u548c\u5019\u9009\u4fdd\u62a4\u4e24\u79cd\u589e\u5f3a\u673a\u5236\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316ESD\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u8bc1\u660eESD\u590d\u6742\u5ea6\u4e0a\u754c\u4e3a|S|<nK\uff0c\u9996\u6b21\u7cbe\u786e\u6307\u5b9a\u4e86\u7403\u9762\u89e3\u7801\u590d\u6742\u5ea6\u3002\u589e\u5f3a\u673a\u5236\u5728\u76f8\u540cK\u548c\u03c3\u4e0b\u83b7\u5f97\u66f4\u5927\u7403\u534a\u5f84\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u89e3\u7801\u6743\u8861\u3002\u7b97\u6cd5\u901a\u8fc7K\u7684\u9009\u62e9\u7075\u6d3b\u6865\u63a5\u6b21\u4f18\u548c\u6700\u4f18\u89e3\u7801\u6027\u80fd\u3002", "conclusion": "ESD\u7b97\u6cd5\u63d0\u4f9b\u4e86\u53ef\u5904\u7406\u4e14\u7075\u6d3b\u7684\u89e3\u7801\u6743\u8861\uff0c\u901a\u8fc7\u5927\u89c4\u6a21MIMO\u68c0\u6d4b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002\u8be5\u5de5\u4f5c\u9996\u6b21\u7cbe\u786e\u6307\u5b9a\u4e86\u7403\u9762\u89e3\u7801\u590d\u6742\u5ea6\uff0c\u4e3a\u6574\u6570\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u7801\u8303\u5f0f\u3002"}}
{"id": "2512.11134", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.11134", "abs": "https://arxiv.org/abs/2512.11134", "authors": ["Juan Merlos", "Fabien Racap\u00e9", "Hyomin Choi", "Mateen Ulhaq", "Hari Kalva"], "title": "Feature Compression for Machines with Range-Based Channel Truncation and Frame Packing", "comment": "10 pages, 8 figures. Extended version of the paper with the same title presented at IEEE DCC 2025", "summary": "This paper proposes a method that enhances the compression performance of the current model under development for the upcoming MPEG standard on Feature Coding for Machines (FCM). This standard aims at providing inter-operable compressed bitstreams of features in the context of split computing, i.e., when the inference of a large computer vision neural-network (NN)-based model is split between two devices. Intermediate features can consist of multiple 3D tensors that can be reduced and entropy coded to limit the required bandwidth of such transmission. In the envisioned design for the MPEG-FCM standard, intermediate feature tensors may be reduced using Neural layers before being converted into 2D video frames that can be coded using existing video compression standards. This paper introduces an additional channel truncation and packing method which enables the system to preserve the relevant channels, depending on the statistics of the features at inference time, while preserving the computer vision task performance at the receiver. Implemented within the MPEG-FCM test model, the proposed method yields an average reduction in rate by 10.59% for a given accuracy on multiple computer vision tasks and datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u9053\u622a\u65ad\u4e0e\u6253\u5305\u65b9\u6cd5\uff0c\u63d0\u5347MPEG-FCM\u6807\u51c6\u4e2d\u7279\u5f81\u7f16\u7801\u7684\u538b\u7f29\u6027\u80fd\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u5e73\u5747\u51cf\u5c1110.59%\u7684\u7801\u7387", "motivation": "MPEG-FCM\u6807\u51c6\u65e8\u5728\u4e3a\u673a\u5668\u89c6\u89c9\u4e2d\u7684\u5206\u5272\u8ba1\u7b97\u63d0\u4f9b\u53ef\u4e92\u64cd\u4f5c\u7684\u7279\u5f81\u538b\u7f29\u6bd4\u7279\u6d41\uff0c\u9700\u8981\u5728\u4e0d\u5f71\u54cd\u63a5\u6536\u7aef\u4efb\u52a1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u7279\u5f81\u4f20\u8f93\u6240\u9700\u7684\u5e26\u5bbd", "method": "\u5728MPEG-FCM\u6d4b\u8bd5\u6a21\u578b\u4e2d\u5f15\u5165\u901a\u9053\u622a\u65ad\u4e0e\u6253\u5305\u65b9\u6cd5\uff0c\u6839\u636e\u63a8\u7406\u65f6\u7684\u7279\u5f81\u7edf\u8ba1\u7279\u6027\u4fdd\u7559\u76f8\u5173\u901a\u9053\uff0c\u5c063D\u7279\u5f81\u5f20\u91cf\u8f6c\u6362\u4e3a2D\u89c6\u9891\u5e27\u540e\u4f7f\u7528\u73b0\u6709\u89c6\u9891\u7f16\u7801\u6807\u51c6\u538b\u7f29", "result": "\u5728\u591a\u4e2a\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u7ed9\u5b9a\u51c6\u786e\u5ea6\u8981\u6c42\u4e0b\u5e73\u5747\u51cf\u5c1110.59%\u7684\u7801\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u6536\u7aef\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u901a\u9053\u622a\u65ad\u4e0e\u6253\u5305\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86MPEG-FCM\u6807\u51c6\u7684\u538b\u7f29\u6548\u7387\uff0c\u4e3a\u5206\u5272\u8ba1\u7b97\u573a\u666f\u4e0b\u7684\u7279\u5f81\u7f16\u7801\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.11279", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11279", "abs": "https://arxiv.org/abs/2512.11279", "authors": ["Bruno Macchiavello"], "title": "Information-Theoretic Equivalences Across Rate-Distortion, Quantization, and Decoding", "comment": "This is a preprint version. It has not been peer-reviewed", "summary": "We propose a unified mathematical framework for rate-distortion theory, lattice quantization, and modern error-correcting codes by emphasizing their variational and convex-analytic structure. First, we establish a Gibbs-type variational formulation of the rate-distortion function and show that optimal test channels form an exponential family, with Fullback-Leibler divergence acting as a Bregman divergence. This yields a generalized Pythagorean theorem for projections and a Legendre duality that couples distortion constraints with inverse temperature parameters. Second, the reverse water-filling metaphor is extended to distributed lattice quantization, deriving distortion allocation bounds across eigenmodes of conditional covariance matrices. Third, inference is formalized as decoding by showing that belief propagation in LDPC ensembles and polarization in polar codes can be interpreted as recursive variational inference procedures. These results unify compression, quantization, and decoding as convex projections of continuous information onto discrete manifolds. Extensions to neural compression and quantum information are sketched as corollaries, illustrating the universality of the framework. Illustrative connections to other scientific fields are also presented. Finally, complementary numerical examples and scripts are located in the appendix", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c06\u7387\u5931\u771f\u7406\u8bba\u3001\u683c\u70b9\u91cf\u5316\u548c\u73b0\u4ee3\u7ea0\u9519\u7801\u8054\u7cfb\u8d77\u6765\uff0c\u5f3a\u8c03\u5b83\u4eec\u7684\u53d8\u5206\u548c\u51f8\u5206\u6790\u7ed3\u6784\uff0c\u63ed\u793a\u4e86\u538b\u7f29\u3001\u91cf\u5316\u548c\u89e3\u7801\u4f5c\u4e3a\u8fde\u7eed\u4fe1\u606f\u5230\u79bb\u6563\u6d41\u5f62\u51f8\u6295\u5f71\u7684\u7edf\u4e00\u672c\u8d28\u3002", "motivation": "\u5efa\u7acb\u7387\u5931\u771f\u7406\u8bba\u3001\u683c\u70b9\u91cf\u5316\u548c\u73b0\u4ee3\u7ea0\u9519\u7801\u4e4b\u95f4\u7684\u7edf\u4e00\u6570\u5b66\u6846\u67b6\uff0c\u63ed\u793a\u5b83\u4eec\u5171\u540c\u7684\u53d8\u5206\u548c\u51f8\u5206\u6790\u7ed3\u6784\uff0c\u4e3a\u4fe1\u606f\u7406\u8bba\u7684\u4e0d\u540c\u5206\u652f\u63d0\u4f9b\u7edf\u4e00\u7684\u89c6\u89d2\u3002", "method": "1. \u5efa\u7acb\u7387\u5931\u771f\u51fd\u6570\u7684\u5409\u5e03\u65af\u578b\u53d8\u5206\u516c\u5f0f\uff0c\u8bc1\u660e\u6700\u4f18\u6d4b\u8bd5\u4fe1\u9053\u5f62\u6210\u6307\u6570\u65cf\uff1b2. \u5c06\u53cd\u5411\u6ce8\u6c34\u9690\u55bb\u6269\u5c55\u5230\u5206\u5e03\u5f0f\u683c\u70b9\u91cf\u5316\uff1b3. \u5c06\u63a8\u7406\u5f62\u5f0f\u5316\u4e3a\u89e3\u7801\uff0c\u5c55\u793aLDPC\u7801\u7684\u7f6e\u4fe1\u4f20\u64ad\u548c\u6781\u5316\u7801\u7684\u6781\u5316\u8fc7\u7a0b\u53ef\u89e3\u91ca\u4e3a\u9012\u5f52\u53d8\u5206\u63a8\u7406\u3002", "result": "1. \u7387\u5931\u771f\u51fd\u6570\u5177\u6709\u53d8\u5206\u5f62\u5f0f\uff0c\u6700\u4f18\u4fe1\u9053\u5f62\u6210\u6307\u6570\u65cf\uff0cKL\u6563\u5ea6\u4f5c\u4e3aBregman\u6563\u5ea6\uff1b2. \u63a8\u5bfc\u4e86\u6761\u4ef6\u534f\u65b9\u5dee\u77e9\u9635\u7279\u5f81\u6a21\u4e0a\u7684\u5931\u771f\u5206\u914d\u754c\u9650\uff1b3. \u8bc1\u660e\u4e86\u7f6e\u4fe1\u4f20\u64ad\u548c\u6781\u5316\u8fc7\u7a0b\u662f\u9012\u5f52\u53d8\u5206\u63a8\u7406\uff1b4. \u7edf\u4e00\u4e86\u538b\u7f29\u3001\u91cf\u5316\u548c\u89e3\u7801\u4f5c\u4e3a\u51f8\u6295\u5f71\u8fc7\u7a0b\u3002", "conclusion": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u4fe1\u606f\u7406\u8bba\u7684\u591a\u4e2a\u5206\u652f\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u4f5c\u4e3a\u8fde\u7eed\u4fe1\u606f\u5230\u79bb\u6563\u6d41\u5f62\u51f8\u6295\u5f71\u7684\u5171\u540c\u672c\u8d28\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u795e\u7ecf\u538b\u7f29\u548c\u91cf\u5b50\u4fe1\u606f\u9886\u57df\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u666e\u9002\u6027\u3002"}}
{"id": "2512.11745", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11745", "abs": "https://arxiv.org/abs/2512.11745", "authors": ["Liqiang Huang", "Rachel W. Mills", "Saikiran Mandula", "Lin Bai", "Mahtab Jeyhani", "John Redell", "Hien Van Nguyen", "Saurabh Prasad", "Dragan Maric", "Badrinath Roysam"], "title": "mViSE: A Visual Search Engine for Analyzing Multiplex IHC Brain Tissue Images", "comment": null, "summary": "Whole-slide multiplex imaging of brain tissue generates massive information-dense images that are challenging to analyze and require custom software. We present an alternative query-driven programming-free strategy using a multiplex visual search engine (mViSE) that learns the multifaceted brain tissue chemoarchitecture, cytoarchitecture, and myeloarchitecture. Our divide-and-conquer strategy organizes the data into panels of related molecular markers and uses self-supervised learning to train a multiplex encoder for each panel with explicit visual confirmation of successful learning. Multiple panels can be combined to process visual queries for retrieving similar communities of individual cells or multicellular niches using information-theoretic methods. The retrievals can be used for diverse purposes including tissue exploration, delineating brain regions and cortical cell layers, profiling and comparing brain regions without computer programming. We validated mViSE's ability to retrieve single cells, proximal cell pairs, tissue patches, delineate cortical layers, brain regions and sub-regions. mViSE is provided as an open-source QuPath plug-in.", "AI": {"tldr": "mViSE\u662f\u4e00\u4e2a\u514d\u7f16\u7a0b\u7684\u591a\u91cd\u53ef\u89c6\u5316\u641c\u7d22\u5f15\u64ce\uff0c\u7528\u4e8e\u5206\u6790\u8111\u7ec4\u7ec7\u5168\u5207\u7247\u591a\u91cd\u6210\u50cf\u6570\u636e\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u4fe1\u606f\u8bba\u65b9\u6cd5\u68c0\u7d22\u76f8\u4f3c\u7ec6\u80de\u7fa4\u843d\u548c\u7ec4\u7ec7\u533a\u57df\u3002", "motivation": "\u8111\u7ec4\u7ec7\u5168\u5207\u7247\u591a\u91cd\u6210\u50cf\u4ea7\u751f\u6d77\u91cf\u4fe1\u606f\u5bc6\u96c6\u7684\u56fe\u50cf\uff0c\u5206\u6790\u56f0\u96be\u4e14\u9700\u8981\u5b9a\u5236\u8f6f\u4ef6\uff0c\u9700\u8981\u4e00\u79cd\u514d\u7f16\u7a0b\u7684\u67e5\u8be2\u9a71\u52a8\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u6cbb\u7b56\u7565\u5c06\u6570\u636e\u7ec4\u7ec7\u6210\u76f8\u5173\u5206\u5b50\u6807\u8bb0\u9762\u677f\uff0c\u4f7f\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u4e3a\u6bcf\u4e2a\u9762\u677f\u8bad\u7ec3\u591a\u91cd\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u7ec4\u5408\u591a\u4e2a\u9762\u677f\u5904\u7406\u89c6\u89c9\u67e5\u8be2\uff0c\u68c0\u7d22\u76f8\u4f3c\u7684\u7ec6\u80de\u7fa4\u843d\u6216\u591a\u7ec6\u80de\u751f\u6001\u4f4d\u3002", "result": "\u9a8c\u8bc1\u4e86mViSE\u80fd\u591f\u68c0\u7d22\u5355\u4e2a\u7ec6\u80de\u3001\u90bb\u8fd1\u7ec6\u80de\u5bf9\u3001\u7ec4\u7ec7\u6591\u5757\uff0c\u5e76\u6210\u529f\u5212\u5206\u76ae\u8d28\u5c42\u3001\u8111\u533a\u548c\u4e9a\u533a\uff0c\u5df2\u4f5c\u4e3a\u5f00\u6e90QuPath\u63d2\u4ef6\u63d0\u4f9b\u3002", "conclusion": "mViSE\u63d0\u4f9b\u4e86\u4e00\u79cd\u514d\u7f16\u7a0b\u7684\u67e5\u8be2\u9a71\u52a8\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5206\u6790\u8111\u7ec4\u7ec7\u591a\u91cd\u6210\u50cf\u6570\u636e\uff0c\u652f\u6301\u7ec4\u7ec7\u63a2\u7d22\u3001\u8111\u533a\u5212\u5206\u548c\u6bd4\u8f83\u7b49\u591a\u79cd\u5e94\u7528\u3002"}}
{"id": "2512.11322", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11322", "abs": "https://arxiv.org/abs/2512.11322", "authors": ["Neri Merhav"], "title": "Refinements and Generalizations of the Shannon Lower Bound via Extensions of the Kraft Inequality", "comment": "25 pages, submitted for publication", "summary": "We derive a few extended versions of the Kraft inequality for lossy compression, which pave the way to the derivation of several refinements and extensions of the well known Shannon lower bound in a variety of instances of rate-distortion coding. These refinements and extensions include sharper bounds for one-to-one codes and $D$-semifaithful codes, a Shannon lower bound for distortion measures based on sliding-window functions, and an individual-sequence counterpart of the Shannon lower bound.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u6709\u635f\u538b\u7f29\u7684Kraft\u4e0d\u7b49\u5f0f\u6269\u5c55\u7248\u672c\uff0c\u5e76\u57fa\u4e8e\u6b64\u6539\u8fdb\u4e86\u9999\u519c\u4e0b\u754c\u5728\u591a\u79cd\u7387\u5931\u771f\u7f16\u7801\u573a\u666f\u4e0b\u7684\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u9999\u519c\u4e0b\u754c\u5728\u591a\u79cd\u6709\u635f\u7f16\u7801\u573a\u666f\u4e0b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u754c\u9650\u6765\u6307\u5bfc\u7387\u5931\u771f\u7f16\u7801\u7684\u7406\u8bba\u5206\u6790\u3002", "method": "\u901a\u8fc7\u63a8\u5bfc\u6709\u635f\u538b\u7f29\u7684\u6269\u5c55Kraft\u4e0d\u7b49\u5f0f\uff0c\u4ee5\u6b64\u4e3a\u5de5\u5177\u6539\u8fdb\u548c\u6269\u5c55\u9999\u519c\u4e0b\u754c\uff0c\u5e94\u7528\u4e8e\u4e00\u5bf9\u4e00\u7f16\u7801\u3001D-\u534a\u5fe0\u5b9e\u7f16\u7801\u3001\u6ed1\u52a8\u7a97\u5931\u771f\u5ea6\u91cf\u7b49\u573a\u666f\u3002", "result": "\u83b7\u5f97\u4e86\u66f4\u5c16\u9510\u7684\u4e00\u5bf9\u4e00\u7f16\u7801\u548cD-\u534a\u5fe0\u5b9e\u7f16\u7801\u754c\u9650\uff0c\u63a8\u5bfc\u4e86\u57fa\u4e8e\u6ed1\u52a8\u7a97\u51fd\u6570\u7684\u9999\u519c\u4e0b\u754c\uff0c\u4ee5\u53ca\u4e2a\u4f53\u5e8f\u5217\u5bf9\u5e94\u7684\u9999\u519c\u4e0b\u754c\u3002", "conclusion": "\u6269\u5c55\u7684Kraft\u4e0d\u7b49\u5f0f\u4e3a\u6709\u635f\u538b\u7f29\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u7406\u8bba\u5de5\u5177\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u9999\u519c\u4e0b\u754c\u5728\u591a\u79cd\u7387\u5931\u771f\u7f16\u7801\u573a\u666f\u4e0b\u7684\u7cbe\u786e\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2512.11170", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.11170", "abs": "https://arxiv.org/abs/2512.11170", "authors": ["Nicholas Bampton", "Tian J. Ma", "Minh N. Do"], "title": "A Unified Theory of Dynamic Programming Algorithms in Small Target Detection", "comment": "11 pages, 6 figures", "summary": "Small target detection is inherently challenging due to the minimal size, lack of distinctive features, and the presence of complex backgrounds. Heavy noise further complicates the task by both obscuring and imitating the target appearance. Weak target signals require integrating target trajectories over multiple frames, an approach that can be computationally intensive. Dynamic programming offers an efficient solution by decomposing the problem into iterative maximization. This, however, has limited the analytical tools available for their study. In this paper, we present a robust framework for this class of algorithms and establish rigorous convergence results for error rates under mild assumptions. We depart from standard analysis by modeling error probabilities as a function of distance from the target, allowing us to construct a relationship between uncertainty in location and uncertainty in existence. From this framework, we introduce a novel algorithm, Normalized Path Integration (NPI), that utilizes the similarity between sequential observations, enabling target detection with unknown or time varying features.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5c0f\u76ee\u6807\u68c0\u6d4b\u7684\u9c81\u68d2\u6846\u67b6\uff0c\u5f15\u5165\u5f52\u4e00\u5316\u8def\u5f84\u79ef\u5206(NPI)\u7b97\u6cd5\uff0c\u5229\u7528\u5e8f\u5217\u89c2\u6d4b\u76f8\u4f3c\u6027\u68c0\u6d4b\u672a\u77e5\u6216\u65f6\u53d8\u7279\u5f81\u7684\u76ee\u6807", "motivation": "\u5c0f\u76ee\u6807\u68c0\u6d4b\u9762\u4e34\u5c3a\u5bf8\u5c0f\u3001\u7279\u5f81\u4e0d\u660e\u663e\u3001\u80cc\u666f\u590d\u6742\u7b49\u6311\u6218\uff0c\u5f3a\u566a\u58f0\u8fdb\u4e00\u6b65\u6a21\u7cca\u76ee\u6807\u5916\u89c2\uff0c\u73b0\u6709\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u5206\u6790\u5de5\u5177\u6709\u9650\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6536\u655b\u4fdd\u8bc1", "method": "\u63d0\u51fa\u9c81\u68d2\u5206\u6790\u6846\u67b6\uff0c\u5c06\u9519\u8bef\u6982\u7387\u5efa\u6a21\u4e3a\u4e0e\u76ee\u6807\u8ddd\u79bb\u7684\u51fd\u6570\uff0c\u5efa\u7acb\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u4e0e\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u5f52\u4e00\u5316\u8def\u5f84\u79ef\u5206(NPI)\u7b97\u6cd5\uff0c\u5229\u7528\u5e8f\u5217\u89c2\u6d4b\u76f8\u4f3c\u6027", "result": "\u5efa\u7acb\u4e86\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u8bef\u5dee\u7387\u7684\u4e25\u683c\u6536\u655b\u7ed3\u679c\uff0cNPI\u7b97\u6cd5\u80fd\u591f\u68c0\u6d4b\u5177\u6709\u672a\u77e5\u6216\u65f6\u53d8\u7279\u5f81\u7684\u76ee\u6807", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5c0f\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u57fa\u7840\uff0cNPI\u7b97\u6cd5\u901a\u8fc7\u5229\u7528\u5e8f\u5217\u76f8\u4f3c\u6027\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7279\u5f81\u672a\u77e5\u6216\u65f6\u53d8\u60c5\u51b5\u4e0b\u7684\u5c40\u9650\u6027"}}
{"id": "2512.11331", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11331", "abs": "https://arxiv.org/abs/2512.11331", "authors": ["Chenyiming Wen", "Binpu Shi", "Min Li", "Ming-Min Zhao", "Min-Jian Zhao", "Jiangzhou Wang"], "title": "AMBER: An Adaptive Multimodal Mask Transformer for Beam Prediction with Missing Modalities", "comment": "12 pages, 9 figures", "summary": "With the widespread adoption of millimeter-wave (mmWave) massive multi-input-multi-output (MIMO) in vehicular networks, accurate beam prediction and alignment have become critical for high-speed data transmission and reliable access. While traditional beam prediction approaches primarily rely on in-band beam training, recent advances have started to explore multimodal sensing to extract environmental semantics for enhanced prediction. However, the performance of existing multimodal fusion methods degrades significantly in real-world settings because they are vulnerable to missing data caused by sensor blockage, poor lighting, or GPS dropouts. To address this challenge, we propose AMBER ({A}daptive multimodal {M}ask transformer for {BE}am p{R}ediction), a novel end-to-end framework that processes temporal sequences of image, LiDAR, radar, and GPS data, while adaptively handling arbitrary missing-modality cases. AMBER introduces learnable modality tokens and a missing-modality-aware mask to prevent cross-modal noise propagation, along with a learnable fusion token and multihead attention to achieve robust modality-specific information distillation and feature-level fusion. Furthermore, a class-former-aided modality alignment (CMA) module and temporal-aware positional embedding are incorporated to preserve temporal coherence and ensure semantic alignment across modalities, facilitating the learning of modality-invariant and temporally consistent representations for beam prediction. Extensive experiments on the real-world DeepSense6G dataset demonstrate that AMBER significantly outperforms existing multimodal learning baselines. In particular, it maintains high beam prediction accuracy and robustness even under severe missing-modality scenarios, validating its effectiveness and practical applicability.", "AI": {"tldr": "AMBER\uff1a\u4e00\u79cd\u81ea\u9002\u5e94\u591a\u6a21\u6001\u63a9\u7801Transformer\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u6beb\u7c73\u6ce2\u5927\u89c4\u6a21MIMO\u8f66\u8f7d\u7f51\u7edc\u4e2d\u7684\u6ce2\u675f\u9884\u6d4b\uff0c\u80fd\u591f\u9c81\u68d2\u5730\u5904\u7406\u4efb\u610f\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u3002", "motivation": "\u6beb\u7c73\u6ce2\u5927\u89c4\u6a21MIMO\u5728\u8f66\u8f7d\u7f51\u7edc\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u51c6\u786e\u7684\u6ce2\u675f\u9884\u6d4b\u548c\u5bf9\u51c6\u5bf9\u9ad8\u901f\u6570\u636e\u4f20\u8f93\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u4f20\u611f\u5668\u906e\u6321\u3001\u5149\u7167\u4e0d\u8db3\u6216GPS\u4e22\u5931\u5bfc\u81f4\u7684\u7f3a\u5931\u6570\u636e\u5f88\u8106\u5f31\u3002", "method": "\u63d0\u51faAMBER\u6846\u67b6\uff0c\u5904\u7406\u56fe\u50cf\u3001LiDAR\u3001\u96f7\u8fbe\u548cGPS\u7684\u65f6\u5e8f\u6570\u636e\uff0c\u81ea\u9002\u5e94\u5904\u7406\u4efb\u610f\u6a21\u6001\u7f3a\u5931\u3002\u5f15\u5165\u53ef\u5b66\u4e60\u6a21\u6001\u4ee4\u724c\u548c\u7f3a\u5931\u6a21\u6001\u611f\u77e5\u63a9\u7801\u9632\u6b62\u8de8\u6a21\u6001\u566a\u58f0\u4f20\u64ad\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u878d\u5408\u4ee4\u724c\u548c\u591a\u5934\u6ce8\u610f\u529b\u5b9e\u73b0\u9c81\u68d2\u7684\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u84b8\u998f\u548c\u7279\u5f81\u7ea7\u878d\u5408\u3002\u8fd8\u5305\u542b\u7c7b\u524d\u9988\u8f85\u52a9\u6a21\u6001\u5bf9\u9f50\u6a21\u5757\u548c\u65f6\u5e8f\u611f\u77e5\u4f4d\u7f6e\u5d4c\u5165\uff0c\u4fdd\u6301\u65f6\u5e8f\u4e00\u81f4\u6027\u5e76\u786e\u4fdd\u8de8\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754cDeepSense6G\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAMBER\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002\u7279\u522b\u662f\u5728\u4e25\u91cd\u6a21\u6001\u7f3a\u5931\u573a\u666f\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6ce2\u675f\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "AMBER\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5904\u7406\u7f3a\u5931\u6a21\u6001\u548c\u9c81\u68d2\u7684\u591a\u6a21\u6001\u878d\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8f66\u8f7d\u7f51\u7edc\u4e2d\u6ce2\u675f\u9884\u6d4b\u7684\u5b9e\u9645\u6311\u6218\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\u3002"}}
{"id": "2512.10965", "categories": ["eess.SP", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10965", "abs": "https://arxiv.org/abs/2512.10965", "authors": ["Qiming Zhang", "Xiucheng Wang", "Nan Cheng", "Zhisheng Yin", "Xiang Li"], "title": "RMSup: Physics-Informed Radio Map Super-Resolution for Compute-Enhanced Integrated Sensing and Communications", "comment": null, "summary": "Radio maps (RMs) provide a spatially continuous description of wireless propagation, enabling cross-layer optimization and unifying communication and sensing for integrated sensing and communications (ISAC). However, constructing high-fidelity RMs at operational scales is difficult, since physics-based solvers are time-consuming and require precise scene models, while learning methods degrade under incomplete priors and sparse measurements, often smoothing away critical discontinuities. We present RMSup, a physics-informed super-resolution framework that functions with uniform sparse sampling and imperfect environment priors. RMSup extracts Helmholtz equation-informed boundary and singularity prompts from the measurements, fuses them with base-station side information and coarse scene descriptors as conditional inputs, and employs a boundary-aware dual-head network to reconstruct a high-fidelity RM and recover environmental contours jointly. Experimental results show the proposed RMsup achieves state-of-the-art performance both in RM construction and ISAC-related environment sensing.", "AI": {"tldr": "RMSup\uff1a\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u5229\u7528\u7a00\u758f\u91c7\u6837\u548c\u4e0d\u5b8c\u7f8e\u73af\u5883\u5148\u9a8c\u6784\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u7535\u5730\u56fe\uff0c\u540c\u65f6\u6062\u590d\u73af\u5883\u8f6e\u5ed3", "motivation": "\u65e0\u7ebf\u7535\u5730\u56fe\u5bf9\u4e8e\u8de8\u5c42\u4f18\u5316\u548c\u901a\u4fe1\u611f\u77e5\u4e00\u4f53\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u64cd\u4f5c\u89c4\u6a21\u4e0a\u6784\u5efa\u9ad8\u4fdd\u771f\u5730\u56fe\uff1a\u57fa\u4e8e\u7269\u7406\u7684\u6c42\u89e3\u5668\u8017\u65f6\u4e14\u9700\u8981\u7cbe\u786e\u573a\u666f\u6a21\u578b\uff0c\u800c\u5b66\u4e60\u65b9\u6cd5\u5728\u7a00\u758f\u6d4b\u91cf\u548c\u4e0d\u5b8c\u6574\u5148\u9a8c\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u5f80\u5f80\u4f1a\u5e73\u6ed1\u6389\u5173\u952e\u7684\u95f4\u65ad\u7279\u5f81\u3002", "method": "RMSup\u6846\u67b6\u4ece\u6d4b\u91cf\u4e2d\u63d0\u53d6\u4ea5\u59c6\u970d\u5179\u65b9\u7a0b\u4fe1\u606f\u7684\u8fb9\u754c\u548c\u5947\u70b9\u63d0\u793a\uff0c\u5c06\u5176\u4e0e\u57fa\u7ad9\u4fa7\u4fe1\u606f\u548c\u7c97\u7cd9\u573a\u666f\u63cf\u8ff0\u7b26\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\u878d\u5408\uff0c\u91c7\u7528\u8fb9\u754c\u611f\u77e5\u7684\u53cc\u5934\u7f51\u7edc\u8054\u5408\u91cd\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u7535\u5730\u56fe\u5e76\u6062\u590d\u73af\u5883\u8f6e\u5ed3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRMSup\u5728\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u548cISAC\u76f8\u5173\u73af\u5883\u611f\u77e5\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "RMSup\u80fd\u591f\u5229\u7528\u5747\u5300\u7a00\u758f\u91c7\u6837\u548c\u4e0d\u5b8c\u7f8e\u73af\u5883\u5148\u9a8c\uff0c\u6709\u6548\u6784\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u7535\u5730\u56fe\u5e76\u6062\u590d\u73af\u5883\u8f6e\u5ed3\uff0c\u4e3a\u901a\u4fe1\u611f\u77e5\u4e00\u4f53\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11443", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11443", "abs": "https://arxiv.org/abs/2512.11443", "authors": ["Yuan Li"], "title": "Capacity-Achieving Codes with Inverse-Ackermann-Depth Encoders", "comment": null, "summary": "For any symmetric discrete memoryless channel with input and output alphabet of size $q$, where $q$ is a prime power, we prove that there exist error-correcting codes approaching channel capacity encodable by arithmetic circuits (with weighted addition gates) over $\\mathbb{F}_q$ of size $O(n)$ and depth $\u03b1(n)$, where $\u03b1(n)$ is a version of the inverse Ackermann function. Our results suggest that certain capacity-achieving codes admit highly efficient encoding circuits that are both in linear size and of inverse-Ackermann depth. Our construction composes a linear code with constant rate and relative distance, based on the constructions of G\u00e1l, Hansen, Kouck\u00fd, Pudl\u00e1k, and Viola [IEEE Trans. Inform. Theory 59(10), 2013] and Drucker and Li [COCOON 2023], with an additional layer formed by a disperser graph whose edge weights are chosen uniformly at random.", "AI": {"tldr": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f\u5bf9\u79f0\u79bb\u6563\u65e0\u8bb0\u5fc6\u4fe1\u9053\uff0c\u5b58\u5728\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u7684\u7ea0\u9519\u7801\uff0c\u5176\u7f16\u7801\u7535\u8def\u5177\u6709\u7ebf\u6027\u89c4\u6a21\u548c\u9006Ackermann\u6df1\u5ea6\u3002", "motivation": "\u7814\u7a76\u662f\u5426\u5b58\u5728\u65e2\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u53c8\u5177\u6709\u9ad8\u6548\u7f16\u7801\u7535\u8def\u7684\u7ea0\u9519\u7801\uff0c\u7279\u522b\u662f\u63a2\u7d22\u7ebf\u6027\u89c4\u6a21\u548c\u6781\u6d45\u6df1\u5ea6\u7684\u53ef\u80fd\u6027\u3002", "method": "\u7ed3\u5408\u57fa\u4e8eG\u00e1l\u7b49\u4eba\u548cDrucker-Li\u6784\u9020\u7684\u5177\u6709\u6052\u5b9a\u901f\u7387\u548c\u76f8\u5bf9\u8ddd\u79bb\u7684\u7ebf\u6027\u7801\uff0c\u518d\u6dfb\u52a0\u4e00\u5c42\u7531\u968f\u673a\u5747\u5300\u9009\u62e9\u8fb9\u6743\u91cd\u7684\u6269\u5c55\u56fe\u6784\u6210\u7684\u989d\u5916\u5c42\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u8f93\u5165\u8f93\u51fa\u5b57\u6bcd\u8868\u5927\u5c0f\u4e3a\u7d20\u6570\u5e42q\u7684\u5bf9\u79f0\u79bb\u6563\u65e0\u8bb0\u5fc6\u4fe1\u9053\uff0c\u5b58\u5728\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u7684\u7ea0\u9519\u7801\uff0c\u5176\u7f16\u7801\u7535\u8def\u89c4\u6a21\u4e3aO(n)\uff0c\u6df1\u5ea6\u4e3a\u9006Ackermann\u51fd\u6570\u7248\u672c\u03b1(n)\u3002", "conclusion": "\u67d0\u4e9b\u8fbe\u5230\u4fe1\u9053\u5bb9\u91cf\u7684\u7ea0\u9519\u7801\u786e\u5b9e\u5b58\u5728\u9ad8\u5ea6\u9ad8\u6548\u7684\u7f16\u7801\u7535\u8def\uff0c\u540c\u65f6\u5177\u6709\u7ebf\u6027\u89c4\u6a21\u548c\u9006Ackermann\u6df1\u5ea6\uff0c\u8fd9\u4e3a\u9ad8\u6548\u7f16\u7801\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2512.10970", "categories": ["eess.SP", "cs.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.10970", "abs": "https://arxiv.org/abs/2512.10970", "authors": ["Yulei Wang", "Yalin Liu", "Yaru Fu", "Yuanwei Liu"], "title": "Uplink Rate Maximization for Pinching Antenna- Assisted Covert Backscatter Communication", "comment": null, "summary": "The emerging pinching antenna (PA) technology enables flexible antenna positioning for creating line-of-sight (LoS) links, thus offering substantial potential to facilitate ambient signal-based backscatter communication (BSC). This paper investigates PA-assisted BSC for enhanced communication and covertness in the presence of a randomly distributed eavesdropper. An optimization problem is formulated to maximize the uplink covert transmission rate by jointly optimizing the transmit power and antenna positions while satisfying both communication reliability and covertness constraints. An alternative optimization (AO)-based framework is proposed to solve this problem. Numerical results demonstrate that the proposed PA-BSC effectively mitigates the double near-far problem, where energy harvesting and backscatter transmission degrade simultaneously due to distance disparities, thereby improving downlink energy harvesting and uplink data transmission while maintaining covertness performance under practical deployment scenarios.", "AI": {"tldr": "PA-BSC\u6280\u672f\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u53d1\u5c04\u529f\u7387\uff0c\u5728\u5b58\u5728\u968f\u673a\u5206\u5e03\u7a83\u542c\u8005\u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u5927\u5316\u4e0a\u884c\u94fe\u8def\u9690\u853d\u4f20\u8f93\u901f\u7387\uff0c\u540c\u65f6\u89e3\u51b3\u53cc\u8fdc\u8fd1\u95ee\u9898\u3002", "motivation": "\u5939\u6301\u5929\u7ebf\u6280\u672f\u80fd\u591f\u7075\u6d3b\u8c03\u6574\u5929\u7ebf\u4f4d\u7f6e\u4ee5\u5efa\u7acb\u89c6\u8ddd\u94fe\u8def\uff0c\u4e3a\u73af\u5883\u4fe1\u53f7\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002\u7136\u800c\uff0c\u5728\u5b58\u5728\u968f\u673a\u5206\u5e03\u7a83\u542c\u8005\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u540c\u65f6\u4fdd\u8bc1\u901a\u4fe1\u53ef\u9760\u6027\u548c\u9690\u853d\u6027\uff0c\u5e76\u89e3\u51b3\u7531\u4e8e\u8ddd\u79bb\u5dee\u5f02\u5bfc\u81f4\u7684\u80fd\u91cf\u6536\u96c6\u548c\u53cd\u5411\u6563\u5c04\u4f20\u8f93\u540c\u65f6\u6076\u5316\u7684\u53cc\u8fdc\u8fd1\u95ee\u9898\u3002", "method": "\u63d0\u51faPA\u8f85\u52a9\u7684BSC\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u529f\u7387\u548c\u5929\u7ebf\u4f4d\u7f6e\u6765\u6700\u5927\u5316\u4e0a\u884c\u9690\u853d\u4f20\u8f93\u901f\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u901a\u4fe1\u53ef\u9760\u6027\u548c\u9690\u853d\u6027\u7ea6\u675f\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cPA-BSC\u80fd\u6709\u6548\u7f13\u89e3\u53cc\u8fdc\u8fd1\u95ee\u9898\uff0c\u5728\u5b9e\u7528\u90e8\u7f72\u573a\u666f\u4e0b\uff0c\u540c\u65f6\u6539\u5584\u4e0b\u884c\u80fd\u91cf\u6536\u96c6\u548c\u4e0a\u884c\u6570\u636e\u4f20\u8f93\uff0c\u540c\u65f6\u4fdd\u6301\u9690\u853d\u6027\u80fd\u3002", "conclusion": "PA-BSC\u6280\u672f\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u529f\u7387\u5206\u914d\uff0c\u5728\u5b58\u5728\u7a83\u542c\u5a01\u80c1\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9690\u853d\u7684\u901a\u4fe1\uff0c\u4e3a\u89e3\u51b3\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u4e2d\u7684\u53cc\u8fdc\u8fd1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.11642", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11642", "abs": "https://arxiv.org/abs/2512.11642", "authors": ["Timm Gilles"], "title": "Stable low-rank matrix recovery from 3-designs", "comment": null, "summary": "We study the recovery of low-rank Hermitian matrices from rank-one measurements obtained by uniform sampling from complex projective 3-designs, using nuclear-norm minimization. This framework includes phase retrieval as a special case via the PhaseLift method. In general, complex projective $t$-designs provide a practical means of partially derandomizing Gaussian measurement models. While near-optimal recovery guarantees are known for $4$-designs, and it is known that $2$-designs do not permit recovery with a subquadratic number of measurements, the case of $3$-designs has remained open. In this work, we close this gap by establishing recovery guarantees for (exact and approximate) $3$-designs that parallel the best-known results for $4$-designs. In particular, we derive bounds on the number of measurements sufficient for stable and robust low-rank recovery via nuclear-norm minimization. Our results are especially relevant in practice, as explicit constructions of $4$-designs are significantly more challenging than those of $3$-designs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ece\u590d\u5c04\u5f713-design\u7684\u79e9\u4e00\u6d4b\u91cf\u4e2d\u6062\u590d\u4f4e\u79e9\u5384\u7c73\u7279\u77e9\u9635\u7684\u95ee\u9898\uff0c\u586b\u8865\u4e863-design\u6062\u590d\u7406\u8bba\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e863-design\u4e0e4-design\u5177\u6709\u76f8\u4f3c\u7684\u6062\u590d\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5df2\u77e54-design\u53ef\u4ee5\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6062\u590d\u4fdd\u8bc1\uff0c\u800c2-design\u65e0\u6cd5\u5b9e\u73b0\u4e9a\u4e8c\u6b21\u6d4b\u91cf\u6062\u590d\uff0c\u4f463-design\u7684\u6062\u590d\u6027\u80fd\u4e00\u76f4\u672a\u77e5\u3002\u7531\u4e8e4-design\u7684\u663e\u5f0f\u6784\u9020\u6bd43-design\u56f0\u96be\u5f97\u591a\uff0c\u56e0\u6b64\u7814\u7a763-design\u7684\u6062\u590d\u6027\u80fd\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u610f\u4e49\u3002", "method": "\u4f7f\u7528\u6838\u8303\u6570\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u4ece\u590d\u5c04\u5f713-design\u7684\u5747\u5300\u91c7\u6837\u83b7\u5f97\u7684\u79e9\u4e00\u6d4b\u91cf\u4e2d\u6062\u590d\u4f4e\u79e9\u5384\u7c73\u7279\u77e9\u9635\u3002\u8be5\u6846\u67b6\u901a\u8fc7PhaseLift\u65b9\u6cd5\u5c06\u76f8\u4f4d\u6062\u590d\u4f5c\u4e3a\u7279\u4f8b\u5305\u542b\u5728\u5185\u3002", "result": "\u5efa\u7acb\u4e863-design\u7684\u6062\u590d\u4fdd\u8bc1\uff0c\u5176\u6027\u80fd\u4e0e\u5df2\u77e5\u76844-design\u6700\u4f73\u7ed3\u679c\u76f8\u5f53\u3002\u63a8\u5bfc\u4e86\u7a33\u5b9a\u548c\u9c81\u68d2\u4f4e\u79e9\u6062\u590d\u6240\u9700\u7684\u6d4b\u91cf\u6570\u91cf\u754c\u9650\uff0c\u7279\u522b\u662f\u8bc1\u660e\u4e863-design\u53ef\u4ee5\u5b9e\u73b0\u4e0e4-design\u76f8\u4f3c\u7684\u6062\u590d\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e863-design\u6062\u590d\u7406\u8bba\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u8bc1\u660e\u4e863-design\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u4e0e4-design\u76f8\u5f53\u7684\u6062\u590d\u6027\u80fd\uff0c\u800c3-design\u7684\u6784\u9020\u6bd44-design\u5bb9\u6613\u5f97\u591a\uff0c\u56e0\u6b64\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.11231", "categories": ["eess.SP", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.11231", "abs": "https://arxiv.org/abs/2512.11231", "authors": ["Siyuan Cang", "Cong Liu", "Xueli Sheng", "Xiaoming Cui", "Chao Li", "Changxin Fa", "Jiantong Chen", "Chaoran Yang", "Huayong Yang"], "title": "Robust Detection of Underwater Target Against Non-Uniform Noise With Optical Fiber DAS Array", "comment": "17 pages, 29 figures. The IEEE Transactions on Instrumentation and Measurement has accepted this research for publication, and it is currently accessible in its early access version", "summary": "The detection of underwater targets is severely affected by the non-uniform spatial characteristics of marine environmental noise. Additionally, the presence of both natural and anthropogenic acoustic sources, including shipping traffic, marine life, and geological activity, further complicates the underwater acoustic landscape. Addressing these challenges requires advanced underwater sensors and robust signal processing techniques. In this paper, we present a novel approach that leverages an optical fiber distributed acoustic sensing (DAS) system combined with a broadband generalized sparse covariance-fitting framework for underwater target direction sensing, particularly focusing on robustness against non-uniform noise. The DAS system incorporates a newly developed spiral-sensitized optical cable, which significantly improves sensitivity compared to conventional submarine cables. This innovative design enables the system to capture acoustic signals with greater precision. Notably, the sensitivity of the spiral-wound sensitized cable is around -145.69 dB re: 1 rad / (uPa*m), as measured inside the standing-wave tube. Employing simulations, we assess the performance of the algorithm across diverse noise levels and target configurations, consistently revealing higher accuracy and reduced background noise compared to conventional beamforming techniques and other sparse techniques. In a controlled pool experiment, the correlation coefficient between waveforms acquired by the DAS system and a standard hydrophone reached 0.973, indicating high fidelity in signal capture.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5149\u7ea4\u5206\u5e03\u5f0f\u58f0\u5b66\u4f20\u611f\u7cfb\u7edf\u4e0e\u5bbd\u5e26\u5e7f\u4e49\u7a00\u758f\u534f\u65b9\u5dee\u62df\u5408\u6846\u67b6\u7684\u6c34\u4e0b\u76ee\u6807\u65b9\u5411\u611f\u77e5\u65b0\u65b9\u6cd5\uff0c\u7279\u522b\u9488\u5bf9\u975e\u5747\u5300\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "motivation": "\u6c34\u4e0b\u76ee\u6807\u68c0\u6d4b\u53d7\u5230\u6d77\u6d0b\u73af\u5883\u566a\u58f0\u975e\u5747\u5300\u7a7a\u95f4\u7279\u6027\u7684\u4e25\u91cd\u5f71\u54cd\uff0c\u52a0\u4e0a\u822a\u8fd0\u3001\u6d77\u6d0b\u751f\u7269\u548c\u5730\u8d28\u6d3b\u52a8\u7b49\u81ea\u7136\u548c\u4eba\u4e3a\u58f0\u6e90\u7684\u5e72\u6270\uff0c\u4f7f\u5f97\u6c34\u4e0b\u58f0\u5b66\u73af\u5883\u66f4\u52a0\u590d\u6742\u3002\u9700\u8981\u5148\u8fdb\u7684\u6c34\u4e0b\u4f20\u611f\u5668\u548c\u9c81\u68d2\u7684\u4fe1\u53f7\u5904\u7406\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u91c7\u7528\u65b0\u578b\u87ba\u65cb\u654f\u611f\u5316\u5149\u7f06\u7684\u5149\u7ea4\u5206\u5e03\u5f0f\u58f0\u5b66\u4f20\u611f\u7cfb\u7edf\uff0c\u7ed3\u5408\u5bbd\u5e26\u5e7f\u4e49\u7a00\u758f\u534f\u65b9\u5dee\u62df\u5408\u6846\u67b6\u8fdb\u884c\u6c34\u4e0b\u76ee\u6807\u65b9\u5411\u611f\u77e5\u3002\u87ba\u65cb\u654f\u611f\u5316\u5149\u7f06\u76f8\u6bd4\u4f20\u7edf\u6d77\u5e95\u7535\u7f06\u663e\u8457\u63d0\u9ad8\u4e86\u7075\u654f\u5ea6\uff08\u7ea6-145.69 dB re: 1 rad/(uPa*m)\uff09\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u6355\u83b7\u58f0\u5b66\u4fe1\u53f7\u3002", "result": "\u4eff\u771f\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u7b97\u6cd5\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u548c\u76ee\u6807\u914d\u7f6e\u4e0b\u5747\u8868\u73b0\u51fa\u6bd4\u4f20\u7edf\u6ce2\u675f\u5f62\u6210\u6280\u672f\u548c\u5176\u4ed6\u7a00\u758f\u6280\u672f\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u80cc\u666f\u566a\u58f0\u3002\u5728\u53d7\u63a7\u6c34\u6c60\u5b9e\u9a8c\u4e2d\uff0cDAS\u7cfb\u7edf\u4e0e\u6807\u51c6\u6c34\u542c\u5668\u83b7\u53d6\u7684\u6ce2\u5f62\u76f8\u5173\u7cfb\u6570\u8fbe\u52300.973\uff0c\u8868\u660e\u4fe1\u53f7\u6355\u83b7\u5177\u6709\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u521b\u65b0\u7684\u87ba\u65cb\u654f\u611f\u5316\u5149\u7f06\u8bbe\u8ba1\u548c\u5148\u8fdb\u7684\u7a00\u758f\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6c34\u4e0b\u975e\u5747\u5300\u566a\u58f0\u73af\u5883\u4e2d\u7684\u76ee\u6807\u65b9\u5411\u611f\u77e5\u95ee\u9898\uff0c\u4e3a\u6c34\u4e0b\u76d1\u6d4b\u548c\u63a2\u6d4b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11420", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11420", "abs": "https://arxiv.org/abs/2512.11420", "authors": ["Fuhai Wang", "Tiebin Mi", "Chun Wang", "Rujing Xiong", "Zhengyu Wang", "Robert Caiming Qiu"], "title": "Source Localization and Power Estimation through RISs: Performance Analysis and Prototype Validations", "comment": null, "summary": "This paper investigates the capabilities and effectiveness of backward localization centered on reconfigurable intelligent surfaces (RISs). In the backward sensing paradigm, the region of interest (RoI) is illuminated using a set of diverse radiation patterns. These patterns encode spatial information into a sequence of measurements, which are subsequently processed to reconstruct the RoI. We show that a single RIS can estimate the direction of arrival of incident waves by leveraging configurational diversity, and that the spatial diversity provided by multiple RISs further improves the accuracy of source localization and power estimation. The underlying structure of the sensing operator in the multi-snapshot measurement process is clarified. For single-RIS localization, the sensing operator is decomposed into a product of structured matrices, each corresponding to a specific physical process: wave propagation to and from the RIS, the relative phase offsets of elements with respect to the reference point, and the applied phase configuration of each element. A unified framework for identifying key performance indicators is established by analyzing the conditioning of the sensing operators. In the multi-RIS setting, we derive--via rank analysis--the governing law among the RoI size, the number of elements, and the number of measurements. Upper bounds on the relative error of the least squares reconstruction algorithm are derived. These bounds clarify how key performance indicators affect estimation error and provide valuable guidance for system-level optimization. Numerical experiments confirm that the trend of the relative error is consistent with the theoretical bounds.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u57fa\u4e8e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u7684\u540e\u5411\u5b9a\u4f4d\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5355RIS\u548c\u591aRIS\u7cfb\u7edf\u5982\u4f55\u901a\u8fc7\u914d\u7f6e\u591a\u6837\u6027\u5b9e\u73b0\u6ce2\u8fbe\u65b9\u5411\u4f30\u8ba1\u548c\u6e90\u5b9a\u4f4d\uff0c\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u6027\u80fd\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u7814\u7a76RIS\u5728\u540e\u5411\u611f\u77e5\u8303\u5f0f\u4e2d\u7684\u80fd\u529b\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528RIS\u7684\u914d\u7f6e\u591a\u6837\u6027\u6765\u7f16\u7801\u7a7a\u95f4\u4fe1\u606f\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6e90\u5b9a\u4f4d\u548c\u529f\u7387\u4f30\u8ba1\uff0c\u4e3a\u7cfb\u7edf\u7ea7\u4f18\u5316\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5c06\u540e\u5411\u611f\u77e5\u7b97\u5b50\u5206\u89e3\u4e3a\u7ed3\u6784\u5316\u77e9\u9635\u4e58\u79ef\uff0c\u5206\u6790\u591a\u5feb\u7167\u6d4b\u91cf\u8fc7\u7a0b\u4e2d\u7684\u7b97\u5b50\u7ed3\u6784\uff0c\u901a\u8fc7\u79e9\u5206\u6790\u63a8\u5bfcRoI\u5927\u5c0f\u3001\u5355\u5143\u6570\u91cf\u548c\u6d4b\u91cf\u6570\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u6027\u80fd\u6307\u6807\u5206\u6790\u6846\u67b6\u3002", "result": "\u5355RIS\u53ef\u5b9e\u73b0\u6ce2\u8fbe\u65b9\u5411\u4f30\u8ba1\uff0c\u591aRIS\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\uff1b\u63a8\u5bfc\u4e86\u6700\u5c0f\u4e8c\u4e58\u91cd\u6784\u7b97\u6cd5\u7684\u76f8\u5bf9\u8bef\u5dee\u4e0a\u754c\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u8fb9\u754c\u7684\u8d8b\u52bf\u4e00\u81f4\u6027\u3002", "conclusion": "RIS\u901a\u8fc7\u914d\u7f6e\u591a\u6837\u6027\u6709\u6548\u5b9e\u73b0\u540e\u5411\u5b9a\u4f4d\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edf\u6027\u80fd\u4e0e\u5173\u952e\u53c2\u6570\u4e4b\u95f4\u7684\u7406\u8bba\u5173\u7cfb\uff0c\u4e3aRIS\u611f\u77e5\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2512.11444", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11444", "abs": "https://arxiv.org/abs/2512.11444", "authors": ["Baptiste Sambon", "Gilles Monnoyer", "Claude Oestges", "Luc Vandendorpe"], "title": "Point Target Near-Field Bistatic Imaging: Chirp-Based Aliasing Analysis", "comment": "Accepted to 2025 IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)", "summary": "This paper presents a chirp-based framework for characterising aliasing in a bistatic Near-Field (NF) imaging system equipped with multidimensional antenna arrays. Extending monostatic formulations, we derive closed-form expressions for the maximum spatial frequency, enabling the analytical derivations of the conditions for aliasing-free image reconstruction. The framework also provides a geometric interpretation of aliasing based on the antenna array geometry, target position, and antenna element spacing. Numerical results corroborate theoretical findings and show that the aliasing-free region enlarges with smaller antenna spacing, greater target range, lower array dimensionality, and smaller arrays. These results enable more effective design of bistatic NF imaging systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5541\u557e\u4fe1\u53f7\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u914d\u5907\u591a\u7ef4\u5929\u7ebf\u9635\u5217\u7684\u53cc\u57fa\u5730\u8fd1\u573a\u6210\u50cf\u7cfb\u7edf\u4e2d\u7684\u6df7\u53e0\u73b0\u8c61\uff0c\u63a8\u5bfc\u51fa\u65e0\u6df7\u53e0\u56fe\u50cf\u91cd\u5efa\u7684\u6761\u4ef6\u3002", "motivation": "\u53cc\u57fa\u5730\u8fd1\u573a\u6210\u50cf\u7cfb\u7edf\u5728\u96f7\u8fbe\u3001\u533b\u5b66\u6210\u50cf\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u5929\u7ebf\u9635\u5217\u914d\u7f6e\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u6df7\u53e0\u73b0\u8c61\uff0c\u5f71\u54cd\u56fe\u50cf\u8d28\u91cf\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5355\u57fa\u5730\u7cfb\u7edf\uff0c\u9700\u8981\u6269\u5c55\u81f3\u53cc\u57fa\u5730\u914d\u7f6e\u3002", "method": "\u57fa\u4e8e\u5541\u557e\u4fe1\u53f7\u6846\u67b6\uff0c\u6269\u5c55\u5355\u57fa\u5730\u516c\u5f0f\uff0c\u63a8\u5bfc\u6700\u5927\u7a7a\u95f4\u9891\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5206\u6790\u5929\u7ebf\u9635\u5217\u51e0\u4f55\u3001\u76ee\u6807\u4f4d\u7f6e\u548c\u5929\u7ebf\u95f4\u8ddd\u5bf9\u6df7\u53e0\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u51e0\u4f55\u89e3\u91ca\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u7406\u8bba\u63a8\u5bfc\uff0c\u663e\u793a\u65e0\u6df7\u53e0\u533a\u57df\u968f\u5929\u7ebf\u95f4\u8ddd\u51cf\u5c0f\u3001\u76ee\u6807\u8ddd\u79bb\u589e\u52a0\u3001\u9635\u5217\u7ef4\u5ea6\u964d\u4f4e\u548c\u9635\u5217\u5c3a\u5bf8\u51cf\u5c0f\u800c\u6269\u5927\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cc\u57fa\u5730\u8fd1\u573a\u6210\u50cf\u7cfb\u7edf\u7684\u6df7\u53e0\u5206\u6790\u63d0\u4f9b\u7406\u8bba\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u6709\u6548\u5730\u8bbe\u8ba1\u7cfb\u7edf\u53c2\u6570\u4ee5\u907f\u514d\u6df7\u53e0\uff0c\u63d0\u9ad8\u6210\u50cf\u8d28\u91cf\u3002"}}
{"id": "2512.11461", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11461", "abs": "https://arxiv.org/abs/2512.11461", "authors": ["Taissir Y. Elganimi", "Mahmoud Aldababsa", "Ali A. Nasir", "Khaled M. Rabie"], "title": "STAR-RIS-Aided Secure Communications:Analytical Insights and Performance Comparison", "comment": "15 pages", "summary": "Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) have emerged as a promising technology for enabling full-space signal manipulation and enhancing wireless network coverage and capacity. In this article, we present a comprehensive analytical comparison of STAR-RIS-assisted systems with single-input single-output (SISO), conventional RISs, and decode-and-forward (DF) relaying schemes, including both half-duplex (HD) and full-duplex (FD) modes. Closed-form expressions are derived for the achievable secrecy rates of STAR-RIS-aided communications under both the absence and presence of eavesdroppers. Unlike most existing works, the direct source destination link is incorporated in all considered schemes, and optimal transmit power allocation is investigated for HD and FD-DF relaying. Furthermore, we provide the conditions under which STAR-RIS outperforms HD- and FD-DF relaying and quantify the minimum number of STAR-RIS elements required to achieve superior rates. The impacts of key system parameters including transmit power, number of elements, reflection-to-transmission power ratio, element-splitting factor, and deployment positions on both achievable and secrecy performance are investigated. The results reveal that STAR-RIS systems can achieve superior rates and secrecy rates compared to all benchmark schemes.", "AI": {"tldr": "STAR-RIS\u6280\u672f\u76f8\u6bd4\u4f20\u7edfRIS\u548cDF\u4e2d\u7ee7\u65b9\u6848\uff0c\u5728\u5b89\u5168\u901f\u7387\u548c\u53ef\u8fbe\u901f\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u672c\u6587\u901a\u8fc7\u95ed\u5f0f\u8868\u8fbe\u5f0f\u5206\u6790\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u53ca\u5173\u952e\u53c2\u6570\u5f71\u54cd\u3002", "motivation": "STAR-RIS\u4f5c\u4e3a\u65b0\u5174\u6280\u672f\u80fd\u591f\u5b9e\u73b0\u5168\u7a7a\u95f4\u4fe1\u53f7\u64cd\u63a7\uff0c\u589e\u5f3a\u65e0\u7ebf\u7f51\u7edc\u8986\u76d6\u548c\u5bb9\u91cf\u3002\u672c\u6587\u65e8\u5728\u5168\u9762\u5206\u6790STAR-RIS\u8f85\u52a9\u7cfb\u7edf\u76f8\u6bd4SISO\u3001\u4f20\u7edfRIS\u548cDF\u4e2d\u7ee7\u65b9\u6848\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u901a\u4fe1\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u63a8\u5bfc\u4e86STAR-RIS\u8f85\u52a9\u901a\u4fe1\u5728\u6709\u65e0\u7a83\u542c\u8005\u60c5\u51b5\u4e0b\u7684\u53ef\u8fbe\u5b89\u5168\u901f\u7387\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b\u8003\u8651\u4e86\u6e90-\u76ee\u7684\u76f4\u63a5\u94fe\u8def\uff1b\u7814\u7a76\u4e86HD\u548cFD-DF\u4e2d\u7ee7\u7684\u6700\u4f18\u529f\u7387\u5206\u914d\uff1b\u5206\u6790\u4e86STAR-RIS\u4f18\u4e8eDF\u4e2d\u7ee7\u7684\u6761\u4ef6\u53ca\u6240\u9700\u6700\u5c0f\u5355\u5143\u6570\u3002", "result": "STAR-RIS\u7cfb\u7edf\u5728\u6240\u6709\u57fa\u51c6\u65b9\u6848\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u53ef\u8fbe\u901f\u7387\u548c\u5b89\u5168\u901f\u7387\uff1b\u786e\u5b9a\u4e86STAR-RIS\u4f18\u4e8eHD-\u548cFD-DF\u4e2d\u7ee7\u7684\u6761\u4ef6\uff1b\u91cf\u5316\u4e86\u5b9e\u73b0\u4f18\u8d8a\u6027\u80fd\u6240\u9700\u7684\u6700\u5c0fSTAR-RIS\u5355\u5143\u6570\u3002", "conclusion": "STAR-RIS\u6280\u672f\u76f8\u6bd4\u4f20\u7edfRIS\u548cDF\u4e2d\u7ee7\u65b9\u6848\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\uff0c\u80fd\u591f\u63d0\u4f9b\u66f4\u597d\u7684\u5b89\u5168\u901a\u4fe1\u6027\u80fd\uff0c\u5173\u952e\u7cfb\u7edf\u53c2\u6570\u5982\u53d1\u5c04\u529f\u7387\u3001\u5355\u5143\u6570\u3001\u53cd\u5c04-\u900f\u5c04\u529f\u7387\u6bd4\u7b49\u5bf9\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2512.11537", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11537", "abs": "https://arxiv.org/abs/2512.11537", "authors": ["Stefan H\u00e4gele", "Adam Misik", "Eckehard Steinbach"], "title": "RadarFuseNet: Complex-Valued Attention-Based Fusion of IQ Time- and Frequency-Domain Radar Features for Classification Tasks", "comment": "5 pages, 4 figures", "summary": "Millimeter-wave (mmWave) radar has emerged as a compact and powerful sensing modality for advanced perception tasks that leverage machine learning techniques. It is particularly effective in scenarios where vision-based sensors fail to capture reliable information, such as detecting occluded objects or distinguishing between different surface materials in indoor environments. Due to the non-linear characteristics of mmWave radar signals, deep learning-based methods are well suited for extracting relevant information from in-phase and quadrature (IQ) data. However, the current state of the art in IQ signal-based occluded-object and material classification still offers substantial potential for further improvement. In this paper, we propose a bidirectional cross-attention fusion network that combines IQ-signal and FFT-transformed radar features obtained by distinct complex-valued convolutional neural networks (CNNs). The proposed method achieves improved performance and robustness compared to standalone complex-valued CNNs. We achieve a near-perfect material classification accuracy of 99.92% on samples collected at same sensor-to-surface distances used during training, and an improved accuracy of 67.38% on samples measured at previously unseen distances, demonstrating improved generalization ability across varying measurement conditions. Furthermore, the accuracy for occluded object classification improves from 91.99% using standalone complex-valued CNNs to 94.20% using our proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7f51\u7edc\uff0c\u7ed3\u5408IQ\u4fe1\u53f7\u548cFFT\u53d8\u6362\u7684\u96f7\u8fbe\u7279\u5f81\uff0c\u7528\u4e8e\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7684\u906e\u6321\u7269\u4f53\u548c\u6750\u6599\u5206\u7c7b\uff0c\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528\u590d\u503cCNN\u6709\u66f4\u597d\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u89c6\u89c9\u4f20\u611f\u5668\u5931\u6548\u7684\u573a\u666f\uff08\u5982\u906e\u6321\u7269\u4f53\u68c0\u6d4b\u3001\u5ba4\u5185\u6750\u6599\u533a\u5206\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5f53\u524d\u57fa\u4e8eIQ\u4fe1\u53f7\u7684\u906e\u6321\u7269\u4f53\u548c\u6750\u6599\u5206\u7c7b\u65b9\u6cd5\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7f51\u7edc\uff0c\u901a\u8fc7\u4e0d\u540c\u7684\u590d\u503c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u63d0\u53d6IQ\u4fe1\u53f7\u548cFFT\u53d8\u6362\u7684\u96f7\u8fbe\u7279\u5f81\uff0c\u7136\u540e\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u8fd9\u4e9b\u7279\u5f81\u3002", "result": "\u5728\u76f8\u540c\u8ddd\u79bb\u4e0b\u6750\u6599\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523099.92%\uff0c\u5728\u672a\u89c1\u8ddd\u79bb\u4e0b\u8fbe\u523067.38%\uff08\u6cdb\u5316\u80fd\u529b\u63d0\u5347\uff09\uff1b\u906e\u6321\u7269\u4f53\u5206\u7c7b\u51c6\u786e\u7387\u4ece91.99%\u63d0\u5347\u523094.20%\u3002", "conclusion": "\u63d0\u51fa\u7684\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7f51\u7edc\u663e\u8457\u63d0\u5347\u4e86\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u906e\u6321\u7269\u4f53\u548c\u6750\u6599\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f18\u4e8e\u5355\u72ec\u7684\u590d\u503cCNN\u65b9\u6cd5\u3002"}}
{"id": "2512.11556", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11556", "abs": "https://arxiv.org/abs/2512.11556", "authors": ["Stefan H\u00e4gele", "Adam Misik", "Constantin Patsch", "Eckehard Steinbach"], "title": "ACCOR: Attention-Enhanced Complex-Valued Contrastive Learning for Occluded Object Classification Using mmWave Radar IQ Signals", "comment": "7 pages, 6 figures", "summary": "Millimeter-wave (mmWave) radar has emerged as a robust sensing modality for several areas, offering reliable operation under adverse environmental conditions. Its ability to penetrate lightweight materials such as packaging or thin walls enables non-visual sensing in industrial and automated environments and can provide robotic platforms with enhanced environmental perception when used alongside optical sensors. Recent work with MIMO mmWave radar has demonstrated its ability to penetrate cardboard packaging for occluded object classification. However, existing models leave room for improvement and warrant a more thorough evaluation across different sensing frequencies. In this paper, we propose ACCOR, an attention-enhanced complex-valued contrastive learning approach for radar, enabling robust occluded object classification. We process complex-valued IQ radar signals using a complex-valued CNN backbone, followed by a multi-head attention layer and a hybrid loss. Our proposed loss combines a weighted cross-entropy term with a supervised contrastive term. We further extend an existing 64 GHz dataset with a 67 GHz subset of the occluded objects and evaluate our model using both center frequencies. Performance evaluation demonstrates that our approach outperforms prior radar-specific models and image classification models with adapted input, achieving classification accuracies of 96.60% at 64 GHz and 93.59% at 67 GHz for ten different objects. These results demonstrate the benefits of complex-valued deep learning with attention and contrastive learning for mmWave radar-based occluded object classification in industrial and automated environments.", "AI": {"tldr": "ACCOR\uff1a\u57fa\u4e8e\u6ce8\u610f\u529b\u589e\u5f3a\u590d\u6570\u5bf9\u6bd4\u5b66\u4e60\u7684\u6beb\u7c73\u6ce2\u96f7\u8fbe\u906e\u6321\u7269\u4f53\u5206\u7c7b\u65b9\u6cd5\uff0c\u572864GHz\u548c67GHz\u9891\u7387\u4e0b\u5206\u522b\u8fbe\u523096.60%\u548c93.59%\u7684\u51c6\u786e\u7387", "motivation": "\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u6076\u52a3\u73af\u5883\u4e0b\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u7a7f\u900f\u8f7b\u8d28\u6750\u6599\u8fdb\u884c\u975e\u89c6\u89c9\u611f\u77e5\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u906e\u6321\u7269\u4f53\u5206\u7c7b\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u9891\u7387\u8bc4\u4f30", "method": "\u4f7f\u7528\u590d\u6570CNN\u9aa8\u5e72\u7f51\u7edc\u5904\u7406IQ\u96f7\u8fbe\u4fe1\u53f7\uff0c\u7ed3\u5408\u591a\u5934\u6ce8\u610f\u529b\u5c42\u548c\u6df7\u5408\u635f\u5931\u51fd\u6570\uff08\u52a0\u6743\u4ea4\u53c9\u71b5+\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\uff09\uff0c\u63d0\u51faACCOR\u6846\u67b6", "result": "\u572864GHz\u548c67GHz\u9891\u7387\u4e0b\u5206\u522b\u8fbe\u523096.60%\u548c93.59%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u96f7\u8fbe\u4e13\u7528\u6a21\u578b\u548c\u56fe\u50cf\u5206\u7c7b\u6a21\u578b", "conclusion": "\u590d\u6570\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u6ce8\u610f\u529b\u548c\u5bf9\u6bd4\u5b66\u4e60\u80fd\u6709\u6548\u63d0\u5347\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u906e\u6321\u7269\u4f53\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u548c\u81ea\u52a8\u5316\u73af\u5883"}}
{"id": "2512.11629", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11629", "abs": "https://arxiv.org/abs/2512.11629", "authors": ["Anish Nair", "Austin O' Connell", "Shalomi Arulpragasam", "Noah Kim"], "title": "PaddleSat Optical Charging Station in Space", "comment": null, "summary": "This work investigates the feasibility and design trade-offs for a companion spacecraft, or PaddleSat, to charge a host spacecraft by wirelessly transmitting power using a directional laser system. The primary goal of the PaddleSat is to supplement power on a host spacecraft to reduce the requirements for onboard power systems of the host spacecraft or extend mission lifetimes. System performance estimates, link budget calculations, optical transmission hardware and link analysis, design tradeoffs between beam divergence, optical efficiency, and relative orbital control requirements are examined.", "AI": {"tldr": "\u7814\u7a76\u4e00\u79cd\u540d\u4e3aPaddleSat\u7684\u4f34\u98de\u822a\u5929\u5668\uff0c\u901a\u8fc7\u5b9a\u5411\u6fc0\u5149\u7cfb\u7edf\u65e0\u7ebf\u4f20\u8f93\u7535\u529b\u4e3a\u5bbf\u4e3b\u822a\u5929\u5668\u5145\u7535\uff0c\u4ee5\u8865\u5145\u5bbf\u4e3b\u822a\u5929\u5668\u7535\u529b\u6216\u5ef6\u957f\u4efb\u52a1\u5bff\u547d", "motivation": "\u5bbf\u4e3b\u822a\u5929\u5668\u7684\u673a\u8f7d\u7535\u529b\u7cfb\u7edf\u9700\u6c42\u8f83\u9ad8\u6216\u4efb\u52a1\u5bff\u547d\u6709\u9650\uff0c\u9700\u8981\u8865\u5145\u7535\u529b\u6765\u6e90\u3002\u901a\u8fc7\u4f34\u98de\u822a\u5929\u5668\u65e0\u7ebf\u5145\u7535\u53ef\u4ee5\u51cf\u5c11\u5bbf\u4e3b\u822a\u5929\u5668\u7684\u7535\u529b\u7cfb\u7edf\u8981\u6c42\u6216\u5ef6\u957f\u4efb\u52a1\u8fd0\u884c\u65f6\u95f4", "method": "\u91c7\u7528\u5b9a\u5411\u6fc0\u5149\u65e0\u7ebf\u7535\u529b\u4f20\u8f93\u7cfb\u7edf\uff0c\u8fdb\u884c\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u3001\u94fe\u8def\u9884\u7b97\u8ba1\u7b97\u3001\u5149\u5b66\u4f20\u8f93\u786c\u4ef6\u548c\u94fe\u8def\u5206\u6790\uff0c\u7814\u7a76\u5149\u675f\u53d1\u6563\u3001\u5149\u5b66\u6548\u7387\u548c\u76f8\u5bf9\u8f68\u9053\u63a7\u5236\u8981\u6c42\u4e4b\u95f4\u7684\u8bbe\u8ba1\u6743\u8861", "result": "\u8fdb\u884c\u4e86\u53ef\u884c\u6027\u5206\u6790\u548c\u8bbe\u8ba1\u6743\u8861\u7814\u7a76\uff0c\u5305\u62ec\u7cfb\u7edf\u6027\u80fd\u4f30\u8ba1\u3001\u94fe\u8def\u9884\u7b97\u8ba1\u7b97\u3001\u5149\u5b66\u4f20\u8f93\u786c\u4ef6\u5206\u6790\uff0c\u4ee5\u53ca\u5149\u675f\u53d1\u6563\u3001\u5149\u5b66\u6548\u7387\u548c\u76f8\u5bf9\u8f68\u9053\u63a7\u5236\u8981\u6c42\u4e4b\u95f4\u7684\u4f18\u5316\u5e73\u8861", "conclusion": "PaddleSat\u4f34\u98de\u822a\u5929\u5668\u901a\u8fc7\u5b9a\u5411\u6fc0\u5149\u65e0\u7ebf\u5145\u7535\u5728\u6280\u672f\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u4f46\u9700\u8981\u5728\u5149\u675f\u53d1\u6563\u3001\u5149\u5b66\u6548\u7387\u548c\u8f68\u9053\u63a7\u5236\u4e4b\u95f4\u8fdb\u884c\u4ed4\u7ec6\u7684\u8bbe\u8ba1\u6743\u8861\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u7535\u529b\u4f20\u8f93"}}
