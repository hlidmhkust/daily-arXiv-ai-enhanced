<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 6]
- [eess.SP](#eess.SP) [Total: 13]
- [cs.IT](#cs.IT) [Total: 9]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Super-résolution non supervisée d'images hyperspectrales de télédétection utilisant un entraînement entièrement synthétique](https://arxiv.org/abs/2602.02552)
*Xinxin Xu,Yann Gousseau,Christophe Kervazo,Saïd Ladjal*

Main category: eess.IV

TL;DR: 提出基于合成丰度数据的无监督高光谱图像超分辨率方法，通过高光谱解混和死叶模型生成训练数据，无需高分辨率真值


<details>
  <summary>Details</summary>
Motivation: 现有高光谱单图像超分辨率方法大多依赖有监督学习，需要高分辨率真值数据，但在实际应用中往往难以获取

Method: 1) 通过高光谱解混将图像分解为端元和丰度图；2) 使用死叶模型生成合成丰度数据训练神经网络；3) 将超分辨后的丰度图与端元重新组合得到最终高光谱图像

Result: 实验结果表明该方法有效，证明了合成数据用于训练的相关性

Conclusion: 提出了一种无需高分辨率真值的无监督高光谱超分辨率方法，通过合成丰度数据训练，在保持光谱信息的同时提升空间分辨率

Abstract: Hyperspectral single image super-resolution (SISR) aims to enhance spatial resolution while preserving the rich spectral information of hyperspectral images. Most existing methods rely on supervised learning with high-resolution ground truth data, which is often unavailable in practice. To overcome this limitation, we propose an unsupervised learning approach based on synthetic abundance data. The hyperspectral image is first decomposed into endmembers and abundance maps through hyperspectral unmixing. A neural network is then trained to super-resolve these maps using data generated with the dead leaves model, which replicates the statistical properties of real abundances. The final super-resolution hyperspectral image is reconstructed by recombining the super-resolved abundance maps with the endmembers. Experimental results demonstrate the effectiveness of our method and the relevance of synthetic data for training.

</details>


### [2] [EchoJEPA: A Latent Predictive Foundation Model for Echocardiography](https://arxiv.org/abs/2602.02603)
*Alif Munim,Adibvafa Fallahpour,Teodora Szasz,Ahmadreza Attarpour,River Jiang,Brana Sooriyakanthan,Maala Sooriyakanthan,Heather Whitney,Jeremy Slivnick,Barry Rubin,Wendy Tsang,Bo Wang*

Main category: eess.IV

TL;DR: EchoJEPA是一个用于超声心动图的基础模型，通过1800万次超声心动图训练，采用潜在预测范式，显著提升左心室射血分数估计精度和视图分类性能，并表现出优异的样本效率、鲁棒性和跨患者群体迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前超声心动图基础模型未能有效分离解剖信号与超声图像中占主导的随机斑点噪声和采集伪影，需要开发能够学习可泛化表示的新方法以减少标注负担并提高诊断一致性。

Method: 提出EchoJEPA模型，在300K患者的1800万次超声心动图上进行预训练，采用潜在预测范式；引入具有因子化流嵌入的多视图探测框架，用于在冻结骨干下进行标准化评估。

Result: EchoJEPA将左心室射血分数估计误差降低19%，视图分类准确率达87.4%；仅用1%标注数据即达到78.6%准确率（基线用100%数据仅42.1%）；声学扰动下性能仅下降2.3%（次优模型下降16.8%）；零样本迁移到儿科患者误差降低15%。

Conclusion: 潜在预测是超声基础模型的优越范式，EchoJEPA在样本效率、鲁棒性和跨患者群体迁移能力方面显著优于现有方法，为超声心动图分析提供了强大的基础模型。

Abstract: Foundation models for echocardiography promise to reduce annotation burden and improve diagnostic consistency by learning generalizable representations from large unlabeled video archives. However, current approaches fail to disentangle anatomical signal from the stochastic speckle and acquisition artifacts that dominate ultrasound imagery. We present EchoJEPA, a foundation model for echocardiography trained on 18 million echocardiograms across 300K patients, the largest pretraining corpus for this modality to date. We also introduce a novel multi-view probing framework with factorized stream embeddings that standardizes evaluation under frozen backbones. Compared to prior methods, EchoJEPA reduces left ventricular ejection fraction estimation error by 19% and achieves 87.4% view classification accuracy. EchoJEPA exhibits strong sample efficiency, reaching 78.6% accuracy with only 1% of labeled data versus 42.1% for the best baseline trained on 100%. Under acoustic perturbations, EchoJEPA degrades by only 2.3% compared to 16.8% for the next best model, and transfers zero-shot to pediatric patients with 15% lower error than the next best model, outperforming all fine-tuned baselines. These results establish latent prediction as a superior paradigm for ultrasound foundation models.

</details>


### [3] [Physics-based generation of multilayer corneal OCT data via Gaussian modeling and MCML for AI-driven diagnostic and surgical guidance applications](https://arxiv.org/abs/2602.02755)
*Jinglun Yu,Yaning Wang,Rosalinda Xiong,Ziyi Huang,Kristina Irsch,Jin U. Kang*

Main category: eess.IV

TL;DR: 提出可配置的蒙特卡洛模拟框架，生成合成角膜OCT图像及五层分割标签，用于AI模型训练


<details>
  <summary>Details</summary>
Motivation: 角膜OCT成像的深度学习模型训练受限于大型标注数据集的可用性，需要可扩展的合成数据生成方法

Method: 使用高斯表面五层角膜模型，结合光学特性和MCML光传输模拟，考虑系统特性如共焦PSF和灵敏度衰减，生成合成图像和像素级分割标签

Result: 生成了超过10,000张高分辨率(1024x1024)图像-标签对，支持几何、光子计数、噪声和系统参数的自定义

Conclusion: 该框架为AI模型提供了可控、可重复、可扩展的训练资源，支持眼科图像引导诊断和手术指导应用的发展

Abstract: Training deep learning models for corneal optical coherence tomography (OCT) imaging is limited by the availability of large, well-annotated datasets. We present a configurable Monte Carlo simulation framework that generates synthetic corneal B-scan optical OCT images with pixel-level five-layer segmentation labels derived directly from the simulation geometry. A five-layer corneal model with Gaussian surfaces captures curvature and thickness variability in healthy and keratoconic eyes. Each layer is assigned optical properties from the literature and light transport is simulated using Monte Carlo modeling of light transport in multi-layered tissues (MCML), while incorporating system features such as the confocal PSF and sensitivity roll-off. This approach produces over 10,000 high-resolution (1024x1024) image-label pairs and supports customization of geometry, photon count, noise, and system parameters. The resulting dataset enables systematic training, validation, and benchmarking of AI models under controlled, ground-truth conditions, providing a reproducible and scalable resource to support the development of diagnostic and surgical guidance applications in image-guided ophthalmology.

</details>


### [4] [Wide-field high-resolution microscopy via high-speed galvo scanning and real-time mosaicking](https://arxiv.org/abs/2602.02758)
*Ziyi Huang,Rosalinda Xiong,Yaning Wang,Jinglun Yu,Jin U. Kang*

Main category: eess.IV

TL;DR: 提出了一种适用于线性和正弦扫描的宽场显微图像拼接框架，通过几何拼接模型、亮度校正和接缝处理，实现了大视场（2.5×2.5 cm²）快速（约6秒）的高质量图像重建。


<details>
  <summary>Details</summary>
Motivation: 传统振镜扫描（特别是正弦驱动）会导致空间采样不均匀，引起几何不一致性和亮度变化，影响宽场高分辨率显微镜的大视场成像质量。

Method: 结合基于平移的几何拼接模型、ROI亮度校正和接缝感知羽化技术，利用校准的扫描参数和同步的扫描-相机控制，无需基于图像内容的配准。

Result: 成功重建了线性和正弦扫描策略下的宽场拼接图像，视场达2.5×2.5 cm²，采集时间约6秒，亮度均匀性、对比度噪声比提高，接缝伪影减少，保持7.81 μm横向分辨率。

Conclusion: 该框架为基于扫描的宽场显微图像拼接提供了实用高效的解决方案，适用于不同扫描策略，显著提升了图像质量和处理效率。

Abstract: Wide-field high-resolution microscopy requires fast scanning and accurate image mosaicking to cover large fields of view without compromising image quality. However, conventional galvanometric scanning, particularly under sinusoidal driving, can introduce nonuniform spatial sampling, leading to geometric inconsistencies and brightness variations across the scanned field. To address these challenges, we present an image mosaicking framework for wide-field microscopic imaging that is applicable to both linear and sinusoidal galvanometric scanning strategies. The proposed approach combines a translation-based geometric mosaicking model with region-of-interest (ROI) based brightness correction and seam-aware feathering to improve radiometric consistency across large fields of view. The method relies on calibrated scan parameters and synchronized scan--camera control, without requiring image-content-based registration. Using the proposed framework, wide-field mosaicked images were successfully reconstructed under both linear and sinusoidal scanning strategies, achieving a field of view of up to $2.5 \times 2.5~\mathrm{cm}^2$ with a total acquisition time of approximately $6~\mathrm{s}$ per dataset. Quantitative evaluation shows that both scanning strategies demonstrate improved image quality, including enhanced brightness uniformity, increased contrast-to-noise ratio (CNR), and reduced seam-related artifacts after image processing, while preserving a lateral resolution of $7.81~μ\mathrm{m}$. Overall, the presented framework provides a practical and efficient solution for scan-based wide-field microscopic mosaicking.

</details>


### [5] [Super-Resolution and Denoising of Corneal B-Scan OCT Imaging Using Diffusion Model Plug-and-Play Priors](https://arxiv.org/abs/2602.02795)
*Yaning Wang,Jinglun Yu,Wenhan Guo,Ziyi Huang,Rosalinda Xiong,Yu Sun,Jin U. Kang*

Main category: eess.IV

TL;DR: 提出基于扩散模型即插即用先验的超分辨率框架，用于OCT Bscan图像的4倍空间分辨率增强和去噪，通过贝叶斯逆问题公式化实现解剖结构一致性。


<details>
  <summary>Details</summary>
Motivation: OCT在角膜成像中至关重要，但高速采集会降低空间分辨率并增加散斑噪声，影响准确解读，需要同时提升分辨率和去噪的方法。

Method: 采用扩散模型即插即用先验框架，将重建公式化为贝叶斯逆问题，结合马尔可夫链蒙特卡洛采样和预训练生成先验来强制解剖一致性。

Result: 在活体鱼眼角膜数据集上验证，相比双三次插值、传统监督U-Net基线和替代扩散先验方法，能产生更精确的解剖结构、更好的角膜层分界和更优的噪声抑制，在PSNR、SSIM和感知指标上达到最先进性能。

Conclusion: 扩散驱动的即插即用重建方法能提供高保真、高分辨率的OCT成像，支持更可靠的临床评估和先进的图像引导干预，并可扩展到其他需要鲁棒超分辨率和去噪的生物医学成像模态。

Abstract: Optical coherence tomography (OCT) is pivotal in corneal imaging for both surgical planning and diagnosis. However, high-speed acquisitions often degrade spatial resolution and increase speckle noise, posing challenges for accurate interpretation. We propose an advanced super-resolution framework leveraging diffusion model plug-and-play (PnP) priors to achieve 4x spatial resolution enhancement alongside effective denoising of OCT Bscan images. Our approach formulates reconstruction as a principled Bayesian inverse problem, combining Markov chain Monte Carlo sampling with pretrained generative priors to enforce anatomical consistency. We comprehensively validate the framework using \emph{in vivo} fisheye corneal datasets, to assess robustness and scalability under diverse clinical settings. Comparative experiments against bicubic interpolation, conventional supervised U-Net baselines, and alternative diffusion priors demonstrate that our method consistently yields more precise anatomical structures, improved delineation of corneal layers, and superior noise suppression. Quantitative results show state-of-the-art performance in peak signal-to-noise ratio, structural similarity index, and perceptual metrics. This work highlights the potential of diffusion-driven plug-and-play reconstruction to deliver high-fidelity, high-resolution OCT imaging, supporting more reliable clinical assessments and enabling advanced image-guided interventions. Our findings suggest the approach can be extended to other biomedical imaging modalities requiring robust super-resolution and denoising.

</details>


### [6] [Real-time topology-aware M-mode OCT segmentation for robotic deep anterior lamellar keratoplasty (DALK) guidance](https://arxiv.org/abs/2602.02798)
*Rosalinda Xiong,Jinglun Yu,Yaning Wang,Ziyi Huang,Jin U. Kang*

Main category: eess.IV

TL;DR: 提出一种轻量级、拓扑感知的M-mode OCT分割管道，用于机器人深前板层角膜移植手术中的实时深度反馈，在单GPU上实现超过80Hz的端到端处理速度。


<details>
  <summary>Details</summary>
Motivation: 机器人深前板层角膜移植手术需要准确的实时深度反馈来接近后弹力层而不穿孔。M-mode术中OCT提供高时间分辨率深度轨迹，但斑点噪声、衰减和器械引起的阴影常导致不连续或模糊的层界面，难以在部署帧率下实现解剖学一致的分割。

Method: 基于UNeXt的轻量级、拓扑感知M-mode分割管道，结合解剖拓扑正则化，在低信噪比条件下稳定边界连续性和层序。系统在单GPU上实现超过80Hz的端到端处理速度。

Result: 在标准兔眼M-mode数据集上评估显示，相比拓扑不可知控制方法，具有改进的定性边界稳定性，同时保持可部署的实时性能。

Conclusion: 提出的拓扑感知分割系统能够提供稳定的实时深度更新率，为机器人角膜移植手术提供实用的实时引导，超出仅模型计时的性能。

Abstract: Robotic deep anterior lamellar keratoplasty (DALK) requires accurate real time depth feedback to approach Descemet's membrane (DM) without perforation. M-mode intraoperative optical coherence tomography (OCT) provides high temporal resolution depth traces, but speckle noise, attenuation, and instrument induced shadowing often result in discontinuous or ambiguous layer interfaces that challenge anatomically consistent segmentation at deployment frame rates. We present a lightweight, topology aware M-mode segmentation pipeline based on UNeXt that incorporates anatomical topology regularization to stabilize boundary continuity and layer ordering under low signal to noise ratio conditions. The proposed system achieves end to end throughput exceeding 80 Hz measured over the complete preprocessing inference overlay pipeline on a single GPU, demonstrating practical real time guidance beyond model only timing. This operating margin provides temporal headroom to reject low quality or dropout frames while maintaining a stable effective depth update rate. Evaluation on a standard rabbit eye M-mode dataset using an established baseline protocol shows improved qualitative boundary stability compared with topology agnostic controls, while preserving deployable real time performance.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [7] [Joint single-shot ToA and DoA estimation for VAA-based BLE ranging with phase ambiguity: A deep learning-based approach](https://arxiv.org/abs/2602.02503)
*Jincheng Xie,Yili Deng,Jiguang He,Pengyu Wang,Miaomiao Dong,Rui Tang,Zhongyi Huang*

Main category: eess.SP

TL;DR: 提出一种基于神经网络的相位恢复框架，结合虚拟天线阵列和BLE双向信道频率响应，解决单天线BLE设备的到达方向估计问题


<details>
  <summary>Details</summary>
Motivation: 传统DoA估计方法需要多天线阵列，成本高且不适合尺寸受限的BLE设备。虚拟天线阵列技术虽然能用单天线实现DoA估计，但BLE仅提供单次双向CFR且存在二进制相位模糊问题，阻碍了VAA的直接应用。

Method: 提出统一模型结合VAA与BLE双向CFR，引入基于神经网络的相位恢复框架，使用行/列预测器配合投票机制解决相位模糊问题。恢复后的单向CFR使MUSIC等超分辨率算法能够进行联合ToA和DoA估计。

Result: 仿真结果表明，该方法在非均匀VAA下表现优异，当SNR≥5dB时，均方误差接近克拉美罗下界。

Conclusion: 该方法成功解决了BLE设备单天线DoA估计中的相位模糊问题，使尺寸受限的BLE设备能够实现精确的到达方向估计。

Abstract: Conventional direction-of-arrival (DoA) estimation methods rely on multi-antenna arrays, which are costly to implement on size-constrained Bluetooth Low Energy (BLE) devices. Virtual antenna array (VAA) techniques enable DoA estimation with a single antenna, making angle estimation feasible on such devices. However, BLE only provides a single-shot two-way channel frequency response (CFR) with a binary phase ambiguity issue, which hinders the direct application of VAA. To address this challenge, we propose a unified model that combines VAA with BLE two-way CFR, and introduce a neural network based phase recovery framework that employs row / column predictors with a voting mechanism to resolve the ambiguity. The recovered one-way CFR then enables super resolution algorithms such as MUSIC for joint time of arrival (ToA) and DoA estimation. Simulation results demonstrate that the proposed method achieves superior performance under non-uniform VAAs, with mean square errors approaching the Cramer Rao bound at SNR $\geq$ 5 dB.

</details>


### [8] [Pilots and Other Predictable Elements of the Starlink Ku-Band Downlink](https://arxiv.org/abs/2602.02627)
*Wenkai Qin,Mark L. Psiaki,John R. Bowman,Todd E. Humphreys*

Main category: eess.SP

TL;DR: 该论文识别并利用了Starlink Ku波段下行波形中的可预测元素（如专用导频符号），实现了低成本紧凑接收机的高精度机会定位、导航和定时。


<details>
  <summary>Details</summary>
Motivation: Starlink卫星信号通常被认为难以用于定位导航，因为其波形设计不公开且包含加密数据。然而，作者发现信号中存在可预测元素，这些元素可以用于实现低成本、高精度的机会定位导航定时。

Method: 开发了Starlink信号的采集和解调框架，解码Starlink帧结构，识别出边缘导频（edge pilots）——位于每个信道边缘的4QAM符号带，这些符号在所有帧、波束、信道和卫星中重复出现。同时发现大多数QPSK调制符号并非高熵用户数据，而是遵循规则镶嵌结构叠加在恒定参考模板上。

Result: 利用帧级可预测元素可获得约48dB的处理增益，使低成本紧凑接收机即使在低信噪比的Starlink侧波束下也能提取精确的到达时间测量值。

Conclusion: Starlink信号中的可预测元素为机会定位导航定时提供了新途径，通过最大化信号处理增益，实现了低成本紧凑接收机的高精度测量能力。

Abstract: We identify and characterize dedicated pilot symbols and other predictable elements embedded within the Starlink Ku-band downlink waveform. Exploitation of these predictable elements enables precise opportunistic positioning, navigation, and timing using compact, low-gain receivers by maximizing the signal processing gain available for signal acquisition and time-of-arrival (TOA) estimation. We develop an acquisition and demodulation framework to decode Starlink frames and disclose the explicit sequences of the edge pilots -- bands of 4QAM symbols located at both edges of each Starlink channel that apparently repeat identically across all frames, beams, channels, and satellites. We further reveal that the great majority of QPSK-modulated symbols do not carry high-entropy user data but instead follow a regular tessellated structure superimposed on a constant reference template. We demonstrate that exploiting frame-level predictable elements yields a processing gain of approximately 48 dB, thereby enabling low-cost, compact receivers to extract precise TOA measurements even from low-SNR Starlink side beams.

</details>


### [9] [STAR-RIS-Assisted Full-Space Angle Estimation via Finite Rate of Innovation](https://arxiv.org/abs/2602.02893)
*Ziming Liu,Tao Chen,Muran Guo,Francesco Verde*

Main category: eess.SP

TL;DR: 提出基于STAR-RIS和有限创新率模型的空域角度估计框架，支持全空间角度检测，通过近端梯度算法和湮灭滤波器实现无网格角度估计。


<details>
  <summary>Details</summary>
Motivation: 传统传感器架构通常将角度估计限制在半空间，而STAR-RIS通过同时传输和反射支持全空间角度检测，但需要有效的估计方法来利用这种能力。

Method: 1) 针对两种STAR-RIS配置（元素均匀和非均匀能量分配）建立FRI信号模型；2) 推导角度估计的Ziv-Zakai界；3) 开发基于交替投影的近端梯度算法恢复FRI采样结构；4) 构建湮灭滤波器，通过多项式求根实现无网格角度估计。

Result: 数值结果表明，所提方法在两种配置下都能可靠工作，以低开销实现改进的角度估计性能。

Conclusion: 基于STAR-RIS的FRI框架为全空间角度估计提供了有效解决方案，通过灵活的配置和计算高效的算法实现了优于传统方法的性能。

Abstract: Conventional sensor architectures typically restrict angle estimation to the half-space. By enabling simultaneous transmission and reflection, simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) can support full-space angle detection. This paper develops a fullspace angle estimation framework by leveraging a finite rate of innovation (FRI) model enabled by STAR-RIS. We distinguish two practical STAR-RIS configurations: (i) an element-wise uniform setting, where all metasurface elements share identical energy-splitting (ES) coefficients and phase differences, and (ii) a nonuniform ES setting, where the phase difference is common across elements while the ES coefficients vary element-wise to increase design flexibility. For each regime, we formulate the corresponding FRI-based signal model and derive the Ziv-Zakai bound (ZZB) for angle estimation. To recover the underlying FRI sampling structure, we develop a proximal-gradient algorithm implemented via alternating projections in matrix space and establish its convergence. Exploiting the recovered FRI structure, we construct an annihilating filter whose zeros encode user angles, enabling gridless estimation via polynomial root finding. Numerical results demonstrate that the proposed methods operate reliably across both configuration regimes and achieve improved angle estimation performance with low overhead.

</details>


### [10] [Tri-Hybrid Holographic Beamforming for Integrated Sensing and Communication](https://arxiv.org/abs/2602.03000)
*Shupei Zhang,Shuhao Zeng,Boya Di,Lingyang Song*

Main category: eess.SP

TL;DR: 提出了一种基于可重构全息表面的三混合全息ISAC框架，通过数字、模拟和RHS电磁层联合优化，在满足通信速率要求的同时最小化感知波形误差，实现低成本大规模天线阵列的ISAC系统。


<details>
  <summary>Details</summary>
Motivation: 6G中ISAC需要同时执行通信和感知任务，但传统大规模天线阵列成本高。RHS作为低成本大规模天线实现方案，可集成到ISAC系统中实现全息ISAC，但需要解决数字、模拟和RHS层的联合优化挑战。

Method: 提出三混合全息ISAC方案，波束成形器包含数字层、模拟层和RHS电磁层。模拟层使用少量移相器提供子阵列级相位控制，RHS层实现幅度调制。设计了PS相位和RHS幅度响应的联合优化方法，解决层间耦合和不同可行域问题。

Result: 理论分析显示优化后的幅度响应聚集在边界值附近（1-bit幅度控制），降低了硬件和算法复杂度。仿真结果表明该方案实现了通信与感知任务间的可控性能权衡。实测RHS波束增益验证了子阵列级移相对全息波束成形的增强效果。随着RHS元件数量增加，该方案性能超过传统混合波束成形，同时显著减少移相器数量。

Conclusion: 三混合全息ISAC框架为低成本大规模全息ISAC提供了可行路径，通过联合优化PS相位和RHS幅度响应，在减少硬件复杂度的同时实现了通信与感知的良好性能平衡，是6G ISAC系统的有前景解决方案。

Abstract: Integrated sensing and communication (ISAC) can perform both communication and sensing tasks using the same frequency band and hardware, making it a key technology for 6G. As a low-cost implementation for large-scale antenna arrays, reconfigurable holographic surfaces (RHSs) can be integrated into ISAC systems to realize the holographic ISAC paradigm, where enlarged radiation apertures achieve significant beamforming gains. In this paper, we investigate the tri-hybrid holographic ISAC framework, where the beamformer comprises digital, analog, and RHS-based electromagnetic (EM) layers. The analog layer employs a small number of phase shifters (PSs) to provide subarray-level phase control for the amplitude-modulated RHSs. Tri-hybrid beamforming provides a pathway for low-cost large-scale holographic ISAC. However, compared to conventional ISAC systems, it is challenging to achieve joint subarray-level phase control via PSs and element-level radiation amplitude control via RHSs for holographic ISAC. To address this, we present a tri-hybrid holographic ISAC scheme that minimizes sensing waveform error while satisfying the minimum user rate requirement. A joint optimization approach for PS phases and RHS amplitude responses is designed to address inter-layer coupling and distinct feasible regions. Theoretical analyses reveal that the optimized amplitude responses cluster near boundary values, i.e., 1-bit amplitude control, to reduce hardware and algorithmic complexity. Simulation results show that the proposed scheme achieves a controllable performance trade-off between communication and sensing tasks. Measured RHS beam gain validates the enhancement of holographic beamforming through subarray-level phase shifting. Moreover, as the number of RHS elements increases, the proposed approach exceeds the performance of conventional hybrid beamforming while significantly reducing the number of PSs.

</details>


### [11] [Stationarity and Spectral Characterization of Random Signals on Simplicial Complexes](https://arxiv.org/abs/2602.03055)
*Madeline Navarro,Andrei Buciulea,Santiago Segarra,Antonio Marques*

Main category: eess.SP

TL;DR: 提出一个概率框架用于定义单纯复形上的随机拓扑信号，通过推广经典平稳性概念，利用Hodge和Dirac理论的谱对偶性，将平稳拓扑信号定义为拓扑滤波器对白噪声的输出。


<details>
  <summary>Details</summary>
Motivation: 数据日益具有复杂结构，图虽然能编码节点间关系，但无法表示非二元连接或多节点间关系。单纯复形能连接多个节点并建模单纯形间关系，但现有研究主要基于确定性方法，缺乏概率框架。

Method: 通过Hodge和Dirac理论的谱对偶性，推广经典平稳性概念，定义单纯复形上的平稳拓扑信号为拓扑滤波器对白噪声的输出，并明确定义拓扑功率谱密度。

Result: 成功建立了拓扑信号的平稳性理论框架，该框架自然地扩展了时间序列和图信号的平稳性性质，并通过多个合成和真实世界模拟验证了其实际应用价值。

Conclusion: 提出的概率框架为拓扑信号分析提供了理论基础，通过谱性质的优势和明确的功率谱密度定义，增强了拓扑信号处理的实际应用能力。

Abstract: It is increasingly common for data to possess intricate structure, necessitating new models and analytical tools. Graphs, a prominent type of structure, can encode the relationships between any two entities (nodes). However, graphs neither allow connections that are not dyadic nor permit relationships between sets of nodes. We thus turn to simplicial complexes for connecting more than two nodes as well as modeling relationships between simplices, such as edges and triangles. Our data then consist of signals lying on topological spaces, represented by simplicial complexes. Much recent work explores these topological signals, albeit primarily through deterministic formulations. We propose a probabilistic framework for random signals defined on simplicial complexes. Specifically, we generalize the classical notion of stationarity. By spectral dualities of Hodge and Dirac theory, we define stationary topological signals as the outputs of topological filters given white noise. This definition naturally extends desirable properties of stationarity that hold for both time-series and graph signals. Crucially, we properly define topological power spectral density (PSD) through a clear spectral characterization. We then discuss the advantages of topological stationarity due to spectral properties via the PSD. In addition, we empirically demonstrate the practicality of these benefits through multiple synthetic and real-world simulations.

</details>


### [12] [Multipath Extended Target Tracking with Labeled Random Finite Sets](https://arxiv.org/abs/2602.03464)
*Guanhua Ding,Tao Huang,Qinchen Wu,Jinping Sun,Yanping Wang,Bing Zhu,Guoqiang Mao*

Main category: eess.SP

TL;DR: 提出MPET-GLMB滤波器，用于多径环境下的扩展目标跟踪，通过统一贝叶斯框架联合建模目标存在、测量分区以及测量-目标-传播路径关联，在动态多径环境中实现优越的状态估计精度和轨迹连续性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率雷达在自动驾驶系统中至关重要，但传统跟踪算法面临挑战：每个目标产生多个测量值，存在多径效应。现有解决方案要么依赖点目标假设，要么将多径测量视为杂波，而当前扩展目标跟踪器在复杂多径环境中缺乏保持轨迹连续性的能力。

Method: 提出多径扩展目标广义标记多伯努利(MPET-GLMB)滤波器。基于标记随机有限集理论推导统一贝叶斯框架，联合建模目标存在、测量分区以及测量、目标和传播路径之间的关联。采用基于吉布斯采样的联合预测和更新实现以提高计算效率，并引入测量驱动的自适应出生模型来初始化轨迹。

Result: 在模拟场景和真实汽车雷达数据上的实验结果表明，所提出的滤波器优于最先进的方法，在动态多径环境中实现了优越的状态估计精度和鲁棒的轨迹维护。

Conclusion: MPET-GLMB滤波器能够有效处理高分辨率雷达中的多径扩展目标跟踪问题，无需启发式后处理即可同时估计目标和反射器的轨迹，为自动驾驶系统提供了更可靠的感知解决方案。

Abstract: High-resolution radar sensors are critical for autonomous systems but pose significant challenges to traditional tracking algorithms due to the generation of multiple measurements per object and the presence of multipath effects. Existing solutions often rely on the point target assumption or treat multipath measurements as clutter, whereas current extended target trackers often lack the capability to maintain trajectory continuity in complex multipath environments. To address these limitations, this paper proposes the multipath extended target generalized labeled multi-Bernoulli (MPET-GLMB) filter. A unified Bayesian framework based on labeled random finite set theory is derived to jointly model target existence, measurement partitioning, and the association between measurements, targets, and propagation paths. This formulation enables simultaneous trajectory estimation for both targets and reflectors without requiring heuristic post-processing. To enhance computational efficiency, a joint prediction and update implementation based on Gibbs sampling is developed. Furthermore, a measurement-driven adaptive birth model is introduced to initialize tracks without prior knowledge of target positions. Experimental results from simulated scenarios and real-world automotive radar data demonstrate that the proposed filter outperforms state-of-the-art methods, achieving superior state estimation accuracy and robust trajectory maintenance in dynamic multipath environments.

</details>


### [13] [Channel-Aware Conditional Diffusion Model for Secure MU-MISO Communications](https://arxiv.org/abs/2602.03524)
*Tong Hui,Xiao Tang,Yichen Wang,Qinghe Du,Dusit Niyato,Zhu Han*

Main category: eess.SP

TL;DR: 本文提出了一种基于条件扩散模型的物理层安全方法，用于联合设计合法波束成形和人工噪声，相比传统优化方法和判别式深度学习模型，在安全性能和实时实现方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在实时实现方面存在困难，而典型的判别式深度学习模型可能无法应对未预见场景。为了解决无线通信中信息安全这一基本需求，需要一种能够学习最优安全策略分布并适应各种场景的方法。

Method: 将安全优化问题重新表述为条件生成过程，使用扩散模型学习近最优联合波束成形和人工噪声策略的内在分布。采用带有交叉注意力的U-Net架构集成信道状态信息作为生成基础，并通过包含总保密率的目标函数对训练模型进行微调以进一步提升安全性能。

Result: 仿真结果验证了学习过程的收敛性，并证明所提出的生成方法在各种场景下相比基线方法实现了更优的保密性能。

Conclusion: 基于条件扩散模型的生成方法能够有效解决物理层安全问题，在实时实现和应对未预见场景方面优于传统方法，为无线通信安全提供了新的解决方案。

Abstract: While information securityis a fundamental requirement for wireless communications, conventional optimization based approaches often struggle with real-time implementation, and deep models, typically discriminative in nature, may lack the ability to cope with unforeseen scenarios. To address this challenge, this paper investigates the design of legitimate beamforming and artificial noise (AN) to achieve physical layer security by exploiting the conditional diffusion model. Specifically, we reformulate the security optimization as a conditional generative process, using a diffusion model to learn the inherent distribution of near-optimal joint beamforming and AN strategies. We employ a U-Net architecture with cross-attention to integrate channel state information, as the basis for the generative process. Moreover, we fine-tune the trained model using an objective incorporating the sum secrecy rate such that the security performance is further enhanced. Finally, simulation results validate the learning process convergence and demonstrate that the proposed generative method achieves superior secrecy performance across various scenarios as compared with the baselines.

</details>


### [14] [Low-Complexity Distributed Combining Design for Near-Field Cell-Free XL-MIMO Systems](https://arxiv.org/abs/2602.03581)
*Zhe Wang,Jiayi Zhang,Bokai Xu,Dusit Niyato,Bo Ai,Shiwen Mao,Zhu Han*

Main category: eess.SP

TL;DR: 本文研究了近场无蜂窝超大规模MIMO系统的低复杂度分布式组合方案设计，提出了五种基于矩阵近似方法或SSOR算法的低复杂度分布式组合方案。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决近场无蜂窝超大规模MIMO系统中分布式处理的计算复杂度问题，需要在保证性能的同时降低计算负担。

Method: 首先构建了上行频谱效率分析框架，推导了集中式和分布式处理方案。然后基于CMMSE和LMMSE组合方案，提出了五种低复杂度分布式组合方案：两种基于矩阵近似方法（GSLI-MMSE和SI-LMMSE），以及三种基于SSOR算法的分布式LMMSE组合方案。

Result: 提出了五种低复杂度分布式组合方案，包括基于矩阵近似的方法和基于SSOR迭代算法的方法，这些方案能够在降低计算复杂度的同时保持系统性能。

Conclusion: 本文为近场无蜂窝超大规模MIMO系统提供了有效的低复杂度分布式组合方案设计，通过矩阵近似和SSOR算法显著降低了计算复杂度，同时保持了系统性能，为实际部署提供了可行的解决方案。

Abstract: In this paper, we investigate the low-complexity distributed combining scheme design for near-field cell-free extremely large-scale multiple-input-multiple-output (CF XL-MIMO) systems. Firstly, we construct the uplink spectral efficiency (SE) performance analysis framework for CF XL-MIMO systems over centralized and distributed processing schemes. Notably, we derive the centralized minimum mean-square error (CMMSE) and local minimum mean-square error (LMMSE) combining schemes over arbitrary channel estimators. Then, focusing on the CMMSE and LMMSE combining schemes, we propose five low-complexity distributed combining schemes based on the matrix approximation methodology or the symmetric successive over relaxation (SSOR) algorithm. More specifically, we propose two matrix approximation methodology-aided combining schemes: Global Statistics \& Local Instantaneous information-based MMSE (GSLI-MMSE) and Statistics matrix Inversion-based LMMSE (SI-LMMSE). These two schemes are derived by approximating the global instantaneous information in the CMMSE combining and the local instantaneous information in the LMMSE combining with the global and local statistics information by asymptotic analysis and matrix expectation approximation, respectively. Moreover, by applying the low-complexity SSOR algorithm to iteratively solve the matrix inversion in the LMMSE combining, we derive three distributed SSOR-based LMMSE combining schemes, distinguished from the applied information and initial values.

</details>


### [15] [Statistics Approximation-Enabled Distributed Beamforming for Cell-Free Massive MIMO](https://arxiv.org/abs/2602.03590)
*Zhe Wang,Emil Björnson,Jiayi Zhang,Peng Zhang,Vitaly Petrov,Bo Ai*

Main category: eess.SP

TL;DR: 提出GSLI-MMSE分布式波束成形方案，用于无蜂窝大规模MIMO网络，结合全局统计信息和局部瞬时信息，性能接近集中式MMSE方案。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO网络需要分布式处理方案，以降低计算复杂度和回程开销，同时保持接近集中式方案的性能。

Method: 采用矩阵求逆推导构建MMSE合并，然后应用统计近似方法，用信道统计量近似其他AP的瞬时项，形成基于局部瞬时信息和全局统计的分布式合并方案，并利用上下行对偶性推导预编码方案。

Result: 在稳定视距条件下（如静态用户的莱斯衰落信道），GSLI-MMSE方案性能接近最优集中式MMSE方案。

Conclusion: GSLI-MMSE方案为无蜂窝大规模MIMO网络提供了一种有效的分布式波束成形方法，在保持性能的同时降低了实现复杂度。

Abstract: We study a distributed beamforming approach for cell-free massive multiple-input multiple-output networks, referred to as Global Statistics \& Local Instantaneous information-based minimum mean-square error (GSLI-MMSE). The scenario with multi-antenna access points (APs) is considered over three different channel models: correlated Rician fading with fixed or random line-of-sight (LoS) phase-shifts, and correlated Rayleigh fading. With the aid of matrix inversion derivations, we can construct the conventional MMSE combining from the perspective of each AP, where global instantaneous information is involved. Then, for an arbitrary AP, we apply the statistics approximation methodology to approximate instantaneous terms related to other APs by channel statistics to construct the distributed combining scheme at each AP with local instantaneous information and global statistics. With the aid of uplink-downlink duality, we derive the respective GSLI-MMSE precoding schemes. Numerical results showcase that the proposed GSLI-MMSE scheme demonstrates performance comparable to the optimal centralized MMSE scheme, under the stable LoS conditions, e.g., with static users having Rician fading with a fixed LoS path.

</details>


### [16] [A Multi-decoder Neural Tracking Method for Accurately Predicting Speech Intelligibility](https://arxiv.org/abs/2602.03624)
*Rien Sonck,Bernd Accou,Tom Francart,Jonas Vanthornhout*

Main category: eess.SP

TL;DR: 提出多解码器方法从EEG预测言语接收阈值，准确度接近行为测试（差异<1dB），可将EEG采集时间缩短至15分钟。


<details>
  <summary>Details</summary>
Motivation: 现有EEG方法预测言语可懂度的准确性和鲁棒性不如行为测试（测试-重测差异通常<1dB），需要为无法进行行为测试的人群（如意识障碍患者、助听器配戴者）提供客观评估方法。

Method: 使用多解码器方法，聚合数百个在不同言语特征和EEG预处理设置下训练的神经追踪解码器。从39名参与者收集EEG数据，将神经追踪值组合成高维特征向量，用支持向量回归模型预测言语接收阈值。

Result: 预测结果与行为言语接收阈值显著相关（r=0.647，p<0.001；NRMSE=0.19），所有差异均小于1dB。使用预训练的主体无关解码器可将EEG数据采集时间减少至15分钟而不损失准确性。

Conclusion: 多解码器方法能够准确预测言语接收阈值，为无法进行行为测试的临床人群提供了可靠的客观评估工具，同时显著减少了数据采集时间，具有临床应用潜力。

Abstract: Objective: EEG-based methods can predict speech intelligibility, but their accuracy and robustness lag behind behavioral tests, which typically show test-retest differences under 1 dB. We introduce the multi-decoder method to predict speech reception thresholds (SRTs) from EEG recordings, enabling objective assessment for populations unable to perform behavioral tests; such as those with disorders of consciousness or during hearing aid fitting. Approach: The method aggregates data from hundreds of decoders, each trained on different speech features and EEG preprocessing setups to quantify neural tracking (NT) of speech signals. Using data from 39 participants (ages 18-24), we recorded 29 minutes of EEG per person while they listened to speech at six signal-to-noise ratios and a quiet story. NT values were combined into a high-dimensional feature vector per subject, and a support vector regression model was trained to predict SRTs from these vectors. Main Result: Predictions correlated significantly with behavioral SRTs (r = 0.647, p < 0.001; NRMSE = 0.19), with all differences under 1 dB. SHAP analysis showed theta/delta bands and early lags had slightly greater influence. Using pretrained subject-independent decoders reduced required EEG data collection to 15 minutes (3 minutes of story, 12 minutes across six SNR conditions) without losing accuracy.

</details>


### [17] [VR-VFL: Joint Rate and Client Selection for Vehicular Federated Learning Under Imperfect CSI](https://arxiv.org/abs/2602.03711)
*Metehan Karatas,Subhrakanti Dey,Christian Rohner,Jose Mairton Barros da Silva*

Main category: eess.SP

TL;DR: VR-VFL是一种针对车载边缘网络的新型联邦学习方法，通过动态客户端选择、自适应传输速率和灵活轮次时间，在非完美信道状态下实现更高效的资源分配，比现有方法收敛速度快约40%。


<details>
  <summary>Details</summary>
Motivation: 车载边缘网络中的联邦学习面临车辆高移动性和非完美信道状态信息的挑战，现有方法通常假设固定通信轮次或理想信道条件，无法适应真实场景需求。

Method: 提出可变速率车载联邦学习（VR-VFL），结合动态客户端选择、自适应传输速率选择，并允许轮次时间根据无线条件灵活调整，基于双目标优化框架平衡学习收敛和轮次完成时间。

Result: 仿真结果表明，VR-VFL方案比文献中其他方法收敛速度快约40%，在车载边缘网络中实现了更高效的学习性能。

Conclusion: VR-VFL通过考虑移动性和实际无线约束，为车载边缘网络中的联邦学习提供了更实用和高效的解决方案，显著提升了学习收敛速度。

Abstract: Federated learning in vehicular edge networks faces major challenges in efficient resource allocation, largely due to high vehicle mobility and the presence of imperfect channel state information. Many existing methods oversimplify these realities, often assuming fixed communication rounds or ideal channel conditions, which limits their effectiveness in real-world scenarios. To address this, we propose variable rate vehicular federated learning (VR-VFL), a novel federated learning method designed specifically for vehicular networks under imperfect channel state information. VR-VFL combines dynamic client selection with adaptive transmission rate selection, while also allowing round times to flex in response to changing wireless conditions. At its core, VR-VFL is built on a bi-objective optimization framework that strikes a balance between improving learning convergence and minimizing the time required to complete each round. By accounting for both the challenges of mobility and realistic wireless constraints, VR-VFL offers a more practical and efficient approach to federated learning in vehicular edge networks. Simulation results show that the proposed VR-VFL scheme achieves convergence approximately 40% faster than other methods in the literature.

</details>


### [18] [A Narrowband Fully-Analog Multi-Antenna Transmitter](https://arxiv.org/abs/2602.03718)
*Nikola Zlatanov*

Main category: eess.SP

TL;DR: 提出一种窄带全模拟N天线发射机，通过可编程无源干涉网络和相位控制元件，用单相干RF音合成任意复数激励向量，相比全数字阵列显著降低功耗。


<details>
  <summary>Details</summary>
Motivation: 传统全数字天线阵列需要大量射频前端组件，功耗高。本文旨在设计一种全模拟发射机架构，能够模拟全数字阵列的功能，同时显著降低功耗。

Method: 采用可编程无源干涉网络，通过二进制幅度分裂树分配天线幅度，配合相位库控制相位。使用2N-1个可调自由度，实现确定性O(N)编程过程，无需迭代优化。

Result: 在N≤16时，相比等效商用全数字阵列，全模拟架构在射频前端功耗方面有显著节省。该架构能够实现符号级更新，支持快速调谐。

Conclusion: 本文提出了一种窄带全模拟发射机概念验证，通过可编程无源网络和相位控制实现全数字阵列功能，同时大幅降低功耗，为未来低功耗无线系统提供新方向。

Abstract: This paper proposes a narrowband fully-analog $N$-antenna transmitter that emulates the functionality of a narrowband fully-digital $N$-antenna transmitter. Specifically, in symbol interval $m$, the proposed fully-analog transmitter synthesizes an arbitrary complex excitation vector $\bm x[m]\in\mathbb{C}^N$ with prescribed total power $\|\bm x[m]\|_2^2=P$ from a single coherent RF tone, using only tunable phase-control elements embedded in a passive interferometric programmable network. The programmable network is excited through one input port while the remaining $N - 1$ input ports are impedance matched. In the ideal lossless case, the network transfer is unitary and therefore redistributes RF power among antenna ports without dissipative amplitude control.
  The synthesis task is posed as a unitary state-preparation problem: program a unitary family so that $\bm V(\bm\varphi)\bm e_1=\bm c$, where $\bm c=\bm x/\sqrt{P}$ and $\|\bm c\|_2=1$. We provide a constructive realization and a closed-form programming rule: a binary magnitude-splitting tree allocates the desired per-antenna magnitudes $|c_n|$ using $N -1$ tunable split ratios, and a per-antenna output phase bank assigns the target phases using $N$ tunable phase shifts. The resulting architecture uses $2N-1$ real tunable degrees of freedom and admits a deterministic $O(N)$ programming procedure with no iterative optimization, enabling symbol-by-symbol updates when the chosen phase-control technology supports the required tuning speed.
  Using representative COTS components, we model the RF-front-end DC power of the proposed fully-analog transmitter and compare it against an equivalent COTS fully-digital array. For $N\le 16$, the comparison indicates significant RF-front-end power savings for the fully-analog architecture.
  The results in this paper are intended as a proof-of-concept for a narrowband fully-analog transmitter.

</details>


### [19] [Digital-Twin Empowered Deep Reinforcement Learning For Site-Specific Radio Resource Management in NextG Wireless Aerial Corridor](https://arxiv.org/abs/2602.03801)
*Pulok Tarafder,Zoheb Hassan,Imtiaz Ahmed,Danda B. Rawat,Kamrul Hasan,Cong Pu*

Main category: eess.SP

TL;DR: 提出基于数字孪生的两阶段优化框架，结合物理波束增益建模与深度强化学习，解决无人机空中走廊的基站关联和波束选择问题，实现高性能、低延迟的资源管理。


<details>
  <summary>Details</summary>
Motivation: 多无人机空中走廊的基站关联和波束选择面临高维动作空间、信道状态信息获取开销大、信道快速变化和严格延迟要求等挑战。传统组合优化方法计算量大，而基于学习的方法需要大量特定场景数据集，难以实时应用。

Method: 采用数字孪生驱动的两阶段框架：第一阶段使用高精度射线追踪构建信道孪生，结合地理空间和网络信息，通过双退火算法预计算最优波束方向；第二阶段训练多头部近端策略优化智能体，在数字孪生生成的信道数据集上学习，直接映射复杂信道和波束状态到联合决策。

Result: 提出的PPO智能体在密集无人机场景中，相比DQN提升44%-121%，相比传统启发式优化提升249%-807%，同时将推理延迟降低数个数量级。

Conclusion: 数字孪生驱动的训练管道能够为特定场景部署提供高性能、低延迟的无线资源管理策略，适合下一代空中走廊网络的实时资源管理。

Abstract: Joint base station (BS) association and beam selection in multi-UAV aerial corridors constitutes a challenging radio resource management (RRM) problem. It is driven by high-dimensional action spaces, need for substantial overhead to acquire global channel state information (CSI), rapidly varying propagation channels, and stringent latency requirements. Conventional combinatorial optimization methods, while near-optimal, are computationally prohibitive for real-time operation in such dynamic environments. While learning-based approaches can mitigate computational complexity and CSI overhead, the need for extensive site-specific (SS) datasets for model training remains a key challenge. To address these challenges, we develop a Digital Twin (DT)-enabled two-stage optimization framework that couples physics-based beam gain modeling with DRL for scalable online decision-making. In the first stage, a channel twin (CT) is constructed using a high-fidelity ray-tracing solver with geo-spatial contexts, and network information to capture SS propagation characteristics, and dual annealing algorithm is employed to precompute optimal transmission beam directions. In the second stage, a Multi-Head Proximal Policy Optimization (MH-PPO) agent, equipped with a scalable multi-head actor-critic architecture, is trained on the DT-generated channel dataset to directly map complex channel and beam states to jointly execute UAV-BS-beam association decisions. The proposed PPO agent achieves a 44%-121% improvement over DQN and 249%-807% gain over traditional heuristic based optimization schemes in a dense UAV scenario, while reducing inference latency by several orders of magnitude. These results demonstrate that DT-driven training pipelines can deliver high-performance, low-latency RRM policies tailored to SS deployments suitable for real-time resource management in next-generation aerial corridor networks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [20] [Precoding-Oriented CSI Feedback Design with Mutual Information Regularized VQ-VAE](https://arxiv.org/abs/2602.02508)
*Xi Chen,Homa Esfahanizadeh,Foad Sohrabi*

Main category: cs.IT

TL;DR: 提出基于向量量化变分自编码器的预编码导向CSI反馈框架，通过信息论正则化优化有限反馈下的码本利用，实现固定长度反馈下接近可变长度神经压缩的性能。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统中，用户设备的CSI压缩对信道重建和预编码设计至关重要。核心挑战是在CSI反馈开销和下行链路速率之间取得平衡，即最大化有限反馈的效用以维持高系统性能。

Method: 提出预编码导向的CSI反馈框架，基于向量量化变分自编码器，并引入信息论正则化。使用可微分的互信息下界估计器作为训练正则化器，在固定反馈预算下促进学习码本的有效利用。

Result: 数值结果表明，该方法在固定长度反馈下实现了与可变长度神经压缩方案相当的速率。学习到的码字表现出更均匀的使用分布，并捕获了与底层信道状态信息强相关的可解释结构。

Conclusion: 提出的预编码导向CSI反馈框架通过信息论正则化有效优化了有限反馈资源的利用，在固定长度反馈约束下实现了高性能，同时学习到的码本具有更好的可解释性。

Abstract: Efficient channel state information (CSI) compression at the user equipment plays a key role in enabling accurate channel reconstruction and precoder design in massive multiple-input multiple-output systems. A key challenge lies in balancing the CSI feedback overhead with the achievable downlink rate, i.e., maximizing the utility of limited feedback to maintain high system performance. In this work, we propose a precoding-oriented CSI feedback framework based on a vector quantized variational autoencoder, augmented with an information-theoretic regularization. To achieve this, we introduce a differentiable mutual information lower-bound estimator as a training regularizer to promote effective utilization of the learned codebook under a fixed feedback budget. Numerical results demonstrate that the proposed method achieves rates comparable to variable-length neural compression schemes, while operating with fixed-length feedback. Furthermore, the learned codewords exhibit significantly more uniform usage and capture interpretable structures that are strongly correlated with the underlying channel state information.

</details>


### [21] [Rate-Distortion Analysis of Optically Passive Vision Compression](https://arxiv.org/abs/2602.02768)
*Ronald Ogden,David Fridovich-Keil,Takashi Tanaka*

Main category: cs.IT

TL;DR: 提出一种基于事件相机的光学被动视觉压缩方案，通过光学生成余弦变换实现高速、免计算的视频压缩，在码率-失真性能上优于独立事件相机。


<details>
  <summary>Details</summary>
Motivation: 自主决策中远程视觉传感器需要在资源受限的实时信道传输高容量视觉数据，而机器人控制系统可能快速失稳，需要更高采样频率，这加剧了传输挑战。

Method: 提出光学被动视觉压缩方案，让事件相机观测视觉场景的光学生成余弦变换，受现代视频编解码器启发，实现高速、免计算的视频压缩。

Result: 模拟显示光学被动视觉压缩方案的码率-失真性能优于独立事件相机，且随着事件相机空间分辨率的提高，这种性能差距会进一步增大。

Conclusion: 光学被动视觉压缩方案为资源受限的实时视觉传输提供了一种有前景的解决方案，特别是在需要高采样频率的机器人控制应用中。

Abstract: The use of remote vision sensors for autonomous decision-making poses the challenge of transmitting high-volume visual data over resource-constrained channels in real-time. In robotics and control applications, many systems can quickly destabilize, which can exacerbate the issue by necessitating higher sampling frequencies. This work proposes a novel sensing paradigm in which an event camera observes the optically generated cosine transform of a visual scene, enabling high-speed, computation-free video compression inspired by modern video codecs. In this study, we simulate this optically passive vision compression (OPVC) scheme and compare its rate-distortion performance to that of a standalone event camera (SAEC). We find that the rate-distortion performance of the OPVC scheme surpasses that of the SAEC and that this performance gap increases as the spatial resolution of the event camera increases.

</details>


### [22] [Straggler-Aware Coded Polynomial Aggregation](https://arxiv.org/abs/2602.03074)
*Xi Zhong,Jörg Kliewer,Mingyue Ji*

Main category: cs.IT

TL;DR: 将编码多项式聚合(CPA)扩展到具有预定义非掉队者模式的分布式计算系统，建立了精确恢复的必要和充分条件，并识别了保证精确恢复的交集大小阈值。


<details>
  <summary>Details</summary>
Motivation: 现有的CPA方案仅限于理想化的无掉队者系统，无法在实际分布式计算中处理掉队者问题。需要将CPA扩展到能够容忍掉队者的实际分布式计算环境。

Method: 将CPA扩展到具有预定义非掉队者模式的分布式计算系统，建立精确恢复的可行性条件，识别交集大小阈值，并提供可行的CPA方案构造方法。

Result: 证明了在掉队者感知的CPA中，精确恢复所需的worker响应数量少于基于个体解码的多项式编码，可行性由非掉队者模式的交集结构决定，并识别了保证精确恢复的交集大小阈值。

Conclusion: 成功将CPA扩展到掉队者感知的分布式计算系统，建立了精确恢复的理论框架，提供了实用的CPA方案构造方法，并通过仿真验证了理论预测的可行性转变。

Abstract: Coded polynomial aggregation (CPA) in distributed computing systems enables the master to directly recover a weighted aggregation of polynomial computations without individually decoding each term, thereby reducing the number of required worker responses. However, existing CPA schemes are restricted to an idealized setting in which the system cannot tolerate stragglers. In this paper, we extend CPA to straggler-aware distributed computing systems with a pre-specified non-straggler pattern, where exact recovery is required for a given collection of admissible non-straggler sets. Our main results show that exact recovery of the desired aggregation is achievable with fewer worker responses than that required by polynomial codes based on individual decoding, and that feasibility is characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA. We identify an intersection-size threshold that is sufficient to guarantee exact recovery. When the number of admissible non-straggler sets is sufficiently large, we further show that this threshold is necessary in a generic sense. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations verify our theoretical results by demonstrating a sharp feasibility transition at the predicted intersection threshold.

</details>


### [23] [Entropy Functions on Two-Dimensional Faces of Polymatroid Region with One Extreme Ray Containing Rank-One Matroid](https://arxiv.org/abs/2602.03363)
*Kaizhe He,Qi Chen*

Main category: cs.IT

TL;DR: 本文研究了n度多拟阵区域2维面上的熵函数特征，特别关注包含秩1拟阵的极射线，并将另一极射线包含拟阵的2维面分为四类


<details>
  <summary>Details</summary>
Motivation: 熵函数的特征化在信息论中具有基础重要性。通过在多拟阵区域（香农外边界）上施加约束，可以得到该区域的面以及具有特殊结构的熵函数。本文旨在研究2维面上的熵函数特征

Method: 通过约束多拟阵区域来获得其面结构，特别关注包含秩1拟阵的极射线，并对另一极射线包含拟阵的2维面进行分类

Result: 将包含秩1拟阵的极射线和另一极射线包含拟阵的2维面分为四种类型，完成了对这类2维面的完整分类

Conclusion: 成功分类了n度多拟阵区域中具有特定结构的2维面，为理解熵函数在多拟阵区域面上的分布提供了重要进展

Abstract: Characterization of entropy functions is of fundamental importance in information theory. By imposing constraints on their Shannon outer bound, i.e., the polymatroidal region, one obtains the faces of the region and entropy functions on them with special structures. In this paper, we characterize entropy functions on 2-dimensional faces of polymatroid region of degree n with one extreme ray containing rank-1 matroid. We classify all such 2-dimensional faces with another extreme ray containing a matroid into four types.

</details>


### [24] [Universal Costas Matrices: Towards a General Framework for Costas Array Construction](https://arxiv.org/abs/2602.03407)
*Fatih Gulec,Vahid Abolghasemi*

Main category: cs.IT

TL;DR: 提出统一框架分析Costas阵列，引入UCM和UCFM概念，开发基于重构的搜索方法，显著加速搜索过程


<details>
  <summary>Details</summary>
Motivation: Costas阵列具有理想自相关和低互相关特性，在雷达、无线通信和集成感知通信中很有价值，但现有发现方法效率有限，需要更系统化的分析框架

Method: 提出统一框架，引入通用Costas矩阵(UCM)和通用Costas频率矩阵(UCFM)，研究其结构特性，开发基于重构的搜索方法从UCFM生成UCM

Result: 数值结果表明，所提方法显著加速搜索过程，增强对Costas阵列生成的结构理解，为未来AI辅助发现奠定基础

Conclusion: 该统一框架为Costas阵列分析提供了新视角，基于重构的搜索方法提高了效率，为人工智能辅助的Costas阵列发现开辟了道路

Abstract: Costas arrays are a special type of permutation matrices with ideal autocorrelation and low cross-correlation properties, making them valuable for radar, wireless communication, and integrated sensing and communication applications. This paper presents a novel unified framework for analyzing and discovering new Costas arrays. We introduce Universal Costas Matrices (UCMs) and Universal Costas Frequency Matrices (UCFMs) and investigate their structural characteristics. A framework integrating UCMs and UCFMs is proposed to pave the way for future artificial intelligence-assisted Costas array discovery. Leveraging the structural properties of UCMs and UCFMs, a reconstruction-based search method is developed to generate UCMs from UCFMs. Numerical results demonstrate that the proposed approach significantly accelerates the search process and enhances structural insight into Costas array generation.

</details>


### [25] [On (Im)possibility of Network Oblivious Transfer via Noisy Channels and Non-Signaling Correlations](https://arxiv.org/abs/2602.03421)
*Hadi Aghaee,Christian Deppe,Holger Boche*

Main category: cs.IT

TL;DR: 研究在诚实但好奇的各方之间，通过噪声多址信道和广播信道实现网络不经意传输的基本限制，当各方可以访问一般三方无信号相关时。主要结果表明完美不经意传输是不可能的，即使在渐近情况下也无法实现可忽略的泄漏。


<details>
  <summary>Details</summary>
Motivation: 探索在网络环境中实现安全通信的基本限制，特别是在各方可以访问三方无信号相关资源的情况下。研究在噪声信道和无信号相关组合下，不经意传输协议的可行性边界。

Method: 将共享资源建模为任意三方无信号盒子，为信道行为和产生的相关性提供统一视角。分析在渐近情况下重复使用资源对接收方区分非预期消息能力的影响。

Result: 完美不经意传输是不可能的。在渐近情况下，即使可忽略的泄漏也无法实现，因为资源的重复使用会放大接收方区分非预期消息的能力。然而，接收方自身的隐私不受普遍不可能性限制。

Conclusion: 在噪声信道和一般三方无信号相关下，实现完美网络不经意传输存在基本限制，即使在渐近情况下也无法避免泄漏。但接收方隐私的保护相对更容易实现。

Abstract: This work investigates the fundamental limits of implementing network oblivious transfer via noisy multiple access channels and broadcast channels between honest-but-curious parties when the parties have access to general tripartite non-signaling correlations. By modeling the shared resource as an arbitrary tripartite non-signaling box, we obtain a unified perspective on both the channel behavior and the resulting correlations. Our main result demonstrates that perfect oblivious transfer is impossible. In the asymptotic regime, we further show that even negligible leakage cannot be achieved, as repeated use of the resource amplifies the receiver(s)'s ability to distinguish messages that were not intended for him/them. In contrast, the receiver(s)'s own privacy is not subject to a universal impossibility limitation.

</details>


### [26] [Generative Decompression: Optimal Lossy Decoding Against Distribution Mismatch](https://arxiv.org/abs/2602.03505)
*Saeed R. Khosravirad,Ahmed Alkhateeb,Ingrid van de Voorde*

Main category: cs.IT

TL;DR: 论文研究压缩编码中分布不匹配时的最优解码策略，提出生成式解压缩方法，在解码端进行贝叶斯修正，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决标准化通信系统中编码器设计分布与实际分布不匹配的问题，当解码器获得编码器未知的边信息或先验时，需要优化解码策略。

Method: 提出生成式解压缩方法，在解码端基于真实分布进行条件期望估计，替代传统的质心规则；扩展到噪声信道传输和任务导向解码。

Result: 生成式解压缩显著缩小了与理想联合优化基准的性能差距，在高斯源和深度学习语义分类实验中表现优异。

Conclusion: 解码端生成式贝叶斯修正策略在不修改编码器的情况下实现自适应高保真重建，优于传统分离架构。

Abstract: This paper addresses optimal decoding strategies in lossy compression where the assumed distribution for compressor design mismatches the actual (true) distribution of the source. This problem has immediate relevance in standardized communication systems where the decoder acquires side information or priors about the true distribution that are unavailable to the fixed encoder. We formally define the mismatched quantization problem, demonstrating that the optimal reconstruction rule, termed generative decompression, aligns with classical Bayesian estimation by taking the conditional expectation under the true distribution given the quantization indices and adapting it to fixed-encoder constraints. This strategy effectively performs a generative Bayesian correction on the decoder side, strictly outperforming the conventional centroid rule. We extend this framework to transmission over noisy channels, deriving a robust soft-decoding rule that quantifies the inefficiency of standard modular source--channel separation architectures under mismatch. Furthermore, we generalize the approach to task-oriented decoding, showing that the optimal strategy shifts from conditional mean estimation to maximum a posteriori (MAP) detection. Experimental results on Gaussian sources and deep-learning-based semantic classification demonstrate that generative decompression closes a vast majority of the performance gap to the ideal joint-optimization benchmark, enabling adaptive, high-fidelity reconstruction without modifying the encoder.

</details>


### [27] [Secure Decentralized Pliable Index Coding for Target Data Size](https://arxiv.org/abs/2602.03579)
*Anjali Padmanabhan,Danya Arun Bindhu,Nujoom Sageer Karat,Shanuja Sasi*

Main category: cs.IT

TL;DR: 研究去中心化可塑索引编码（DPIC）在异构边信息情况下的安全传输方案，确保每个客户端最终恰好获得T个消息，同时分析通信成本。


<details>
  <summary>Details</summary>
Motivation: 现有DPIC研究大多假设同构设置（相同的边信息基数和单消息需求），但现实分布式系统中客户端通常拥有不同数量的先验信息，这限制了实际应用。需要研究异构边信息基数下的DPIC问题。

Method: 提出一种传输方案，协调客户端广播以最大化编码效率，同时确保每个客户端达到共同目标水平T。施加严格的安全约束：任何客户端获取的消息数量不超过目标T，保证每个客户端最终恰好获得T个消息。

Result: 分析了所提方案在这种安全约束下的通信成本。

Conclusion: 该研究解决了DPIC在异构边信息环境下的实际问题，提出了既能保证编码效率又能满足严格安全约束的传输方案，为分布式系统中信息交换的安全性和效率提供了新方法。

Abstract: Decentralized Pliable Index Coding (DPIC) problem addresses efficient information exchange in distributed systems where clients communicate among themselves without a central server. An important consideration in DPIC is the heterogeneity of side-information and demand sizes. Although many prior works assume homogeneous settings with identical side-information cardinality and single message demands, these assumptions limit real-world applicability where clients typically possess unequal amounts of prior information. In this paper, we study DPIC problem under heterogeneous side-information cardinalities. We propose a transmission scheme that coordinates client broadcasts to maximize coding efficiency while ensuring that each client achieves a common target level $T$. In addition, we impose a strict security constraint that no client acquires more than the target $T$ number of messages, guaranteeing that each client ends up with exactly $T$ messages. We analyze the communication cost incurred by the proposed scheme under this security constraint.

</details>


### [28] [Sleep or Transmit: Dual-Mode Energy-Efficient Design for NOMA-Enabled Backscatter Networks](https://arxiv.org/abs/2602.03607)
*Hajar El Hassani,Mikael Gidlund*

Main category: cs.IT

TL;DR: 该论文提出了一种结合非正交多址接入(NOMA)的上行链路反向散射通信设计，通过优化时间、功率和反射系数来最大化系统能量效率，适用于大规模物联网部署。


<details>
  <summary>Details</summary>
Motivation: 物联网设备快速增长需要频谱效率和能量效率兼备的通信系统。传统反向散射通信在密集部署中频谱效率下降，需要新的解决方案来提升能量效率。

Method: 在双静态网络中，多个反向散射节点通过射频能量收集在睡眠和活动模式间切换。采用Dinkelbach-based交替优化算法，对耦合的时间、功率和反射变量进行优化，获得闭式更新解。

Result: 分析揭示了两种操作模式（取决于功率可用性、电路需求和传播条件）。仿真显示该设计能自适应时间分配，相比固定功率基准提升8%能量效率，相比无睡眠基准提升68%，相比正交多址接入提升127%。

Conclusion: NOMA使能的反向散射通信是大规模物联网部署的可扩展、高能量效率解决方案，通过优化资源分配显著提升系统性能。

Abstract: The rapid growth of Internet-of-Things (IoT) devices demands communication systems that are both spectrally efficient and energy frugal. Backscatter communication (BackCom) is an attractive low-power paradigm, but its spectral efficiency declines in dense deployments. This paper presents an uplink BackCom design that integrates non-orthogonal multiple access (NOMA) and maximizes system energy efficiency (EE). In a bistatic network where multiple backscatter nodes (BNs) harvest RF energy and alternate between sleep and active modes, we formulate a fractional program with coupled time, power, and reflection variables and develop a Dinkelbach-based alternating optimization (AO) algorithm with closed-form updates. Analysis reveals two operating modes depending on power availability, circuit demands and propagation conditions. Simulations show the proposed design adapts the time allocation, achieving up to 8% higher EE than fixed-power and 68% than no-sleep baselines, and delivering up to 127% EE gains over orthogonal multiple access (OMA). These results establish NOMA-enabled BackCom as a scalable, energy efficient solution for large-scale IoT deployments.

</details>
