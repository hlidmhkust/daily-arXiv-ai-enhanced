{"id": "2509.22898", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.22898", "abs": "https://arxiv.org/abs/2509.22898", "authors": ["Priyanka Choudhary", "Maheshanand Bhaintwal"], "title": "The Service Rate Region of Hamming Codes", "comment": null, "summary": "The service rate region of a coded distributed storage system is the set of\nall achievable data access requests under the capacity constraints. This paper\ninvestigates the service rate regions of systematic Hamming codes using\nhypergraph theory and derives bounds for the maximal achievable service rate of\nindividual data objects. We establish upper bounds on the sum of service rates\nof data symbols indexed by a subset of systematic nodes in a systematic binary\nHamming code, and explore the achievability of these bounds. Additionally, for\nnon-systematic binary Hamming codes, we conclude that the aggregate service\nrate is limited by the number of columns of odd weight in the associated\ngenerator matrix."}
{"id": "2509.22912", "categories": ["cs.IT", "cs.FL", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.22912", "abs": "https://arxiv.org/abs/2509.22912", "authors": ["Xiang Huang", "Xiaoyuan Li", "Jack H. Lutz", "Neil Lutz"], "title": "Multihead Finite-State Dimension", "comment": null, "summary": "We introduce multihead finite-state dimension, a generalization of\nfinite-state dimension in which a group of finite-state agents (the heads) with\noblivious, one-way movement rules, each reporting only one symbol at a time,\nenable their leader to bet on subsequent symbols in an infinite data stream. In\naggregate, such a scheme constitutes an $h$-head finite state gambler whose\nmaximum achievable growth rate of capital in this task, quantified using\nbetting strategies called gales, determines the multihead finite-state\ndimension of the sequence. The 1-head case is equivalent to finite-state\ndimension as defined by Dai, Lathrop, Lutz and Mayordomo (2004). In our main\ntheorem, we prove a strict hierarchy as the number of heads increases, giving\nan explicit sequence family that separates, for each positive integer $h$, the\nearning power of $h$-head finite-state gamblers from that of $(h+1)$-head\nfinite-state gamblers. We prove that multihead finite-state dimension is stable\nunder finite unions but that the corresponding quantity for any fixed number\n$h>1$ of heads--the $h$-head finite-state predimension--lacks this stability\nproperty."}
{"id": "2509.23090", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23090", "abs": "https://arxiv.org/abs/2509.23090", "authors": ["Wenqin Zhang", "Han Mao Kiah", "Son Hoang Dau"], "title": "Zigzag Codes Revisited: From Optimal Rebuilding to Small Skip Cost and Small Fields", "comment": null, "summary": "We revisit zigzag array codes, a family of MDS codes known for achieving\noptimal access and optimal rebuilding ratio in single-node repair. In this\nwork, we endow zigzag codes with two new properties: small field size and low\nskip cost. First, we prove that when the row-indexing group is $\\mathcal{G} =\n\\mathbb{Z}_2^m$ and the field has characteristic two, explicit coefficients\nover any field with $|\\mathcal{F}|\\ge N$ guarantee the MDS property, thereby\ndecoupling the dependence among $p$, $k$, and $M$. Second, we introduce an\nordering-and-subgroup framework that yields repair-by-transfer schemes with\nbounded skip cost and low repair-fragmentation ratio (RFR), while preserving\noptimal access and optimal rebuilding ratio. Our explicit constructions include\nfamilies with zero skip cost whose rates approach $2/3$, and families with\nbounded skip cost whose rates approach $3/4$ and $4/5$. These rates are\ncomparable to those of MDS array codes widely deployed in practice. Together,\nthese results demonstrate that zigzag codes can be made both more flexible in\ntheory and more practical for modern distributed storage systems."}
{"id": "2509.23274", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23274", "abs": "https://arxiv.org/abs/2509.23274", "authors": ["Yirun Wang", "Yongqing Wang", "Yuyao Shen", "Gongpu Wang", "Chintha Tellambura"], "title": "RIS- and Multi-Snapshot-Enabled SISO 3D Position and Velocity Estimation With Single Base Station", "comment": "15 pages, 7 figures", "summary": "Reconfigurable intelligent surface (RIS) panels can act as cost-effective\nanchors for radio localization, complementing conventional base station (BS)\nanchors. This paper investigates joint three-dimensional position and velocity\nestimation (3D-JPVE) in single-input single-output (SISO) systems with only one\nBS available. We first theoretically show that 3D-JPVE is infeasible when\nrelying solely on a single RIS or on multiple snapshots alone. To address this,\nwe propose combining RIS deployment with multi-snapshot utilization to enable\nrealizable 3D-JPVE. A two-stage method is developed for multi-snapshot channel\nparameter estimation, comprising a tensor-based coarse estimation step followed\nby a maximum likelihood refinement step. In particular, we introduce a\nthird-order tensor formulation to decompose the challenging 3D joint\nangle-of-departure and Doppler shift estimation (3D-JADE) into two tractable\nsubproblems, which are jointly solved via a low-complexity alternating\noptimization approach. Building on the channel parameter estimates, we further\ndesign a two-stage low-complexity method for optimal 3D-JPVE: coarse estimation\nis obtained from differential measurements through linear equations, and the\npreliminary results are refined iteratively using the original measurements.\nMoreover, we derive the closed-form Cramer-Rao lower bound (CRLB) and show that\nthe proposed 3D-JPVE method approaches CRLB-level accuracy. Simulation results\nconfirm the statistical efficiency of the proposed estimators and demonstrate\nsubstantial 3D-JPVE performance gains when deploying active RIS compared to\npassive RIS."}
{"id": "2509.22795", "categories": ["eess.SP", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.22795", "abs": "https://arxiv.org/abs/2509.22795", "authors": ["Yi Hu", "Zheyuan Cheng"], "title": "Generative Modeling and Decision Fusion for Unknown Event Detection and Classification Using Synchrophasor Data", "comment": "10 pages", "summary": "Reliable detection and classification of power system events are critical for\nmaintaining grid stability and situational awareness. Existing approaches often\ndepend on limited labeled datasets, which restricts their ability to generalize\nto rare or unseen disturbances. This paper proposes a novel framework that\nintegrates generative modeling, sliding-window temporal processing, and\ndecision fusion to achieve robust event detection and classification using\nsynchrophasor data. A variational autoencoder-generative adversarial network is\nemployed to model normal operating conditions, where both reconstruction error\nand discriminator error are extracted as anomaly indicators. Two complementary\ndecision strategies are developed: a threshold-based rule for computational\nefficiency and a convex hull-based method for robustness under complex error\ndistributions. These features are organized into spatiotemporal detection and\nclassification matrices through a sliding-window mechanism, and an\nidentification and decision fusion stage integrates the outputs across PMUs.\nThis design enables the framework to identify known events while systematically\nclassifying previously unseen disturbances into a new category, addressing a\nkey limitation of supervised classifiers. Experimental results demonstrate\nstate-of-the-art accuracy, surpassing machine learning, deep learning, and\nenvelope-based baselines. The ability to recognize unknown events further\nhighlights the adaptability and practical value of the proposed approach for\nwide-area event analysis in modern power systems."}
{"id": "2509.22685", "categories": ["eess.IV", "cs.CV", "cs.GR", "I.3.7; I.4.1; I.4.5; I.6.3"], "pdf": "https://arxiv.org/pdf/2509.22685", "abs": "https://arxiv.org/abs/2509.22685", "authors": ["Adam Haroon", "Anush Lakshman", "Badrinath Balasubramaniam", "Beiwen Li"], "title": "VIRTUS-FPP: Virtual Sensor Modeling for Fringe Projection Profilometry in NVIDIA Isaac Sim", "comment": "16 pages, 13 figures, in preparation for IEEE Transactions on\n  Instrumentation and Measurement", "summary": "Fringe projection profilometry (FPP) has been established as a high-accuracy\n3D reconstruction method capable of achieving sub-pixel accuracy. However, this\ntechnique faces significant constraints due to complex calibration\nrequirements, bulky system footprint, and sensitivity to environmental\nconditions. To address these limitations, we present VIRTUS-FPP, the first\ncomprehensive physics-based virtual sensor modeling framework for FPP built in\nNVIDIA Isaac Sim. By leveraging the physics-based rendering and programmable\nsensing capabilities of simulation, our framework enables end-to-end modeling\nfrom calibration to reconstruction with full mathematical fidelity to the\nunderlying principles of structured light. We conduct comprehensive virtual\ncalibration and validate our system's reconstruction accuracy through\nquantitative comparison against ground truth geometry. Additionally, we\ndemonstrate the ability to model the virtual system as a digital twin by\nreplicating a physical FPP system in simulation and validating correspondence\nbetween virtual and real-world measurements. Experimental results demonstrate\nthat VIRTUS-FPP accurately models optical phenomena critical to FPP and\nachieves results comparable to real-world systems while offering unprecedented\nflexibility for system configuration, sensor prototyping, and environmental\ncontrol. This framework significantly accelerates the development of real-world\nFPP systems by enabling rapid virtual prototyping before physical\nimplementation."}
{"id": "2509.23284", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23284", "abs": "https://arxiv.org/abs/2509.23284", "authors": ["Xiaomin Cao", "Mohammadali Mohammadi", "Hien Quoc Ngo", "Hyundong Shin", "Michail Matthaiou"], "title": "RIS-Assisted XL-MIMO for Near-Field and Far-Field Communications", "comment": "The manuscript has been accepted for publication in IEEE TWC", "summary": "We consider a reconfigurable intelligent surface (RIS)-assisted extremely\nlarge-scale multiple-input multiple-output (XL-MIMO) downlink system, where an\nXL-MIMO array serves two groups of single-antennas users, namely near-field\nusers (NFUEs) and far-field users (FFUEs). FFUEs are subject to blockage, and\ntheir communication is facilitated through the RIS. We consider three precoding\nschemes at the XL-MIMO array, namely central zero-forcing (CZF), local\nzero-forcing (LZF) and maximum ratio transmission (MRT). Closed-form\nexpressions for the spectral efficiency (SE) of all users are derived for MRT\nprecoding, while statistical-form expressions are obtained for CZF and LZF\nprocessing. A heuristic visibility region (VR) selection algorithm is also\nintroduced to help reduce the computational complexity of the precoding scheme.\nFurthermore, we devise a two-stage phase shifts design and power control\nalgorithm to maximize the sum of weighted minimum SE of two groups of users\nwith CZF, LZF and MRT precoding schemes. The simulation results indicate that,\nwhen equal priority is given to NFUEs and FFUEs, the proposed design improves\nthe sum of the weighted minimum SE by 31.9\\%, 37.8\\%, and 119.2\\% with CZF,\nLZF, and MRT, respectively, compared to the case with equal power allocation\nand random phase shifts design. CZF achieves the best performance, while LZF\noffers comparable results with lower complexity. When prioritizing NFUEs or\nFFUEs, LZF achieves strong performance for the prioritized group, whereas CZF\nensures balanced performance between NFUEs and FFUEs."}
{"id": "2509.22810", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22810", "abs": "https://arxiv.org/abs/2509.22810", "authors": ["Jianheng Zhou", "Chenyu Liu", "Jinan Zhou", "Yi Ding", "Yang Liu", "Haoran Luo", "Ziyu Jia", "Xinliang Zhou"], "title": "Introducing Multimodal Paradigm for Learning Sleep Staging PSG via General-Purpose Model", "comment": null, "summary": "Sleep staging is essential for diagnosing sleep disorders and assessing\nneurological health. Existing automatic methods typically extract features from\ncomplex polysomnography (PSG) signals and train domain-specific models, which\noften lack intuitiveness and require large, specialized datasets. To overcome\nthese limitations, we introduce a new paradigm for sleep staging that leverages\nlarge multimodal general-purpose models to emulate clinical diagnostic\npractices. Specifically, we convert raw one-dimensional PSG time-series into\nintuitive two-dimensional waveform images and then fine-tune a multimodal large\nmodel to learn from these representations. Experiments on three public datasets\n(ISRUC, MASS, SHHS) demonstrate that our approach enables general-purpose\nmodels, without prior exposure to sleep data, to acquire robust staging\ncapabilities. Moreover, explanation analysis reveals our model learned to mimic\nthe visual diagnostic workflow of human experts for sleep staging by PSG\nimages. The proposed method consistently outperforms state-of-the-art baselines\nin accuracy and robustness, highlighting its efficiency and practical value for\nmedical applications. The code for the signal-to-image pipeline and the PSG\nimage dataset will be released."}
{"id": "2509.22696", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22696", "abs": "https://arxiv.org/abs/2509.22696", "authors": ["MohammadReza Abbaszadeh Bavil Soflaei", "Karim SamadZamini"], "title": "Explainable Deep Learning for Cataract Detection in Retinal Images: A Dual-Eye and Knowledge Distillation Approach", "comment": "13 Pages, 8 figures, Submitted as part of PhD research", "summary": "Cataract remains a leading cause of visual impairment worldwide, and early\ndetection from retinal imaging is critical for timely intervention. We present\na deep learning pipeline for cataract classification using the Ocular Disease\nRecognition dataset, containing left and right fundus photographs from 5000\npatients. We evaluated CNNs, transformers, lightweight architectures, and\nknowledge-distilled models. The top-performing model, Swin-Base Transformer,\nachieved 98.58% accuracy and an F1-score of 0.9836. A distilled MobileNetV3,\ntrained with Swin-Base knowledge, reached 98.42% accuracy and a 0.9787 F1-score\nwith greatly reduced computational cost. The proposed dual-eye Siamese variant\nof the distilled MobileNet, integrating information from both eyes, achieved an\naccuracy of 98.21%. Explainability analysis using Grad-CAM demonstrated that\nthe CNNs concentrated on medically significant features, such as lens opacity\nand central blur. These results show that accurate, interpretable cataract\ndetection is achievable even with lightweight models, supporting potential\nclinical integration in resource-limited settings"}
{"id": "2509.23360", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23360", "abs": "https://arxiv.org/abs/2509.23360", "authors": ["Yifan Feng", "Nail Akar", "Zhengchuan Chen", "Mehul Motani"], "title": "Absorbing Markov Chain-Based Analysis of Age of Information in Discrete-Time Dual-Queue Systems", "comment": null, "summary": "Status update systems require the timely collection of sensing information\nfor which deploying multiple sensors/servers to obtain diversity gains is\nconsidered as a promising solution. In this work, we construct an absorbing\nMarkov chain (AMC) to exactly model Age of Information (AoI) in a discretetime\ndual-queue (DTDQ) status update system with generate at will (GAW) status\nupdates, discrete phase-type (DPH-type) distributed service times and\ntransmission freezing. Specifically, transmission is frozen for a certain\nnumber of slots following the initiation of a transmission, after which one of\nthe two servers is allowed to simultaneously sample the monitored physical\nprocess and transmit a status update packet, according to the availabilities\nand priorities of the two servers. Based on the discrete-time AMC, we provide\nthe exact distributions of both AoI and peak AoI (PAoI), enabling the\nderivation of arbitrary order moments. In addition, we analytically study the\nrole of freezing using several typical service time distributions, including\ngeometric, uniform, and triangular distributions. The introduction of freezing\nfor DTDQ systems is demonstrated to be significantly beneficial in reducing the\nmean AoI for various service time distributions. Additionally, we study the\nimpact of the statistical parameters of the service times and heterogeneity\nbetween the two servers on the freezing gain, i.e., reduction in mean AoI\nattained with optimum freezing policies."}
{"id": "2509.22869", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22869", "abs": "https://arxiv.org/abs/2509.22869", "authors": ["Abdulkadir Bilge", "Erdem Ergen", "Burak Soner", "Sinem Coleri"], "title": "Scalable Wi-Fi RSS-Based Indoor Localization via Automatic Vision-Assisted Calibration", "comment": "Presented at the ICAT 2025 conference, Sarajevo, September 2025. See\n  https://icat.etf.unsa.ba/2025/", "summary": "Wi-Fi-based positioning promises a scalable and privacy-preserving solution\nfor location-based services in indoor environments such as malls, airports, and\ncampuses. RSS-based methods are widely deployable as RSS data is available on\nall Wi-Fi-capable devices, but RSS is highly sensitive to multipath, channel\nvariations, and receiver characteristics. While supervised learning methods\noffer improved robustness, they require large amounts of labeled data, which is\noften costly to obtain. We introduce a lightweight framework that solves this\nby automating high-resolution synchronized RSS-location data collection using a\nshort, camera-assisted calibration phase. An overhead camera is calibrated only\nonce with ArUco markers and then tracks a device collecting RSS data from\nbroadcast packets of nearby access points across Wi-Fi channels. The resulting\n(x, y, RSS) dataset is used to automatically train mobile-deployable\nlocalization algorithms, avoiding the privacy concerns of continuous video\nmonitoring. We quantify the accuracy limits of such vision-assisted RSS data\ncollection under key factors such as tracking precision and label\nsynchronization. Using the collected experimental data, we benchmark\ntraditional and supervised learning approaches under varying signal conditions\nand device types, demonstrating improved accuracy and generalization,\nvalidating the utility of the proposed framework for practical use. All code,\ntools, and datasets are released as open source."}
{"id": "2509.22712", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22712", "abs": "https://arxiv.org/abs/2509.22712", "authors": ["Zihan Wei", "Tapabrata Chakraborti"], "title": "Achieving Fair Skin Lesion Detection through Skin Tone Normalization and Channel Pruning", "comment": "29pages, 12 figures", "summary": "Recent works have shown that deep learning based skin lesion image\nclassification models trained on unbalanced dataset can exhibit bias toward\nprotected demographic attributes such as race, age,and gender. Current bias\nmitigation methods usually either achieve high level of fairness with the\ndegradation of accuracy, or only improve the model fairness on a single\nattribute. Additionally usually most bias mitigation strategies are either pre\nhoc through data processing or post hoc through fairness evaluation, instead of\nbeing integrated into the model learning itself. To solve these existing\ndrawbacks, we propose a new Individual Typology Angle (ITA) Loss-based skin\ntone normalization and data augmentation method that directly feeds into an\nadaptable meta learning-based joint channel pruning framework. In skin tone\nnormalization, ITA is used to estimate skin tone type and adjust automatically\nto target tones for dataset balancing. In the joint channel pruning framework,\ntwo nested optimization loops are used to find critical channels.The inner\noptimization loop finds and prunes the local critical channels by weighted soft\nnearest neighbor loss, and the outer optimization loop updates the weight of\neach attribute using group wise variance loss on meta-set. Experiments\nconducted in the ISIC2019 dataset validate the effectiveness of our method in\nsimultaneously improving the fairness of the model on multiple sensitive\nattributes without significant degradation of accuracy. Finally, although the\npruning mechanism adds some computational cost during training phase, usually\ntraining is done off line. More importantly,"}
{"id": "2509.23407", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23407", "abs": "https://arxiv.org/abs/2509.23407", "authors": ["Erkin Yapici", "Yusuf Islam Tek", "Ertugrul Basar"], "title": "Noise-Domain Non-Orthogonal Multiple Access for Three Users", "comment": "11 pages, 6 figures, submitted for publication", "summary": "In this study, we propose a novel three-user noise-domain non-orthogonal\nmultiple access (ND-NOMA) scheme by introducing the correlation as a new\ndimension besides mean and variance quantities used in two-user ND-NOMA. The\nnew three-user ND-NOMA scheme includes both uplink and downlink scenarios, with\ndetectors designed to decode the information embedded in mean, variance, and\ncorrelation. Our theoretical analysis and simulation results under Rician\nfading channels show that the proposed system is capable of achieving promising\nbit error rate (BER) performance while preserving the low power and low\ncomplexity advantages of ND-NOMA. This new ND-NOMA design enables simultaneous\ncommunication among three users using different dimensions, paving the way for\nscalable multi-user communication in noise-domain systems and in the\nInternet-of-things (IoT) environments."}
{"id": "2509.22891", "categories": ["eess.SP", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2509.22891", "abs": "https://arxiv.org/abs/2509.22891", "authors": ["Ashwini Kulkarni", "Santosh Nannuru"], "title": "Time-Frequency Analysis of Non-Uniformly Sampled Signals via Sample Density Adaptation", "comment": null, "summary": "The analysis of non-stationary signals in non-uniformly sampled data is a\nchallenging task. Time-integrated methods, such as the generalised Lomb-Scargle\n(GLS) periodogram, provide a robust statistical assessment of persistent\nperiodicities but are insensitive to transient events. Conversely, existing\ntime-frequency methods often rely on fixed-duration windows or interpolation,\nwhich can be suboptimal for non-uniform data. We introduce the non-uniform\nStockwell-transform (NUST), a time-frequency framework that applies a localized\ndensity adaptive spectral analysis directly to non-uniformly sampled data. NUST\nemploys a doubly adaptive window that adjusts its width based on both frequency\nand local data density, providing detailed time-frequency information for both\ntransient and persistent signals. We validate the NUST on numerous\nnon-uniformly sampled synthetic signals, demonstrating its superior\ntime-localization performance compared to GLS. Furthermore, we apply NUST to\nHARPS radial velocity data of the multi-planetary system HD 10180, successfully\ndistinguishing coherent planetary signals from stellar activity."}
{"id": "2509.22736", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.22736", "abs": "https://arxiv.org/abs/2509.22736", "authors": ["Merve Gülle", "Junno Yun", "Yaşar Utku Alçalar", "Mehmet Akçakaya"], "title": "Consistency Models as Plug-and-Play Priors for Inverse Problems", "comment": null, "summary": "Diffusion models have found extensive use in solving numerous inverse\nproblems. Such diffusion inverse problem solvers aim to sample from the\nposterior distribution of data given the measurements, using a combination of\nthe unconditional score function and an approximation of the posterior related\nto the forward process. Recently, consistency models (CMs) have been proposed\nto directly predict the final output from any point on the diffusion ODE\ntrajectory, enabling high-quality sampling in just a few NFEs. CMs have also\nbeen utilized for inverse problems, but existing CM-based solvers either\nrequire additional task-specific training or utilize data fidelity operations\nwith slow convergence, not amenable to large-scale problems. In this work, we\nreinterpret CMs as proximal operators of a prior, enabling their integration\ninto plug-and-play (PnP) frameworks. We propose a solver based on PnP-ADMM,\nwhich enables us to leverage the fast convergence of conjugate gradient method.\nWe further accelerate this with noise injection and momentum, dubbed PnP-CM,\nand show it maintains the convergence properties of the baseline PnP-ADMM. We\nevaluate our approach on a variety of inverse problems, including inpainting,\nsuper-resolution, Gaussian deblurring, and magnetic resonance imaging (MRI)\nreconstruction. To the best of our knowledge, this is the first CM trained for\nMRI datasets. Our results show that PnP-CM achieves high-quality\nreconstructions in as few as 4 NFEs, and can produce meaningful results in 2\nsteps, highlighting its effectiveness in real-world inverse problems while\noutperforming comparable CM-based approaches."}
{"id": "2509.23447", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23447", "abs": "https://arxiv.org/abs/2509.23447", "authors": ["K. K. Krishnan Namboodiri", "Elizabath Peter", "Derya Malak", "Petros Elia"], "title": "Fundamental Limits of Distributed Computing for Linearly Separable Functions", "comment": "49 pages", "summary": "This work addresses the problem of distributed computation of linearly\nseparable functions, where a master node with access to $K$ datasets, employs\n$N$ servers to compute $L$ user-requested functions, each defined over the\ndatasets. Servers are instructed to compute subfunctions of the datasets and\nmust communicate computed outputs to the user, who reconstructs the requested\noutputs. The central challenge is to reduce the per-server computational load\nand the communication cost from servers to the user, while ensuring recovery\nfor any possible set of $L$ demanded functions.\n  We here establish the fundamental communication-computation tradeoffs for\narbitrary $K$ and $L$, through novel task-assignment and communication\nstrategies that, under the linear-encoding and no-subpacketization assumptions,\nare proven to be either exactly optimal or within a factor of three from the\noptimum. In contrast to prior approaches that relied on fixed assignments of\ntasks -- either disjoint or cyclic assignments -- our key innovation is a\nnullspace-based design that jointly governs task assignment and server\ntransmissions, ensuring exact decodability for all demands, and attaining\noptimality over all assignment and delivery methods. To prove this optimality,\nwe here uncover a duality between nullspaces and sparse matrix factorizations,\nenabling us to recast the distributed computing problem as an equivalent\nfactorization task and derive a sharp information-theoretic converse bound.\nBuilding on this, we establish an additional converse that, for the first time,\nlinks the communication cost to the covering number from the theory of general\ncovering designs."}
{"id": "2509.23065", "categories": ["eess.SP", "math.CV"], "pdf": "https://arxiv.org/pdf/2509.23065", "abs": "https://arxiv.org/abs/2509.23065", "authors": ["Mohammad Amin Saeidi", "Hina Tabassum"], "title": "Resource Allocation in Cooperative Mid-band/THz Networks in the Presence of Mobility", "comment": "This paper has been accepted for publication in IEEE journals", "summary": "This paper develops a comprehensive framework to investigate and optimize the\ndownlink performance of cooperative multi-band networks (MBNs) operating on\nupper mid-band (UMB) and terahertz (THz) frequencies, where base stations (BSs)\nin each band cooperatively serve users. The framework captures sophisticated\nfeatures such as near-field channel modeling, fully and partially connected\nantenna architectures, and users' mobility. First, we consider joint user\nassociation and hybrid beamforming optimization to maximize the system\nsum-rate, subject to power constraints, maximum cluster size of cooperating\nBSs, and users' quality-of-service (QoS) constraints. By leveraging fractional\nprogramming FP and majorization-minimization techniques, an iterative algorithm\nis proposed to solve the non-convex optimization problem. We then consider\nhandover (HO)-aware resource allocation for moving users in a cooperative\nUMB/THz MBN. Two HO-aware resource allocation methods are proposed. The first\nmethod focuses on maximizing the HO-aware system sum-rate subject to HO-aware\nQoS constraints. Using Jensen's inequality and properties of logarithmic\nfunctions, the non-convex optimization problem is tightly approximated with a\nconvex one and solved. The second method addresses a multi-objective\noptimization problem to maximize the system sum-rate, while minimizing the\ntotal number of HOs. Numerical results demonstrate the efficacy of the proposed\nalgorithms, cooperative UMB/THz MBN over stand-alone THz networks, as well as\nthe critical importance of accurate near-field modeling in extremely large\nantenna arrays. Moreover, the proposed HO-aware resource allocation methods\neffectively mitigate the impact of HOs, enhancing performance in the considered\nsystem."}
{"id": "2509.23165", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.23165", "abs": "https://arxiv.org/abs/2509.23165", "authors": ["Guillaume Houry", "Tom Boeken", "Stéphanie Allassonnière", "Jean Feydy"], "title": "Untangling Vascular Trees for Surgery and Interventional Radiology", "comment": null, "summary": "The diffusion of minimally invasive, endovascular interventions motivates the\ndevelopment of visualization methods for complex vascular networks. We propose\na planar representation of blood vessel trees which preserves the properties\nthat are most relevant to catheter navigation: topology, length and curvature.\nTaking as input a three-dimensional digital angiography, our algorithm produces\na faithful two-dimensional map of the patient's vessels within a few seconds.\nTo this end, we propose optimized implementations of standard morphological\nfilters and a new recursive embedding algorithm that preserves the global\norientation of the vascular network. We showcase our method on peroperative\nimages of the brain, pelvic and knee artery networks. On the clinical side, our\nmethod simplifies the choice of devices prior to and during the intervention.\nThis lowers the risk of failure during navigation or device deployment and may\nhelp to reduce the gap between expert and common intervention centers. From a\nresearch perspective, our method simulates the cadaveric display of artery\ntrees from anatomical dissections. This opens the door to large population\nstudies on the branching patterns and tortuosity of fine human blood vessels.\nOur code is released under the permissive MIT license as part of the\nscikit-shapes Python library (https://scikit-shapes.github.io )."}
{"id": "2509.23908", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23908", "abs": "https://arxiv.org/abs/2509.23908", "authors": ["Qingyang Wang", "Zhuohui Yao", "Wenchi Cheng", "Xiao Zheng"], "title": "Post-disaster Max-Min Rate Optimization for Multi-UAV RSMA Network in Obstacle Environments", "comment": null, "summary": "This paper proposes a rate-splitting multiple access (RSMA) transmission\nscheme to maximize the minimum achievable rate among ground users for emergency\ncommunications in post-disaster scenarios with obstacles, with which the\noptimal positioning of multiple unmanned aerial vehicle (UAV)-enabled base\nstations can be achieved timely.To address the resulting non-convex and\nintractable optimization problem, we design an alternating optimization\napproach. Specifically, we relax obstacle-related constraints using penalty\nterms. In each iteration, block coordinate descent (BCD) and successive convex\napproximation (SCA) are applied alternately to obtain locally optimal\nsolutions, and penalty multipliers are updated to ensure convergence of the\nrelaxed problem to the original one. Simulation results demonstrate that the\nproposed scheme significantly outperforms benchmark methods in terms of the\nminimum achievable rate, verifying its effectiveness and superiority."}
{"id": "2509.23302", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.23302", "abs": "https://arxiv.org/abs/2509.23302", "authors": ["Wilson de Souza Junior", "Taufik Abrao", "Amine Mezghani", "Ekram Hossain"], "title": "Dual-Function Beam Pattern Design for Multi-Target ISAC Systems: A Decoupled Approach", "comment": "13 pages; 7 figures; tables; 3 tables; manuscript submitted to IEEE\n  journal", "summary": "We investigate the beampattern design problem for mono-static multi-user (MU)\nmulti-point-target integrated sensing and communication (ISAC) systems, where a\ndual-function multiple-input multiple-output (DF-MIMO) base station (BS)\nperforms downlink communication and radar sensing simultaneously. In ISAC\nsystems, sensing and communication inherently compete for resources. As\ncommunication demand increases, the beam pattern is reshaped, which might\ndegrade the direction of arrival (DoA) sensing accuracy, measured in terms of\nmean-squared error (MSE) and lower-bounded by the Cramer-Rao lower bound\n(CRLB). Since conventional joint formulations of the sensing-based problem\noften overlook this trade-off, our work addresses it by decomposing the\nsensing-based problem into two subproblems (SPs). This decomposition enables a\nmore effective exploitation of the beam pattern's physical properties, which we\nrefer to as the Sensing-Guided Communication Dual-Function (SGCDF) beam pattern\ndesign. We further develop a low-complexity extension using the Riemannian\nManifold Optimization (RMO) and convex closed-set projection. Simulation\nresults confirm that the proposed method improves multi-target estimation\naccuracy, compared to traditional joint optimization strategies, by preserving\nthe beam pattern, while the low-complexity version offers an excellent\nperformance-complexity tradeoff, maintaining high accuracy with significantly\nreduced computational cost."}
{"id": "2509.23200", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.23200", "abs": "https://arxiv.org/abs/2509.23200", "authors": ["Linwei Zhu", "Junhao Zhu", "Xu Zhang", "Huan Zhang", "Ye Li", "Runmin Cong", "Sam Kwong"], "title": "Enhanced Quality Aware-Scalable Underwater Image Compression", "comment": "19 pages, 14 figures; submitted to ACM Transactions on Multimedia\n  Computing, Communications, and Applications", "summary": "Underwater imaging plays a pivotal role in marine exploration and ecological\nmonitoring. However, it faces significant challenges of limited transmission\nbandwidth and severe distortion in the aquatic environment. In this work, to\nachieve the target of both underwater image compression and enhancement\nsimultaneously, an enhanced quality-aware scalable underwater image compression\nframework is presented, which comprises a Base Layer (BL) and an Enhancement\nLayer (EL). In the BL, the underwater image is represented by controllable\nnumber of non-zero sparse coefficients for coding bits saving. Furthermore, the\nunderwater image enhancement dictionary is derived with shared sparse\ncoefficients to make reconstruction close to the enhanced version. In the EL, a\ndual-branch filter comprising rough filtering and detail refinement branches is\ndesigned to produce a pseudo-enhanced version for residual redundancy removal\nand to improve the quality of final reconstruction. Extensive experimental\nresults demonstrate that the proposed scheme outperforms the state-of-the-art\nworks under five large-scale underwater image datasets in terms of Underwater\nImage Quality Measure (UIQM)."}
{"id": "2509.24161", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24161", "abs": "https://arxiv.org/abs/2509.24161", "authors": ["Hengfeng Liu", "Chunming Tang", "Cuiling Fan"], "title": "Capacity-Achieving Codes for Noisy Insertion Channels", "comment": null, "summary": "DNA storage has emerged as a promising solution for large-scale and long-term\ndata preservation. Among various error types, insertions are the most frequent\nerrors occurring in DNA sequences, where the inserted symbol is often identical\nor complementary to the original, and in practical implementations, noise can\nfurther cause the inserted symbol to mutate into a random one, which creates\nsignificant challenges to reliable data recovery. In this paper, we investigate\na new noisy insertion channel, where infinitely many insertions of symbols\ncomplement or identical to the original ones and up to one insertion of random\nsymbol may occur. We determine the coding capacity of the noisy channel and\nconstruct asymptotically optimal error-correcting codes achieving the coding\ncapacity."}
{"id": "2509.23444", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23444", "abs": "https://arxiv.org/abs/2509.23444", "authors": ["Lorenzo Italiano", "Alireza Pourafzal", "Hui Chen", "Mattia Brambilla", "Gonzalo Seco-Granados", "Monica Nicoli", "Henk Wymeersch"], "title": "HoloTrace: a Location Privacy Preservation Solution for mmWave MIMO-OFDM Systems", "comment": "submitted to IEEE Journal on Selected Areas in Communications", "summary": "The technological innovation towards 6G cellular networks introduces\nunprecedented capabilities for user equipment (UE) localization, but it also\nraises serious concerns about physical layer location privacy. This paper\nintroduces HoloTrace, a signal-level privacy preservation framework that relies\non user-side spoofing of localization-relevant features to prevent the\nextraction of precise location information from the signals received by a base\nstation (BS) in a mmWave MIMO-OFDM system. Spoofing is performed by the user on\nlocation parameters such as angle of arrival (AoA), angle of departure (AoD),\nand time difference of arrival (TDoA). Without requiring any protocol\nmodification nor network-side support, our method strategically perturbs pilot\ntransmissions to prevent a BS from performing non-consensual UE localization.\nThe methodology allows the UE to spoof its position, keeping the precoder\nunchanged. We formulate spoofing as a unified rank-constrained projection\nproblem, and provide closed-form solutions under varying levels of channel\nstate information (CSI) at the UE, including scenarios with and without CSI\nknowledge. Simulation results confirm that the proposed approach enables the UE\nto deceive the BS, inducing significant localization errors, while the impact\non link capacity varies depending on the spoofed position. Our findings\nestablish HoloTrace as a practical and robust privacy-preserving solution for\nfuture 6G networks."}
{"id": "2509.23341", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.23341", "abs": "https://arxiv.org/abs/2509.23341", "authors": ["Tiago de S. Fernandes", "Ricardo L. de Queiroz"], "title": "On the Impact of LiDAR Point Cloud Compression on Remote Semantic Segmentation", "comment": "5 pages, 8 figures", "summary": "Autonomous vehicles rely on LiDAR sensors to generate 3D point clouds for\naccurate segmentation and object detection. In a context of a smart city\nframework, we would like to understand the effect that transmission\n(compression) can have on remote (cloud) segmentation, instead of local\nprocessing. In this short paper, we try to understand the impact of point cloud\ncompression on semantic segmentation performance and to estimate the necessary\nbandwidth requirements. We developed a new (suitable) distortion metric to\nevaluate such an impact. Two of MPEG's compression algorithms (GPCC and L3C2)\nand two leading semantic segmentation algorithms (2DPASS and PVKD) were tested\nover the Semantic KITTI dataset. Results indicate that high segmentation\nquality requires communication throughput of approximately 0.6 MB/s for G-PCC\nand 2.8 MB/s for L3C2. These results are important in order to plan\ninfrastructure resources for autonomous navigation."}
{"id": "2509.24333", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24333", "abs": "https://arxiv.org/abs/2509.24333", "authors": ["Zhentian Zhang", "Kai-Kit Wong", "David Morales-Jimenez", "Hao Jiang", "Pablo Ramírez-Espinosa", "Chan-Byoung Chae", "Christos Masouros"], "title": "Finite-blocklength Fluid Antenna Systems With Spatial Block-Correlation Channel Model", "comment": null, "summary": "Massive connectivity with ultra-low latency and high reliability necessitates\nfundamental advances in future communication networks operating under\nfinite-blocklength (FBL) transmission. Fluid antenna systems (FAS) have emerged\nas a promising enabler, offering superior spectrum and energy efficiency in\nshort-packet/FBL scenarios. In this work, by leveraging the simplicity and\naccuracy of block-correlation channel modeling, we rigorously bound the\nperformance limits of FBL-FAS from a statistical perspective, focusing on two\nkey performance metrics: block error rate (BLER) and outage probability (OP).\nFurthermore, we introduce a novel complex-integral simplification method based\non Gauss-Laguerre quadrature, which achieves higher approximation accuracy\ncompared to existing Taylor-expansion-based approaches. Numerical results\nvalidate the robustness of the proposed analysis and clearly demonstrate the\nsuperiority of FBL-FAS over conventional multiple-antenna systems with fixed\nantenna placement."}
{"id": "2509.23520", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23520", "abs": "https://arxiv.org/abs/2509.23520", "authors": ["Kalpesh Jaykar", "Prasanth Velvaluri", "Nian X. Sun", "Richard D. James"], "title": "Theoretical framework of passive ME antenna arrays enabling in-vivo monitoring: A pathway to smart implants", "comment": null, "summary": "A new brain-computer interface (BCI) technology, deployed through minimally\ninvasive surgery, is changing the way we think about treating severe\nneurological conditions. The central idea is to place a device called Stentrode\nin the brain's vasculature, which enables neuromodulation and helps patients\nregain the ability to communicate. However, in such devices, the battery and\nelectronics are wired and could introduce damage or implant malfunction. In\nthese cases, a Stentrode integrated with magnetoelectric (ME) antennas could be\nof great interest. ME antennas offer significant advantages over traditional\nantennas, leveraging acoustic resonance rather than electromagnetic resonance\nto achieve a size reduction of up to five orders of magnitude. In addition to\ntheir compactness and immunity to ground-plane interference, ME antennas could\nbe adopted for use in vascular implants, such as coronary stents, potentially\nenabling minimally invasive monitoring and communication. Despite these\nadvantages, a single antenna embedded in the implant may be constrained by the\nlimited volume of magnetostrictive material, which could result in low output\ngain. To address this gain limitation, we propose using antenna arrays designed\nto produce constructive interference at a designated far-field point, ideally\nlocated outside the patient, to enhance signal transmission and receiving\ncapabilities. We develop a mathematical model to represent the antennas and\noptimize their spatial arrangement and phase synchronization. Simulations based\non this model demonstrate promising high-gain performance at the prescribed\nfar-field location through phase manipulation."}
{"id": "2509.23442", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23442", "abs": "https://arxiv.org/abs/2509.23442", "authors": ["Md. Saiful Bari Siddiqui", "Mohammed Imamul Hassan Bhuiyan"], "title": "S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network", "comment": "Submitted to IEEE Journal of Biomedical and Health Informatics\n  (JBHI). This preprint includes few additional details not present in the\n  journal submission", "summary": "Convolutional Neural Networks have become a cornerstone of medical image\nanalysis due to their proficiency in learning hierarchical spatial features.\nHowever, this focus on a single domain is inefficient at capturing global,\nholistic patterns and fails to explicitly model an image's frequency-domain\ncharacteristics. To address these challenges, we propose the Spatial-Spectral\nSummarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns\nfrom both spatial and spectral representations simultaneously. The S$^3$F-Net\nperforms a fusion of a deep spatial CNN with our proposed shallow spectral\nencoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,\nwhich leverages the Convolution Theorem by applying a bank of learnable filters\ndirectly to an image's full Fourier spectrum via a computation-efficient\nelement-wise multiplication. This allows the SpectralFilter layer to attain a\nglobal receptive field instantaneously, with its output being distilled by a\nlightweight summarizer network. We evaluate S$^3$F-Net across four medical\nimaging datasets spanning different modalities to validate its efficacy and\ngeneralizability. Our framework consistently and significantly outperforms its\nstrong spatial-only baseline in all cases, with accuracy improvements of up to\n5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive\naccuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs\nbetter on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%\naccuracy, surpassing many top-performing, much deeper models. Our\nexplainability analysis also reveals that the S$^3$F-Net learns to dynamically\nadjust its reliance on each branch based on the input pathology. These results\nverify that our dual-domain approach is a powerful and generalizable paradigm\nfor medical image analysis."}
{"id": "2509.24373", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24373", "abs": "https://arxiv.org/abs/2509.24373", "authors": ["Matteo Zecchin", "Unnikrishnan Kunnath Ganesan", "Giuseppe Durisi", "Petar Popovski", "Osvaldo Simeone"], "title": "Prediction-Powered Communication with Distortion Guarantees", "comment": null, "summary": "The development of 6G wireless systems is taking place alongside the\ndevelopment of increasingly intelligent wireless devices and network nodes. The\nchanging technological landscape is motivating a rethinking of classical\nShannon information theory that emphasizes semantic and task-oriented\nparadigms. In this paper, we study a prediction-powered communication setting,\nin which devices, equipped with artificial intelligence (AI)-based predictors,\ncommunicate under zero-delay constraints with strict distortion guarantees. Two\nclasses of distortion measures are considered: (i) outage-based metrics,\nsuitable for tasks tolerating occasional packet losses, such as real-time\ncontrol or monitoring; and (ii) bounded distortion metrics, relevant to\nsemantic-rich tasks like text or video transmission. We propose two zero-delay\ncompression algorithms leveraging online conformal prediction to provide\nper-sequence guarantees on the distortion of reconstructed sequences over\nerror-free and packet-erasure channels with feedback. For erasure channels, we\nintroduce a doubly-adaptive conformal update to compensate for channel-induced\nerrors and derive sufficient conditions on erasure statistics to ensure\ndistortion constraints. Experiments on semantic text compression validate the\napproach, showing significant bit rate reductions while strictly meeting\ndistortion guarantees compared to state-of-the-art prediction-powered\ncompression methods."}
{"id": "2509.23644", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23644", "abs": "https://arxiv.org/abs/2509.23644", "authors": ["Omkar Nitsure", "Sampath Kumar Dondapati", "Satish Mulleti"], "title": "Learnable Kernels for FRI -- Joint Kernel Encoder Optimization and Hardware Validation", "comment": "10 pages", "summary": "Finite Rate of Innovation (FRI) sampling techniques provide efficient\nframeworks for reconstructing signals with inherent sparsity at rates below\nNyquist. However, traditional FRI reconstruction methods rely heavily on\npre-defined kernels, often limiting hardware implementation and reconstruction\naccuracy under noisy conditions. In this paper, we propose a robust, flexible,\nand practically implementable framework for FRI reconstruction by introducing\nnovel learnable kernel strategies. First, we demonstrate effective\nreconstruction using known, fixed kernels such as truncated Gaussian and\nGaussian pair kernels, which mitigate the requirement that the samples should\nhave a sum-of-exponentials (SoE) form. Next, we extend this concept by jointly\noptimizing both the sampling kernel and reconstruction encoder through a\nunified learning approach, yielding adaptive kernels that significantly\noutperform traditional methods in resolution and noise robustness, with reduced\nsampling rates. Furthermore, we propose a practical hardware realization by\nrepresenting kernels as sums of two exponential decay signals with jointly\noptimized poles, facilitating compact, efficient analog implementations. Our\napproach is validated experimentally through hardware implementations using a\nunity-gain Sallen-Key analog filter, achieving accurate real-world signal\nrecovery. The developed convolutional neural network-based encoder\nsubstantially reduces computational complexity, demonstrating competitive\nperformance with fewer parameters, making our method particularly suitable for\nresource-constrained, edge-based deployments."}
{"id": "2509.23590", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23590", "abs": "https://arxiv.org/abs/2509.23590", "authors": ["Fangyu Liu", "Peiwen Jiang", "Wenjin Wang", "Chao-Kai Wen", "Shi Jin", "Jun Zhang"], "title": "Foundation Model-Based Adaptive Semantic Image Transmission for Dynamic Wireless Environments", "comment": null, "summary": "Foundation model-based semantic transmission has recently shown great\npotential in wireless image communication. However, existing methods exhibit\ntwo major limitations: (i) they overlook the varying importance of semantic\ncomponents for specific downstream tasks, and (ii) they insufficiently exploit\nwireless domain knowledge, resulting in limited robustness under dynamic\nchannel conditions. To overcome these challenges, this paper proposes a\nfoundation model-based adaptive semantic image transmission system for dynamic\nwireless environments, such as autonomous driving. The proposed system\ndecomposes each image into a semantic segmentation map and a compressed\nrepresentation, enabling task-aware prioritization of critical objects and\nfine-grained textures. A task-adaptive precoding mechanism then allocates radio\nresources according to the semantic importance of extracted features. To ensure\naccurate channel information for precoding, a channel estimation knowledge map\n(CEKM) is constructed using a conditional diffusion model that integrates user\nposition, velocity, and sparse channel samples to train scenario-specific\nlightweight estimators. At the receiver, a conditional diffusion model\nreconstructs high-quality images from the received semantic features, ensuring\nrobustness against channel impairments and partial data loss. Simulation\nresults on the BDD100K dataset with multi-scenario channels generated by\nQuaDRiGa demonstrate that the proposed method outperforms existing approaches\nin terms of perceptual quality (SSIM, LPIPS, FID), task-specific accuracy\n(IoU), and transmission efficiency. These results highlight the effectiveness\nof integrating task-aware semantic decomposition, scenario-adaptive channel\nestimation, and diffusion-based reconstruction for robust semantic transmission\nin dynamic wireless environments."}
{"id": "2509.24433", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24433", "abs": "https://arxiv.org/abs/2509.24433", "authors": ["Xin Wei", "Weidong Mei", "Xuan Huang", "Zhi Chen", "Boyu Ning"], "title": "Energy-Efficient Movable Antennas: Mechanical Power Modeling and Performance Optimization", "comment": null, "summary": "Movable antennas (MAs) offer additional spatial degrees of freedom (DoFs) to\nenhance communication performance through local antenna movement. However, to\nachieve accurate and fast antenna movement, MA drivers entail non-negligible\nmechanical power consumption, rendering energy efficiency (EE) optimization\nmore critical compared to conventional fixed-position antenna (FPA) systems. To\naddress this issue, we develop a fundamental power consumption model for\nstepper motor-driven multi-MA systems based on electric motor theory. Based on\nthis model, we formulate an EE maximization problem from a multi-MA base\nstation (BS) to multiple single-FPA users. We aim to jointly optimize the MAs'\npositions, moving speeds, and the BS's transmit precoding matrix subject to\ncollision-avoidance constraints during the multi-MA movements. However, this\nproblem is difficult to solve. To tackle this challenge, we first reveal that\nthe collision-avoidance constraints can always be relaxed without loss of\noptimality by properly renumbering the MA indices. For the resulting relaxed\nproblem, we first consider a simplified single-user setup and uncover a hidden\nmonotonicity of the EE performance with respect to the MAs' moving speeds. To\nsolve the remaining optimization problem, we develop a two-layer optimization\nframework. In the inner layer, the Dinkelbach algorithm is employed to derive\nthe optimal beamforming solution for any given MA positions. In the outer\nlayer, a sequential update algorithm is proposed to iteratively refine the MA\npositions based on the optimal values obtained from the inner layer. Next, we\nproceed to the general multi-user case and propose an alternating optimization\n(AO) algorithm. Numerical results demonstrate that despite the additional\nmechanical power consumption, the proposed algorithms can outperform both\nconventional FPA systems and other existing EE maximization benchmarks"}
{"id": "2509.23687", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.23687", "abs": "https://arxiv.org/abs/2509.23687", "authors": ["Runze Dong", "Buhong Wang", "Cunqian Feng", "Jiang Weng", "Chen Han", "Jiwei Tian"], "title": "Joint Hybrid Beamforming and Artificial Noise Design for Secure Multi-UAV ISAC Networks", "comment": null, "summary": "Integrated sensing and communication (ISAC) emerges as a key enabler for\nnext-generation applications such as smart cities and autonomous systems. Its\nintegration with unmanned aerial vehicles (UAVs) unlocks new potentials for\nreliable communication and precise sensing in dynamic aerial environments.\nHowever, existing research predominantly treats UAVs as aerial base stations,\noverlooking their role as ISAC users, and fails to leverage large-scale antenna\narrays at terrestrial base stations to enhance security and spectral\nefficiency. This paper propose a secure and spectral efficient ISAC framework\nfor multi-UAV networks, and a two-stage optimization approach is developed to\njointly design hybrid beamforming (HBF), artificial noise (AN) injection, and\nUAV trajectories. Aiming at maximizing the sum secrecy rate, the first stage\nemploys Proximal Policy Optimization (PPO) to optimize digital beamformers and\ntrajectories, and the second stage decomposes the digital solution into analog\nand digital components via low-complexity matrix factorization. Simulation\nresults demonstrate the effectiveness of the proposed framework compared to\nbenchmark schemes."}
{"id": "2509.23930", "categories": ["eess.IV", "cs.CV", "92C55"], "pdf": "https://arxiv.org/pdf/2509.23930", "abs": "https://arxiv.org/abs/2509.23930", "authors": ["Eric Walser", "Peter McCaffrey", "Kal Clark", "Nicholas Czarnek"], "title": "A University of Texas Medical Branch Case Study on Aortic Calcification Detection", "comment": "9 pages, 2 figures", "summary": "This case study details The University of Texas Medical Branch (UTMB)'s\npartnership with Zauron Labs, Inc. to enhance detection and coding of aortic\ncalcifications (ACs) using chest radiographs. ACs are often underreported\ndespite their significant prognostic value for cardiovascular disease, and UTMB\npartnered with Zauron to apply its advanced AI tools, including a\nhigh-performing image model (AUC = 0.938) and a fine-tuned language model based\non Meta's Llama 3.2, to retrospectively analyze imaging and report data. The\neffort identified 495 patients out of 3,988 unique patients assessed (5,000\ntotal exams) whose reports contained indications of aortic calcifications that\nwere not properly coded for reimbursement (12.4% miscode rate) as well as an\nadditional 84 patients who had aortic calcifications that were missed during\ninitial review (2.1% misdiagnosis rate). Identification of these patients\nprovided UTMB with the potential to impact clinical care for these patients and\npursue $314k in missed annual revenue. These findings informed UTMB's decision\nto adopt Zauron's Guardian Pro software system-wide to ensure accurate,\nAI-enhanced peer review and coding, improving both patient care and financial\nsolvency. This study is covered under University of Texas Health San Antonio's\nInstitutional Review Board Study ID 00001887."}
{"id": "2509.24558", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24558", "abs": "https://arxiv.org/abs/2509.24558", "authors": ["Yun-Bin Zhao", "Zhong-Feng Sun"], "title": "Splitting Alternating Algorithms for Sparse Solutions of Linear Systems with Concatenated Orthogonal Matrices", "comment": null, "summary": "A class of splitting alternating algorithms is proposed for finding the\nsparse solution of linear systems with concatenated orthogonal matrices.\nDepending on the number of matrices concatenated, the proposed algorithms are\nclassified into the two-block splitting alternating algorithm (TSAA) and the\nmulti-block splitting alternating algorithm (MSAA). These algorithms aim to\ndecompose a large-scale linear system into two or more coupled subsystems, each\nsignificantly smaller than the original system, and then combine the solutions\nof these subsystems to produce the sparse solution of the original system. The\nproposed algorithms only involve matrix-vector products and reduced orthogonal\nprojections. It turns out that the proposed algorithms are globally convergent\nto the sparse solution of a linear system if the matrix (along with the\nsparsity level of the solution) satisfies a coherence-type condition. Numerical\nexperiments indicate that the proposed algorithms are very promising and can\nquickly and accurately locate the sparse solution of a linear system with\nsignificantly fewer iterations than several mainstream iterative methods."}
{"id": "2509.23792", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23792", "abs": "https://arxiv.org/abs/2509.23792", "authors": ["Kabuto Arai", "Takumi Yoshida", "Takumi Takahashi", "Koji Ishibashi"], "title": "Expectation Propagation-Based Signal Detection for Highly Correlated MIMO Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Large-scale multiple-input-multiple-output (MIMO) systems typically operate\nin dense array deployments with limited scattering environments, leading to\nhighly correlated and ill-conditioned channel matrices that severely degrade\nthe performance of message-passing-based detectors. To tackle this issue, this\npaper proposes an expectation propagation (EP)-based detector, termed\noverlapping block partitioning EP (OvEP). In OvEP, the large-scale measurement\nvector is partitioned into partially overlapping blocks. For each block and its\noverlapping part, a low-complexity linear minimum mean square error\n(LMMSE)-based filter is designed according to the partitioned structure. The\nresulting LMMSE outputs are then combined to generate the input to the\ndenoiser. In this combining process, subtracting the overlapping-part outputs\nfrom the block outputs effectively mitigates the adverse effects of inter-block\ncorrelation induced by high spatial correlation. The proposed algorithm is\nconsistently derived within the EP framework, and its fixed point is\ntheoretically proven to coincide with the stationary point of a relaxed\nKullback- Leibler (KL) minimization problem. The mechanisms underlying the\ntheoretically predicted performance improvement are further clarified through\nnumerical simulations. The proposed algorithm achieves performance close to\nconventional LMMSE-EP with lower computational complexity."}
{"id": "2509.24227", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.24227", "abs": "https://arxiv.org/abs/2509.24227", "authors": ["Baltasar Ramos", "Cristian Garrido", "Paulette Narv'aez", "Santiago Gelerstein Claro", "Haotian Li", "Rafael Salvador", "Constanza V'asquez-Venegas", "Iv'an Gallegos", "Yi Zhang", "V'ictor Casta~neda", "Cristian Acevedo", "Dan Wu", "Gonzalo C'ardenas", "Camilo G. Sotomayor"], "title": "Non-Invasive Detection of PROState Cancer with Novel Time-Dependent Diffusion MRI and AI-Enhanced Quantitative Radiological Interpretation: PROS-TD-AI", "comment": "Study protocol preprint (not peer reviewed). Prepared with the MDPI\n  Journal of Imaging Word author template. Primary category: eess.IV. Code and\n  patient data are not publicly available due to privacy; requests will be\n  considered under a data-use agreement", "summary": "Prostate cancer (PCa) is the most frequently diagnosed malignancy in men and\nthe eighth leading cause of cancer death worldwide. Multiparametric MRI (mpMRI)\nhas become central to the diagnostic pathway for men at intermediate risk,\nimproving de-tection of clinically significant PCa (csPCa) while reducing\nunnecessary biopsies and over-diagnosis. However, mpMRI remains limited by\nfalse positives, false negatives, and moderate to substantial interobserver\nagreement. Time-dependent diffusion (TDD) MRI, a novel sequence that enables\ntissue microstructure characterization, has shown encouraging preclinical\nperformance in distinguishing clinically significant from insignificant PCa.\nCombining TDD-derived metrics with machine learning may provide robust,\nzone-specific risk prediction with less dependence on reader training and\nimproved accuracy compared to current standard-of-care. This study protocol\nout-lines the rationale and describes the prospective evaluation of a\nhome-developed AI-enhanced TDD-MRI software (PROSTDAI) in routine diagnostic\ncare, assessing its added value against PI-RADS v2.1 and validating results\nagainst MRI-guided prostate biopsy."}
{"id": "2509.24699", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24699", "abs": "https://arxiv.org/abs/2509.24699", "authors": ["Huanmin Ge", "Zhiqiang Xu"], "title": "On the Performance of Amplitude-Based Models for Low-Rank Matrix Recovery", "comment": null, "summary": "In this paper, we focus on low-rank phase retrieval, which aims to\nreconstruct a matrix $\\mathbf{X}_0\\in \\mathbb{R}^{n\\times m}$ with ${\\mathrm{\nrank}}(\\mathbf{X}_0)\\le r$ from noise-corrupted amplitude measurements\n$\\mathbf{y}=|\\mathcal{A}(\\mathbf{X}_0)|+\\boldsymbol{\\eta}$, where\n$\\mathcal{A}:\\mathbb{R}^{n\\times m}\\rightarrow \\mathbb{R}^{p}$ is a linear map\nand $\\boldsymbol{\\eta}\\in \\mathbb{R}^p$ is the noise vector. We first examine\nthe rank-constrained nonlinear least-squares model $\\hat{\\mathbf{X}}\\in\n\\mathop{\\mathrm{argmin}}\\limits_{\\substack{\\mathbf{X}\\in \\mathbb{R}^{n\\times\nm},\\mathrm{rank}(\\mathbf{X})\\le\nr}}\\||\\mathcal{A}(\\mathbf{X})|-\\mathbf{y}\\|_2^2$ to estimate $\\mathbf{X}_0$,\nand demonstrate that the reconstruction error satisfies\n$\\min\\{\\|\\hat{\\mathbf{X}}-\\mathbf{X}_0\\|_F,\n\\|\\hat{\\mathbf{X}}+\\mathbf{X}_0\\|_F\\}\\lesssim\n\\frac{\\|\\boldsymbol{\\eta}\\|_2}{\\sqrt{p}}$ with high probability, provided\n$\\mathcal{A}$ is a Gaussian measurement ensemble and $p\\gtrsim (m+n)r$. We also\nprove that the error bound $\\frac{\\|\\boldsymbol{\\eta}\\|_2}{\\sqrt{p}}$ is tight\nup to a constant. Furthermore, we relax the rank constraint to a nuclear-norm\nconstraint. Hence, we propose the Lasso model for low-rank phase retrieval,\ni.e., the constrained nuclear-norm model and the unconstrained version. We also\nestablish comparable theoretical guarantees for these models. To achieve this,\nwe introduce a strong restricted isometry property (SRIP) for the linear map\n$\\mathcal{A}$, analogous to the strong RIP in phase retrieval. This work\nprovides a unified treatment that extends existing results in both phase\nretrieval and low-rank matrix recovery from rank-one measurements."}
{"id": "2509.23807", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23807", "abs": "https://arxiv.org/abs/2509.23807", "authors": ["Hongyu Wang", "Wenjia Xu", "Guangzuo Li", "Siyuan Wan", "Yaohua Sun", "Jiuniu Wang", "Mugen Peng"], "title": "Online Specific Emitter Identification via Collision-Alleviated Signal Hash", "comment": "This paper has been accepted by IEEE Transactions on Vehicular\n  Technology", "summary": "Specific Emitter Identification (SEI) has been widely studied, aiming to\ndistinguish signals from different emitters given training samples from those\nemitters. However, real-world scenarios often require identifying signals from\nnovel emitters previously unseen. Since these novel emitters only have a few or\nno prior samples, existing models struggle to identify signals from novel\nemitters online and tend to bias toward the distribution of seen emitters. To\naddress these challenges, we propose the Online Specific Emitter Identification\n(OSEI) task, comprising both online \\revise{few-shot and generalized zero-shot}\nlearning tasks. It requires constructing models using signal samples from seen\nemitters and then identifying new samples from seen and novel emitters online\nduring inference. We propose a novel hash-based model, Collision-Alleviated\nSignal Hash (CASH), providing a unified approach for addressing the OSEI task.\nThe CASH operates in two steps: in the seen emitters identifying step, a signal\nencoder and a seen emitters identifier determine whether the signal sample is\nfrom seen emitters, mitigating the model from biasing toward seen emitters\ndistribution. In the signal hash coding step, an online signal hasher assigns a\nhash code to each signal sample, identifying its specific emitter. Experimental\nresults on real-world signal datasets (i.e., ADSB and ORACLE) demonstrate that\nour method accurately identifies signals from both seen and novel emitters\nonline. This model outperforms existing methods by a minimum of 6.08\\% and\n8.55\\% in accuracy for the few-shot and \\revise{generalized zero-shot learning\n}tasks, respectively. The code will be open-sourced at\n\\href{https://github.com/IntelliSensing/OSEI-CASH}{https://github.com/IntelliSensing/OSEI-CASH}."}
{"id": "2509.24247", "categories": ["eess.IV", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24247", "abs": "https://arxiv.org/abs/2509.24247", "authors": ["Kai Yuan", "Dongxu Li", "Jianhao Huang", "Han Zhang", "Chuan Huang"], "title": "Adaptive Source-Channel Coding for Multi-User Semantic and Data Communications", "comment": null, "summary": "This paper considers a multi-user semantic and data communication\n(MU-SemDaCom) system, where a base station (BS) simultaneously serves users\nwith different semantic and data tasks through a downlink multi-user\nmultiple-input single-output (MU-MISO) channel. The coexistence of\nheterogeneous communication tasks, diverse channel conditions, and the\nrequirements for digital compatibility poses significant challenges to the\nefficient design of MU-SemDaCom systems. To address these issues, we propose a\nmulti-user adaptive source-channel coding (MU-ASCC) framework that adaptively\noptimizes deep neural network (DNN)-based source coding, digital channel\ncoding, and superposition broadcasting. First, we employ a data-regression\nmethod to approximate the end-to-end (E2E) semantic and data distortions, for\nwhich no closed-form expressions exist. The obtained logistic formulas\ndecompose the E2E distortion as the addition of the source and channel\ndistortion terms, in which the logistic parameter variations are task-dependent\nand jointly determined by both the DNN and channel parameters. Then, based on\nthe derived formulas, we formulate a weighted-sum E2E distortion minimization\nproblem that jointly optimizes the source-channel coding rates, power\nallocation, and beamforming vectors for both the data and semantic users.\nFinally, an alternating optimization (AO) framework is developed, where the\nadaptive rate optimization is solved using the subgradient descent method,\nwhile the joint power and beamforming is addressed via the uplink-downlink\nduality (UDD) technique. Simulation results demonstrate that, compared with the\nconventional separate source-channel coding (SSCC) and deep joint\nsource-channel coding (DJSCC) schemes that are designed for a single task, the\nproposed MU-ASCC scheme achieves simultaneous improvements in both the data\nrecovery and semantic task performance."}
{"id": "2509.24794", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24794", "abs": "https://arxiv.org/abs/2509.24794", "authors": ["Sisi Miao", "Jonathan Mandelbaum", "Holger Jäkel", "Laurent Schmalen"], "title": "On the Error Rate of Binary BCH Codes under Error-and-erasure Decoding", "comment": null, "summary": "Determining the exact decoding error probability of linear block codes is an\ninteresting problem. For binary BCH codes, McEliece derived methods to estimate\nthe error probability of a simple bounded distance decoding (BDD) for BCH\ncodes. However, BDD falls short in many applications. In this work, we consider\nerror-and-erasure decoding and its variants that improve upon BDD. We derive\nclosed-form expressions for their error probabilities and validate them through\nsimulations. Then, we illustrate their use in assessing concatenated coding\nschemes."}
{"id": "2509.23920", "categories": ["eess.SP", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.23920", "abs": "https://arxiv.org/abs/2509.23920", "authors": ["Masahiro Kurisaki"], "title": "Asymptotic Expansion for Nonlinear Filtering in the Small System Noise Regime", "comment": "This paper is a self-contained exposition of the methodological part\n  of Section 4 in arXiv:2501.16333", "summary": "We propose a new asymptotic expansion method for nonlinear filtering, based\non a small parameter in the system noise. The conditional expectation is\nexpanded as a power series in the noise level, with each coefficient computed\nby solving a system of ordinary differential equations. This approach mitigates\nthe trade-off between computational efficiency and accuracy inherent in\nexisting methods such as Gaussian approximations and particle filters.\nMoreover, by incorporating an Edgeworth-type expansion, our method captures\ncomplex features of the conditional distribution, such as multimodality, with\nsignificantly lower computational cost than conventional filtering algorithms."}
{"id": "2509.24325", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.24325", "abs": "https://arxiv.org/abs/2509.24325", "authors": ["Jiaye Fu", "Qiankun Gao", "Chengxiang Wen", "Yanmin Wu", "Siwei Ma", "Jiaqi Zhang", "Jian Zhang"], "title": "ReCon-GS: Continuum-Preserved Guassian Streaming for Fast and Compact Reconstruction of Dynamic Scenes", "comment": null, "summary": "Online free-viewpoint video (FVV) reconstruction is challenged by slow\nper-frame optimization, inconsistent motion estimation, and unsustainable\nstorage demands. To address these challenges, we propose the Reconfigurable\nContinuum Gaussian Stream, dubbed ReCon-GS, a novel storage-aware framework\nthat enables high fidelity online dynamic scene reconstruction and real-time\nrendering. Specifically, we dynamically allocate multi-level Anchor Gaussians\nin a density-adaptive fashion to capture inter-frame geometric deformations,\nthereby decomposing scene motion into compact coarse-to-fine representations.\nThen, we design a dynamic hierarchy reconfiguration strategy that preserves\nlocalized motion expressiveness through on-demand anchor re-hierarchization,\nwhile ensuring temporal consistency through intra-hierarchical deformation\ninheritance that confines transformation priors to their respective hierarchy\nlevels. Furthermore, we introduce a storage-aware optimization mechanism that\nflexibly adjusts the density of Anchor Gaussians at different hierarchy levels,\nenabling a controllable trade-off between reconstruction fidelity and memory\nusage. Extensive experiments on three widely used datasets demonstrate that,\ncompared to state-of-the-art methods, ReCon-GS improves training efficiency by\napproximately 15% and achieves superior FVV synthesis quality with enhanced\nrobustness and stability. Moreover, at equivalent rendering quality, ReCon-GS\nslashes memory requirements by over 50% compared to leading state-of-the-art\nmethods."}
{"id": "2509.24845", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24845", "abs": "https://arxiv.org/abs/2509.24845", "authors": ["Masoud Kaveh", "Farshad Rostami Ghadi", "Francisco Hernando-Gallego", "Diego Martín", "Kai-Kit Wong", "Riku Jäntti"], "title": "Physical Layer Security over Fluid Reconfigurable Intelligent Surface-assisted Communication Systems", "comment": null, "summary": "This letter investigates the secrecy performance of wireless communication\nsystems assisted by a fluid reconfigurable intelligent surface (FRIS). Unlike\nconventional reconfigurable intelligent surfaces (RISs) with fixed geometries,\nFRISs dynamically select a subset of reflective elements based on real-time\nchannel conditions, offering enhanced spatial diversity and adaptability. Using\nthis foundation, we model a secure downlink scenario where a base station\ncommunicates with a legitimate user in the presence of an eavesdropper, and the\npropagation is assisted by a FRIS with a limited number of elements set to the\nON state. We analyze the system's secrecy performance under spatial correlation\nby deriving analytical lower and upper bounds for the secrecy outage\nprobability (SOP) and average secrecy capacity (ASC), respectively. Our results\ndemonstrate that FRIS effectively enables secure communication under spatial\ncorrelation. Even with partial activation, FRIS significantly outperforms\nconventional RISs in enhancing secrecy performance under varying deployment\ndensities and element correlations."}
{"id": "2509.24097", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24097", "abs": "https://arxiv.org/abs/2509.24097", "authors": ["Henglin Pu", "Zhu Han", "Athina P. Petropulu", "Husheng Li"], "title": "Wideband Integrated Sensing and Communications: Spectral Efficiency and Signaling Design", "comment": null, "summary": "In integrated sensing and communications (ISAC), a distinguishing feature of\n6G wireless networks, the main challenge lies in integrating the two distinct\nfunctions of sensing and communication within the same waveform. In this paper,\nthe ISAC waveform synthesis is studied in the wideband regime, since a large\nbandwidth can simplify the analysis and is justified by the employment of\nmillimeter wave or higher frequency band. Standard orthogonal frequency\ndivision multiplexing (OFDM) signaling is assumed, and the wideband analysis of\nsensing is a counterpart of the existing studies on wideband communications. It\nis proposed that the phase over such OFDM subcarriers is for modulating\ncommunication messages while the power spectral density (PSD) is shaped for the\nsensing performance. Beyond OFDM, we further reveal a duality between the\nproposed PSD-shaping rule and the orthogonal time frequency space (OTFS)\nwaveform. Flattening the OTFS delay-axis PSD produces the same integrated\nsidelobe level (ISL) reduction effect in the delay-Doppler domain as PSD\ncontrol achieves for OFDM in the frequency domain. To balance communication and\nsensing performance over frequency-selective channels, we propose a\nlow-complexity, water-filling-like allocator with an explicit PSD-flatness\n(variance) constraint. The performance of the proposed wideband ISAC scheme is\ndemonstrated using both numerical simulations and hardware experiments."}
{"id": "2509.24334", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.24334", "abs": "https://arxiv.org/abs/2509.24334", "authors": ["Wankun Chen", "Feng Gao", "Yanhai Gan", "Jingchao Cao", "Junyu Dong", "Qian Du"], "title": "Wavelet-Assisted Mamba for Satellite-Derived Sea Surface Temperature Super-Resolution", "comment": "Accepted by IEEE TGRS 2025", "summary": "Sea surface temperature (SST) is an essential indicator of global climate\nchange and one of the most intuitive factors reflecting ocean conditions.\nObtaining high-resolution SST data remains challenging due to limitations in\nphysical imaging, and super-resolution via deep neural networks is a promising\nsolution. Recently, Mamba-based approaches leveraging State Space Models (SSM)\nhave demonstrated significant potential for long-range dependency modeling with\nlinear complexity. However, their application to SST data super-resolution\nremains largely unexplored. To this end, we propose the Wavelet-assisted Mamba\nSuper-Resolution (WMSR) framework for satellite-derived SST data. The WMSR\nincludes two key components: the Low-Frequency State Space Module (LFSSM) and\nHigh-Frequency Enhancement Module (HFEM). The LFSSM uses 2D-SSM to capture\nglobal information of the input data, and the robust global modeling\ncapabilities of SSM are exploited to preserve the critical temperature\ninformation in the low-frequency component. The HFEM employs the pixel\ndifference convolution to match and correct the high-frequency feature,\nachieving accurate and clear textures. Through comprehensive experiments on\nthree SST datasets, our WMSR demonstrated superior performance over\nstate-of-the-art methods. Our codes and datasets will be made publicly\navailable at https://github.com/oucailab/WMSR."}
{"id": "2509.25067", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.25067", "abs": "https://arxiv.org/abs/2509.25067", "authors": ["Rohollah Vahdani", "S. Mohammad Razavizadeh"], "title": "Capacity Achieving Design for Hybrid Beamforming in Millimeter Wave Massive MIMO Systems", "comment": "Published in IEEE Transactions on Vehicular Technology, Volume: 74,\n  Issue: 3, March 2025", "summary": "Hybrid digital and analog beamforming is a highly effective technique for\nimplementing beamforming methods in millimeter wave (mmWave) systems. It\nprovides a viable solution to replace the complex fully digital beamforming\ntechniques. However, the current design of precoding and combining matrices in\nhybrid beamforming solely relies on the channel information, neglecting the\ncrucial consideration of the structure of covariance matrices of the transmit\nsignals. In this paper, we present a novel approach for the joint design of\nhybrid beamforming matrices at the transmitter and receiver. This approach is\ncentered around the optimization of the covariance matrix of the transmitted\nsignals. Our goal is to maximize the downlink sum rate capacity of the system\nby achieving an optimal design of the transmit covariance matrix. We tackle the\nnon-convex nature of this problem by leveraging the dual relationship between\nthe broadcast channel (BC) and the multiple access channel (MAC). Through\nextensive simulations in various scenarios, including point-to-point\nmulti-input multi-output (MIMO), multi-user (MU) multi-input single-output\n(MISO), and MU-MIMO, we demonstrate the superiority of our proposed method over\ntraditional designs. These results highlight the effectiveness and versatility\nof our approach in optimizing beamforming for mmWave systems."}
{"id": "2509.24178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24178", "abs": "https://arxiv.org/abs/2509.24178", "authors": ["Chengwei Zhou", "Steve Majerus", "Gourav Datta"], "title": "BladderFormer: A Streaming Transformer for Real-Time Urological State Monitoring", "comment": "Under review", "summary": "Bladder pressure monitoring systems are increasingly vital in diagnosing and\nmanaging urinary tract dysfunction. Existing solutions rely heavily on\nhand-crafted features and shallow classifiers, limiting their adaptability to\ncomplex signal dynamics. We propose a one-layer streaming transformer model for\nreal-time classification of bladder pressure states, operating on\nwavelet-transformed representations of raw time-series data. Our model\nincorporates temporal multi-head self-attention and state caching, enabling\nefficient online inference with high adaptability. Trained on a dataset of 91\npatients with 20,000-80,000 samples each, our method demonstrates improved\naccuracy, higher energy- and latency-efficiency. Implementation considerations\nfor edge deployment on low-power hardware, such as edge graphical processing\nunits (GPU) and micro-controllers, are also discussed."}
{"id": "2509.24497", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.24497", "abs": "https://arxiv.org/abs/2509.24497", "authors": ["Pranoti Nage", "Sanjay Shitole"], "title": "A Novel Preprocessing Unit for Effective Deep Learning based Classification and Grading of Diabetic Retinopathy", "comment": null, "summary": "Early detection of diabetic retinopathy (DR) is crucial as it allows for\ntimely intervention, preventing vision loss and enabling effective management\nof diabetic complications. This research performs detection of DR and DME at an\nearly stage through the proposed framework which includes three stages:\npreprocessing, segmentation, feature extraction, and classification. In the\npreprocessing stage, noise filtering is performed by fuzzy filtering, artefact\nremoval is performed by non-linear diffusion filtering, and the contrast\nimprovement is performed by a novel filter called Adaptive Variable Distance\nSpeckle (AVDS) filter. The AVDS filter employs four distance calculation\nmethods such as Euclidean, Bhattacharya, Manhattan, and Hamming. The filter\nadaptively chooses a distance method which produces the highest contrast value\namongst all 3 methods. From the analysis, hamming distance method was found to\nachieve better results for contrast and Euclidean distance showing less error\nvalue with high PSNR. The segmentation stage is performed using Improved\nMask-Regional Convolutional Neural Networks (Mask RCNN). In the final stage,\nfeature extraction and classification using novel Self-Spatial Attention\ninfused VGG-16 (SSA-VGG-16), which effectively captures both global contextual\nrelationships and critical spatial regions within retinal images, thereby\nimproving the accuracy and robustness of DR and DME detection and grading. The\neffectiveness of the proposed method is assessed using two distinct datasets:\nIDRiD and MESSIDOR."}
{"id": "2509.25074", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.25074", "abs": "https://arxiv.org/abs/2509.25074", "authors": ["Kirill Andreev", "Pavel Rybin", "Alexey Frolov"], "title": "Unsourced Random Access", "comment": "Published in Foundations and Trends in Communications and Information\n  Theory, 2025", "summary": "Current wireless networks are designed to optimize spectral efficiency for\nhuman users, who typically require sustained connections for high-data-rate\napplications like file transfers and video streaming. However, these networks\nare increasingly inadequate for the emerging era of machine-type communications\n(MTC). With a vast number of devices exhibiting sporadic traffic patterns\nconsisting of short packets, the grant-based multiple access procedures\nutilized by existing networks lead to significant delays and inefficiencies. To\naddress this issue the unsourced random access (URA) paradigm has been\nproposed. This paradigm assumes the devices to share a common encoder thus\nsimplifying the reception process by eliminating the identification procedure.\nThe URA paradigm not only addresses the computational challenges but it also\nconsiders the random access (RA) as a coding problem, i.e., takes into account\nboth medium access protocols and physical layer effects. In this monograph we\nprovide a comprehensive overview of the URA problem in noisy channels, with the\nmain task being to explain the major ideas rather than to list all existing\nsolutions."}
{"id": "2509.24222", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.24222", "abs": "https://arxiv.org/abs/2509.24222", "authors": ["Zhisheng Chen", "Yingwei Zhang", "Qizhen Lan", "Tianyu Liu", "Huacan Wang", "Yi Ding", "Ziyu Jia", "Ronghao Chen", "Kun Wang", "Xinliang Zhou"], "title": "Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning", "comment": null, "summary": "Foundation models pretrained on various and unlabeled data have demonstrated\nsignificant success in natural language and vision, but their application to\nelectroencephalography (EEG) remains challenged due to the signal's unique\nproperties. Existing brain foundation models that inherit architectures\ndesigned for text or images lead to three limitations in pre-training: 1)\nconflating time-domain waveform patterns with frequency-domain rhythmic\nfeatures in a single processing stream, 2) ignoring the critical spatial\ntopology of electrodes with different standards, and 3) reliance on the\ninflexible, dense network to process functionally distinct EEG patterns. To\naddress these challenges, we introduce the Unified Neural Topological\nFoundation Model (Uni-NTFM), which is designed based on neuroscience principles\nto produce universal and interpretable representations. Uni-NTFM integrates\nthree core innovations: 1) a decoupled architecture parallelly encodes time,\nfrequency, and raw signal representations before performing cross-domain\nfeature integration; 2) a topological embedding mechanism to unify electrodes\nfrom different international standards and generate structured input sequences\nfor brain regions; and 3) a Mixture-of-Experts neural Transformer that\nefficiently scales model capacity by routing signal patterns to specialized\nsubnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B\nparameters and was pretrained on over 28,000 hours of diverse EEG data via a\ndual-domain masked reconstruction objective. Uni-NTFM significantly outperforms\nexisting task-specific methods and foundation models across nine distinct\ndownstream tasks under both linear probing and fine-tuning settings,\ndemonstrating a superior ability to learn universal representations of brain\nactivity."}
{"id": "2509.03070", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2509.03070", "abs": "https://arxiv.org/abs/2509.03070", "authors": ["Po-Heng Chou", "Wei-Lung Mao", "Ru-Ping Lin"], "title": "YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform", "comment": "5 pages, 2 figures, 2 tables, submitted to IEEE Sensors Letters", "summary": "This letter proposes a YOLO-based framework for spatial bearing fault\ndiagnosis using time-frequency spectrograms derived from continuous wavelet\ntransform (CWT). One-dimensional vibration signals are first transformed into\ntime-frequency spectrograms using Morlet wavelets to capture transient fault\nsignatures. These spectrograms are then processed by YOLOv9, v10, and v11\nmodels to classify fault types. Evaluated on three benchmark datasets,\nincluding Case Western Reserve University (CWRU), Paderborn University (PU),\nand Intelligent Maintenance System (IMS), the proposed CWT-YOLO pipeline\nachieves significantly higher accuracy and generalizability than the baseline\nMCNN-LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%\n(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism\nenables direct visualization of fault locations in spectrograms, offering a\npractical solution for condition monitoring in rotating machinery."}
{"id": "2507.02824", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.02824", "abs": "https://arxiv.org/abs/2507.02824", "authors": ["Po-Heng Chou", "Ching-Wen Chen", "Wan-Jen Huang", "Walid Saad", "Yu Tsao", "Ronald Y. Chang"], "title": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift", "comment": "5 pages, 4 figures, 2 tables, accepted by 2024 IEEE Globecom\n  Workshops", "summary": "In this paper, the precoding design is investigated for maximizing the\nthroughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO)\nsystems with obstructed direct communication paths. In particular, a\nreconfigurable intelligent surface (RIS) is employed to enhance MIMO\ntransmissions, considering mmWave characteristics related to line-of-sight\n(LoS) and multipath effects. The traditional exhaustive search (ES) for optimal\ncodewords in the continuous phase shift is computationally intensive and\ntime-consuming. To reduce computational complexity, permuted discrete Fourier\ntransform (DFT) vectors are used for finding codebook design, incorporating\namplitude responses for practical or ideal RIS systems. However, even if the\ndiscrete phase shift is adopted in the ES, it results in significant\ncomputation and is time-consuming. Instead, the trained deep neural network\n(DNN) is developed to facilitate faster codeword selection. Simulation results\nshow that the DNN maintains sub-optimal spectral efficiency even as the\ndistance between the end-user and the RIS has variations in the testing phase.\nThese results highlight the potential of DNN in advancing RIS-aided systems."}
{"id": "2509.24355", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24355", "abs": "https://arxiv.org/abs/2509.24355", "authors": ["Sefa Kayraklık", "Recep Baş", "Hasan Oğuzhan Çalışkan", "Samed Şahinoğlu", "Sercan Erdoğan", "İlhami Ünal", "İbrahim Hökelek", "Kıvanç Nurdan", "Ali Görçin"], "title": "N78 Frequency Band Modular RIS Design and Implementation", "comment": "Presented at EuMC2025, Copyright EuMA", "summary": "Reconfigurable intelligent surface (RIS), capable of dynamically controlling\nwireless propagation characteristics using reflecting antenna elements, is a\npromising technology for enhancing signal coverage and improving end-user\nconnectivity in next-generation wireless networks. This paper presents a\ncomplete design flow of a modular RIS prototype operating at the n78 frequency\nband, starting from the simulations to the prototype development and testing.\nAn RIS prototype includes one master and up to sixteen slave blocks, each of\nwhich has an identical hardware structure with $8\\times 8$ reflecting surface\nelements and a controller board. The phase shift response of each unit element\nis controlled with a PIN diode to form a $180^\\circ$ phase difference between\nthe ON and OFF states. The measurement experiment using two RIS blocks, horn\nantennas, and a vector network analyzer showed that the improvement of the\nreceived signal power is more than $15$ dB across the n78 frequency band for a\ngiven placement."}
{"id": "2509.24247", "categories": ["eess.IV", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24247", "abs": "https://arxiv.org/abs/2509.24247", "authors": ["Kai Yuan", "Dongxu Li", "Jianhao Huang", "Han Zhang", "Chuan Huang"], "title": "Adaptive Source-Channel Coding for Multi-User Semantic and Data Communications", "comment": null, "summary": "This paper considers a multi-user semantic and data communication\n(MU-SemDaCom) system, where a base station (BS) simultaneously serves users\nwith different semantic and data tasks through a downlink multi-user\nmultiple-input single-output (MU-MISO) channel. The coexistence of\nheterogeneous communication tasks, diverse channel conditions, and the\nrequirements for digital compatibility poses significant challenges to the\nefficient design of MU-SemDaCom systems. To address these issues, we propose a\nmulti-user adaptive source-channel coding (MU-ASCC) framework that adaptively\noptimizes deep neural network (DNN)-based source coding, digital channel\ncoding, and superposition broadcasting. First, we employ a data-regression\nmethod to approximate the end-to-end (E2E) semantic and data distortions, for\nwhich no closed-form expressions exist. The obtained logistic formulas\ndecompose the E2E distortion as the addition of the source and channel\ndistortion terms, in which the logistic parameter variations are task-dependent\nand jointly determined by both the DNN and channel parameters. Then, based on\nthe derived formulas, we formulate a weighted-sum E2E distortion minimization\nproblem that jointly optimizes the source-channel coding rates, power\nallocation, and beamforming vectors for both the data and semantic users.\nFinally, an alternating optimization (AO) framework is developed, where the\nadaptive rate optimization is solved using the subgradient descent method,\nwhile the joint power and beamforming is addressed via the uplink-downlink\nduality (UDD) technique. Simulation results demonstrate that, compared with the\nconventional separate source-channel coding (SSCC) and deep joint\nsource-channel coding (DJSCC) schemes that are designed for a single task, the\nproposed MU-ASCC scheme achieves simultaneous improvements in both the data\nrecovery and semantic task performance."}
{"id": "2509.24428", "categories": ["eess.SP", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.24428", "abs": "https://arxiv.org/abs/2509.24428", "authors": ["Santos Michelena", "Maxime Ferreira Da Costa", "José Picheral"], "title": "Strong Basin of Attraction for Unmixing Kernels With the Variable Projection Method", "comment": "5 pages, 4 figures. Submitted to the 2026 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP)", "summary": "The problem of recovering a mixture of spike signals convolved with distinct\npoint spread functions (PSFs) lying on a parametric manifold, under the\nassumption that the spike locations are known, is studied. The PSF unmixing\nproblem is formulated as a projected non-linear least squares estimator. A\nlower bound on the radius of the region of strong convexity is established in\nthe presence of noise as a function of the manifold coherence and Lipschitz\nproperties, guaranteeing convergence and stability of the optimization program.\nNumerical experiments highlight the speed of decay of the PSF class in the\nproblem's conditioning and confirm theoretical findings. Finally, the proposed\nestimator is deployed on real-world spectroscopic data from laser-induced\nbreakdown spectroscopy (LIBS), removing the need for manual calibration and\nvalidating the method's practical relevance."}
{"id": "2509.24805", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24805", "abs": "https://arxiv.org/abs/2509.24805", "authors": ["Andriy Enttsel", "Alex Marchioni", "Andrea Zanellini", "Mauro Mangia", "Gianluca Setti", "Riccardo Rovatti"], "title": "RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off", "comment": "12 pages, 11 figures", "summary": "Extensive monitoring systems generate data that is usually compressed for\nnetwork transmission. This compressed data might then be processed in the cloud\nfor tasks such as anomaly detection. However, compression can potentially\nimpair the detector's ability to distinguish between regular and irregular\npatterns due to information loss. Here we extend the information-theoretic\nframework introduced in [1] to simultaneously address the trade-off between the\nthree features on which the effectiveness of the system depends: the\neffectiveness of compression, the amount of distortion it introduces, and the\ndistinguishability between compressed normal signals and compressed anomalous\nsignals. We leverage a Gaussian assumption to draw curves showing how moving on\na Pareto surface helps administer such a trade-off better than simply relying\non optimal rate-distortion compression and hoping that compressed signals can\nbe distinguished from each other."}
{"id": "2509.24537", "categories": ["eess.SP", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.24537", "abs": "https://arxiv.org/abs/2509.24537", "authors": ["Philipp del Hougne"], "title": "Low-Complexity Wireless Multi-Port Sensing by Multiplexed De-Embedding of an Over-the-Air Fixture", "comment": "9 pages including 5 figures", "summary": "Wireless multi-port sensing remotely retrieves the scattering matrix of a\nmulti-port device under test (DUT) connected to a set of\nnot-directly-accessible (NDA) antennas that couple over-the-air (OTA) to a set\nof accessible antennas. If (i) the OTA fixture characteristics are known, and\n(ii) the number of independent measurements at the accessible antennas is\nsufficient, the OTA fixture can be de-embedded to recover the DUT\ncharacteristics. In recent prior work, we solved (i) by connecting the NDA\nantennas to a specific known tunable load network (TLN). Here, we tackle (ii)\nby additionally using the TLN to provide measurement diversity. The connection\nbetween OTA fixture and TLN constitutes a programmable fixture (PF). When the\nDUT characteristics cannot be identified based on a single PF realization, we\nadd measurement diversity with multiple PF realizations. The underlying\n\"multiplexed de-embedding\" achieves the joint de-embedding of an ensemble of PF\nrealizations when a single PF realization cannot be de-embedded. We\nexperimentally demonstrate our concept by remotely estimating the scattering\nmatrix of a reciprocal, non-unitary 4-port DUT (10 complex-valued unknowns) via\na rich-scattering OTA fixture purely based on measurements of a single\ntransmission coefficient between two accessible antennas across 30 different PF\nrealizations. We systematically study the trade-off between the number of\nindependent measurements at the accessible antennas and the number of PF\nrealizations. Multiplexed de-embedding of the OTA fixture paves the path to\nimplementing wireless multi-port sensing with low hardware complexity in areas\nlike RFID and wireless bioelectronics."}
{"id": "2509.24588", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24588", "abs": "https://arxiv.org/abs/2509.24588", "authors": ["Luis F. Abanto-Leon", "Muhammad Salman", "Lismer Andres Caceres-Najarro"], "title": "BARProp: Fast-Converging and Memory-Efficient RSS-Based Localization Algorithm for IoT", "comment": "9 pages, 8 figures, and 4 tables", "summary": "Leveraging received signal strength (RSS) measurements for indoor\nlocalization is highly attractive due to their inherent availability in\nubiquitous wireless protocols. However, prevailing RSS-based methods often\ndepend on complex computational algorithms or specialized hardware, rendering\nthem impractical for low-cost access points. To address these challenges, this\npaper introduces buffer-aided RMSProp (BARProp), a fast and memory-efficient\nlocalization algorithm specifically designed for RSS-based tasks. The key\ninnovation of BARProp lies in a novel mechanism that dynamically adapts the\ndecay factor by monitoring the energy variations of recent gradients stored in\na buffer, thereby achieving both accelerated convergence and enhanced\nstability. Furthermore, BARProp requires less than 15% of the memory used by\nstate-of-the-art methods. Extensive evaluations with real-world data\ndemonstrate that BARProp not only achieves higher localization accuracy but\nalso delivers at least a fourfold improvement in convergence speed compared to\nexisting benchmarks."}
{"id": "2509.24683", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24683", "abs": "https://arxiv.org/abs/2509.24683", "authors": ["Johan Arbustini", "Eric Elzenheimer", "Elizaveta Spetzler", "Pablo Mendoza", "Daniel Fernández", "Jordi Madrenas", "Jeffrey McCord", "Michael Höft", "Robert Rieger", "Andreas Bahr"], "title": "Impedance Modeling of Magnetometers: A Path Toward Low-Noise Readout Circuits", "comment": "4 pages, 3 figures, BMT2025 conference paper", "summary": "Optimizing sensor readout schemes and integrated circuit designs for both\nopen-loop and closed-loop implementations requires precise modeling and\nsimulation strategies. This study introduces a novel two-port impedance model\nto estimate the behavior of a converse Magnetoelectric (cME) sensor. This model\nprovides a possible framework for calculating transfer functions and simulating\nmagnetometer behavior in both continuous- and discrete-time simulation\nenvironments, and it is also possibly transferable to other magnetometer types.\nCommon S-parameters were measured experimentally using an impedance analyzer\nand converted to Z-parameters to create a transfer function for system-level\nsimulations. The model was validated through an analysis of output-related\nnoise using MATLAB and LTSpice simulations to optimize the noise of the analog\ncircuit parts of the system. The simulation results were compared with\nexperimental measurements using a Zurich Instruments lock-in amplifier and the\ncustom-designed low-noise printed circuit board (PCB) under model\nconsiderations. The proposed methodology derives noise considerations and the\ntransfer function of a magnetometer. These are essential for readout schemes\nfor mixed-signal circuit design. This allows low-noise electronics to be\ndesigned and extended to other sensor interface electronics, broadening their\napplicability in high-performance magnetic sensing."}
{"id": "2509.24805", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24805", "abs": "https://arxiv.org/abs/2509.24805", "authors": ["Andriy Enttsel", "Alex Marchioni", "Andrea Zanellini", "Mauro Mangia", "Gianluca Setti", "Riccardo Rovatti"], "title": "RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off", "comment": "12 pages, 11 figures", "summary": "Extensive monitoring systems generate data that is usually compressed for\nnetwork transmission. This compressed data might then be processed in the cloud\nfor tasks such as anomaly detection. However, compression can potentially\nimpair the detector's ability to distinguish between regular and irregular\npatterns due to information loss. Here we extend the information-theoretic\nframework introduced in [1] to simultaneously address the trade-off between the\nthree features on which the effectiveness of the system depends: the\neffectiveness of compression, the amount of distortion it introduces, and the\ndistinguishability between compressed normal signals and compressed anomalous\nsignals. We leverage a Gaussian assumption to draw curves showing how moving on\na Pareto surface helps administer such a trade-off better than simply relying\non optimal rate-distortion compression and hoping that compressed signals can\nbe distinguished from each other."}
{"id": "2509.24819", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.24819", "abs": "https://arxiv.org/abs/2509.24819", "authors": ["Kunyu Wu", "Qiushi Zhao", "Zihan Feng", "Yunxi Mu", "Hao Qin", "Xinyu Zhang", "Xingqi Zhang"], "title": "Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning", "comment": null, "summary": "Urban railway systems increasingly rely on communication based train control\n(CBTC) systems, where optimal deployment of access points (APs) in tunnels is\ncritical for robust wireless coverage. Traditional methods, such as empirical\nmodel-based optimization algorithms, are hindered by excessive measurement\nrequirements and suboptimal solutions, while machine learning (ML) approaches\noften struggle with complex tunnel environments. This paper proposes a deep\nreinforcement learning (DRL) driven framework that integrates parabolic wave\nequation (PWE) channel modeling, conditional generative adversarial network\n(cGAN) based data augmentation, and a dueling deep Q network (Dueling DQN) for\nAP placement optimization. The PWE method generates high-fidelity path loss\ndistributions for a subset of AP positions, which are then expanded by the cGAN\nto create high resolution path loss maps for all candidate positions,\nsignificantly reducing simulation costs while maintaining physical accuracy. In\nthe DRL framework, the state space captures AP positions and coverage, the\naction space defines AP adjustments, and the reward function encourages signal\nimprovement while penalizing deployment costs. The dueling DQN enhances\nconvergence speed and exploration exploitation balance, increasing the\nlikelihood of reaching optimal configurations. Comparative experiments show\nthat the proposed method outperforms a conventional Hooke Jeeves optimizer and\ntraditional DQN, delivering AP configurations with higher average received\npower, better worst-case coverage, and improved computational efficiency. This\nwork integrates high-fidelity electromagnetic simulation, generative modeling,\nand AI-driven optimization, offering a scalable and data-efficient solution for\nnext-generation CBTC systems in complex tunnel environments."}
{"id": "2509.24941", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24941", "abs": "https://arxiv.org/abs/2509.24941", "authors": ["Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Emil Björnson"], "title": "Low-Complexity Receiver Design for Multicarrier CAPA-based Systems in Doubly-Dispersive Channels", "comment": "Submitted to an IEEE conference", "summary": "We propose a novel low-complexity receiver design for multicarrier continuous\naperture array (CAPA) systems operating over doubly-dispersive (DD) channels.\nThe receiver leverages a Gaussian Belief Propagation (GaBP)-based framework\nthat hinges only on element-wise scalar operations for the detection of the\ntransmitted symbols. Simulation results for the orthogonal frequency division\nmultiplexing (OFDM), orthogonal time frequency space (OTFS), and affine\nfrequency division multiplexing (AFDM) waveforms demonstrate significant\nperformance improvements in terms of uncoded bit error rate (BER) compared to\nconventional discrete antenna array systems, while maintaining very low\ncomputational complexity."}
{"id": "2509.25095", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.25095", "abs": "https://arxiv.org/abs/2509.25095", "authors": ["M A Al-Masud", "Juan Miguel Lopez Alcaraz", "Nils Strodthoff"], "title": "Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks", "comment": "26 pages, 3 figures source code under\n  https://github.com/AI4HealthUOL/ecg-fm-benchmarking", "summary": "The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yet\nmachine learning for ECG interpretation remains fragmented, often limited to\nnarrow tasks or datasets. Foundation models promise broader adaptability, but\ntheir generalization across diverse ECG tasks is not well understood. We\nbenchmarked eight ECG foundation models on 26 clinically relevant tasks using\n12 public datasets comprising 1,650 regression and classification targets.\nModels were evaluated under fine-tuning and frozen settings, with scaling\nanalyses across dataset sizes. Results show heterogeneous performance across\ndomains: in the most widely studied domain, adult ECG interpretation, three\nfoundation models consistently outperformed strong supervised baselines. In\ncontrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,\ndominated other categories where most foundation models failed to surpass\nsupervised learning. Foundation models also displayed distinct scaling\nbehaviors with dataset size, which are critical for small-scale clinical\napplications. Overall, while foundation models show promise for adult ECG\nanalysis, substantial gaps remain in cardiac structure, outcome prediction, and\npatient characterization. Notably, ECG-CPC's strong performance despite being\norders of magnitude smaller and consuming minimal computational resources\nhighlights untapped opportunities for advancing ECG foundation models."}
{"id": "2509.23274", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.23274", "abs": "https://arxiv.org/abs/2509.23274", "authors": ["Yirun Wang", "Yongqing Wang", "Yuyao Shen", "Gongpu Wang", "Chintha Tellambura"], "title": "RIS- and Multi-Snapshot-Enabled SISO 3D Position and Velocity Estimation With Single Base Station", "comment": "15 pages, 7 figures", "summary": "Reconfigurable intelligent surface (RIS) panels can act as cost-effective\nanchors for radio localization, complementing conventional base station (BS)\nanchors. This paper investigates joint three-dimensional position and velocity\nestimation (3D-JPVE) in single-input single-output (SISO) systems with only one\nBS available. We first theoretically show that 3D-JPVE is infeasible when\nrelying solely on a single RIS or on multiple snapshots alone. To address this,\nwe propose combining RIS deployment with multi-snapshot utilization to enable\nrealizable 3D-JPVE. A two-stage method is developed for multi-snapshot channel\nparameter estimation, comprising a tensor-based coarse estimation step followed\nby a maximum likelihood refinement step. In particular, we introduce a\nthird-order tensor formulation to decompose the challenging 3D joint\nangle-of-departure and Doppler shift estimation (3D-JADE) into two tractable\nsubproblems, which are jointly solved via a low-complexity alternating\noptimization approach. Building on the channel parameter estimates, we further\ndesign a two-stage low-complexity method for optimal 3D-JPVE: coarse estimation\nis obtained from differential measurements through linear equations, and the\npreliminary results are refined iteratively using the original measurements.\nMoreover, we derive the closed-form Cramer-Rao lower bound (CRLB) and show that\nthe proposed 3D-JPVE method approaches CRLB-level accuracy. Simulation results\nconfirm the statistical efficiency of the proposed estimators and demonstrate\nsubstantial 3D-JPVE performance gains when deploying active RIS compared to\npassive RIS."}
{"id": "2509.23442", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23442", "abs": "https://arxiv.org/abs/2509.23442", "authors": ["Md. Saiful Bari Siddiqui", "Mohammed Imamul Hassan Bhuiyan"], "title": "S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network", "comment": "Submitted to IEEE Journal of Biomedical and Health Informatics\n  (JBHI). This preprint includes few additional details not present in the\n  journal submission", "summary": "Convolutional Neural Networks have become a cornerstone of medical image\nanalysis due to their proficiency in learning hierarchical spatial features.\nHowever, this focus on a single domain is inefficient at capturing global,\nholistic patterns and fails to explicitly model an image's frequency-domain\ncharacteristics. To address these challenges, we propose the Spatial-Spectral\nSummarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns\nfrom both spatial and spectral representations simultaneously. The S$^3$F-Net\nperforms a fusion of a deep spatial CNN with our proposed shallow spectral\nencoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,\nwhich leverages the Convolution Theorem by applying a bank of learnable filters\ndirectly to an image's full Fourier spectrum via a computation-efficient\nelement-wise multiplication. This allows the SpectralFilter layer to attain a\nglobal receptive field instantaneously, with its output being distilled by a\nlightweight summarizer network. We evaluate S$^3$F-Net across four medical\nimaging datasets spanning different modalities to validate its efficacy and\ngeneralizability. Our framework consistently and significantly outperforms its\nstrong spatial-only baseline in all cases, with accuracy improvements of up to\n5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive\naccuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs\nbetter on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%\naccuracy, surpassing many top-performing, much deeper models. Our\nexplainability analysis also reveals that the S$^3$F-Net learns to dynamically\nadjust its reliance on each branch based on the input pathology. These results\nverify that our dual-domain approach is a powerful and generalizable paradigm\nfor medical image analysis."}
{"id": "2509.23590", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23590", "abs": "https://arxiv.org/abs/2509.23590", "authors": ["Fangyu Liu", "Peiwen Jiang", "Wenjin Wang", "Chao-Kai Wen", "Shi Jin", "Jun Zhang"], "title": "Foundation Model-Based Adaptive Semantic Image Transmission for Dynamic Wireless Environments", "comment": null, "summary": "Foundation model-based semantic transmission has recently shown great\npotential in wireless image communication. However, existing methods exhibit\ntwo major limitations: (i) they overlook the varying importance of semantic\ncomponents for specific downstream tasks, and (ii) they insufficiently exploit\nwireless domain knowledge, resulting in limited robustness under dynamic\nchannel conditions. To overcome these challenges, this paper proposes a\nfoundation model-based adaptive semantic image transmission system for dynamic\nwireless environments, such as autonomous driving. The proposed system\ndecomposes each image into a semantic segmentation map and a compressed\nrepresentation, enabling task-aware prioritization of critical objects and\nfine-grained textures. A task-adaptive precoding mechanism then allocates radio\nresources according to the semantic importance of extracted features. To ensure\naccurate channel information for precoding, a channel estimation knowledge map\n(CEKM) is constructed using a conditional diffusion model that integrates user\nposition, velocity, and sparse channel samples to train scenario-specific\nlightweight estimators. At the receiver, a conditional diffusion model\nreconstructs high-quality images from the received semantic features, ensuring\nrobustness against channel impairments and partial data loss. Simulation\nresults on the BDD100K dataset with multi-scenario channels generated by\nQuaDRiGa demonstrate that the proposed method outperforms existing approaches\nin terms of perceptual quality (SSIM, LPIPS, FID), task-specific accuracy\n(IoU), and transmission efficiency. These results highlight the effectiveness\nof integrating task-aware semantic decomposition, scenario-adaptive channel\nestimation, and diffusion-based reconstruction for robust semantic transmission\nin dynamic wireless environments."}
{"id": "2509.24373", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24373", "abs": "https://arxiv.org/abs/2509.24373", "authors": ["Matteo Zecchin", "Unnikrishnan Kunnath Ganesan", "Giuseppe Durisi", "Petar Popovski", "Osvaldo Simeone"], "title": "Prediction-Powered Communication with Distortion Guarantees", "comment": null, "summary": "The development of 6G wireless systems is taking place alongside the\ndevelopment of increasingly intelligent wireless devices and network nodes. The\nchanging technological landscape is motivating a rethinking of classical\nShannon information theory that emphasizes semantic and task-oriented\nparadigms. In this paper, we study a prediction-powered communication setting,\nin which devices, equipped with artificial intelligence (AI)-based predictors,\ncommunicate under zero-delay constraints with strict distortion guarantees. Two\nclasses of distortion measures are considered: (i) outage-based metrics,\nsuitable for tasks tolerating occasional packet losses, such as real-time\ncontrol or monitoring; and (ii) bounded distortion metrics, relevant to\nsemantic-rich tasks like text or video transmission. We propose two zero-delay\ncompression algorithms leveraging online conformal prediction to provide\nper-sequence guarantees on the distortion of reconstructed sequences over\nerror-free and packet-erasure channels with feedback. For erasure channels, we\nintroduce a doubly-adaptive conformal update to compensate for channel-induced\nerrors and derive sufficient conditions on erasure statistics to ensure\ndistortion constraints. Experiments on semantic text compression validate the\napproach, showing significant bit rate reductions while strictly meeting\ndistortion guarantees compared to state-of-the-art prediction-powered\ncompression methods."}
{"id": "2509.24433", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24433", "abs": "https://arxiv.org/abs/2509.24433", "authors": ["Xin Wei", "Weidong Mei", "Xuan Huang", "Zhi Chen", "Boyu Ning"], "title": "Energy-Efficient Movable Antennas: Mechanical Power Modeling and Performance Optimization", "comment": null, "summary": "Movable antennas (MAs) offer additional spatial degrees of freedom (DoFs) to\nenhance communication performance through local antenna movement. However, to\nachieve accurate and fast antenna movement, MA drivers entail non-negligible\nmechanical power consumption, rendering energy efficiency (EE) optimization\nmore critical compared to conventional fixed-position antenna (FPA) systems. To\naddress this issue, we develop a fundamental power consumption model for\nstepper motor-driven multi-MA systems based on electric motor theory. Based on\nthis model, we formulate an EE maximization problem from a multi-MA base\nstation (BS) to multiple single-FPA users. We aim to jointly optimize the MAs'\npositions, moving speeds, and the BS's transmit precoding matrix subject to\ncollision-avoidance constraints during the multi-MA movements. However, this\nproblem is difficult to solve. To tackle this challenge, we first reveal that\nthe collision-avoidance constraints can always be relaxed without loss of\noptimality by properly renumbering the MA indices. For the resulting relaxed\nproblem, we first consider a simplified single-user setup and uncover a hidden\nmonotonicity of the EE performance with respect to the MAs' moving speeds. To\nsolve the remaining optimization problem, we develop a two-layer optimization\nframework. In the inner layer, the Dinkelbach algorithm is employed to derive\nthe optimal beamforming solution for any given MA positions. In the outer\nlayer, a sequential update algorithm is proposed to iteratively refine the MA\npositions based on the optimal values obtained from the inner layer. Next, we\nproceed to the general multi-user case and propose an alternating optimization\n(AO) algorithm. Numerical results demonstrate that despite the additional\nmechanical power consumption, the proposed algorithms can outperform both\nconventional FPA systems and other existing EE maximization benchmarks"}
{"id": "2509.25067", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.25067", "abs": "https://arxiv.org/abs/2509.25067", "authors": ["Rohollah Vahdani", "S. Mohammad Razavizadeh"], "title": "Capacity Achieving Design for Hybrid Beamforming in Millimeter Wave Massive MIMO Systems", "comment": "Published in IEEE Transactions on Vehicular Technology, Volume: 74,\n  Issue: 3, March 2025", "summary": "Hybrid digital and analog beamforming is a highly effective technique for\nimplementing beamforming methods in millimeter wave (mmWave) systems. It\nprovides a viable solution to replace the complex fully digital beamforming\ntechniques. However, the current design of precoding and combining matrices in\nhybrid beamforming solely relies on the channel information, neglecting the\ncrucial consideration of the structure of covariance matrices of the transmit\nsignals. In this paper, we present a novel approach for the joint design of\nhybrid beamforming matrices at the transmitter and receiver. This approach is\ncentered around the optimization of the covariance matrix of the transmitted\nsignals. Our goal is to maximize the downlink sum rate capacity of the system\nby achieving an optimal design of the transmit covariance matrix. We tackle the\nnon-convex nature of this problem by leveraging the dual relationship between\nthe broadcast channel (BC) and the multiple access channel (MAC). Through\nextensive simulations in various scenarios, including point-to-point\nmulti-input multi-output (MIMO), multi-user (MU) multi-input single-output\n(MISO), and MU-MIMO, we demonstrate the superiority of our proposed method over\ntraditional designs. These results highlight the effectiveness and versatility\nof our approach in optimizing beamforming for mmWave systems."}
