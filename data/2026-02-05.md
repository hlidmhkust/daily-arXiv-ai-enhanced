<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 4]
- [eess.IV](#eess.IV) [Total: 5]
- [eess.SP](#eess.SP) [Total: 25]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference](https://arxiv.org/abs/2602.03949)
*Emrah Akyol*

Main category: cs.IT

TL;DR: 研究在速率和计算约束下的战略性高斯语义压缩，编码器和解码器优化不同的二次目标，推导出战略率失真函数，并证明计算限制作为隐式速率约束能带来语义准确性的指数级提升。


<details>
  <summary>Details</summary>
Motivation: 为数据高效和能量高效的AI提供信息理论基础，并为现代多模态语言模型在资源约束下作为后验设计机制提供原则性解释。研究编码器和解码器目标不一致时的战略交互问题。

Method: 采用高斯语义压缩框架，潜在高斯状态生成任务相关的语义变量，解码器通过MMSE估计进行最佳响应，将编码器问题简化为信息速率约束下的后验协方差设计。分析直接、远程和完全信息三种机制。

Result: 推导出战略率失真函数，得到语义注水算法和速率约束高斯说服解决方案，证明高斯最优性。发现架构计算限制作为隐式速率约束，模型深度和推理时间计算能带来语义准确性的指数级提升，多模态观测消除了远程编码固有的几何平均惩罚。

Conclusion: 该研究为数据高效和能量高效的AI提供了信息理论基础，并为现代多模态语言模型在资源约束下作为后验设计机制提供了原则性解释，揭示了战略交互、计算约束和多模态观测对语义压缩性能的影响。

Abstract: We study strategic Gaussian semantic compression under rate and compute constraints, where an encoder and decoder optimize distinct quadratic objectives. A latent Gaussian state generates a task dependent semantic variable, and the decoder best responds via MMSE estimation, reducing the encoder's problem to posterior covariance design under an information rate constraint. We characterize the strategic rate distortion function in direct, remote, and full information regimes, derive semantic waterfilling and rate constrained Gaussian persuasion solutions, and establish Gaussian optimality under misaligned objectives. We further show that architectural compute limits act as implicit rate constraints, yielding exponential improvements in semantic accuracy with model depth and inference time compute, while multimodal observation eliminates the geometric mean penalty inherent to remote encoding. These results provide information theoretic foundations for data and energy efficient AI and offer a principled interpretation of modern multimodal language models as posterior design mechanisms under resource constraints.

</details>


### [2] [Joint Sleep Mode Activation and Load Balancing with Dynamic Cell Load: A Combinatorial Bandit Approach](https://arxiv.org/abs/2602.04808)
*Wajahat Bashir Gilkar,Gourab Ghatak*

Main category: cs.IT

TL;DR: 提出一种组合式多臂老虎机方法，通过智能触发小基站睡眠模式并结合小区范围扩展负载均衡，在保证5G服务质量的同时优化网络能效。


<details>
  <summary>Details</summary>
Motivation: 5G网络中大量小基站的能耗问题日益突出，但简单地关闭小基站会增加相邻基站和宏基站的负载，反而可能降低整体能效。需要一种智能方法来平衡节能与服务质量。

Method: 采用组合式上置信界算法选择要关闭的小基站，结合小区范围扩展进行负载均衡。模型考虑了用户位置、相对基站位置和数据需求等动态负载因素，可作为O-RAN近实时RAN智能控制器应用实现。

Result: 实验表明，提出的CUCB+负载均衡算法不仅优于保持所有小基站开启的朴素策略，也优于其他先进的强化学习解决方案，在保证5QI服务质量要求的同时显著提升能效。

Conclusion: 该组合式多臂老虎机方法为5G网络节能提供了有效的解决方案，能够在保证服务质量的前提下智能管理小基站的睡眠模式，且易于在O-RAN架构中部署实现。

Abstract: We propose a combinatorial bandit formulation to opportunistically trigger sleep modes in gNode-B (gNB) small cells (SCs), followed by a cell range expansion (CRE)-based load balancing procedure. This is implemented by ensuring that the fifth generation (5G) quality of service identifier (5QI)-requirements of user equipments (UEs) are maintained. The key challenge is the fact that while deactivating a given SC gNB reduces its own consumption, it may increase the load on neighboring gNBs and the macro gNB (coverage cell), impacting the overall energy efficiency. This phenomenon is accurately characterized by modeling the dynamic cell load that jointly takes into account the location of the UEs, their relative locations to all the SCs, and their data demands. We experimentally show that the proposed combinatorial upper confidence bound (CUCB) followed by the load balancer outperforms not only the naive strategies like arbitrarily keeping all the SCs on, but also other state-of-the-art reinforcement learning solutions. The proposed algorithm can be implemented as open-radio access network (O-RAN) near-real-time (NRT) RAN intelligent controller (RIC) xApps.

</details>


### [3] [Game of Coding for Vector-Valued Computations](https://arxiv.org/abs/2602.04810)
*Hanzaleh Akbari Nodehi,Parsa Moradi,Soheil Mohajer,Mohammad Ali Maddah-Ali*

Main category: cs.IT

TL;DR: 将博弈编码框架从标量计算扩展到N维欧几里得空间，为高维数据计算提供理论基础，保持对抗多数情况下的弹性特性


<details>
  <summary>Details</summary>
Motivation: 传统编码理论需要诚实节点占多数的严格信任假设，而博弈编码利用经济理性保证正确性，但先前研究仅限于标量计算，无法处理现实世界中的高维数据任务

Method: 将博弈编码框架扩展到N维欧几里得空间，为向量值计算提供严格的问题表述，并完全表征所得高维博弈的均衡策略

Result: 分析表明，在标量设置中建立的弹性特性在向量机制中得以保留，为无需诚实多数假设的安全大规模去中心化计算奠定理论基础

Conclusion: 成功将博弈编码扩展到高维空间，为去中心化机器学习等新兴无许可应用提供了处理现实世界高维数据的能力，突破了传统编码理论的信任限制

Abstract: The game of coding is a new framework at the intersection of game theory and coding theory; designed to transcend the fundamental limitations of classical coding theory. While traditional coding theoretic schemes rely on a strict trust assumption, that honest nodes must outnumber adversarial ones to guarantee valid decoding, the game of coding leverages the economic rationality of actors to guarantee correctness and reliable decodability, even in the presence of an adversarial majority. This capability is paramount for emerging permissionless applications, particularly decentralized machine learning (DeML). However, prior investigations into the game of coding have been strictly confined to scalar computations, limiting their applicability to real world tasks where high dimensional data is the norm. In this paper, we bridge this gap by extending the framework to the general $N$-dimensional Euclidean space. We provide a rigorous problem formulation for vector valued computations and fully characterize the equilibrium strategies of the resulting high dimensional game. Our analysis demonstrates that the resilience properties established in the scalar setting are preserved in the vector regime, establishing a theoretical foundation for secure, large scale decentralized computing without honest majority assumptions.

</details>


### [4] [Capacity Bounds on Doppler OFDM Channels](https://arxiv.org/abs/2602.04862)
*Pablo Orellana,Zheng Li,Jean-Marc Kelif,Sheng Yang,Shlomo Shamai*

Main category: cs.IT

TL;DR: 该论文研究LEO卫星系统中由残余多普勒频移引起的信道不确定性，提出了一种基于子空间对齐的叠加编码方案，在低复杂度下实现接近最优的速率。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星系统由于高速移动会产生显著的多普勒效应。虽然大部分多普勒频移可以被补偿，但残余的频率不确定性会形成结构化的信道不确定性，从而限制可实现的通信速率。

Method: 采用块衰落信道模型 H = F + sG，其中s是未知的标量随机参数。首先在一般N×N MIMO设置下研究该模型，推导基于显式传输方案的可实现速率下界和使用对偶方法的容量上界。提出具有子空间对齐(SN)和连续干扰消除的实用叠加方案，其中粗层流作为解码细层数据的隐式导频。

Result: 在近相干和高信噪比区域表征了渐近容量，通过多普勒-OFDM仿真表明，提出的SN方案以低复杂度实现了接近最优的速率。

Conclusion: 该研究为LEO卫星系统中的残余多普勒不确定性提供了有效的通信方案，提出的子空间对齐叠加编码方案在性能和复杂度之间取得了良好平衡，对实际系统设计具有指导意义。

Abstract: Low Earth orbit (LEO) satellite systems experience significant Doppler effects due to high mobility. While Doppler shifts can be largely compensated, residual frequency uncertainty induces a structured form of channel uncertainty that can limit achievable rates. We model this effect using a block-fading channel of the form $ \mathbf{H} = \mathbf{F} + s \mathbf{G} $, where $s$ is an unknown scalar random parameter. We first study this model in a general $N\times N$ MIMO setting. For this channel, we derive achievable rate lower bounds based on explicit transmission schemes and capacity upper bounds using a duality approach. We study Gaussian signaling and propose a practical superposition scheme with subspace alignment (SN) and successive interference cancellation, where a coarse-layer stream serves as an implicit pilot for decoding refined-layer data. We characterize asymptotic capacity in the near-coherent and high-SNR regimes, and show via Doppler-OFDM simulations that the proposed SN scheme achieves near-optimal rates with low complexity.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [5] [DINO-AD: Unsupervised Anomaly Detection with Frozen DINO-V3 Features](https://arxiv.org/abs/2602.03870)
*Jiayu Huo,Jingyuan Hong,Liyun Chen*

Main category: eess.IV

TL;DR: 提出DINO-AD框架，利用DINO-V3自监督特征进行医学图像异常检测，通过嵌入相似性匹配和前景感知K-means聚类实现精确异常定位。


<details>
  <summary>Details</summary>
Motivation: 医学图像异常检测需要像素级标注，这在大规模应用中成本高昂。现有方法在精确异常定位方面仍有不足，需要更有效的无监督方法。

Method: 1) 使用DINO-V3提取自监督视觉特征；2) 嵌入相似性匹配选择语义对齐的支持图像；3) 前景感知K-means聚类建模正常特征分布；4) 通过余弦相似度比较查询特征与聚类正常嵌入生成异常图。

Result: 在Brain和Liver数据集上达到SOTA性能，AUROC最高达98.71。定性结果显示异常定位更清晰准确，消融实验验证了各模块的有效性。

Conclusion: DINO-AD框架利用自监督特征实现了高效准确的医学图像异常检测，具有鲁棒性和泛化能力，为无标注异常检测提供了有效解决方案。

Abstract: Unsupervised anomaly detection (AD) in medical images aims to identify abnormal regions without relying on pixel-level annotations, which is crucial for scalable and label-efficient diagnostic systems. In this paper, we propose a novel anomaly detection framework based on DINO-V3 representations, termed DINO-AD, which leverages self-supervised visual features for precise and interpretable anomaly localization. Specifically, we introduce an embedding similarity matching strategy to select a semantically aligned support image and a foreground-aware K-means clustering module to model the distribution of normal features. Anomaly maps are then computed by comparing the query features with clustered normal embeddings through cosine similarity. Experimental results on both the Brain and Liver datasets demonstrate that our method achieves superior quantitative performance compared with state-of-the-art approaches, achieving AUROC scores of up to 98.71. Qualitative results further confirm that our framework produces clearer and more accurate anomaly localization. Extensive ablation studies validate the effectiveness of each proposed component, highlighting the robustness and generalizability of our approach.

</details>


### [6] [To What Extent Do Token-Level Representations from Pathology Foundation Models Improve Dense Prediction?](https://arxiv.org/abs/2602.03887)
*Weiming Chen,Xitong Ling,Xidong Wang,Zhenyang Cai,Yijia Guo,Mingxi Fu,Ziyi Zeng,Minxi Ouyang,Jiawen Li,Yizhi Wang,Tian Guan,Benyou Wang,Yonghong He*

Main category: eess.IV

TL;DR: PFM-DenseBench是一个大规模病理学基础模型密集预测基准，系统评估了17个PFM在18个公开分割数据集上的表现，为实际部署提供指导。


<details>
  <summary>Details</summary>
Motivation: 病理学基础模型(PFMs)发展迅速，已成为下游临床任务的常用骨干网络，具有良好的跨组织和机构迁移能力。然而，对于密集预测任务（如分割），实际部署仍缺乏对不同PFM在不同数据集上表现的清晰、可复现的理解，以及适应策略如何影响性能和稳定性的系统认知。

Method: 提出了PFM-DenseBench基准，在统一协议下系统评估17个PFM在18个公开分割数据集上的表现。采用多种适应和微调策略，包括不同的调优选择，进行全面的性能分析。

Result: 通过大规模基准测试，得出了关于不同PFM和调优选择在异构数据集上成功或失败的实践导向性见解。研究提供了容器、配置文件和数据集卡片，支持可复现的评估。

Conclusion: PFM-DenseBench为实际密集病理学任务提供了系统评估框架，帮助研究人员和从业者做出明智的PFM选择，并理解不同适应策略的影响，促进病理学基础模型在实际部署中的应用。

Abstract: Pathology foundation models (PFMs) have rapidly advanced and are becoming a common backbone for downstream clinical tasks, offering strong transferability across tissues and institutions. However, for dense prediction (e.g., segmentation), practical deployment still lacks a clear, reproducible understanding of how different PFMs behave across datasets and how adaptation choices affect performance and stability. We present PFM-DenseBench, a large-scale benchmark for dense pathology prediction, evaluating 17 PFMs across 18 public segmentation datasets. Under a unified protocol, we systematically assess PFMs with multiple adaptation and fine-tuning strategies, and derive insightful, practice-oriented findings on when and why different PFMs and tuning choices succeed or fail across heterogeneous datasets. We release containers, configs, and dataset cards to enable reproducible evaluation and informed PFM selection for real-world dense pathology tasks. Project Website: https://m4a1tastegood.github.io/PFM-DenseBench

</details>


### [7] [CONRep: Uncertainty-Aware Vision-Language Report Drafting Using Conformal Prediction](https://arxiv.org/abs/2602.03910)
*Danial Elyassirad,Benyamin Gheiji,Mahsa Vatanparast,Amir Mahmoud Ahmadzadeh,Seyed Amir Asef Agah,Mana Moassefi,Meysam Tavakoli,Shahriar Faghani*

Main category: eess.IV

TL;DR: CONRep是一个模型无关的框架，通过整合共形预测为视觉语言模型生成的放射学报告提供统计基础的不确定性量化，提高自动化报告系统的透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前自动化放射学报告生成系统大多缺乏明确的不确定性估计，限制了临床部署的信任度和安全性。需要一种方法来量化VLM生成报告的不确定性，以提高系统的透明度和临床可用性。

Method: 提出CONRep框架，整合共形预测方法，在标签级别校准预定义发现的二元预测，在句子级别通过图像-文本语义对齐评估自由文本印象的不确定性。该框架是模型无关的，适用于生成式和对比式VLM。

Result: 在公共胸部X光数据集上的评估显示，高置信度输出的结果与放射科医生标注和真实印象的一致性显著高于低置信度输出。框架在不修改底层模型的情况下实现了校准的置信度分层。

Conclusion: CONRep通过提供统计基础的不确定性量化，提高了自动化放射学报告系统的透明度、可靠性和临床可用性，为安全临床部署奠定了基础。

Abstract: Automated radiology report drafting (ARRD) using vision-language models (VLMs) has advanced rapidly, yet most systems lack explicit uncertainty estimates, limiting trust and safe clinical deployment. We propose CONRep, a model-agnostic framework that integrates conformal prediction (CP) to provide statistically grounded uncertainty quantification for VLM-generated radiology reports. CONRep operates at both the label level, by calibrating binary predictions for predefined findings, and the sentence level, by assessing uncertainty in free-text impressions via image-text semantic alignment. We evaluate CONRep using both generative and contrastive VLMs on public chest X-ray datasets. Across both settings, outputs classified as high confidence consistently show significantly higher agreement with radiologist annotations and ground-truth impressions than low-confidence outputs. By enabling calibrated confidence stratification without modifying underlying models, CONRep improves the transparency, reliability, and clinical usability of automated radiology reporting systems.

</details>


### [8] [AtlasPatch: An Efficient and Scalable Tool for Whole Slide Image Preprocessing in Computational Pathology](https://arxiv.org/abs/2602.03998)
*Ahmed Alagha,Christopher Leclerc,Yousef Kotp,Omar Metwally,Calvin Moras,Peter Rentopoulos,Ghodsiyeh Rostami,Bich Ngoc Nguyen,Jumanah Baig,Abdelhakim Khellaf,Vincent Quoc-Huy Trinh,Rabeb Mizouni,Hadi Otrok,Jamal Bentahar,Mahdi S. Hosseini*

Main category: eess.IV

TL;DR: AtlasPatch是一个高效、可扩展的WSI预处理框架，通过基于Segment-Anything模型的半自动标注训练实现准确的组织检测，显著降低计算成本的同时保持SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前全切片图像预处理存在两大问题：传统方法依赖不准确的启发式阈值分割，而基于AI的方法虽然准确但计算复杂度高且训练数据多样性有限。这成为计算病理学AI工作流的主要计算瓶颈。

Method: 1) 使用约30,000张WSI缩略图的异质半手动标注数据集训练组织检测模块；2) 基于Segment-Anything模型进行高效微调；3) 将缩略图组织掩码外推到全分辨率切片；4) 支持用户指定放大倍率提取补丁坐标；5) 提供补丁直接编码嵌入或存储选项；6) 在CPU和GPU上高效并行化。

Result: 在分割精度、计算复杂度和下游多实例学习任务中，AtlasPatch匹配最先进方法的性能，同时仅需其一小部分计算成本。工具已开源。

Conclusion: AtlasPatch提供了一个高效、可扩展的WSI预处理解决方案，解决了计算病理学中的关键计算瓶颈，在保持高性能的同时显著降低了计算开销。

Abstract: Whole-slide image (WSI) preprocessing, typically comprising tissue detection followed by patch extraction, is foundational to AI-driven computational pathology workflows. This remains a major computational bottleneck as existing tools either rely on inaccurate heuristic thresholding for tissue detection, or adopt AI-based approaches trained on limited-diversity data that operate at the patch level, incurring substantial computational complexity. We present AtlasPatch, an efficient and scalable slide preprocessing framework for accurate tissue detection and high-throughput patch extraction with minimal computational overhead. AtlasPatch's tissue detection module is trained on a heterogeneous and semi-manually annotated dataset of ~30,000 WSI thumbnails, using efficient fine-tuning of the Segment-Anything model. The tool extrapolates tissue masks from thumbnails to full-resolution slides to extract patch coordinates at user-specified magnifications, with options to stream patches directly into common image encoders for embedding or store patch images, all efficiently parallelized across CPUs and GPUs. We assess AtlasPatch across segmentation precision, computational complexity, and downstream multiple-instance learning, matching state-of-the-art performance while operating at a fraction of their computational cost. AtlasPatch is open-source and available at https://github.com/AtlasAnalyticsLab/AtlasPatch.

</details>


### [9] [MS-SCANet: A Multiscale Transformer-Based Architecture with Dual Attention for No-Reference Image Quality Assessment](https://arxiv.org/abs/2602.04032)
*Mayesha Maliha R. Mithila,Mylene C. Q. Farias*

Main category: eess.IV

TL;DR: MS-SCANet是一种基于Transformer的无参考图像质量评估网络，采用多尺度双分支结构，结合空间和通道注意力机制，通过跨分支注意力增强特征整合，并引入两种一致性损失函数，在多个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统单尺度方法在图像质量评估中难以同时捕捉精细和粗糙细节，现有方法在跨尺度特征整合方面存在局限，需要更有效的多尺度处理机制来提升与人类主观评分的相关性。

Method: 提出MS-SCANet：1）多尺度双分支结构处理不同尺度图像；2）定制化空间和通道注意力机制强调关键特征；3）跨分支注意力机制增强不同尺度特征整合；4）引入两种一致性损失函数（跨分支一致性损失和自适应池化一致性损失）保持特征缩放时的空间完整性。

Result: 在KonIQ-10k、LIVE、LIVE Challenge和CSIQ等数据集上的广泛评估表明，MS-SCANet持续超越最先进方法，与人类主观评分具有更强的相关性。

Conclusion: MS-SCANet为无参考图像质量评估提供了一个鲁棒的框架，通过多尺度处理、注意力机制和一致性损失函数的创新组合，显著提升了性能表现。

Abstract: We present the Multi-Scale Spatial Channel Attention Network (MS-SCANet), a transformer-based architecture designed for no-reference image quality assessment (IQA). MS-SCANet features a dual-branch structure that processes images at multiple scales, effectively capturing both fine and coarse details, an improvement over traditional single-scale methods. By integrating tailored spatial and channel attention mechanisms, our model emphasizes essential features while minimizing computational complexity. A key component of MS-SCANet is its cross-branch attention mechanism, which enhances the integration of features across different scales, addressing limitations in previous approaches. We also introduce two new consistency loss functions, Cross-Branch Consistency Loss and Adaptive Pooling Consistency Loss, which maintain spatial integrity during feature scaling, outperforming conventional linear and bilinear techniques. Extensive evaluations on datasets like KonIQ-10k, LIVE, LIVE Challenge, and CSIQ show that MS-SCANet consistently surpasses state-of-the-art methods, offering a robust framework with stronger correlations with subjective human scores.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [10] [Majorization-Minimization Networks for Inverse Problems: An Application to EEG Imaging](https://arxiv.org/abs/2602.03855)
*Le Minh Triet Tran,Sarah Reynaud,Ronan Fablet,Adrien Merlini,François Rousseau,Mai Quyen Pham*

Main category: eess.SP

TL;DR: 提出一种基于双层优化的学习型Majorization-Minimization框架，通过轻量级RNN学习结构化曲率上界，在保持经典MM下降保证的同时提升逆问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 逆问题通常是不适定的，需要具有强稳定性和收敛保证的优化方案。现有的基于学习的方法（如深度展开和元学习）虽然取得了良好的经验性能，但通常缺乏对下降和曲率的显式控制，限制了鲁棒性。

Method: 在双层优化设置中提出学习型Majorization-Minimization框架。不学习完整的优化器，而是学习一个结构化曲率上界来控制每个MM步骤，同时保持经典MM下降保证。上界由轻量级循环神经网络参数化，并显式约束以满足有效的MM条件。对于余弦相似度损失，推导出显式曲率边界以获得对角上界；当解析边界不可用时，使用高效的Hessian-向量积谱估计自动上界局部曲率而不显式形成Hessian矩阵。

Result: 在EEG源成像实验上展示了相比深度展开和元学习基线方法在准确性、稳定性和跨数据集泛化能力方面的改进。

Conclusion: 提出的学习型MM框架通过结合学习能力和经典优化理论保证，为逆问题提供了更稳健和可泛化的解决方案，在保持理论保证的同时实现了更好的性能。

Abstract: Inverse problems are often ill-posed and require optimization schemes with strong stability and convergence guarantees. While learning-based approaches such as deep unrolling and meta-learning achieve strong empirical performance, they typically lack explicit control over descent and curvature, limiting robustness. We propose a learned Majorization-Minimization (MM) framework for inverse problems within a bilevel optimization setting. Instead of learning a full optimizer, we learn a structured curvature majorant that governs each MM step while preserving classical MM descent guarantees. The majorant is parameterized by a lightweight recurrent neural network and explicitly constrained to satisfy valid MM conditions. For cosine-similarity losses, we derive explicit curvature bounds yielding diagonal majorants. When analytic bounds are unavailable, we rely on efficient Hessian-vector product-based spectral estimation to automatically upper-bound local curvature without forming the Hessian explicitly. Experiments on EEG source imaging demonstrate improved accuracy, stability, and cross-dataset generalization over deep-unrolled and meta-learning baselines.

</details>


### [11] [The Turing Synthetic Radar Dataset: A dataset for pulse deinterleaving](https://arxiv.org/abs/2602.03856)
*Edward Gunn,Adam Hosford,Robert Jones,Leo Zeitler,Ian Groves,Victoria Nockles*

Main category: eess.SP

TL;DR: 提出了Turing合成雷达数据集，这是一个包含6000个脉冲序列、近30亿个脉冲的综合数据集，用于雷达脉冲解交织研究和电子战应用


<details>
  <summary>Details</summary>
Motivation: 解决电子战和信号情报中多个未知发射器交织雷达脉冲的分离问题，为雷达脉冲解交织研究提供基准测试和新的研究方法

Method: 创建了包含6000个脉冲序列的综合合成雷达数据集，涵盖两种接收器配置，模拟了最多110个发射器的真实场景，并启动了Turing解交织挑战赛

Result: 建立了包含近30亿个脉冲的公开可用数据集，支持复杂模型开发，并提供了标准化评估程序

Conclusion: Turing合成雷达数据集是首批公开可用的综合脉冲序列数据集之一，旨在促进电子战社区中复杂模型的发展

Abstract: We present the Turing Synthetic Radar Dataset, a comprehensive dataset to serve both as a benchmark for radar pulse deinterleaving research and as an enabler of new research methods. The dataset addresses the critical problem of separating interleaved radar pulses from multiple unknown emitters for electronic warfare applications and signal intelligence. Our dataset contains a total of 6000 pulse trains over two receiver configurations, totalling to almost 3 billion pulses, featuring realistic scenarios with up to 110 emitters and significant parameter space overlap. To encourage dataset adoption and establish standardised evaluation procedures, we have launched an accompanying Turing Deinterleaving Challenge, for which models need to associate pulses in interleaved pulse trains to the correct emitter by clustering and maximising metrics such as the V-measure. The Turing Synthetic Radar Dataset is one of the first publicly available, comprehensively simulated pulse train datasets aimed to facilitate sophisticated model development in the electronic warfare community

</details>


### [12] [PENGUIN: General Vital Sign Reconstruction from PPG with Flow Matching State Space Model](https://arxiv.org/abs/2602.03858)
*Shuntaro Suzuki,Shuitsu Koyama,Shinnosuke Hirano,Shunya Nagashima*

Main category: eess.SP

TL;DR: PENGUIN：基于生成流匹配的通用框架，从PPG信号重建多种生命体征连续波形，克服现有方法单任务限制和形态特征丢失问题


<details>
  <summary>Details</summary>
Motivation: PPG信号易受运动伪影和噪声影响，现有方法多为单任务或环境特定，缺乏通用性；且近期通用方法依赖多秒间隔预测，丢弃了生命体征的形态特征

Method: 提出PENGUIN框架，扩展深度状态空间模型，采用生成流匹配技术，实现对PPG信号的细粒度条件化，重建多种生命体征的连续波形

Result: 在6个真实世界PPG数据集上的3个生命体征重建任务（心电图重建、呼吸监测、动脉血压监测）中，PENGUIN始终优于任务特定和通用基线方法

Conclusion: PENGUIN作为从PPG进行稳健生命体征重建的通用框架，解决了现有方法的局限性，展示了在多样化PPG解码场景中的强大性能

Abstract: Photoplethysmography (PPG) plays a crucial role in continuous cardiovascular health monitoring as a non-invasive and cost-effective modality. However, PPG signals are susceptible to motion artifacts and noise, making accurate estimation of vital signs such as arterial blood pressure (ABP) challenging. Existing estimation methods are often restricted to a single-task or environment, limiting their generalizability across diverse PPG decoding scenarios. Moreover, recent general-purpose approaches typically rely on predictions over multi-second intervals, discarding the morphological characteristics of vital signs. To address these challenges, we propose PENGUIN, a generative flow-matching framework that extends deep state space models, enabling fine-grained conditioning on PPG for reconstructing multiple vital signs as continuous waveforms. We evaluate PENGUIN using six real-world PPG datasets across three distinct vital sign reconstruction tasks (electrocardiogram reconstruction, respiratory monitoring, and ABP monitoring). Our method consistently outperformed both task-specific and general-purpose baselines, demonstrating PENGUIN as a general framework for robust vital sign reconstruction from PPG.

</details>


### [13] [Polynomial Closed-Form Model for Evaluating Nonlinear Interference in Any Island](https://arxiv.org/abs/2602.03860)
*Yanchao Jiang,Pierluigi Poggiolini*

Main category: eess.SP

TL;DR: 提出多项式闭式GN模型，通过将每个信道沿跨距的空间功率剖面表示为多项式，推导出所有自干扰、交叉干扰和多信道干扰的通用闭式表达式


<details>
  <summary>Details</summary>
Motivation: 传统GN模型计算复杂，需要数值积分，难以快速评估光纤非线性干扰。需要一种更高效、解析的模型来准确计算非线性干扰贡献。

Method: 将每个信道沿光纤跨距的空间功率剖面表示为多项式形式，基于此推导出完整的闭式表达式，涵盖自干扰、交叉干扰和多信道干扰的所有贡献

Result: 获得了通用的闭式表达式，提供了完整的数学推导，能够准确计算所有类型的非线性干扰，相比传统方法计算效率更高

Conclusion: 提出的多项式闭式GN模型为光纤通信系统中的非线性干扰分析提供了高效准确的解析工具，简化了系统性能评估

Abstract: Polynomial closed-form GN model is proposed by expressing the spatial power profile of each channel along a span as a polynomial. In this paper, we present the generic closed-form expression for all contributions of self-, cross-, and multi-channel interference. The full derivation is provided.

</details>


### [14] [An Enhanced Polar-Domain Dictionary Design for Elevated BSs in Near-Field U-MIMO](https://arxiv.org/abs/2602.04331)
*Luca Antonelli,Antonio Alberto D'Amico,Luca Sanguinetti*

Main category: eess.SP

TL;DR: 提出一种适用于任意基站位置的三维近场U-MIMO网格设计框架，通过优化归一化均方误差提升信道表示精度，在sub-THz频段实现更优的信道估计和频谱效率。


<details>
  <summary>Details</summary>
Motivation: 现有U-MIMO网格设计方法大多假设基站位于地面，忽略了基站高度的影响，这与实际部署场景不符。需要开发能适应任意基站位置的通用网格设计框架。

Method: 提出广义网格设计框架，基于最优归一化均方误差最小化来优化角度和距离域的采样网格，而非传统的相关性方法。在sub-THz频段评估采用P-SOMP算法的混合U-MIMO系统性能。

Result: 分析和数值结果表明，相比现有方法，所提设计在信道估计精度和频谱效率方面均有显著提升。

Conclusion: 考虑基站三维位置的实际部署场景，通过优化归一化均方误差的网格设计方法能有效提升近场U-MIMO系统性能，为实际部署提供了更准确的网格设计解决方案。

Abstract: Near-field U-MIMO communications require carefully optimized sampling grids in both angular and distance domains. However, most existing grid design methods neglect the influence of base station height, assuming instead that the base station is positioned at ground level - a simplification that rarely reflects real-world deployments. To overcome this limitation, we propose a generalized grid design framework that accommodates arbitrary base station locations. Unlike conventional correlation-based approaches, our method optimizes the grid based on the minimization of the optimal normalized mean squared error, leading to more accurate channel representation. We evaluate the performance of a hybrid U-MIMO system operating at sub-THz frequencies, considering the P-SOMP algorithm for channel estimation. Analytical and numerical results show that the proposed design enhances both channel estimation accuracy and spectral efficiency compared to existing alternatives.

</details>


### [15] [A Multi-Modal Foundational Model for Wireless Communication and Sensing](https://arxiv.org/abs/2602.04016)
*Vahid Yazdnian,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: 提出一个任务无关、多模态的无线物理层基础模型，通过物理引导的自监督预训练学习可迁移的物理感知表示，实现跨任务和环境的鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的无线技术泛化能力差：大多数模型是任务特定、环境依赖且限于窄感知模态，在新场景部署时需要昂贵的重新训练。

Method: 采用物理引导的自监督预训练策略，引入专门的物理令牌来捕捉电磁传播控制的跨模态物理对应关系，学习可迁移的物理感知表示。

Result: 该模型在多种下游任务（大规模多天线优化、无线信道估计、设备定位）中表现出优异的泛化能力、对部署变化的鲁棒性，并显著减少数据需求。

Conclusion: 该任务无关、多模态的基础模型为下一代无线通信和感知系统提供了强大的泛化能力，能够适应多样化的任务和环境，减少对标记数据的依赖。

Abstract: Artificial intelligence is a key enabler for next-generation wireless communication and sensing. Yet, today's learning-based wireless techniques do not generalize well: most models are task-specific, environment-dependent, and limited to narrow sensing modalities, requiring costly retraining when deployed in new scenarios. This work introduces a task-agnostic, multi-modal foundational model for physical-layer wireless systems that learns transferable, physics-aware representations across heterogeneous modalities, enabling robust generalization across tasks and environments. Our framework employs a physics-guided self-supervised pretraining strategy incorporating a dedicated physical token to capture cross-modal physical correspondences governed by electromagnetic propagation. The learned representations enable efficient adaptation to diverse downstream tasks, including massive multi-antenna optimization, wireless channel estimation, and device localization, using limited labeled data. Our extensive evaluations demonstrate superior generalization, robustness to deployment shifts, and reduced data requirements compared to task-specific baselines.

</details>


### [16] [Cross-Attention Transformer for Joint Multi-Receiver Uplink Neural Decoding](https://arxiv.org/abs/2602.04728)
*Xavier Tardy,Grégoire Lefebvre,Apostolos Kountouris,Haïfa Fares,Amor Nafkha*

Main category: eess.SP

TL;DR: 提出一种基于交叉注意力Transformer的联合解码方法，用于多接入点协作接收的上行OFDM信号，无需显式信道估计，通过比特度量目标训练，在Wi-Fi信道中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统多接入点协作接收需要显式的信道估计，在导频稀疏或链路质量变化时性能受限。本文旨在设计一种无需显式信道估计、能自适应融合各接收器可靠性的联合解码方案。

Method: 采用交叉注意力Transformer架构：每个接收器使用共享编码器学习时频结构，通过token-wise交叉注意力模块融合多个接收器信息，直接输出软对数似然比供标准信道解码器使用，使用比特度量目标进行训练。

Result: 在真实Wi-Fi信道中，该方法持续优于传统流水线和强卷积基线，经常匹配甚至超过假设完美信道知识的强大基线。模型紧凑、计算成本低（低GFLOPs）、GPU延迟低。

Conclusion: 提出的交叉注意力Transformer是一种实用的下一代Wi-Fi接收器构建模块，无需显式信道估计，能自适应融合多接收器信息，在稀疏导频和链路质量变化时保持鲁棒性。

Abstract: We propose a cross-attention Transformer for joint decoding of uplink OFDM signals received by multiple coordinated access points. A shared per-receiver encoder learns time-frequency structure within each received grid, and a token-wise cross-attention module fuses the receivers to produce soft log-likelihood ratios for a standard channel decoder, without requiring explicit per-receiver channel estimates. Trained with a bit-metric objective, the model adapts its fusion to per-receiver reliability, tolerates missing or degraded links, and remains robust when pilots are sparse. Across realistic Wi-Fi channels, it consistently outperforms classical pipelines and strong convolutional baselines, frequently matching (and in some cases surpassing) a powerful baseline that assumes perfect channel knowledge per access point. Despite its expressiveness, the architecture is compact, has low computational cost (low GFLOPs), and achieves low latency on GPUs, making it a practical building block for next-generation Wi-Fi receivers.

</details>


### [17] [Cross-Frequency Bispectral EEG Analysis of Reach-to-Grasp Planning and Execution](https://arxiv.org/abs/2602.04018)
*Sima Ghafoori,Anna Cetera,Ali Rabiee,MH Farhadi,Rahul Singh,Mariusz Furmanek,Yalda Shahriari,Reza Abiri*

Main category: eess.SP

TL;DR: EEG高阶交叉频率耦合分析揭示运动规划与执行阶段的非线性神经特征差异，为脑机接口提供新标记


<details>
  <summary>Details</summary>
Motivation: 传统EEG运动解码主要依赖线性二阶谱特征，但神经抓握控制源于多脑节律的非线性相互作用，需要探索高阶交叉频率动态是否能够区分自然抓握行为中的运动规划与执行阶段

Method: 采用基于线索的范式记录执行精确抓握和力量抓握时的EEG，使用交叉频率双谱分析计算典型频带对的双相干矩阵，提取幅值和相位特征，进行分类、基于置换的特征选择和受试者内统计测试

Result: 执行阶段比规划阶段表现出更强、更具区分性的非线性耦合，主要由β和γ频带驱动；精确抓握与力量抓握的解码在规划和执行阶段表现相当，表明抓握类型表征在规划阶段形成并持续到执行；信息性双谱特征反映前额叶、中央区和枕叶区域的协调活动

Conclusion: 非线性交叉频率耦合为运动规划和执行提供了可解释且稳健的标记，将双谱EEG分析扩展到生态有效的抓握行为，支持其在脑机接口和神经假肢控制中的相关性

Abstract: Neural control of grasping arises from nonlinear interactions across multiple brain rhythms, yet EEG-based motor decoding has largely relied on linear, second-order spectral features. Here, we examine whether higher-order cross-frequency dynamics distinguish motor planning from execution during natural reach-to-grasp behavior. EEG was recorded in a cue-based paradigm during executed precision and power grips, enabling stage-resolved analysis of preparatory and execution-related neural activity.
  Cross-frequency bispectral analysis was used to compute bicoherence matrices across canonical frequency band pairs, from which magnitude- and phase-based features were extracted. Classification, permutation-based feature selection, and within-subject statistical testing showed that execution is characterized by substantially stronger and more discriminative nonlinear coupling than planning, with dominant contributions from beta- and gamma-driven interactions. In contrast, decoding of precision versus power grips achieved comparable performance during planning and execution, indicating that grasp-type representations emerge during planning and persist into execution.
  Spatial and spectral analyses further revealed that informative bispectral features reflect coordinated activity across prefrontal, central, and occipital regions. Despite substantial feature redundancy, effective dimensionality reduction preserved decoding performance. Together, these findings demonstrate that nonlinear cross-frequency coupling provides an interpretable and robust marker of motor planning and execution, extending bispectral EEG analysis to ecologically valid grasping and supporting its relevance for brain-computer interfaces and neuroprosthetic control.

</details>


### [18] [Ultra-Fast Device-Free Visible Light Sensing and Localization via Reflection-Based ΔRSS and Deep Learning](https://arxiv.org/abs/2602.04062)
*Helena Serpi,Christina,Politi*

Main category: eess.SP

TL;DR: 提出了一种超快速、无设备的可见光传感与定位系统，利用天花板安装的光电探测器捕获单LED VLC信道响应的时空变化，通过光学信号反射建模准确、非侵入式地推断人的存在和位置。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需穿戴设备、非侵入式的人体存在检测和定位系统，利用现有的可见光通信基础设施，实现高精度、快速响应的室内定位和传感。

Method: 使用天花板安装的光电探测器捕获单LED可见光通信信道的时空变化，通过光学信号反射建模分析信号特征，并采用多架构深度神经网络集成库中的机器学习模型进行推理。

Result: 系统能够准确、非侵入式地推断人的存在和位置，具有高度适应性，可服务于不同的现实世界传感和定位场景。

Conclusion: 该系统提供了一种创新的可见光传感和定位解决方案，利用现有VLC基础设施实现无设备、非侵入式的人体检测和定位，具有实际应用潜力。

Abstract: We propose an Ultra-Fast, Device-Free Visible Light Sensing and Positioning system that captures spatiotemporal variations in single-LED VLC channel responses, using ceiling-mounted photodetectors, to accurately and non-intrusively infer human presence and position through optical signal reflection modeling. The system is highly adaptive and ready to serve different real-world sensing and positioning scenarios using one or more ML based models from the library of multi-architecture deep neural network ensembles we have developed.

</details>


### [19] [Structure-Informed Estimation for Pilot-Limited MIMO Channels via Tensor Decomposition](https://arxiv.org/abs/2602.04083)
*Alexandre Barbosa de Lima*

Main category: eess.SP

TL;DR: 提出了一种混合张量-神经网络架构，用于宽带MIMO系统中的导频受限信道估计，将问题建模为稀疏观测下的低秩张量补全，相比传统方法显著降低了导频开销。


<details>
  <summary>Details</summary>
Motivation: 在5G/6G高维场景中，宽带MIMO系统的信道估计面临导频开销的根本性限制。传统方法需要大量导频，而现有张量方法通常假设完全观测的接收信号张量，不适用于导频受限的实际场景。

Method: 采用混合张量-神经网络架构：1) 将信道估计建模为稀疏观测下的低秩张量补全问题；2) 比较CP分解（适用于匹配多径模型的镜面信道）和Tucker分解（对模型失配更鲁棒）；3) 使用轻量级3D U-Net学习低秩结构之外的残差分量，连接代数模型与真实传播效应。

Result: 样本复杂度近似按内在模型维度L(Nr+Nt+Nf)缩放，而非环境张量大小NrNtNf。在合成信道上，5-10%导频密度下比LS和OMP基线提升10-20dB NMSE；在DeepMIMO射线追踪信道上，比纯张量方法额外减少24-44% NMSE。

Conclusion: 混合张量-神经网络架构有效解决了宽带MIMO系统中的导频受限信道估计问题，通过结合代数分解的模型优势和神经网络对复杂传播效应的学习能力，显著提升了估计性能并降低了导频开销。

Abstract: Channel estimation in wideband multiple-input multiple-output (MIMO) systems faces fundamental pilot overhead limitations in high-dimensional beyond-5G and sixth-generation (6G) scenarios. This paper presents a hybrid tensor-neural architecture that formulates pilot-limited channel estimation as low-rank tensor completion from sparse observations -- a fundamentally different setting from prior tensor methods that assume fully observed received signal tensors. A canonical polyadic (CP) baseline implemented via a projection-based scheme (Tucker completion under partial observations) and Tucker decompositions are compared under varying signal-to-noise ratio (SNR) and scattering conditions: CP performs well for specular channels matching the multipath model, while Tucker provides greater robustness under model mismatch. A lightweight three-dimensional (3D) U-Net learns residual components beyond the low-rank structure, bridging algebraic models and realistic propagation effects. Empirical recovery threshold analysis shows that sample complexity scales approximately with intrinsic model dimensionality $L(N_r + N_t + N_f)$ rather than ambient tensor size $N_r N_t N_f$, where $L$ denotes the number of dominant propagation paths. Experiments on synthetic channels demonstrate 10-20\,dB normalized mean-square error (NMSE) improvement over least-squares (LS) and orthogonal matching pursuit (OMP) baselines at 5-10\% pilot density, while evaluations on DeepMIMO ray-tracing channels show 24-44\% additional NMSE reduction over pure tensor-based methods.

</details>


### [20] [Uncertainty Principle for Vertex-Time Graph Signal Processing](https://arxiv.org/abs/2602.04084)
*Yanan Zhao,Xingchao Jian,Feng Ji,Wee Peng Tay,Antonio Ortega*

Main category: eess.SP

TL;DR: 该论文提出了一个图信号在顶点-时间域的不确定性原理，统一了经典的时频不确定性原理和图不确定性原理，并基于此开发了新的信号重构方法和图拓扑推断方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理传感器网络和社交网络中的间歇性数据时存在局限性，需要一种能够同时考虑空间（图顶点）和时间域信号定位的统一框架，以改进信号重构和图学习性能。

Method: 通过定义顶点-时间域和谱-频率域的扩展度来量化信号定位，识别出在空间和时间域都能达到最大集中度的信号类别，构建新的顶点-时间字典，并基于不确定性原理开发图拓扑推断方法。

Result: 在合成和真实数据集上的数值实验表明，该方法相比现有方法在重构精度、噪声鲁棒性和图学习性能方面都有显著提升。

Conclusion: 该研究成功建立了统一的顶点-时间不确定性原理框架，为处理图信号提供了新的理论基础和实用工具，特别适用于传感器网络和社交网络等实际应用场景。

Abstract: We present an uncertainty principle for graph signals in the vertex-time domain, unifying the classical time-frequency and graph uncertainty principles within a single framework. By defining vertex-time and spectral-frequency spreads, we quantify signal localization across these domains. Our framework identifies a class of signals that achieve maximum concentration in both the spatial and temporal domains. These signals serve as fundamental atoms for a new vertex-time dictionary, enhancing signal reconstruction under practical constraints, such as intermittent data commonly encountered in sensor and social networks. Furthermore, we introduce a novel graph topology inference method leveraging the uncertainty principle. Numerical experiments on synthetic and real datasets validate the effectiveness of our approach, demonstrating improved reconstruction accuracy, greater robustness to noise, and enhanced graph learning performance compared to existing methods.

</details>


### [21] [Semantic Pilot Design for Data-Aided Channel Estimation Using a Large Language Model](https://arxiv.org/abs/2602.04126)
*Sojeong Park,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 提出一种基于大语言模型的语义导频设计，用于文本数据传输中的信道估计，通过LLM纠正解码文本中的错误来识别可靠符号作为额外导频


<details>
  <summary>Details</summary>
Motivation: 在文本数据传输中，信道损伤常表现为解码文本中的拼写错误，传统导频估计方法可能不够高效，需要利用语义信息提高信道估计性能

Method: 使用LLM纠正初始解码文本中的错误，比较原始解码文本与纠正后的版本，识别可靠解码符号作为语义导频，用于数据辅助的信道估计

Result: 仿真结果显示，该方案优于传统仅使用导频的估计方法，实现了更低的归一化均方误差、相位误差和比特错误率

Conclusion: 这是首个利用语义信息进行可靠符号选择的工作，证明了语义导频设计能有效提升信道估计性能，为数据辅助信道估计提供了新思路

Abstract: This paper proposes a semantic pilot design for data-aided channel estimation in text-inclusive data transmission, using a large language model (LLM). In this scenario, channel impairments often appear as typographical errors in the decoded text, which can be corrected using an LLM. The proposed method compares the initially decoded text with the LLM-corrected version to identify reliable decoded symbols. A set of selected symbols, referred to as a semantic pilot, is used as an additional pilot for data-aided channel estimation. To the best of our knowledge, this work is the first to leverage semantic information for reliable symbol selection. Simulation results demonstrate that the proposed scheme outperforms conventional pilot-only estimation, achieving lower normalized mean squared error and phase error of the estimated channel, as well as reduced bit error rate.

</details>


### [22] [Spatial Angular Pseudo-Derivative Searching: A Single Snapshot Super-resolution Sparse DOA Scheme with Potential for Practical Application](https://arxiv.org/abs/2602.04169)
*Longxin Bai,Jingchao Zhang,Liyan Qiao*

Main category: eess.SP

TL;DR: 提出一种基于空间角度伪导数的稀疏DOA估计算法，针对汽车雷达的计算资源有限、阵列孔径受限和单快照场景，实现实时高效的高精度超分辨估计。


<details>
  <summary>Details</summary>
Motivation: 汽车雷达需要准确、高分辨率、实时的DOA估计，但现有稀疏信号恢复方法计算复杂度太高，难以在实际系统中部署。需要针对汽车雷达的计算资源有限、阵列孔径受限和单快照等约束条件设计高效算法。

Method: 提出空间角度伪导数概念，将其作为约束引入标准L0范数最小化问题，构建更符合DOA物理特性的目标函数。对应的SAPD搜索算法将高维优化转化为高效网格搜索，避免高阶矩阵求逆和计算密集型迭代。

Result: SAPD算法在计算复杂度和收敛性方面表现优异，数值仿真表明该方法在实时效率、高精度和超分辨率之间取得了优越平衡，非常适合下一代汽车雷达应用。

Conclusion: SAPD算法为汽车雷达系统提供了一种计算高效、精度高的DOA估计解决方案，克服了传统稀疏方法计算复杂度过高的瓶颈，具有实际部署价值。

Abstract: Accurate, high-resolution, and real-time DOA estimation is a cornerstone of environmental perception in automotive radar systems. While sparse signal recovery techniques offer super-resolution and high-precision estimation, their prohibitive computational complexity remains a primary bottleneck for practical deployment. This paper proposes a sparse DOA estimation scheme specifically tailored for the stringent requirements of automotive radar such as limited computational resources, restricted array apertures, and a single snapshot. By introducing the concept of the spatial angular pseudo-derivative and incorporating this property as a constraint into a standard L0-norm minimization problem, we formulate an objective function that more faithfully characterizes the physical properties of the DOA problem. The associated solver, designated as the SAPD search algorithm, naturally transforms the high-dimensional optimization task into an efficient grid-search scheme. The SAPD algorithm circumvents high-order matrix inversions and computationally intensive iterations. We provide an analysis of the computational complexity and convergence properties of the proposed algorithm. Extensive numerical simulations demonstrate that the SAPD method achieves a superior balance of real-time efficiency, high precision, and super-resolution, making it highly suitable for next-generation automotive radar applications.

</details>


### [23] [GPINND: A deep-learning-based state of health estimation for Lithium-ion battery](https://arxiv.org/abs/2602.04187)
*Yuzhu Lei,Guanding Yu*

Main category: eess.SP

TL;DR: 提出一种融合深度学习与电化学机制的电池健康状态估计方法，通过构建混合驱动代理模型、自监督参数识别网络和残差校正SOH估计网络，实现非迭代参数识别和高精度SOH估计。


<details>
  <summary>Details</summary>
Motivation: 电化学模型在电池退化诊断中具有优越的可解释性和可靠性，但其迭代参数识别的高计算成本严重阻碍了电化学信息化的健康状态估计在实际实时系统中的实现。

Method: 1. 构建混合驱动代理模型，融合高保真仿真数据和物理约束学习内部电化学动力学；2. 开发自监督框架训练参数识别网络，最小化电压重构误差；3. 利用识别参数作为物理化学健康指标，建立高精度SOH估计网络，采用数据驱动残差校正补偿识别偏差；4. 采用顺序训练策略解决收敛问题。

Result: 实验结果显示，该方法平均电压重构均方根误差为0.0198V，SOH估计均方根误差为0.0014，实现了高精度估计。

Conclusion: 该方法成功解决了电化学模型实时应用的计算瓶颈，通过深度学习与物理机制融合实现了高效、准确的电池健康状态估计，为实际系统部署提供了可行方案。

Abstract: Electrochemical models offer superior interpretability and reliability for battery degradation diagnosis. However, the high computational cost of iterative parameter identification severely hinders the practical implementation of electrochemically informed state of health (SOH) estimation in real-time systems. To address this challenge, this paper proposes an SOH estimation method that integrates deep learning with electrochemical mechanisms and adopts a sequential training strategy. First, we construct a hybrid-driven surrogate model to learn internal electrochemical dynamics by fusing high-fidelity simulation data with physical constraints. This model subsequently serves as an accurate and differentiable physical kernel for voltage reconstruction. Then, we develop a self-supervised framework to train a parameter identification network by minimizing the voltage reconstruction error. The resulting model enables the non-iterative identification of aging parameters from external measurements. Finally, utilizing the identified parameters as physicochemical health indicators, we establish a high-precision SOH estimation network that leverages data-driven residual correction to compensate for identification deviations. Crucially, a sequential training strategy is applied across these modules to effectively mitigate convergence issues and improve the accuracy of each module. Experimental results demonstrate that the proposed method achieves an average voltage reconstruction root mean square error (RMSE) of 0.0198 V and an SOH estimation RMSE of 0.0014.

</details>


### [24] [Maneuverable-Jamming-Aided Secure Communication and Sensing in A2G-ISAC Systems](https://arxiv.org/abs/2602.04209)
*Libiao Lou,Yuan Liu,Fotis Foukalas,Hongjiang Lei,Gaofeng Pan,Theodoros A. Tsiftsis,Hongwu Liu*

Main category: eess.SP

TL;DR: 提出一种用于空地一体化感知通信系统的机动干扰辅助安全通信与感知方案，通过双无人机协同工作，在混合单/双基地雷达配置下实现安全通信与目标感知的平衡。


<details>
  <summary>Details</summary>
Motivation: 空地一体化感知通信系统中，安全通信与目标感知在资源分配上存在根本性冲突，难以同时达到最优性能。需要设计一种方案来平衡这两项功能，同时考虑实际系统中不完美干扰消除带来的残余干扰影响。

Method: 采用双无人机协同工作：源无人机和机动干扰无人机。采用两阶段设计：安全通信阶段使用块坐标下降算法结合信任域逐次凸逼近和半定松弛优化轨迹与波束成形；感知通信阶段通过加权距离最小化问题确定感知位置，再联合优化波束成形。

Result: 仿真结果表明，所提方案在基准方法中实现了最高的平均保密率，同时保持了稳健的感知性能，并验证了不完美干扰消除残余干扰对安全通信和感知的影响。

Conclusion: 提出的机动干扰辅助安全通信与感知方案通过两阶段设计和双无人机协同，有效解决了空地一体化感知通信系统中安全通信与感知的资源冲突问题，在保证感知性能的同时显著提升了通信安全性。

Abstract: In this paper, we propose a maneuverablejamming-aided secure communication and sensing (SCS) scheme for an air-to-ground integrated sensing and communication (A2G-ISAC) system, where a dual-functional source UAV and a maneuverable jamming UAV operate collaboratively in a hybrid monostatic-bistatic radar configuration. The maneuverable jamming UAV emits artificial noise to assist the source UAV in detecting multiple ground targets while interfering with an eavesdropper. The effects of residual interference caused by imperfect successive interference cancellation on the received signal-to-interference-plus-noise ratio are considered, which degrades the system performance. To maximize the average secrecy rate (ASR) under transmit power budget, UAV maneuvering constraints, and sensing requirements, the dual-UAV trajectory and beamforming are jointly optimized. Given that secure communication and sensing fundamentally conflict in terms of resource allocation, making it difficult to achieve optimal performance for both simultaneously, we adopt a two-phase design to address this challenge. By dividing the mission into the secure communication (SC) phase and the SCS phase, the A2G-ISAC system can focus on optimizing distinct objectives separately. In the SC phase, a block coordinate descent algorithm employing the trust-region successive convex approximation and semidefinite relaxation iteratively optimizes dual-UAV trajectory and beamforming. For the SCS phase, a weighted distance minimization problem determines the suitable dual-UAV sensing positions by a greedy algorithm, followed by the joint optimization of source beamforming and jamming beamforming. Simulation results demonstrate that the proposed scheme achieves the highest ASR among benchmarks while maintaining robust sensing performance, and confirm the impact of the SIC residual interference on both secure communication and sensing.

</details>


### [25] [Aortic Valve Disease Detection from PPG via Physiology-Informed Self-Supervised Learning](https://arxiv.org/abs/2602.04266)
*Jiaze Wang,Qinghao Zhao,Zizheng Chen,Zhejun Sun,Deyun Zhang,Yuxi Zhou,Shenda Hong*

Main category: eess.SP

TL;DR: 提出PG-SSL框架，利用生理学知识指导的自监督学习，解决PPG数据标签稀缺问题，实现主动脉瓣疾病的低成本大规模早期筛查。


<details>
  <summary>Details</summary>
Motivation: 传统超声心动图诊断主动脉瓣疾病成本高且需要专业知识，限制了大规模早期筛查。PPG作为可穿戴设备中的广泛可用技术，具有筛查潜力，但金标准标签数据极度稀缺限制了数据驱动方法的有效性。

Method: 提出生理学指导的自监督学习（PG-SSL）框架：1）将临床知识形式化为PPG形态表型；2）构建脉搏模式识别代理任务进行自监督预训练；3）使用双分支门控融合架构在小规模标签数据上进行微调。

Result: 在超过17万个未标记PPG样本上训练，AS和AR筛查的AUC分别达到0.765和0.776，显著优于基于有限标签数据的监督基线。多变量分析验证模型输出作为独立数字生物标志物，在调整标准临床风险因素后仍具有持续预后价值。

Conclusion: PG-SSL为医学人工智能中的标签稀缺问题提供了有效的领域知识驱动解决方案，显示出实现主动脉瓣疾病低成本、大规模早期筛查的强大潜力。

Abstract: Traditional diagnosis of aortic valve disease relies on echocardiography, but its cost and required expertise limit its use in large-scale early screening. Photoplethysmography (PPG) has emerged as a promising screening modality due to its widespread availability in wearable devices and its ability to reflect underlying hemodynamic dynamics. However, the extreme scarcity of gold-standard labeled PPG data severely constrains the effectiveness of data-driven approaches. To address this challenge, we propose and validate a new paradigm, Physiology-Guided Self-Supervised Learning (PG-SSL), aimed at unlocking the value of large-scale unlabeled PPG data for efficient screening of Aortic Stenosis (AS) and Aortic Regurgitation (AR). Using over 170,000 unlabeled PPG samples from the UK Biobank, we formalize clinical knowledge into a set of PPG morphological phenotypes and construct a pulse pattern recognition proxy task for self-supervised pre-training. A dual-branch, gated-fusion architecture is then employed for efficient fine-tuning on a small labeled subset. The proposed PG-SSL framework achieves AUCs of 0.765 and 0.776 for AS and AR screening, respectively, significantly outperforming supervised baselines trained on limited labeled data. Multivariable analysis further validates the model output as an independent digital biomarker with sustained prognostic value after adjustment for standard clinical risk factors. This study demonstrates that PG-SSL provides an effective, domain knowledge-driven solution to label scarcity in medical artificial intelligence and shows strong potential for enabling low-cost, large-scale early screening of aortic valve disease.

</details>


### [26] [Joint Fractional Delay and Doppler Frequency Estimator Under Spectrum Wrapping Phenomenon for LEO-ICAN AFDM Signals](https://arxiv.org/abs/2602.04316)
*Zhenyu Chen,Ke Xiao,Xiaomei Tang,Jing Lei,Muzi Yuan,Guangfu Sun*

Main category: eess.SP

TL;DR: 本文针对LEO卫星ICAN信号中的AFDM波形，解决了分数延迟和多普勒频率估计问题，提出了一种基于PSPR检测和ELG的联合估计算法，具有低复杂度、低开销和高精度优势。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星的快速发展，集成通信导航信号设计在车联网领域受到关注。AFDM作为新一代波形具有抗多普勒效应强、调制结构简单、导频开销低等优点，适合高动态LEO卫星场景。然而，LEO-ICAN AFDM信号面临分数延迟和多普勒频率估计挑战，现有研究忽略其固有的频谱包裹现象可能导致模型构建偏差。

Method: 本文深入推导了AFDM在分数情况下的输入输出关系，揭示了其等效信道的包络特性，并提出了一种基于峰值旁瓣功率比检测和早晚门限的联合估计算法，用于估计分数多普勒频率和延迟。

Result: 仿真结果表明，与传统方法相比，该算法具有低复杂度、低保护间隔开销和高精度的优势。

Conclusion: 本文提出的基于PSPR检测和ELG的联合估计算法有效解决了AFDM在LEO-ICAN场景中的分数延迟和多普勒频率估计问题，为高动态卫星通信导航一体化系统提供了实用解决方案。

Abstract: With the rapid development of low earth orbit (LEO) satellites, the design of integrated communication and navigation (ICAN) signals has attracted increasing attention, especially in the field of vehicle-to-everything (V2X). As a new-generation waveform, Affine Frequency Division Multiplexing (AFDM) features high robustness against Doppler effects, a simple modulation structure, and low pilot overhead, making it a promising candidate for high-dynamic LEO satellite scenarios. However, LEO-ICAN AFDM signals face challenges in fractional delay and Doppler frequency estimation. Existing studies that ignore its inherent spectrum wrapping phenomenon may lead to deviations of varying degrees in model construction. This paper conducts an in-depth derivation of AFDM's input-output relationship under fractional cases, reveals the envelope characteristics of its equivalent channel, and proposes a joint estimation algorithm based on peak-to-sidelobe power ratio (PSPR) detection and early-late gate (ELG) to estimate fractional Doppler frequency and delay. Simulations show that the algorithm has low complexity, low guard interval overhead, and high precision compared with traditional methods.

</details>


### [27] [Rigid Body Localization via Gaussian Belief Propagation with Quadratic Angle Approximation](https://arxiv.org/abs/2602.04410)
*Niclas Führling,Hyeon Seok Rou,Giuseppe Abreu,David González G.,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 提出一种基于高斯置信传播的刚性体定位新方法，通过二次角度近似消除对目标方向先验信息的依赖，实现高精度旋转角度估计


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯置信传播的刚性体定位方法需要准确的目标方向先验信息，这限制了其实际应用。本文旨在消除这一限制，开发一种不依赖精确方向先验的定位方案

Method: 采用二次角度近似来线性化先验与目标刚性体之间的相对方向，基于线性化模型推导消息传递规则，估计目标刚性体的平移向量和旋转矩阵

Result: 数值实验验证了所提角度近似方法的良好性能，以及刚性体定位在均方根误差方面相比现有技术的优越表现，同时保持了低计算复杂度

Conclusion: 成功开发了一种不依赖精确方向先验的高斯置信传播刚性体定位方法，通过二次角度近似实现了高精度估计，在性能和复杂度之间取得了良好平衡

Abstract: Gaussian belief propagation (GaBP) is a technique that relies on linearized error and input-output models to yield low-complexity solutions to complex estimation problems, which has been recently shown to be effective in the design of range-based GaBP schemes for stationary and moving rigid body localization (RBL) in three-dimensional (3D) space, as long as an accurate prior on the orientation of the target rigid body is available. In this article we present a novel range-based RBL scheme via GaBP that removes the latter limitation. To this end, the proposed method incorporates a quadratic angle approximation to linearize the relative orientation between the prior and the target rigid body, enabling high precision estimates of corresponding rotation angles even for large deviations. Leveraging the resulting linearized model, we derive the corresponding message-passing (MP) rules to obtain estimates of the translation vector and rotation matrix of the target rigid body, relative to a prior reference frame. Numerical results corroborate the good performance of the proposed angle approximation itself, as well as the consequent RBL performance in terms of root mean square errors (RMSEs) in comparison to the state-of-the-art (SotA), while maintaining a low computational complexity

</details>


### [28] [An Information-Theoretic Detector for Multiple Scatterers in SAR Tomography](https://arxiv.org/abs/2602.04465)
*Pia Addabbo,Diego Reale,Antonio Pauciullo,Gianfranco Fornaro,Danilo Orlando*

Main category: eess.SP

TL;DR: 提出一种基于信息理论和压缩感知的SAR层析成像自适应多假设检验架构，用于解决城市区域中同一像素内多个散射体的检测和参数估计问题。


<details>
  <summary>Details</summary>
Motivation: 在城市区域，SAR图像中的叠掩现象导致同一像素内包含来自不同高度的多个散射体贡献。传统方法难以有效检测和分离这些多重散射体，需要更先进的检测和参数估计方法。

Method: 采用信息理论框架，设计单阶段自适应多假设检验架构，结合压缩感知方法对每个假设下的未知参数进行估计。

Result: 该方法在仿真数据和真实数据上都得到了验证，并与合适的对比方法进行了比较，显示出良好的性能。

Conclusion: 提出的基于信息理论和压缩感知的自适应多假设检验架构能够有效解决SAR层析成像中的多重散射体检测问题，为城市区域的3D重建和形变监测提供了改进方案。

Abstract: Persistent scatterer interferometry and Synthetic Aperture Radar (SAR) Tomography are powerful tools for the detection and time monitoring of persistent scatterers. They have been proven to be effective in urban scenarios, especially for buildings and infrastructures 3-D reconstruction and monitoring of deformation. In urban areas, occurrence of layover leads to the presence of multiple contributions within the same image pixel from scatterers located at different heights. In the context of SAR Tomography, this problem can be addressed by considering a multiple hypothesis test to detect the presence of feasible multiple scatterers [1][2]. In the present paper, we consider this problem in the framework of the information theory and exploit the theoretical tool, developed in [3], to design a one-stage adaptive architecture for multiple hypothesis testing problems in the context of SAR Tomography. Moreover, we resort to the compressive sensing approach for the estimation of the unknown parameters under each hypothesis. This architecture has been verified on both simulated as well as real data also in comparison with suitable counterparts.

</details>


### [29] [Total Variation Sparse Bayesian Learning for Block Sparsity via Majorization-Minimization](https://arxiv.org/abs/2602.04623)
*Yanbin He,Geethu Joseph*

Main category: eess.SP

TL;DR: 提出一种新的优化框架，用于解决具有差异对数总变分正则化的稀疏贝叶斯学习问题，通过指数重参数化技术改进计算效率和恢复精度。


<details>
  <summary>Details</summary>
Motivation: 实际信号通常具有未知的块边界和孤立的非零项，传统方法难以处理这种复杂的稀疏模式。现有的差异对数总变分正则化稀疏贝叶斯学习方法虽然有效，但由于其复杂形式导致优化问题难以求解。

Method: 通过引入稀疏贝叶斯学习超参数的指数重参数化，揭示了一种新的结构，允许采用主优化-最小化公式，并自然扩展到未知噪声方差估计。

Result: 在合成数据和扩展源方向到达估计上的稀疏恢复结果表明，与基准方法相比，该方法在准确性和运行时性能方面都有所改进。

Conclusion: 提出的优化框架有效解决了差异对数总变分正则化稀疏贝叶斯学习的计算难题，为处理复杂稀疏模式提供了更高效和准确的解决方案。

Abstract: Block sparsity is a widely exploited structure in sparse recovery, offering significant gains when signal blocks are known. Yet, practical signals often exhibit unknown block boundaries and isolated non-zero entries, which challenge traditional approaches. A promising method to handle such complex sparsity patterns is the difference-of-logs total variation (DoL-TV) regularized sparse Bayesian learning (SBL). However, due to the complex form of DoL-TV term, the resulting optimization problem is hard to solve. This paper develops a new optimization framework for the DoL-TV SBL cost function. By introducing an exponential reparameterization of the SBL hyperparameters, we reveal a novel structure that admits a majorization-minimization formulation and naturally extends to unknown noise variance estimation. Sparse recovery results on both synthetic data and extended source direction-of-arrival estimation demonstrate improved accuracy and runtime performance compared to benchmark methods.

</details>


### [30] [Learning to Separate RF Signals Under Uncertainty: Detect-Then-Separate vs. Unified Joint Models](https://arxiv.org/abs/2602.04650)
*Ariel Rodrigez,Alejandro Lancho,Amir Weiss*

Main category: eess.SP

TL;DR: 提出统一联合模型(UJM)用于单通道射频信号处理，通过单一神经网络架构同时进行干扰检测与分离，相比传统的检测-分离策略(DTS)具有更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着射频频谱日益拥挤，通信信号必须共存，产生非高斯结构的异构干扰。现有数据驱动方法通常假设干扰类型已知，导致专用模型集合难以扩展。需要一种更可扩展的方法来处理未知干扰类型。

Method: 提出统一联合模型(UJM)，使用单一深度神经网络架构直接从接收信号中学习联合检测和分离。采用定制的UNet架构处理基带(复值)射频信号，并与传统的检测-分离策略(DTS)进行比较。

Result: 在合成和记录的干扰类型上，容量匹配的UJM能够匹配oracle辅助DTS的性能，适用于不同的信干噪比、干扰类型和星座阶数，包括训练和测试中类型不确定性比例不匹配的情况。

Conclusion: UJM作为DTS的可扩展实用替代方案，为更广泛机制下的统一分离开辟了新方向，证明了单一联合模型能够有效处理异构干扰恢复问题。

Abstract: The increasingly crowded radio frequency (RF) spectrum forces communication signals to coexist, creating heterogeneous interferers whose structure often departs from Gaussian models. Recovering the interference-contaminated signal of interest in such settings is a central challenge, especially in single-channel RF processing. Existing data-driven methods often assume that the interference type is known, yielding ensembles of specialized models that scale poorly with the number of interferers. We show that detect-then-separate (DTS) strategies admit an analytical justification: within a Gaussian mixture framework, a plug-in maximum a posteriori detector followed by type-conditioned optimal estimation achieves asymptotic minimum mean-square error optimality under a mild temporal-diversity condition. This makes DTS a principled benchmark, but its reliance on multiple type-specific models limits scalability. Motivated by this, we propose a unified joint model (UJM), in which a single deep neural architecture learns to jointly detect and separate when applied directly to the received signal. Using tailored UNet architectures for baseband (complex-valued) RF signals, we compare DTS and UJM on synthetic and recorded interference types, showing that a capacity-matched UJM can match oracle-aided DTS performance across diverse signal-to-interference-and-noise ratios, interference types, and constellation orders, including mismatched training and testing type-uncertainty proportions. These findings highlight UJM as a scalable and practical alternative to DTS, while opening new directions for unified separation under broader regimes.

</details>


### [31] [HFMCA: Orthonormal Feature Learning for EEG-based Brain Decoding](https://arxiv.org/abs/2602.04681)
*Yinghao Wang,Lintao Xu,Shujian Yu,Enzo Tartaglione,Van-Tam Nguyen*

Main category: eess.SP

TL;DR: 提出基于层次功能最大相关算法（HFMCA）的自监督框架，通过特征去相关和冗余减少学习正交EEG表示，在SEED和BCIC-2A数据集上超越现有自监督基线，显著提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: 脑电图（EEG）分析对脑机接口和神经科学至关重要，但EEG信号固有的噪声和高维度特性阻碍了有效的特征学习，需要开发能够捕获本质脑动力学并减少冗余的表示学习方法。

Method: 提出基于层次功能最大相关算法（HFMCA）的自监督框架，通过强制特征去相关和减少冗余来学习正交EEG表示，从而稳健地捕获各种EEG识别任务中的基本脑动力学。

Result: 在SEED和BCIC-2A两个基准数据集上验证，HFMCA预训练持续优于竞争的自监督基线，在SEED情感识别任务上提升2.71%，在BCIC-2A运动想象分类任务上提升2.57%，在跨被试泛化方面表现出色。

Conclusion: HFMCA框架通过自监督学习正交EEG表示，有效解决了EEG信号噪声和高维度问题，在多个EEG识别任务上实现了最先进的性能，显著提升了跨被试泛化能力。

Abstract: Electroencephalography (EEG) analysis is critical for brain-computer interfaces and neuroscience, but the intrinsic noise and high dimensionality of EEG signals hinder effective feature learning. We propose a self-supervised framework based on the Hierarchical Functional Maximal Correlation Algorithm (HFMCA), which learns orthonormal EEG representations by enforcing feature decorrelation and reducing redundancy. This design enables robust capture of essential brain dynamics for various EEG recognition tasks. We validate HFMCA on two benchmark datasets, SEED and BCIC-2A, where pretraining with HFMCA consistently outperforms competitive self-supervised baselines, achieving notable gains in classification accuracy. Across diverse EEG tasks, our method demonstrates superior cross-subject generalization under leave-one-subject-out validation, advancing state-of-the-art by 2.71\% on SEED emotion recognition and 2.57\% on BCIC-2A motor imagery classification.

</details>


### [32] [Knowledge Distillation for mmWave Beam Prediction Using Sub-6 GHz Channels](https://arxiv.org/abs/2602.04703)
*Sina Tavakolian,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 提出基于知识蒸馏的高效子6GHz信道-毫米波波束映射框架，用小型学生模型替代大型教师模型，减少99%参数和计算复杂度


<details>
  <summary>Details</summary>
Motivation: 毫米波高速移动环境中的波束成形需要大量训练开销，现有利用子6GHz信道预测毫米波波束的方法依赖大型深度学习模型，计算和内存需求过高

Method: 基于知识蒸馏技术，开发两种紧凑的学生DL架构：个体蒸馏策略和关系蒸馏策略，仅保留少量隐藏层但能模仿大型教师模型的性能

Result: 学生模型达到教师模型的波束预测精度和频谱效率，同时将可训练参数和计算复杂度降低99%

Conclusion: 提出的知识蒸馏框架为毫米波波束预测提供了一种计算高效的解决方案，在保持性能的同时大幅降低资源需求

Abstract: Beamforming in millimeter-wave (mmWave) high-mobility environments typically incurs substantial training overhead. While prior studies suggest that sub-6 GHz channels can be exploited to predict optimal mmWave beams, existing methods depend on large deep learning (DL) models with prohibitive computational and memory requirements. In this paper, we propose a computationally efficient framework for sub-6 GHz channel-mmWave beam mapping based on the knowledge distillation (KD) technique. We develop two compact student DL architectures based on individual and relational distillation strategies, which retain only a few hidden layers yet closely mimic the performance of large teacher DL models. Extensive simulations demonstrate that the proposed student models achieve the teacher's beam prediction accuracy and spectral efficiency while reducing trainable parameters and computational complexity by 99%.

</details>


### [33] [Resilient Channel Charting Under Varying Radio Link Availability](https://arxiv.org/abs/2602.04704)
*Jonas Pirkl,Jonathan Ott,Maximilian Stahlke,George Yammine,Tobias Feigl,Christopher Mutschler*

Main category: eess.SP

TL;DR: AdaPos是一种自适应定位架构，通过结合卷积特征提取和基于transformer的编码器，能够原生处理可变数量的信道测量输入，解决传统信道图绘制方法对固定输入尺寸的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 传统信道图绘制(CC)方法假设固定尺寸输入（如恒定天线数量），但在实际系统中天线可能故障、信号可能被阻挡或天线配置可能在切换时改变，导致固定输入架构脆弱。现有方法需要为每种天线配置训练单独模型，训练成本随阵列规模呈指数增长。

Method: AdaPos结合卷积特征提取和基于transformer的编码器，使用可学习的天线标识符和自注意力机制来融合任意CSI输入子集。通过新颖的训练策略，提供对单个天线故障和全阵列中断的弹性。

Result: 在两个公开真实世界数据集（SISO和MIMO）上的实验表明，AdaPos在缺失天线条件下保持最先进的精度，用一个统一模型替代了大约57个配置特定模型。

Conclusion: AdaPos为信道图绘制提供了一种灵活、弹性的解决方案，能够处理实际系统中常见的可变天线配置问题，显著减少了模型训练和维护的复杂性。

Abstract: Channel charting (CC) has become a key technology for RF-based localization, enabling unsupervised radio fingerprinting, even in non line of sight scenarios, with a minimum of reference position labels. However, most CC models assume fixed-size inputs, such as a constant number of antennas or channel measurements. In practical systems, antennas may fail, signals may be blocked, or antenna sets may change during handovers, making fixed-input architectures fragile. Existing radio-fingerprinting approaches address this by training separate models for each antenna configuration, but the resulting training effort scales prohibitively with the array size. We propose Adaptive Positioning (AdaPos), a CC architecture that natively handles variable numbers of channel measurements. AdaPos combines convolutional feature extraction with a transformer-based encoder using learnable antenna identifiers and self-attention to fuse arbitrary subsets of CSI inputs. Experiments on two public real-world datasets (SISO and MIMO) show that AdaPos maintains state-of-the-art accuracy under missing-antenna conditions and replaces roughly 57 configuration-specific models with a single unified model. With AdaPos and our novel training strategies, we provide resilience to both individual antenna failures and full-array outages.

</details>


### [34] [Safe-NEureka: a Hybrid Modular Redundant DNN Accelerator for On-board Satellite AI Processing](https://arxiv.org/abs/2602.04803)
*Riccardo Tedeschi,Luigi Ghionda,Alessandro Nadalini,Yvan Tortorella,Arpan Suravi Prasad,Luca Benini,Davide Rossi,Francesco Conti*

Main category: eess.SP

TL;DR: Safe-NEureka是一个用于卫星AI加速的混合模块冗余DNN加速器，支持冗余模式（DMR硬件恢复）和性能模式（最大化并行吞吐），在12nm工艺下实现96倍故障执行减少和15%面积开销。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星星座需要AI加速器来处理安全关键功能（如自主GNC，不容许错误）和性能关键处理（如高带宽传感器数据，可容忍偶尔错误），因此需要结合辐射故障防护和高吞吐量的解决方案。

Method: 提出Safe-NEureka混合模块冗余DNN加速器，采用两种工作模式：冗余模式使用双模块冗余（DMR）和硬件恢复机制；性能模式重新利用冗余数据路径最大化并行吞吐。内存接口采用ECC保护，控制器采用三模块冗余（TMR）。

Result: 在GlobalFoundries 12nm技术实现中，冗余模式下故障执行减少96倍，面积开销15%；性能模式下3x3密集卷积接近基线速度，吞吐量降低5%，效率降低11%（相比冗余模式的48%和53%）。

Conclusion: Safe-NEureka的灵活性确保了高开销仅用于关键任务，为空间应用提供了一个多功能解决方案，能够在辐射防护和高性能之间实现平衡。

Abstract: Low Earth Orbit (LEO) constellations are revolutionizing the space sector, with on-board Artificial Intelligence (AI) becoming pivotal for next-generation satellites. AI acceleration is essential for safety-critical functions such as autonomous Guidance, Navigation, and Control (GNC), where errors cannot be tolerated, and performance-critical processing of high-bandwidth sensor data, where occasional errors are tolerable. Consequently, AI accelerators for satellites must combine robust protection against radiation-induced faults with high throughput. This paper presents Safe-NEureka, a Hybrid Modular Redundant Deep Neural Network (DNN) accelerator for heterogeneous RISC-V systems. It operates in two modes: a redundancy mode utilizing Dual Modular Redundancy (DMR) with hardware-based recovery, and a performance mode repurposing redundant datapaths to maximize parallel throughput. Furthermore, its memory interface is protected by Error Correction Codes (ECCs), and the controller by Triple Modular Redundancy (TMR). Implementation in GlobalFoundries 12nm technology shows a 96 reduction in faulty executions in redundancy mode, with a manageable 15 area overhead. In performance mode, the architecture achieves near-baseline speeds on 3x3 dense convolutions with a 5 throughput and 11 efficiency reduction, compared to 48 and 53 in redundancy mode. This flexibility ensures high overheads are limited to critical tasks, establishing Safe-NEureka as a versatile solution for space applications.

</details>
