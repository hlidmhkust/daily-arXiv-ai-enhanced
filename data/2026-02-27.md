<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 3]
- [eess.SP](#eess.SP) [Total: 9]
- [cs.IT](#cs.IT) [Total: 6]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Deep Accurate Solver for the Geodesic Problem](https://arxiv.org/abs/2602.22275)
*Saar Huberman,Amit Bracha,Ron Kimmel*

Main category: eess.IV

TL;DR: 论文提出了一种基于深度学习的高阶精确测地距离计算方法，相比传统多边形网格近似方法，能达到三阶精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过多边形网格近似连续曲面计算测地距离，但这种方法最多只能达到二阶精度。需要开发更高精度的计算方法来改进测地距离的近似质量。

Method: 提出了一种基于神经网络的局部求解器，隐式近似连续曲面的结构。该方法结合了数值求解器（局部近似距离函数）和高效的因果排序方案，使用神经网络替代传统的局部求解器来提升精度。

Result: 提出的学习方法相比最佳可能的多面体近似和先前基于学习的方法具有更好的精度，达到了三阶精度，并提供了进一步改进的自举方法。

Conclusion: 基于深度学习的局部求解器能够显著提高测地距离计算的精度，达到三阶收敛率，为曲面距离计算提供了新的高阶精确方法。

Abstract: A common approach to compute distances on continuous surfaces is by considering a discretized polygonal mesh approximating the surface and estimating distances on the polygon. We show that exact geodesic distances restricted to the polygon are at most second-order accurate with respect to the distances on the corresponding continuous surface. By order of accuracy we refer to the convergence rate as a function of the average distance between sampled points. Next, a higher-order accurate deep learning method for computing geodesic distances on surfaces is introduced. Traditionally, one considers two main components when computing distances on surfaces: a numerical solver that locally approximates the distance function, and an efficient causal ordering scheme by which surface points are updated. Classical minimal path methods often exploit a dynamic programming principle with quasi-linear computational complexity in the number of sampled points. The quality of the distance approximation is determined by the local solver that is revisited in this paper. To improve state of the art accuracy, we consider a neural network-based local solver which implicitly approximates the structure of the continuous surface. We supply numerical evidence that the proposed learned update scheme provides better accuracy compared to the best possible polyhedral approximations and previous learning-based methods. The result is a third-order accurate solver with a bootstrapping-recipe for further improvement.

</details>


### [2] [Learning to reconstruct from saturated data: audio declipping and high-dynamic range imaging](https://arxiv.org/abs/2602.22279)
*Victor Sechaud,Laurent Jacques,Patrice Abry,Julián Tachella*

Main category: eess.IV

TL;DR: 提出一种自监督学习方法，用于从饱和（裁剪）测量中恢复音频和图像，无需地面真值数据，仅使用裁剪信号进行训练。


<details>
  <summary>Details</summary>
Motivation: 基于学习的方法在解决逆问题中很普遍，但在实际应用中常因缺乏训练所需的地面真值而受限。现有自监督方法大多局限于线性逆问题，需要扩展到非线性问题如从裁剪测量中恢复音频和图像。

Method: 假设信号分布对幅度变化近似不变，提出从饱和信号中学习的充分条件，并设计自监督损失函数来训练重建网络。该方法仅使用裁剪测量进行训练。

Result: 在音频和图像数据上的实验表明，该方法尽管仅依赖裁剪测量进行训练，但效果几乎与完全监督方法相当。

Conclusion: 成功将自监督学习扩展到非线性逆问题，为从饱和测量中恢复信号提供了一种有效的无监督解决方案，克服了实际应用中缺乏地面真值数据的限制。

Abstract: Learning based methods are now ubiquitous for solving inverse problems, but their deployment in real-world applications is often hindered by the lack of ground truth references for training. Recent self-supervised learning strategies offer a promising alternative, avoiding the need for ground truth. However, most existing methods are limited to linear inverse problems. This work extends self-supervised learning to the non-linear problem of recovering audio and images from clipped measurements, by assuming that the signal distribution is approximately invariant to changes in amplitude. We provide sufficient conditions for learning to reconstruct from saturated signals alone and a self-supervised loss that can be used to train reconstruction networks. Experiments on both audio and image data show that the proposed approach is almost as effective as fully supervised approaches, despite relying solely on clipped measurements for training.

</details>


### [3] [HARU-Net: Hybrid Attention Residual U-Net for Edge-Preserving Denoising in Cone-Beam Computed Tomography](https://arxiv.org/abs/2602.22544)
*Khuram Naveed,Ruben Pauwels*

Main category: eess.IV

TL;DR: 提出HARU-Net用于CBCT去噪，结合混合注意力机制和残差学习，在尸体数据集上训练，性能优于现有方法且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: CBCT在低剂量采集时会产生强噪声，降低软组织可见性和精细解剖结构清晰度。传统去噪方法难以有效抑制噪声同时保留边缘，而深度学习方法受限于高分辨率CBCT训练数据稀缺。

Method: 提出混合注意力残差U-Net（HARU-Net），包含三个核心组件：1) 跳跃连接中的混合注意力变换器块（HAB）用于选择性强调重要解剖特征；2) 瓶颈处的残差混合注意力变换器组（RHAG）增强全局上下文建模和长程特征交互；3) 残差学习卷积块实现更深层、更稳定的特征提取。

Result: HARU-Net在PSNR（37.52 dB）、SSIM（0.9557）和GMSD（0.1084）指标上均优于SwinIR和Uformer等SOTA方法，且计算成本显著低于现有方法。

Conclusion: HARU-Net提供了一种有效且临床可靠的CBCT去噪方法，计算效率高，为改善低剂量CBCT成像的诊断质量提供了实用进展。

Abstract: Cone-beam computed tomography (CBCT) is widely used in dental and maxillofacial imaging, but low-dose acquisition introduces strong, spatially varying noise that degrades soft-tissue visibility and obscures fine anatomical structures. Classical denoising methods struggle to suppress noise in CBCT while preserving edges. Although deep learning-based approaches offer high-fidelity restoration, their use in CBCT denoising is limited by the scarcity of high-resolution CBCT data for supervised training. To address this research gap, we propose a novel Hybrid Attention Residual U-Net (HARU-Net) for high-quality denoising of CBCT data, trained on a cadaver dataset of human hemimandibles acquired using a high-resolution protocol of the 3D Accuitomo 170 (J. Morita, Kyoto, Japan) CBCT system. The novel contribution of this approach is the integration of three complementary architectural components: (i) a hybrid attention transformer block (HAB) embedded within each skip connection to selectively emphasize salient anatomical features, (ii) a residual hybrid attention transformer group (RHAG) at the bottleneck to strengthen global contextual modeling and long-range feature interactions, and (iii) residual learning convolutional blocks to facilitate deeper, more stable feature extraction throughout the network. HARU-Net consistently outperforms state-of-the-art (SOTA) methods including SwinIR and Uformer, achieving the highest PSNR (37.52 dB), highest SSIM (0.9557), and lowest GMSD (0.1084). This effective and clinically reliable CBCT denoising is achieved at a computational cost significantly lower than that of the SOTA methods, offering a practical advancement toward improving diagnostic quality in low-dose CBCT imaging.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [4] [FM-RME: Foundation Model Empowered Radio Map Estimation](https://arxiv.org/abs/2602.22231)
*Dong Yang,Yue Wang,Songyang Zhang,Yingshu Li,Zhipeng Cai,Zhi Tian*

Main category: eess.SP

TL;DR: 提出FM-RME基础模型，通过自监督预训练实现多维无线电地图估计的零样本泛化


<details>
  <summary>Details</summary>
Motivation: 传统无线电地图估计方法无法捕捉复杂频谱环境的多维动态特性，现有数据驱动方法忽略物理先验知识，在数据效率和多维场景中受限

Method: 构建几何感知特征提取模块编码物理传播对称性（平移和旋转不变性），结合基于注意力的神经网络学习跨时空谱域的长程相关性，采用掩码自监督多维预训练策略

Result: FM-RME在多样化数据集上表现出优异的学习性能，具备超越现有方法的零样本泛化能力，支持空间、时间和频谱维度的估计

Conclusion: FM-RME作为基础模型，通过结合物理先验知识和自监督学习，实现了高效的多维无线电地图估计和零样本泛化

Abstract: Traditional radio map estimation (RME) techniques fail to capture multi-dimensional and dynamic characteristics of complex spectrum environments. Recent data-driven methods achieve accurate RME in spatial domain, but ignore physical prior knowledge of radio propagation, limiting data efficiency especially in multi-dimensional scenarios. To overcome such limitations, we propose a new foundation model, characterized by self-supervised pre-training on diverse data for zero-shot generalization, enabling multi-dimensional radio map estimation (FM-RME). Specifically, FM-RME builds an effective synergy of two core components: a geometry-aware feature extraction module that encodes physical propagation symmetries, i.e., translation and rotation invariance, as inductive bias, and an attention-based neural network that learns long-range correlations across the spatial-temporal-spectral domains. A masked self-supervised multi-dimensional pre-training strategy is further developed to learn generalizable spectrum representations across diverse wireless environments. Once pre-trained, FM-RME supports zero-shot inference for multi-dimensional RME, including spatial, temporal, and spectral estimation, without scenario-specific retraining. Simulation results verify that FM-RME exhibits desired learning performance across diverse datasets and zero-shot generalization capabilities beyond existing RME methods.

</details>


### [5] [Full Waveform Inversion using the Wasserstein metric for ultrasound transducer array based NDT](https://arxiv.org/abs/2602.22378)
*Daniel Rossato,Thiago Alberto Rigo Passarin,Gustavo Pinto Pires,Daniel Rodrigues Pipa*

Main category: eess.SP

TL;DR: 该论文提出在超声全波形反演中使用Wasserstein距离替代传统L2损失，以解决超声数据低频缺失导致的周期跳跃问题，并通过GPU实现验证了方法的有效性和计算可行性。


<details>
  <summary>Details</summary>
Motivation: 传统超声成像方法假设线性直接模型，忽略了非线性现象（如多次反射）。全波形反演（FWI）能考虑所有非线性效应，但应用于超声数据时，由于低频成分缺失，L2损失函数容易陷入局部最小值（周期跳跃问题）。

Method: 使用平方Wasserstein（W2）最优传输距离作为采集数据与合成数据之间的度量，推导了W2损失的伴随声场解析解，采用低内存策略避免存储完整模拟场，并实现了GPU（CUDA）加速。

Result: 在六个原型案例中，五个案例的W2方法像素级平方误差比L2方法低至少一个数量级，而梯度计算时间仅增加不超过2%。

Conclusion: W2损失函数适用于超声相控阵全波形反演，能有效解决周期跳跃问题，且计算上可行，为超声无损评估提供了更准确的成像方法。

Abstract: Ultrasonic imaging methods often assume linear direct models, while in reality, many nonlinear phenomena are present, e.g. multiple reflections. A family of imaging methods called Full Waveform Inversion (FWI), which has been developed in the field of seismic imaging, uses full acoustic wave simulations as direct models, taking into account virtually all nonlinearities, which can ultimately enhance the accuracy of ultrasonic imaging. However, the problem of cycle skipping -- the existence of many local minima of the Least Squares (L2) misfit function due to the oscillatory nature of the signals -- is worsened when FWI is applied to ultrasound data because of a lack of low-frequency components. In this paper, we explore the use of the squared Wasserstein (W2) Optimal Transport Distance as the metric for the misfit between the acquired and the synthetic data, applying the method to Nondestructive Evaluation with ultrasonic phased arrays. An analytical continuous time-domain derivation of the adjoint acoustic field related to the W2 misfit is presented and used for the computation of the gradients. To cope with the computational burden of FWI, we apply a low-memory strategy that allows for the computation of the gradients without the storage of the full simulated fields. The GPU implementation of the method (in CUDA language) is detailed, and the source code is made available. Six prototypical cases are presented, and the corresponding sound speed maps are reconstructed with FWI using both the L2 and the W2 misfit functionals. In five of the six cases, the pixel-wise sum of squared errors obtained with W2 was at least one order of magnitude lower than that obtained with W2, with an increase in the gradient computation time not exceeding 2\%. The results highlight both the adequacy of the W2 misfit for ultrasonic FWI with phased arrays and its computational feasibility.

</details>


### [6] [CSI-RFF: Leveraging Micro-Signals on CSI for RF Fingerprinting of Commodity WiFi](https://arxiv.org/abs/2602.22738)
*Ruiqi Kong,He Chen*

Main category: eess.SP

TL;DR: CSI-RFF框架利用CSI曲线中的微信号实现商用WiFi设备的射频指纹识别，通过信号空间提取技术分离信道失真和微CSI，实现99%攻击检测率和0%误报率


<details>
  <summary>Details</summary>
Motivation: 传统射频指纹识别方法通常需要专用硬件，而商用WiFi设备的射频指纹识别面临挑战。本文旨在利用CSI中的微信号实现商用WiFi设备的开放集认证，为移动机器人等应用提供安全访问控制。

Method: 提出CSI-RFF框架，首先发现CSI中的微信号（micro-CSI）可作为射频指纹，然后开发信号空间提取技术分离信道失真和微CSI，最后基于提取的稳定微CSI特征进行设备认证。

Result: 实验表明micro-CSI具有设备特异性且随时间稳定，在静态和移动条件下，使用20个CSI测量构建指纹时，认证算法能达到接近99%的平均攻击检测率和0%的误报率。

Conclusion: CSI-RFF成功利用商用WiFi设备的CSI微信号实现有效的射频指纹识别，为开放集认证提供了新方法，在移动机器人访问控制等应用场景中表现出优异性能。

Abstract: This paper introduces CSI-RFF, a new framework that leverages micro-signals embedded within Channel State Information (CSI) curves to realize Radio-Frequency Fingerprinting of commodity off-the-shelf (COTS) WiFi devices for open-set authentication. The micro-signals that serve as RF fingerprints are termed ``micro-CSI''. Through experimentation, we have found that the presence of micro-CSI can primarily be attributed to imperfections in the RF circuitry. Furthermore, this characteristic signal is detectable in WiFi 4/5/6 network interface cards (NICs). We have conducted further experiments to determine the most effective CSI collection configurations to stabilize micro-CSI. Yet, extracting micro-CSI for authentication purposes poses a significant challenge. This complexity arises from the fact that CSI measurements inherently include both micro-CSI and the distortions introduced by wireless channels. These two elements are intricately intertwined, making their separation non-trivial. To tackle this challenge, we have developed a signal space-based extraction technique for line-of-sight (LoS) scenarios, which can effectively separate the distortions caused by wireless channels and micro-CSI. Over the course of our comprehensive CSI data collection period extending beyond one year, we found that the extracted micro-CSI displays unique characteristics specific to each WiFi device and remains invariant over time. This establishes micro-CSI as a suitable candidate for device fingerprinting. Finally, we conduct a case study focusing on area access control for mobile robots. Our experimental results demonstrate that the micro-CSI-based authentication algorithm can achieve an average attack detection rate close to 99% with a false alarm rate of 0% in both static and mobile conditions when using 20 CSI measurements to construct one fingerprint.

</details>


### [7] [A guided residual search for nonlinear state-space identification](https://arxiv.org/abs/2602.22964)
*Merijn Floren,Jan Swevers*

Main category: eess.SP

TL;DR: 提出一种分解非线性状态空间模型参数估计问题的方法，通过线性模型初始化、残差动态引导搜索和多点射击优化，提高估计的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 非线性状态空间模型的参数估计通常是一个高度非凸的优化问题，容易导致收敛缓慢和次优解，需要提高估计过程的可靠性和效率。

Method: 将整体优化问题分解为一系列可处理的子问题：1) 基于初始线性模型；2) 通过引导残差搜索估计非线性残差动态；3) 使用多点射击优化进行细化。

Result: 在两个基准测试上的实验结果表明，相对于最先进的黑盒方法具有竞争性性能，并且相比朴素初始化方法收敛性有所改善。

Conclusion: 通过分解优化问题和分阶段估计策略，能够有效提高非线性状态空间模型参数估计的可靠性和效率，避免传统方法中的收敛问题。

Abstract: Parameter estimation of nonlinear state-space models from input-output data typically requires solving a highly non-convex optimization problem prone to slow convergence and suboptimal solutions. This work improves the reliability and efficiency of the estimation process by decomposing the overall optimization problem into a sequence of tractable subproblems. Based on an initial linear model, nonlinear residual dynamics are first estimated via a guided residual search and subsequently refined using multiple-shooting optimization. Experimental results on two benchmarks demonstrate competitive performance relative to state-of-the-art black-box methods and improved convergence compared to naive initialization.

</details>


### [8] [Digital Twin-Based Beamforming for Interference Mitigation in AF Relay MIMO Systems](https://arxiv.org/abs/2602.22991)
*Alexander Bonora,Anna V. Guglielmi,Davide Scazzoli,Marco Giordani,Maurizio Magarini,Vineeth Teeda,Stefano Tomasin*

Main category: eess.SP

TL;DR: 提出预测辅助优化(PAO)框架，用于AF中继辅助多用户MIMO系统中的波束成形设计，仅依赖接收功率测量，无需完整CSI，通过神经网络预测发射机位置和数字孪生引导优化。


<details>
  <summary>Details</summary>
Motivation: MIMO系统中的波束成形需要考虑干扰抑制，但通常需要准确的CSI，而由于信道变化、反馈开销或硬件限制，CSI往往难以获取。AF中继被动转发信号而不进行测量，无法获取完整CSI。

Method: 提出PAO框架：1) 监督学习神经网络基于信号观测预测发射机位置；2) 数字孪生引导的优化算法在模拟无线电环境中迭代优化中继波束方向。框架仅依赖接收功率测量，无需完整CSI。

Result: 在定制毫米波实验平台上使用实际测量验证框架，展示了定位精度与波束成形性能之间的权衡。PAO在存在定位误差时仍保持鲁棒性，同时减少了对实际测量的需求。

Conclusion: PAO框架为AF中继辅助MIMO系统提供了一种有效的波束成形解决方案，在CSI不可靠或不可用时仍能工作，通过预测和数字孪生技术实现优化，具有实际应用价值。

Abstract: Beamforming in multiple-input multiple-output (MIMO) systems should take interference mitigation into account. However, for beamform design, accurate channel state information (CSI) is needed, which is often difficult to obtain due to channel variability, feedback overhead, or hardware constraints. For example, amplify-and-forward (AF) relays passively forward signals without measurement, precluding full CSI acquisition to and from the relay. To address these issues, this paper introduces a novel prediction-assisted optimization (PAO) framework for beamform design in AF relay-assisted multiuser MIMO systems. The proposed solution in the AF relay aims at maximizing the signal-plus-interference-to-noise ratio (SINR). Unlike other methods, PAO relies solely on received power measurements, making it suitable for scenarios where CSI is unreliable or unavailable. PAO consists of two stages: a supervised-learning-based neural network (NN) that predicts the positions of transmitters using signal observations, and an optimization algorithm, guided by a digital twin (DT), that iteratively refines the beam direction of the relay in a simulated radio environment. As a key contribution, we validate the proposed framework using realistic measurements collected on a custom-built experimental millimeter wave (mmWave) platform, which enables training of the NN model under practical wireless conditions. The estimated information is then used to update the digital twin with knowledge of the surrounding environment, enabling online optimization. Numerical results show the trade-off between localization accuracy and beamforming performance and confirm that PAO maintains robustness even in the presence of localization errors while reducing the need for real-world measurements.

</details>


### [9] [Scattering Transform for Auditory Attention Decoding](https://arxiv.org/abs/2602.23003)
*René Pallenberg,Fabrice Katzberg,Alfred Mertins,Marco Maass*

Main category: eess.SP

TL;DR: 提出使用散射变换作为听觉注意解码的新预处理方法，相比传统方法在特定条件下能显著提升性能


<details>
  <summary>Details</summary>
Motivation: 解决助听器中的鸡尾酒会问题，传统听觉注意解码方法大多使用相同的预处理方法，需要寻找更优的替代方案

Method: 提出使用两层散射变换作为预处理方法，与传统滤波器组、同步压缩短时傅里叶变换和常用预处理方法进行比较，在KUL和DTU数据集上使用CNN、LSTM、Transformer/图神经网络等模型进行多任务分类评估

Result: 散射变换在KUL数据集上对受试者相关条件能显著提升性能，在DTU数据集上仅对部分模型或训练数据较多时有效，表明散射变换能提取额外相关信息

Conclusion: 散射变换作为听觉注意解码的预处理方法具有潜力，特别是在受试者相关条件下能提供性能优势，但其效果受数据集和训练数据量影响

Abstract: The use of hearing aids will increase in the coming years due to demographic change. One open problem that remains to be solved by a new generation of hearing aids is the cocktail party problem. A possible solution is electroencephalography-based auditory attention decoding. This has been the subject of several studies in recent years, which have in common that they use the same preprocessing methods in most cases. In this work, in order to achieve an advantage, the use of a scattering transform is proposed as an alternative to these preprocessing methods. The two-layer scattering transform is compared with a regular filterbank, the synchrosqueezing short-time Fourier transform and the common preprocessing. To demonstrate the performance, the known and the proposed preprocessing methods are compared for different classification tasks on two widely used datasets, provided by the KU Leuven (KUL) and the Technical University of Denmark (DTU). Both established and new neural-network-based models, CNNs, LSTMs, and recent Transformer/graph-based models are used for classification. Various evaluation strategies were compared, with a focus on the task of classifying speakers who are unknown from the training. We show that the two-layer scattering transform can significantly improve the performance for subject-related conditions, especially on the KUL dataset. However, on the DTU dataset, this only applies to some of the models, or when larger amounts of training data are provided, as in 10-fold cross-validation. This suggests that the scattering transform is capable of extracting additional relevant information.

</details>


### [10] [A Scaling Law for Bandwidth Under Quantization](https://arxiv.org/abs/2602.23252)
*Maximilian Kalcher,Tena Dubcek*

Main category: eess.SP

TL;DR: 该论文推导了ADC位深与1/f^α信号有效带宽之间的缩放定律，表明每增加1位可将截止频率扩展2^{2/α}倍，对于α=2近似每比特带宽翻倍。


<details>
  <summary>Details</summary>
Motivation: 研究ADC量化噪声对具有1/f^α功率谱信号的带宽限制问题，量化噪声会引入平坦的噪声基底，与衰减的信号频谱相交形成有效截止频率，需要量化这种关系。

Method: 推导量化噪声基底Δ^2/(6f_s)与1/f^α信号频谱相交的数学关系，建立位深N与有效截止频率f_c的缩放定律，并通过合成信号（α∈{1.5,2.0,2.5}）和真实EEG数据进行验证。

Result: 理论预测误差低于3%（使用理论噪声基底）和约14%（使用经验估计噪声基底），验证了缩放定律的有效性。对于α=2，每增加1位ADC位深，有效带宽近似翻倍。

Conclusion: 建立了ADC位深与1/f^α信号有效带宽之间的定量缩放关系，为ADC设计选择提供了理论指导，特别是在生物信号（如EEG）等具有1/f特征的应用中。

Abstract: We derive a scaling law relating ADC bit depth to effective bandwidth for signals with $1/f^α$ power spectra. Quantization introduces a flat noise floor whose intersection with the declining signal spectrum defines an effective cutoff frequency $f_c$. We show that each additional bit extends this cutoff by a factor of $2^{2/α}$, approximately doubling bandwidth per bit for $α= 2$. The law requires that quantization noise be approximately white, a condition whose minimum bit depth $N_{\min}$ we show to be $α$-dependent. Validation on synthetic $1/f^α$ signals for $α\in \{1.5, 2.0, 2.5\}$ yields prediction errors below 3\% using the theoretical noise floor $Δ^2/(6f_s)$, and approximately 14\% when the noise floor is estimated empirically from the quantized signal's spectrum. We illustrate practical implications on real EEG data.

</details>


### [11] [Analog Time Multiplexing for Digital-to-Analog Conversion](https://arxiv.org/abs/2602.23284)
*Juana M. Martínez-Heredia,Alfredo P. Vega-Leal*

Main category: eess.SP

TL;DR: 该论文提出在模拟域进行时间复用，以解决Sigma Delta调制DAC的信号带宽限制问题，从而提高对动态效应的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于Sigma Delta调制的数模转换器(DAC)的信号带宽受限于速度约束。传统的时间交织技术通过在数字域进行时间复用，虽然能降低时钟频率，但仍存在动态效应问题。

Method: 提出在模拟域而非数字域进行时间复用。将原始架构替换为M个并行路径，这些路径以M倍降低的频率工作，然后在模拟域进行时间复用，最后通过高速时钟的DAC转换为模拟信号。

Result: 通过在模拟域进行时间复用，实现了对动态效应的鲁棒性，提高了系统的稳定性和性能。

Conclusion: 模拟域时间复用是一种有效的技术，能够解决Sigma Delta调制DAC的速度限制问题，同时增强系统对动态效应的抵抗能力。

Abstract: The signal bandwidth of Digital to Analog Converters based on Sigma Delta Modulation is limited by speed constrains. Time-Interleaving allows coping with complexity vs. speed by replacing the original architecture by M parallel paths. These path are clocked at a frequency M times smaller and their digital outputs time multiplexed. This is then converted to analog by means of a Digital to Analog Converter clocked at the high rate. This preprint proposes that time multiplexing be performed in the analog domain. As a result robustness against dynamic effects is achieved.

</details>


### [12] [CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons](https://arxiv.org/abs/2602.23338)
*Kyle D. Massingill,Tyler M. Karasinski,Sean Bryan,Michael Baricuatro,Daniel Bliss,Delondrae Carter,Walter Goodwin,Jonathan Greenfield,Christopher Groppi,Jae Joiner,Philip Mauskopf,Philip Rybak,Scott Smas,Roshni Suresh,Joesph Tinlin,Bianca Wullen,Peter Wullen*

Main category: eess.SP

TL;DR: CubeSounder：一种用于水汽辐射测量的低成本小型微波光谱仪，通过被动波导滤波器组实现，已在商业平流层气球飞行中成功演示。


<details>
  <summary>Details</summary>
Motivation: 微波探测是全球数值天气预报的主要驱动力，但受限于传统微波仪器的可扩展性。现代加工技术和商用微波组件使得设计低尺寸、重量、功耗和成本（SWaP-C）的微波光谱仪成为可能，同时保持宽带宽性能。

Method: 开发了CubeSounder光谱仪，专门用于水汽辐射测量，采用被动波导滤波器组技术。包括原型开发、高空气球载荷设计，并在商业平流层气球飞行中进行演示。重点介绍了定制毫米波滤波器组的仿真和制造过程。

Result: 成功在商业平流层气球飞行中演示了CubeSounder系统，收集了初始数据，验证了低SWaP-C微波光谱仪的设计可行性。

Conclusion: CubeSounder展示了利用现代制造技术和商用组件开发低成本、小型化微波光谱仪的可行性，为可扩展的微波探测系统提供了新途径，特别是在水汽辐射测量应用方面。

Abstract: Microwave sounding is the leading driver of global numerical weather forecasting, but is limited by the scalability of such instruments. With modern machining and commercial microwave components, it is now possible to design low size, weight, power, and cost (SWaP-C) microwave spectrometers while maintaining wide bandwidth performance. Here we report on the status of CubeSounder, a spectrometer tailored for water vapor radiometry that utilizes passive wave guide filter banks. After developing a prototype and high altitude balloon payload, we demonstrated CubeSounder on commercial stratospheric balloon flights. We report on our design process, especially the simulation and fabrication of the custom millimeter-wave filter banks. We also report the initial results of the data collected from the balloon flights.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [13] [Queue occupancy and server size distribution of a queue length dependent vacation queue with an optional service](https://arxiv.org/abs/2602.22295)
*Ashish Verma,Sourav Pradhan*

Main category: cs.IT

TL;DR: 分析具有单次和多次休假的无限缓冲区离散时间批量到达队列系统，该系统采用两阶段服务（基本服务和可选服务），适用于现代通信系统。


<details>
  <summary>Details</summary>
Motivation: 离散时间排队系统在现代通信系统中具有高度适用性，能够提供自适应数据包处理、拥塞控制安全/检查、节能操作，并支持5G、物联网和边缘计算环境中常见的突发流量。需要分析具有两阶段服务的批量到达队列系统。

Method: 分析无限缓冲区离散时间批量到达队列，采用单次和多次休假策略，客户以批量方式在两阶段服务中处理：第一阶段基本服务（FES）和第二阶段可选服务（SOS）。推导了FES和SOS完成后等待传输数据包数量与正在处理数据包数量的联合分布的双变量概率生成函数。

Result: 建立了任意时隙的完整联合分布，包括休假完成状态。通过数值示例展示了所提框架的适用性，包括离散相位型服务时间分布的例子。通过图形表示研究了关键参数对边际系统概率和不同性能指标的敏感性分析。

Conclusion: 该研究为具有两阶段服务和休假策略的离散时间批量到达队列系统提供了完整的数学分析框架，适用于现代通信系统中的自适应数据包处理、安全检查和节能操作等应用场景。

Abstract: The discrete time queueing system is highly applicable to modern telecommunication systems, where it provides adaptive packet handling, congestion controlled security/inspection, energy efficient operation, and supports bursty traffic common in 5G, Internet of Things (IoT), and edge computing environments. In this article, we analyze an infinite-buffer discrete-time batch-arrival queue with single and multiple vacation policy where customers are served in batches, in two phases, namely first essential service (FES) and second optional service (SOS). In such systems, the FES corresponds to basic data processing or packet routing, while SOS represents secondary tasks such as encryption, error checking, data compression, or deep packet inspection that may not be necessary for every packet. Here, we derive the bivariate probability generating functions for the joint distribution of the number of packets waiting for transmission and the number are being processed immediately after the completion of both the FES and SOS. Furthermore, the complete joint distribution at arbitrary time slots, including vacation completion states, is established. Numerical illustrations demonstrate the applicability of the proposed framework, including an example with discrete phase type service time distribution. Finally, the sensitivity analysis of the key parameters on marginal system's probabilities and different performance measures have been investigated through several graphical representations.

</details>


### [14] [On the Computation Rate of All-Reduce](https://arxiv.org/abs/2602.22482)
*Yufeng Zhou,Hua Sun*

Main category: cs.IT

TL;DR: 论文研究了All-Reduce问题的计算速率，提出了基于割集的上界和基于时间共享的线性规划下界，并在特定网络拓扑中得到了最优解或接近最优的界。


<details>
  <summary>Details</summary>
Motivation: 研究All-Reduce问题在任意带宽并行链路网络中的计算速率优化，旨在为分布式计算中的求和操作提供理论性能界限。

Method: 1. 提出割集上界；2. 基于时间共享的线性规划下界（针对先Reduce后Broadcast的方案）；3. 将一般界限应用于特定网络拓扑（循环、完全、超立方体网络）。

Result: 1. 为特定网络类别获得了最优计算速率；2. 对于循环、完全和超立方体网络，获得了已知最佳速率界限（上界不超过下界的两倍）。

Conclusion: 论文建立了All-Reduce问题的理论性能界限框架，为实际分布式系统中的求和操作提供了性能分析和优化指导。

Abstract: In the All-Reduce problem, each one of the K nodes holds an input and wishes to compute the sum of all K inputs through a communication network where each pair of nodes is connected by a parallel link with arbitrary bandwidth. The computation rate of All-Reduce is defined as the number of sum instances that can be computed over each network use. For the computation rate, we provide a cut-set upper bound and a linear programming lower bound based on time (bandwidth) sharing over all schemes that first perform Reduce (aggregating all inputs at one node) and then perform Broadcast (sending the sum from that node to all other nodes). Specializing the two general bounds gives us the optimal computation rate for a class of communication networks and the best-known rate bounds (where the upper bound is no more than twice of the lower bound) for cyclic, complete, and hypercube networks.

</details>


### [15] [A Thermodynamic Structure of Asymptotic Inference](https://arxiv.org/abs/2602.22605)
*Willy Wong*

Main category: cs.IT

TL;DR: 论文提出了一个用于渐近推断的热力学框架，将样本量和参数方差定义为状态空间，其中香农信息扮演熵的角色，并推导出类似热力学定律的信息不等式。


<details>
  <summary>Details</summary>
Motivation: 建立统计推断与热力学之间的形式对应关系，将信息论概念（如香农信息）纳入热力学框架，为统计推断提供新的物理视角和数学结构。

Method: 构建一个热力学框架，其中样本量和参数方差定义状态空间，香农信息作为熵，通过积分因子组织其变化形成类似热力学第一定律的平衡方程。

Result: 推导出类似反向第二定律的循环不等式、类似第三定律的表示噪声下熵的下界、最优推断路径、信息增益的全局界限，以及类似卡诺效率的信息效率，其根本受噪声下限限制。

Conclusion: 该框架表明，系综物理和推断物理构成了在统一热力学描述中沿相反方向演化的影子过程，de Bruijn恒等式和I-MMSE关系在Gaussian极限情况下作为同一热力学结构的坐标投影出现。

Abstract: A thermodynamic framework for asymptotic inference is developed in which sample size and parameter variance define a state space. Within this description, Shannon information plays the role of entropy, and an integrating factor organizes its variation into a first-law-type balance equation. The framework supports a cyclic inequality analogous to a reversed second law, derived for the estimation of the mean. A non-trivial third-law-type result emerges as a lower bound on entropy set by representation noise. Optimal inference paths, global bounds on information gain, and a natural Carnot-like information efficiency follow from this structure, with efficiency fundamentally limited by a noise floor. Finally, de Bruijn's identity and the I-MMSE relation in the Gaussian-limit case appear as coordinate projections of the same underlying thermodynamic structure. This framework suggests that ensemble physics and inferential physics constitute shadow processes evolving in opposite directions within a unified thermodynamic description.

</details>


### [16] [Multi-modal Data Driven Virtual Base Station Construction for Massive MIMO Beam Alignment](https://arxiv.org/abs/2602.22796)
*Yijie Bian,Wei Guo,Jie Yang,Shenghui Song,Jun Zhang,Shi Jin,Khaled B. Letaief*

Main category: cs.IT

TL;DR: 提出一个可解释的框架，在混合视距和非视距传播环境中进行波束对齐，利用多模态数据构建虚拟基站，实现低训练开销的波束管理。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO是实现第六代网络高数据速率的关键技术，但其性能依赖于有效的波束管理，而传统方法训练开销大。特别是在混合视距和非视距传播环境中，波束对齐更具挑战性。

Method: 利用多模态数据（如3D LiDAR点云）构建虚拟基站，这些VBS是基站在反射表面上的镜像图像。基于VBS开发波束对齐方案，包括粗粒度信道重建和部分波束训练。

Result: 数值结果表明，所提方法在频谱效率方面达到接近最优的性能，同时显著降低训练开销。

Conclusion: 提出的可解释框架通过虚拟基站提供无线环境的稀疏空间表示，在混合传播环境中实现了高效波束对齐，为大规模MIMO系统提供了实用的波束管理解决方案。

Abstract: Massive multiple-input multiple-output (MIMO) is a key enabler for the high data rates required by the sixth-generation networks, yet its performance hinges on effective beam management with low training overhead. This paper proposes an interpretable framework to tackle beam alignment in mixed line-of-sight (LoS) and non-line-of-sight (NLoS) propagation environments. Our approach utilizes multi-modal data to construct virtual base stations (VBSs), which are geometrically defined as mirror images of the base station across reflecting surfaces reconstructed from 3D LiDAR points. These VBSs provide a sparse and spatial representation of the dominant features of the wireless environment. Based on the constructed VBSs, we develop a VBS-assisted beam alignment scheme comprising coarse channel reconstruction followed by partial beam training. Numerical results demonstrate that the proposed method achieves near-optimal performance in terms of spectral efficiency.

</details>


### [17] [Semantic Communication Through the Lens of Context-Dependent Channel Modeling](https://arxiv.org/abs/2602.22934)
*Javad Gholipour,Rafael F. Schaefer,Gerhard P. Fettweis*

Main category: cs.IT

TL;DR: 本文研究语义通信中语义噪声问题，假设理想物理信道，引入虚拟状态相关信道建模，分析语义编码器表示能力，推导容量结果和可达速率。


<details>
  <summary>Details</summary>
Motivation: 语义通信作为下一代网络有前景的范式，但仍存在基本挑战未解决。本文针对语义噪声仅来自语义信道（假设理想物理信道）的特殊子类问题进行研究。

Method: 基于语义通信的概率模型，利用上下文概念，引入虚拟状态相关信道建模系统，其中状态代表上下文在通信中起关键作用。分析语义编码器的表示能力，探索存在语义噪声的各种语义通信场景。

Result: 推导了某些情况下的容量结果和其他情况下的可达速率，为语义通信系统设计提供了理论依据。

Conclusion: 通过引入虚拟状态相关信道模型，本文为语义通信中语义噪声问题的分析提供了理论框架，推导的容量结果和可达速率对语义通信系统设计具有指导意义。

Abstract: Semantic communication has emerged as a promising paradigm for next-generation networks, yet several fundamental challenges remain unresolved. Building on the probabilistic model of semantic communication and leveraging the concept of context, this paper examines a specific subclass of semantic communication problems, where semantic noise originates solely from the semantic channel, assuming an ideal physical channel. To model this system, we introduce a virtual state-dependent channel, where the state-representing context-plays a crucial role in shaping communication. We further analyze the representational capability of the semantic encoder and explore various semantic communication scenarios in the presence of semantic noise, deriving capacity results for some cases and achievable rates for others.

</details>


### [18] [Frequency-Ordered Tokenization for Better Text Compression](https://arxiv.org/abs/2602.22958)
*Maximilian Kalcher*

Main category: cs.IT

TL;DR: 提出频率有序分词技术，通过利用自然语言词元的幂律分布特性（Zipf定律），对文本进行预处理以提升无损压缩效果。


<details>
  <summary>Details</summary>
Motivation: 自然语言文本中词元频率遵循幂律分布（Zipf定律），高频词元出现频繁但通常使用较大标识符，若能重新排序使高频词元获得小整数标识符，可提升压缩效率。

Method: 使用字节对编码（BPE）对文本分词，根据词元频率重新排序词汇表（高频词元获得小整数标识符），然后用变长整数编码结果，最后输入标准压缩器。

Result: 在enwik8（100MB维基百科）上，相比原始压缩：zlib提升7.08个百分点，LZMA提升1.69个百分点，zstd提升0.76个百分点（均包含词汇表开销）。在enwik9（1GB）及中文、阿拉伯文文本上效果一致。预处理还加速了计算密集型压缩算法：包含预处理的总时间比原始zstd-22快3.1倍，比原始LZMA快2.4倍。

Conclusion: 频率有序分词是一种简单有效的文本预处理技术，能显著提升无损压缩效果并加速压缩过程，代码实现仅需不到50行。

Abstract: We present frequency-ordered tokenization, a simple preprocessing technique that improves lossless text compression by exploiting the power-law frequency distribution of natural language tokens (Zipf's law). The method tokenizes text with Byte Pair Encoding (BPE), reorders the vocabulary so that frequent tokens receive small integer identifiers, and encodes the result with variable-length integers before passing it to any standard compressor. On enwik8 (100 MB Wikipedia), this yields improvements of 7.08 percentage points (pp) for zlib, 1.69 pp for LZMA, and 0.76 pp for zstd (all including vocabulary overhead), outperforming the classical Word Replacing Transform. Gains are consistent at 1 GB scale (enwik9) and across Chinese and Arabic text. We further show that preprocessing accelerates compression for computationally expensive algorithms: the total wall-clock time including preprocessing is 3.1x faster than raw zstd-22 and 2.4x faster than raw LZMA, because the preprocessed input is substantially smaller. The method can be implemented in under 50 lines of code.

</details>
