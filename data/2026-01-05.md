<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 6]
- [eess.SP](#eess.SP) [Total: 13]
- [cs.IT](#cs.IT) [Total: 7]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Deep Learning Approach for the Diagnosis of Pediatric Pneumonia Using Chest X-ray Imaging](https://arxiv.org/abs/2601.00041)
*Fatemeh Hosseinabadi,Mohammad Mojtaba Rohani*

Main category: eess.IV

TL;DR: 本研究评估了三种CNN架构（ResNetRS、RegNet、EfficientNetV2）在儿童肺炎X光片自动分类中的性能，RegNet表现最佳，准确率达92.4%，灵敏度90.1%。


<details>
  <summary>Details</summary>
Motivation: 儿童肺炎是全球儿童发病率和死亡率的主要原因，及时准确诊断至关重要，但常受限于放射学专业知识的缺乏以及儿童影像的生理和程序复杂性。

Method: 从公开数据集中提取1,000张儿童胸部X光图像，预处理后进行二元分类标注。使用预训练的ImageNet权重对ResNetRS、RegNet和EfficientNetV2三种CNN架构进行微调，基于准确率和灵敏度进行评估。

Result: RegNet表现最佳，准确率92.4%，灵敏度90.1%；ResNetRS次之，准确率91.9%，灵敏度89.3%；EfficientNetV2准确率88.5%，灵敏度88.1%。

Conclusion: 深度学习模型特别是RegNet在儿童肺炎自动诊断中表现出色，有望辅助临床决策，缓解放射科专家短缺问题，提高诊断效率和准确性。

Abstract: Pediatric pneumonia remains a leading cause of morbidity and mortality in children worldwide. Timely and accurate diagnosis is critical but often challenged by limited radiological expertise and the physiological and procedural complexity of pediatric imaging. This study investigates the performance of state-of-the-art convolutional neural network (CNN) architectures ResNetRS, RegNet, and EfficientNetV2 using transfer learning for the automated classification of pediatric chest Xray images as either pneumonia or normal.A curated subset of 1,000 chest X-ray images was extracted from a publicly available dataset originally comprising 5,856 pediatric images. All images were preprocessed and labeled for binary classification. Each model was fine-tuned using pretrained ImageNet weights and evaluated based on accuracy and sensitivity. RegNet achieved the highest classification performance with an accuracy of 92.4 and a sensitivity of 90.1, followed by ResNetRS (accuracy: 91.9, sensitivity: 89.3) and EfficientNetV2 (accuracy: 88.5, sensitivity: 88.1).

</details>


### [2] [Hear the Heartbeat in Phases: Physiologically Grounded Phase-Aware ECG Biometrics](https://arxiv.org/abs/2601.00170)
*Jintao Huang,Lu Leng,Yi Zhang,Ziyuan Yang*

Main category: eess.IV

TL;DR: 提出分层相位感知融合框架，通过三阶段设计避免跨特征纠缠，利用心电信号相位特异性进行身份认证，并引入心跳感知多原型注册策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有心电图身份认证方法通常将心跳视为同质信号，忽略了心脏周期内的相位特异性特征，这限制了身份识别的准确性和鲁棒性。

Method: 提出分层相位感知融合框架：1) 相位内表示独立提取每个心脏相位的特征；2) 相位分组层次融合按生理关系聚合相关相位；3) 全局表示融合自适应平衡各分组贡献。同时提出心跳感知多原型注册策略，构建多原型模板集减少心跳特异性噪声影响。

Result: 在三个公开数据集上的实验表明，该方法在闭集和开集设置下均取得了最先进的性能，优于其他现有方法。

Conclusion: 通过显式建模心脏相位特异性特征并采用分层融合策略，能够有效提升心电图身份认证的准确性和鲁棒性，为可穿戴设备提供更可靠的身份识别方案。

Abstract: Electrocardiography (ECG) is adopted for identity authentication in wearable devices due to its individual-specific characteristics and inherent liveness. However, existing methods often treat heartbeats as homogeneous signals, overlooking the phase-specific characteristics within the cardiac cycle. To address this, we propose a Hierarchical Phase-Aware Fusion~(HPAF) framework that explicitly avoids cross-feature entanglement through a three-stage design. In the first stage, Intra-Phase Representation (IPR) independently extracts representations for each cardiac phase, ensuring that phase-specific morphological and variation cues are preserved without interference from other phases. In the second stage, Phase-Grouped Hierarchical Fusion (PGHF) aggregates physiologically related phases in a structured manner, enabling reliable integration of complementary phase information. In the final stage, Global Representation Fusion (GRF) further combines the grouped representations and adaptively balances their contributions to produce a unified and discriminative identity representation. Moreover, considering ECG signals are continuously acquired, multiple heartbeats can be collected for each individual. We propose a Heartbeat-Aware Multi-prototype (HAM) enrollment strategy, which constructs a multi-prototype gallery template set to reduce the impact of heartbeat-specific noise and variability. Extensive experiments on three public datasets demonstrate that HPAF achieves state-of-the-art results in the comparison with other methods under both closed and open-set settings.

</details>


### [3] [Let Distortion Guide Restoration (DGR): A physics-informed learning framework for Prostate Diffusion MRI](https://arxiv.org/abs/2601.00226)
*Ziyang Long,Binesh Nader,Lixia Wang,Archana Vadiraj Malaji,Chia-Chi Yang,Haoran Sun,Rola Saouaf,Timothy Daskivich,Hyung Kim,Yibin Xie,Debiao Li,Hsin-Jung Yang*

Main category: eess.IV

TL;DR: 提出DGR框架，通过物理信息混合CNN-扩散模型，无需额外采集即可校正前列腺单次激发EPI DWI中的严重磁化率失真


<details>
  <summary>Details</summary>
Motivation: 前列腺DWI中的磁化率失真严重影响图像质量和诊断准确性，传统方法需要额外采集（如B0场图），限制了临床应用。需要一种无需额外采集的校正方法

Method: 1. 构建物理前向失真模型，利用410个多机构研究的无失真前列腺DWI和配准T2图像合成大规模配对数据
2. 结合11个实测B0场图生成模拟失真数据
3. 设计混合CNN-扩散框架：CNN几何校正模块 + 条件扩散细化模块，在T2解剖引导下进行校正

Result: 1. 在合成验证集（n=34）上，DGR的PSNR高于FSL TOPUP和FUGUE，NMSE更低
2. 在34个真实临床病例（包括髋关节假体和明显直肠扩张）中，DGR改善了几何保真度
3. 放射科医生评分显示图像质量和诊断置信度均有提高

Conclusion: 学习物理模拟前向过程的逆过程为前列腺DWI失真校正提供了一种实用的替代方案，无需依赖额外采集的校正流程

Abstract: We present Distortion-Guided Restoration (DGR), a physics-informed hybrid CNN-diffusion framework for acquisition-free correction of severe susceptibility-induced distortions in prostate single-shot EPI diffusion-weighted imaging (DWI). DGR is trained to invert a realistic forward distortion model using large-scale paired distorted and undistorted data synthesized from distortion-free prostate DWI and co-registered T2-weighted images from 410 multi-institutional studies, together with 11 measured B0 field maps from metal-implant cases incorporated into a forward simulator to generate low-b DWI (b = 50 s per mm squared), high-b DWI (b = 1400 s per mm squared), and ADC distortions. The network couples a CNN-based geometric correction module with conditional diffusion refinement under T2-weighted anatomical guidance. On a held-out synthetic validation set (n = 34) using ground-truth simulated distortion fields, DGR achieved higher PSNR and lower NMSE than FSL TOPUP and FUGUE. In 34 real clinical studies with severe distortion, including hip prostheses and marked rectal distension, DGR improved geometric fidelity and increased radiologist-rated image quality and diagnostic confidence. Overall, learning the inverse of a physically simulated forward process provides a practical alternative to acquisition-dependent distortion-correction pipelines for prostate DWI.

</details>


### [4] [The Impact of Lesion Focus on the Performance of AI-Based Melanoma Classification](https://arxiv.org/abs/2601.00355)
*Tanay Donde*

Main category: eess.IV

TL;DR: 研究分析黑色素瘤分类模型注意力与诊断性能的关系，发现模型对病灶区域关注度越高，诊断性能越好


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤是最致命的皮肤癌亚型，早期准确检测可改善患者预后。尽管机器学习模型（特别是CNN）在自动化黑色素瘤分类方面显示出巨大潜力，但由于对病灶区域关注不一致，其诊断可靠性仍受影响。

Method: 使用掩码图像、边界框检测和迁移学习，结合多种可解释性和敏感性分析方法，研究模型注意力与病灶区域的对齐程度及其与精确率、召回率和F1分数的相关性。

Result: 结果显示，对病灶区域关注度更高的模型取得了更好的诊断性能，表明可解释AI在医学诊断中的潜力。

Conclusion: 该研究为未来开发更准确、更可信赖的黑色素瘤分类模型奠定了基础。

Abstract: Melanoma is the most lethal subtype of skin cancer, and early and accurate detection of this disease can greatly improve patients' outcomes. Although machine learning models, especially convolutional neural networks (CNNs), have shown great potential in automating melanoma classification, their diagnostic reliability still suffers due to inconsistent focus on lesion areas. In this study, we analyze the relationship between lesion attention and diagnostic performance, involving masked images, bounding box detection, and transfer learning. We used multiple explainability and sensitivity analysis approaches to investigate how well models aligned their attention with lesion areas and how this alignment correlated with precision, recall, and F1-score. Results showed that models with a higher focus on lesion areas achieved better diagnostic performance, suggesting the potential of interpretable AI in medical diagnostics. This study provides a foundation for developing more accurate and trustworthy melanoma classification models in the future.

</details>


### [5] [Physics-Guided Dual-Domain Plug-and-Play ADMM for Low-Dose CT Reconstruction](https://arxiv.org/abs/2601.00669)
*Sayantan Dutta,Sudhanya Chatterjee,Ashwini Galande,K. S. Shriram,Bipul Das*

Main category: eess.IV

TL;DR: 提出PnP-MBIR框架，通过两阶段自监督N2N训练深度去噪器，实现超低剂量CT高质量重建，剂量降低70-80%


<details>
  <summary>Details</summary>
Motivation: 超低剂量CT可大幅减少患者辐射暴露，但会产生严重的结构性和随机噪声，降低图像质量，需要有效的重建方法

Method: 提出Plug-and-Play模型迭代重建框架，集成两阶段自监督Noise-to-Noise训练的深度卷积去噪器，交替执行正弦图域数据保真和图像域去噪

Result: 在模拟和临床数据集上，该方法在剂量降低70-80%的情况下，保持与标准全剂量扫描相当的诊断保真度，纹理一致性和细节保留优于基线方法

Conclusion: 该框架有效减少条纹和结构化伪影，同时保留细微组织对比度，是超低剂量CT重建的有前景工具

Abstract: Ultra-low-dose CT (ULDCT) imaging can greatly reduce patient radiation exposure, but the resulting scans suffer from severe structured and random noise that degrades image quality. To address this challenge, we propose a novel Plug-and-Play model-based iterative reconstruction framework (PnP-MBIR) that integrates a deep convolutional denoiser trained in a 2-stage self-supervised Noise-to-Noise (N2N) scheme. The method alternates between enforcing sinogram-domain data fidelity and applying the learned image-domain denoiser within an optimization, enabling artifact suppression while maintaining anatomical structure. The 2-stage protocol enables fully self-supervised training from noisy data, followed by high-dose fine-tuning, ensuring the denoiser's robustness in the ultra-low-dose regime. Our method enables high-quality reconstructions at $\sim$70--80\% lower dose levels, while maintaining diagnostic fidelity comparable to standard full-dose scans. Quantitative evaluations using Gray-Level Co-occurrence Matrix (GLCM) features -- including contrast, homogeneity, entropy, and correlation -- confirm that the proposed method yields superior texture consistency and detail preservation over standalone deep learning and supervised PnP baselines. Qualitative and quantitative results on both simulated and clinical datasets demonstrate that our framework effectively reduces streaks and structured artifacts while preserving subtle tissue contrast, making it a promising tool for ULDCT reconstruction.

</details>


### [6] [KDPhys: An Attention Guided 3D to 2D Knowledge Distillation for Real-time Video-Based Physiological Measurement](https://arxiv.org/abs/2601.00714)
*Nicky Nirlipta Sahoo,VS Sachidanand,Matcha Naga Gayathri,Balamurali Murugesan,Keerthi Ram,Jayaraj Joseph,Mohanasankar Sivaprakasam*

Main category: eess.IV

TL;DR: KDPhys：基于注意力知识蒸馏的轻量级远程光电容积描记（rPPG）信号提取框架，通过3D到2D特征蒸馏和DILATE损失函数，在减少50%参数的同时提升性能


<details>
  <summary>Details</summary>
Motivation: 随着COVID-19大流行，对实时非接触式生理监测的需求急剧增加，特别是在远程医疗领域。现有rPPG方法计算复杂度高，需要开发更高效的轻量级模型

Method: 提出KDPhys框架：1）使用注意力机制的知识蒸馏，将3D CNN教师模型的全局时间表征蒸馏到轻量级2D CNN学生模型；2）引入DILATE损失函数，同时考虑rPPG信号的形态和时间特征

Result: 模型仅需0.23M参数（现有方法的一半），推理速度提升56.67%。在三个基准数据集上平均MAE为1.78 bpm，比现有最优方法降低18.15%。在不同环境和活动场景下表现出良好鲁棒性

Conclusion: KDPhys是rPPG领域首个知识蒸馏应用，通过3D到2D特征蒸馏和DILATE损失，实现了高效轻量化的生理信号提取，为实时远程健康监测提供了实用解决方案

Abstract: Camera-based physiological monitoring, such as remote photoplethysmography (rPPG), captures subtle variations in skin optical properties caused by pulsatile blood volume changes using standard digital camera sensors. The demand for real-time, non-contact physiological measurement has increased significantly, particularly during the SARS-CoV-2 pandemic, to support telehealth and remote health monitoring applications. In this work, we propose an attention-based knowledge distillation (KD) framework, termed KDPhys, for extracting rPPG signals from facial video sequences. The proposed method distills global temporal representations from a 3D convolutional neural network (CNN) teacher model to a lightweight 2D CNN student model through effective 3D-to-2D feature distillation. To the best of our knowledge, this is the first application of knowledge distillation in the rPPG domain. Furthermore, we introduce a Distortion Loss incorporating Shape and Time (DILATE), which jointly accounts for both morphological and temporal characteristics of rPPG signals. Extensive qualitative and quantitative evaluations are conducted on three benchmark datasets. The proposed model achieves a significant reduction in computational complexity, using only half the parameters of existing methods while operating 56.67% faster. With just 0.23M parameters, it achieves an 18.15% reduction in Mean Absolute Error (MAE) compared to state-of-the-art approaches, attaining an average MAE of 1.78 bpm across all datasets. Additional experiments under diverse environmental conditions and activity scenarios further demonstrate the robustness and adaptability of the proposed approach.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [7] [Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes](https://arxiv.org/abs/2601.00012)
*Shahar Ain Kedem,Itamar Zimerman,Eliya Nachmani*

Main category: eess.SP

TL;DR: 提出一种受NeRF启发的EEG信号处理方法，将EEG电极类比为不同视角，训练神经网络编码整个信号，实现连续时空重建和虚拟电极生成。


<details>
  <summary>Details</summary>
Motivation: EEG数据具有长度可变、信噪比低、个体差异大、随时间漂移等挑战，且缺乏大规模干净数据集。现有深度学习方法难以有效处理EEG信号，需要新的建模方法。

Method: 借鉴NeRF思想，将EEG电极位置类比为NeRF中的不同视角，训练神经网络以NeRF风格编码单个EEG样本，生成固定大小的权重向量表示整个信号。该表示支持在任意时间点和空间位置重建EEG信号。

Result: 方法能够连续可视化任意分辨率（包括超高分辨率）的脑活动，重建原始EEG信号，有效模拟不存在的电极数据，提升标准EEG处理网络的性能。

Conclusion: NeRF启发的EEG处理方法为EEG信号建模提供了新思路，通过连续表示克服了传统离散采样的限制，在信号重建、虚拟电极生成和下游任务性能提升方面展现出潜力。

Abstract: Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.

</details>


### [8] [Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI](https://arxiv.org/abs/2601.00014)
*Eran Zvuloni,Ronit Almog,Michael Glikson,Shany Brimer Biton,Ilan Green,Izhar Laufer,Offer Amir,Joachim A. Behar*

Main category: eess.SP

TL;DR: 使用深度学习模型DeepHHF分析24小时单导联心电图数据，可在5年内预测心衰风险，准确率达AUC 0.80，优于30秒片段模型和临床评分。


<details>
  <summary>Details</summary>
Motivation: 心衰影响11.8%的65岁以上成年人，降低生活质量和寿命。预防心衰可降低发病率和死亡率。需要非侵入性、经济实惠且广泛可及的预测工具。

Method: 使用Technion-Leumit Holter ECG数据集（69,663条记录，47,729名患者，20年数据）。开发深度学习模型DeepHHF，训练于24小时单导联心电图数据，并与30秒片段模型和临床评分对比。

Result: DeepHHF的AUC达0.80，优于对比模型。高风险个体住院或死亡风险增加两倍。可解释性分析显示模型关注心律失常和心脏异常，关键注意力集中在上午8点至下午3点。

Conclusion: 深度学习可有效建模24小时连续心电图数据，捕捉阵发性事件和昼夜节律变化，对心衰风险预测至关重要。单导联Holter心电图结合AI是非侵入性、经济实惠且广泛可及的有前景工具。

Abstract: Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction.

</details>


### [9] [Adaptive Pinching Antenna Optimization via Meta-Learning for Physical-Layer Security in Dynamic Wireless Networks](https://arxiv.org/abs/2601.00115)
*Khalid T. Musri,Akram Y. Sarhan,Osamah A. Abdullah,Hayder Al-Hraishawi*

Main category: eess.SP

TL;DR: 提出基于梯度元学习的波导夹持天线系统实时控制框架，解决用户位置不确定性和物理层安全约束下的联合天线定位与发射功率优化问题。


<details>
  <summary>Details</summary>
Motivation: 在动态无线环境中，用户位置不确定性严重影响波导夹持天线系统的中断性能和物理层安全，需要快速适应变化的移动性和信道条件。

Method: 引入概率系统模型捕捉不完美定位影响，构建联合优化问题满足概率可靠性和安全要求，采用模型无关元学习（MAML）学习可迁移初始化，实现有限导频反馈下的快速在线适应。

Result: 仿真结果表明，该方法在中断概率、安全性能和收敛延迟方面显著优于Reptile元学习、非元强化学习、传统优化、静态天线放置和仅功率控制等方法。

Conclusion: 元学习是解决非平稳无线环境中可重构夹持天线系统安全低延迟控制的有效工具。

Abstract: This paper develops a gradient-based meta-learning framework for real-time control of waveguided pinching-antenna systems under user-location uncertainty and physical-layer security (PLS) constraints. A probabilistic system model is introduced to capture the impact of imperfect localization on outage performance and secrecy. Based on this model, a joint antenna-positioning and transmit-power optimization problem is formulated to satisfy probabilistic reliability and secrecy requirements. To enable rapid adaptation in highly dynamic environments, the proposed approach employs model-agnostic meta-learning (MAML) to learn a transferable initialization across diverse mobility and channel conditions, allowing few-shot online adaptation using limited pilot feedback. Simulation results demonstrate that the proposed framework significantly outperforms Reptile-based meta-learning, non-meta reinforcement learning, conventional optimization, static antenna placement, and power-only control in terms of outage probability, secrecy performance, and convergence latency. These results establish meta-learning as an effective tool for secure and low-latency control of reconfigurable pinching-antenna systems in non-stationary wireless environments.

</details>


### [10] [AI-Driven Channel State Information (CSI) Extrapolation for 6G: Current Situations, Challenges and Future Research](https://arxiv.org/abs/2601.00159)
*Yuan Gao,Zichen Lu,Xinyi Wu,Wenjun Yu,Shengli Liu,Jianbo Du,Yanliang Jin,Shunqing Zhang,Xiaoli Chu,Shugong Xu*

Main category: eess.SP

TL;DR: 本文首次全面综述了6G通信系统中CSI外推技术的现状、挑战与未来方向，涵盖性能指标、模型驱动与AI驱动方法、数据集及未来研究机会。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法在6G高移动性、超大规模MIMO和多频段系统中面临可扩展性挑战，CSI外推技术能通过部分CSI推断完整CSI来显著降低开销，但目前缺乏对SOTA CSI外推技术的全面综述。

Method: 首先分析6G中CSI外推的特定性能指标，然后综述模型驱动和AI驱动的时间、频率、天线和多域CSI外推方法，总结关键见解，并考察可用于训练AI驱动模型的开源信道数据集和模拟器。

Result: 提供了CSI外推技术的全面综述，总结了现有方法的优缺点，识别了AI驱动方法在满足性能要求方面的潜力，并整理了相关数据集资源。

Conclusion: 本文填补了CSI外推技术全面综述的空白，讨论了现有研究的关键挑战，并提出了未来的研究方向，为6G通信系统优化提供了重要参考。

Abstract: CSI extrapolation is an effective method for acquiring channel state information (CSI), essential for optimizing performance of sixth-generation (6G) communication systems. Traditional channel estimation methods face scalability challenges due to the surging overhead in emerging high-mobility, extremely large-scale multiple-input multiple-output (EL-MIMO), and multi-band systems. CSI extrapolation techniques mitigate these challenges by using partial CSI to infer complete CSI, significantly reducing overhead. Despite growing interest, a comprehensive review of state-of-the-art (SOTA) CSI extrapolation techniques is lacking. This paper addresses this gap by comprehensively reviewing the current status, challenges, and future directions of CSI extrapolation for the first time. Firstly, we analyze the performance metrics specific to CSI extrapolation in 6G, including extrapolation accuracy, adaption to dynamic scenarios and algorithm costs. We then review both model-driven and artificial intelligence (AI)-driven approaches for time, frequency, antenna, and multi-domain CSI extrapolation. Key insights and takeaways from these methods are summarized. Given the promise of AI-driven methods in meeting performance requirements, we also examine the open-source channel datasets and simulators that could be used to train high-performance AI-driven CSI extrapolation models. Finally, we discuss the critical challenges of the existing research and propose perspective research opportunities.

</details>


### [11] [Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design](https://arxiv.org/abs/2601.00171)
*Lingyun Xu,Bowen Wang,Huiyong Li,Ziyang Cheng*

Main category: eess.SP

TL;DR: 该论文研究了ISCC网络中边缘AI推理的感知精度与预编码系数之间的关系，提出了判别增益(DG)来表征感知精度，并开发了有效的预编码算法来最大化DG。


<details>
  <summary>Details</summary>
Motivation: 在集成感知、通信和计算(ISCC)网络中，边缘AI推理需要同时处理感知、通信和计算任务。现有研究缺乏对感知精度与预编码系数之间关系的深入分析，这限制了边缘AI推理的性能优化。

Method: 首先构建了基于空中计算(over-the-air)的ISCC网络系统模型，包括分布式边缘传感器进行特征提取和边缘服务器进行分类。然后提出了判别增益(DG)来量化感知精度，并推导了DG关于预编码系数的显式函数。基于此，设计了有效的预编码算法来解决非凸的DG最大化问题。

Result: 仿真结果表明，所提出的设计在ISCC网络中实现边缘推理是有效且可行的，验证了感知精度与预编码系数之间的关系分析以及所提算法的性能。

Conclusion: 该工作为ISCC网络中边缘AI推理的感知精度优化提供了理论框架和实用算法，通过分析感知精度与预编码系数的关系并设计有效的预编码方案，显著提升了边缘推理性能。

Abstract: This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks.

</details>


### [12] [Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping](https://arxiv.org/abs/2601.00434)
*Dhandeep Challagundla,Ignatius Bezzam,Riadul Islam*

Main category: eess.SP

TL;DR: 提出基于时间域计算的存内计算架构，用时间数字转换器替代传统模数转换器，降低功耗和面积，实现高效神经网络加速。


<details>
  <summary>Details</summary>
Motivation: 传统存内计算架构使用模数转换器执行乘累加操作，但ADC带来显著的面积和功耗开销以及非线性问题，需要更高效的解决方案。

Method: 提出谐振时间域存内计算架构，采用8T SRAM单元进行位级乘累加操作，使用4位时间数字转换器和脉冲收缩延迟元件，结合权重静态数据映射策略和自动SRAM宏选择算法。

Result: 在TSMC 28nm工艺上验证8KB SRAM阵列，吞吐量达320GOPS，能效为38.46TOPS/W。在六个CNN模型评估中，SRAM从32KB扩展到256KB时推理能耗降低8倍，量化后精度损失最小。

Conclusion: TDC-CiM架构通过消除ADC需求，用TDC实现低功耗数字转换，结合优化算法，为CNN工作负载提供了可扩展且高能效的存内计算解决方案。

Abstract: In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W.

</details>


### [13] [MIMO-AFDM Outperforms MIMO-OFDM in the Face of Hardware Impairments](https://arxiv.org/abs/2601.00502)
*Zeping Sui,Zilong Liu,Leila Musavian,Yong Liang Guan,Lie-Liang Yang,Lajos Hanzo*

Main category: eess.SP

TL;DR: 研究硬件损伤对MIMO-AFDM系统的影响，发现AFDM在硬件损伤下仍能保持全分集阶数，相比OFDM具有更强的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 研究硬件损伤（包括乘性和加性）对MIMO-AFDM系统性能的影响，评估其在现实硬件不完美条件下的表现，并与传统MIMO-OFDM系统进行比较。

Method: 针对小规模MIMO-AFDM系统推导了ML检测器的紧致BER上界；针对大规模系统推导了LMMSE检测器的闭式BER近似，包括不完美信道估计场景。通过理论分析和仿真验证。

Result: 1) 硬件损伤下的AFDM系统仍能保持全分集阶数；2) 理论BER结果与仿真结果高度匹配；3) MIMO-AFDM比MIMO-OFDM对乘性失真（如相位噪声、载波频率偏移）更具鲁棒性；4) 在相同加性硬件损伤条件下，MIMO-AFDM始终优于MIMO-OFDM。

Conclusion: AFDM凭借其固有的啁啾信号特性和离散仿射傅里叶变换的扩展效应，相比OFDM具有更强的ICI抗干扰能力，即使在硬件损伤条件下也能实现最大全分集增益。

Abstract: The impact of both multiplicative and additive hardware impairments (HWIs) on multiple-input multiple-output affine frequency division multiplexing (MIMO-AFDM) systems is investigated. For small-scale MIMO-AFDM systems, a tight bit error rate (BER) upper bound associated with the maximum likelihood (ML) detector is derived. By contrast, for large-scale systems, a closed-form BER approximation associated with the linear minimum mean squared error (LMMSE) detector is presented, including realistic imperfect channel estimation scenarios. Our first key observation is that the full diversity order of a hardware-impaired AFDM system remains unaffected, which is a unique advantage. Furthermore, our analysis shows that 1) the BER results derived accurately predict the simulated ML performance in moderate-to-high signal-to-noise ratios (SNRs), while the theoretical BER curve of the LMMSE detector closely matches that of the Monte-Carlo based one. 2) MIMO-AFDM is more resilient to multiplicative distortions, such as phase noise and carrier frequency offset, compared to its orthogonal frequency division multiplexing (OFDM) counterparts. This is attributed to its inherent chirp signal characteristics; 3) MIMO-AFDM consistently achieves superior BER performance compared to conventional MIMO-OFDM systems under the same additive HWI conditions, as well as different velocity values. The latter is because MIMO-AFDM is also resilient to the additional inter-carrier interference (ICI) imposed by the nonlinear distortions of additive HWIs. In a nutshell, compared to OFDM, AFDM demonstrates stronger ICI resilience and achieves the maximum full diversity attainable gain even under HWIs, thanks to its intrinsic chirp signalling structure as well as to the beneficial spreading effect of the discrete affine Fourier transform.

</details>


### [14] [Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks](https://arxiv.org/abs/2601.00538)
*Chi-Te Kuo,Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: eess.SP

TL;DR: 提出参数化共享的多智能体混合深度强化学习（PMHRL）方法，优化多MF-RIS辅助的NOMA下行网络，实现最高能效


<details>
  <summary>Details</summary>
Motivation: 多功能可重构智能表面（MF-RIS）结合主动RIS的信号覆盖扩展能力和能量收集的自持特性，但需要解决多MF-RIS辅助NOMA网络中的能效优化问题

Method: 设计参数化共享的多智能体混合深度强化学习（PMHRL），结合PPO处理连续变量和DQN处理离散变量，联合优化功率分配、波束成形、MF-RIS配置和位置

Result: PMHRL相比其他基准方法（无参数化共享、纯PPO、纯DQN）获得最高能效；多MF-RIS辅助NOMA相比无EH/放大、传统RIS、无RIS/MF-RIS场景在不同多址方式下均实现最高能效

Conclusion: 提出的PMHRL方法能有效优化多MF-RIS辅助NOMA网络的能效，参数化共享机制和混合强化学习方法显著提升性能，多MF-RIS架构在通信效率和自持性方面具有优势

Abstract: Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.

</details>


### [15] [Fractional Programming for Kullback-Leibler Divergence in Hypothesis Testing](https://arxiv.org/abs/2601.00564)
*Jeongwoo Park,Seongkyu Jung,Kaiming Shen,Jeonghun Park*

Main category: eess.SP

TL;DR: 提出基于分数规划的计算高效优化框架，用于最大化Kullback-Leibler散度，显著降低计算复杂度并加速收敛


<details>
  <summary>Details</summary>
Motivation: 主动感知和假设检验中的波形设计需要最大化KLD散度，但现有优化方法计算复杂度高，需要每次迭代进行矩阵求逆，限制了实际应用

Method: 1) 使用矩阵分数规划将KLD最大化问题转化为一系列可处理的二次子问题；2) 引入非齐次松弛技术，用闭式更新替代昂贵的线性系统求解器；3) 采用STEM加速方法将迭代方案解释为定点映射

Result: 提出的算法将每次迭代复杂度降至二次阶，总运行时间比最先进基准方法减少数个数量级，在多个随机接入和联合感知通信场景中验证了有效性

Conclusion: 该计算高效优化框架成功解决了KLD最大化问题的高计算复杂度挑战，为主动感知和假设检验中的波形设计提供了实用解决方案

Abstract: Maximizing the Kullback-Leibler divergence (KLD) is a fundamental problem in waveform design for active sensing and hypothesis testing, as it directly relates to the error exponent of detection probability. However, the associated optimization problem is highly nonconvex due to the intricate coupling of log-determinant and matrix trace terms. Existing solutions often suffer from high computational complexity, typically requiring matrix inversion at every iteration. In this paper, we propose a computationally efficient optimization framework based on fractional programming (FP). Our key idea is to reformulate the KLD maximization problem into a sequence of tractable quadratic subproblems using matrix FP. To further reduce complexity, we introduce a nonhomogeneous relaxation technique that replaces the costly linear system solver with a simple closed-form update, thereby reducing the per-iteration complexity to quadratic order. To compensate for the convergence speed trade-off caused by relaxation, we employ an acceleration method called STEM by interpreting the iterative scheme as a fixed-point mapping. The resulting algorithm achieves significantly faster convergence rates with low per-iteration cost. Numerical results demonstrate that our approach reduces the total runtime by orders of magnitude compared to a state-of-the-art benchmark. Finally, we apply the proposed framework to a multiple random access scenario and a joint integrated sensing and communication scenario, validating the efficacy of our framework in such applications.

</details>


### [16] [WiFo-MUD: Wireless Foundation Model for Heterogeneous Multi-User Demodulator](https://arxiv.org/abs/2601.00612)
*Zonghui Yang,Shijian Gao,Xuesong Cai,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: 提出WiFo-MUD，一种基于扩散模型的通用多用户解调基础模型，通过条件去噪和通信感知一致性蒸馏，在异构配置下实现高效推理和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有解调器在通用多用户环境中表现不佳：传统方法难以平衡准确性和复杂度，深度学习方法在异构配置下缺乏适应性，现有扩散模型灵活性不足。

Method: 提出WiFo-MUD模型，包含：1）对齐用户间信噪比不平衡；2）定制化主干网络进行条件去噪；3）通信感知一致性蒸馏方法；4）动态用户分组策略。

Result: 在大规模异构数据集上取得最先进结果，展示高效推理能力，并在不同系统配置下表现出强泛化性能。

Conclusion: WiFo-MUD作为通用扩散基础模型，有效解决了多用户解调中的准确性与适应性难题，为无线通信提供了灵活可靠的解调解决方案。

Abstract: Multi-user signal demodulation is critical to wireless communications, directly impacting transmission reliability and efficiency. However, existing demodulators underperform in generic multi-user environments: classical demodulators struggle to balance accuracy and complexity, while deep learning-based methods lack adaptability under heterogeneous configurations. Although diffusion models have been introduced for demodulation, their flexibility remains limited for practical use. To address these issues, this work proposes WiFo-MUD, a universal diffusion-based foundation model for multi-user demodulation. The model aligns inter-user signal-to-noise ratio imbalance and performs conditional denoising via a customized backbone. Furthermore, a communication-aware consistency distillation method and a dynamic user-grouping strategy are devised to enhance inference. WiFo-MUD achieves state-of-the-art results on large-scale heterogeneous datasets, demonstrating efficient inference and strong generalization across varying system configurations.

</details>


### [17] [Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO](https://arxiv.org/abs/2601.00616)
*Yasaman Khorsandmanesh,Emil Bjornson,Joakim Jalden*

Main category: eess.SP

TL;DR: 提出一种分裂预编码架构，将预编码设计分离到AAS和BBU之间，通过本地子空间选择降低信道维度，优化量化细化预编码，提升频谱效率。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO 5G架构中，有限的fronthaul容量是实际瓶颈。传统下行设计将整个预编码计算放在BBU，并通过fronthaul传输高维预编码矩阵，导致显著的量化损失和信令开销。

Method: 提出分裂预编码架构：AAS执行本地子空间选择以降低信道维度，BBU基于得到的有效信道计算优化的量化细化预编码。

Result: 数值结果表明，所提出的分裂预编码策略比传统单级预编码实现了更高的总频谱效率。

Conclusion: 通过将预编码设计分离到AAS和BBU，该架构有效解决了fronthaul容量限制问题，在降低量化损失和信令开销的同时提升了系统性能。

Abstract: Limited fronthaul capacity is a practical bottleneck in massive multiple-input multiple-output (MIMO) 5G architectures, where a base station (BS) consists of an advanced antenna system (AAS) connected to a baseband unit (BBU). Conventional downlink designs place the entire precoding computation at the BBU and transmit a high-dimensional precoding matrix over the fronthaul, resulting in substantial quantization losses and signaling overhead. This letter proposes a splitting precoding architecture that separates the design between the AAS and BBU. The AAS performs a local subspace selection to reduce the channel dimensionality, while the BBU computes an optimized quantized refinement precoding based on the resulting effective channel. The numerical results show that the proposed splitting precoding strategy achieves higher sum spectral efficiency than conventional one-stage precoding.

</details>


### [18] [Conformal Reconfigurable Intelligent Surfaces: A Cylindrical Geometry Perspective](https://arxiv.org/abs/2601.00734)
*Filippo Pepe,Ivan Iudice,Giuseppe Castaldi,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 圆柱形可重构智能表面（RIS）从理想阻抗合成到一比特元原子实现，通过解析模型和优化方法验证了其波束合成能力，证明了一比特RIS在保持低硬件复杂度下实现定向散射的可行性。


<details>
  <summary>Details</summary>
Motivation: 研究圆柱形RIS是为了在无人机、城市基础设施等非平面平台上实现自适应波前控制，推动下一代无线通信技术的发展。

Method: 首先开发精确的解析模型和几何光学模型探索设计极限，然后建立适用于离散可重构架构的半解析模型，采用进化优化和低复杂度策略（如最小功率无失真响应方法）进行波束合成，并通过全波仿真验证。

Result: 一比特RIS能够实现定向散射，具有可管理的旁瓣水平和最小硬件复杂度，验证了圆柱形RIS的可行性。

Conclusion: 圆柱形RIS具有实际应用潜力，为双用途无线平台集成和现实通信场景应用打开了大门。

Abstract: Curved reconfigurable intelligent surfaces (RISs) represent a promising frontier for next-generation wireless communication, enabling adaptive wavefront control on nonplanar platforms such as unmanned aerial vehicles and urban infrastructure. This work presents a systematic investigation of cylindrical RISs, progressing from idealized surface-impedance synthesis to practical implementations based on simple one-bit meta-atoms. Exact analytical and geometrical-optics-based models are first developed to explore fundamental design limits, followed by a semi-analytical formulation tailored to discrete, reconfigurable architectures. This model enables efficient beam synthesis using both evolutionary optimization and low-complexity strategies, including the minimum power distortionless response method, and is validated through full-wave simulations. Results confirm that one-bit RISs can achieve directive scattering with manageable sidelobe levels and minimal hardware complexity. These findings establish the viability of cylindrical RISs and open the door to their integration into dual-use wireless platforms for real-world communication scenarios.

</details>


### [19] [Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming](https://arxiv.org/abs/2601.00780)
*Robert Kuku Fotock,Alessio Zappone,Agbotiname Lucky Imoize,Marco Di Renzo*

Main category: eess.SP

TL;DR: 该研究提出了一种在点对点多天线无线链路中使用可重构超表面实现全息波束赋形的方法，通过优化发射协方差矩阵和超表面反射矩阵来最大化系统能效。


<details>
  <summary>Details</summary>
Motivation: 传统全数字波束赋形架构虽然能实现显著的多路复用增益，但能耗较高。本研究旨在通过部署可重构超表面实现全息波束赋形，在保证性能的同时显著提升系统能效。

Method: 在发射和接收天线阵列附近各部署一个可重构超表面，构建全息波束赋形结构。开发低复杂度算法优化发射协方差矩阵和两个超表面的反射矩阵，以最大化系统能效。算法保证收敛到一阶最优点，并为单天线或单流传输场景推导了超表面矩阵的闭式解。

Result: 数值性能分析表明，与全数字波束赋形架构相比，基于超表面的全息波束赋形能提供显著的能效增益，即使后者实现了可观的多路复用增益。超表面被设计为近无源且受全局反射约束。

Conclusion: 在点对点多天线无线链路中部署可重构超表面实现全息波束赋形是提升系统能效的有效方法，提出的优化算法具有低复杂度且能保证收敛，为未来无线通信系统的能效优化提供了新思路。

Abstract: This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [20] [A repair scheme for a distributed storage system based on multivariate polynomials](https://arxiv.org/abs/2601.00120)
*Hiram H. López,Gretchen L. Matthews,Daniel Valvo*

Main category: cs.IT

TL;DR: 将基于Reed-Solomon码的单节点精确修复方案扩展到基于Reed-Muller码的分布式存储系统，支持单节点和多节点故障修复


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统需要高效的数据恢复机制，现有基于Reed-Solomon码的精确修复方案只能处理单变量多项式，需要扩展到基于多变量多项式的Reed-Muller码系统

Method: 扩展GW论文中的精确修复方案，将其应用于基于Reed-Muller码的分布式存储系统，利用多变量多项式的特性设计修复算法

Result: 提出了能够修复任意单节点故障和满足特定条件的多节点故障的修复方案，扩展了现有修复方案的应用范围

Conclusion: 成功将精确修复方案从Reed-Solomon码扩展到Reed-Muller码，为基于多变量多项式编码的分布式存储系统提供了有效的故障修复机制

Abstract: A distributed storage system stores data across multiple nodes, with the primary objective of enabling efficient data recovery even in the event of node failures. The main goal of an exact repair scheme is to recover the data from a failed node by accessing and downloading information from the rest of the nodes. In a groundbreaking paper, ~\cite{GW} developed an exact repair scheme for a distributed storage system that is based on Reed-Solomon codes, which depend on single-variable polynomials. In these notes, we extend the repair scheme to the family of distributed storage systems based on Reed-Muller codes, which are linear codes based on multivariate polynomials. The repair scheme we propose repairs any single node failure and multiple node failures, provided the positions satisfy certain conditions.

</details>


### [21] [The permutation group of Reed-Solomon codes over arbitrary points](https://arxiv.org/abs/2601.00122)
*Eduardo Camps-Moreno,Jun Bo Lau,Hiram H. López,Welington Santos*

Main category: cs.IT

TL;DR: 证明了Reed-Solomon码的置换群由保持评估点集不变的一次多项式构成


<details>
  <summary>Details</summary>
Motivation: 研究Reed-Solomon码的置换群结构，为理解这类重要纠错码的对称性提供理论基础

Method: 通过数学证明，建立Reed-Solomon码置换群与保持评估点集不变的一次多项式之间的等价关系

Result: 证明了Reed-Solomon码的置换群恰好由那些保持评估点集不变的一次多项式构成

Conclusion: 该结果为Reed-Solomon码置换群提供了简洁的刻画，并直接推导出评估点集为整个有限域或乘法群时的已知结果

Abstract: In this work, we prove that the permutation group of a Reed-Solomon code is given by the polynomials of degree one that leave the set of evaluation points invariant. Our results provide a straightforward proof of the well-known cases of the permutation group of the Reed-Solomon code when the set of evaluation points is the whole finite field or the multiplicative group.

</details>


### [22] [Evolution of UE in Massive MIMO Systems for 6G: From Passive to Active](https://arxiv.org/abs/2601.00251)
*Kwonyeol Park,Hyuckjin Choi,Geonho Han,Gyoseung Lee,Yeonjoon Choi,Sunwoo Park,Junil Choi*

Main category: cs.IT

TL;DR: 该论文综述了从5G到6G演进中，用户设备在mMIMO系统中的角色转变，从被动收发器转变为主动参与系统性能优化的智能实体，分析了3GPP标准化进展、设备实现挑战和架构创新。


<details>
  <summary>Details</summary>
Motivation: 无线网络对低延迟、高可靠性的要求日益严格，动态信道环境暴露了传统gNB中心化mMIMO架构的局限性，需要重新思考用户设备在系统中的角色，使其从被动接收者转变为主动参与者。

Method: 通过回顾3GPP Release 15-19的标准化演进，分析UE功能从基本CSI报告到AI/ML增强CSI和UE发起波束管理的进展；研究MPUE架构、设备端智能处理和能效操作等实现挑战；采用数字孪生评估验证UE中心化功能的影响。

Result: 数字孪生评估表明：UE发起的波束报告在现实移动场景中提高了吞吐量；多面板架构相比单面板UE增强了链路鲁棒性；UE主动参与能显著提升系统性能。

Conclusion: 从5G到6G的演进中，UE正从被动收发器转变为主动智能实体，通过AI/ML增强、多面板架构和UE发起的管理功能，能够显著提升mMIMO系统性能，这需要标准化、设备实现和架构创新的协同推进。

Abstract: As wireless networks continue to evolve, stringent latency and reliability requirements and highly dynamic channels expose fundamental limitations of gNB-centric massive multiple-input multiple-output (mMIMO) architectures, motivating a rethinking of the user equipment (UE) role. In response, the UE is transitioning from a passive transceiver into an active entity that directly contributes to system-level performance. In this context, this article examines the evolving role of the UE in mMIMO systems during the transition from fifth-generation (5G) to sixth-generation (6G), bridging third generation partnership project (3GPP) standardization, device implementation, and architectural innovation. Through a chronological review of 3GPP Releases 15 to 19, we highlight the progression of UE functionalities from basic channel state information (CSI) reporting to artificial intelligence (AI) and machine learning (ML)-based CSI enhancement and UE-initiated beam management. We further examine key implementation challenges, including multi-panel UE (MPUE) architectures, on-device intelligent processing, and energy-efficient operation, and then discuss corresponding architectural innovations under practical constraints. Using digital-twin-based evaluations, we validate the impact of emerging UE-centric functionalities, illustrating that UE-initiated beam reporting improves throughput in realistic mobility scenarios, while a multi-panel architecture enhances link robustness compared with a single-panel UE.

</details>


### [23] [Semantic Transmission Framework in Direct Satellite Communications](https://arxiv.org/abs/2601.00381)
*Chong Huang,Xuyang Chen,Jingfu Li,Pei Xiao,Gaojie Chen,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出用于卫星直接通信的语义传输框架，通过REINFORCE++算法优化语义效率指标，解决链路预算不足问题


<details>
  <summary>Details</summary>
Motivation: 当前卫星通信中链路预算不足已成为直接接入的瓶颈问题，需要有效的解决方案来提升通信性能

Method: 开发卫星直接通信的语义传输框架，引入带优化权重的语义效率指标，提出决策辅助的REINFORCE++算法，联合优化传输模式选择、卫星-用户关联、ISL任务迁移、去噪步骤和自适应权重

Result: 数值结果表明，所提算法比基线方法获得更高的语义效率

Conclusion: 语义传输框架是解决卫星通信链路预算不足问题的有效可行方案，REINFORCE++算法能有效优化语义效率指标

Abstract: Insufficient link budget has become a bottleneck problem for direct access in current satellite communications. In this paper, we develop a semantic transmission framework for direct satellite communications as an effective and viable solution to tackle this problem. To measure the tradeoffs between communication, computation, and generation quality, we introduce a semantic efficiency metric with optimized weights. The optimization aims to maximize the average semantic efficiency metric by jointly optimizing transmission mode selection, satellite-user association, ISL task migration, denoising steps, and adaptive weights, which is a complex nonlinear integer programming problem. To maximize the average semantic efficiency metric, we propose a decision-assisted REINFORCE++ algorithm that utilizes feasibility-aware action space and a critic-free stabilized policy update. Numerical results show that the proposed algorithm achieves higher semantic efficiency than baselines.

</details>


### [24] [On the burst-covering radius of binary cyclic codes](https://arxiv.org/abs/2601.00435)
*Gabriel Sac Himelfarb,Moshe Schwartz*

Main category: cs.IT

TL;DR: 该论文研究突发覆盖码，为循环码提供更强的突发覆盖半径界限，并提出高效算法


<details>
  <summary>Details</summary>
Motivation: 研究突发覆盖码，旨在建立码参数与突发覆盖半径之间的理论联系，特别关注循环码的突发覆盖性能

Method: 使用线性反馈移位寄存器序列分析循环码的突发覆盖半径，为BCH码证明新的LFSR序列模式频率界限

Result: 建立了突发覆盖码的一般界限，为循环码提供了更强的突发覆盖半径界限，能有效界定二进制原始BCH码和Melas码的覆盖半径

Conclusion: 提出了突发覆盖循环码的高效算法，LFSR序列的模式频率界限具有独立的理论价值

Abstract: We define and study burst-covering codes. We provide some general bounds connecting the code parameters with its burst-covering radius. We then provide stronger bounds on the burst-covering radius of cyclic codes, by employing linear-feedback shift-register (LFSR) sequences. For the case of BCH codes we prove a new bound on pattern frequencies in LFSR sequences, which is of independent interest. Using this tool, we can bound the covering-radius of binary primitive BCH codes and Melas codes. We conclude with an efficient algorithm for burst-covering cyclic codes.

</details>


### [25] [CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge](https://arxiv.org/abs/2601.00549)
*Zhiheng Guo,Zhaoyang Liu,Zihan Cen,Chenyuan Feng,Xinghua Sun,Xiang Chen,Tony Q. S. Quek,Xijun Wang*

Main category: cs.IT

TL;DR: CoCo-Fed是一个基于压缩和组合的联邦学习框架，通过双重维度降维投影解决O-RAN中神经网络部署的内存和通信瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 在开放无线接入网络(O-RAN)架构中部署大规模神经网络面临两个关键瓶颈：1) 资源受限的gNB上本地训练所需的内存占用过大；2) 高维模型更新在带宽受限的回程链路上进行全局聚合时的带宽饱和问题。

Method: CoCo-Fed采用双重维度降维投影技术：本地层面，对梯度进行双维度降维投影，使优化器能够在低秩结构上运行而不引入额外推理参数/延迟；全局层面，引入基于正交子空间叠加的传输协议，将层间更新投影并叠加到每个gNB的单个整合矩阵中，大幅减少回程流量。

Result: 在到达角估计任务上的大量仿真表明，CoCo-Fed在内存和通信效率方面显著优于现有基线方法，同时在非独立同分布设置下保持稳健的收敛性。

Conclusion: CoCo-Fed通过统一的压缩和组合框架，有效解决了O-RAN中联邦学习的内存和通信瓶颈，为无线感知任务提供了理论保证的收敛性，实现了边缘智能的高效部署。

Abstract: The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.

</details>


### [26] [Universal Outlier Hypothesis Testing via Mean- and Median-Based Tests](https://arxiv.org/abs/2601.00712)
*Bernhard C. Geiger,Tobias Koch,Josipa Mihaljević,Maximilian Toller*

Main category: cs.IT

TL;DR: 论文研究了通用异常假设检验问题，提出两种方法：当异常序列数量亚线性增长时使用均值估计，当异常序列比例固定时使用中位数估计，两者都能达到已知分布的最大似然检验的错误指数。


<details>
  <summary>Details</summary>
Motivation: 研究通用异常假设检验问题，其中观测序列数量和异常序列数量都随序列长度增长。传统方法假设异常序列数量固定，但在实际应用中异常序列数量可能随总序列数增长，需要新的解决方案。

Method: 提出两种方法：1）均值估计法：当异常序列数量亚线性增长时，通过所有观测序列的均值估计典型分布π；2）中位数估计法：当异常序列比例固定时，通过所有观测序列的中位数估计π。两种方法都能达到已知π和μ的最大似然检验的错误指数。

Result: 均值估计法在异常序列数量亚线性增长时能实现最大似然检验的错误指数。中位数估计法在异常序列比例固定时也能达到最大似然检验的错误指数，但仅以概率趋近1成立。为此引入了典型错误指数的概念。

Conclusion: 论文解决了异常序列数量随总序列数增长的通用异常假设检验问题，提出了适应不同异常比例的有效方法，并引入了典型错误指数来形式化分析中位数估计法的性能。

Abstract: Universal outlier hypothesis testing refers to a hypothesis testing problem where one observes a large number of length-$n$ sequences -- the majority of which are distributed according to the typical distribution $π$ and a small number are distributed according to the outlier distribution $μ$ -- and one wishes to decide, which of these sequences are outliers without having knowledge of $π$ and $μ$. In contrast to previous works, in this paper it is assumed that both the number of observation sequences and the number of outlier sequences grow with the sequence length. In this case, the typical distribution $π$ can be estimated by computing the mean over all observation sequences, provided that the number of outlier sequences is sublinear in the total number of sequences. It is demonstrated that, in this case, one can achieve the error exponent of the maximum likelihood test that has access to both $π$ and $μ$. However, this mean-based test performs poorly when the number of outlier sequences is proportional to the total number of sequences. For this case, a median-based test is proposed that estimates $π$ as the median of all observation sequences. It is demonstrated that the median-based test achieves again the error exponent of the maximum likelihood test that has access to both $π$ and $μ$, but only with probability approaching one. To formalize this case, the typical error exponent -- similar to the typical random coding exponent introduced in the context of random coding for channel coding -- is proposed.

</details>
