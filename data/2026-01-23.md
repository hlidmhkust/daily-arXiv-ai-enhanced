<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 8]
- [eess.SP](#eess.SP) [Total: 19]
- [cs.IT](#cs.IT) [Total: 15]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Q-Probe: Scaling Image Quality Assessment to High Resolution via Context-Aware Agentic Probing](https://arxiv.org/abs/2601.15356)
*Xiang Li,XueHeng Li,Yu Wang,XuanHua He,ZhangChi Hu,WeiWei Yu,ChengJun Xie*

Main category: eess.IV

TL;DR: Q-Probe：首个基于智能代理的高分辨率图像质量评估框架，通过上下文感知探测解决现有RL方法在捕捉局部退化方面的不足，在Vista-Bench基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的图像质量评估模型依赖粗粒度全局视图，无法在高分辨率场景下捕捉细微的局部退化。新兴的"图像思维"范式虽然通过放大机制实现多尺度视觉感知，但直接应用于IQA会引入虚假的"裁剪即退化"偏见，并将自然景深误解为伪影。

Method: 提出Q-Probe框架：1）构建Vista-Bench基准，专门用于高分辨率IQA中的细粒度局部退化分析；2）采用三阶段训练范式，逐步将模型与人类偏好对齐，同时通过新颖的上下文感知裁剪策略消除因果偏见。

Result: 大量实验表明，Q-Probe在高分辨率设置下达到最先进的性能，同时在各种分辨率尺度上保持卓越的有效性。

Conclusion: Q-Probe是首个基于智能代理的高分辨率图像质量评估框架，通过上下文感知探测成功解决了现有方法在捕捉局部退化方面的局限性，为高分辨率IQA提供了有效的解决方案。

Abstract: Reinforcement Learning (RL) has empowered Multimodal Large Language Models (MLLMs) to achieve superior human preference alignment in Image Quality Assessment (IQA). However, existing RL-based IQA models typically rely on coarse-grained global views, failing to capture subtle local degradations in high-resolution scenarios. While emerging "Thinking with Images" paradigms enable multi-scale visual perception via zoom-in mechanisms, their direct adaptation to IQA induces spurious "cropping-implies-degradation" biases and misinterprets natural depth-of-field as artifacts. To address these challenges, we propose Q-Probe, the first agentic IQA framework designed to scale IQA to high resolution via context-aware probing. First, we construct Vista-Bench, a pioneering benchmark tailored for fine-grained local degradation analysis in high-resolution IQA settings. Furthermore, we propose a three-stage training paradigm that progressively aligns the model with human preferences, while simultaneously eliminating causal bias through a novel context-aware cropping strategy. Extensive experiments demonstrate that Q-Probe achieves state-of-the-art performance in high-resolution settings while maintaining superior efficacy across resolution scales.

</details>


### [2] [High-Fidelity 3D Tooth Reconstruction by Fusing Intraoral Scans and CBCT Data via a Deep Implicit Representation](https://arxiv.org/abs/2601.15358)
*Yi Zhu,Razmig Kechichian,Raphaël Richert,Satoshi Ikehata,Sébastien Valette*

Main category: eess.IV

TL;DR: 提出一个自动融合CBCT和IOS数据的深度学习管道，生成无缝、完整的高保真3D牙齿模型


<details>
  <summary>Details</summary>
Motivation: 数字牙科需要高保真的3D牙齿模型，但临床成像模式各有局限：CBCT能捕捉牙根但牙冠分辨率低且噪声大，IOS提供高保真牙冠但没有牙根信息。简单融合会导致不自然的接缝和伪影。

Method: 提出一个全自动管道，使用深度隐式表示融合CBCT和IOS数据。首先分割并稳健配准牙齿实例，然后创建结合IOS牙冠和CBCT牙根的混合代理网格。核心方法是用这个噪声代理指导类别特定的DeepSDF网络，通过优化过程将输入投影到理想牙齿形状的学习流形上。

Result: 定性和定量评估显示，该方法独特地保留了IOS的高保真牙冠和CBCT的患者特定牙根形态，克服了每种模态和简单缝合的局限性。

Conclusion: 该方法成功实现了CBCT和IOS数据的无缝融合，生成完整、水密且解剖学一致的3D牙齿模型，为数字牙科提供了高质量的牙齿重建解决方案。

Abstract: High-fidelity 3D tooth models are essential for digital dentistry, but must capture both the detailed crown and the complete root. Clinical imaging modalities are limited: Cone-Beam Computed Tomography (CBCT) captures the root but has a noisy, low-resolution crown, while Intraoral Scanners (IOS) provide a high-fidelity crown but no root information. A naive fusion of these sources results in unnatural seams and artifacts. We propose a novel, fully-automated pipeline that fuses CBCT and IOS data using a deep implicit representation. Our method first segments and robustly registers the tooth instances, then creates a hybrid proxy mesh combining the IOS crown and the CBCT root. The core of our approach is to use this noisy proxy to guide a class-specific DeepSDF network. This optimization process projects the input onto a learned manifold of ideal tooth shapes, generating a seamless, watertight, and anatomically coherent model. Qualitative and quantitative evaluations show our method uniquely preserves both the high-fidelity crown from IOS and the patient-specific root morphology from CBCT, overcoming the limitations of each modality and naive stitching.

</details>


### [3] [Aligned Stable Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency](https://arxiv.org/abs/2601.15368)
*Yikai Wang,Junqiu Yu,Chenjie Cao,Xiangyang Xue,Yanwei Fu*

Main category: eess.IV

TL;DR: ASUKA框架解决生成式图像修复中的两个关键问题：不想要的物体插入和颜色不一致，通过重建先验和专门VAE解码器提升修复质量


<details>
  <summary>Details</summary>
Motivation: 现有生成式图像修复方法虽然能产生逼真结果，但仍存在两个主要问题：1）不想要的物体插入（模型可能在掩码区域幻觉出与周围环境不匹配的任意物体）；2）颜色不一致（修复区域常出现明显色移，导致纹理模糊和图像质量下降）

Method: 提出ASUKA框架：1）使用重建先验引导生成模型，抑制幻觉物体同时保持生成灵活性；2）设计专门的VAE解码器，将潜在到图像的解码制定为局部协调任务，减少色移；3）在U-Net和DiT两种代表性修复架构上实现，提出轻量级注入策略，最小化对原始生成能力的干扰

Result: 在Places2数据集和提出的MISATO多样化基准上评估，ASUKA能有效抑制物体幻觉并提升颜色一致性，优于标准扩散模型、整流流模型和其他修复方法

Conclusion: ASUKA框架通过分析生成式图像修复中的关键问题并提出高效的后处理解决方案，显著提升了修复质量，解决了不想要的物体插入和颜色不一致问题，为预训练修复模型提供了实用的改进方案

Abstract: Generative image inpainting can produce realistic, high-fidelity results even with large, irregular masks. However, existing methods still face key issues that make inpainted images look unnatural. In this paper, we identify two main problems: (1) Unwanted object insertion: generative models may hallucinate arbitrary objects in the masked region that do not match the surrounding context. (2) Color inconsistency: inpainted regions often exhibit noticeable color shifts, leading to smeared textures and degraded image quality. We analyze the underlying causes of these issues and propose efficient post-hoc solutions for pre-trained inpainting models. Specifically, we introduce the principled framework of Aligned Stable inpainting with UnKnown Areas prior (ASUKA). To reduce unwanted object insertion, we use reconstruction-based priors to guide the generative model, suppressing hallucinated objects while preserving generative flexibility. To address color inconsistency, we design a specialized VAE decoder that formulates latent-to-image decoding as a local harmonization task. This design significantly reduces color shifts and produces more color-consistent results. We implement ASUKA on two representative inpainting architectures: a U-Net-based model and a DiT-based model. We analyze and propose lightweight injection strategies that minimize interference with the model's original generation capacity while ensuring the mitigation of the two issues. We evaluate ASUKA using the Places2 dataset and MISATO, our proposed diverse benchmark. Experiments show that ASUKA effectively suppresses object hallucination and improves color consistency, outperforming standard diffusion, rectified flow models, and other inpainting methods. Dataset, models and codes will be released in github.

</details>


### [4] [OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation](https://arxiv.org/abs/2601.15369)
*Letian Zhang,Sucheng Ren,Yanqing Liu,Xianhang Li,Zeyu Wang,Yuyin Zhou,Huaxiu Yao,Zeyu Zheng,Weili Nie,Guilin Liu,Zhiding Yu,Cihang Xie*

Main category: eess.IV

TL;DR: OpenVision 3提出了一种统一的视觉编码器，能够同时服务于图像理解和图像生成任务，通过联合优化重建和语义信号，在共享潜在空间中学习协同的表征。


<details>
  <summary>Details</summary>
Motivation: 当前视觉编码器通常分别针对理解任务（如CLIP）和生成任务（如VAE）进行设计，缺乏统一的视觉表征。本文旨在开发一个单一的统一视觉表示，能够同时支持图像理解和生成，促进两种任务之间的协同效应。

Method: 核心架构简单：将VAE压缩的图像潜在表示输入ViT编码器，训练其输出支持两个互补角色：1）传递给ViT-VAE解码器重建原始图像（捕获生成结构）；2）通过对比学习和图像描述目标优化同一表示（增强语义特征）。在共享潜在空间中联合优化重建驱动和语义驱动的信号。

Result: 在冻结编码器的下游评估中：1）多模态理解方面，在LLaVA-1.5框架中与标准CLIP编码器表现相当（SeedBench：62.4 vs 62.2，POPE：83.7 vs 82.9）；2）生成方面，在RAE框架中显著超越标准CLIP编码器（ImageNet gFID：1.89 vs 2.54）。

Conclusion: OpenVision 3证明了统一视觉表示在理解和生成任务上的可行性，通过联合优化重建和语义信号，编码器学习到了能够在这两种任务上良好泛化的协同表征。这项工作有望推动统一建模的未来研究。

Abstract: This paper presents a family of advanced vision encoder, named OpenVision 3, that learns a single, unified visual representation that can serve both image understanding and image generation. Our core architecture is simple: we feed VAE-compressed image latents to a ViT encoder and train its output to support two complementary roles. First, the encoder output is passed to the ViT-VAE decoder to reconstruct the original image, encouraging the representation to capture generative structure. Second, the same representation is optimized with contrastive learning and image-captioning objectives, strengthening semantic features. By jointly optimizing reconstruction- and semantics-driven signals in a shared latent space, the encoder learns representations that synergize and generalize well across both regimes. We validate this unified design through extensive downstream evaluations with the encoder frozen. For multimodal understanding, we plug the encoder into the LLaVA-1.5 framework: it performs comparably with a standard CLIP vision encoder (e.g., 62.4 vs 62.2 on SeedBench, and 83.7 vs 82.9 on POPE). For generation, we test it under the RAE framework: ours substantially surpasses the standard CLIP-based encoder (e.g., gFID: 1.89 vs 2.54 on ImageNet). We hope this work can spur future research on unified modeling.

</details>


### [5] [A Machine Vision Approach to Preliminary Skin Lesion Assessments](https://arxiv.org/abs/2601.15539)
*Ali Khreis,Ro'Yah Radaideh,Quinn McGill*

Main category: eess.IV

TL;DR: 本研究比较了基于ABCD规则的皮肤病变评估系统与多种机器学习方法，发现从头训练的小型CNN在小型医学数据集上优于传统方法和大型预训练模型。


<details>
  <summary>Details</summary>
Motivation: 恶性皮肤病变的早期检测对改善患者预后至关重要。本研究旨在评估结合临床ABCD规则与机器学习分类的综合皮肤病变评估系统，探索自动化诊断的最佳方法。

Method: 使用HAM10000数据集的1000张图像子集，实现基于ABCD规则的自动化管道计算总皮肤镜评分（TDS）。比较了规则系统、传统分类器（逻辑回归、随机森林、SVM）和深度学习模型（EfficientNet-B0迁移学习、自定义三层CNN）。

Result: 规则系统临床可解释性高但性能受限；EfficientNet-B0因自然图像与医学图像的领域偏移而失败；自定义三层CNN在应用中值滤波的图像上达到78.5%准确率和86.5%召回率，比传统方法提高19个百分点。

Conclusion: 直接像素级学习能捕捉手工特征之外的诊断模式；针对小型、特定领域医学数据集，专门构建的轻量级架构可以超越大型预训练模型；领域适应和从头训练对医学图像分析至关重要。

Abstract: Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets.

</details>


### [6] [FUGC: Benchmarking Semi-Supervised Learning Methods for Cervical Segmentation](https://arxiv.org/abs/2601.15572)
*Jieyun Bai,Yitong Tang,Zihao Zhou,Mahdi Islam,Musarrat Tabassum,Enrique Almar-Munoz,Hongyu Liu,Hui Meng,Nianjiang Lv,Bo Deng,Yu Chen,Zilun Peng,Yusong Xiao,Li Xiao,Nam-Khanh Tran,Dac-Phu Phan-Le,Hai-Dang Nguyen,Xiao Liu,Jiale Hu,Mingxu Huang,Jitao Liang,Chaolu Feng,Xuezhi Zhang,Lyuyang Tong,Bo Du,Ha-Hieu Pham,Thanh-Huy Nguyen,Min Xu,Juntao Jiang,Jiangning Zhang,Yong Liu,Md. Kamrul Hasan,Jie Gan,Zhuonan Liang,Weidong Cai,Yuxin Huang,Gongning Luo,Mohammad Yaqub,Karim Lekadir*

Main category: eess.IV

TL;DR: FUGC是首个针对宫颈分割的半监督学习基准，在ISBI 2025发布，包含890张TVS图像，旨在解决标记数据稀缺问题，为AI辅助早产风险评估提供基础。


<details>
  <summary>Details</summary>
Motivation: 经阴道超声宫颈结构准确分割对评估自发性早产风险至关重要，但标记数据稀缺限制了监督学习方法的性能，需要建立半监督学习基准来解决这一问题。

Method: 提出FUGC基准挑战，提供890张TVS图像数据集（500训练/90验证/300测试），使用Dice相似系数、Hausdorff距离和运行时间三个指标加权评估（0.4/0.4/0.2），吸引了10个团队82名参与者提交创新解决方案。

Result: 最佳方法在各项指标上分别达到90.26% mDSC、38.88 mHD和32.85 ms RT，证明了半监督方法在有限标记数据下的有效性，为AI辅助临床早产风险评估提供了基础。

Conclusion: FUGC建立了宫颈分割的标准化基准，展示了半监督方法在有限标记数据下的有效性，为AI辅助临床早产风险评估提供了重要基础。

Abstract: Accurate segmentation of cervical structures in transvaginal ultrasound (TVS) is critical for assessing the risk of spontaneous preterm birth (PTB), yet the scarcity of labeled data limits the performance of supervised learning approaches. This paper introduces the Fetal Ultrasound Grand Challenge (FUGC), the first benchmark for semi-supervised learning in cervical segmentation, hosted at ISBI 2025. FUGC provides a dataset of 890 TVS images, including 500 training images, 90 validation images, and 300 test images. Methods were evaluated using the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD), and runtime (RT), with a weighted combination of 0.4/0.4/0.2. The challenge attracted 10 teams with 82 participants submitting innovative solutions. The best-performing methods for each individual metric achieved 90.26\% mDSC, 38.88 mHD, and 32.85 ms RT, respectively. FUGC establishes a standardized benchmark for cervical segmentation, demonstrates the efficacy of semi-supervised methods with limited labeled data, and provides a foundation for AI-assisted clinical PTB risk assessment.

</details>


### [7] [THOR: A Versatile Foundation Model for Earth Observation Climate and Society Applications](https://arxiv.org/abs/2601.16011)
*Theodor Forgaard,Jarle H. Reksten,Anders U. Waldeland,Valerio Marsocci,Nicolas Longépé,Michael Kampffmeyer,Arnt-Børre Salberg*

Main category: eess.IV

TL;DR: THOR是一个计算自适应的地球观测基础模型，能够统一处理多传感器数据，支持任意补丁大小部署，实现计算成本与特征分辨率的动态权衡。


<details>
  <summary>Details</summary>
Motivation: 当前地球观测基础模型存在架构僵化、难以处理异构传感器、受限于固定补丁大小等问题，限制了在实际场景中灵活权衡计算与精度的部署需求。

Method: 提出THOR模型，首次统一处理Sentinel-1、-2、-3卫星数据，采用随机化补丁和输入图像大小策略进行预训练，使单一权重集能在推理时处理任意补丁大小。

Result: 在THOR Pretrain数据集上预训练后，在下游基准测试中达到最先进性能，特别是在数据有限的情况下（如PANGAEA 10%分割）表现优异。

Conclusion: THOR解决了输入异质性和部署刚性问题，其灵活的特征生成能力适用于多样化的气候和社会应用场景。

Abstract: Current Earth observation foundation models are architecturally rigid, struggle with heterogeneous sensors and are constrained to fixed patch sizes. This limits their deployment in real-world scenarios requiring flexible computeaccuracy trade-offs. We propose THOR, a "computeadaptive" foundation model that solves both input heterogeneity and deployment rigidity. THOR is the first architecture to unify data from Copernicus Sentinel-1, -2, and -3 (OLCI & SLSTR) satellites, processing their native 10 m to 1000 m resolutions in a single model. We pre-train THOR with a novel randomized patch and input image size strategy. This allows a single set of pre-trained weights to be deployed at inference with any patch size, enabling a dynamic trade-off between computational cost and feature resolution without retraining. We pre-train THOR on THOR Pretrain, a new, large-scale multi-sensor dataset and demonstrate state-of-the-art performance on downstream benchmarks, particularly in data-limited regimes like the PANGAEA 10% split, validating that THOR's flexible feature generation excels for diverse climate and society applications.

</details>


### [8] [Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation](https://arxiv.org/abs/2601.16064)
*Shams Nafisa Ali,Taufiq Hasan*

Main category: eess.IV

TL;DR: Phi-SegNet：一种结合相位感知信息的CNN架构，通过在架构和优化层面整合频域表示，提升医学图像分割的泛化能力和边界精度


<details>
  <summary>Details</summary>
Motivation: 现有分割架构主要编码空间信息而忽略频域表示，后者包含丰富的结构和纹理线索。虽然最近有研究在特征层面探索谱信息，但在监督层面整合频率线索（对细粒度目标定位至关重要）仍未充分开发

Method: 提出Phi-SegNet，包含：1）Bi-Feature Mask Former模块，混合相邻编码器特征以减少语义差距；2）Reverse Fourier Attention块，使用相位正则化特征细化解码器输出；3）专用相位感知损失，将特征与结构先验对齐，形成强调边界精度的闭环反馈

Result: 在五个公共数据集（X射线、超声、组织病理学、MRI、结肠镜）上评估，Phi-SegNet始终达到最先进性能，IoU平均相对提升1.54±1.26%，F1分数提升0.98±0.71%。在跨数据集泛化场景中也表现出鲁棒和优越性能

Conclusion: 研究证明了在特征表示和监督中利用谱先验的潜力，为在细粒度目标定位方面表现出色的通用分割框架铺平了道路

Abstract: Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [9] [ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks](https://arxiv.org/abs/2601.15422)
*Berk Ciloglu,Ozgun Ersoy,Metin Ozturk,Ali Gorcin*

Main category: eess.SP

TL;DR: 该论文提出了一种ISAC-over-NTN架构，结合无人机和HAPS平台，在灾后场景中同时提供可靠通信和用户检测功能。


<details>
  <summary>Details</summary>
Motivation: 灾害场景中地面网络可能部分或完全瘫痪，需要确保可靠的通信和态势感知能力，以支持搜救行动和人员连接。

Method: 采用创新的波束成形方法，将多用户MIMO通信和单基地感知集成在同一传输链中，同时传输数据并基于多普勒效应检测用户移动性。

Result: 该框架在保持可靠连接的同时，实现了对关键位置用户的高检测精度，达到90%的运动检测灵敏度和88%的检测准确率。

Conclusion: ISAC-over-NTN架构能够有效解决灾后场景中的通信和用户检测需求，为搜救行动提供可靠的技术支持。

Abstract: In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.

</details>


### [10] [Achievable Rate Optimization for Large Flexible Intelligent Metasurface Assisted Downlink MISO under Statistical CSI](https://arxiv.org/abs/2601.15471)
*Ling He,Vaibhav Kumar,Anastasios Papazafeiropoulos,Miaowen Wen,Le-Nam Tran,Marwa Chafii*

Main category: eess.SP

TL;DR: 提出基于统计CSI的柔性智能超表面优化框架，用于MISO下行系统，通过联合优化功率分配和超表面形变来最大化平均可达和速率


<details>
  <summary>Details</summary>
Motivation: 现有柔性智能超表面辅助系统设计大多假设完美的瞬时信道状态信息，这在大规模网络中不切实际，因为训练开销大且信道估计复杂

Method: 提出基于统计CSI的鲁棒优化框架，开发基于块坐标上升的迭代算法，联合优化功率分配和FIM形变

Result: 仿真结果表明，所提出的统计CSI驱动的FIM设计显著优于传统的刚性天线阵列，验证了其有效性和实用性

Conclusion: 基于统计CSI的柔性智能超表面优化框架能够有效解决大规模网络中瞬时CSI获取困难的问题，提供实用且性能优越的解决方案

Abstract: The integration of electromagnetic metasurfaces into wireless communications enables intelligent control of the propagation environment. Recently, flexible intelligent metasurfaces (FIMs) have evolved beyond conventional reconfigurable intelligent surfaces (RISs), enabling three-dimensional surface deformation for adaptive wave manipulation. However, most existing FIM-aided system designs assume perfect instantaneous channel state information (CSI), which is impractical in large-scale networks due to the high training overhead and complicated channel estimation. To overcome this limitation, we propose a robust statistical-CSI-based optimization framework for downlink multiple-input single-output (MISO) systems with FIM-assisted transmitters. A block coordinate ascent (BCA)-based iterative algorithm is developed to jointly optimize power allocation and FIM morphing, maximizing the average achievable sum rate. Simulation results show that the proposed statistical-CSI-driven FIM design significantly outperforms conventional rigid antenna arrays (RAAs), validating its effectiveness and practicality.

</details>


### [11] [Applicability and Limitation Analysis of PMU Data and Phasor Concept for Low- and High- Frequency Oscillations](https://arxiv.org/abs/2601.15529)
*Bowen Ou,Bin Wang,Slava Maslennikov,Hanchao Liu,Jim Follum*

Main category: eess.SP

TL;DR: 该论文揭示了PMU在表示高频振荡信号时的根本局限性，提出了更通用的信号模型和多步估计方法，并指出相量概念本身在高频振荡下可能失效。


<details>
  <summary>Details</summary>
Motivation: PMU将高速波形数据转换为低速相量数据，是电力系统广域监测和控制的基础，但现有PMU相量表示振荡信号仅对低频振荡有效。本文旨在探究这一局限性的根本原因，并提出更好的解决方案。

Method: 提出更通用的信号模型，采用多步估计方法，结合单周期DFT、矩阵铅笔法和最小二乘法来更好地表示和估计含振荡的波形信号。

Result: 数值实验表明所提出的信号模型和估计方法具有优越性能。研究还发现，对于具有不对称次同步和超同步分量的高频振荡信号，相量概念本身可能失效。

Conclusion: 研究揭示了PMU数据和相量概念的根本局限性，强调在现代电力系统中分析高频振荡时需要依赖波形数据而非相量数据。

Abstract: Phasor Measurement Units (PMUs) convert high-speed waveform data into low-speed phasor data, which are fundamental to wide-area monitoring and control in power systems, with oscillation detection and localization among their most prominent applications. However, representing electrical waveform signals with oscillations using PMU phasors is effective only for low-frequency oscillations. This paper investigates the root causes of this limitation, focusing on errors introduced by Discrete Fourier Transform (DFT)-based signal processing, in addition to the attenuation effects of anti-aliasing filters, and the impact of low reporting rates. To better represent and estimate waveform signals with oscillations, we propose a more general signal model and a multi-step estimation method that leverages one-cycle DFT, the Matrix Pencil Method, and the Least Squares Method. Numerical experiments demonstrate the superior performance of the proposed signal model and estimation method. Furthermore, this paper reveals that the phasor concept, let alone PMU phasors, can become invalid for waveform signals with high-frequency oscillations characterized by asymmetric sub- and super-synchronous components. These findings highlight the fundamental limitations of PMU data and phasor concept, and emphasize the need to rely on waveform data for analyzing high-frequency oscillations in modern power systems.

</details>


### [12] [Distributed Uplink Anti-Jamming in LEO Mega-Constellations via Game-Theoretic Beamforming](https://arxiv.org/abs/2601.15557)
*Shizhen Jia,Mingjun Ying,Marco Mezzavilla,Theodore S. Rappaport,Sundeep Rangan*

Main category: eess.SP

TL;DR: 本文提出一种分布式多卫星抗干扰策略，利用LEO巨型星座的密集连接和高速星间链路，通过凸凹博弈建模和高效min-max求解器，显著提升卫星网络在强干扰下的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: LEO卫星星座在轨道动力学可预测和几何暴露的情况下，容易受到地面干扰。传统单卫星干扰抑制技术即使在大型天线阵列下也难以从附近干扰机中空间分离期望的上行链路信号。

Method: 将上行干扰场景建模为期望地面发射机与干扰机之间的凸凹博弈，双方优化空间协方差矩阵以最大化或最小化可达速率。提出结合交替最佳响应更新和投影梯度下降的高效min-max求解器，使波束成形策略快速收敛到纳什均衡。

Result: 使用真实的Starlink轨道几何和Sionna射线追踪仿真表明，近距离干扰机可以瘫痪单卫星链路，但分布式卫星协作显著增强了抗干扰能力，在强干扰下将容量分布向上移动。

Conclusion: 分布式多卫星抗干扰策略利用现代LEO巨型星座的密集连接特性，通过卫星间协作有效对抗地面干扰，为NTN提供了更强的抗干扰能力。

Abstract: Low-Earth-Orbit (LEO) satellite constellations have become vital in emerging commercial and defense Non-Terrestrial Networks (NTNs). However, their predictable orbital dynamics and exposed geometries make them highly susceptible to ground-based jamming. Traditional single-satellite interference mitigation techniques struggle to spatially separate desired uplink signals from nearby jammers, even with large antenna arrays. This paper explores a distributed multi-satellite anti-jamming strategy leveraging the dense connectivity and high-speed inter-satellite links of modern LEO mega-constellations. We model the uplink interference scenario as a convex-concave game between a desired terrestrial transmitter and a jammer, each optimizing their spatial covariance matrices to maximize or minimize achievable rate. We propose an efficient min-max solver combining alternating best-response updates with projected gradient descent, achieving fast convergence of the beamforming strategy to the Nash equilibrium. Using realistic Starlink orbital geometries and Sionna ray-tracing simulations, we demonstrate that while close-proximity jammers can cripple single-satellite links, distributed satellite cooperation significantly enhances resilience, shifting the capacity distribution upward under strong interference.

</details>


### [13] [An Iterated Hybrid Fast Parallel FIR Filter](https://arxiv.org/abs/2601.15582)
*Keshab K. Parhi*

Main category: eess.SP

TL;DR: 提出一种新型迭代快速并行FIR滤波器——快速混合滤波器，通过在不同层使用不同结构的2-并行滤波器来降低硬件复杂度


<details>
  <summary>Details</summary>
Motivation: 并行FIR滤波通过同时处理多个输入样本提高DSP应用的计算效率和吞吐量，需要设计更高效的并行滤波器架构

Method: 采用迭代FFA方法，在内部层使用转置2-并行快速FIR滤波器，在最外层使用直接形式2-并行快速FIR滤波器，形成混合结构

Result: 混合快速并行滤波器相比先前方法需要更少的加法运算，降低了硬件复杂度

Conclusion: 提出的快速混合滤波器架构通过创新的迭代混合设计，在保持并行处理优势的同时减少了硬件资源需求

Abstract: This paper revisits the design and optimization of parallel fast finite impulse response (FIR) filters using polyphase decomposition and iterated fast FIR algorithms (FFAs). Parallel FIR filtering enhances computational efficiency and throughput in digital signal processing (DSP) applications by enabling the simultaneous processing of multiple input samples. We revisit a prior approach to design of fast parallel filter architectures by using the iterated FFA approach where the same primitive filter, such as 2-parallel, is iterated to design the fast parallel filter. In this paper, we present yet another novel iterated fast parallel FIR filter, referred to as the fast hybrid filter. The hybrid filter iterates a transposed 2-parallel fast FIR filter in all the inner layers and a direct-form 2-parallel fast FIR filter in the outermost layer, resulting in reduced hardware complexity. Such an iterated hybrid approach has not been presented before. We show that the hybrid fast parallel filters require less number of additions compared to prior approaches.

</details>


### [14] [Amalgamated CHIRP and OFDM for ISAC](https://arxiv.org/abs/2601.15584)
*Pankaj Kumar,Mohammed El-Hajjar,Ibrahim A. Hemadeh,Yasser Mestrah,Suraj Srivastava,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出一种结合OFDM和chirp波形的新型ISAC波形，通过仿射叠加实现低PAPR的准恒定包络OFDM，利用chirp进行感知而不占用通信资源，提升感知精度和通信效率。


<details>
  <summary>Details</summary>
Motivation: 传统OFDM系统存在高PAPR问题，且ISAC中感知功能需要占用通信资源，降低通信性能。需要开发能同时高效支持通信和感知的波形。

Method: 提出OFDM与chirp波形的仿射融合架构，利用chirp进行感知而不消耗通信资源。在时隙级将chirp信号集成到OFDM框架中，提升距离估计精度。

Result: 融合波形具有更好的自相关特性，改善距离和速度的RMSE，降低PAPR，实现准恒定包络OFDM。同时表征了通信与感知性能之间的权衡关系。

Conclusion: 提出的OFDM-chirp融合波形有效解决了传统OFDM的高PAPR问题，在ISAC框架中实现了感知不占用通信资源，提升了整体系统性能。

Abstract: Integrated Sensing and Communication (ISAC) requires the development of a waveform capable of efficiently supporting both communication and sensing functionalities. This paper proposes a novel waveform that combines the benefits of both the orthogonal frequency division multiplexing (OFDM) and the chirp waveforms to improve both the communication and sensing performance within an ISAC framework. Hence, a new architecture is proposed that utilizes the conventional communication framework while leveraging the parameters sensed at the receiver (Rx) for enhancing the communication performance. We demonstrate that the affine addition of OFDM and chirp signals results in a near constant-envelope OFDM waveform, which effectively reduces the peak-to-average power ratio (PAPR), a key limitation of traditional OFDM systems. Using the OFDM framework for sensing in the conventional fashion requires the allocation of some resources for sensing, which in turn reduces communication performance. As a remedy, the proposed affine amalgam facilitates sensing through the chirp waveform without consuming communication resources, thereby preserving communication efficiency. Furthermore, a novel technique of integrating the chirp signal into the OFDM framework at the slot-level is proposed to enhance the accuracy of range estimation. The results show that the OFDM signal incorporated with chirp has better autocorrelation properties, improved root mean square error (RMSE) of range and velocity, and lower PAPR. Finally, we characterize the trade-off between communications and sensing performance.

</details>


### [15] [Does 6G Need a New Waveform: Comparing Zak-OTFS with CP-OFDM](https://arxiv.org/abs/2601.15602)
*Imran Ali Khan,Saif Khan Mohammed,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank,Anton Monk,Shachar Kons,Shlomo Rakib,Yoav Hebron*

Main category: eess.SP

TL;DR: 本文全面比较了CP-OFDM和Zak-OTFS在6G传播环境中的性能，指出波形选择本质上是架构选择：OFDM避免ICI而Zak-OTFS接受ICI，后者在高速移动和大时延扩展场景中表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着全球对Zak-OTFS等新波形的兴趣增长，需要在6G各种传播环境下系统比较CP-OFDM和Zak-OTFS的性能，为波形选择提供依据。核心问题是理解波形选择本质上是架构选择：避免ICI（OFDM）还是接受ICI（Zak-OTFS）。

Method: 对循环前缀OFDM（CP-OFDM）和Zak-OTFS在完整的6G传播环境范围内进行全面的性能比较分析。

Result: Zak-OTFS在具有高时延/多普勒扩展的双扩展6G使用场景（如高速移动和/或大蜂窝）中表现出优越性能。架构选择取决于典型使用场景，而典型场景受地理因素影响（大蜂窝在许多重要无线市场中是常态）。

Conclusion: 波形选择本质上是架构选择：OFDM通过避免ICI简化均衡但受限于ICI不可预测性；Zak-OTFS虽然均衡更复杂但I/O关系可预测且获取简单。在6G高移动性/大蜂窝场景中，Zak-OTFS更具优势。

Abstract: Across the world, there is growing interest in new waveforms, Zak-OTFS in particular, and over-the-air implementations are starting to appear. The choice between OFDM and Zak-OTFS is not so much a choice between waveforms as it is an architectural choice between preventing inter-carrier interference (ICI) and embracing ICI. In OFDM, once the Input-Output (I/O) relation is known, equalization is relatively simple, at least when there is no ICI. However, in the presence of ICI the I/O relation is non-predictable and its acquisition is non-trivial. In contrast, equalization is more involved in Zak-OTFS due to inter-symbol-interference (ISI), however the I/O relation is predictable and its acquisition is simple. {Zak-OTFS exhibits superior performance in doubly-spread 6G use cases with high delay/Doppler channel spreads (i.e., high mobility and/or large cells), but architectural choice is governed by the typical use case, today and in the future. What is typical depends to some degree on geography, since large delay spread is a characteristic of large cells which are the rule rather than the exception in many important wireless markets.} This paper provides a comprehensive performance comparison of cyclic prefix OFDM (CP-OFDM) and Zak-OTFS across the full range of 6G propagation environments. The performance results provide insights into the fundamental architectural choice.

</details>


### [16] [Bistatic ISAC: Practical Challenges and Solutions](https://arxiv.org/abs/2601.15733)
*Lucas Giroto,Marcus Henninger,Alexander Felix,Maximilian Bauhofer,Taewon Jeong,Umut Utku Erdem,Stephan ten Brink,Thomas Zwick,Benjamin Nuss,Silvio Mandelli*

Main category: eess.SP

TL;DR: 本文探讨了6G网络中双基地集成感知与通信的实际挑战与解决方案，重点讨论了OFDM波形下的系统设计、硬件损伤影响限制、信号处理技术以及基于5G参数的仿真结果。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，集成感知与通信成为关键技术。双基地ISAC在实际部署中面临硬件损伤、同步困难等实际问题，需要系统性的解决方案来平衡感知性能与通信质量。

Method: 采用正交频分复用波形，设计系统以同时满足感知性能指标和限制硬件损伤影响。提出空中同步信号处理技术，生成包含距离、多普勒频移和角度信息的周期图。通过基于5G参数的仿真验证方案。

Result: 仿真结果显示，在符合5G标准的蜂窝ISAC场景下，所提出的系统设计和信号处理技术能够有效实现感知功能，同时控制硬件损伤的影响。验证了双基地ISAC在实际部署中的可行性。

Conclusion: 双基地ISAC在6G网络中具有实际应用潜力，但需要解决硬件损伤、同步精度等挑战。提出的系统设计和信号处理方案为实际部署提供了基础，未来仍需进一步研究开放挑战。

Abstract: This article presents and discusses challenges and solutions for practical issues in bistatic integrated sensing and communication (ISAC) in 6G networks. Considering orthogonal frequency-division multiplexing as the adopted waveform, a discussion on system design aiming to achieve both a desired sensing key performance indicators and limit the impact of hardware impairments is presented. In addition, signal processing techniques to enable over-the-air synchronization and generation of periodograms with range, Doppler shift, and angular information are discussed. Simulation results are then presented for a cellular-based ISAC scenario considering system parameterization compliant to current 5G and, finally, a discussion on open challenges for future deployments is presented.

</details>


### [17] [Joint Pilot and Unknown Data-based Localization for OFDM Opportunistic Radar Systems](https://arxiv.org/abs/2601.15785)
*Mathieu Reniers,Martin Willame,Jérôme Louveaux,Luc Vandendorpe*

Main category: eess.SP

TL;DR: 提出一种从通信信号的数据载荷中提取定位信息而不解码的方法，利用FFT实现高效估计，相比现有方法有更好的定位性能


<details>
  <summary>Details</summary>
Motivation: 现有ISAC方法要么仅使用导频信号进行定位（忽略数据符号中的雷达信息），要么依赖数据解码（定位性能受限于通信系统）。需要一种能从数据载荷中提取定位信息而不解码的方法。

Method: 提出新颖方法，从数据载荷中提取定位信息而不解码。考虑机会场景：用户通信信号被配备均匀线性阵列天线的机会雷达捕获。使用快速傅里叶变换实现高效估计。

Result: 通过数值仿真证明，该方法相比文献中现有方法具有更优越的定位性能。

Conclusion: 该方法能够有效利用通信信号中的数据载荷进行定位，无需解码，在ISAC系统中实现了更好的定位性能。

Abstract: Integrated Sensing and Communications (ISAC) has emerged as a promising paradigm for Sixth Generation (6G) and Wi-Fi 7 networks, with the communication-centric approach being particularly attractive due to its compatibility with current standards. Typical communication signals comprise both deterministic known pilot signals and random unknown data payloads. Most existing approaches either rely solely on pilots for positioning, thereby ignoring the radar information present in the received data symbols that constitute the majority of each frame, or rely on data decisions, which bounds positioning performance to that of the communication system. To overcome these limitations, we propose a novel method that extracts positioning information from data payloads without decoding them. We consider an opportunistic scenario in which communication signals from a user are captured by an opportunistic radar equipped with a Uniform Linear Arrays of antennas. We show that, in this setting, the estimation can be efficiently implemented using Fast Fourier Transforms. Finally, we demonstrate superior localization performance compared to existing methods in the literature through numerical simulations.

</details>


### [18] [Adaptive Non-Uniform Sampling of Bandlimited Signals via Algorithm-Encoder Co-Design](https://arxiv.org/abs/2601.15790)
*Kaluguri Yashaswini,Anshu Arora,Satish Mulleti*

Main category: eess.SP

TL;DR: 提出基于算法-编码器协同设计的自适应非均匀采样框架，通过局部能量条件允许在信号缓慢变化区域稀疏采样，在快速变化区域密集采样，显著降低采样密度。


<details>
  <summary>Details</summary>
Motivation: 传统均匀采样需要满足全局Nyquist条件，即使信号缓慢变化区域也需高密度采样，造成资源浪费。希望开发自适应采样方法，根据信号局部特性动态调整采样密度。

Method: 1) 推导局部能量收敛条件；2) 设计可变偏置、可变阈值积分-放电时间编码机(VBT-IF-TEM)；3) 引入移位信号公式抑制过采样；4) 使用时间编码和信号平均值离散表示模拟信号；5) 通过标准迭代算法实现完美重建。

Result: 相比均匀采样和传统IF-TEM，在合成信号、超声导波和ECG信号上实现采样密度显著降低，同时保持准确重建。展示了采样密度、重建精度和收敛行为之间的可控权衡。

Conclusion: 提出的自适应非均匀采样框架突破了传统Nyquist限制，允许局部采样率低于Nyquist率，通过算法-编码器协同设计实现了采样效率与重建精度的优化平衡。

Abstract: We propose an adaptive non-uniform sampling framework for bandlimited signals based on an algorithm-encoder co-design perspective. By revisiting the convergence analysis of iterative reconstruction algorithms for non-uniform measurements, we derive a local, energy-based sufficient condition that governs reconstruction behavior as a function of the signal and derivative energies within each sampling interval. Unlike classical approaches that impose a global Nyquist-type bound on the inter-sample spacing, the proposed condition permits large gaps in slowly varying regions while enforcing denser sampling only where the signal exhibits rapid temporal variation. Building on this theoretical insight, we design a variable-bias, variable-threshold integrate-and-fire time encoding machine (VBT-IF-TEM) whose firing mechanism is explicitly shaped to enforce the derived local convergence condition. To ensure robustness, a shifted-signal formulation is introduced to suppress excessive firing in regions where the magnitude of the signal amplitude is close to zero or the local signal energy approaches zero. Using the proposed encoder, an analog signal is discretely represented by time encodings and signal averages, enabling perfect reconstruction via a standard iterative algorithm even when the local sampling rate falls below the Nyquist rate. Simulation results on synthetic signals and experiments on ultrasonic guided-wave and ECG signals demonstrate that the proposed framework achieves substantial reductions in sampling density compared to uniform sampling and conventional IF-TEMs, while maintaining accurate reconstruction. The results further highlight a controllable tradeoff between sampling density, reconstruction accuracy, and convergence behavior, which can be navigated through adaptive parameter selection.

</details>


### [19] [Dual-Mapping Sparse Vector Transmission for Short Packet URLLC](https://arxiv.org/abs/2601.15819)
*Yanfeng Zhang,Xu Zhu,Jinkai Zheng,Weiwei Yang,Xianhua Yu,Haiyong Zeng,Yujie Liu,Yong Liang Guan*

Main category: eess.SP

TL;DR: 提出双映射稀疏向量编码(DM-SVC)方案，通过块稀疏映射和单元素稀疏映射相结合，提升短包传输性能，在块错误率和频谱效率方面优于现有SVC方案。


<details>
  <summary>Details</summary>
Motivation: 稀疏向量编码(SVC)是下一代通信系统中超可靠低延迟通信(URLLC)的有前景的短包传输方法，但需要进一步提升传输性能。

Method: 提出双映射SVC(DM-SVC)方案，核心思想是通过块稀疏映射和单元素稀疏映射将传输信息比特映射到稀疏向量。块稀疏映射能将发射功率集中在少量非零块中提高解码精度，单元素稀疏映射确保码长不会随传输信息比特数急剧增加。接收端采用两阶段解码算法顺序识别非零块索引和单元素非零索引。

Result: 大量仿真结果验证了所提DM-SVC方案在块错误率和频谱效率方面优于现有SVC方案。

Conclusion: DM-SVC方案通过双映射策略有效提升了SVC的短包传输性能，为URLLC应用提供了更优的解决方案。

Abstract: Sparse vector coding (SVC) is a promising short-packet transmission method for ultra reliable low latency communication (URLLC) in next generation communication systems. In this paper, a dual-mapping SVC (DM-SVC) based short packet transmission scheme is proposed to further enhance the transmission performance of SVC. The core idea behind the proposed scheme lies in mapping the transmitted information bits onto sparse vectors via block and single-element sparse mappings. The block sparse mapping pattern is able to concentrate the transmit power in a small number of non-zero blocks thus improving the decoding accuracy, while the single-element sparse mapping pattern ensures that the code length does not increase dramatically with the number of transmitted information bits. At the receiver, a two-stage decoding algorithm is proposed to sequentially identify non-zero block indexes and single-element non-zero indexes. Extensive simulation results verify that proposed DM-SVC scheme outperforms the existing SVC schemes in terms of block error rate and spectral efficiency.

</details>


### [20] [Separable Delay And Doppler Estimation In Passive Radar](https://arxiv.org/abs/2601.15821)
*Mats Viberg,Daniele Gerosa,Tomas McKelvey,Patrik Dammert,Thomas Eriksson*

Main category: eess.SP

TL;DR: 提出一种用于被动雷达的可分离参数估计方法，将时延和多普勒参数分开估计，避免昂贵的二维搜索，降低计算复杂度和通信开销。


<details>
  <summary>Details</summary>
Motivation: 被动雷达中，分布式传感器网络利用机会照射源信号检测和定位目标。传统方法需要联合估计目标的时延和多普勒参数，这需要进行昂贵的二维搜索，计算复杂度高，在分布式雷达设置中通信开销大。

Method: 提出可分离估计方法：首先将数据分成可管理大小的批次；然后单独估计时延参数（避免二维搜索）；给定时延估计后，恢复批次间的相干性来估计多普勒参数。该方法针对慢速移动目标设计。

Result: 时延估计精度与全批次二维方法相似；多普勒参数估计在广泛参数范围内优于传统方法；同时显著降低了计算复杂度和分布式雷达设置中的通信开销。

Conclusion: 提出的可分离参数估计方法为被动雷达提供了一种有效的替代方案，在保持时延估计精度的同时，提高了多普勒估计性能，并显著降低了计算和通信成本。

Abstract: In passive radar, a network of distributed sensors exploit signals from so-called Illuminators-of-Opportunity to detect and localize targets. We consider the case where the IO signal is available at each receiver node through a reference channel, whereas target returns corrupted by interference are collected in a separate surveillance channel. The problem formulation is similar to an active radar that uses a noise-like waveform, or an integrated sensing and communication application. The available data is first split into batches of manageable size. In the direct approach, the target's time-delay and Doppler parameters are estimated jointly by incoherently combining the batch-wise data. We propose a new method to estimate the time-delay separately, thus avoiding a costly 2-D search. Our approach is designed for slowly moving targets, and the accuracy of the time-delay estimate is similar to that of the full batch-wise 2-D method. Given the time-delay, the coherency between batches can be restored when estimating the Doppler parameter. Thereby, the separable approach is found to yield superior Doppler estimates over a wide parameter range. In addition to reducing computational complexity, the proposed separable estimation technique also significantly reduces the communication overhead in a distributed radar setting.

</details>


### [21] [Performance Analysis of Digital Beamforming mmWave MIMO with Low-Resolution DACs/ADCs](https://arxiv.org/abs/2601.15831)
*Faruk Pasic,Mariam Mussbah,Stefan Schwarz,Markus Rupp,Fredrik Tufvesson,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 研究毫米波MIMO系统中全数字波束成形在低分辨率量化下的信道估计性能，发现4位DAC/ADC能在能耗和速率间提供良好折衷


<details>
  <summary>Details</summary>
Motivation: 未来无线通信需要毫米波MIMO全数字波束成形来提供高数据速率，但全数字系统需要低分辨率DAC/ADC来保证能效，这些量化器会引入失真并降低系统性能

Method: 研究毫米波MIMO系统在全数字波束成形和低分辨率量化下的信道估计性能，评估系统在频谱效率和能量效率方面的表现

Result: 仿真结果表明，每个DAC/ADC采用4位中等量化分辨率能在能量消耗和可达到的数据速率之间提供有利的折衷

Conclusion: 在毫米波MIMO全数字波束成形系统中，适度的4位量化分辨率是实现能效和性能平衡的可行方案

Abstract: Future wireless communications will rely on multiple-input multiple-output (MIMO) beamforming operating at millimeter wave (mmWave) frequency bands to deliver high data rates. To support flexible spatial processing and meet the demands of latency critical applications, it is essential to use fully digital mmWave MIMO beamforming, which relies on accurate channel estimation. However, ensuring power efficiency in fully digital mmWave MIMO systems requires the use of low-resolution digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). The reduced resolution of these quantizers introduces distortion in both transmitted and received signals, ultimately degrading system performance. In this paper, we investigate the channel estimation performance of mmWave MIMO systems employing fully digital beamforming with low-resolution quantization, under practical system constraints. We evaluate the system performance in terms of spectral efficiency (SE) and energy efficiency (EE). Simulation results demonstrate that a moderate quantization resolutions of 4-bit per DAC/ADC offers a favorable trade-off between energy consumption and achievable data rate.

</details>


### [22] [Time-Varying Rician K-factor in Measured Vehicular Channels at cmWave and mmWave Bands](https://arxiv.org/abs/2601.15863)
*Faruk Pasic,Markus Hofer,Thomas Zemen,Andreas F. Molisch,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 该论文通过多频段信道测量，分析了车对基础设施通信中不同频段（3.2GHz、34.3GHz、62.35GHz）的莱斯K因子时变特性及其与均方根时延扩展的相关性。


<details>
  <summary>Details</summary>
Motivation: 未来车载通信系统将集成毫米波技术以提高数据传输速率，需要研究毫米波与传统厘米波频段的传播效应和小尺度衰落差异，而莱斯K因子是表征小尺度衰落的关键参数。

Method: 在城市街道环境中进行多频段车对基础设施信道测量，使用中心频率为3.2GHz、34.3GHz和62.35GHz的三个频段，带宽155.5MHz，探测重复率31.25μs，分析K因子的时变特性及其与均方根时延扩展的关系。

Result: 研究发现不同频段的莱斯K因子相似，且与均方根时延扩展存在相关性。

Conclusion: 毫米波和厘米波频段在小尺度衰落特性上具有相似性，K因子与时延扩展的相关性为信道建模提供了重要参考。

Abstract: Future vehicular communication systems will integrate millimeter wave (mmWave) technology to enhance data transmission rates. To investigate the propagation effects and small-scale fading differences between mmWave and conventional centimeter wave (cmWave) bands, multi-band channel measurements have to be conducted. One key parameter to characterize small-scale fading is the Rician K-factor. In this paper, we analyze the time-varying K-factor of vehicle-to-infrastructure (V2I) channels across multiple frequency bands, measured in an urban street environment. Specifically, we investigate three frequency bands with center frequencies of 3.2 GHz, 34.3 GHz and 62.35 GHz using measurement data with 155.5 MHz bandwidth and a sounding repetition rate of 31.25 μs. Furthermore, we analyze the relationship between K-factor and root-mean-square (RMS) delay spread. We show that the Ricean K-factor is similar at different frequency bands and that is correlated with the RMS delay spread.

</details>


### [23] [Reconstructing Patched or Partial Holograms to allow for Whole Slide Imaging with a Self-Referencing Holographic Microscope](https://arxiv.org/abs/2601.15952)
*Philip Groult,Julia D. Sistermanns,Ellen Emken,Oliver Hayden,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 提出一种自适应重建算法，将定量相位成像与全玻片成像结合，实现宫颈涂片的三波数字全息显微成像


<details>
  <summary>Details</summary>
Motivation: 目前计算机辅助细胞学诊断主要基于全玻片成像与深度学习，而定量相位成像能提供更丰富的细胞信息但需要较少样本制备。这两种技术尚未结合，需要开发新方法将QPI的优势整合到WSI中。

Method: 开发自适应重建算法，使用自参考三波数字全息显微镜实现宫颈涂片的全玻片成像。算法能处理部分全息图和拼接全息图，适用于单次拍摄的全息图，并具有灵活适应不同输入的适应性。

Result: 算法在测试的上皮细胞上表现良好，成功实现了定量相位成像与全玻片成像的结合，为宫颈涂片提供了更丰富的细胞信息。

Conclusion: 该研究首次将定量相位成像与全玻片成像技术结合，为细胞学筛查提供了新的成像方法，有望改善计算机辅助诊断的准确性和效率。

Abstract: The last decade has seen significant advances in computer-aided diagnostics for cytological screening, mainly through the improvement and integration of scanning techniques such as whole slide imaging (WSI) and the combination with deep learning. Simultaneously, new imaging techniques such as quantitative phase imaging (QPI) are being developed to capture richer cell information with less sample preparation. So far, the two worlds of WSI and QPI have not been combined. In this work, we present a reconstruction algorithm which makes whole slide imaging of cervical smears possible by using a self-referencing three-wave digital holographic microscope. Since a WSI is constructed by combining multiple patches, the algorithm is adaptive and can be used on partial holograms and patched holograms. We present the algorithm for a single shot hologram, the adaptations to make it flexible to various inputs and show that the algorithm performs well for the tested epithelial cells. This is a preprint of our paper, which has been accepted for publication in 2026 IEEE International Symposium on Biomedical Imaging (ISBI).

</details>


### [24] [Performance Scaling Laws for PD Array-based Receivers in IM/DD Optical Wireless Communication Systems](https://arxiv.org/abs/2601.15973)
*Aravindh Krishnamoorthy,Robert Schober,Harald Haas*

Main category: eess.SP

TL;DR: 光电探测器阵列接收机中电域合并的性能缩放规律研究，考虑光功率与电功率的平方律关系，分析阵列系统与单探测器系统的性能对比


<details>
  <summary>Details</summary>
Motivation: 研究光电探测器阵列接收机中电域合并的性能缩放规律，为下一代高带宽探测器阵列接收机的设计提供实用指导

Method: 通过分析光功率与电功率的平方律关系，建立数学模型，比较阵列系统与单探测器系统在信噪比和可达速率方面的性能

Result: 分析结果表明：光电探测器阵列在足够窄的光束和高于特定信噪比阈值时能提供性能增益；仅增加探测器数量不能提升性能，需要联合优化光束模式、电磁模式、接收功率和探测器位置

Conclusion: 光电探测器阵列接收机的设计需要综合考虑多种参数优化，本文模型和洞察为下一代高带宽探测器阵列接收机设计提供了实用指南和权衡考量

Abstract: We study the performance scaling laws for electrical-domain combining in photodetector (PD) array-based receivers employing intensity modulation and direct detection, taking into account the inherent square-law relationship between the optical and electrical received powers. The performance of PD array-based systems is compared, in terms of signal-to-noise ratio (SNR) and achievable rate, to that of a reference receiver employing a single PD. Analytical and numerical results show that PD arrays provide performance gains for sufficiently narrow beams and above an SNR threshold. Furthermore, increasing the number of PDs alone does not enhance performance, and joint optimization of beam pattern, transverse electromagnetic mode, received power, and PD positions is necessary. Our model and derived insights provide practical guidelines and highlight the trade-offs for the design of next-generation high-bandwidth PD array receivers.

</details>


### [25] [Graph Topology Identification Based on Covariance Matching](https://arxiv.org/abs/2601.15999)
*Yongsheng Han,Raj Thilak Rajan,Geert Leus*

Main category: eess.SP

TL;DR: 提出CovMatch框架，通过匹配经验协方差与图模型理论协方差来统一解决图拓扑识别问题，无需传统方法的限制性假设。


<details>
  <summary>Details</summary>
Motivation: 传统图拓扑识别方法依赖概率模型或复杂优化，常面临非凸性、需要无环性或正权重等限制性假设的问题。需要一种更通用、假设更少的框架。

Method: 提出协方差匹配(CovMatch)框架：直接对齐观测数据的经验协方差与底层图模型的理论协方差。通过重参数化，将图学习问题简化为圆锥混合整数规划（无向图）或正交矩阵优化（有向图）。

Result: CovMatch能处理无向图和稀疏有向图（无论是否无环或正权重），无需显式结构约束知识。数值实验表明，即使对于较大图，该方法也能高效恢复真实拓扑，在准确性上优于标准基线方法。

Conclusion: CovMatch是图拓扑识别的强大替代方案，为学习复杂网络拓扑提供了更少假设的途径，有望推动该领域更广泛的研究。

Abstract: Graph topology identification (GTI) is a central challenge in networked systems, where the underlying structure is often hidden, yet nodal data are available. Conventional solutions to address these challenges rely on probabilistic models or complex optimization formulations, commonly suffering from non-convexity or requiring restrictive assumptions on acyclicity or positivity. In this paper, we propose a novel covariance matching (CovMatch) framework that directly aligns the empirical covariance of the observed data with the theoretical covariance implied by an underlying graph. We show that as long as the data-generating process permits an explicit covariance expression, CovMatch offers a unified route to topology inference.
  We showcase our methodology on linear structural equation models (SEMs), showing that CovMatch naturally handles both undirected and general sparse directed graphs - whether acyclic or positively weighted - without explicit knowledge of these structural constraints. Through appropriate reparameterizations, CovMatch simplifies the graph learning problem to either a conic mixed integer program for undirected graphs or an orthogonal matrix optimization for directed graphs. Numerical results confirm that, even for relatively large graphs, our approach efficiently recovers the true topology and outperforms standard baselines in accuracy. These findings highlight CovMatch as a powerful alternative to log-determinant or Bayesian methods for GTI, paving the way for broader research on learning complex network topologies with minimal assumptions.

</details>


### [26] [Low-Complexity Sparse Superimposed Coding for Ultra Reliable Low Latency Communications](https://arxiv.org/abs/2601.16012)
*Yanfeng Zhang,Xi'an Fan,Xu Zhu,Jinkai Zheng,Hui Liang,Weiwei Yang,Tom H. Luan*

Main category: eess.SP

TL;DR: 提出一种低复杂度稀疏叠加编码方案，通过设计稀疏码本结构降低编解码复杂度，在BLER性能和计算复杂度之间取得良好平衡


<details>
  <summary>Details</summary>
Motivation: 传统稀疏叠加编码方案由于使用密集码本矩阵导致编解码复杂度高，在超可靠低延迟通信的短包传输场景中需要降低复杂度

Method: 设计稀疏码本结构，每个码字仅包含少量非零元素，使用传统的多径匹配追踪算法进行解码，利用码本稀疏性显著降低整体复杂度

Result: 仿真结果表明，所提方案在BLER性能和计算复杂度之间取得有利平衡，在不同传输块长度下表现出强鲁棒性

Conclusion: 提出的低复杂度稀疏叠加编码方案通过稀疏码本设计有效降低了编解码复杂度，为超可靠低延迟通信的短包传输提供了实用解决方案

Abstract: Sparse superimposed coding (SSC) has emerged as a promising technique for short-packet transmission in ultra-reliable low-latency communication scenarios. However, conventional SSC schemes often suffer from high encoding and decoding complexity due to the use of dense codebook matrices. In this paper, we propose a low-complexity SSC scheme by designing a sparse codebook structure, where each codeword contains only a small number of non-zero elements. The decoding is performed using the traditional multipath matching pursuit algorithm, and the overall complexity is significantly reduced by exploiting the sparsity of the codebook. Simulation results show that the proposed scheme achieves a favorable trade-off between BLER performance and computational complexity, and exhibits strong robustness across different transmission block lengths.

</details>


### [27] [Hybrid Channel Estimation with Quantized Phase Feedback for Over-the-Air Computation](https://arxiv.org/abs/2601.16054)
*Martin Dahl,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出混合信道估计方案，结合基于互易性和基于反馈的信道估计，降低空中计算的信令开销，研究量化相位反馈的影响，并提出两种变体方案。


<details>
  <summary>Details</summary>
Motivation: 为了降低空中计算的信令开销，需要更高效的信道估计方案。传统方法可能产生过多信令开销，因此需要结合不同估计方法的优势。

Method: 提出混合信道估计方案，结合基于互易性和基于反馈的信道估计。研究量化相位反馈的影响，假设幅度精确估计。提出两种变体：第一种仅通过反馈估计相位，第二种通过互易性估计相位并结合最优量化相位反馈。

Result: 通过仿真和理论分析表明，第二种变体方案（基于互易性估计相位并结合最优量化相位反馈）的性能优于第一种变体（仅通过反馈估计相位）。

Conclusion: 混合信道估计方案能有效降低空中计算的信令开销，通过分离幅度和相位的估计精度选择，第二种变体方案在性能上更具优势。

Abstract: To reduce the signaling overhead of over-the-air computation, a hybrid channel estimation scheme is proposed, where reciprocity-based and feedback-based channel estimation are combined. In particular, the impact of quantized phase-feedback is studied while the amplitude is assumed estimated exactly. The scheme enables selecting the estimation precision of amplitude and phase separately, depending on the importance of each. Two variants of the scheme are proposed: As shown through simulations and theory, the second variant with reciprocity-based estimation of the channel phase, and optimal quantization of phase feedback, can outperform the first variant estimating the phase by feedback only.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [28] [Partially Polarized Polar Codes: A New Design for 6G Control Channels](https://arxiv.org/abs/2601.15404)
*Arman Fazeli,Mohammad M. Mansour,Ziyuan Zhu,Louay Jalloul*

Main category: cs.IT

TL;DR: PPP码是一种新型类极化码，通过选择性修剪极化核来修改比特信道容量，确保解码早期有保证数量的非冻结比特可用，从而支持更有效的早期终止，特别适用于下行控制信道的盲解码。


<details>
  <summary>Details</summary>
Motivation: 在下行控制信道的盲解码场景中，用户设备需要处理多个候选码字，其中许多不包含有效控制信息。传统极化码在解码早期无法提供足够的信息比特，导致早期终止效果不佳，而硬件限制又阻碍了直接扩展更大块长度。

Method: PPP码从传统极化码构建，通过选择性修剪极化核来修改合成的比特信道容量，确保解码早期有保证数量的非冻结比特可用。论文还提出了几种专门针对PPP码的冻结比特映射设计策略。

Result: PPP码相比传统极化码在性能上有显著提升，特别是在较大块长度下，硬件限制阻碍了直接扩展时。与现有的聚合或分段方法相比，PPP码实现了更高的效率，且无需额外的硬件支持。

Conclusion: PPP码通过修改极化核结构，在解码早期提供可用的信息比特，有效支持早期终止，特别适用于下行控制信道的盲解码场景，相比现有方法具有更高的效率和更好的可扩展性。

Abstract: We introduce a new family of polar-like codes, called Partially Polarized Polar (PPP) codes. PPP codes are constructed from conventional polar codes by selectively pruning polarization kernels, thereby modifying the synthesized bit-channel capacities to ensure a guaranteed number of non-frozen bits available early in decoding. These early-access information bits enable more effective early termination, which is particularly valuable for blind decoding in downlink control channels, where user equipment (UE) must process multiple candidates, many of which carry no valid control information. Our results show that PPP codes offer substantial performance gains over conventional polar codes, particularly at larger block lengths where hardware limitations restrict straightforward scaling. Compared with existing methods such as aggregation or segmentation, PPP codes achieve higher efficiency without the need for additional hardware support. Finally, we propose several frozen-bitmap design strategies tailored to PPP codes.

</details>


### [29] [Rank-metric codes over arbitrary fields: Bounds and constructions](https://arxiv.org/abs/2601.15464)
*Alessandro Neri,Ferdinando Zullo*

Main category: cs.IT

TL;DR: 该论文综述了秩度量码的发展历程、数学基础、边界理论、构造方法及其在有限域和更一般代数结构上的扩展研究。


<details>
  <summary>Details</summary>
Motivation: 秩度量码在1978年由Delsarte首次研究，后被Gabidulin重新发现，已成为编码理论的核心主题。它们在网络编码中有重要应用，并与多个数学领域有深刻联系。论文旨在系统梳理秩度量码的理论发展，特别是从有限域扩展到更一般代数结构的研究进展。

Method: 采用综述研究方法，系统考察秩度量码的数学基础，包括：1) 分析Singleton-like边界条件及其在不同代数结构下的紧致性；2) 研究在具有循环伽罗瓦扩张的域上构造最大秩距离(MRD)码的方法；3) 探讨线性秩度量码与系统和规避子空间的关系；4) 回顾在代数闭域和实数域上的相关结果。

Result: 论文展示了Singleton-like边界在有限域情况下是紧致的，但在更一般的代数结构中可能不紧致。建立了线性秩度量码与系统和规避子空间的深刻联系。总结了代数闭域和实数域上秩度量码的研究成果，这些结果先前出现在拓扑和测度论背景下。

Conclusion: 秩度量码理论已从有限域扩展到更一般的代数结构，形成了丰富的理论体系。未来研究方向包括：MRD码存在性猜想、在各种域扩张上秩度量码的探索，以及进一步连接编码理论与代数几何、拓扑等其他数学领域。

Abstract: Rank-metric codes, defined as sets of matrices over a finite field with the rank distance, have gained significant attention due to their applications in network coding and connections to diverse mathematical areas. Initially studied by Delsarte in 1978 and later rediscovered by Gabidulin, these codes have become a central topic in coding theory. This paper surveys the development and mathematical foundations, in particular, regarding bounds and constructions of rank-metric codes, emphasizing their extension beyond finite fields to more general settings. We examine Singleton-like bounds on code parameters, demonstrating their sharpness in finite field cases and contrasting this with contexts where the bounds are not tight. Furthermore, we discuss constructions of Maximum Rank Distance (MRD) codes over fields with cyclic Galois extensions and the relationship between linear rank-metric codes with systems and evasive subspaces. The paper also reviews results for algebraically closed fields and real numbers, previously appearing in the context of topology and measure theory. We conclude by proposing future research directions, including conjectures on MRD code existence and the exploration of rank-metric codes over various field extensions.

</details>


### [30] [Stabilizer-Code Channel Transforms Beyond Repetition Codes for Improved Hashing Bounds](https://arxiv.org/abs/2601.15505)
*Tyler Kann,Matthieu R. Bloch,Shrinivas Kudekar,Ruediger Urbanke*

Main category: cs.IT

TL;DR: 该论文提出了一种通过稳定子码作为信道变换来改进非对称泡利信道可达速率的方法，超越了传统的量子哈希界限。


<details>
  <summary>Details</summary>
Motivation: 量子哈希界限对于非对称泡利信道通常不是紧致的，需要寻找方法来改进可达速率。

Method: 将任意稳定子码作为信道变换，构建完整的辛表，计算逻辑泡利错误和校验子在物理泡利信道下的联合分布，通过带有解码器边信息的哈希界限获得可达速率。

Result: 通过对小型变换进行结构化搜索，报告了能够改进先前研究中具有偏斜和独立错误的泡利信道族基线哈希界限的实例。

Conclusion: 稳定子码作为信道变换的方法能够超越传统哈希界限，为非对称泡利信道提供了改进的可达速率。

Abstract: The quantum hashing bound guarantees that rates up to $1-H(p_I, p_X, p_Y, p_Z)$ are achievable for memoryless Pauli channels, but it is not generally tight. A known way to improve achievable rates for certain asymmetric Pauli channels is to apply a small inner stabilizer code to a few channel uses, decode, and treat the resulting logical noise as an induced Pauli channel; reapplying the hashing argument to this induced channel can beat the baseline hashing bound. We generalize this induced-channel viewpoint to arbitrary stabilizer codes used purely as channel transforms. Given any $ [\![ n, k ]\!] $ stabilizer generator set, we construct a full symplectic tableau, compute the induced joint distribution of logical Pauli errors and syndromes under the physical Pauli channel, and obtain an achievable rate via a hashing bound with decoder side information. We perform a structured search over small transforms and report instances that improve the baseline hashing bound for a family of Pauli channels with skewed and independent errors studied in prior work.

</details>


### [31] [A Class of Subadditive Information Measures and their Applications](https://arxiv.org/abs/2601.15639)
*Hamidreza Abin,Mahdi Zinati,Amin Gohari,Mohammad Hossein Yassaee,Mohammad Mahdi Mojahedian*

Main category: cs.IT

TL;DR: 本文提出了(G,f)-散度这一两参数散度族，通过将非递减函数G应用于f-散度D_f得到。基于此定义了(G,f)-信息度量，并重点研究了其在乘积分布和乘积信道上的次可加性，建立了简化原则和充分条件，最后应用于信道编码、假设检验和球面打包指数框架。


<details>
  <summary>Details</summary>
Motivation: 现有的f-散度在信息论中应用广泛，但缺乏更灵活的度量框架。本文旨在构建一个更通用的两参数散度族，能够统一处理多种信息度量问题，特别是研究其在乘积结构上的次可加性，为信道编码和假设检验等应用提供理论工具。

Method: 1. 定义(G,f)-散度：对f-散度D_f应用非递减函数G得到；2. 定义对应的(G,f)-信息度量I_{G,f}(X;Y)；3. 建立次可加性的简化原则：证明对于广泛的G类，只需在二元字母表上验证散度次可加性；4. 针对特定G函数（x, log(1+x), -log(1-x)）推导f的充分条件。

Result: 1. 成功构建了(G,f)-散度理论框架；2. 建立了次可加性的简化原则，大幅降低了验证复杂度；3. 针对三类特定G函数，给出了保证次可加性的f充分条件，覆盖了许多标准f-散度；4. 将理论应用于：有限块长信道编码逆定理、二元假设检验界限、以及Shannon-Gallager-Berlekamp球面打包指数框架的扩展。

Conclusion: 本文提出的(G,f)-散度框架为信息度量提供了灵活的工具，其建立的次可加性理论简化了分析复杂度，并在多个信息论应用中展示了实用价值，扩展了经典结果的应用范围。

Abstract: We introduce a two-parameter family of discrepancy measures, termed \emph{$(G,f)$-divergences}, obtained by applying a non-decreasing function $G$ to an $f$-divergence $D_f$. Building on Csiszár's formulation of mutual $f$-information, we define a corresponding $(G,f)$-information measure $
I_{G,f}(X;Y)$. A central theme of the paper is subadditivity over product distributions and product channels. We develop reduction principles showing that, for broad classes of $G$, it suffices to verify divergence subadditivity on binary alphabets. Specializing to the functions $G(x)\in\{x,\log(1+x),-\log(1-x)\}$, we derive tractable sufficient conditions on $f$ that guarantee subadditivity, covering many standard $f$-divergences. Finally, we present applications to finite-blocklength converses for channel coding, bounds in binary hypothesis testing, and an extension of the Shannon--Gallager--Berlekamp sphere-packing exponent framework to subadditive $(G,f)$-divergences.

</details>


### [32] [Generative AI-Empowered Semantic Twin Channel Model for ISAC](https://arxiv.org/abs/2601.15642)
*Yi Chen,Yatao Hu,Ming Li,Chong Han*

Main category: cs.IT

TL;DR: 该论文提出了一种面向语义的ISAC信道建模方法，通过生成式AI构建语义孪生信道模型，以平衡传感与通信需求，实现可控仿真和可复现基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前ISAC信道建模存在缺口：统计模型过于粗糙，忽略了传感所需的关键多径特征；确定性模型计算效率低，难以扩展到系统级评估。需要一种能同时考虑环境对传感意义和信道对通信行为的统一抽象。

Method: 提出语义导向的信道建模原则，在保持环境语义的同时抽象不必要的细节。引入生成式AI赋能的语义孪生信道模型，生成代表特定语义条件的物理合理信道实现。

Result: 案例研究表明，在具有挑战性的多视角设置下，模型能保持语义一致性。这为可控仿真、数据集生成和可复现的ISAC基准测试提供了实用路径。

Conclusion: 环境语义对于ISAC信道建模至关重要，语义孪生信道模型能有效平衡准确性和复杂性，为未来ISAC设计和标准化提供了新的建模框架。

Abstract: Integrated sensing and communication (ISAC) increasingly exposes a gap in today's channel modeling. Efficient statistical models focus on coarse communication-centric metrics, and therefore miss the weak but critical multipath signatures for sensing, whereas deterministic models are computationally inefficient to scale for system-level ISAC evaluation. This gap calls for a unifying abstraction that can couple what the environment means for sensing with how the channel behaves for communication, namely, environmental semantics. This article clarifies the meaning and essentiality of environmental semantics in ISAC channel modeling and establishes how semantics is connected to observable channel structures across multiple semantic levels. Based on this perspective, a semantics-oriented channel modeling principle was advocated, which preserves environmental semantics while abstracting unnecessary detail to balance accuracy and complexity. Then, a generative AI-empowered semantic twin channel model (STCM) was introduced to generate a family of physically plausible channel realizations representative of a semantic condition. Case studies further show semantic consistency under challenging multi-view settings, suggesting a practical path to controllable simulation, dataset generation, and reproducible ISAC benchmarking toward future design and standardization.

</details>


### [33] [Generalized Information Inequalities via Submodularity, and Two Combinatorial Problems](https://arxiv.org/abs/2601.15723)
*Gunank Jakhar,Gowtham R. Kurri,Suryajith Chillara,Vinod M. Prabhakaran*

Main category: cs.IT

TL;DR: 本文在熵不等式与子模性关系的基础上，建立了Madiman-Tetali强/弱不等式的凸函数推广，提出了改进的Loomis-Whitney型投影不等式，并用Shearer引理扩展了极值图论结果。


<details>
  <summary>Details</summary>
Motivation: 熵不等式与子模性之间存在深刻联系，已有Madiman-Tetali和Sason分别建立了统一框架。本文旨在在这些框架基础上进一步推进，建立更一般的凸函数推广，改进经典投影不等式，并扩展极值图论结果。

Method: 1) 建立子模函数的Madiman-Tetali强/弱不等式的凸函数推广；2) 利用强Madiman-Tetali不等式的特例，推导有限点集的改进Loomis-Whitney型投影不等式；3) 使用Shearer引理（而非Han不等式）研究极值图论问题。

Result: 1) 获得了子模函数的凸函数推广的Madiman-Tetali不等式；2) 提出了改进的Loomis-Whitney型投影不等式，通过切片级结构信息提升经典界；3) 恢复了Sason和Boucheron等人的结果并进行了扩展。

Conclusion: 本文成功扩展了熵不等式与子模性的统一框架，建立了凸函数推广，改进了经典投影不等式，并用Shearer引理扩展了极值图论结果，为信息不等式理论提供了新的工具和视角。

Abstract: It is well known that there is a strong connection between entropy inequalities and submodularity, since the entropy of a collection of random variables is a submodular function. Unifying frameworks for information inequalities arising from submodularity were developed by Madiman and Tetali (2010) and Sason (2022). Madiman and Tetali (2010) established strong and weak fractional inequalities that subsume classical results such as Han's inequality and Shearer's lemma. Sason (2022) introduced a convex-functional framework for generalizing Han's inequality, and derived unified inequalities for submodular and supermodular functions. In this work, we build on these frameworks and make three contributions. First, we establish convex-functional generalizations of the strong and weak Madiman and Tetali inequalities for submodular functions. Second, using a special case of the strong Madiman-Tetali inequality, we derive a new Loomis-Whitney-type projection inequality for finite point sets in $\mathbb{R}^d$, which improves upon the classical Loomis-Whitney bound by incorporating slice-level structural information. Finally, we study an extremal graph theory problem that recovers and extends the previously known results of Sason (2022) and Boucheron et al., employing Shearer's lemma in contrast to the use of Han's inequality in those works.

</details>


### [34] [Recursive Flow: A Generative Framework for MIMO Channel Estimation](https://arxiv.org/abs/2601.15767)
*Zehua Jiang,Fenghao Zhu,Chongwen Huang,Richeng Jin,Zhaohui Yang,Xiaoming Chen,Zhaoyang Zhang,Mérouane Debbah*

Main category: cs.IT

TL;DR: RC-Flow是一种利用预训练流匹配先验的递归信道估计算法，通过闭环精炼框架在噪声主导场景下实现鲁棒信道重建，推理延迟降低两个数量级，低信噪比下性能提升2.7dB。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统中的信道估计是基础挑战，估计精度直接影响频谱效率和链路可靠性。传统开环生成模型在噪声主导场景下性能受限，需要更鲁棒的闭环精炼方法。

Method: 提出RC-Flow算法：1）利用预训练流匹配先验；2）建立闭环精炼框架，包含序列重启机制和锚定轨迹校正；3）结合流一致先验方向与数据保真度近端投影；4）采用自适应双调度策略平衡收敛速度与重建精度。

Result: 1）推理延迟降低两个数量级；2）低信噪比下相比基于分数的基线方法获得2.7dB性能增益；3）在不同噪声水平下均达到最先进性能；4）理论分析证明递归算子的全局渐近稳定性。

Conclusion: RC-Flow通过闭环精炼框架有效结合生成先验与数据保真约束，在噪声主导的大规模MIMO信道估计场景中实现了高效鲁棒的重建性能，为实际系统部署提供了有前景的解决方案。

Abstract: Channel estimation is a fundamental challenge in massive multiple-input multiple-output systems, where estimation accuracy governs the spectral efficiency and link reliability. In this work, we introduce Recursive Flow (RC-Flow), a novel solver that leverages pre-trained flow matching priors to robustly recover channel state information from noisy, under-determined measurements. Different from conventional open-loop generative models, our approach establishes a closed-loop refinement framework via a serial restart mechanism and anchored trajectory rectification. By synergizing flow-consistent prior directions with data-fidelity proximal projections, the proposed RC-Flow achieves robust channel reconstruction and delivers state-of-the-art performance across diverse noise levels, particularly in noise-dominated scenarios. The framework is further augmented by an adaptive dual-scheduling strategy, offering flexible management of the trade-off between convergence speed and reconstruction accuracy. Theoretically, we analyze the Jacobian spectral radius of the recursive operator to prove its global asymptotic stability. Numerical results demonstrate that RC-Flow reduces inference latency by two orders of magnitude while achieving a 2.7 dB performance gain in low signal-to-noise ratio regimes compared to the score-based baseline.

</details>


### [35] [Practical applications of Set Shaping Theory to Non-Uniform Sequences](https://arxiv.org/abs/2601.15853)
*A. Schmidt,A. Vdberg,A. Petit*

Main category: cs.IT

TL;DR: 本文提出了一种近似排序方法，克服了集合整形理论应用于非均匀序列时的指数复杂度障碍，实现了理论预测的整形增益。


<details>
  <summary>Details</summary>
Motivation: 集合整形理论需要按信息内容对原始序列和变换序列进行排序，但精确排序具有指数复杂度，这阻碍了该理论在非均匀序列上的实际应用。

Method: 采用近似但信息丰富的排序方法，在保持集合整形理论结构要求的同时，避免了指数复杂度，实现了理论预测的整形增益。

Result: 该方法成功将集合整形理论扩展到非均匀序列，验证了理论预测的整形优势，并提供了公开可用的软件实现以确保可复现性。

Conclusion: 通过近似排序方法，集合整形理论可以实际应用于非均匀序列，克服了指数复杂度障碍，为实际编码应用提供了可行的实现方案。

Abstract: Set Shaping Theory (SST) moves beyond the classical fixed-space model by constructing bijective mappings the original sequence set into structured regions of a larger sequence space. These shaped subsets are characterized by a reduced average information content, measured by the product of the empirical entropy and the length, yielding (N +k)H0(f(s)) < NH0(s), which represents the universal coding limit when the source distribution is unknown. The principal experimental difficulty in applying Set Shaping Theory to non-uniform sequences arises from the need to order the sequences of both the original and transformed sets according to their information content. An exact ordering of these sets entails exponential complexity, rendering a direct implementation impractical. In this article, we show that this obstacle can be overcome by performing an approximate but informative ordering that preserves the structural requirements of SST while achieving the shaping gain predicted by the theory. This result extends previous experimental findings obtained for uniformly distributed sequences and demonstrates that the shaping advantage of SST persists for non-uniform sequences. Finally, to ensure full reproducibility, the software implementing the proposed method has been made publicly available on GitHub, enabling independent verification of the results reported in this work

</details>


### [36] [Blind Identification of Channel Codes: A Subspace-Coding Approach](https://arxiv.org/abs/2601.15903)
*Pramod Singh,Prasad Krishnan,Arti Yardi*

Main category: cs.IT

TL;DR: 提出一种基于子空间码框架的二进制对称信道码识别新方法，结合汉明距离和子空间距离解码原理，性能优于现有通用技术


<details>
  <summary>Details</summary>
Motivation: 现有信道码盲识别方法大多要求码族具有特殊结构，计算复杂度高，且缺乏严格的理论性能保证。需要一种能在二进制对称信道上有效识别随机线性码的通用方法

Method: 提出最小去噪子空间差异解码器，基于子空间码和算子信道框架，结合汉明距离和子空间距离解码原理，用于二进制对称信道上的码识别

Result: 为有界权重错误提供了理论性能保证，给出了二进制对称信道上误码概率界限。仿真显示在大多数信道条件下，即使接收向量数量有限，对随机线性码的识别性能也优于现有通用技术

Conclusion: 该方法在二进制对称信道上为随机线性码的盲识别提供了一种有效的解决方案，具有理论保证和实际性能优势

Abstract: The problem of blind identification of channel codes at a receiver involves identifying a code chosen by a transmitter from a known code-family, by observing the transmitted codewords through the channel. Most existing approaches for code-identification are contingent upon the codes in the family having some special structure, and are often computationally expensive otherwise. Further, rigorous analytical guarantees on the performance of these existing techniques are largely absent. This work presents a new method for code-identification on the binary symmetric channel (BSC), inspired by the framework of subspace codes for operator channels, carefully combining principles of hamming-metric and subspace-metric decoding. We refer to this method as the minimum denoised subspace discrepancy decoder. We present theoretical guarantees for code-identification using this decoder, for bounded-weight errors, and also present a bound on the probability of error when used on the BSC. Simulations demonstrate the improved performance of our decoder for random linear codes beyond existing general-purpose techniques, across most channel conditions and even with a limited number of received vectors.

</details>


### [37] [A Remark on Downlink Massive Random Access](https://arxiv.org/abs/2601.15928)
*Yuchen Liao,Wenyi Zhang*

Main category: cs.IT

TL;DR: 该论文通过组合数学中的覆盖数组理论，为下行大规模随机接入设计确定性变长码，将开销降低至不超过1+log₂e比特。


<details>
  <summary>Details</summary>
Motivation: 在下行大规模随机接入中，基站向大量用户中的一小部分活跃用户发送消息。传统方法需要显式编码活跃用户身份，开销随总用户数对数增长。最近研究表明开销可以降低到与总用户数无关的上界，但需要随机编码。本文旨在寻找确定性构造方法。

Method: 将下行大规模随机接入的码设计问题建模为组合数学中的覆盖数组问题，利用覆盖数组理论构造确定性变长码。

Result: 证明了存在确定性构造的变长码，其开销不超过1+log₂e比特，这比之前随机编码方法的上界更优。

Conclusion: 通过将下行大规模随机接入的码设计问题与覆盖数组理论联系起来，本文提供了确定性构造方法，显著降低了开销，为实际系统设计提供了理论依据。

Abstract: In downlink massive random access (DMRA), a base station transmits messages to a typically small subset of active users, selected randomly from a massive number of total users. Explicitly encoding the identities of active users would incur a significant overhead scaling logarithmically with the number of total users. Recently, via a random coding argument, Song, Attiah and Yu have shown that the overhead can be reduced to within some upper bound irrespective of the number of total users. In this remark, recognizing that the code design for DMRA is an instance of covering arrays in combinatorics, we show that there exists deterministic construction of variable-length codes that incur an overhead no greater than $1 + log_2 e$ bits.

</details>


### [38] [Stacked Intelligent Metasurface-Aided Wave-Domain Signal Processing: From Communications to Sensing and Computing](https://arxiv.org/abs/2601.16030)
*Jiancheng An,Chau Yuen,Marco Di Renzo,Mehdi Bennis,Merouane Debbah,Lajos Hanzo*

Main category: cs.IT

TL;DR: 该论文综述了堆叠智能超表面(SIM)技术，这是一种结合神经网络、电磁计算和超表面的新兴技术，用于在电磁域直接处理信号，实现高速、大规模并行、低功耗的计算任务。


<details>
  <summary>Details</summary>
Motivation: 结合神经网络的抽象特征提取能力、电磁计算的波传播特性以及超表面的波前调控能力，探索物理神经网络在电磁域直接处理信号的可能性，以实现更高效的计算和信号处理。

Method: 采用堆叠智能超表面(SIM)技术，通过多层超表面结构在电磁域直接执行计算操作。论文从理论基础、原型设计、优化训练策略（从两个不同视角）等方面进行系统分析。

Result: SIM技术展示了在通信、传感和计算领域的多样化应用潜力，实验证据表明单个设备能够支持多种功能，具有高速、大规模并行和低功耗的独特优势。

Conclusion: SIM技术为下一代无线网络中的电磁域信号处理开辟了有前景的途径，但仍需解决关键技术挑战，并探索进一步的研究方向以充分发挥其潜力。

Abstract: Neural networks possess incredible capabilities for extracting abstract features from data. Electromagnetic computing harnesses wave propagation to execute computational operations. Metasurfaces, composed of subwavelength meta-atoms, are capable of engineering electromagnetic waves in unprecedented ways. What happens when combining these three cutting-edge technologies? This question has sparked a surge of interest in designing physical neural networks using stacked intelligent metasurface (SIM) technology, with the aim of implementing various computational tasks by directly processing electromagnetic waves. SIMs open up an exciting avenue toward high-speed, massively parallel, and low-power signal processing in the electromagnetic domain. This article provides a comprehensive overview of SIM technology, commencing with its evolutionary development. We subsequently examine its theoretical foundations and existing SIM prototypes in depth. Furthermore, the optimization/training strategies conceived to configure SIMs for achieving the desired functionalities are discussed from two different perspectives. Additionally, we explore the diverse applications of SIM technology across the communication, sensing, and computing domains, presenting experimental evidence that highlights its distinctive advantages in supporting multiple functions within a single device. Finally, we identify critical technical challenges that must be addressed to deploy SIMs in next-generation wireless networks and shed light on promising research directions to unlock their full potential.

</details>


### [39] [RIS-Aided Cooperative ISAC Network for Imaging-Based Low-Altitude Surveillance](https://arxiv.org/abs/2601.16033)
*Zhixin Chen,Yixuan Huang,Zhengze Ji,Jie Yang,Shi Jin*

Main category: cs.IT

TL;DR: 提出基于可重构智能表面(RIS)的协作式集成感知与通信(ISAC)网络用于低空监视，采用主动RIS增强信号，将低空监视建模为压缩感知成像问题，实现300米高度有效成像与目标检测。


<details>
  <summary>Details</summary>
Motivation: 低空经济对先进监视技术需求迫切，但传统方法存在部署成本高、信号强度低的局限性，需要开发更有效的低空监视解决方案。

Method: 1) 构建RIS辅助的协作式ISAC网络，利用RIS将ISAC信号反射至低空进行感知；2) 采用主动RIS(ARIS)增强信号强度；3) 将低空监视建模为基于压缩感知理论的成像问题，使用子空间追踪算法求解；4) 推导系统的克拉美-罗下界(CRLB)，分析系统参数对感知性能的影响。

Result: 数值结果表明，在相同功率约束下，主动RIS优于被动RIS，能够在高达300米的高度实现有效成像和目标检测，为ISAC系统配置提供指导。

Conclusion: 提出的RIS辅助低空成像系统通过主动RIS增强信号、压缩感知成像方法，有效解决了传统低空监视的成本高、信号弱问题，为低空经济领域提供了可行的先进监视技术方案。

Abstract: The low-altitude economy is integral to the advancement of numerous sectors, necessitating the development of advanced low-altitude surveillance techniques. Nevertheless, conventional methods encounter limitations of high deployment costs and low signal strength. This study proposes a reconfigurable intelligent surface (RIS)-aided cooperative integrated sensing and communication (ISAC) network for low-altitude surveillance. This network employs RISs to reflect ISAC signals into low-altitude space for sensing. To enhance signal strength, we employ active RIS (ARIS) to amplify the signals. Moreover, in order to avoid error propagation and data association in traditional sensing methods, we model low-altitude surveillance as an imaging problem based on compressed sensing theory, which can be solved through the subspace pursuit algorithm. We derive the Cramer-Rao lower bound (CRLB) of the proposed RIS-aided low-altitude imaging system and analyze the impacts of various system parameters on sensing performance, providing guidance for ISAC system configuration. Numerical results show that ARIS outperforms passive RIS under identical power constraints, achieving effective imaging and target detection at altitudes up to 300 meters.

</details>


### [40] [Tri-Hybrid Beamforming Design for integrated Sensing and Communications](https://arxiv.org/abs/2601.16036)
*Tianyu Fang,Mengyuan Ma,Markku Juntti,Nhan Thanh Nguyen*

Main category: cs.IT

TL;DR: 论文研究了用于集成感知与通信（ISAC）的三混合波束成形架构，通过多目标优化平衡通信SNR和感知功率，提出低复杂度迭代算法，相比传统混合波束成形提高了空间增益和能效，但波束对准能力有所降低。


<details>
  <summary>Details</summary>
Motivation: 三混合波束成形架构能支持超大规模天线阵列的能效通信，但需要研究其在集成感知与通信（ISAC）中的应用，以同时提升通信和感知性能。

Method: 提出多目标优化问题，平衡通信信噪比（SNR）和目标方向的感知功率，考虑总功耗和三混合波束成形架构的物理限制。开发高效迭代算法，每次迭代中变量以闭式更新，实现低复杂度快速执行设计。

Result: 数值结果表明，三混合架构相比传统混合波束成形架构提高了空间增益和能量效率，但波束对准能力有所降低。

Conclusion: 三混合波束成形架构为ISAC系统提供了有效的解决方案，在提升空间增益和能效方面具有优势，但需要权衡波束对准能力的损失。

Abstract: Tri-hybrid beamforming architectures have been proposed to enable energy-efficient communications systems in extra-largescale antenna arrays using low-cost programmable metasurface antennas. We study the tri-hybrid beamforming design for integrated sensing and communications (ISAC) to improve both communications and sensing performances. Specifically, we formulate a multi-objective optimization problem that balances communications signal-to-noise ratio (SNR) and the sensing power at a target direction, subject to constraints on the total power consumption and physical limitations inherent to the trihybrid beamforming architecture. We develop an efficient iterative algorithm in which the variables are updated in a closed form at each iteration, leading to a low-complexity and fast-execution design. Numerical results show that the tri-hybrid architecture improves spatial gain and energy efficiency, though with reduced beam alignment capability compared to conventional hybrid beamforming architectures.

</details>


### [41] [Tensor Reed-Muller Codes: Achieving Capacity with Quasilinear Decoding Time](https://arxiv.org/abs/2601.16164)
*Emmanuel Abbe,Colin Sandon,Oscar Sprumont*

Main category: cs.IT

TL;DR: 本文提出了两种张量Reed-Muller码的构造，能在低于信道容量的任意恒定速率下实现准线性时间解码，具有不同的错误概率和解码时间权衡。


<details>
  <summary>Details</summary>
Motivation: Reed-Muller码虽然具有简单的代数结构，但其解码复杂度较高。本文旨在构造具有准线性时间解码能力的纠错码，同时保持接近信道容量的速率。

Method: 定义张量Reed-Muller码为多个Reed-Muller码的张量积，提出两种构造：1) t=3时使用O(n log log n)解码时间；2) t≥4时使用O(n log n)解码时间。关键工具是多项式时间算法，用于解码任意张量码，即使分量码本身不可多项式时间解码。

Result: 1) 第一种构造(t=3)的错误概率为n^{-ω(log n)}，解码时间O(n log log n)；2) 第二种构造(t≥4)的错误概率为2^{-n^{1/2-1/[2(t-2)]-o(1)}}，解码时间O(n log n)。两种构造都能在低于信道容量的任意恒定速率下工作。

Conclusion: 张量Reed-Muller码提供了一种在接近信道容量的速率下实现准线性时间解码的有效方法，通过张量积结构和创新的解码算法克服了传统Reed-Muller码解码复杂度的限制。

Abstract: Define the codewords of the Tensor Reed-Muller code $\mathsf{TRM}(r_1,m_1;r_2,m_2;\dots;r_t,m_t)$ to be the evaluation vectors of all multivariate polynomials in the variables $\left\{x_{ij}\right\}_{i=1,\dots,t}^{j=1,\dots m_i}$ with degree at most $r_i$ in the variables $x_{i1},x_{i2},\dots,x_{im_i}$. The generator matrix of $\mathsf{TRM}(r_1,m_1;\dots;r_t,m_t)$ is thus the tensor product of the generator matrices of the Reed-Muller codes $\mathsf{RM}(r_1,m_1),\dots, \mathsf{RM}(r_t,m_t)$.
  We show that for any constant rate $R$ below capacity, one can construct a Tensor Reed-Muller code $\mathsf{TRM}(r_1,m_1;\dotsc;r_t,m_t)$ of rate $R$ that is decodable in quasilinear time. For any blocklength $n$, we provide two constructions of such codes:
  1) Our first construction (with $t=3$) has error probability $n^{-ω(\log n)}$ and decoding time $O(n\log\log n)$.
  2) Our second construction, for any $t\geq 4$, has error probability $2^{-n^{\frac{1}{2}-\frac{1}{2(t-2)}-o(1)}}$ and decoding time $O(n\log n)$.
  One of our main tools is a polynomial-time algorithm for decoding an arbitrary tensor code $C=C_1\otimes\dotsc\otimes C_t$ from $\frac{d_{\min}(C)}{2\max\{d_{\min}(C_1),\dotsc,d_{\min}(C_t) \}}-1$ adversarial errors. Crucially, this algorithm does not require the codes $C_1,\dotsc,C_t$ to themselves be decodable in polynomial time.

</details>


### [42] [Non-Linearly Separable Distributed Computing: A Sparse Tensor Factorization Approach](https://arxiv.org/abs/2601.16171)
*Ali Khalesi,Ahmad Tanha,Derya Malak,Petros Elia*

Main category: cs.IT

TL;DR: 提出一种基于张量理论的分布式计算框架，用于优化多服务器环境下多项式函数评估的计算和通信成本


<details>
  <summary>Details</summary>
Motivation: 在N服务器分布式计算环境中，K个用户请求评估L个实值基子函数的任意多元多项式。现有方法在计算和通信成本方面存在优化空间，需要更高效的任务分配和数据通信技术

Method: 采用张量理论方法：1) 将不可线性分解的函数表示为设计的张量$\bar{\mathcal{F}}$；2) 通过稀疏分解为张量$\bar{\mathcal{E}}$和矩阵$\mathbf{D}$来定义任务分配、连接性和通信模式；3) 使用基于固定支撑SVD的张量分解方法和多维子张量平铺技术

Result: 提出的可实现方案显著降低了计算和通信成本，性能大幅优于现有技术

Conclusion: 基于张量分解的方法为分布式计算中非线性函数评估提供了有效的任务分配和通信优化框架，在计算和通信效率方面取得了实质性改进

Abstract: The work considers the $N$-server distributed computing setting with $K$ users requesting functions that are arbitrary multi-variable polynomial evaluations of $L$ real (potentially non-linear) basis subfunctions. Our aim is to seek efficient task-allocation and data-communication techniques that reduce computation and communication costs. Towards this, we take a tensor-theoretic approach, in which we represent the requested non-linearly decomposable functions using a properly designed tensor $\bar{\mathcal{F}}$, whose sparse decomposition into a tensor $\bar{\mathcal{E}}$ and matrix $\mathbf{D}$ directly defines the task assignment, connectivity, and communication patterns. We here design an achievable scheme, employing novel fixed-support SVD-based tensor factorization methods and careful multi-dimensional tiling of subtensors, yielding computation and communication protocols whose costs are derived here, and which are shown to perform substantially better than the state of art.

</details>
