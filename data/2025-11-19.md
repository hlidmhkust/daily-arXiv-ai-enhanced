<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 14]
- [eess.IV](#eess.IV) [Total: 4]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [DNA Storage in the Short Molecule Regime](https://arxiv.org/abs/2511.14284)
*Ran Tamir,Nir Weinberger,Albert Guillén i Fàbregas*

Main category: cs.IT

TL;DR: 本文完成了DNA存储系统中短DNA分子可存储信息量的猜想证明，提出了两种编码方案，其中随机编码方案在短分子区域与逆界匹配，另一种方案计算复杂度低但仅在特定短分子范围内达到最优缩放。


<details>
  <summary>Details</summary>
Motivation: 研究DNA存储系统中短DNA分子能够可靠存储的信息量，验证Shomorony和Heckel (2022)提出的关于信息比特数缩放规律的猜想。

Method: 分析随机编码方案，其中每个码字通过量化从概率单纯形中随机生成的概率质量函数获得，并分析最优最大似然解码器；还提出了第二种计算复杂度显著降低的编码方案。

Result: 推导了与最近建立的逆界在整个短分子区域匹配的可达性界；第二种方案在除特定非常短分子范围外的所有情况下都能达到最优缩放。

Conclusion: 完成了DNA存储系统短分子区域信息存储容量猜想的证明，提供了两种编码方案，分别具有理论最优性和实际计算效率优势。

Abstract: We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.

</details>


### [2] [The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys](https://arxiv.org/abs/2511.14444)
*Zhou Li,Xiang Zhang,Yizhou Zhao,Haiqiang Chen,Jihao Fan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文研究了在分组密钥和抗合谋攻击下的去中心化安全聚合问题，确定了最优的通信速率和密钥速率区域，并给出了可行性条件和最小资源需求。


<details>
  <summary>Details</summary>
Motivation: 受高效分组密钥生成协议的启发，研究在对称分组密钥设置下的去中心化安全聚合问题，为去中心化学习系统提供通信和密钥高效的安全聚合设计思路。

Method: 采用信息论方法分析去中心化安全聚合问题，考虑用户通过无差错广播信道连接，每个用户持有私密输入，使用分组密钥来保护隐私，同时满足恢复和安全约束。

Result: 确定了DSA在分组密钥下的可行性条件：当G=1或G≥K-T时不可行；当2≤G<K-T时，每个用户至少广播1个符号，每个分组密钥至少包含(K-T-2)/C(K-T-1,G)个独立符号。

Conclusion: 建立了分组密钥下DSA的基本极限，为去中心化学习系统中的通信和密钥高效安全聚合提供了设计指导。

Abstract: This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\ge K-T$. Otherwise, when $2\le G<K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.

</details>


### [3] [Monimial Matrix Analogue of Yoshida's theorem](https://arxiv.org/abs/2511.14480)
*Ananda Chakraborty*

Main category: cs.IT

TL;DR: 本文研究了有限域上线性码的权重枚举器变体，推广了平均完全联合权重枚举器的概念，建立了相关的MacWilliams恒等式和Yoshida定理的单项式类似物。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上线性码的权重枚举器变体，特别是平均完全联合权重枚举器的推广，以深化对编码理论中权重分布性质的理解。

Method: 推广平均完全联合权重枚举器概念，建立MacWilliams类型恒等式，发展Yoshida定理的单项式类似物，并扩展到g重完全联合权重枚举器。

Result: 建立了平均完全联合权重枚举器的MacWilliams恒等式，证明了Yoshida定理的单项式矩阵类似物，并给出了g重情况的广义表示。

Conclusion: 成功推广了平均完全联合权重枚举器理论，建立了相应的恒等式和定理，为编码理论中的权重分布分析提供了新的工具和框架。

Abstract: In this paper, we study variants of weight enumerators of linear codes over $\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.

</details>


### [4] [Neural Networks-Enabled Channel Reconstruction for Fluid Antenna Systems: A Data-Driven Approach](https://arxiv.org/abs/2511.14520)
*Haoyu Liang,Zhentian Zhang,Jian Dang,Hao Jiang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 提出一种基于神经网络的数据驱动信道重建方法，用于流体天线系统，相比现有方法在精度和计算效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统利用紧凑阵列空间内的电磁端口相关性提供空间分集，但需要准确的信道状态信息。现有信道重建方法在模型无关场景下缺乏高精度和高效计算的通用解决方案。

Method: 采用数据驱动的神经网络方法进行信道重建，构建了一个计算效率高的框架。

Result: 数值结果显示该方法实现了显著增强的重建精度，计算复杂度大幅降低，具有快速收敛和鲁棒的重建能力，优于当前最先进技术。

Conclusion: 所提出的神经网络驱动信道重建方案为流体天线系统提供了一种高效精确的解决方案，在性能和计算效率方面均超越现有方法。

Abstract: Fluid antenna systems (FASs) offer substantial spatial diversity by exploiting the electromagnetic port correlation within compact array spaces, thereby generating favorable small-scale fading conditions with beneficial channel gain envelope fluctuations. This unique capability opens new opportunities for a wide range of communication applications and emerging technologies. However, accurate channel state information (CSI) must be acquired before a fluid antenna can be effectively utilized. Although several efforts have been made toward channel reconstruction in FASs, a generally applicable solution to both model-based or model-free scenario with both high precision and efficient computational flow remains lacking. In this work, we propose a data-driven channel reconstruction approach enabled by neural networks. The proposed framework not only achieves significantly enhanced reconstruction accuracy but also requires substantially lower computational complexity compared with existing model-free methods. Numerical results further demonstrate the rapid convergence and robust reconstruction capability of the proposed scheme, outperforming current state-of-the-art techniques.

</details>


### [5] [Compression with Privacy-Preserving Random Access](https://arxiv.org/abs/2511.14524)
*Venkat Chandar,Aslan Tchamkerten,Shashank Vatedka*

Main category: cs.IT

TL;DR: 论文证明i.i.d.二进制源序列可以在任意高于熵率的速率下无损压缩，使得任何单个比特的解码不会泄露其他比特的信息。


<details>
  <summary>Details</summary>
Motivation: 研究在无损压缩中实现信息隔离，确保解码单个比特时不会泄露其他比特的信息，增强隐私保护。

Method: 使用信息论和编码理论，设计压缩方案使得解码任何单个比特X_i时，不会获得关于其他比特{X_j: j≠i}的任何信息。

Result: 成功实现了在任意高于熵率的压缩速率下，单个比特的解码完全隔离其他比特的信息。

Conclusion: 证明了存在无损压缩方案可以在保持压缩效率的同时，实现比特级的信息隔离，为隐私保护编码提供了理论基础。

Abstract: It is shown that an i.i.d. binary source sequence $X_1, \ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \emph{no} information about the other bits $\{X_j : j \neq i\}$.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [6] [DualLaguerreNet: A Decoupled Spectral Filter GNN and the Uncovering of the Flexibility-Stability Trade-off](https://arxiv.org/abs/2511.13729)
*Huseyin Goksu*

Main category: eess.SP

TL;DR: 提出DualLaguerreNet解决单滤波器GNN在异质图上的妥协问题，通过解耦频谱灵活性实现更好的异质图性能，但发现灵活性-稳定性权衡导致在简单同质图上表现下降。


<details>
  <summary>Details</summary>
Motivation: 基于频谱滤波器的GNN（如LaguerreNet）在统一解决异质性和过平滑问题方面有潜力，但单滤波器模型存在"妥协"问题，单个自适应参数需要在整个图频谱上学习次优的平均响应。

Method: 提出DualLaguerreNet架构，将图拉普拉斯算子分解为低频和高频两个算子，分别学习两个独立的自适应Laguerre多项式滤波器，参数化为alpha_1和alpha_2，实现解耦频谱灵活性。

Result: DualLaguerreNet在复杂异质图任务上达到最先进性能（优于LaguerreNet），但在简单同质图任务上表现不佳，揭示了"灵活性-稳定性权衡"问题。

Conclusion: 本文提出了异质图上的新SOTA架构，同时对自适应GNN滤波器设计中的偏差-方差权衡进行了批判性分析，表明简单模型的"妥协"起到了重要的正则化作用。

Abstract: Graph Neural Networks (GNNs) based on spectral filters, such as the Adaptive Orthogonal Polynomial Filter (AOPF) class (e.g., LaguerreNet), have shown promise in unifying the solutions for heterophily and over-smoothing. However, these single-filter models suffer from a "compromise" problem, as their single adaptive parameter (e.g., alpha) must learn a suboptimal, averaged response across the entire graph spectrum. In this paper, we propose DualLaguerreNet, a novel GNN architecture that solves this by introducing "Decoupled Spectral Flexibility." DualLaguerreNet splits the graph Laplacian into two operators, L_low (low-frequency) and L_high (high-frequency), and learns two independent, adaptive Laguerre polynomial filters, parameterized by alpha_1 and alpha_2, respectively. This work, however, uncovers a deeper finding. While our experiments show DualLaguerreNet's flexibility allows it to achieve state-of-the-art results on complex heterophilic tasks (outperforming LaguerreNet), it simultaneously underperforms on simpler, homophilic tasks. We identify this as a fundamental "Flexibility-Stability Trade-off". The increased parameterization (2x filter parameters and 2x model parameters) leads to overfitting on simple tasks, demonstrating that the "compromise" of simpler models acts as a crucial regularizer. This paper presents a new SOTA architecture for heterophily while providing a critical analysis of the bias-variance trade-off inherent in adaptive GNN filter design.

</details>


### [7] [GegenbauerNet: Finding the Optimal Compromise in the GNN Flexibility-Stability Trade-off](https://arxiv.org/abs/2511.13730)
*Huseyin Goksu*

Main category: eess.SP

TL;DR: 提出了GegenbauerNet来解决谱图神经网络在[-1,1]域中的灵活性-稳定性权衡问题，通过对称性和单一形状参数实现最优折衷。


<details>
  <summary>Details</summary>
Motivation: 解决谱GNN在[-1,1]域中面临的灵活性-稳定性权衡问题，之前的L-JacobiNet因高方差表现不佳，而S-JacobiNet虽然稳定但存在固定偏差。

Method: 基于Gegenbauer多项式构建GNN滤波器，强制执行对称性但允许学习单一形状参数lambda，限制灵活性同时避免固定偏差。

Result: GegenbauerNet在异配图的局部滤波任务(K=2)中表现最优，而L-JacobiNet在高K滤波任务中保持最高性能。在7个数据集上的综合评估验证了这些发现。

Conclusion: 在[-1,1]谱域中，最优滤波器选择关键取决于目标局部性(K)和可接受的设计偏差水平，为GNN开发者提供了重要设计原则。

Abstract: Spectral Graph Neural Networks (GNNs) operating in the canonical [-1, 1] domain (like ChebyNet and its adaptive generalization, L-JacobiNet) face a fundamental Flexibility-Stability Trade-off. Our previous work revealed a critical puzzle: the 2-parameter adaptive L-JacobiNet often suffered from high variance and was surprisingly outperformed by the 0-parameter, stabilized-static S-JacobiNet. This suggested that stabilization was more critical than adaptation in this domain. In this paper, we propose \textbf{GegenbauerNet}, a novel GNN filter based on the Gegenbauer polynomials, to find the Optimal Compromise in this trade-off. By enforcing symmetry (alpha=beta) but allowing a single shape parameter (lambda) to be learned, GegenbauerNet limits flexibility (variance) while escaping the fixed bias of S-JacobiNet. We demonstrate that GegenbauerNet (1-parameter) achieves superior performance in the key local filtering regime (K=2 on heterophilic graphs) where overfitting is minimal, validating the hypothesis that a controlled, symmetric degree of freedom is optimal. Furthermore, our comprehensive K-ablation study across homophilic and heterophilic graphs, using 7 diverse datasets, clarifies the domain's behavior: the fully adaptive L-JacobiNet maintains the highest performance on high-K filtering tasks, showing the value of maximum flexibility when regularization is managed. This study provides crucial design principles for GNN developers, showing that in the [-1, 1] spectral domain, the optimal filter depends critically on the target locality (K) and the acceptable level of design bias.

</details>


### [8] [THD-BAR: Topology Hierarchical Derived Brain Autoregressive Modeling for EEG Generic Representations](https://arxiv.org/abs/2511.13733)
*Wenchao Yang,Weidong Yan,Wenkang Liu,Yulan Ma,Yang Li*

Main category: eess.SP

TL;DR: 提出THD-BAR方法，通过脑拓扑层次结构重新定义自回归学习为"下一尺度时间预测"问题，有效捕捉EEG信号的时空动态特性，在多个下游任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有自回归方法主要依赖多通道EEG数据的简单时间序列，无法捕捉EEG信号的丰富生理特征，且时间中心建模方法限制了脑活动动态空间拓扑的有效表示

Method: 引入脑拓扑层次结构建立EEG通道的多尺度空间顺序，设计拓扑层次向量量化变分自编码器进行多尺度标记化，开发增强的脑自回归模块配合专门掩码策略进行预测

Result: 在17个数据集上进行大规模预训练，在10个下游数据集5个不同任务上验证，THD-BAR始终优于现有方法

Conclusion: 该方法展现了优越的泛化能力和建模能力，为EEG通用表示学习提供了有效解决方案

Abstract: Large-scale pre-trained models hold significant potential for learning universal EEG representations. However, most existing methods, particularly autoregressive (AR) frameworks, primarily rely on straightforward temporal sequencing of multi-channel EEG data, which fails to capture the rich physiological characteristics inherent to EEG signals. Moreover, their time-centered modeling approach also limits the effective representation of the dynamic spatial topology of brain activity. To address these challenges and fully exploit the potential of large-scale EEG models, we propose a novel Topology Hierarchical Derived Brain Autoregressive Modeling (THD-BAR) for EEG generic representations. The core innovation of THD-BAR lies in the introduction of the Brain Topology Hierarchy (BTH), which establishes a multi-scale spatial order for EEG channels. This hierarchical structure enables a redefinition of autoregressive learning as a "next-scale-time prediction" problem, effectively capturing both spatial and temporal dynamics. Based on BTH, we design a Topology-Hierarchical Vector Quantized-Variational Autoencoder (THVQ-VAE) for multi-scale tokenization and develop an enhanced Brain Autoregressive (BAR) module with specialized masking strategies for prediction. Through extensive large-scale pre-training on 17 datasets, followed by rigorous validation on 10 downstream datasets spanning 5 distinct tasks, THD-BAR consistently outperforms existing methods. These results highlight the superior generalization and modeling capabilities of our proposed approach.

</details>


### [9] [Compute-in-Memory Implementation of State Space Models for Event Sequence Processing](https://arxiv.org/abs/2511.13912)
*Xiaoyu Zhang,Mingtao Hu,Sen Lu,Soohyeon Kim,Eric Yeu-Jer Lee,Yuyang Liu,Wei D. Lu*

Main category: eess.SP

TL;DR: 提出一种在存内计算硬件中实现状态空间模型的方法，通过重新参数化模型和使用忆阻器实现高效的事件驱动处理


<details>
  <summary>Details</summary>
Motivation: 状态空间模型在长序列处理中表现出色，但需要高效硬件实现来支持实时事件驱动处理

Method: 重新参数化模型为实值系数和共享衰减常数，利用忆阻器的短期记忆效应在存内计算系统中原生实现状态演化

Result: 系统在事件驱动的视觉和音频任务中实现了高精度和高能效

Conclusion: 通过算法与硬件协同设计，成功实现了支持全异步处理的高效能状态空间模型硬件系统

Abstract: State space models (SSMs) have recently emerged as a powerful framework for long sequence processing, outperforming traditional methods on diverse benchmarks. Fundamentally, SSMs can generalize both recurrent and convolutional networks and have been shown to even capture key functions of biological systems. Here we report an approach to implement SSMs in energy-efficient compute-in-memory (CIM) hardware to achieve real-time, event-driven processing. Our work re-parameterizes the model to function with real-valued coefficients and shared decay constants, reducing the complexity of model mapping onto practical hardware systems. By leveraging device dynamics and diagonalized state transition parameters, the state evolution can be natively implemented in crossbar-based CIM systems combined with memristors exhibiting short-term memory effects. Through this algorithm and hardware co-design, we show the proposed system offers both high accuracy and high energy efficiency while supporting fully asynchronous processing for event-based vision and audio tasks.

</details>


### [10] [Stacked Intelligent Metasurfaces for Multicarrier Cognitive Radio ISAC](https://arxiv.org/abs/2511.13933)
*Alireza Fadakar,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 提出了一种结合认知无线电和集成感知通信的SIM框架，通过优化波束模式同时实现次级用户定位和限制对主用户的干扰。


<details>
  <summary>Details</summary>
Motivation: 融合认知无线电和集成感知通信技术，利用堆叠智能超表面实现6G及以上的多功能可编程前端，在定位次级用户的同时限制对主用户的干扰。

Method: 采用交替优化算法优化SIM端到端传输响应，将分层SIM架构类比深度神经网络，定义波束模式匹配损失，使用小批量Adam优化器学习优化SIM系数。

Result: 当SIM具有足够层数时，所提方法在次级用户定位精度和主用户频谱效率方面达到接近最优性能，显著优于传统单层可重构智能表面设计。

Conclusion: 基于SIM的CR-ISAC框架能够有效平衡定位精度和干扰控制，为6G及未来的多功能无线系统提供了有前景的解决方案。

Abstract: The fusion of cognitive radio (CR) and integrated sensing and communication (ISAC), enabled by stacked intelligent metasurfaces (SIMs), offers a promising path for multi-functional programmable front ends in 6G and beyond. In this paper we propose a novel CR-ISAC framework that leverages an SIM integrated with the secondary base station (SB) to learn and realize optimal beampatterns that simultaneously (i) minimize the Bayesian Cramér-Rao bound (BCRB) for localizing a secondary user equipment (SU) and (ii) limit averaged interference at primary user equipments (PUs) so that spectral efficiency loss is constrained, with the target of at most a few percent degradation. We propose an efficient alternating optimization-based algorithm to obtain the optimal end-to-end transmission response of the SIM for all orthogonal frequency division multiplexing (OFDM) subcarriers. Drawing an analogy between the layered SIM architecture and deep neural networks, we define a beampattern- matching loss, derive analytical gradients for backpropagation, and implement a learning-based optimization of the SIM coefficients using a mini-batch Adam optimizer. A complexity analysis is provided, and extensive numerical experiments are performed to evaluate the proposed CR-ISAC framework. The results show that the proposed SIM coefficient optimization methods attain near-optimal performance in terms of both the SU BCRB localization metric and the PUs average spectral efficiency when the SIM has a sufficient number of layers, and they substantially outperform traditional single-layer reconfigurable intelligent surface (RIS) designs.

</details>


### [11] [Cross-Sparsity-Enabled Multipath Perception via Structured Bayesian Inference for Multi-Target Estimation](https://arxiv.org/abs/2511.14051)
*Xiang Chen,Ming-Min Zhao,An Liu,Min Li,Qingjiang Shi,Min-Jian Zhao*

Main category: eess.SP

TL;DR: 提出了一种利用多径环境中目标间散射产生的第一阶反射路径来增强多目标角度估计的方法，通过构建交叉稀疏结构和分层先验模型，结合高效的变分贝叶斯推理算法，在降低计算复杂度的同时提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 在多径环境中，目标间散射产生的第一阶反射路径包含结构信息，这些路径的出发角和到达角与不同目标的直接路径角度重合，可作为额外的先验知识来改进目标方向估计。

Method: 构建多目标感知信道的稀疏表示，提出三层分层结构化先验模型下的交叉稀疏结构，并开发结构化快速Turbo变分贝叶斯推理算法，结合高效消息传递策略和双时间尺度更新方案。

Result: 仿真结果表明，利用所提出的交叉稀疏结构能够显著提高目标角度估计精度，SF-TVBI算法在保持与Turbo-VBI相当估计性能的同时，具有更低的计算复杂度。

Conclusion: 通过利用多径环境中的第一阶反射路径结构信息，提出的交叉稀疏结构和SF-TVBI算法能够有效提升多目标角度估计性能，同时降低计算负担。

Abstract: In this paper, we investigate a multi-target sensing system in multipath environment, where inter-target scattering gives rise to first-order reflected paths whose angles of departure (AoDs) and angles of arrival (AoAs) coincide with the direct-path angles of different targets. Unlike other multipath components, these first-order paths carry structural information that can be exploited as additional prior knowledge for target direction estimation. To exploit this property, we construct a sparse representation of the multi-target sensing channel and propose a novel cross sparsity structure under a three-layer hierarchical structured (3LHS) prior model, which leverages the first-order paths to enhance the prior probability of the direct paths and thereby improve the estimation accuracy. Building on this model, we propose a structured fast turbo variational Bayesian inference (SF-TVBI) algorithm, which integrates an efficient message-passing strategy to enable tractable probabilistic exchange within the cross sparsity, and a two-timescale update scheme to reduce the update frequency of the high-dimensional sparse vector. Simulation results demonstrate that leveraging the proposed cross sparsity structure is able to improve the target angle estimation accuracy substantially, and the SF-TVBI algorithm achieves estimation performance comparable to that of the Turbo-VBI, but with lower computational complexity.

</details>


### [12] [Lightweight Multi-task CNN for ECG Diagnosis with GRU-Diffusion](https://arxiv.org/abs/2511.14104)
*Lehuai Xu,Zirui Lu,Haoran Yang,Yina Zhou*

Main category: eess.SP

TL;DR: 提出Multi-task DFNet轻量级多任务框架，用于ECG分类，通过动态共享任务知识提高效率，集成GRU增强的扩散模型生成高质量合成信号处理不平衡数据。


<details>
  <summary>Details</summary>
Motivation: 随着边缘设备实时ECG分类需求增加，现有模型面临高计算成本和在不平衡数据集上精度有限的问题。

Method: 采用多任务框架动态共享知识，集成GRU增强的扩散模型捕捉时间依赖性并生成不平衡类别的合成信号。

Result: 在MIT-BIH和PTB数据集上分别达到99.72%和99.89%的准确率，参数量显著少于传统模型。

Conclusion: 为多任务ECG诊断提供紧凑高效解决方案，适合在资源受限的可穿戴设备上部署，具有边缘医疗应用潜力。

Abstract: With the increasing demand for real-time Electrocardiogram (ECG) classification on edge devices, existing models face challenges of high computational cost and limited accuracy on imbalanced datasets.This paper presents Multi-task DFNet, a lightweight multi-task framework for ECG classification across the MIT-BIH Arrhythmia Database and the PTB Diagnostic ECG Database, enabling efficient task collaboration by dynamically sharing knowledge across tasks, such as arrhythmia detection, myocardial infarction (MI) classification, and other cardiovascular abnormalities. The proposed method integrates GRU-augmented Diffusion, where the GRU is embedded within the diffusion model to capture temporal dependencies better and generate high-quality synthetic signals for imbalanced classes. The experimental results show that Multi-task DFNet achieves 99.72% and 99.89% accuracy on the MIT-BIH dataset and PTB dataset, respectively, with significantly fewer parameters compared to traditional models, making it suitable for deployment on wearable ECG monitors. This work offers a compact and efficient solution for multi-task ECG diagnosis, providing a promising potential for edge healthcare applications on resource-constrained devices.

</details>


### [13] [A Patient-Independent Neonatal Seizure Prediction Model Using Reduced Montage EEG and ECG](https://arxiv.org/abs/2511.14110)
*Sithmini Ranasingha,Agasthi Haputhanthri,Hansa Marasinghe,Nima Wickramasinghe,Kithmin Wickremasinghe,Jithangi Wanigasinghe,Chamira U. S. Edussooriya,Joshua P. Kulasingham*

Main category: eess.SP

TL;DR: 提出基于卷积神经网络的模型，通过区分EEG的发作间期和发作前期状态来早期预测新生儿癫痫发作，结合EEG和ECG信号，准确率高达97.52%，可在发作前30分钟预测。


<details>
  <summary>Details</summary>
Motivation: 新生儿癫痫易导致神经损伤，但临床表现微妙易误诊。cEEG监测虽为金标准但昂贵耗时，需要开发自动预测方法。

Method: 使用卷积神经网络，提取多通道EEG和ECG信号的MFCC矩阵作为输入特征，采用注意力机制和10折交叉验证，模型为患者无关设计。

Result: 模型平均准确率97.52%，敏感性98.31%，特异性96.39%，F1分数97.95%。加入ECG使F1分数提高1.42%，注意力机制再提升0.5%。

Conclusion: 该模型具有在新生儿重症监护室最小监督部署的潜力，能及时可靠预测癫痫发作，并通过迁移学习展现对未见患者的强泛化能力。

Abstract: Neonates are highly susceptible to seizures, often leading to short or long-term neurological impairments. However, clinical manifestations of neonatal seizures are subtle and often lead to misdiagnoses. This increases the risk of prolonged, untreated seizure activity and subsequent brain injury. Continuous video electroencephalogram (cEEG) monitoring is the gold standard for seizure detection. However, this is an expensive evaluation that requires expertise and time. In this study, we propose a convolutional neural network-based model for early prediction of neonatal seizures by distinguishing between interictal and preictal states of the EEG. Our model is patient-independent, enabling generalization across multiple subjects, and utilizes mel-frequency cepstral coefficient matrices extracted from multichannel EEG and electrocardiogram (ECG) signals as input features. Trained and validated on the Helsinki neonatal EEG dataset with 10-fold cross-validation, the proposed model achieved an average accuracy of 97.52%, sensitivity of 98.31%, specificity of 96.39%, and F1-score of 97.95%, enabling accurate seizure prediction up to 30 minutes before onset. The inclusion of ECG alongside EEG improved the F1-score by 1.42%, while the incorporation of an attention mechanism yielded an additional 0.5% improvement. To enhance transparency, we incorporated SHapley Additive exPlanations (SHAP) as an explainable artificial intelligence method to interpret the model and provided localization of seizure focus using scalp plots. The overall results demonstrate the model's potential for minimally supervised deployment in neonatal intensive care units, enabling timely and reliable prediction of neonatal seizures, while demonstrating strong generalization capability across unseen subjects through transfer learning.

</details>


### [14] [Integrated Positioning and Communication for Cooperative Multi-LEO Uplink Communications: A Dual-Timescale Kalman Filter-Aided Approach](https://arxiv.org/abs/2511.14421)
*Ali Hanif,Yuchen Zhang,Pinjun Zheng,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 提出了一个集成定位与通信(IPAC)框架，利用LEO卫星的位置信息来改善上行链路信道状态信息获取，通过双时间尺度卡尔曼滤波和期望最大化算法提升信道估计精度和通信性能。


<details>
  <summary>Details</summary>
Motivation: LEO卫星通信面临信道状态信息获取困难的问题，但LEO信道具有视距主导和几何特性，可以利用定位信息来改善信道估计。

Method: 采用双时间尺度卡尔曼滤波框架：大时间尺度使用无迹卡尔曼滤波器跟踪用户位置和速度，小时间尺度利用位置信息进行数据辅助的上行链路信道估计，并通过期望最大化算法联合处理信道估计和协作数据检测。

Result: 数值结果表明，所提出的IPAC方法在信道估计精度和通信性能方面优于传统基准方法。

Conclusion: 集成定位与通信框架能有效利用LEO卫星的位置信息来克服信道状态信息获取的挑战，提升系统性能。

Abstract: Low Earth orbit (LEO) satellites are a crucial component of the future non-terrestrial networks (NTN) due to lower latency, robust signal strengths, shorter revisit times, and dense constellations. However, acquiring reliable channel state information (CSI) in LEO satellite communication remains challenging owing to severe signal attenuation over long propagation distances and short coherence times. Despite these challenges, LEO channels benefit from pronounced line-of-sight dominance and geometric properties inherently tied to positioning information. In this work, we propose an integrated positioning and communication (IPAC) framework for multi-LEO satellite networks to address the unique challenges posed by LEO channels. Specifically, we leverage in-the-loop LEO positioning to exploit users' position information for improving uplink CSI acquisition. To overcome the link-budget limitations of single-satellite systems, cooperative multi-LEO uplink data detection is adopted. By exploiting the different coherent timescales of position-related parameters and random channel gains, we develop a dual-timescale Kalman filter-based IPAC framework: an unscented Kalman filter (UKF) for tracking users' position and velocity in the large-timescale, and a Kalman filter that leverages the position information obtained in the large-timescale for improved data-aided uplink channel estimation in the small-timescale. Finally, the two tasks of channel estimation and cooperative data detection are jointly addressed through the expectation maximization (EM) algorithm. Numerical results demonstrate that the proposed IPAC approach outperforms the conventional baseline in terms of channel estimation accuracy and communication performance.

</details>


### [15] [Covariance-based Imaging and Multi-View Fusion for Networked Sensing](https://arxiv.org/abs/2511.14490)
*Junyuan Gao,Weifeng Zhu,Yanmo Hu,Shuowen Zhang,Jiannong Cao,Yongpeng Wu,Giuseppe Caire,Liang Liu*

Main category: eess.SP

TL;DR: 提出了一种用于6G网络的多视角成像技术，通过两阶段方法联合处理多个接收基站的回波信号，实现精确的目标成像。


<details>
  <summary>Details</summary>
Motivation: 在6G集成感知与通信网络中，需要开发有效的多视角成像技术，能够联合利用所有接收基站的目标回波信号来精确构建目标图像。

Method: 采用两阶段方法：第一阶段各接收基站基于接收信号的样本协方差矩阵恢复个体图像；第二阶段中央处理单元融合所有接收器的个体图像构建高质量图像，使用边缘保持自然邻域插值和联合优化框架。

Result: 广泛的数值结果表明，所提出的方案显著提高了成像性能，有助于未来6G网络的高质量环境重建。

Conclusion: 该技术为6G集成感知与通信网络提供了一种有效的多视角成像解决方案，能够实现高质量的环境重建。

Abstract: This paper considers multi-view imaging in a sixth-generation (6G) integrated sensing and communication network, which consists of a transmit base-station (BS), multiple receive BSs connected to a central processing unit (CPU), and multiple extended targets. Our goal is to devise an effective multi-view imaging technique that can jointly leverage the targets' echo signals at all the receive BSs to precisely construct the image of these targets. To achieve this goal, we propose a two-phase approach. In Phase I, each receive BS recovers an individual image based on the sample covariance matrix of its received signals. Specifically, we propose a novel covariance-based imaging framework to jointly estimate effective scattering intensity and grid positions, which reduces the number of estimated parameters leveraging channel statistical properties and allows grid adjustment to conform to target geometry. In Phase II, the CPU fuses the individual images of all the receivers to construct a high-quality image of all the targets. Specifically, we design edge-preserving natural neighbor interpolation (EP-NNI) to map individual heterogeneous images onto common and finer grids, and then propose a joint optimization framework to estimate fused scattering intensity and BS fields of view. Extensive numerical results show that the proposed scheme significantly enhances imaging performance, facilitating high-quality environment reconstruction for future 6G networks.

</details>


### [16] [Adversarial Learning-Based Radio Map Reconstruction for Fingerprinting Localization](https://arxiv.org/abs/2511.14495)
*Jiaming Zhang,Jiajun He,Tianyu Lu,Jie Zhang,Okan Yurduseven*

Main category: eess.SP

TL;DR: ComGAN是一个特征引导的对抗框架，通过推断未测量参考点的缺失RSS值来重建不完整的指纹数据库，结合条件生成对抗网络和空间特征学习，优化方法聚合多个预测集以提升定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决指纹数据库中接收信号强度值缺失的问题，通过重建不完整的指纹数据库来提高指纹定位的准确性和可靠性。

Method: 提出ComGAN框架，集成辅助子网络到条件生成对抗网络中实现空间特征学习，开发优化方法通过聚合多个预测集来精化RSS预测。

Result: 实验结果显示，该方案达到与真实测量相当的均方根误差，优于现有重建方法，重建指纹与测量数据结合训练时，定位精度可与完整数据集训练的模型相媲美。

Conclusion: ComGAN框架能有效重建不完整的指纹数据库，显著提升指纹定位性能，为不完整数据环境下的定位问题提供了有效解决方案。

Abstract: This letter presents a feature-guided adversarial framework, namely ComGAN, which is designed to reconstruct an incomplete fingerprint database by inferring missing received signal strength (RSS) values at unmeasured reference points (RPs). An auxiliary subnetwork is integrated into a conditional generative adversarial network (cGAN) to enable spatial feature learning. An optimization method is then developed to refine the RSS predictions by aggregating multiple prediction sets, achieving an improved localization performance. Experimental results demonstrate that the proposed scheme achieves a root mean squared error (RMSE) comparable to the ground-truth measurements while outperforming state-of-the-art reconstruction methods. When the reconstructed fingerprint is combined with measured data for training, the fingerprinting localization achieves accuracy comparable to models trained on fully measured datasets.

</details>


### [17] [Tri-Hybrid Beamforming Design for Fully-Connected Pinching Antenna Systems](https://arxiv.org/abs/2511.14517)
*Cheng-Jie Zhao,Zhaolin Wang,Hyundong Shin,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了一种新型全连接三混合波束成形架构，用于夹持天线系统，相比传统子连接架构具有更好的能量效率和更少的射频链需求。


<details>
  <summary>Details</summary>
Motivation: 传统子连接夹持天线系统存在性能限制，需要开发更高效的波束成形架构来提升系统性能并降低复杂度。

Method: 采用全连接架构，通过可调相移网络连接所有射频链和波导，提出基于分数规划和迫零的两种算法来联合优化发射波束成形器和天线位置。

Result: 仿真结果表明，全连接三混合波束成形夹持天线系统在加权和速率方面与传统子连接架构相当，但具有更优的能量效率和更少的射频链需求。

Conclusion: 所提出的全连接三混合波束成形架构为夹持天线系统提供了一种高效且实用的解决方案，在性能和复杂度之间取得了良好平衡。

Abstract: A novel fully-connected (FC) tri-hybrid beamforming (THB) architecture is proposed for pinching antenna systems (PASS). In contrast to conventional sub-connected (SC) PASS, the proposed FC architecture employs a tunable phase-shifter network to interconnect all radio frequency (RF) chains with all waveguides. This facilitates a THB framework that integrates conventional hybrid analog-digital beamforming with pinching beamforming. A weighted sum-rate (WSR) optimization problem is then formulated to jointly optimize the transmit beamformers and pinching antenna (PA) positions. Two algorithms are developed to address this challenging non-convex problem. 1) Fractional programming (FP)-based algorithm: This algorithm directly maximizes the WSR using an FP-based alternating optimization framework. Particularly, a success-history based adaptive differential evolution (SHADE) method is proposed to optimize PA positions, effectively addressing the intractable multimodal objective function. 2) Zero-forcing (ZF)-based algorithm: To reduce design complexity, zero-forcing is employed for transmit beamforming. The PA positions are subsequently optimized to maximize the WSR via a modified SHADE method. Simulation results validate the effectiveness of the proposed algorithms, revealing that the FC-THB PASS achieves WSR comparable to the SC architecture while delivering superior energy efficiency with fewer RF chains.

</details>


### [18] [A Two-Stage ISAC Framework for Low-Altitude Economy Based on 5G NR Signals](https://arxiv.org/abs/2511.14529)
*Haisu Wu,Hong Ren,Cunhua Pan,Boshi Wang,Jun Tang,Haoyang Weng,Feng Shu,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 本文提出了一种基于5G NR信号的两阶段无人机感知框架，通过标准初始接入信号和自定义稀疏导频结构实现高精度感知，克服了传统SSB信号的分辨率限制。


<details>
  <summary>Details</summary>
Motivation: 随着低空经济的发展，需要支持新兴应用同时兼容现有网络架构。基于5G NR信号的集成感知与通信(ISAC)被认为是可行方案，但仅使用标准SSB信号存在分辨率限制。

Method: 采用两阶段粗到精感知框架：第一阶段融合SSB、Type#0-PDCCH和SIB1信息进行初始目标检测；第二阶段引入基于稀疏阵列理论的稀疏导频结构(SPS)，使用加权解缠相位(WUP)技术和RELAX迭代方法进行高分辨率参数估计，最后用DBSCAN算法修剪冗余检测。

Result: 综合仿真结果表明，所提框架相比其他技术具有优越的估计精度和计算效率。

Conclusion: 该两阶段框架有效解决了5G NR信号在无人机感知中的分辨率限制问题，为低空经济应用提供了可行的ISAC解决方案。

Abstract: The evolution of next-generation wireless networks has spurred the vigorous development of the low-altitude economy (LAE). To support this emerging field while remaining compatible with existing network architectures, integrated sensing and communication (ISAC) based on 5G New Radio (NR) signals is regarded as a promising solution. However, merely leveraging standard 5G NR signals, such as the Synchronization Signal Block (SSB), presents fundamental limitations in sensing resolution. To address the issue, this paper proposes a two-stage coarse-to-fine sensing framework that utilizes standard 5G NR initial access signals augmented by a custom-designed sparse pilot structure (SPS) for high-precision unmanned aerial vehicles (UAV) sensing. In Stage I, we first fuse information from the SSB, Type\#0-PDCCH, and system information block 1 (SIB1) to ensure the initial target detection. In Stage II, a refined estimation algorithm is introduced to overcome the resolution limitations of these signals. Inspired by the sparse array theory, this stage employs a novel SPS, which is inserted into resource blocks (RBs) within the CORSET\#0 bandwidth. To accurately extract the off-grid range and velocity parameters from these sparse pilots, we develop a corresponding high-resolution algorithm based on the weighted unwrapped phase (WUP) technique and the RELAX-based iterative method. Finally, the density-based spatial clustering of applications with noise (DBSCAN) algorithm is adopted to prune the redundant detections arising from beam overlap. Comprehensive simulation results demonstrate the superior estimation accuracy and computational efficiency of the proposed framework in comparison to other techniques.

</details>


### [19] [Doppler Invariant CNN for Signal Classification](https://arxiv.org/abs/2511.14640)
*Avi Bagchi,Dwight Hutchenson*

Main category: eess.SP

TL;DR: 提出一种具有复数层和自适应多相采样的CNN架构，通过频域卷积平移等变性实现多普勒频移不变性，无需多普勒增强训练即可保持分类准确性。


<details>
  <summary>Details</summary>
Motivation: 在对抗环境中进行无线电频谱监测需要可靠的自动信号分类技术，现有深度学习方法依赖暴力多普勒增强来实现泛化，这降低了训练效率和可解释性。

Method: 使用复数层卷积神经网络，在频域利用卷积平移等变性，通过自适应多相采样作为池化层，最后使用全局平均池化层实现频率箱平移不变性。

Result: 实验结果表明，与普通CNN不同，该模型在没有多普勒频移训练样本的情况下，对随机多普勒频移仍能保持一致的分类准确率。

Conclusion: 该方法建立了一个基于不变性的信号分类框架，提供了对真实世界效应的可证明鲁棒性。

Abstract: Radio spectrum monitoring in contested environments motivates the need for reliable automatic signal classification technology. Prior work highlights deep learning as a promising approach, but existing models depend on brute-force Doppler augmentation to achieve real-world generalization, which undermines both training efficiency and interpretability. In this paper, we propose a convolutional neural network (CNN) architecture with complex-valued layers that exploits convolutional shift equivariance in the frequency domain. To establish provable frequency bin shift invariance, we use adaptive polyphase sampling (APS) as pooling layers followed by a global average pooling layer at the end of the network. Using a synthetic dataset of common interference signals, experimental results demonstrate that unlike a vanilla CNN, our model maintains consistent classification accuracy with and without random Doppler shifts despite being trained on no Doppler-shifted examples. Overall, our method establishes an invariance-driven framework for signal classification that offers provable robustness against real-world effects.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [20] [Self-Supervised Compression and Artifact Correction for Streaming Underwater Imaging Sonar](https://arxiv.org/abs/2511.13922)
*Rongsheng Qian,Chi Xu,Xiaoqiang Ma,Hao Fang,Yili Jin,William I. Atlas,Jiangchuan Liu*

Main category: eess.IV

TL;DR: SCOPE是一个自监督框架，联合执行声纳图像压缩和伪影校正，无需干净-噪声对或合成假设，在嵌入式GPU上实时运行，可将上行带宽减少80%以上。


<details>
  <summary>Details</summary>
Motivation: 实时成像声纳在水下监测中很重要，但受到两个耦合挑战的限制：高度有限的上行带宽和影响高达98%帧的声纳特定伪影（斑点、运动模糊、混响、声学阴影）。

Method: 结合自适应码本压缩（ACC）学习频率编码的潜在表示，以及频率感知多尺度分割（FAMS）将帧分解为低频结构和稀疏高频动态，同时抑制快速波动的伪影。使用对冲训练策略通过无标签生成的低通代理对指导频率感知学习。

Result: 在数月的现场ARIS声纳数据上评估，SCOPE实现了0.77的结构相似性指数（SSIM），比先前的自监督去噪基线提高了40%，比特率低至<=0.0118 bpp。减少上行带宽80%以上，同时改善下游检测。

Conclusion: 学习频率结构化的潜在表示能够在实际部署条件下实现实用的低比特率声纳流传输，同时保留信号细节。

Abstract: Real-time imaging sonar has become an important tool for underwater monitoring in environments where optical sensing is unreliable. Its broader use is constrained by two coupled challenges: highly limited uplink bandwidth and severe sonar-specific artifacts (speckle, motion blur, reverberation, acoustic shadows) that affect up to 98% of frames. We present SCOPE, a self-supervised framework that jointly performs compression and artifact correction without clean-noise pairs or synthetic assumptions. SCOPE combines (i) Adaptive Codebook Compression (ACC), which learns frequency-encoded latent representations tailored to sonar, with (ii) Frequency-Aware Multiscale Segmentation (FAMS), which decomposes frames into low-frequency structure and sparse high-frequency dynamics while suppressing rapidly fluctuating artifacts. A hedging training strategy further guides frequency-aware learning using low-pass proxy pairs generated without labels. Evaluated on months of in-situ ARIS sonar data, SCOPE achieves a structural similarity index (SSIM) of 0.77, representing a 40% improvement over prior self-supervised denoising baselines, at bitrates down to <= 0.0118 bpp. It reduces uplink bandwidth by more than 80% while improving downstream detection. The system runs in real time, with 3.1 ms encoding on an embedded GPU and 97 ms full multi-layer decoding on the server end. SCOPE has been deployed for months in three Pacific Northwest rivers to support real-time salmon enumeration and environmental monitoring in the wild. Results demonstrate that learning frequency-structured latents enables practical, low-bitrate sonar streaming with preserved signal details under real-world deployment conditions.

</details>


### [21] [PoCGM: Poisson-Conditioned Generative Model for Sparse-View CT Reconstruction](https://arxiv.org/abs/2511.13967)
*Changsheng Fang,Yongtong Liu,Bahareh Morovati,Shuo Han,Li Zhou,Hengyong Yu*

Main category: eess.IV

TL;DR: 提出PoCGM模型，将PFGM++改造为条件生成框架，用于稀疏视图CT重建，有效抑制伪影并保留结构细节


<details>
  <summary>Details</summary>
Motivation: 减少CT投影视图数量可降低辐射剂量和提高时间分辨率，但会导致严重的混叠伪影和结构细节丢失，影响临床应用

Method: 将PFGM++重构为条件生成框架，在训练和采样阶段整合稀疏视图数据作为指导，建模基于稀疏观测的全视图重建后验分布

Result: 定性和定量评估显示PoCGM优于基线方法，在伪影抑制、细节保留方面表现更好，在剂量敏感和时间关键场景中具有可靠性能

Conclusion: PoCGM成功将PFGM++适应于医学成像任务，为稀疏视图CT重建提供了有效的解决方案

Abstract: In computed tomography (CT), reducing the number of projection views is an effective strategy to lower radiation exposure and/or improve temporal resolution. However, this often results in severe aliasing artifacts and loss of structural details in reconstructed images, posing significant challenges for clinical applications. Inspired by the success of the Poisson Flow Generative Model (PFGM++) in natural image generation, we propose a PoCGM (Poisson-Conditioned Generative Model) to address the challenges of sparse-view CT reconstruction. Since PFGM++ was originally designed for unconditional generation, it lacks direct applicability to medical imaging tasks that require integrating conditional inputs. To overcome this limitation, the PoCGM reformulates PFGM++ into a conditional generative framework by incorporating sparse-view data as guidance during both training and sampling phases. By modeling the posterior distribution of full-view reconstructions conditioned on sparse observations, PoCGM effectively suppresses artifacts while preserving fine structural details. Qualitative and quantitative evaluations demonstrate that PoCGM outperforms the baselines, achieving improved artifact suppression, enhanced detail preservation, and reliable performance in dose-sensitive and time-critical imaging scenarios.

</details>


### [22] [ELiC: Efficient LiDAR Geometry Compression via Cross-Bit-depth Feature Propagation and Bag-of-Encoders](https://arxiv.org/abs/2511.14070)
*Junsik Kim,Gun Bang,Soowoong Kim*

Main category: eess.IV

TL;DR: ELiC是一个实时LiDAR几何压缩框架，通过跨比特深度特征传播、编码器池选择和Morton层次结构，在保持实时吞吐的同时实现最先进的压缩效果。


<details>
  <summary>Details</summary>
Motivation: 现有的分层LiDAR几何压缩方法在每个深度级别独立处理，需要从坐标重新估计局部上下文，限制了压缩效率。

Method: 结合跨比特深度特征传播（重用密集低深度的特征支持稀疏高深度的预测）、编码器池选择（为每个深度选择最合适的编码网络）和Morton层次结构（保持全局Z顺序）。

Result: 在Ford和SemanticKITTI数据集上实现了最先进的压缩效果，同时保持实时吞吐量。

Conclusion: ELiC通过改进熵建模和计算效率，在LiDAR几何压缩方面取得了显著进展，代码和模型将在发表后发布。

Abstract: Hierarchical LiDAR geometry compression encodes voxel occupancies from low to high bit-depths, yet prior methods treat each depth independently and re-estimate local context from coordinates at every level, limiting compression efficiency. We present ELiC, a real-time framework that combines cross-bit-depth feature propagation, a Bag-of-Encoders (BoE) selection scheme, and a Morton-order-preserving hierarchy. Cross-bit-depth propagation reuses features extracted at denser, lower depths to support prediction at sparser, higher depths. BoE selects, per depth, the most suitable coding network from a small pool, adapting capacity to observed occupancy statistics without training a separate model for each level. The Morton hierarchy maintains global Z-order across depth transitions, eliminating per-level sorting and reducing latency. Together these components improve entropy modeling and computation efficiency, yielding state-of-the-art compression at real-time throughput on Ford and SemanticKITTI. Code and models will be released upon publication.

</details>


### [23] [NERD: Network-Regularized Diffusion Sampling For 3D Computed Tomography](https://arxiv.org/abs/2511.14680)
*Shijun Liang,Ismail Alkhouri,Qing Qu,Rongrong Wang,Saiprasad Ravishankar*

Main category: eess.IV

TL;DR: 提出了NERD方法，通过将L1正则化引入优化目标来解决3D CT重建问题，减少切片间伪影并促进连贯的体积重建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的方法主要针对2D重建任务，无法直接扩展到3D CT图像重建问题，需要解决切片间的一致性问题。

Method: 在优化目标中加入L1正则化项以鼓励相邻切片的空间连续性，并提出了基于ADMM和PDHG的高效优化策略。

Result: 在医学3D CT数据上的实验表明，该方法达到了最先进或极具竞争力的结果。

Conclusion: NERD方法成功地将扩散模型扩展到3D CT重建，通过正则化处理解决了切片间一致性问题，取得了优异的性能。

Abstract: Numerous diffusion model (DM)-based methods have been proposed for solving inverse imaging problems. Among these, a recent line of work has demonstrated strong performance by formulating sampling as an optimization procedure that enforces measurement consistency, forward diffusion consistency, and both step-wise and backward diffusion consistency. However, these methods have only considered 2D reconstruction tasks and do not directly extend to 3D image reconstruction problems, such as in Computed Tomography (CT). To bridge this gap, we propose NEtwork-Regularized diffusion sampling for 3D CT (NERD) by incorporating an L1 regularization into the optimization objective. This regularizer encourages spatial continuity across adjacent slices, reducing inter-slice artifacts and promoting coherent volumetric reconstructions. Additionally, we introduce two efficient optimization strategies to solve the resulting objective: one based on the Alternating Direction Method of Multipliers (ADMM) and another based on the Primal-Dual Hybrid Gradient (PDHG) method. Experiments on medical 3D CT data demonstrate that our approach achieves either state-of-the-art or highly competitive results.

</details>
