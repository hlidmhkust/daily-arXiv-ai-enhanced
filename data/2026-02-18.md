<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 3]
- [eess.SP](#eess.SP) [Total: 14]
- [cs.IT](#cs.IT) [Total: 5]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [StrokeNeXt: A Siamese-encoder Approach for Brain Stroke Classification in Computed Tomography Imagery](https://arxiv.org/abs/2602.15087)
*Leo Thomas Ramos,Angel D. Sappa*

Main category: eess.IV

TL;DR: StrokeNeXt：用于2D CT图像中风分类的双分支ConvNeXt模型，在6,774张CT图像数据集上达到0.988的准确率和F1分数，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 需要开发高效准确的中风分类模型，以在2D CT图像中同时进行中风检测和亚型分类（缺血性与出血性），解决现有卷积和Transformer方法在准确性和计算效率方面的不足。

Method: 采用双分支设计，使用两个ConvNeXt编码器提取特征，通过基于堆叠1D操作的轻量级卷积解码器进行特征融合，包括瓶颈投影和变换层，以及紧凑的分类头。

Result: 在6,774张CT图像数据集上，StrokeNeXt在准确率和F1分数上达到0.988，显著优于卷积和Transformer基线方法。统计检验证实性能提升具有统计显著性，各类别的敏感性和特异性表现稳健，校准误差更低，误分类率低，且具有低推理时间和快速收敛特性。

Conclusion: StrokeNeXt是一种高效准确的中风分类模型，在2D CT图像中同时实现了优异的中风检测和亚型分类性能，具有临床应用的潜力。

Abstract: We present StrokeNeXt, a model for stroke classification in 2D Computed Tomography (CT) images. StrokeNeXt employs a dual-branch design with two ConvNeXt encoders, whose features are fused through a lightweight convolutional decoder based on stacked 1D operations, including a bottleneck projection and transformation layers, and a compact classification head. The model is evaluated on a curated dataset of 6,774 CT images, addressing both stroke detection and subtype classification between ischemic and hemorrhage cases. StrokeNeXt consistently outperforms convolutional and Transformer-based baselines, reaching accuracies and F1-scores of up to 0.988. Paired statistical tests confirm that the performance gains are statistically significant, while class-wise sensitivity and specificity demonstrate robust behavior across diagnostic categories. Calibration analysis shows reduced prediction error compared to competing methods, and confusion matrix results indicate low misclassification rates. In addition, the model exhibits low inference time and fast convergence.

</details>


### [2] [Benchmarking Self-Supervised Models for Cardiac Ultrasound View Classification](https://arxiv.org/abs/2602.15339)
*Youssef Megahed,Salma I. Megahed,Robin Ducharme,Inok Lee,Adrian D. C. Chan,Mark C. Walker,Steven Hawken*

Main category: eess.IV

TL;DR: USF-MAE自监督学习框架在心脏超声图像视图分类任务中优于MoCo v3，在CACTUS数据集上实现了更高的AUC、准确率、F1分数和召回率。


<details>
  <summary>Details</summary>
Motivation: 心脏超声图像的可靠解读对临床诊断至关重要。自监督学习可以利用大量未标记数据学习有意义的表示，本研究旨在评估和比较两种自监督学习框架在心脏超声视图分类任务上的性能。

Method: 使用CACTUS数据集（37,736张专家标注的心脏超声图像），比较USF-MAE和MoCo v3两种自监督学习框架。采用5折交叉验证，相同训练协议（学习率0.0001，权重衰减0.01），评估ROC-AUC、准确率、F1分数和召回率等指标。

Result: USF-MAE在所有指标上均优于MoCo v3：平均测试AUC为99.99%（±0.01%）vs 99.97%（±0.01%）；平均测试准确率为99.33%（±0.18%）vs 98.99%（±0.28%）。F1分数和召回率也显示类似趋势，差异具有统计显著性（p=0.0048 < 0.01）。

Conclusion: USF-MAE在心脏超声视图分类任务中比MoCo v3学习到更具区分性的特征，证明了其在自动化心脏超声分类中的潜力。

Abstract: Reliable interpretation of cardiac ultrasound images is essential for accurate clinical diagnosis and assessment. Self-supervised learning has shown promise in medical imaging by leveraging large unlabelled datasets to learn meaningful representations. In this study, we evaluate and compare two self-supervised learning frameworks, USF-MAE, developed by our team, and MoCo v3, on the recently introduced CACTUS dataset (37,736 images) for automated simulated cardiac view (A4C, PL, PSAV, PSMV, Random, and SC) classification. Both models used 5-fold cross-validation, enabling robust assessment of generalization performance across multiple random splits. The CACTUS dataset provides expert-annotated cardiac ultrasound images with diverse views. We adopt an identical training protocol for both models to ensure a fair comparison. Both models are configured with a learning rate of 0.0001 and a weight decay of 0.01. For each fold, we record performance metrics including ROC-AUC, accuracy, F1-score, and recall. Our results indicate that USF-MAE consistently outperforms MoCo v3 across metrics. The average testing AUC for USF-MAE is 99.99% (+/-0.01% 95% CI), compared to 99.97% (+/-0.01%) for MoCo v3. USF-MAE achieves a mean testing accuracy of 99.33% (+/-0.18%), higher than the 98.99% (+/-0.28%) reported for MoCo v3. Similar trends are observed for the F1-score and recall, with improvements statistically significant across folds (paired t-test, p=0.0048 < 0.01). This proof-of-concept analysis suggests that USF-MAE learns more discriminative features for cardiac view classification than MoCo v3 when applied to this dataset. The enhanced performance across multiple metrics highlights the potential of USF-MAE for improving automated cardiac ultrasound classification.

</details>


### [3] [Rate-Distortion Optimization for Ensembles of Non-Reference Metrics](https://arxiv.org/abs/2602.15779)
*Xin Xiong,Samuel Fernández-Menduiña,Eduardo Pavez,Antonio Ortega,Neil Birkbeck,Balu Adsumilli*

Main category: eess.IV

TL;DR: 论文提出了一种改进的视频编码率失真优化方法，通过集成多个无参考质量评估指标并进行梯度平滑，解决了单一指标线性化带来的局限性和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频编码的率失真优化主要依赖全参考指标（如SSE），但无参考指标更适合评估用户生成内容。然而，单一无参考指标的线性化方法存在梯度不稳定和模型特定偏差问题，导致优化效果有限或不稳定。

Method: 扩展了线性化无参考指标框架，优化多个无参考指标的集成，并引入基于平滑的公式来稳定梯度。该方法特别适用于混合编解码器，避免了神经网络无参考指标的迭代评估和反向传播，降低了编码器复杂度。

Result: 在AVC和Cool-chic编解码器上验证，使用YouTube UGC数据集。实验表明，该方法在多个无参考指标上实现了一致的码率节省，没有增加解码器复杂度，对于Cool-chic还显著减少了编码运行时间。

Conclusion: 提出的集成多个无参考指标并稳定梯度的框架，能够有效解决单一指标线性化的局限性，在保持低复杂度的同时实现更稳健的视频编码质量优化。

Abstract: Non-reference metrics (NRMs) can assess the visual quality of images and videos without a reference, making them well-suited for the evaluation of user-generated content. Nonetheless, rate-distortion optimization (RDO) in video coding is still mainly driven by full-reference metrics, such as the sum of squared errors, which treat the input as an ideal target. A way to incorporate NRMs into RDO is through linearization (LNRM), where the gradient of the NRM with respect to the input guides bit allocation. While this strategy improves the quality predicted by some metrics, we show that it can yield limited gains or degradations when evaluated with other NRMs. We argue that NRMs are highly non-linear predictors with locally unstable gradients that can compromise the quality of the linearization; furthermore, optimizing a single metric may exploit model-specific biases that do not generalize across quality estimators. Motivated by this observation, we extend the LNRM framework to optimize ensembles of NRMs and, to further improve robustness, we introduce a smoothing-based formulation that stabilizes NRM gradients prior to linearization. Our framework is well-suited to hybrid codecs, and we advocate for its use with overfitted codecs, where it avoids iterative evaluations and backpropagation of neural network-based NRMs, reducing encoder complexity relative to direct NRM optimization. We validate the proposed approach on AVC and Cool-chic, using the YouTube UGC dataset. Experiments demonstrate consistent bitrate savings across multiple NRMs with no decoder complexity overhead and, for Cool-chic, a substantial reduction in encoding runtime compared to direct NRM optimization.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [4] [Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient](https://arxiv.org/abs/2602.15036)
*Saumyadip Mukhopadhyay,Kiho Yang,Kasyap Thottasserymana Vasudevan,Mounica Jyothi Divvela,Selim Dogru,Dilip Krishnamurthy,Fergo Treska,Werner Gillijns,Ryan Ryoung han Kim,Kumara Sastry,Vivek Singh*

Main category: eess.SP

TL;DR: NVIDIA cuLitho利用加速计算和AI技术，为计算光刻带来57倍端到端加速，实现更好的工艺窗口和边缘放置误差


<details>
  <summary>Details</summary>
Motivation: 科学计算需求激增远超晶体管缩放速度，导致成本、能耗和排放不可持续增长。计算光刻作为半导体制造中最大的工作负载，在埃米时代变得异常复杂，需要更精确建模和更广泛解决方案探索。

Method: 重新设计软件栈，重构计算光刻核心原语（衍射光学、计算几何、多变量优化、数据处理），结合加速计算和AI技术作为计算密集型步骤的高保真替代方案。

Result: 实现57倍端到端加速，在IMEC的硅实验中显示35%更好的工艺窗口和19%更好的边缘放置误差。首次在芯片尺度上量化展示了加速计算和AI在光刻中的优势。

Conclusion: 加速计算和AI共同构成了科学工作负载的可持续下一代计算平台，通过cuLitho在计算光刻中实现了革命性改进，支持更严格的解决方案如曲线掩模、高数值孔径EUV光刻和亚原子建模。

Abstract: From climate science to drug discovery, scientific computing demands have surged dramatically in recent years -- driven by larger datasets, more sophisticated models, and higher simulation fidelity. This growth rate far outpaces transistor scaling, leading to unsustainably rising costs, energy consumption, and emissions. Semiconductor manufacturing is no exception. Computational lithography -- involving transferring circuitry to silicon in diffraction-limited conditions -- is the largest workload in semiconductor manufacturing. It has also grown exceptionally complex as miniaturization has advanced in the angstrom-era, requiring more accurate modeling, intricate corrections, and broader solution-space exploration. Accelerated computing (AC) offers a solution by dramatically freeing up the compute and power envelope. AI augments these gains by serving as high-fidelity surrogates for compute-intensive steps. Together, they present a sustainable, next-generation computing platform for scientific workloads. This new paradigm needs a fundamental redesign of the software stack. For computational lithography, NVIDIA cuLitho reinvents the core primitives -- diffractive optics, computational geometry, multi-variant optimization, data processing -- to achieve a transformative 57X end-to-end acceleration. Beyond dramatically faster cycles, this expanded compute envelope enables more rigorous solutions, including curvilinear masks, high-numerical aperture extreme ultraviolet (high-NA EUV) lithography, and subatomic modeling. We reinvest a small fraction of the freed-up compute to include through-focus correction for better process resilience. Silicon experiments at IMEC show significant benefits compared to conventional methods -- 35% better process window and 19% better edge placement error. This is the first quantified chip-scale demonstration of the lithography benefits of AC and AI in silicon.

</details>


### [5] [Combining scEEG and PPG for reliable sleep staging using lightweight wearables](https://arxiv.org/abs/2602.15042)
*Jiawei Wang,Liang Xu,Shuntian Zheng,Yu Guan,Kaichen Wang,Ziqing Zhang,Chen Chen,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 该研究探索了单通道脑电图（scEEG）与光电容积描记图（PPG）融合在短时间窗口（30秒-30分钟）约束下进行4类睡眠分期，提出Mamba增强融合方法显著提升了浅睡眠分类性能。


<details>
  <summary>Details</summary>
Motivation: 当前轻量级可穿戴设备（如单通道脑电图或光电容积描记图）的可靠睡眠分期仍具挑战。scEEG直接测量皮层活动但浅睡眠分期性能有限，PPG能有效检测浅睡眠但传统方法需要整夜记录（8-10小时），不利于及时睡眠干预反馈。

Method: 研究评估了各模态所需的时间上下文，探索了三种融合策略：分数级融合、特征级交叉注意力融合，以及结合时间上下文建模的Mamba增强融合。在MESA数据集上训练，并在CFS和ABC数据集上进行跨数据集验证。

Result: Mamba增强融合在MESA数据集上获得最佳性能（Cohen's Kappa κ = 0.798，准确率86.9%），浅睡眠分类显著改善（F1分数：85.63% vs. 77.76%，召回率：82.85% vs. 69.95%），在CFS和ABC数据集上泛化良好。

Conclusion: scEEG-PPG融合是轻量级可穿戴睡眠监测的有前景方法，为更易获取的睡眠健康评估提供了途径，特别在短时间窗口约束下能有效提升浅睡眠分类性能。

Abstract: Reliable sleep staging remains challenging for lightweight wearable devices such as single-channel electroencephalography (scEEG) or photoplethysmography (PPG). scEEG offers direct measurement of cortical activity and serves as the foundation for sleep staging, yet exhibits limited performance on light sleep stages. PPG provides a low-cost complement that captures autonomic signatures effective for detecting light sleep. However, prior PPG-based methods rely on full night recordings (8 - 10 hours) as input context, which is less practical to provide timely feedback for sleep intervention. In this work, we investigate scEEG-PPG fusion for 4-class sleep staging under short-window (30 s - 30 min) constraints. First, we evaluate the temporal context required for each modality, to better understand the relationship of sleep staging performance with respect to monitoring window. Second, we investigate three fusion strategies: score-level fusion, cross-attention fusion enabling feature-level interactions, and Mamba-enhanced fusion incorporating temporal context modeling. Third, we train and evaluate on the Multi-Ethnic Study of Atherosclerosis (MESA) dataset and perform cross-dataset validation on the Cleveland Family Study (CFS) and the Apnea, Bariatric surgery, and CPAP (ABC) datasets. The Mamba-enhanced fusion achieves the best performance on MESA (Cohen's Kappa $κ$ = 0.798, Acc = 86.9%), with particularly notable improvement in light sleep classification (F1-score: 85.63% vs. 77.76%, recall: 82.85% vs. 69.95% for scEEG alone), and generalizes well to CFS and ABC datasets with different populations. These findings suggest that scEEG-PPG fusion is a promising approach for lightweight wearable based sleep monitoring, offering a pathway toward more accessible sleep health assessment. Source code of this project can be found at: https://github.com/DavyWJW/scEEG-PPGFusion

</details>


### [6] [Large elements and advanced beamformers for increased field of view in 2-D ultrasound matrix arrays](https://arxiv.org/abs/2602.15174)
*Mick Gardner,Michael L. Oelze*

Main category: eess.SP

TL;DR: 通过增大阵元尺寸并使用先进波束形成器，在保持图像质量的同时扩大三维超声矩阵阵列的视野范围


<details>
  <summary>Details</summary>
Motivation: 三维超声在腹部、产科和心血管成像中有广泛应用前景，但传统矩阵阵列因阵元数量极高而视野受限。本研究旨在通过减少阵元数量的阵列设计来扩大视野范围。

Method: 采用增大阵元尺寸的策略，并比较DAS、NSI、DCF和MV四种波束形成器。通过K-wave仿真3D点扩散函数，并使用1024元矩阵阵列在Verasonics 256系统上进行实验，通过电子耦合模拟更大阵元间距和尺寸，利用定位系统分段采集数据创建虚拟大孔径。

Result: 仿真显示NSI、DCF和MV相比DAS具有更低的旁瓣和更窄的主瓣。实验中使用耦合因子为2时获得了高质量图像，视野扩大一倍，同时保持与原始矩阵阵列相同的阵元数量。NSI波束形成器在仿真和大孔径实验中表现最佳，在耦合因子高达4时仍能保持与未耦合DAS相同的分辨率。

Conclusion: 研究表明可以通过增大阵元尺寸构建更大的矩阵阵列，同时利用先进波束形成器保持分辨率，为扩大三维超声视野提供了可行方案。

Abstract: Three-dimensional (3D) ultrasound promises various medical applications for abdominal, obstetrics, and cardiovascular imaging. However, ultrasound matrix arrays have extremely high element counts limiting their field of view (FOV). This work seeks to demonstrate an increased field-of-view using a reduced element count array design. The approach is to increase the element size and use advanced beamformers to maintain image quality. The delay and sum (DAS), Null Subtraction Imaging (NSI), directional coherence factor (DCF), and Minimum Variance (MV) beamformers were compared. K-wave simulations of the 3D point-spread functions (PSF) of NSI, DCF, and MV display reduced side lobes and narrowed main lobes compared to DAS. Experiments were conducted using a multiplexed 1024-element matrix array on a Verasonics 256 system. Elements were electronically coupled to imitate a larger pitch and element size. Then, a virtual large aperture was created by using a positioning system to collect data in sections with the matrix array. High-quality images were obtained using a coupling factor of two, doubling the FOV while maintaining the same element count in the virtual large aperture as the original matrix array. The NSI beamformer demonstrated the best resolution performance in simulations and on the large aperture, maintaining the same resolution as uncoupled DAS for coupling factors up to 4. Our results demonstrate how larger matrix arrays could be constructed with larger elements, with resolution maintained by advanced beamformers.

</details>


### [7] [Secure High-Resolution ISAC via Multi-Layer Intelligent Metasurfaces: A Layered Optimization Framework](https://arxiv.org/abs/2602.15209)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

TL;DR: 本文提出了一种基于堆叠智能超表面(SIM)的集成感知与通信(ISAC)系统，通过分层优化框架同时提升通信安全性和感知精度，相比传统方法在感知准确性和保密率方面有显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC系统在实现高分辨率感知的同时，难以兼顾通信安全性和频谱效率，存在根本性限制。需要一种创新方法来克服这些挑战。

Method: 采用堆叠智能超表面(SIM)辅助的多功能系统，提出分层优化框架，通过多目标优化公式平衡保密率最大化和感知误差最小化，使用分层块坐标下降算法协调感知配置、安全波束成形、通信超表面优化和资源分配。

Result: 仿真结果显示，相比传统方法，感知精度提升32-61%，保密率提高15-35%，同时保持计算效率。

Conclusion: 这项工作为安全且高精度的多功能无线系统建立了新范式，通过SIM技术实现了感知与通信性能的协同优化。

Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal technology for next-generation wireless networks, enabling simultaneous data transmission and environmental sensing. However, existing ISAC systems face fundamental limitations in achieving high-resolution sensing while maintaining robust communication security and spectral efficiency. This paper introduces a transformative approach leveraging stacked intelligent metasurfaces (SIM) to overcome these challenges. We propose a multi-functional SIM-assisted system that jointly optimizes communication secrecy and sensing accuracy through a novel layered optimization framework. Our solution employs a multi-objective optimization formulation that balances secrecy rate maximization with sensing error minimization under practical hardware constraints. The proposed layered block coordinate descent algorithm efficiently coordinates sensing configuration, secure beamforming, communication metasurface optimization, and resource allocation while ensuring robustness to channel uncertainties. Extensive simulations demonstrate significant performance gains over conventional approaches, achieving 32-61\% improvement in sensing accuracy and 15-35\% enhancement in secrecy rates while maintaining computational efficiency. This work establishes a new paradigm for secure and high-precision multi-functional wireless systems.

</details>


### [8] [Multiplierless DFT Approximation Based on the Prime Factor Algorithm](https://arxiv.org/abs/2602.15218)
*L. Portella,F. M. Bayer,R. J. Cintra*

Main category: eess.SP

TL;DR: 提出基于小素数点DFT近似的完全无乘法器DFT近似方法，消除了中间乘法步骤和误差传播，设计出1023点DFT近似


<details>
  <summary>Details</summary>
Motivation: 现有DFT近似方法通常基于Cooley-Tukey算法，但会继承中间旋转因子乘法，这些因子通常不被近似，否则误差传播会影响整体性能。需要一种能消除中间乘法步骤、防止误差传播的完全无乘法器DFT近似方法。

Method: 利用素数因子算法框架，基于小素数点DFT近似构建DFT近似。该方法完全消除中间乘法步骤，防止内部误差传播。具体实现基于3点、11点和31点DFT近似来设计1023点DFT近似。

Result: 提出的1023点DFT近似不仅具有显著更低的算术复杂度，而且与竞争方法相比产生了更小的近似误差测量值。

Conclusion: 素数因子算法为推导完全无乘法器DFT近似提供了必要框架，提出的基于小素数点DFT近似的方法能有效消除中间乘法步骤和误差传播，在复杂度和精度方面均优于现有方法。

Abstract: Matrix approximation methods have successfully produced efficient, low-complexity approximate transforms for the discrete cosine transforms and the discrete Fourier transforms. For the DFT case, literature archives approximations operating at small power-of-two blocklenghts, such as \{8, 16, 32\}, or at large blocklengths, such as 1024, which are obtained by means of the Cooley-Tukey-based approximation relying on the small-blocklength approximate transforms. Cooley-Tukey-based approximations inherit the intermediate multiplications by twiddled factors which are usually not approximated; otherwise the effected error propagation would prevent the overall good performance of the approximation. In this context, the prime factor algorithm can furnish the necessary framework for deriving fully multiplierless DFT approximations. We introduced an approximation method based on small prime-sized DFT approximations which entirely eliminates intermediate multiplication steps and prevents internal error propagation. To demonstrate the proposed method, we design a fully multiplierless 1023-point DFT approximation based on 3-, 11- and 31-point DFT approximations. The performance evaluation according to popular metrics showed that the proposed approximations not only presented a significantly lower arithmetic complexity but also resulted in smaller approximation error measurements when compared to competing methods.

</details>


### [9] [SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation](https://arxiv.org/abs/2602.15326)
*Hao Chen,Zavareh Bozorgasl*

Main category: eess.SP

TL;DR: SCENE是一种用于空中联邦蒸馏的无导频、相位不变的聚合原语，通过非相干能量估计实现无偏软标签平均，适用于短相干时间和硬件受限场景。


<details>
  <summary>Details</summary>
Motivation: 针对空中联邦蒸馏中需要避免每轮信道状态信息获取的场景，特别是在短相干时间和硬件受限环境下，需要一种无导频、相位不变的聚合方法，以减少开销并适应硬件限制。

Method: 设备将软标签向量映射到非负发射能量，采用恒定每轮功率和恒定包络信号（PAPR接近1）。服务器使用自中心化能量估计器去除噪声能量偏移，得到加权软标签平均的无偏估计。还开发了无导频比率归一化变体以消除未知大尺度增益。

Result: SCENE的估计方差随接收天线数M和重复因子S按1/(SM)衰减。收敛边界与相干OTA-FD分析一致，在导频开销不可忽略时可能优于相干设计。

Conclusion: SCENE通过适度的非相干方差常数换取零上行导频、无偏聚合和硬件友好传输，特别适用于需要避免每轮CSI获取的短相干时间和硬件受限场景。

Abstract: We propose SCENE (Self-Centering Noncoherent Estimator), a pilot-free and phase-invariant aggregation primitive for over-the-air federated distillation (OTA-FD). Each device maps its soft-label (class-probability) vector to nonnegative transmit energies under constant per-round power and constant-envelope signaling (PAPR near 1). At the server, a self-centering energy estimator removes the noise-energy offset and yields an unbiased estimate of the weighted soft-label average, with variance decaying on the order of 1/(SM) in the number of receive antennas M and repetition factor S. We also develop a pilot-free ratio-normalized variant that cancels unknown large-scale gains, provide a convergence bound consistent with coherent OTA-FD analyses, and present an overhead-based crossover comparison. SCENE targets short-coherence and hardware-constrained regimes, where avoiding per-round CSI is essential: it trades a modest noncoherent variance constant for zero uplink pilots, unbiased aggregation, and hardware-friendly transmission, and can outperform coherent designs when pilot overhead is non-negligible.

</details>


### [10] [Adaptive Selection of Codebook Using Assistance Information and Artificial Intelligence for 6G Systems](https://arxiv.org/abs/2602.15530)
*Denis Esiunin,Alexei Davydov*

Main category: eess.SP

TL;DR: 提出一种基于神经网络的自适应码本选择方法，通过UE上报的统计信道特性来预测不同码本的量化精度，从而在保证系统吞吐量的同时降低CSI开销。


<details>
  <summary>Details</summary>
Motivation: 下行预编码器量化精度受传播条件影响，需要为每个UE独立调整参数。传统固定码本选择方法无法适应不同信道条件，导致CSI报告开销大或性能下降。

Method: 提出基站端UE辅助的码本选择方案：UE上报时域、频域和空域的统计信道特性；基站使用神经网络预测不同码本类型的量化精度；基于预测精度选择最优码本，同时考虑CSI报告开销和预编码性能。

Result: 系统级仿真表明，所提方法在维持目标系统吞吐量性能的同时，显著降低了总的CSI开销。

Conclusion: 基于神经网络的UE辅助码本选择方案能够有效适应不同信道条件，在保证系统性能的前提下优化CSI报告开销，为5G/6G系统中的自适应预编码量化提供了有效解决方案。

Abstract: This paper addresses the problem of adaptive codebook (CB) selection for downlink (DL) precoder quantization in channel state information (CSI) reporting. The accuracy of precoder quantization depends on propagation conditions, requiring independent parameter adaptation for each user equipment (UE). To enable optimal CB selection, this paper proposes UE-assisted CB selection at the base station (BS) using reported by the UE statistical channel properties across time, frequency, and spatial domains. The reported assistance information serves as input to a neural network (NN), which predicts the quantization accuracy of various CB types for each served user. The predicted accuracy is then used to select the optimal CB while considering the associated CSI reporting overhead and precoding performance. System-level simulations demonstrate that the proposed approach reduces total CSI overhead while maintaining the target system throughput performance.

</details>


### [11] [Waveform Design for ISAC System: A Consensus ADMM Approach](https://arxiv.org/abs/2602.15544)
*Ngoc-Son Duong,Huyen-Trang Ta,Quang-Tang Ngo,Thi-Hue Duong,Van-Lap Nguyen,Cong-Minh Nguyen,Minh-Tran Nguyen,Thai-Mai Dinh*

Main category: eess.SP

TL;DR: 提出一种用于多用户下行链路ISAC系统的联合发射波形和接收滤波器设计方法，在恒定模量和相似性约束下平衡通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: 在实际的恒定模量和相似性约束下，多用户下行链路集成感知与通信（ISAC）系统需要同时优化通信和感知性能，现有方法难以有效处理这一非凸多目标优化问题。

Method: 采用共识交替方向乘子法（ADMM）框架，交替更新发射波形和雷达滤波器，有效处理感知SINR的非凸分数形式，确保快速收敛。

Result: 仿真结果表明，与现有基准方案相比，所提方法在通信总速率和感知SINR之间实现了更好的权衡。

Conclusion: 提出的基于共识ADMM的联合设计方法能够有效解决ISAC系统在实用约束下的多目标优化问题，为通信和感知性能的平衡提供了有效解决方案。

Abstract: We study joint transmit-waveform and receive-filter design for a multi-user downlink integrated sensing and communication (ISAC) system under practical constant-modulus and similarity constraints. We cast the design as a unified multi-objective program that balances communication sum rate and sensing signal-to-interference-plus-noise ratio (SINR). To address this, we introduce an efficient algorithm that use consensus alternating direction method of multipliers (ADMM) framework to alternately update the transmit waveform and radar filter. The proposed method effectively handles the non-convex fractional sensing's SINR formulation and ensures fast convergence. Simulation results demonstrate that the proposed approach achieves better trade-offs between communication sum rate and sensing's SINR compared to existing benchmark schemes.

</details>


### [12] [Tracking Time-Varying Multipath Channels forActive Sonar Applications](https://arxiv.org/abs/2602.15555)
*Ashwani Koul,Gustaf Hendeby,Isaac Skog*

Main category: eess.SP

TL;DR: 提出直接在原始测量域学习和跟踪多径背景的框架，通过状态空间模型和扩展卡尔曼滤波实现信道跟踪，参数通过边缘似然学习，最终用于目标检测的序列似然比检验


<details>
  <summary>Details</summary>
Motivation: 传统方法在距离-多普勒域进行背景学习计算量大，且可能掩盖相位相干结构。需要直接在原始测量域学习和跟踪多径背景，以更准确高效地监测和跟踪时变浅水环境中的声学多径背景

Method: 从宽带多普勒线性化的时变多径信道冲激响应出发，推导出具有异方差测量方程的状态空间模型。使用扩展卡尔曼滤波进行信道跟踪，未知参数通过边缘似然学习，并通过p值显著性检验评估模型统计充分性

Result: BELLHOP仿真表明，所提模型能更好地捕捉海面波动和收发器漂移引起的信道动态变化，在时变浅水环境中提供更可靠的检测性能

Conclusion: 直接在原始测量域学习和跟踪多径背景的框架优于传统距离-多普勒域方法，能更有效地处理时变浅水环境中的信道动态，提高目标检测的可靠性

Abstract: Reliable detection and tracking in active sonar require accurate and efficient learning of the acoustic multipath background environment. Conventionally, background learning is performed after transforming measurements into the range-Doppler domain, a step that is computationally expensive and can obscure phase-coherent structure useful for monitoring and tracking. This paper proposes a framework for learning and tracking the multipath background directly in the raw measurement domain. Starting from a wideband Doppler linearization of the impulse response of a time-varying multipath channel, a state-space model with a heteroscedastic measurement equation is derived. This model enables channel tracking using an extended Kalman filter (EKF), and unknown model parameters are learned from the marginalized likelihood. The statistical adequacy of the proposed models is assessed via a p-value significance test. Finally, this paper integrates the learned channel model into a sequential likelihood-ratio test for target detection. BELLHOP-based simulations show that the proposed model better captures channel dynamics induced by sea-surface fluctuations and transmitter and receiver drift, yielding more reliable detection in time-varying shallow-water environments

</details>


### [13] [Physics-Informed Anomaly Detection of Terrain Material Change in Radar Imagery](https://arxiv.org/abs/2602.15618)
*Abdel Hakiem Mohamed Abbas Mohamed Ahmed,Beth Jelfs,Airlie Chapman,Eric Schoof,Christopher Gilliam*

Main category: eess.SP

TL;DR: 提出基于物理的雷达图像地形材料变化检测方法，通过轻量级电磁前向模型生成双时相SLC图像，结合物理感知特征和多种无监督检测器，在合成场景中验证了相干性和鲁棒协方差对材料变化检测的改进效果。


<details>
  <summary>Details</summary>
Motivation: 雷达图像中地形材料变化（如介电常数、粗糙度或湿度变化）的检测对许多应用很重要，但传统方法可能无法有效处理复杂的电磁散射特性和杂波环境。

Method: 1) 提出轻量级电磁前向模型模拟带标签材料图的双时相单视复图像；2) 推导物理感知特征栈，包括干涉相干性；3) 评估多种无监督检测器：Reed-Xiaoli/局部RX（使用Tyler's M估计器）、相干变化检测和紧凑卷积自编码器；4) 通过蒙特卡洛实验扫描不同参数变化。

Result: 在合成但物理基础真实的场景中，相干性和鲁棒协方差显著改善了材料变化的异常检测性能；在重尾杂波环境中，简单的分数级融合实现了最佳的F1分数。

Conclusion: 结合物理模型和鲁棒统计方法能有效检测雷达图像中的地形材料变化，相干性特征和鲁棒协方差估计在复杂杂波环境中特别有效，分数级融合策略能进一步提升检测性能。

Abstract: In this paper we consider physics-informed detection of terrain material change in radar imagery (e.g., shifts in permittivity, roughness or moisture). We propose a lightweight electromagnetic (EM) forward model to simulate bi-temporal single-look complex (SLC) images from labelled material maps. On these data, we derive physics-aware feature stacks that include interferometric coherence, and evaluate unsupervised detectors: Reed-Xiaoli (RX)/Local-RX with robust scatter (Tyler's M-estimator), Coherent Change Detection (CCD), and a compact convolutional auto-encoder. Monte Carlo experiments sweep dielectric/roughness/moisture changes, number of looks and clutter regimes (gamma vs K-family) at fixed probability of false alarm. Results on synthetic but physically grounded scenes show that coherence and robust covariance markedly improve anomaly detection of material changes; a simple score-level fusion achieves the best F1 in heavy-tailed clutter.

</details>


### [14] [Passive Imaging with Ambient Noise Under Wave Speed Mismatch: Mathematical Analysis and Wave Speed Estimation](https://arxiv.org/abs/2602.15623)
*Zetao Fei,Josselin Garnier*

Main category: eess.SP

TL;DR: 该论文研究被动相关成像中的波速估计问题，在背景波速未知的情况下，通过引入搜索波速分析偏移成像中的确定性偏移和散焦效应，提出基于虚拟导星的有效波速估计方法。


<details>
  <summary>Details</summary>
Motivation: 从环境噪声源记录中重建介质反射率是一个挑战性问题，特别是在背景波速未知的情况下。现有方法在部分边界测量和未知波速条件下难以准确成像。

Method: 1. 分析均匀背景中点反射体的日光偏移成像，引入搜索波速推导波速失配引起的确定性偏移和散焦效应公式；2. 扩展至相关长度小于波长的随机介质，利用均匀情况下的偏移公式引入虚拟导星；3. 提出基于虚拟导星空间平均的有效波速估计策略。

Result: 1. 证明了偏移成像功能包络的最大值提供了真实波速的可靠估计器；2. 虚拟导星在不同搜索波速下保持固定，实现了有效的波速估计；3. 为均匀和随机介质建立了波速估计器的分辨率分析；4. 数值实验验证了理论结果。

Conclusion: 该研究提出了在背景波速未知条件下被动相关成像的有效波速估计方法，通过分析偏移成像中的确定性效应和引入虚拟导星，解决了部分边界测量中的波速估计难题，为被动成像技术提供了理论支持和实用工具。

Abstract: It is known that waves generated by ambient noise sources and recorded by passive receivers can be used to image the reflectivities of an unknown medium. However, reconstructing the reflectivity of the medium from partial boundary measurements remains a challenging problem, particularly when the background wave speed is unknown. In this paper, we investigate passive correlation-based imaging in the daylight configuration, where uncontrolled noise sources illuminate the medium and only ambient fields are recorded by a sensor array. We first analyze daylight migration for a point reflector embedded in a homogeneous background. By introducing a searching wave speed into the migration functional, we derive an explicit characterization of the deterministic shift and defocusing effects induced by wave-speed mismatch. We show that the maximum of the envelope of the resulting functional provides a reliable estimator of the true wave speed. We then extend the analysis to a random medium with correlation length smaller than the wavelength. Leveraging the shift formula obtained in the homogeneous case, we introduce a virtual guide star that remains fixed under migration with different searching speeds. This property enables an effective wave-speed estimation strategy based on spatial averaging around the virtual guide star. For both homogeneous and random media, we establish resolution analyses for the proposed wave-speed estimators. Numerical experiments are conducted to validate the theoretical result.

</details>


### [15] [Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications](https://arxiv.org/abs/2602.15640)
*Peizheng Li,Xinyi Lin,Adnan Aijaz*

Main category: eess.SP

TL;DR: 提出TC-HITL-RL框架，将人类反馈、语义效用和延迟控制整合到语义感知Open RAN架构中，通过CMDP建模和PPO算法解决语义通信中的延迟约束问题。


<details>
  <summary>Details</summary>
Motivation: 语义通信需要在保证语义保真度的同时满足严格延迟要求，特别是在沉浸式和关键安全服务中。现有方法难以平衡语义质量和延迟约束。

Method: 1) 提出时间约束的人机协同强化学习框架；2) 将人类反馈驱动的语义适应建模为约束马尔可夫决策过程；3) 使用原始-对偶近端策略优化算法，结合动作屏蔽和延迟感知奖励塑造；4) 在语义感知Open RAN架构中实现。

Result: 仿真显示TC-HITL-RL能持续满足每个用户的时序约束，在奖励方面优于基线调度器，稳定资源消耗，为延迟感知语义适应提供了实用方案。

Conclusion: 该框架成功解决了语义通信中语义保真度与延迟保证的平衡问题，通过人类反馈和强化学习的结合，为沉浸式和关键安全服务提供了可行的语义适应方案。

Abstract: Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic adaptation.

</details>


### [16] [NYUSIM: A Roadmap to AI-Enabled Statistical Channel Modeling and Simulation](https://arxiv.org/abs/2602.15737)
*Isha Jariwala,Xinquan Wang,Bridget Meier,Guanyue Qian,Dipankar Shakya,Mingjun Ying,Homa Nikbakht,Daniel Abraham,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: NYUSIM从MATLAB迁移到Python，支持6G研究，整合3D天线数据格式，验证统计一致性，为AI驱动的信道建模提供可扩展基础


<details>
  <summary>Details</summary>
Motivation: AI无线信道建模需要大量准确且物理一致的真实测量数据集。现有NYUSIM框架基于MATLAB，需要迁移到Python以提高可扩展性，支持6G研究，并整合现代AI工作流程

Method: 将完整的NYUSIM框架从MATLAB迁移到Python，整合6.75GHz和16.95GHz的新统计模型，引入Ant3D 3D天线数据格式，通过K-S检验、矩分析和端到端测试进行严格验证

Result: 成功迁移并验证了NYUSIM Python版本，保持了与MATLAB v4.0的统计一致性，支持大规模并行数据生成，为AI信道建模提供了可扩展基础

Conclusion: NYUSIM Python版本为未来AI驱动的信道建模建立了稳健、可验证且可扩展的基础，支持6G研究并整合现代AI工作流程

Abstract: Integrating artificial intelligence (AI) into wireless channel modeling requires large, accurate, and physically consistent datasets derived from real measurements. Such datasets are essential for training and validating models that learn spatio-temporal channel behavior across frequencies and environments. NYUSIM, introduced by NYU WIRELESS in 2016, generates realistic spatio-temporal channel data using extensive outdoor and indoor measurements between 28 and 142 GHz. To improve scalability and support 6G research, we migrated the complete NYUSIM framework from MATLAB to Python, and are incorporating new statistical model generation capabilities from extensive field measurements in the new 6G upper mid-band spectrum at 6.75 GHz (FR1(C)) and 16.95 GHz (FR3) [1]. The NYUSIM Python also incorporates a 3D antenna data format, referred to as Ant3D, which is a standardized, full-sphere format for defining canonical, commercial, or measured antenna patterns for any statistical or site-specific ray tracing modeling tool. Migration from MATLAB to Python was rigorously validated through Kolmogorov-Smirnov (K-S) tests, moment analysis, and end-to-end testing with unified randomness control, confirming statistical consistency and reproduction of spatio-temporal channel statistics, including spatial consistency with the open-source MATLAB NYUSIM v4.0 implementation. The NYUSIM Python version is designed to integrate with modern AI workflows and enable large-scale parallel data generation, establishing a robust, verified, and extensible foundation for future AI-enabled channel modeling.

</details>


### [17] [Measurement-Based Validation of Geometry-Driven RIS Beam Steering in Industrial Environments](https://arxiv.org/abs/2602.15808)
*Adam Umra,Simon Tewes,Niklas Beckmann,Niels König,Aydin Sezgin,Robert Schmitt*

Main category: eess.SP

TL;DR: 在工业大厅环境中，基于几何驱动的可重构智能表面(RIS)波束赋形技术通过测量验证了其实际可行性，展示了空间选择性聚焦能力。


<details>
  <summary>Details</summary>
Motivation: 虽然几何驱动的RIS配置方法因其简单性和实时操作性而具有吸引力，但在工业大厅等具有密集多径和金属散射的挑战性环境中的性能尚未得到充分验证。

Method: 提出了一种新颖的RIS配置方案，在RIS前方近距离安装四个贴片天线来引导入射场并实现可控反射。使用5 GHz RIS原型在大型工业大厅中进行测量评估，实现基于分析计算的量化配置。

Result: 二维接收功率图显示了一致的空间选择性聚焦。在接收器附近优化的配置产生清晰的功率最大值，而转向偏移位置则导致20-30 dB的快速功率下降。随着RIS-接收器距离增加，由于有限孔径和几何约束，仰角选择性变宽，而方位角转向保持稳健。

Conclusion: 这些结果证实了几何驱动的RIS波束赋形在工业环境中的实际可行性，并支持其在非理想传播条件下用于空间场控制和定位。

Abstract: Reconfigurable intelligent surfaces (RISs) offer programmable control of radio propagation for future wireless systems. For configuration, geometry-driven analytical approaches are appealing for their simplicity and real-time operation, but their performance in challenging environments such as industrial halls with dense multipath and metallic scattering is not well established. To this end, we present a measurement-based evaluation of geometry-driven RIS beam steering in a large industrial hall using a 5 GHz RIS prototype. A novel RIS configuration is proposed in which four patch antennas are mounted in close proximity in front of the RIS to steer the incident field and enable controlled reflection. For this setup, analytically computed, quantized configurations are implemented. Two-dimensional received power maps from two measurement areas reveal consistent, spatially selective focusing. Configurations optimized near the receiver produce clear power maxima, while steering to offset locations triggers a rapid 20-30 dB reduction. With increasing RIS-receiver distance, elevation selectivity broadens due to finite-aperture and geometric constraints, while azimuth steering remains robust. These results confirm the practical viability of geometry-driven RIS beam steering in industrial environments and support its use for spatial field control and localization under non-ideal propagation.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [18] [VQ-DSC-R: Robust Vector Quantized-Enabled Digital Semantic Communication With OFDM Transmission](https://arxiv.org/abs/2602.15045)
*Jianqiao Chen,Nan Ma,Xiaodong Xu,Tingting Zhu,Huishi Song,Chen Dong,Wenkai Liu,Rui Meng,Ping Zhang*

Main category: cs.IT

TL;DR: 提出VQ-DSC-R系统，结合向量量化和OFDM传输实现鲁棒的数字语义通信，通过Swin Transformer提取语义特征、ANDVQ减少量化误差、CDM优化信道信息，在真实场景中实现高压缩比和鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 当前语义通信研究主要集中在模拟通信和简化信道模型，缺乏与数字基础设施的互操作性。需要开发能够在实际数字传输环境中工作的鲁棒数字语义通信系统。

Method: 1. 基于Swin Transformer的骨干网络进行分层语义特征提取，结合VQ模块将特征映射到共享语义量化码本；2. 提出ANDVQ方案，利用K近邻统计动态调整量化过程，减少量化误差；3. 使用条件扩散模型优化信道状态信息，设计注意力模块自适应信道噪声；4. 采用三阶段训练策略优化整个系统。

Result: 实验证明VQ-DSC-R系统优于基准方案，在实际场景中实现了高压缩比和鲁棒性能，能够有效应对多径衰落信道和噪声。

Conclusion: VQ-DSC-R系统成功解决了数字语义通信中的关键挑战，为语义通信与数字基础设施的互操作性提供了有效解决方案，在压缩效率和传输鲁棒性方面表现出色。

Abstract: Digital mapping of semantic features is essential for achieving interoperability between semantic communication and practical digital infrastructure. However, current research efforts predominantly concentrate on analog semantic communication with simplified channel models. To bridge these gaps, we develop a robust vector quantized-enabled digital semantic communication (VQ-DSC-R) system built upon orthogonal frequency division multiplexing (OFDM) transmission. Our work encompasses the framework design of VQ-DSC-R, followed by a comprehensive optimization study. Firstly, we design a Swin Transformer-based backbone for hierarchical semantic feature extraction, integrated with VQ modules that map the features into a shared semantic quantized codebook (SQC) for efficient index transmission. Secondly, we propose a differentiable vector quantization with adaptive noise-variance (ANDVQ) scheme to mitigate quantization errors in SQC, which dynamically adjusts the quantization process using K-nearest neighbor statistics, while exponential moving average mechanism stabilizes SQC training. Thirdly, for robust index transmission over multipath fading channel and noise, we develop a conditional diffusion model (CDM) to refine channel state information, and design an attention-based module to dynamically adapt to channel noise. The entire VQ-DSC-R system is optimized via a three-stage training strategy. Extensive experiments demonstrate superiority of VQ-DSC-R over benchmark schemes, achieving high compression ratios and robust performance in practical scenarios.

</details>


### [19] [GRAM-DIFF: Gram Matrix Guided Diffusion for MIMO Channel Estimation](https://arxiv.org/abs/2602.15187)
*Xinyuan Wang,Krishna Narayanan*

Main category: cs.IT

TL;DR: GRAM-DIFF：基于Gram矩阵引导的扩散框架，用于半盲MIMO信道估计，通过结合Gram矩阵引导和似然引导，在信道估计中实现更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的信道估计方法主要利用学习的生成先验，但未能充分利用从数据符号中估计得到的二阶结构信息。在实际系统中，可以从接收符号中估计信道Gram矩阵，这提供了信道子空间结构的实现级信息。

Method: 提出GRAM-DIFF框架，将预训练的角域扩散先验与两种互补的引导机制相结合：1）新颖的Gram矩阵引导项，在反向扩散过程中强制二阶一致性；2）来自导频观测的似然引导。采用信噪比匹配初始化和自适应引导缩放确保稳定性和低推理延迟。

Result: 在3GPP和QuaDRiGa信道模型上的仿真显示，相比确定性扩散基线方法，GRAM-DIFF在归一化均方误差方面有持续改进，在NMSE为0.1时比Fest等人（2024）的基线方法获得4-6 dB的信噪比增益。该框架在相干时间约束下表现出优雅退化，当基于数据的Gram估计变得不可靠时，平滑地恢复到似然引导扩散。

Conclusion: GRAM-DIFF通过有效整合信道Gram矩阵的结构信息，显著提升了半盲MIMO信道估计性能，为实际无线通信系统提供了鲁棒且高效的信道估计解决方案。

Abstract: We propose GRAM-DIFF, a Gram-matrix-guided diffusion framework for semi-blind multiple input multiple output (MIMO) channel estimation. Recent diffusion-based estimators leverage learned generative priors to improve pilot-based channel estimation; but they do not exploit second-order structural information estimated from data symbols. In practical systems, the channel Gram matrix can be estimated from received symbols and it provides realization-level information about channel subspace structure. The proposed method integrates a pre-trained angular-domain diffusion prior with two complementary guidance mechanisms: a novel Gram-matrix guidance term that enforces second-order consistency during the reverse diffusion process, and likelihood guidance from pilot observations. Signal-to-noise ratio (SNR)-matched initialization and adaptive guidance scaling ensure stability and low inference latency. Simulations on 3GPP and QuaDRiGa channel models demonstrate consistent normalized mean-squared error (NMSE) improvements over deterministic diffusion baselines, achieving 4 to 6 dB SNR gains at an NMSE of 0.1 over the baseline in Fest et al. (2024). The framework exhibits graceful degradation under coherence-time constraints, smoothly reverting to likelihood-guided diffusion when data-based Gram estimates become unreliable.

</details>


### [20] [On the Entropy of General Mixture Distributions](https://arxiv.org/abs/2602.15303)
*Namyoon Lee*

Main category: cs.IT

TL;DR: 提出了一种确定性闭式工具包，用于边界估计和精确逼近混合分布的微分熵，通过信息论信道视角将混合熵分解为分量内不确定性平均值和重叠项。


<details>
  <summary>Details</summary>
Motivation: 混合分布是处理多模态数据的重要模型，但即使每个分量密度很简单，混合熵的计算仍然非常困难，因为混合将对数与求和耦合在一起。需要开发直接基于分量参数的边界估计和精确逼近方法。

Method: 采用信息论信道视角：潜在混合标签作为输入，观测作为输出。将混合熵分解为分量内不确定性平均值加上重叠项（量化观测揭示隐藏标签的程度）。使用分量密度间的成对重叠积分来边界估计和逼近重叠项，并通过简单族相关偏移校正Jensen重叠边界的系统偏差，最后通过裁剪步骤保证估计始终遵循通用信息论边界。

Result: 为高斯、因子化拉普拉斯、均匀和混合分布提供了闭式特化，数值实验验证了所得边界和逼近在分离度、维度、分量数量和相关协方差方面的有效性。

Conclusion: 开发了一种确定性闭式工具包，能够准确逼近混合熵，通过信息论信道视角和重叠积分方法解决了混合熵计算的长期难题，为多模态数据分析提供了实用工具。

Abstract: Mixture distributions are a workhorse model for multimodal data in information theory, signal processing, and machine learning. Yet even when each component density is simple, the differential entropy of the mixture is notoriously hard to compute because the mixture couples a logarithm with a sum. This paper develops a deterministic, closed-form toolkit for bounding and accurately approximating mixture entropy directly from component parameters. Our starting point is an information-theoretic channel viewpoint: the latent mixture label plays the role of an input, and the observation is the output. This viewpoint separates mixture entropy into an average within-component uncertainty plus an overlap term that quantifies how much the observation reveals about the hidden label. We then bound and approximate this overlap term using pairwise overlap integrals between component densities, yielding explicit expressions whenever these overlaps admit a closed form. A simple, family-dependent offset corrects the systematic bias of the Jensen overlap bound and is calibrated to be exact in the two limiting regimes of complete overlap and near-perfect separation. A final clipping step guarantees that the estimate always respects universal information-theoretic bounds. Closed-form specializations are provided for Gaussian, factorized Laplacian, uniform, and hybrid mixtures, and numerical experiments validate the resulting bounds and approximations across separation, dimension, number of components, and correlated covariances.

</details>


### [21] [Corrected-Inverse-Gaussian First-Hitting-Time Modeling for Molecular Communication Under Time-Varying Drift](https://arxiv.org/abs/2602.15335)
*Yen-Chi Lee*

Main category: cs.IT

TL;DR: 提出一种可处理的解析信道模型，用于时变漂移下的首次命中时间分子通信系统，扩展经典逆高斯模型到强非平稳漂移条件。


<details>
  <summary>Details</summary>
Motivation: 现有非平稳传输研究主要依赖数值解或参数拟合，缺乏对吸收边界轨迹级到达动力学的闭式描述，需要适用于动态生物和分子通信环境的物理信息、计算高效的信道模型。

Method: 采用测度变换公式，将首次命中时间密度分解为累积漂移位移项和随机边界通量调制因子，推导出修正逆高斯密度解析表达式。

Result: 模型能准确捕捉复杂传输现象（相位调制、多脉冲色散、瞬态回流），在平滑脉冲和突变切换漂移剖面下与高精度蒙特卡洛模拟一致，保持恒定复杂度评估。

Conclusion: 该框架为动态生物和分子通信环境提供了物理信息、计算高效的信道模型，适用于系统级分析和接收器设计。

Abstract: This paper develops a tractable analytical channel model for first-hitting-time molecular communication systems under time-varying drift. While existing studies of nonstationary transport rely primarily on numerical solutions of advection--diffusion equations or parametric impulse-response fitting, they do not provide a closed-form description of trajectory-level arrival dynamics at absorbing boundaries. By adopting a change-of-measure formulation, we reveal a structural decomposition of the first-hitting-time density into a cumulative-drift displacement term and a stochastic boundary-flux modulation factor. This leads to an explicit analytical expression for the Corrected-Inverse-Gaussian (C-IG) density, extending the classical IG model to strongly nonstationary drift conditions while preserving constant-complexity evaluation. High-precision Monte Carlo simulations under both smooth pulsatile and abrupt switching drift profiles confirm that the proposed model accurately captures complex transport phenomena, including phase modulation, multi-pulse dispersion, and transient backflow. The resulting framework provides a physics-informed, computationally efficient channel model suitable for system-level analysis and receiver design in dynamic biological and molecular communication environments.

</details>


### [22] [A Universal Neural Receiver that Learns at the Speed of Wireless](https://arxiv.org/abs/2602.15458)
*Lingjia Liu,Lizhong Zheng,Yang Yi,Robert Calderbank*

Main category: cs.IT

TL;DR: 提出一种基于卷积的通用神经接收器架构，避免传统AI算法所需的离线训练，适应无线环境的快速变化。


<details>
  <summary>Details</summary>
Motivation: 传统基于数学模型的无线网络设计方法在复杂网络环境下逐渐失效，而现有AI算法依赖离线训练，无法适应无线干扰环境的亚毫秒级变化速度。

Method: 设计基于卷积的通用神经接收器，将卷积反演问题分离为"反演哪个卷积"和"实际反卷积"两个部分。使用简单的神经网络执行反卷积，并通过领域知识设置权重来配置网络，避免大量离线训练。

Result: 提出了一种独立于基站技术的接收器架构，能够处理无线频谱中任何部分的任何信号，有望简化国际标准中不同用例的波形选择讨论。

Conclusion: 通过基于领域知识配置的通用神经接收器，可以避免传统AI算法的离线训练限制，适应无线环境的快速变化，提高无线网络的创新速率。

Abstract: Today we design wireless networks using mathematical models that govern communication in different propagation environments. We rely on measurement campaigns to deliver parametrized propagation models, and on the 3GPP standards process to optimize model-based performance, but as wireless networks become more complex this model-based approach is losing ground. Mobile Network Operators (MNOs) are counting on Artificial Intelligence (AI) to transform wireless by increasing spectral efficiency, reducing signaling overhead, and enabling continuous network innovation through software upgrades. They may also be interested in new use cases like integrated sensing and communications (ISAC). All we need is an AI-native physical layer, so why not simply tailor the offline AI algorithms that have revolutionized image and natural language processing to the wireless domain? We argue that these algorithms rely on off-line training that is precluded by the sub-millisecond speeds at which the wireless interference environment changes. We present an alternative architecture, a universal neural receiver based on convolution, which governs transmit and receive signal processing of any signal in any part of the wireless spectrum. Our neural receiver is designed to invert convolution, and we separate the question of which convolution to invert from the actual deconvolution. The neural network that performs deconvolution is very simple, and we configure this network by setting weights based on domain knowledge. By telling our neural network what we know, we avoid extensive offline training. By developing a universal receiver, we hope to simplify discussions about the proper choice of waveform for different use cases in the international standards. Since the receiver architecture is largely independent of technologies introduced at the base station, we hope to increase the rate of innovation in wireless.

</details>
