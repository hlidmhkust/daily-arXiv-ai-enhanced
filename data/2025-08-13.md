<div id=toc></div>

# Table of Contents

- [eess.IV](#eess.IV) [Total: 5]
- [eess.SP](#eess.SP) [Total: 19]
- [cs.IT](#cs.IT) [Total: 5]


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [1] [Variational volume reconstruction with the Deep Ritz Method](https://arxiv.org/abs/2508.08309)
*Conor Rowan,Sumedh Soman,John A. Evans*

Main category: eess.IV

TL;DR: 提出了一种基于Deep Ritz方法的变分体积重建新方法，用于处理稀疏、噪声的切片数据，解决了传统方法依赖图像分割、切片数量有限和计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 针对生物医学成像（如MRI切片到体积重建）中的挑战：噪声切片数据依赖分割、切片数量有限、传统网格方法计算昂贵。

Method: 结合回归损失和修正的Cahn-Hilliard能量，通过神经网络离散化相场，蒙特卡洛积分近似目标，使用ADAM优化。

Result: 方法在稀疏和噪声数据下仍能快速（秒级）生成高质量重建体积。

Conclusion: 该方法有效解决了传统重建中的关键问题，具有实际应用潜力。

Abstract: We present a novel approach to variational volume reconstruction from sparse,
noisy slice data using the Deep Ritz method. Motivated by biomedical imaging
applications such as MRI-based slice-to-volume reconstruction (SVR), our
approach addresses three key challenges: (i) the reliance on image segmentation
to extract boundaries from noisy grayscale slice images, (ii) the need to
reconstruct volumes from a limited number of slice planes, and (iii) the
computational expense of traditional mesh-based methods. We formulate a
variational objective that combines a regression loss designed to avoid image
segmentation by operating on noisy slice data directly with a modified
Cahn-Hilliard energy incorporating anisotropic diffusion to regularize the
reconstructed geometry. We discretize the phase field with a neural network,
approximate the objective at each optimization step with Monte Carlo
integration, and use ADAM to find the minimum of the approximated variational
objective. While the stochastic integration may not yield the true solution to
the variational problem, we demonstrate that our method reliably produces
high-quality reconstructed volumes in a matter of seconds, even when the slice
data is sparse and noisy.

</details>


### [2] [Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance](https://arxiv.org/abs/2508.08431)
*Praveen Sumanasekara,Athulya Ratnayake,Buddhi Wijenayake,Keshawa Ratnayake,Roshan Godaliyadda,Parakrama Ekanayake,Vijitha Herath*

Main category: eess.IV

TL;DR: 提出一种预处理算法，校正光谱尺度变化，提升高光谱解混性能。


<details>
  <summary>Details</summary>
Motivation: 光谱尺度变化（如地形、光照和阴影）影响解混算法精度和收敛性，现有方法难以处理。

Method: 提出一种预处理算法，隔离并补偿尺度变化，为解混提供更干净的输入。

Result: 实验验证算法显著提升多种解混方法性能，误差降低近50%。

Conclusion: 该算法作为补充步骤，可提升现有解混方法的准确性，具有广泛应用潜力。

Abstract: Spectral variability significantly impacts the accuracy and convergence of
hyperspectral unmixing algorithms. While many methods address complex spectral
variability, large-scale variations in spectral signature scale caused by
factors such as topography, illumination, and shadowing remain a major
challenge. These variations often degrade unmixing performance and complicate
model fitting. In this paper, we propose a novel preprocessing algorithm that
corrects scale-induced spectral variability prior to unmixing. By isolating and
compensating for these large-scale multiplicative effects, the algorithm
provides a cleaner input, enabling unmixing methods to focus more effectively
on modeling nonlinear spectral variability and abundance estimation. We present
a rigorous mathematical framework to describe scale variability and extensive
experimental validation of the proposed algorithm. Furthermore, the algorithm's
impact is evaluated across a broad spectrum of state-of-the-art unmixing
algorithms on two synthetic and two real hyperspectral datasets. The proposed
preprocessing step consistently improves the performance of these algorithms,
including those specifically designed to handle spectral variability, with
error reductions close to 50% in many cases. This demonstrates that scale
correction acts as a complementary step, facilitating more accurate unmixing by
existing methods. The algorithm's generality and significant impact highlight
its potential as a key component in practical hyperspectral unmixing pipelines.
The implementation code will be made publicly available upon publication.

</details>


### [3] [Frequency-Assisted Adaptive Sharpening Scheme Considering Bitrate and Quality Tradeoff](https://arxiv.org/abs/2508.08854)
*Yingxue Pang,Shijie Zhao,Haiqiang Wang,Gen Zhan,Junlin Li,Li Zhang*

Main category: eess.IV

TL;DR: 本文提出了一种基于频率辅助的锐化级别预测模型（FreqSP），旨在优化视频质量与比特率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 锐化技术虽能提升视频质量，但过度锐化会导致比特率增加和服务质量下降，因此需要找到最佳锐化级别。

Method: 通过标注视频的最优锐化级别作为基准，利用CNN特征和高频分量预测最佳锐化级别。

Result: 实验证明FreqSP能有效平衡视频质量和比特率。

Conclusion: FreqSP提供了一种高效的方法来优化视频锐化级别，同时控制带宽成本。

Abstract: Sharpening is a widely adopted technique to improve video quality, which can
effectively emphasize textures and alleviate blurring. However, increasing the
sharpening level comes with a higher video bitrate, resulting in degraded
Quality of Service (QoS). Furthermore, the video quality does not necessarily
improve with increasing sharpening levels, leading to issues such as
over-sharpening. Clearly, it is essential to figure out how to boost video
quality with a proper sharpening level while also controlling bandwidth costs
effectively. This paper thus proposes a novel Frequency-assisted Sharpening
level Prediction model (FreqSP). We first label each video with the sharpening
level correlating to the optimal bitrate and quality tradeoff as ground truth.
Then taking uncompressed source videos as inputs, the proposed FreqSP leverages
intricate CNN features and high-frequency components to estimate the optimal
sharpening level. Extensive experiments demonstrate the effectiveness of our
method.

</details>


### [4] [A new dataset and comparison for multi-camera frame synthesis](https://arxiv.org/abs/2508.09068)
*Conall Daly,Anil Kokaram*

Main category: eess.IV

TL;DR: 论文提出了一种新的多相机数据集，用于公平比较帧插值和视图合成方法。实验表明，在真实图像数据上，深度学习方法并未显著优于传统方法，而在合成场景中，3D高斯泼溅方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的帧插值和视图合成方法因数据集偏置难以直接比较，因此需要开发一个公平的数据集。

Method: 使用自定义密集线性相机阵列构建多相机数据集，并评估经典和深度学习帧插值方法与视图合成方法（3D高斯泼溅）的性能。

Result: 在真实图像数据上，深度学习方法与传统方法表现相当，3D高斯泼溅性能较差；在合成场景中，3D高斯泼溅显著优于帧插值方法。

Conclusion: 数据集和场景类型对方法性能有显著影响，3D高斯泼溅在合成场景中更具优势。

Abstract: Many methods exist for frame synthesis in image sequences but can be broadly
categorised into frame interpolation and view synthesis techniques.
Fundamentally, both frame interpolation and view synthesis tackle the same
task, interpolating a frame given surrounding frames in time or space. However,
most frame interpolation datasets focus on temporal aspects with single cameras
moving through time and space, while view synthesis datasets are typically
biased toward stereoscopic depth estimation use cases. This makes direct
comparison between view synthesis and frame interpolation methods challenging.
In this paper, we develop a novel multi-camera dataset using a custom-built
dense linear camera array to enable fair comparison between these approaches.
We evaluate classical and deep learning frame interpolators against a view
synthesis method (3D Gaussian Splatting) for the task of view in-betweening.
Our results reveal that deep learning methods do not significantly outperform
classical methods on real image data, with 3D Gaussian Splatting actually
underperforming frame interpolators by as much as 3.5 dB PSNR. However, in
synthetic scenes, the situation reverses -- 3D Gaussian Splatting outperforms
frame interpolation algorithms by almost 5 dB PSNR at a 95% confidence level.

</details>


### [5] [Efficient motion-based metrics for video frame interpolation](https://arxiv.org/abs/2508.09078)
*Conall Daly,Darren Ramsook,Anil Kokaram*

Main category: eess.IV

TL;DR: 论文研究了如何通过简单处理运动场来评估视频帧插值算法的感知质量，提出了一种基于运动场发散性的新指标，该指标在计算效率和感知相关性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 评估插值内容的感知质量是视频帧插值领域的研究重点，但现有方法在效率和相关性上仍有不足。

Method: 通过处理运动场提出新的质量指标，并在BVI-VFI数据集上验证其与感知评分的相关性。

Result: 新指标（PLCC=0.51）在感知相关性上与FloLPIPS相当，但计算效率更高（速度提升2.7倍）。

Conclusion: 新指标更倾向于感知上更优的插值帧，而非传统PSNR或SSIM高分帧。

Abstract: Video frame interpolation (VFI) offers a way to generate intermediate frames
between consecutive frames of a video sequence. Although the development of
advanced frame interpolation algorithms has received increased attention in
recent years, assessing the perceptual quality of interpolated content remains
an ongoing area of research. In this paper, we investigate simple ways to
process motion fields, with the purposes of using them as video quality metric
for evaluating frame interpolation algorithms. We evaluate these quality
metrics using the BVI-VFI dataset which contains perceptual scores measured for
interpolated sequences. From our investigation we propose a motion metric based
on measuring the divergence of motion fields. This metric correlates reasonably
with these perceptual scores (PLCC=0.51) and is more computationally efficient
(x2.7 speedup) compared to FloLPIPS (a well known motion-based metric). We then
use our new proposed metrics to evaluate a range of state of the art frame
interpolation metrics and find our metrics tend to favour more perceptual
pleasing interpolated frames that may not score highly in terms of PSNR or
SSIM.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [6] [Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation](https://arxiv.org/abs/2508.08257)
*Zacharias Chen,Alexa Cristelle Cahilig,Sarah Dias,Prithu Kolar,Ravi Prakash,Patrick J. Codd*

Main category: eess.SP

TL;DR: 论文提出了一种用于机器人辅助神经外科手术的多模态传感测试平台，通过视觉、接触式麦克风和力传感器的融合，显著提高了组织分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术虽提升了精确度，但缺乏自然感官反馈，尤其在区分健康与肿瘤组织时。现有研究对多模态传感的探索有限。

Method: 设计了模块化测试平台，结合视觉引导、接触式麦克风和力传感器数据，通过交互式图形界面实现实时数据采集与可视化。

Result: 实验表明，多模态融合显著提高了材料分类的准确性。

Conclusion: 该平台为手术中的传感器融合提供了可扩展的解决方案，展示了多模态方法在实时组织边界划分中的潜力。

Abstract: Robot-assisted neurological surgery is receiving growing interest due to the
improved dexterity, precision, and control of surgical tools, which results in
better patient outcomes. However, such systems often limit surgeons' natural
sensory feedback, which is crucial in identifying tissues -- particularly in
oncological procedures where distinguishing between healthy and tumorous tissue
is vital. While imaging and force sensing have addressed the lack of sensory
feedback, limited research has explored multimodal sensing options for accurate
tissue boundary delineation. We present a user-friendly, modular test bench
designed to evaluate and integrate complementary multimodal sensors for tissue
identification. Our proposed system first uses vision-based guidance to
estimate boundary locations with visual cues, which are then refined using data
acquired by contact microphones and a force sensor. Real-time data acquisition
and visualization are supported via an interactive graphical interface.
Experimental results demonstrate that multimodal fusion significantly improves
material classification accuracy. The platform provides a scalable
hardware-software solution for exploring sensor fusion in surgical applications
and demonstrates the potential of multimodal approaches in real-time tissue
boundary delineation.

</details>


### [7] [Hardware-friendly IR-HARQ for Polar SCL Decoders](https://arxiv.org/abs/2508.08425)
*Marwan Jalaleddine,Jiajie Li,Warren J. Gross*

Main category: eess.SP

TL;DR: 将极坐标码的增量冗余混合自动重传请求（IR-HARQ）方案中的集合操作转换为二进制向量操作，并提出一种新的快速节点集成方法以减少硬件实现中的内存开销。


<details>
  <summary>Details</summary>
Motivation: 为了扩展极坐标码在下一代无线通信系统中的应用，需要支持IR-HARQ方案，但现有方案因集合操作和快速节点增加导致硬件实现效率低下。

Method: 将集合操作转换为二进制向量操作，并引入新的快速节点集成方法以避免增加快速节点数量。

Result: 提出的方案仅比不支持IR-HARQ的SCL解码增加25-27%的内存开销。

Conclusion: 通过优化操作方法和节点集成，显著提高了IR-HARQ方案的硬件兼容性和效率。

Abstract: To extend the applications of polar codes within next-generation wireless
communication systems, it is essential to incorporate support for Incremental
Redundancy (IR) Hybrid Automatic Repeat Request (HARQ) schemes. The baseline
IR-HARQ scheme's reliance on set-based operations leads to irregular memory
access patterns, posing significant challenges for efficient hardware
implementation. Furthermore, the introduction of new bit types increases the
number of fast nodes that are decoded without traversing the sub-tree,
resulting in a substantial area overhead when implemented in hardware. To
address these issues and improve hardware compatibility, we propose
transforming the set-based operations within the polar IR-HARQ scheme into
binary vector operations. Additionally, we introduce a new fast node
integration approach that avoids increasing the number of fast nodes, thereby
minimizing the associated area overhead. Our proposed scheme results in a
memory overhead of 25-27% compared to successive cancellation list (SCL)
decoding without IR-HARQ support.

</details>


### [8] [Tensor-Structured Bayesian Channel Prediction for Upper Mid-Band XL-MIMO Systems](https://arxiv.org/abs/2508.08491)
*Hongwei Hou,Yafei Wang,Xinping Yi,Wenjin Wang,Dirk T. M. Slock,Shi Jin*

Main category: eess.SP

TL;DR: 论文提出了一种针对XL-MIMO系统中信道预测的新方法，结合了张量结构建模和贝叶斯推断，解决了移动性和近场传播带来的挑战。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统在移动性下因信道老化和近场传播特性导致性能下降，需要新的信道预测方法。

Method: 提出了基于张量结构的信道模型，结合空间-频率-时间和波束-延迟-多普勒域，利用贝叶斯推断和EM算法进行高效计算。

Result: 数值模拟表明，所提算法在信道预测性能上优于现有方法。

Conclusion: 该方法为XL-MIMO系统在移动场景下的信道预测提供了有效解决方案。

Abstract: The upper mid-band balances coverage and capacity for the future cellular
systems and also embraces XL-MIMO systems, offering enhanced spectral and
energy efficiency. However, these benefits are significantly degraded under
mobility due to channel aging, and further exacerbated by the unique near-field
(NF) and spatial non-stationarity (SnS) propagation in such systems. To address
this challenge, we propose a novel channel prediction approach that
incorporates dedicated channel modeling, probabilistic representations, and
Bayesian inference algorithms for this emerging scenario. Specifically, we
develop tensor-structured channel models in both the spatial-frequency-temporal
(SFT) and beam-delay-Doppler (BDD) domains, which leverage temporal
correlations among multiple pilot symbols for channel prediction. The factor
matrices of multi-linear transformations are parameterized by BDD domain grids
and SnS factors, where beam domain grids are jointly determined by angles and
slopes under spatial-chirp based NF representations. To enable tractable
inference, we replace environment-dependent BDD domain grids with uniformly
sampled ones, and introduce perturbation parameters in each domain to mitigate
grid mismatch. We further propose a hybrid beam domain strategy that integrates
angle-only sampling with slope hyperparameterization to avoid the computational
burden of explicit slope sampling. Based on the probabilistic models, we
develop tensor-structured bi-layer inference (TS-BLI) algorithm under the
expectation-maximization (EM) framework, which reduces computational complexity
via tensor operations by leveraging the bi-layer factor graph for approximate
E-step inference and an alternating strategy with closed-form updates in the
M-step. Numerical simulations based on the near-practical channel simulator
demonstrate the superior channel prediction performance of the proposed
algorithm.

</details>


### [9] [An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets](https://arxiv.org/abs/2508.08506)
*Mehdi Zafari,Divyanshu Pandey,Rahman Doost-Mohammady*

Main category: eess.SP

TL;DR: 本文分析了分布式多用户波束成形（D-MUBF）在TDD多用户MIMO系统中的挑战，特别是频率同步误差的影响，并通过实验评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 研究D-MUBF在频率同步误差下的表现，填补实验研究的空白。

Method: 提供SINR的闭式表达式，并通过RENEW大规模MIMO测试平台进行实验评估。

Result: 实验数据验证了理论分析，并公开数据集供未来研究使用。

Conclusion: D-MUBF在频率同步误差下仍可行，公开数据集有助于进一步研究。

Abstract: Realizing distributed multi-user beamforming (D-MUBF) in time division duplex
(TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One
of the most fundamental challenges is achieving accurate over-the-air (OTA)
timing and frequency synchronization among distributed access points (APs),
particularly due to residual frequency offsets caused by local oscillator (LO)
drifts. Despite decades of research on synchronization for MU-MIMO, there are
only a few experimental studies that evaluate D-MUBF techniques under imperfect
frequency synchronization among distributed antennas. This paper presents an
analytical and experimental assessment of D-MUBF methods in the presence of
frequency synchronization errors. We provide closed-form expressions for
signal-to-interference-plus-noise ratio (SINR) as a function of channel
characteristics and statistical properties of carrier frequency offset (CFO)
among AP antennas. In addition, through experimental evaluations conducted with
the RENEW massive MIMO testbed, we collected comprehensive datasets across
various experimental scenarios. These datasets comprise uplink pilot samples
for channel and CFO estimation, in addition to uplink multi-user data intended
for analyzing D-MUBF techniques. By examining these datasets, we assess the
performance of D-MUBF in the presence of CFO and compare the analytical
predictions with empirical measurements. Furthermore, we make the datasets
publicly available and provide insights on utilizing them for future research
endeavors.

</details>


### [10] [Learning Zero Constellations for Binary MOCZ in Fading Channels](https://arxiv.org/abs/2508.08571)
*Anthony Joseph Perre,Parker Huggins,Alphan Sahin*

Main category: eess.SP

TL;DR: 论文提出了两种设计零星座的方法，用于二进制调制的共轭倒数零点（BMOCZ）。第一种方法将星座设计视为多标签分类问题，直接学习零点的位置；第二种方法引入神经网络解码器，联合学习解码器和零点星座参数。实验表明，神经网络解码器能直接推广到平坦衰落信道，且性能优于传统Huffman BMOCZ星座，但计算复杂度较高。


<details>
  <summary>Details</summary>
Motivation: 设计更高效的零星座方法，提升二进制调制在共轭倒数零点上的性能。

Method: 1. 将星座设计视为多标签分类问题，学习零点位置；2. 引入神经网络解码器，联合学习解码器和星座参数。

Result: 神经网络解码器能推广到平坦衰落信道，性能优于传统方法，但计算复杂度增加。

Conclusion: 提出的方法在性能上有显著提升，但需权衡计算复杂度。

Abstract: In this work, we propose two methods to design zero constellations for binary
modulation on conjugate-reciprocal zeros (BMOCZ). In the first approach, we
treat constellation design as a multi-label binary classification problem and
learn the zero locations for a direct zero-testing (DiZeT) decoder. In the
second approach, we introduce a neural network (NN)-based decoder and jointly
learn the decoder and zero constellation parameters. We show that the NN-based
decoder can directly generalize to flat-fading channels, despite being trained
under additive white Gaussian noise. Furthermore, the results of numerical
simulations demonstrate that learned zero constellations outperform the
canonical, Huffman BMOCZ constellation, with the proposed NN-based decoder
achieving large performance gain at the expense of increased computational
complexity.

</details>


### [11] [Biomedical Signal Processing: EEG and ECG Classification with Discrete Wavelet Transforms, Energy Distribution, and Convolutional Neural Networks](https://arxiv.org/abs/2508.08602)
*Justin London*

Main category: eess.SP

TL;DR: 提出了一种多模态深度学习模型，用于生物医学信号处理，通过小波变换降噪，并将信号转换为2D和3D图像以提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 传统医生分析生理信号易出错，深度学习可提高准确性。

Method: 使用离散小波变换降噪，多模态图像和特征融合框架将信号转换为2D/3D图像。

Result: 多模态方法结合小波变换提高了疾病分类的准确性。

Conclusion: 多模态深度学习模型在生物医学信号处理中表现出优越性能。

Abstract: Biomedical signal processing extract meaningful information from
physiological signals like electrocardiograms (ECGs), electroencephalograms
(EEGs), and electromyograms (EMGs) to diagnose, monitor, and treat medical
conditions and diseases such as seizures, cardiomyopathy, and neuromuscular
disorders, respectively. Traditional manual physician analysis of electrical
recordings is prone to human error as subtle anomolies may not be detected.
Recently, advanced deep learning has significantly improved the accuracy of
biomedical signal analysis. A multi-modal deep learning model is proposed that
utilizes discrete wavelet transforms for signal pre-processing to reduce noise.
A multi-modal image fusion and multimodal feature fusion framework is utilized
that converts numeric biomedical signals into 2D and 3D images for image
processing using Gramian angular fields, recurrency plots, and Markov
transition fields. In this paper, deep learning models are applied to ECG, EEG,
and human activity signals using actual medical datasets, brain, and heart
recordings. The results demonstrate that using a multi-modal approach using
wavelet transforms improves the accuracy of disease and disorder
classification.

</details>


### [12] [Agentic Graph Neural Networks for Wireless Communications and Networking Towards Edge General Intelligence: A Survey](https://arxiv.org/abs/2508.08620)
*Yang Lu,Shengli Zhang,Chang Liu,Ruichen Zhang,Bo Ai,Dusit Niyato,Wei Ni,Xianbin Wang,Abbas Jamalipour*

Main category: eess.SP

TL;DR: 该论文探讨了图神经网络（GNNs）在无线通信网络中的应用，并提出了基于代理人工智能（AI）的GNN框架，以应对动态环境中多样化的无线系统需求。


<details>
  <summary>Details</summary>
Motivation: 通信网络的复杂性和动态性对设计满足高质量服务和时延敏感性的网络提出了挑战，传统GNN的被动学习框架可能无法满足需求。

Method: 提出使用代理AI整合GNN，实现场景和任务感知的边缘通用智能，并综述了GNN在无线通信中的最新应用。

Result: 总结了GNN在传统系统和新兴技术中的应用，并提出了基于大语言模型（LLM）的智能问答框架。

Conclusion: 代理AI驱动的GNN框架有望提升无线通信网络的适应性和智能化水平。

Abstract: The rapid advancement of communication technologies has driven the evolution
of communication networks towards both high-dimensional resource utilization
and multifunctional integration. This evolving complexity poses significant
challenges in designing communication networks to satisfy the growing
quality-of-service and time sensitivity of mobile applications in dynamic
environments. Graph neural networks (GNNs) have emerged as fundamental deep
learning (DL) models for complex communication networks. GNNs not only augment
the extraction of features over network topologies but also enhance scalability
and facilitate distributed computation. However, most existing GNNs follow a
traditional passive learning framework, which may fail to meet the needs of
increasingly diverse wireless systems. This survey proposes the employment of
agentic artificial intelligence (AI) to organize and integrate GNNs, enabling
scenario- and task-aware implementation towards edge general intelligence. To
comprehend the full capability of GNNs, we holistically review recent
applications of GNNs in wireless communications and networking. Specifically,
we focus on the alignment between graph representations and network topologies,
and between neural architectures and wireless tasks. We first provide an
overview of GNNs based on prominent neural architectures, followed by the
concept of agentic GNNs. Then, we summarize and compare GNN applications for
conventional systems and emerging technologies, including physical, MAC, and
network layer designs, integrated sensing and communication (ISAC),
reconfigurable intelligent surface (RIS) and cell-free network architecture. We
further propose a large language model (LLM) framework as an intelligent
question-answering agent, leveraging this survey as a local knowledge base to
enable GNN-related responses tailored to wireless communication research.

</details>


### [13] [Sparse Near-Field Channel Estimation for XL-MIMO via Adaptive Filtering](https://arxiv.org/abs/2508.08663)
*Vidya Bhasker Shukla,Italo Atzeni*

Main category: eess.SP

TL;DR: 该论文提出了一种基于自适应滤波的近场稀疏信道估计方法（PD-ZALMS），用于XL-MIMO系统，显著提升了估计精度并降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 针对下一代无线应用需求，研究XL-MIMO系统在近场区域的稀疏信道估计问题。

Method: 提出了一种基于自适应滤波的PD-ZALMS方法，适用于子阵列架构的近场信道估计。

Result: PD-ZALMS在信道估计精度和计算复杂度上优于传统方法，并在低至中等信噪比下优于最小二乘估计器。

Conclusion: PD-ZALMS是一种高效且准确的近场XL-MIMO信道估计方法。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems
operating at sub-THz carrier frequencies represent a promising solution to meet
the demands of next-generation wireless applications. This work focuses on
sparse channel estimation for XL-MIMO systems operating in the near-field (NF)
regime. Assuming a practical subarray-based architecture, we develop a NF
channel estimation framework based on adaptive filtering, referred to as
\textit{polar-domain zero-attracting least mean squares (PD-ZALMS)}. The
proposed method achieves significantly superior channel estimation accuracy and
lower computational complexity compared with the well-established polar-domain
orthogonal matching pursuit. In addition, the proposed PD-ZALMS is shown to
outperform the oracle least-squares channel estimator at low-to-moderate
signal-to-noise ratio.

</details>


### [14] [VQ-VAE Based Digital Semantic Communication with Importance-Aware OFDM Transmission](https://arxiv.org/abs/2508.08686)
*Ming Lyu,Hao Chen,Dan Wang,Chen Qiu,Guangyin Feng,Nan Ma,Xiaodong Xu*

Main category: eess.SP

TL;DR: 本文提出了一种基于VQ-VAE的数字语义通信系统，通过共享码本和重要性感知OFDM传输提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信系统多基于模拟传输，缺乏与数字通信的兼容性。

Method: 使用VQ-VAE生成共享码本，提取语义特征并数字化；采用重要性感知OFDM传输保护关键特征。

Result: 实验表明，该方案在低信噪比下优于传统DeepSC，重建性能更优。

Conclusion: 提出的数字语义通信系统有效提升了传输效率和兼容性。

Abstract: Semantic communication (SemCom) significantly reduces redundant data and
improves transmission efficiency by extracting the latent features of
information. However, most of the conventional deep learning-based SemCom
systems focus on analog transmission and lack in compatibility with practical
digital communications. This paper proposes a vector quantized-variational
autoencoder (VQ-VAE) based digital SemCom system that directly transmits the
semantic features and incorporates the importance-aware orthogonal frequency
division multiplexing (OFDM) transmission to enhance the SemCom performance,
where the VQ-VAE generates a discrete codebook shared between the transmitter
and receiver. At transmitter, the latent semantic features are firstly
extracted by VQ-VAE, and then the shared codebook is adopted to match these
features, which are subsequently transformed into a discrete version to adapt
the digital transmission. To protect the semantic information, an
importance-aware OFDM transmission strategy is proposed to allocate the key
features near the OFDM reference signals, where the feature importance is
derived from the gradient-based method. At the receiver, the features are
rematched with the shared codebook to further correct errors. Finally,
experimental results demonstrate that our proposed scheme outperforms the
conventional DeepSC and achieves better reconstruction performance under low
SNR region.

</details>


### [15] [Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information](https://arxiv.org/abs/2508.09020)
*Maria Cecilia Fernández Montefiore,Gustavo González,F. Javier López-Martínez,Fernando Gregorio*

Main category: eess.SP

TL;DR: 本文提出了一种改进的SINR统计模型，用于下行MU-MIMO系统在CSIT不完美时的性能分析，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 在下一代无线网络中，理解MU-MIMO系统在CSIT不完美时的性能是一个关键挑战，准确的SINR统计建模对多用户系统的性能分析至关重要。

Method: 提出了一种改进的SINR统计近似模型，保留了现有方法（如基于Gamma的近似）的解析简单性，同时解决了其低估SINR方差的问题。

Result: 在RSMA支持的MIMO下行系统中验证了模型的准确性，适用于不同用户数、天线数和CSIT过时程度。

Conclusion: 改进的SINR模型在广泛系统配置下表现出色，为MU-MIMO系统的性能分析提供了更准确的工具。

Abstract: Understanding the performance of multi-user multiple-input multiple-output
(MU-MIMO) systems under imperfect channel state information at the transmitter
(CSIT) remains a critical challenge in next-generation wireless networks. In
this context, accurate statistical modeling of the
signal-to-interference-plus-noise ratio (SINR) is essential for enabling
tractable performance analysis of multi-user systems. This paper presents an
improved statistical approximation of the SINR for downlink (DL) MU-MIMO
systems with imperfect CSIT. The proposed model retains the analytical
simplicity of existing approaches (e.g., Gamma-based approximations) while
overcoming their limitations, particularly the underestimation of SINR
variance. We evaluate the proposed approximation in the context of
Rate-Splitting Multiple Access (RSMA)-enabled MIMO DL systems with outdated
CSIT. The results demonstrate excellent accuracy across a wide range of system
configurations, including varying numbers of users, antennas, and degrees of
CSIT staleness.

</details>


### [16] [Evaluating Task Execution Performance Under Energy Measurement Overhead](https://arxiv.org/abs/2508.08757)
*Mateen Ashraf,Shahab Jahanbazi,Onel L. A. López*

Main category: eess.SP

TL;DR: 论文探讨了能量感知对能量收集物联网设备任务执行性能的影响，指出能量测量成本可能抵消其潜在优势，并提出了优化测量与任务执行频率的方法。


<details>
  <summary>Details</summary>
Motivation: 传统上忽视的能量测量成本可能抵消能量感知带来的性能提升，因此需要研究如何通过调整操作参数来优化任务执行性能。

Method: 比较了能量盲（EB）和能量感知（EA）任务决策方法，分析了能量测量频率和任务执行频率对任务完成率的影响。

Result: 研究发现，针对特定硬件设计参数，存在最优的能量测量/任务执行频率，可最大化任务完成率；若参数选择不当，EA调度可能表现不如EB调度。

Conclusion: 优化能量测量和任务执行频率对提升能量收集物联网设备的性能至关重要，不当选择可能导致能量感知优势丧失。

Abstract: Energy-awareness for adapting task execution behavior can bring several
benefits in terms of performance improvement in energy harvesting (EH) Internet
of Things (IoT) devices. However, the energy measurement cost of acquiring
energy information, which is traditionally ignored, can potentially neutralize
or even reverse the potential benefits. This paper highlights operational
parameters, such as energy measurement frequency and task execution frequency,
which can be tuned to improve the task execution performance of an EH-IoT
device. To this end, we consider energy-blind (EB) and energy-aware (EA) task
decision approaches and compare their task completion rate performance. We show
that, for specific hardware design parameters of an EH-IoT device, there exists
an optimal energy measurement/task execution frequency that can maximize the
task completion rate in both approaches. Moreover, if these parameters are not
chosen appropriately, then energy measurement costs can cause EA scheduling to
underperform compared to EB scheduling.

</details>


### [17] [Wideband Coplanar Waveguide MIMO Antenna for 6G Millimeter-Wave Applications with Defected Ground Structure](https://arxiv.org/abs/2508.08771)
*Atta Ullah,Daniyal Munir,Daniel Lindenschmitt,Hans D. Schotten*

Main category: eess.SP

TL;DR: 论文介绍了一种新型宽带小天线，适用于6G毫米波频段（25 GHz至33.5 GHz），采用微带贴片结构和缺陷地结构（DGS），展示了单天线和2x2 MIMO天线的设计。


<details>
  <summary>Details</summary>
Motivation: 为6G无线网络的高频段需求提供一种宽带天线解决方案。

Method: 采用微带贴片结构和缺陷地结构（DGS），设计单天线（2元素）和2x2 MIMO天线（8元素）。

Result: 天线在8.5 GHz宽带范围内表现出优异的回波损耗性能。

Conclusion: 该天线设计有望应用于6G毫米波技术的多种场景。

Abstract: This research study introduces a novel small antenna with wideband capacity
for the higher frequency range. As a possible contender for 6G wireless
networks, the proposed antenna is designed to target the 6G Millimeter-Wave
(mmWave) operating bands spanning 25 GHz to 33.5 GHz. With a microstrip patch
structure fed by a coplanar waveguide (CPW) with the defected ground structure
(DGS), a single antenna is introduced and then a design of 2 x 2 MIMO antenna
is presented. The single antenna has 2 elements, while the 2 x 2 MIMO antenna
has 8 elements. It achieves remarkably well in terms of return loss of 8.5 GHz
wideband, which is anticipated to be used for several applications in 6G mmWave
technology.

</details>


### [18] [Patient-Adaptive Focused Transmit Beamforming using Cognitive Ultrasound](https://arxiv.org/abs/2508.08782)
*Wessel L. van Nierop,Oisín Nolan,Tristan S. W. Stevens,Ruud J. G. van Sloun*

Main category: eess.SP

TL;DR: 提出一种患者自适应的聚焦发射方案，通过后验采样和扩散模型减少发射次数，提高超声图像质量和帧率。


<details>
  <summary>Details</summary>
Motivation: 传统聚焦发射波束形成帧率低，3D成像时更慢；非聚焦发射存在运动去相关和谐波成像能力受限的问题。

Method: 利用后验采样和时域扩散模型感知解剖结构，主动选择信息量最大的发射方式。

Result: 在2D和3D数据集上优于随机和等距子采样，对比噪声比更高，仅需2%发射即可估计射血分数。

Conclusion: 方法高效、实时性强，适用于GPU加速，代码开源。

Abstract: Focused transmit beamforming is the most commonly used acquisition scheme for
echocardiograms, but suffers from relatively low frame rates, and in 3D, even
lower volume rates. Fast imaging based on unfocused transmits has disadvantages
such as motion decorrelation and limited harmonic imaging capabilities. This
work introduces a patient-adaptive focused transmit scheme that has the ability
to drastically reduce the number of transmits needed to produce a high-quality
ultrasound image. The method relies on posterior sampling with a temporal
diffusion model to perceive and reconstruct the anatomy based on partial
observations, while subsequently taking an action to acquire the most
informative transmits. This active perception modality outperforms random and
equispaced subsampling on the 2D EchoNet-Dynamic dataset and a 3D Philips
dataset, where we actively select focused elevation planes. Furthermore, we
show it achieves better performance in terms of generalized contrast-to-noise
ratio when compared to the same number of diverging waves transmits on three
in-house echocardiograms. Additionally, we can estimate ejection fraction using
only 2% of the total transmits and show that the method is robust to outlier
patients. Finally, our method can be run in real-time on GPU accelerators from
2023. The code is publicly available at https://tue-bmd.github.io/ulsa/

</details>


### [19] [ReQuestNet: A Foundational Learning model for Channel Estimation](https://arxiv.org/abs/2508.08790)
*Kumar Pratik,Pouriya Sadeghi,Gabriele Cesa,Sanaz Barghi,Joseph B. Soriaga,Yuanning Yu,Supratik Bhattacharjee,Arash Behboodi*

Main category: eess.SP

TL;DR: 提出了一种名为ReQuestNet的新型神经网络架构，用于5G及更高版本的信道估计，解决了传统线性MMSE方法的局限性，并通过联合处理MIMO层和未知预编码的信道，显著简化了信道估计流程。


<details>
  <summary>Details</summary>
Motivation: 解决无线通信系统中信道估计的复杂性，如处理可变资源块、动态传输层和未知预编码等问题，同时克服传统线性MMSE方法的不足。

Method: ReQuestNet由CoarseNet和RefinementNet两个子单元组成，分别进行粗略信道估计和通过跨预编码PRG和MIMO空间维度相关性进行细化。

Result: 仿真结果显示，ReQuestNet在多种信道条件下显著优于传统MMSE方法，在高信噪比下可达到10dB增益，并能有效泛化到未见过的信道配置。

Conclusion: ReQuestNet通过统一模型简化了信道估计流程，并在性能和泛化能力上表现出色，适用于动态和复杂的无线通信环境。

Abstract: In this paper, we present a novel neural architecture for channel estimation
(CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network
(ReQuestNet). It incorporates several practical considerations in wireless
communication systems, such as ability to handle variable number of resource
block (RB), dynamic number of transmit layers, physical resource block groups
(PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a
single unified model, thereby, drastically simplifying the CE pipeline. Besides
it addresses several limitations of the legacy linear MMSE solutions, for
example, by being independent of other reference signals and particularly by
jointly processing MIMO layers and differently precoded channels with unknown
precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet
followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive
(Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet
channel estimate by incorporating correlations across differently precoded
PRGs, and correlation across multiple input multiple output (MIMO) channel
spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet
significantly outperforms genie minimum mean squared error (MMSE) CE across a
wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB
gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen
channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations
under dynamic PRG BS and varying transmit layer allocations.

</details>


### [20] [Iterative Distortion Cancellation Algorithms for Single-Sideband Systems](https://arxiv.org/abs/2508.08796)
*Jun Dong,Tianwai Bo,Zhuo Wang,Haolei Gao,Zhongwei Tan,Yi Dong*

Main category: eess.SP

TL;DR: 提出了一种迭代失真消除算法，用于数字缓解双边带抖动信号幅度对Kramers-Kronig接收器的影响，无需修改物理层结构。


<details>
  <summary>Details</summary>
Motivation: 解决自动偏置控制模块中双边带抖动信号对Kramers-Kronig接收器的负面影响。

Method: 利用KK关系进行初始信号决策，并重建由抖动信号引起的失真。

Result: 实验显示算法将抖动幅度容忍度提高至10% Vπ，80公里光纤传输中接收灵敏度提升超过1 dB。

Conclusion: 提出的失真消除方法有效提升了接收器性能。

Abstract: We propose an iterative distortion cancellation algorithm to digitally
mitigate the impact of double-sideband dither signal amplitude from the
automatic bias control module on Kramers-Kronig receivers without modifying
physical layer structures. The algorithm utilizes the KK relation for initial
signal decisions and reconstructs the distortion caused by dither signals.
Experimental tests in back-to-back showed it improved tolerance to dither
amplitudes up to 10% V{\pi}. For 80-km fiber transmission, the algorithm
increased the receiver sensitivity by more than 1 dB, confirming the
effectiveness of the proposed distortion cancellation method.

</details>


### [21] [Trajectory-adaptive Beam Shaping: Towards Beam-Management-Free Near-field Communications](https://arxiv.org/abs/2508.08894)
*Sicong Ye,Yulan Gao,Ming Xiao,Peng Wang,Marios Poulakis,Ulrik Imberg*

Main category: eess.SP

TL;DR: 论文提出了一种名为TABS的新方法，通过预定义轨迹自适应调整波束形状，减少实时波束管理的需求，提升毫米波和太赫兹频段的通信性能。


<details>
  <summary>Details</summary>
Motivation: 毫米波和太赫兹频段的高频通信虽能提升数据吞吐量，但面临严重的路径损耗和波束对准问题，传统方法计算和信令开销大。

Method: 提出轨迹自适应波束成形（TABS），利用预定义轨迹调整电磁波前，无需实时波束管理。

Result: 仿真验证了TABS在链路性能、开销降低和实现复杂度方面的优越性。

Conclusion: TABS为高频无线通信提供了一种高效、低开销的解决方案。

Abstract: The quest for higher wireless carrier frequencies spanning the
millimeter-wave (mmWave) and Terahertz (THz) bands heralds substantial
enhancements in data throughput and spectral efficiency for next-generation
wireless networks. However, these gains come at the cost of severe path loss
and a heightened risk of beam misalignment due to user mobility, especially
pronounced in near-field communication. Traditional solutions rely on extremely
directional beamforming and frequent beam updates via beam management, but such
techniques impose formidable computational and signaling overhead. In response,
we propose a novel approach termed trajectory-adaptive beam shaping (TABS) that
eliminates the need for real-time beam management by shaping the
electromagnetic wavefront to follow the user's predefined trajectory. Drawing
inspiration from self-accelerating beams in optics, TABS concentrates energy
along pre-defined curved paths corresponding to the user's motion without
requiring real-time beam reconfiguration. We further introduce a dedicated
quantitative metric to characterize performance under the TABS framework.
Comprehensive simulations substantiate the superiority of TABS in terms of link
performance, overhead reduction, and implementation complexity.

</details>


### [22] [Scalable RIS-Aided Beamforming Strategies for Near-Field MU-MISO via Multi-Antenna Feeder](https://arxiv.org/abs/2508.08993)
*Giulia Torcolacci,Malte Schellmann,Davide Dardari*

Main category: eess.SP

TL;DR: 论文提出了一种模块化波束成形框架，用于近场区域的可重构智能表面（RIS）辅助多用户通信，基于一种新型天线架构（AT-RIS）。分析了多种实现方案，发现对角T-RIS架构在公平性和可扩展性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究近场区域RIS辅助多用户通信的模块化波束成形框架，探索不同架构和预编码方案的性能与复杂度权衡。

Method: 提出AT-RIS架构，结合主动多天线馈源（AMAF）和透射RIS（T-RIS），分析对角和非对角T-RIS架构，并采用聚焦、最小均方误差和特征模分解等预编码方案。

Result: 非对角方案在用户少且角度分离度高时总和速率最高，但对角T-RIS架构（尤其是聚焦方案）在公平性和可扩展性方面表现更优。

Conclusion: 对角AT-RIS架构是近场多用户系统的实用解决方案，平衡了频谱效率、复杂度和公平性。

Abstract: This paper investigates a modular beamforming framework for reconfigurable
intelligent surface (RIS)-aided multi-user (MU) communications in the
near-field regime, built upon a novel antenna architecture integrating an
active multi-antenna feeder (AMAF) array with a transmissive RIS (T-RIS),
referred to as AT-RIS. This decoupling enables coordinated yet independently
configurable designs in the AMAF and T-RIS domains, supporting flexible
strategies with diverse complexity-performance trade-offs. Several
implementations are analyzed, including diagonal and non-diagonal T-RIS
architectures, paired with precoding schemes based on focusing, minimum mean
square error, and eigenmode decomposition. Simulation results demonstrate that
while non-diagonal schemes maximize sum rate in scenarios with a limited number
of User Equipments (UEs) and high angular separability, they exhibit fairness
and scalability limitations as UE density increases. Conversely, diagonal T-RIS
configurations, particularly the proposed focusing-based scheme with uniform
feeder-side power allocation, offer robust, fair, and scalable performance with
minimal channel state information. The findings emphasize the critical impact
of UEs' angular separability and reveal inherent trade-offs among spectral
efficiency, complexity, and fairness, positioning diagonal AT-RIS architectures
as practical solutions for scalable near-field MU multiple-input single-output
systems.

</details>


### [23] [Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins](https://arxiv.org/abs/2508.09055)
*Lorenzo Cazzella,Francesco Linsalata,Mahdi Maleki,Damiano Badini,Matteo Matteucci,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 本文提出Chartwin方法，将定位导向的信道制图与动态数字网络孪生（DNT）结合，展示了半监督信道制图在构建空间一致性地图中的显著性能。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统需要空间一致的信道表示以高效完成通信任务，信道制图作为一种无监督学习技术被引入。

Method: 提出Chartwin方法，结合定位导向的信道制图和动态DNT，进行半监督信道制图。

Result: 静态DNT的定位误差约为4.5米，动态DNT约为6米。

Conclusion: Chartwin方法在信道制图和定位中表现优异，支持DNT辅助的信道制图与定位。

Abstract: Wireless communication systems can significantly benefit from the
availability of spatially consistent representations of the wireless channel to
efficiently perform a wide range of communication tasks. Towards this purpose,
channel charting has been introduced as an effective unsupervised learning
technique to achieve both locally and globally consistent radio maps. In this
letter, we propose Chartwin, a case study on the integration of
localization-oriented channel charting with dynamic Digital Network Twins
(DNTs). Numerical results showcase the significant performance of
semi-supervised channel charting in constructing a spatially consistent chart
of the considered extended urban environment. The considered method results in
$\approx$ 4.5 m localization error for the static DNT and $\approx$ 6 m in the
dynamic DNT, fostering DNT-aided channel charting and localization.

</details>


### [24] [Spectral Efficiency Considerations for 6G](https://arxiv.org/abs/2508.09117)
*Joseph Boccuzzi*

Main category: eess.SP

TL;DR: 论文提出了一种新的系统指标RUE（无线电资源利用效率），用于量化未来6G需求中无线电资源的利用效率，并通过比较典型蜂窝和无小区大规模MIMO部署展示了其必要性。


<details>
  <summary>Details</summary>
Motivation: 随着无线连接向6G发展，需要更高吞吐量、更低延迟和更高可靠性，同时要求更高的效率。现有指标（如SE和EE）不足以全面衡量资源利用效率，因此引入RUE。

Method: 通过分析5G无线电资源、实际限制（如信道矩阵秩不足）和实施损耗（SINR退化）对SE的影响，提出RUE指标，并比较蜂窝和无小区大规模MIMO的性能。

Result: 分析表明5G的RUE仅为47%，显示6G有显著改进空间。同时，增加传输带宽（从100MHz到1.6GHz）和提出支持6G及AI-RAN的新一代RAN架构。

Conclusion: RUE是衡量6G资源利用效率的关键指标，未来研究应关注提升RUE的算法和架构设计。

Abstract: As wireless connectivity continues to evolve towards 6G, there is an
ever-increasing demand to not only deliver higher throughput, lower latency,
and improved reliability, but also do so as efficiently as possible. To this
point, the term efficiency has been quantified through applications to Spectral
Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new
system metric called Radio Resource Utilization Efficiency (RUE). This metric
quantifies the efficiency of the available radio resources (Spectrum, Access
Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We
compare the system performance of Typical Cellular and Cell-Free Massive MIMO
deployments as a vehicle to demonstrate the need for this new metric. We begin
by providing a concise treatment of items impacting SE by introducing three
categories: 5G Radio Resources, Practical Limitations (such as channel matrix
rank deficiency) and Implementation Losses (SINR degradation). For the example
Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47%
(revealing significant room for improvement when defining 6G). Practical
limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO)
measurements conducted in a commercialized deployment. SE losses are
characterized to offer guidance to advanced algorithms employing Machine
Learning (ML) based techniques. We present the benefits of increasing the
transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next
Generation RAN architecture that can support 6G and AI-RAN.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Achievable Rates of Nanopore-based DNA Storage](https://arxiv.org/abs/2508.08567)
*Brendon McBain,Emanuele Viterbo*

Main category: cs.IT

TL;DR: 论文研究了基于纳米孔的DNA存储的可实现速率，使用不依赖碱基调用算法的通道模型解码纳米孔信号，并提出了一种简化的消息传递算法。


<details>
  <summary>Details</summary>
Motivation: 解决纳米孔信号解码中缺乏DNA存储数据集的问题，并评估纳米孔通道模型的性能。

Method: 使用NNC-Scrappie通道模型和动态时间规整（DTW）算法，推导可实现速率，并在公开数据集上进行验证。

Result: 在100个碱基长度的DNA链上，可实现速率为0.64-1.18 bits/碱基，平均为0.96 bits/碱基。

Conclusion: 该方法为纳米孔DNA存储提供了可行的解码方案，但速率仍有提升空间。

Abstract: This paper studies achievable rates of nanopore-based DNA storage when
nanopore signals are decoded using a tractable channel model that does not rely
on a basecalling algorithm. Specifically, the noisy nanopore channel (NNC) with
the Scrappie pore model generates average output levels via i.i.d. geometric
sample duplications corrupted by i.i.d. Gaussian noise (NNC-Scrappie).
Simplified message passing algorithms are derived for efficient soft decoding
of nanopore signals using NNC-Scrappie. Previously, evaluation of this channel
model was limited by the lack of DNA storage datasets with nanopore signals
included. This is solved by deriving an achievable rate based on the dynamic
time-warping (DTW) algorithm that can be applied to genomic sequencing datasets
subject to constraints that make the resulting rate applicable to DNA storage.
Using a publicly-available dataset from Oxford Nanopore Technologies (ONT), it
is demonstrated that coding over multiple DNA strands of $100$ bases in length
and decoding with the NNC-Scrappie decoder can achieve rates of at least
$0.64-1.18$ bits per base, depending on the channel quality of the nanopore
that is chosen in the sequencing device per channel-use, and $0.96$ bits per
base on average assuming uniformly chosen nanopores. These rates are
pessimistic since they only apply to single reads and do not include
calibration of the pore model to specific nanopores.

</details>


### [26] [Optimum 1-Step Majority-Logic Decoding of Binary Reed-Muller Codes](https://arxiv.org/abs/2508.08736)
*Hoang Ly,Emina Soljanin*

Main category: cs.IT

TL;DR: 论文提出了一种新的单步硬判决解码器，适用于所有参数的RM码，实现了最大单步纠错能力，并在擦除设置中达到理论极限。


<details>
  <summary>Details</summary>
Motivation: 现有解码算法要么步骤多，要么参数受限或性能不足，需要一种更高效且通用的解码方法。

Method: 提出了一种单步多数逻辑解码器，同时进行所有多数投票，无需顺序处理，适用于所有r和m。

Result: 该解码器能纠正最多d_min/4错误，并在擦除设置中恢复最多d_min-1符号，达到理论极限。

Conclusion: 这是首个同时实现最优擦除纠正和最大单步纠错能力的RM码解码器。

Abstract: The classical majority-logic decoder proposed by Reed for Reed-Muller codes
RM(r, m) of order r and length 2^m, unfolds in r+1 sequential steps, decoding
message symbols from highest to lowest degree. Several follow-up decoding
algorithms reduced the number of steps, but for a limited set of parameters, or
at the expense of reduced performance, or relying on the existence of some
combinatorial structures. We show that any one-step majority-logic decoder-that
is, a decoder performing all majority votes in one step simultaneously without
sequential processing-can correct at most d_min/4 errors for all values of r
and m, where d_min denotes the code's minimum distance. We then introduce a new
hard-decision decoder that completes the decoding in a single step and attains
this error-correction limit. It applies to all r and m, and can be viewed as a
parallel realization of Reed's original algorithm, decoding all message symbols
simultaneously. Remarkably, we also prove that the decoder is optimum in the
erasure setting: it recovers the message from any erasure pattern of up to
d_min-1 symbols-the theoretical limit. To our knowledge, this is the first
1-step decoder for RM codes that achieves both optimal erasure correction and
the maximum one-step error correction capability.

</details>


### [27] [Optimized Arithmetic Coding for Efficient Data Compression in the Resource-Constrained Internet of Things(IoT)](https://arxiv.org/abs/2508.08840)
*Vatsala Upadhyay,J. Kokila,Abhishek Vaish*

Main category: cs.IT

TL;DR: 论文提出了一种优化的算术编码方法，适用于物联网环境，通过迭代优化、PCA和基数减少技术，显著提升了压缩效率，降低了计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中大量异构数据的存储和传输面临挑战，传统算术编码计算复杂度高，需优化以适应资源受限环境。

Method: 结合迭代优化、PCA降维和基数减少技术，优化算术编码算法，减少冗余计算并提升压缩效率。

Result: 优化算法在图像数据集上表现优异，压缩比达814:1，单图压缩时间101毫秒，显著降低CPU和内存使用。

Conclusion: 优化后的算术编码算法适合实时应用和资源受限环境，高效支持数据传输与存储。

Abstract: The Internet of Things (IoT) generates vast amounts of heterogeneous data,
ranging from sensor readings to log alerts and images, that pose challenges to
storage and data transmission in resource-constrained environments. In this
context, lossless data compression techniques, like Arithmetic Coding, offer an
effective solution owing to their high compression ratio. However, the standard
Arithmetic Coding technique is computationally intensive, leading to high
memory and processing overhead. This paper proposes an optimized version of
Arithmetic coding for the IoT environment that incorporates three improvements
using Iterative and Iteration Optimizations for minimizing redundant
computations and achieving faster convergence; Principal Component
Analysis(PCA) for dimensionality reduction and identifying key features; and
lastly, Cardinality reduction for grouping similar probabilities to improve the
compression efficiency. The proposed method was evaluated on a dataset of
images and demonstrated significant reductions in the time to compress, CPU
utilization, and memory consumption, and preserves data integrity as seen
through the low RMSE values. The optimized version of the Arithmetic Coding
algorithm achieves an impressive compression ratio of 814:1 and 101 ms to
compress a single image. This makes the optimized algorithm suitable for
real-time applications and resource-constrained environments for efficient data
transmission and storage.

</details>


### [28] [A Dual Framework for Optimized Data Storage and Retrieval using Lightweight Python Blockchain and Scalable Smart Contracts with IPFS](https://arxiv.org/abs/2508.08887)
*Vatsala Upadhyay,J. Kokila,Abhishek Vaish*

Main category: cs.IT

TL;DR: 论文提出了一种高效的物联网数据存储与检索框架，结合IPFS和区块链技术，显著提升了数据上传速度，并优化了智能合约的性能。


<details>
  <summary>Details</summary>
Motivation: 传统云存储模型存在延迟、安全性和高成本问题，而现有的IPFS-区块链方案计算效率低且成本高。

Method: 开发了一种双向数据存储与检索系统，动态监控设备数据并传输至IPFS，记录CID到区块链，通过智能合约实现实时访问。进一步优化为轻量级Python框架。

Result: 数据上传时间从117.12秒降至7.63秒（提升93.47%），进一步优化至4.2秒（提升45%）。

Conclusion: 该框架高效、安全，适用于实时和关键物联网应用，优于现有IPFS-智能合约方案。

Abstract: The exponential growth of IoT data demands efficient, secure, and scalable
storage solutions on one hand, and efficient data migration and retrieval on
the other hand are essential for the systems to be practical and acceptable for
different applications. The traditional cloud-based models face latency,
security, and high operational costs, while existing bi-directional data
storage and retrieval-based IPFS models are not computationally efficient and
incur high gas costs at the cost of a necessary blockchain deployment. To
overcome the challenges of efficient data migration, we initially developed a
2-way data storage and retrieval system as well as a scalable framework that
dynamically monitors and transfers device-generated data to IPFS, records the
content identifier(CID) on a blockchain, and enables secure, real-time access
via smart contracts. Experimental results demonstrate that the existing work
achieved an average data upload time of 117.12 sec for a file size of 500 MB;
our framework achieves a faster upload time of 7.63 sec, marking a 93.47%
improvement. We further optimize the proposed framework to reduce the file
upload time incurred from the smart contracts by introducing a
blockchain-inspired, lightweight, and customizable Python framework that
replicates the storage and retrieval functionalities of a traditional
blockchain, where the file upload time is 4.2 sec, further optimized by 45%
from our previous approach, thus demonstrating its efficiency, security and
suitability for deploy ment in real-time and critical IoT applications and
outperforming the existing IPFS-smart contract based solutions.

</details>


### [29] [Generalized Bicycle Codes with Low Connectivity: Minimum Distance Bounds and Hook Errors](https://arxiv.org/abs/2508.09082)
*Reza Dastbasteh,Olatz Sanz Larrarte,Arun John Moncy,Pedro M. Crespo,Josu Etxezarreta Martinez,Ruben M. Otxoa*

Main category: cs.IT

TL;DR: 论文提出了广义自行车（GB）码的最小距离的新上下界，并分析了两种高度简并的GB码族，展示了其逻辑操作和容错性，同时通过数值模拟评估了其逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 研究GB码的最小距离及其在量子纠错中的应用，以探索其性能和潜力。

Method: 通过理论分析确定GB码的最小距离上下界，构造逻辑操作和容错电路，并使用BP-OSD和MWPM解码器进行数值模拟。

Result: 发现两种GB码族具有特定的参数和性能，逻辑错误率阈值接近旋转表面码。

Conclusion: GB码在量子纠错中表现出与表面码相似的性能，具有潜在的应用价值。

Abstract: We present new upper and lower bounds on the minimum distance of certain
generalized bicycle (GB) codes beyond the reach of techniques for classical
codes capable of even capturing the true minimum distance for some cases. These
bounds are then applied to illustrate the existence and analyze two highly
degenerate GB code families with parameters $[[d^2+1,2,d]]$ for odd $d \geq 3$
and $[[d^2,2,d]]$ for even $d \geq 4$, both having the property that each check
qubit is connected to exactly four data qubits similar to surface codes. For
the odd-distance family, we analyze the structure of low-weight logical Pauli
operators and demonstrate the existence of a fault-tolerant logical CNOT gate
between the two logical qubits, achievable through a simple relabeling of data
qubits. We further construct a syndrome extraction pattern for both families
that does not imply minimum distance reduction arising from extraction circuit
faults that propagate from the check qubits to the data qubits. Finally, we
numerically evaluate their logical error rates under a code capacity
depolarizing noise model using the belief propagation ordered statistics
decoding (BP-OSD) and minimum-weight perfect-matching (MWPM) decoders, yielding
thresholds of approximately $14-16\%$ for the odd and even families, very
similar to those of rotated surface codes.

</details>
